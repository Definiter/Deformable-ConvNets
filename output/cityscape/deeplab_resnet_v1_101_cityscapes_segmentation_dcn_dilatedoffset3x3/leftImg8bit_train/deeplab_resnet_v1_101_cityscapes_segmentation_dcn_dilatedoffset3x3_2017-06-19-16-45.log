2017-06-19 16:45:48,994 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn_dilatedoffset3x3'}

2017-06-19 17:56:20,563 Epoch[0] Batch [10]	Speed: 6.29 samples/sec	Train-FCNLogLoss=2.870659,	
2017-06-19 17:56:25,374 Epoch[0] Batch [20]	Speed: 8.32 samples/sec	Train-FCNLogLoss=2.723430,	
2017-06-19 17:56:29,999 Epoch[0] Batch [30]	Speed: 8.65 samples/sec	Train-FCNLogLoss=2.472432,	
2017-06-19 17:56:35,386 Epoch[0] Batch [40]	Speed: 7.43 samples/sec	Train-FCNLogLoss=2.244370,	
2017-06-19 17:56:40,735 Epoch[0] Batch [50]	Speed: 7.48 samples/sec	Train-FCNLogLoss=2.049585,	
2017-06-19 17:56:46,208 Epoch[0] Batch [60]	Speed: 7.31 samples/sec	Train-FCNLogLoss=1.878050,	
2017-06-19 17:56:51,444 Epoch[0] Batch [70]	Speed: 7.64 samples/sec	Train-FCNLogLoss=1.740297,	
2017-06-19 17:56:57,367 Epoch[0] Batch [80]	Speed: 6.75 samples/sec	Train-FCNLogLoss=1.634267,	
2017-06-19 17:57:03,067 Epoch[0] Batch [90]	Speed: 7.02 samples/sec	Train-FCNLogLoss=1.535717,	
2017-06-19 17:57:08,603 Epoch[0] Batch [100]	Speed: 7.23 samples/sec	Train-FCNLogLoss=1.452344,	
2017-06-19 17:57:14,316 Epoch[0] Batch [110]	Speed: 7.00 samples/sec	Train-FCNLogLoss=1.382817,	
2017-06-19 17:57:19,564 Epoch[0] Batch [120]	Speed: 7.62 samples/sec	Train-FCNLogLoss=1.318896,	
2017-06-19 17:57:24,917 Epoch[0] Batch [130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=1.265851,	
2017-06-19 17:57:29,991 Epoch[0] Batch [140]	Speed: 7.88 samples/sec	Train-FCNLogLoss=1.221575,	
2017-06-19 17:57:35,540 Epoch[0] Batch [150]	Speed: 7.21 samples/sec	Train-FCNLogLoss=1.180583,	
2017-06-19 17:57:40,516 Epoch[0] Batch [160]	Speed: 8.04 samples/sec	Train-FCNLogLoss=1.141973,	
2017-06-19 17:57:45,786 Epoch[0] Batch [170]	Speed: 7.59 samples/sec	Train-FCNLogLoss=1.108713,	
2017-06-19 17:57:50,778 Epoch[0] Batch [180]	Speed: 8.01 samples/sec	Train-FCNLogLoss=1.077484,	
2017-06-19 17:57:56,389 Epoch[0] Batch [190]	Speed: 7.13 samples/sec	Train-FCNLogLoss=1.046062,	
2017-06-19 17:58:01,878 Epoch[0] Batch [200]	Speed: 7.29 samples/sec	Train-FCNLogLoss=1.020738,	
2017-06-19 17:58:07,631 Epoch[0] Batch [210]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.995907,	
2017-06-19 17:58:13,430 Epoch[0] Batch [220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.973226,	
2017-06-19 17:58:18,844 Epoch[0] Batch [230]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.950949,	
2017-06-19 17:58:24,678 Epoch[0] Batch [240]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.931753,	
2017-06-19 17:58:30,455 Epoch[0] Batch [250]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.912628,	
2017-06-19 17:58:35,976 Epoch[0] Batch [260]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.893881,	
2017-06-19 17:58:41,771 Epoch[0] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.881484,	
2017-06-19 17:58:47,409 Epoch[0] Batch [280]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.866390,	
2017-06-19 17:58:53,192 Epoch[0] Batch [290]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.849081,	
2017-06-19 17:58:58,079 Epoch[0] Batch [300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.837221,	
2017-06-19 17:59:02,886 Epoch[0] Batch [310]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.826171,	
2017-06-19 17:59:07,587 Epoch[0] Batch [320]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.815760,	
2017-06-19 17:59:12,585 Epoch[0] Batch [330]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.802518,	
2017-06-19 17:59:17,571 Epoch[0] Batch [340]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.791533,	
2017-06-19 17:59:22,255 Epoch[0] Batch [350]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.780070,	
2017-06-19 17:59:27,199 Epoch[0] Batch [360]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.770015,	
2017-06-19 17:59:32,143 Epoch[0] Batch [370]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.760238,	
2017-06-19 17:59:37,068 Epoch[0] Batch [380]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.750510,	
2017-06-19 17:59:42,464 Epoch[0] Batch [390]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.743181,	
2017-06-19 17:59:47,580 Epoch[0] Batch [400]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.734936,	
2017-06-19 17:59:52,856 Epoch[0] Batch [410]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.726002,	
2017-06-19 17:59:58,323 Epoch[0] Batch [420]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.717910,	
2017-06-19 18:00:03,178 Epoch[0] Batch [430]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.709706,	
2017-06-19 18:00:08,105 Epoch[0] Batch [440]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.701818,	
2017-06-19 18:00:12,931 Epoch[0] Batch [450]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.696677,	
2017-06-19 18:00:18,372 Epoch[0] Batch [460]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.690067,	
2017-06-19 18:00:23,188 Epoch[0] Batch [470]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.683002,	
2017-06-19 18:00:28,549 Epoch[0] Batch [480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.676352,	
2017-06-19 18:00:33,482 Epoch[0] Batch [490]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.669998,	
2017-06-19 18:00:38,631 Epoch[0] Batch [500]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.663258,	
2017-06-19 18:00:43,661 Epoch[0] Batch [510]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.658044,	
2017-06-19 18:00:48,756 Epoch[0] Batch [520]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.651731,	
2017-06-19 18:00:54,295 Epoch[0] Batch [530]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.647054,	
2017-06-19 18:00:59,480 Epoch[0] Batch [540]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.641526,	
2017-06-19 18:01:04,220 Epoch[0] Batch [550]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.637493,	
2017-06-19 18:01:09,224 Epoch[0] Batch [560]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.632370,	
2017-06-19 18:01:14,220 Epoch[0] Batch [570]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.626818,	
2017-06-19 18:01:19,440 Epoch[0] Batch [580]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.622421,	
2017-06-19 18:01:24,607 Epoch[0] Batch [590]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.617780,	
2017-06-19 18:01:30,071 Epoch[0] Batch [600]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.613875,	
2017-06-19 18:01:35,717 Epoch[0] Batch [610]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.608844,	
2017-06-19 18:01:41,622 Epoch[0] Batch [620]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.603904,	
2017-06-19 18:01:46,526 Epoch[0] Batch [630]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.600581,	
2017-06-19 18:01:51,350 Epoch[0] Batch [640]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.596669,	
2017-06-19 18:01:56,059 Epoch[0] Batch [650]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.592856,	
2017-06-19 18:02:01,034 Epoch[0] Batch [660]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.589439,	
2017-06-19 18:02:06,201 Epoch[0] Batch [670]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.586424,	
2017-06-19 18:02:11,443 Epoch[0] Batch [680]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.583422,	
2017-06-19 18:02:19,736 Epoch[0] Batch [690]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.581245,	
2017-06-19 18:02:27,527 Epoch[0] Batch [700]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.577498,	
2017-06-19 18:02:35,611 Epoch[0] Batch [710]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.574585,	
2017-06-19 18:02:43,422 Epoch[0] Batch [720]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.572134,	
2017-06-19 18:02:49,038 Epoch[0] Batch [730]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.569599,	
2017-06-19 18:02:54,367 Epoch[0] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.567444,	
2017-06-19 18:02:59,612 Epoch[0] Batch [750]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.564496,	
2017-06-19 18:03:04,660 Epoch[0] Batch [760]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.562117,	
2017-06-19 18:03:09,692 Epoch[0] Batch [770]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.558830,	
2017-06-19 18:03:15,142 Epoch[0] Batch [780]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.556217,	
2017-06-19 18:03:20,103 Epoch[0] Batch [790]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.552928,	
2017-06-19 18:03:24,819 Epoch[0] Batch [800]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.550513,	
2017-06-19 18:03:30,059 Epoch[0] Batch [810]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.547308,	
2017-06-19 18:03:34,785 Epoch[0] Batch [820]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.545001,	
2017-06-19 18:03:40,075 Epoch[0] Batch [830]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.542852,	
2017-06-19 18:03:45,476 Epoch[0] Batch [840]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.540251,	
2017-06-19 18:03:49,944 Epoch[0] Batch [850]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.537449,	
2017-06-19 18:03:54,742 Epoch[0] Batch [860]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.534700,	
2017-06-19 18:03:59,508 Epoch[0] Batch [870]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.532534,	
2017-06-19 18:04:04,373 Epoch[0] Batch [880]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.530292,	
2017-06-19 18:04:10,054 Epoch[0] Batch [890]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.527682,	
2017-06-19 18:04:15,248 Epoch[0] Batch [900]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.525376,	
2017-06-19 18:04:20,538 Epoch[0] Batch [910]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.522986,	
2017-06-19 18:04:25,643 Epoch[0] Batch [920]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.520949,	
2017-06-19 18:04:31,237 Epoch[0] Batch [930]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.519513,	
2017-06-19 18:04:36,434 Epoch[0] Batch [940]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.517568,	
2017-06-19 18:04:41,723 Epoch[0] Batch [950]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.515218,	
2017-06-19 18:04:46,681 Epoch[0] Batch [960]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.513394,	
2017-06-19 18:04:51,623 Epoch[0] Batch [970]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.511860,	
2017-06-19 18:04:56,653 Epoch[0] Batch [980]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.510112,	
2017-06-19 18:05:01,622 Epoch[0] Batch [990]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.508055,	
2017-06-19 18:05:06,725 Epoch[0] Batch [1000]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.506341,	
2017-06-19 18:05:12,399 Epoch[0] Batch [1010]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.505456,	
2017-06-19 18:05:17,665 Epoch[0] Batch [1020]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.505168,	
2017-06-19 18:05:22,659 Epoch[0] Batch [1030]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.505532,	
2017-06-19 18:05:27,966 Epoch[0] Batch [1040]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.505448,	
2017-06-19 18:05:32,758 Epoch[0] Batch [1050]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.504545,	
2017-06-19 18:05:38,317 Epoch[0] Batch [1060]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.504327,	
2017-06-19 18:05:43,486 Epoch[0] Batch [1070]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.503483,	
2017-06-19 18:05:48,819 Epoch[0] Batch [1080]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.502876,	
2017-06-19 18:05:54,081 Epoch[0] Batch [1090]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.501751,	
2017-06-19 18:06:00,157 Epoch[0] Batch [1100]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.501857,	
2017-06-19 18:06:05,494 Epoch[0] Batch [1110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.501640,	
2017-06-19 18:06:10,777 Epoch[0] Batch [1120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.500554,	
2017-06-19 18:06:16,023 Epoch[0] Batch [1130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.499443,	
2017-06-19 18:06:21,242 Epoch[0] Batch [1140]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.498346,	
2017-06-19 18:06:26,681 Epoch[0] Batch [1150]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.497851,	
2017-06-19 18:06:31,601 Epoch[0] Batch [1160]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.496939,	
2017-06-19 18:06:37,348 Epoch[0] Batch [1170]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.495955,	
2017-06-19 18:06:42,416 Epoch[0] Batch [1180]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.494950,	
2017-06-19 18:06:48,256 Epoch[0] Batch [1190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.494197,	
2017-06-19 18:06:52,814 Epoch[0] Batch [1200]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.494228,	
2017-06-19 18:06:58,026 Epoch[0] Batch [1210]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.494220,	
2017-06-19 18:07:02,694 Epoch[0] Batch [1220]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.492757,	
2017-06-19 18:07:07,803 Epoch[0] Batch [1230]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.491912,	
2017-06-19 18:07:13,128 Epoch[0] Batch [1240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.490405,	
2017-06-19 18:07:18,430 Epoch[0] Batch [1250]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.489336,	
2017-06-19 18:07:23,285 Epoch[0] Batch [1260]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.487556,	
2017-06-19 18:07:28,775 Epoch[0] Batch [1270]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.486002,	
2017-06-19 18:07:35,358 Epoch[0] Batch [1280]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.485580,	
2017-06-19 18:07:41,456 Epoch[0] Batch [1290]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.484988,	
2017-06-19 18:07:46,707 Epoch[0] Batch [1300]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.484058,	
2017-06-19 18:07:52,577 Epoch[0] Batch [1310]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.483075,	
2017-06-19 18:07:57,321 Epoch[0] Batch [1320]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.481464,	
2017-06-19 18:08:02,749 Epoch[0] Batch [1330]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.479900,	
2017-06-19 18:08:07,622 Epoch[0] Batch [1340]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.478608,	
2017-06-19 18:08:12,519 Epoch[0] Batch [1350]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.477382,	
2017-06-19 18:08:17,793 Epoch[0] Batch [1360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.475913,	
2017-06-19 18:08:23,195 Epoch[0] Batch [1370]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.474630,	
2017-06-19 18:08:27,988 Epoch[0] Batch [1380]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.473611,	
2017-06-19 18:08:32,684 Epoch[0] Batch [1390]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.472710,	
2017-06-19 18:08:37,612 Epoch[0] Batch [1400]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.472041,	
2017-06-19 18:08:43,087 Epoch[0] Batch [1410]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.470957,	
2017-06-19 18:08:47,916 Epoch[0] Batch [1420]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.469862,	
2017-06-19 18:08:53,490 Epoch[0] Batch [1430]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.468395,	
2017-06-19 18:08:58,394 Epoch[0] Batch [1440]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.467800,	
2017-06-19 18:09:03,496 Epoch[0] Batch [1450]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.466954,	
2017-06-19 18:09:09,290 Epoch[0] Batch [1460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.465738,	
2017-06-19 18:09:15,052 Epoch[0] Batch [1470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.464597,	
2017-06-19 18:09:19,979 Epoch[0] Batch [1480]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.463497,	
2017-06-19 18:09:22,860 Epoch[0] Train-FCNLogLoss=0.462798
2017-06-19 18:09:22,860 Epoch[0] Time cost=795.226
2017-06-19 18:09:24,224 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0001.params"
2017-06-19 18:09:25,937 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0001.states"
2017-06-19 18:09:32,108 Epoch[1] Batch [10]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.329530,	
2017-06-19 18:09:37,693 Epoch[1] Batch [20]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.302568,	
2017-06-19 18:09:42,248 Epoch[1] Batch [30]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.292030,	
2017-06-19 18:09:47,293 Epoch[1] Batch [40]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.303912,	
2017-06-19 18:09:53,161 Epoch[1] Batch [50]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.307544,	
2017-06-19 18:09:59,193 Epoch[1] Batch [60]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.308829,	
2017-06-19 18:10:05,755 Epoch[1] Batch [70]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.310687,	
2017-06-19 18:10:11,483 Epoch[1] Batch [80]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.301795,	
2017-06-19 18:10:16,504 Epoch[1] Batch [90]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.293567,	
2017-06-19 18:10:20,948 Epoch[1] Batch [100]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.289903,	
2017-06-19 18:10:25,664 Epoch[1] Batch [110]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.288159,	
2017-06-19 18:10:30,544 Epoch[1] Batch [120]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.287745,	
2017-06-19 18:10:35,300 Epoch[1] Batch [130]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.286176,	
2017-06-19 18:10:40,116 Epoch[1] Batch [140]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.286620,	
2017-06-19 18:10:44,824 Epoch[1] Batch [150]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.290074,	
2017-06-19 18:10:50,396 Epoch[1] Batch [160]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.287790,	
2017-06-19 18:10:55,309 Epoch[1] Batch [170]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.286301,	
2017-06-19 18:11:00,322 Epoch[1] Batch [180]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.286328,	
2017-06-19 18:11:04,911 Epoch[1] Batch [190]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.284845,	
2017-06-19 18:11:09,552 Epoch[1] Batch [200]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.283809,	
2017-06-19 18:11:14,029 Epoch[1] Batch [210]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.282883,	
2017-06-19 18:11:18,660 Epoch[1] Batch [220]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.281346,	
2017-06-19 18:11:23,508 Epoch[1] Batch [230]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.279349,	
2017-06-19 18:11:28,816 Epoch[1] Batch [240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.278078,	
2017-06-19 18:11:35,100 Epoch[1] Batch [250]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.278471,	
2017-06-19 18:11:40,694 Epoch[1] Batch [260]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.279178,	
2017-06-19 18:11:46,156 Epoch[1] Batch [270]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.279436,	
2017-06-19 18:11:50,664 Epoch[1] Batch [280]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.278799,	
2017-06-19 18:11:56,617 Epoch[1] Batch [290]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.277137,	
2017-06-19 18:12:02,619 Epoch[1] Batch [300]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.277012,	
2017-06-19 18:12:07,736 Epoch[1] Batch [310]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.276986,	
2017-06-19 18:12:12,767 Epoch[1] Batch [320]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.276780,	
2017-06-19 18:12:18,340 Epoch[1] Batch [330]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.275154,	
2017-06-19 18:12:23,394 Epoch[1] Batch [340]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.274436,	
2017-06-19 18:12:27,733 Epoch[1] Batch [350]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.273726,	
2017-06-19 18:12:33,024 Epoch[1] Batch [360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.272403,	
2017-06-19 18:12:37,485 Epoch[1] Batch [370]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.273016,	
2017-06-19 18:12:41,792 Epoch[1] Batch [380]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.272408,	
2017-06-19 18:12:46,641 Epoch[1] Batch [390]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.270547,	
2017-06-19 18:12:51,395 Epoch[1] Batch [400]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.269386,	
2017-06-19 18:12:56,522 Epoch[1] Batch [410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.268753,	
2017-06-19 18:13:01,461 Epoch[1] Batch [420]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.268289,	
2017-06-19 18:13:06,526 Epoch[1] Batch [430]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.268385,	
2017-06-19 18:13:11,894 Epoch[1] Batch [440]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.268435,	
2017-06-19 18:13:17,277 Epoch[1] Batch [450]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.267552,	
2017-06-19 18:13:22,766 Epoch[1] Batch [460]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.267760,	
2017-06-19 18:13:28,071 Epoch[1] Batch [470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.266583,	
2017-06-19 18:13:33,072 Epoch[1] Batch [480]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.266866,	
2017-06-19 18:13:37,833 Epoch[1] Batch [490]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.266573,	
2017-06-19 18:13:42,916 Epoch[1] Batch [500]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.266444,	
2017-06-19 18:13:47,457 Epoch[1] Batch [510]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.265299,	
2017-06-19 18:13:52,313 Epoch[1] Batch [520]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.264469,	
2017-06-19 18:13:57,271 Epoch[1] Batch [530]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.265041,	
2017-06-19 18:14:02,117 Epoch[1] Batch [540]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.265202,	
2017-06-19 18:14:07,037 Epoch[1] Batch [550]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.264822,	
2017-06-19 18:14:11,730 Epoch[1] Batch [560]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.264399,	
2017-06-19 18:14:16,577 Epoch[1] Batch [570]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.263651,	
2017-06-19 18:14:21,783 Epoch[1] Batch [580]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.262415,	
2017-06-19 18:14:27,345 Epoch[1] Batch [590]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.261535,	
2017-06-19 18:14:32,546 Epoch[1] Batch [600]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.260534,	
2017-06-19 18:14:37,379 Epoch[1] Batch [610]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.259774,	
2017-06-19 18:14:42,729 Epoch[1] Batch [620]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.259059,	
2017-06-19 18:14:48,075 Epoch[1] Batch [630]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.257929,	
2017-06-19 18:14:53,323 Epoch[1] Batch [640]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.257699,	
2017-06-19 18:14:58,668 Epoch[1] Batch [650]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.256761,	
2017-06-19 18:15:03,648 Epoch[1] Batch [660]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.256714,	
2017-06-19 18:15:09,151 Epoch[1] Batch [670]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.256411,	
2017-06-19 18:15:14,524 Epoch[1] Batch [680]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.255553,	
2017-06-19 18:15:20,158 Epoch[1] Batch [690]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.254763,	
2017-06-19 18:15:25,749 Epoch[1] Batch [700]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.254000,	
2017-06-19 18:15:31,057 Epoch[1] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.253912,	
2017-06-19 18:15:36,350 Epoch[1] Batch [720]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.253524,	
2017-06-19 18:15:41,797 Epoch[1] Batch [730]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.253414,	
2017-06-19 18:15:46,905 Epoch[1] Batch [740]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.253308,	
2017-06-19 18:15:52,287 Epoch[1] Batch [750]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.253338,	
2017-06-19 18:15:57,349 Epoch[1] Batch [760]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.253195,	
2017-06-19 18:16:02,147 Epoch[1] Batch [770]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.253517,	
2017-06-19 18:16:07,509 Epoch[1] Batch [780]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.253711,	
2017-06-19 18:16:12,699 Epoch[1] Batch [790]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.253238,	
2017-06-19 18:16:18,498 Epoch[1] Batch [800]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.253226,	
2017-06-19 18:16:23,992 Epoch[1] Batch [810]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.253162,	
2017-06-19 18:16:29,531 Epoch[1] Batch [820]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.252931,	
2017-06-19 18:16:35,317 Epoch[1] Batch [830]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.252680,	
2017-06-19 18:16:40,747 Epoch[1] Batch [840]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.253640,	
2017-06-19 18:16:46,036 Epoch[1] Batch [850]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.253759,	
2017-06-19 18:16:51,216 Epoch[1] Batch [860]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.253455,	
2017-06-19 18:16:55,504 Epoch[1] Batch [870]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.253335,	
2017-06-19 18:17:00,492 Epoch[1] Batch [880]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.253368,	
2017-06-19 18:17:05,740 Epoch[1] Batch [890]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.252769,	
2017-06-19 18:17:10,894 Epoch[1] Batch [900]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.252209,	
2017-06-19 18:17:16,768 Epoch[1] Batch [910]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.251821,	
2017-06-19 18:17:21,502 Epoch[1] Batch [920]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.251838,	
2017-06-19 18:17:26,529 Epoch[1] Batch [930]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.251665,	
2017-06-19 18:17:31,926 Epoch[1] Batch [940]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.251738,	
2017-06-19 18:17:37,372 Epoch[1] Batch [950]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.251604,	
2017-06-19 18:17:42,899 Epoch[1] Batch [960]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.251477,	
2017-06-19 18:17:48,089 Epoch[1] Batch [970]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.251368,	
2017-06-19 18:17:53,605 Epoch[1] Batch [980]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.251585,	
2017-06-19 18:17:58,728 Epoch[1] Batch [990]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.251593,	
2017-06-19 18:18:03,699 Epoch[1] Batch [1000]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.251518,	
2017-06-19 18:18:09,939 Epoch[1] Batch [1010]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.251416,	
2017-06-19 18:18:15,345 Epoch[1] Batch [1020]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.251322,	
2017-06-19 18:18:20,674 Epoch[1] Batch [1030]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.250786,	
2017-06-19 18:18:26,353 Epoch[1] Batch [1040]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.250469,	
2017-06-19 18:18:32,163 Epoch[1] Batch [1050]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.250110,	
2017-06-19 18:18:37,816 Epoch[1] Batch [1060]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.250116,	
2017-06-19 18:18:42,958 Epoch[1] Batch [1070]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.249858,	
2017-06-19 18:18:48,442 Epoch[1] Batch [1080]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.249723,	
2017-06-19 18:18:53,736 Epoch[1] Batch [1090]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.249806,	
2017-06-19 18:18:59,249 Epoch[1] Batch [1100]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.249679,	
2017-06-19 18:19:05,183 Epoch[1] Batch [1110]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.250865,	
2017-06-19 18:19:12,484 Epoch[1] Batch [1120]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.253460,	
2017-06-19 18:19:17,738 Epoch[1] Batch [1130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.254316,	
2017-06-19 18:19:22,939 Epoch[1] Batch [1140]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.254696,	
2017-06-19 18:19:27,897 Epoch[1] Batch [1150]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.254457,	
2017-06-19 18:19:32,385 Epoch[1] Batch [1160]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.254499,	
2017-06-19 18:19:37,161 Epoch[1] Batch [1170]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.254648,	
2017-06-19 18:19:41,836 Epoch[1] Batch [1180]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.254832,	
2017-06-19 18:19:46,386 Epoch[1] Batch [1190]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.254526,	
2017-06-19 18:19:51,449 Epoch[1] Batch [1200]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.254535,	
2017-06-19 18:19:56,368 Epoch[1] Batch [1210]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.254374,	
2017-06-19 18:20:02,483 Epoch[1] Batch [1220]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.254436,	
2017-06-19 18:20:09,100 Epoch[1] Batch [1230]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.254450,	
2017-06-19 18:20:15,034 Epoch[1] Batch [1240]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.254278,	
2017-06-19 18:20:21,269 Epoch[1] Batch [1250]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.254019,	
2017-06-19 18:20:26,806 Epoch[1] Batch [1260]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.254218,	
2017-06-19 18:20:32,320 Epoch[1] Batch [1270]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.253948,	
2017-06-19 18:20:38,172 Epoch[1] Batch [1280]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.254156,	
2017-06-19 18:20:44,417 Epoch[1] Batch [1290]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.253855,	
2017-06-19 18:20:50,223 Epoch[1] Batch [1300]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.253806,	
2017-06-19 18:20:55,924 Epoch[1] Batch [1310]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.253714,	
2017-06-19 18:21:01,563 Epoch[1] Batch [1320]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.253392,	
2017-06-19 18:21:07,173 Epoch[1] Batch [1330]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.253528,	
2017-06-19 18:21:13,022 Epoch[1] Batch [1340]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.253243,	
2017-06-19 18:21:18,505 Epoch[1] Batch [1350]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.253022,	
2017-06-19 18:21:24,021 Epoch[1] Batch [1360]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.252694,	
2017-06-19 18:21:29,771 Epoch[1] Batch [1370]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.252425,	
2017-06-19 18:21:34,500 Epoch[1] Batch [1380]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.252439,	
2017-06-19 18:21:39,180 Epoch[1] Batch [1390]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.252538,	
2017-06-19 18:21:44,606 Epoch[1] Batch [1400]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.252707,	
2017-06-19 18:21:49,693 Epoch[1] Batch [1410]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.252488,	
2017-06-19 18:21:54,736 Epoch[1] Batch [1420]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.252655,	
2017-06-19 18:21:59,298 Epoch[1] Batch [1430]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.252807,	
2017-06-19 18:22:04,398 Epoch[1] Batch [1440]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.252901,	
2017-06-19 18:22:09,630 Epoch[1] Batch [1450]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.252730,	
2017-06-19 18:22:14,692 Epoch[1] Batch [1460]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.252502,	
2017-06-19 18:22:19,874 Epoch[1] Batch [1470]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.252134,	
2017-06-19 18:22:24,844 Epoch[1] Batch [1480]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.251749,	
2017-06-19 18:22:27,536 Epoch[1] Train-FCNLogLoss=0.251567
2017-06-19 18:22:27,536 Epoch[1] Time cost=781.599
2017-06-19 18:22:29,175 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0002.params"
2017-06-19 18:22:31,583 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0002.states"
2017-06-19 18:22:37,117 Epoch[2] Batch [10]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.204453,	
2017-06-19 18:22:41,938 Epoch[2] Batch [20]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.209687,	
2017-06-19 18:22:46,868 Epoch[2] Batch [30]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.201229,	
2017-06-19 18:22:51,795 Epoch[2] Batch [40]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.212184,	
2017-06-19 18:22:57,283 Epoch[2] Batch [50]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.212876,	
2017-06-19 18:23:02,237 Epoch[2] Batch [60]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.212635,	
2017-06-19 18:23:07,080 Epoch[2] Batch [70]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.208472,	
2017-06-19 18:23:11,978 Epoch[2] Batch [80]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.212891,	
2017-06-19 18:23:16,816 Epoch[2] Batch [90]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.211365,	
2017-06-19 18:23:22,485 Epoch[2] Batch [100]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.211344,	
2017-06-19 18:23:28,340 Epoch[2] Batch [110]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.212682,	
2017-06-19 18:23:34,218 Epoch[2] Batch [120]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.212027,	
2017-06-19 18:23:40,709 Epoch[2] Batch [130]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.212948,	
2017-06-19 18:23:46,674 Epoch[2] Batch [140]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.212835,	
2017-06-19 18:23:52,682 Epoch[2] Batch [150]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.211565,	
2017-06-19 18:23:58,891 Epoch[2] Batch [160]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.210881,	
2017-06-19 18:24:05,156 Epoch[2] Batch [170]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.209665,	
2017-06-19 18:24:10,832 Epoch[2] Batch [180]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.209123,	
2017-06-19 18:24:17,191 Epoch[2] Batch [190]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.208446,	
2017-06-19 18:24:23,155 Epoch[2] Batch [200]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.210077,	
2017-06-19 18:24:28,531 Epoch[2] Batch [210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.209660,	
2017-06-19 18:24:34,293 Epoch[2] Batch [220]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.211204,	
2017-06-19 18:24:39,891 Epoch[2] Batch [230]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.211974,	
2017-06-19 18:24:44,457 Epoch[2] Batch [240]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.210603,	
2017-06-19 18:24:49,214 Epoch[2] Batch [250]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.210412,	
2017-06-19 18:24:53,923 Epoch[2] Batch [260]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.209880,	
2017-06-19 18:25:00,188 Epoch[2] Batch [270]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.209906,	
2017-06-19 18:25:06,333 Epoch[2] Batch [280]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.210447,	
2017-06-19 18:25:11,633 Epoch[2] Batch [290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.209932,	
2017-06-19 18:25:16,575 Epoch[2] Batch [300]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.209847,	
2017-06-19 18:25:22,342 Epoch[2] Batch [310]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.209599,	
2017-06-19 18:25:27,188 Epoch[2] Batch [320]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.209217,	
2017-06-19 18:25:32,851 Epoch[2] Batch [330]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.209906,	
2017-06-19 18:25:37,822 Epoch[2] Batch [340]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.210854,	
2017-06-19 18:25:42,932 Epoch[2] Batch [350]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.210646,	
2017-06-19 18:25:48,247 Epoch[2] Batch [360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.210769,	
2017-06-19 18:25:54,018 Epoch[2] Batch [370]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.212403,	
2017-06-19 18:25:59,021 Epoch[2] Batch [380]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.212742,	
2017-06-19 18:26:04,734 Epoch[2] Batch [390]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.213285,	
2017-06-19 18:26:10,082 Epoch[2] Batch [400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.213024,	
2017-06-19 18:26:16,433 Epoch[2] Batch [410]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.213432,	
2017-06-19 18:26:22,496 Epoch[2] Batch [420]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.213627,	
2017-06-19 18:26:29,163 Epoch[2] Batch [430]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.213477,	
2017-06-19 18:26:36,634 Epoch[2] Batch [440]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.213516,	
2017-06-19 18:26:44,254 Epoch[2] Batch [450]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.213451,	
2017-06-19 18:26:52,072 Epoch[2] Batch [460]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.213601,	
2017-06-19 18:27:00,350 Epoch[2] Batch [470]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.214137,	
2017-06-19 18:27:08,223 Epoch[2] Batch [480]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.214755,	
2017-06-19 18:27:16,413 Epoch[2] Batch [490]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.214501,	
2017-06-19 18:27:24,611 Epoch[2] Batch [500]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.213987,	
2017-06-19 18:27:32,813 Epoch[2] Batch [510]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.215244,	
2017-06-19 18:27:41,112 Epoch[2] Batch [520]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.215350,	
2017-06-19 18:27:49,161 Epoch[2] Batch [530]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.215120,	
2017-06-19 18:27:57,319 Epoch[2] Batch [540]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.214722,	
2017-06-19 18:28:05,444 Epoch[2] Batch [550]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.214660,	
2017-06-19 18:28:13,512 Epoch[2] Batch [560]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.214364,	
2017-06-19 18:28:21,739 Epoch[2] Batch [570]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.214571,	
2017-06-19 18:28:29,909 Epoch[2] Batch [580]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.214406,	
2017-06-19 18:28:38,122 Epoch[2] Batch [590]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.215034,	
2017-06-19 18:28:46,393 Epoch[2] Batch [600]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.214892,	
2017-06-19 18:28:54,760 Epoch[2] Batch [610]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.214199,	
2017-06-19 18:29:02,952 Epoch[2] Batch [620]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.213826,	
2017-06-19 18:29:10,974 Epoch[2] Batch [630]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.213127,	
2017-06-19 18:29:19,098 Epoch[2] Batch [640]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.212642,	
2017-06-19 18:29:26,922 Epoch[2] Batch [650]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.212022,	
2017-06-19 18:29:34,891 Epoch[2] Batch [660]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.211352,	
2017-06-19 18:29:43,169 Epoch[2] Batch [670]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.211423,	
2017-06-19 18:29:51,213 Epoch[2] Batch [680]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.211197,	
2017-06-19 18:29:59,644 Epoch[2] Batch [690]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.211365,	
2017-06-19 18:30:07,759 Epoch[2] Batch [700]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.211335,	
2017-06-19 18:30:15,704 Epoch[2] Batch [710]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.211179,	
2017-06-19 18:30:23,846 Epoch[2] Batch [720]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.210799,	
2017-06-19 18:30:31,860 Epoch[2] Batch [730]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.210354,	
2017-06-19 18:30:40,018 Epoch[2] Batch [740]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.209942,	
2017-06-19 18:30:48,003 Epoch[2] Batch [750]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.209911,	
2017-06-19 18:30:56,117 Epoch[2] Batch [760]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.209534,	
2017-06-19 18:31:04,408 Epoch[2] Batch [770]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.209462,	
2017-06-19 18:31:12,338 Epoch[2] Batch [780]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.209484,	
2017-06-19 18:31:20,493 Epoch[2] Batch [790]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.209015,	
2017-06-19 18:31:28,720 Epoch[2] Batch [800]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.208800,	
2017-06-19 18:31:36,762 Epoch[2] Batch [810]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.208539,	
2017-06-19 18:31:44,808 Epoch[2] Batch [820]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.208649,	
2017-06-19 18:31:52,937 Epoch[2] Batch [830]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.208361,	
2017-06-19 18:32:01,025 Epoch[2] Batch [840]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.208239,	
2017-06-19 18:32:08,394 Epoch[2] Batch [850]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.208420,	
2017-06-19 18:32:15,831 Epoch[2] Batch [860]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.208123,	
2017-06-19 18:32:22,939 Epoch[2] Batch [870]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.207650,	
2017-06-19 18:32:30,469 Epoch[2] Batch [880]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.207308,	
2017-06-19 18:32:37,497 Epoch[2] Batch [890]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.207001,	
2017-06-19 18:32:45,277 Epoch[2] Batch [900]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.206843,	
2017-06-19 18:32:52,890 Epoch[2] Batch [910]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.206509,	
2017-06-19 18:32:59,862 Epoch[2] Batch [920]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.206479,	
2017-06-19 18:33:07,385 Epoch[2] Batch [930]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.206373,	
2017-06-19 18:33:14,061 Epoch[2] Batch [940]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.206253,	
2017-06-19 18:33:21,590 Epoch[2] Batch [950]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.205902,	
2017-06-19 18:33:28,735 Epoch[2] Batch [960]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.205999,	
2017-06-19 18:33:36,270 Epoch[2] Batch [970]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.205951,	
2017-06-19 18:33:43,704 Epoch[2] Batch [980]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.205842,	
2017-06-19 18:33:50,836 Epoch[2] Batch [990]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.205669,	
2017-06-19 18:33:57,092 Epoch[2] Batch [1000]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.205442,	
2017-06-19 18:34:03,555 Epoch[2] Batch [1010]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.205187,	
2017-06-19 18:34:10,219 Epoch[2] Batch [1020]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.204913,	
2017-06-19 18:34:17,541 Epoch[2] Batch [1030]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.204905,	
2017-06-19 18:34:24,529 Epoch[2] Batch [1040]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.204668,	
2017-06-19 18:34:32,175 Epoch[2] Batch [1050]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.204758,	
2017-06-19 18:34:39,541 Epoch[2] Batch [1060]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.204635,	
2017-06-19 18:34:47,198 Epoch[2] Batch [1070]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.204753,	
2017-06-19 18:34:55,054 Epoch[2] Batch [1080]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.204549,	
2017-06-19 18:35:02,608 Epoch[2] Batch [1090]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.204333,	
2017-06-19 18:35:10,586 Epoch[2] Batch [1100]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.203981,	
2017-06-19 18:35:17,584 Epoch[2] Batch [1110]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.203531,	
2017-06-19 18:35:24,433 Epoch[2] Batch [1120]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.203178,	
2017-06-19 18:35:31,426 Epoch[2] Batch [1130]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.203338,	
2017-06-19 18:35:38,902 Epoch[2] Batch [1140]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.203103,	
2017-06-19 18:35:46,137 Epoch[2] Batch [1150]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.202975,	
2017-06-19 18:35:53,356 Epoch[2] Batch [1160]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.202868,	
2017-06-19 18:36:00,707 Epoch[2] Batch [1170]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.202672,	
2017-06-19 18:36:08,267 Epoch[2] Batch [1180]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.202362,	
2017-06-19 18:36:15,718 Epoch[2] Batch [1190]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.202194,	
2017-06-19 18:36:23,307 Epoch[2] Batch [1200]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.201995,	
2017-06-19 18:36:31,152 Epoch[2] Batch [1210]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.201660,	
2017-06-19 18:36:39,217 Epoch[2] Batch [1220]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.201458,	
2017-06-19 18:36:47,406 Epoch[2] Batch [1230]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.201124,	
2017-06-19 18:36:54,720 Epoch[2] Batch [1240]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.201215,	
2017-06-19 18:37:02,307 Epoch[2] Batch [1250]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.201034,	
2017-06-19 18:37:09,822 Epoch[2] Batch [1260]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.200661,	
2017-06-19 18:37:18,744 Epoch[2] Batch [1270]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.200844,	
2017-06-19 18:37:27,305 Epoch[2] Batch [1280]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.200819,	
2017-06-19 18:37:36,290 Epoch[2] Batch [1290]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.200502,	
2017-06-19 18:37:45,523 Epoch[2] Batch [1300]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.200461,	
2017-06-19 18:37:54,560 Epoch[2] Batch [1310]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.200273,	
2017-06-19 18:38:03,497 Epoch[2] Batch [1320]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.199947,	
2017-06-19 18:38:12,658 Epoch[2] Batch [1330]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.199872,	
2017-06-19 18:38:21,629 Epoch[2] Batch [1340]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.199721,	
2017-06-19 18:38:30,946 Epoch[2] Batch [1350]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.199594,	
2017-06-19 18:38:39,796 Epoch[2] Batch [1360]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.199346,	
2017-06-19 18:38:48,497 Epoch[2] Batch [1370]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.199190,	
2017-06-19 18:38:57,505 Epoch[2] Batch [1380]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.199004,	
2017-06-19 18:39:06,507 Epoch[2] Batch [1390]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.199100,	
2017-06-19 18:39:15,061 Epoch[2] Batch [1400]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.198986,	
2017-06-19 18:39:23,451 Epoch[2] Batch [1410]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.199381,	
2017-06-19 18:39:31,919 Epoch[2] Batch [1420]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.199483,	
2017-06-19 18:39:40,394 Epoch[2] Batch [1430]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.199526,	
2017-06-19 18:39:49,365 Epoch[2] Batch [1440]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.199834,	
2017-06-19 18:39:58,389 Epoch[2] Batch [1450]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.199631,	
2017-06-19 18:40:07,414 Epoch[2] Batch [1460]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.199315,	
2017-06-19 18:40:16,350 Epoch[2] Batch [1470]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.199315,	
2017-06-19 18:40:25,419 Epoch[2] Batch [1480]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.199644,	
2017-06-19 18:40:31,396 Epoch[2] Train-FCNLogLoss=0.199694
2017-06-19 18:40:31,396 Epoch[2] Time cost=1079.812
2017-06-19 18:40:37,361 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0003.params"
2017-06-19 18:40:41,663 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0003.states"
2017-06-19 18:40:50,149 Epoch[3] Batch [10]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.196779,	
2017-06-19 18:40:55,819 Epoch[3] Batch [20]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.182432,	
2017-06-19 18:41:01,337 Epoch[3] Batch [30]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.185688,	
2017-06-19 18:41:06,384 Epoch[3] Batch [40]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.195695,	
2017-06-19 18:41:11,187 Epoch[3] Batch [50]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.188090,	
2017-06-19 18:41:16,777 Epoch[3] Batch [60]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.190455,	
2017-06-19 18:41:22,101 Epoch[3] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.188917,	
2017-06-19 18:41:28,337 Epoch[3] Batch [80]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.187042,	
2017-06-19 18:41:33,596 Epoch[3] Batch [90]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.185237,	
2017-06-19 18:41:39,276 Epoch[3] Batch [100]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.183375,	
2017-06-19 18:41:44,088 Epoch[3] Batch [110]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.184522,	
2017-06-19 18:41:49,332 Epoch[3] Batch [120]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.182117,	
2017-06-19 18:41:55,190 Epoch[3] Batch [130]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.181740,	
2017-06-19 18:42:00,673 Epoch[3] Batch [140]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.181003,	
2017-06-19 18:42:06,217 Epoch[3] Batch [150]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.180768,	
2017-06-19 18:42:11,552 Epoch[3] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.180314,	
2017-06-19 18:42:17,188 Epoch[3] Batch [170]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.180631,	
2017-06-19 18:42:22,538 Epoch[3] Batch [180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.180276,	
2017-06-19 18:42:28,523 Epoch[3] Batch [190]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.182295,	
2017-06-19 18:42:34,093 Epoch[3] Batch [200]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.183016,	
2017-06-19 18:42:39,537 Epoch[3] Batch [210]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.183047,	
2017-06-19 18:42:45,404 Epoch[3] Batch [220]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.184221,	
2017-06-19 18:42:51,579 Epoch[3] Batch [230]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.184482,	
2017-06-19 18:42:56,949 Epoch[3] Batch [240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.185541,	
2017-06-19 18:43:02,703 Epoch[3] Batch [250]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.185181,	
2017-06-19 18:43:08,561 Epoch[3] Batch [260]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.185799,	
2017-06-19 18:43:14,718 Epoch[3] Batch [270]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.185229,	
2017-06-19 18:43:21,237 Epoch[3] Batch [280]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.184871,	
2017-06-19 18:43:27,173 Epoch[3] Batch [290]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.184906,	
2017-06-19 18:43:33,302 Epoch[3] Batch [300]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.184804,	
2017-06-19 18:43:39,314 Epoch[3] Batch [310]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.185099,	
2017-06-19 18:43:44,991 Epoch[3] Batch [320]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.185492,	
2017-06-19 18:43:50,418 Epoch[3] Batch [330]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.184483,	
2017-06-19 18:43:56,512 Epoch[3] Batch [340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.184040,	
2017-06-19 18:44:02,579 Epoch[3] Batch [350]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.183846,	
2017-06-19 18:44:08,770 Epoch[3] Batch [360]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.183459,	
2017-06-19 18:44:14,967 Epoch[3] Batch [370]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.184951,	
2017-06-19 18:44:20,379 Epoch[3] Batch [380]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.184765,	
2017-06-19 18:44:25,923 Epoch[3] Batch [390]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.184606,	
2017-06-19 18:44:31,844 Epoch[3] Batch [400]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.185260,	
2017-06-19 18:44:38,661 Epoch[3] Batch [410]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.184983,	
2017-06-19 18:44:44,530 Epoch[3] Batch [420]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.185034,	
2017-06-19 18:44:50,655 Epoch[3] Batch [430]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.184569,	
2017-06-19 18:44:56,541 Epoch[3] Batch [440]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.184258,	
2017-06-19 18:45:02,024 Epoch[3] Batch [450]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.183870,	
2017-06-19 18:45:07,934 Epoch[3] Batch [460]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.183896,	
2017-06-19 18:45:13,790 Epoch[3] Batch [470]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.183006,	
2017-06-19 18:45:19,887 Epoch[3] Batch [480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.182279,	
2017-06-19 18:45:25,824 Epoch[3] Batch [490]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.182312,	
2017-06-19 18:45:31,569 Epoch[3] Batch [500]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.181952,	
2017-06-19 18:45:37,578 Epoch[3] Batch [510]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.181526,	
2017-06-19 18:45:44,549 Epoch[3] Batch [520]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.182047,	
2017-06-19 18:45:51,424 Epoch[3] Batch [530]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.182154,	
2017-06-19 18:45:57,900 Epoch[3] Batch [540]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.182983,	
2017-06-19 18:46:04,509 Epoch[3] Batch [550]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.183145,	
2017-06-19 18:46:10,330 Epoch[3] Batch [560]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.183141,	
2017-06-19 18:46:16,671 Epoch[3] Batch [570]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.183328,	
2017-06-19 18:46:21,371 Epoch[3] Batch [580]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.183733,	
2017-06-19 18:46:27,412 Epoch[3] Batch [590]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.183389,	
2017-06-19 18:46:33,809 Epoch[3] Batch [600]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.183144,	
2017-06-19 18:46:39,889 Epoch[3] Batch [610]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.183513,	
2017-06-19 18:46:45,420 Epoch[3] Batch [620]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.183417,	
2017-06-19 18:46:51,008 Epoch[3] Batch [630]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.182948,	
2017-06-19 18:46:56,630 Epoch[3] Batch [640]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.183448,	
2017-06-19 18:47:02,709 Epoch[3] Batch [650]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.183153,	
2017-06-19 18:47:08,363 Epoch[3] Batch [660]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.183031,	
2017-06-19 18:47:14,376 Epoch[3] Batch [670]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.182456,	
2017-06-19 18:47:20,145 Epoch[3] Batch [680]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.182003,	
2017-06-19 18:47:26,551 Epoch[3] Batch [690]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.181867,	
2017-06-19 18:47:32,767 Epoch[3] Batch [700]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.181536,	
2017-06-19 18:47:39,088 Epoch[3] Batch [710]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.181288,	
2017-06-19 18:47:44,642 Epoch[3] Batch [720]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.180998,	
2017-06-19 18:47:50,497 Epoch[3] Batch [730]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.180799,	
2017-06-19 18:47:56,549 Epoch[3] Batch [740]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.180892,	
2017-06-19 18:48:02,663 Epoch[3] Batch [750]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.180939,	
2017-06-19 18:48:08,388 Epoch[3] Batch [760]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.181146,	
2017-06-19 18:48:14,797 Epoch[3] Batch [770]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.180804,	
2017-06-19 18:48:21,675 Epoch[3] Batch [780]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.180922,	
2017-06-19 18:48:28,507 Epoch[3] Batch [790]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.181137,	
2017-06-19 18:48:34,522 Epoch[3] Batch [800]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.180846,	
2017-06-19 18:48:40,320 Epoch[3] Batch [810]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.180697,	
2017-06-19 18:48:46,629 Epoch[3] Batch [820]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.180998,	
2017-06-19 18:48:52,493 Epoch[3] Batch [830]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.181069,	
2017-06-19 18:48:58,488 Epoch[3] Batch [840]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.181054,	
2017-06-19 18:49:03,980 Epoch[3] Batch [850]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.181042,	
2017-06-19 18:49:09,911 Epoch[3] Batch [860]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.180965,	
2017-06-19 18:49:15,993 Epoch[3] Batch [870]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.180831,	
2017-06-19 18:49:21,877 Epoch[3] Batch [880]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.180576,	
2017-06-19 18:49:28,363 Epoch[3] Batch [890]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.180400,	
2017-06-19 18:49:34,085 Epoch[3] Batch [900]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.180303,	
2017-06-19 18:49:40,029 Epoch[3] Batch [910]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.180141,	
2017-06-19 18:49:46,150 Epoch[3] Batch [920]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.179951,	
2017-06-19 18:49:52,893 Epoch[3] Batch [930]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.179772,	
2017-06-19 18:50:00,273 Epoch[3] Batch [940]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.179502,	
2017-06-19 18:50:06,725 Epoch[3] Batch [950]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.179607,	
2017-06-19 18:50:12,692 Epoch[3] Batch [960]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.180249,	
2017-06-19 18:50:18,748 Epoch[3] Batch [970]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.180744,	
2017-06-19 18:50:25,058 Epoch[3] Batch [980]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.180723,	
2017-06-19 18:50:31,244 Epoch[3] Batch [990]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.181476,	
2017-06-19 18:50:37,333 Epoch[3] Batch [1000]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.182390,	
2017-06-19 18:50:43,483 Epoch[3] Batch [1010]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.182639,	
2017-06-19 18:50:49,414 Epoch[3] Batch [1020]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.182777,	
2017-06-19 18:50:55,716 Epoch[3] Batch [1030]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.182825,	
2017-06-19 18:51:01,694 Epoch[3] Batch [1040]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.183100,	
2017-06-19 18:51:08,157 Epoch[3] Batch [1050]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.183112,	
2017-06-19 18:51:13,972 Epoch[3] Batch [1060]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.182925,	
2017-06-19 18:51:19,708 Epoch[3] Batch [1070]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.182631,	
2017-06-19 18:51:25,596 Epoch[3] Batch [1080]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.182501,	
2017-06-19 18:51:31,841 Epoch[3] Batch [1090]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.182359,	
2017-06-19 18:51:37,620 Epoch[3] Batch [1100]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.182311,	
2017-06-19 18:51:43,920 Epoch[3] Batch [1110]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.182201,	
2017-06-19 18:51:50,917 Epoch[3] Batch [1120]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.182071,	
2017-06-19 18:51:57,375 Epoch[3] Batch [1130]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.181860,	
2017-06-19 18:52:03,672 Epoch[3] Batch [1140]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.181866,	
2017-06-19 18:52:09,756 Epoch[3] Batch [1150]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.181752,	
2017-06-19 18:52:15,414 Epoch[3] Batch [1160]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.181855,	
2017-06-19 18:52:21,563 Epoch[3] Batch [1170]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.181741,	
2017-06-19 18:52:27,879 Epoch[3] Batch [1180]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.181515,	
2017-06-19 18:52:33,947 Epoch[3] Batch [1190]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.181337,	
2017-06-19 18:52:39,849 Epoch[3] Batch [1200]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.181314,	
2017-06-19 18:52:45,993 Epoch[3] Batch [1210]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.180969,	
2017-06-19 18:52:52,100 Epoch[3] Batch [1220]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.180897,	
2017-06-19 18:52:58,218 Epoch[3] Batch [1230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.180541,	
2017-06-19 18:53:04,226 Epoch[3] Batch [1240]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.180406,	
2017-06-19 18:53:10,525 Epoch[3] Batch [1250]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.180390,	
2017-06-19 18:53:16,680 Epoch[3] Batch [1260]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.180178,	
2017-06-19 18:53:22,249 Epoch[3] Batch [1270]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.180066,	
2017-06-19 18:53:28,255 Epoch[3] Batch [1280]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.179985,	
2017-06-19 18:53:35,284 Epoch[3] Batch [1290]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.180061,	
2017-06-19 18:53:42,276 Epoch[3] Batch [1300]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.179890,	
2017-06-19 18:53:48,523 Epoch[3] Batch [1310]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.179733,	
2017-06-19 18:53:54,946 Epoch[3] Batch [1320]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.179595,	
2017-06-19 18:54:01,272 Epoch[3] Batch [1330]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.179371,	
2017-06-19 18:54:08,231 Epoch[3] Batch [1340]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.179232,	
2017-06-19 18:54:15,494 Epoch[3] Batch [1350]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.179069,	
2017-06-19 18:54:22,246 Epoch[3] Batch [1360]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.179123,	
2017-06-19 18:54:28,652 Epoch[3] Batch [1370]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.179405,	
2017-06-19 18:54:35,000 Epoch[3] Batch [1380]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.179560,	
2017-06-19 18:54:41,489 Epoch[3] Batch [1390]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.179528,	
2017-06-19 18:54:48,094 Epoch[3] Batch [1400]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.179580,	
2017-06-19 18:54:54,341 Epoch[3] Batch [1410]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.179659,	
2017-06-19 18:55:00,551 Epoch[3] Batch [1420]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.179602,	
2017-06-19 18:55:06,754 Epoch[3] Batch [1430]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.179554,	
2017-06-19 18:55:13,714 Epoch[3] Batch [1440]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.179367,	
2017-06-19 18:55:20,955 Epoch[3] Batch [1450]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.179548,	
2017-06-19 18:55:27,620 Epoch[3] Batch [1460]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.179556,	
2017-06-19 18:55:34,613 Epoch[3] Batch [1470]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.179420,	
2017-06-19 18:55:40,824 Epoch[3] Batch [1480]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.179373,	
2017-06-19 18:55:44,315 Epoch[3] Train-FCNLogLoss=0.179248
2017-06-19 18:55:44,315 Epoch[3] Time cost=902.651
2017-06-19 18:55:45,257 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0004.params"
2017-06-19 18:55:47,007 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0004.states"
2017-06-19 18:55:53,898 Epoch[4] Batch [10]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.166109,	
2017-06-19 18:56:00,058 Epoch[4] Batch [20]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.158066,	
2017-06-19 18:56:06,526 Epoch[4] Batch [30]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.158123,	
2017-06-19 18:56:12,660 Epoch[4] Batch [40]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.159130,	
2017-06-19 18:56:18,286 Epoch[4] Batch [50]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.158511,	
2017-06-19 18:56:24,046 Epoch[4] Batch [60]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.158939,	
2017-06-19 18:56:30,434 Epoch[4] Batch [70]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.159911,	
2017-06-19 18:56:36,889 Epoch[4] Batch [80]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.161592,	
2017-06-19 18:56:42,523 Epoch[4] Batch [90]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.159317,	
2017-06-19 18:56:48,781 Epoch[4] Batch [100]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.159922,	
2017-06-19 18:56:54,972 Epoch[4] Batch [110]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.159560,	
2017-06-19 18:57:00,671 Epoch[4] Batch [120]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.161108,	
2017-06-19 18:57:06,112 Epoch[4] Batch [130]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.162699,	
2017-06-19 18:57:12,270 Epoch[4] Batch [140]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.161929,	
2017-06-19 18:57:18,544 Epoch[4] Batch [150]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.163991,	
2017-06-19 18:57:24,886 Epoch[4] Batch [160]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.164645,	
2017-06-19 18:57:31,983 Epoch[4] Batch [170]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.170698,	
2017-06-19 18:57:37,490 Epoch[4] Batch [180]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.175847,	
2017-06-19 18:57:43,695 Epoch[4] Batch [190]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.175715,	
2017-06-19 18:57:49,641 Epoch[4] Batch [200]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.175504,	
2017-06-19 18:57:55,824 Epoch[4] Batch [210]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.174271,	
2017-06-19 18:58:02,293 Epoch[4] Batch [220]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.173624,	
2017-06-19 18:58:08,105 Epoch[4] Batch [230]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.172687,	
2017-06-19 18:58:14,262 Epoch[4] Batch [240]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.173011,	
2017-06-19 18:58:20,162 Epoch[4] Batch [250]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.172456,	
2017-06-19 18:58:26,891 Epoch[4] Batch [260]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.174517,	
2017-06-19 18:58:33,029 Epoch[4] Batch [270]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.175780,	
2017-06-19 18:58:39,355 Epoch[4] Batch [280]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.183189,	
2017-06-19 18:58:45,460 Epoch[4] Batch [290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.188455,	
2017-06-19 18:58:51,029 Epoch[4] Batch [300]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.192699,	
2017-06-19 18:58:56,838 Epoch[4] Batch [310]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.195000,	
2017-06-19 18:59:03,128 Epoch[4] Batch [320]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.195147,	
2017-06-19 18:59:10,275 Epoch[4] Batch [330]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.196755,	
2017-06-19 18:59:16,711 Epoch[4] Batch [340]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.198255,	
2017-06-19 18:59:22,557 Epoch[4] Batch [350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.198667,	
2017-06-19 18:59:28,971 Epoch[4] Batch [360]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.197860,	
2017-06-19 18:59:35,586 Epoch[4] Batch [370]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.197665,	
2017-06-19 18:59:41,751 Epoch[4] Batch [380]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.198187,	
2017-06-19 18:59:48,360 Epoch[4] Batch [390]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.197808,	
2017-06-19 18:59:54,273 Epoch[4] Batch [400]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.197316,	
2017-06-19 19:00:00,754 Epoch[4] Batch [410]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.196535,	
2017-06-19 19:00:06,944 Epoch[4] Batch [420]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.196323,	
2017-06-19 19:00:13,577 Epoch[4] Batch [430]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.195846,	
2017-06-19 19:00:19,698 Epoch[4] Batch [440]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.195609,	
2017-06-19 19:00:25,877 Epoch[4] Batch [450]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.196056,	
2017-06-19 19:00:32,038 Epoch[4] Batch [460]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.195598,	
2017-06-19 19:00:37,943 Epoch[4] Batch [470]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.195113,	
2017-06-19 19:00:43,885 Epoch[4] Batch [480]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.195099,	
2017-06-19 19:00:50,377 Epoch[4] Batch [490]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.195186,	
2017-06-19 19:00:56,550 Epoch[4] Batch [500]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.194773,	
2017-06-19 19:01:03,717 Epoch[4] Batch [510]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.193850,	
2017-06-19 19:01:09,693 Epoch[4] Batch [520]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.193635,	
2017-06-19 19:01:15,745 Epoch[4] Batch [530]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.193146,	
2017-06-19 19:01:21,779 Epoch[4] Batch [540]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.192783,	
2017-06-19 19:01:28,008 Epoch[4] Batch [550]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.192064,	
2017-06-19 19:01:34,691 Epoch[4] Batch [560]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.192231,	
2017-06-19 19:01:41,157 Epoch[4] Batch [570]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.192504,	
2017-06-19 19:01:47,552 Epoch[4] Batch [580]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.192558,	
2017-06-19 19:01:53,782 Epoch[4] Batch [590]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.192566,	
2017-06-19 19:01:59,961 Epoch[4] Batch [600]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.192306,	
2017-06-19 19:02:06,457 Epoch[4] Batch [610]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.192016,	
2017-06-19 19:02:12,134 Epoch[4] Batch [620]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.191350,	
2017-06-19 19:02:18,194 Epoch[4] Batch [630]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.191592,	
2017-06-19 19:02:24,078 Epoch[4] Batch [640]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.191466,	
2017-06-19 19:02:30,851 Epoch[4] Batch [650]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.190943,	
2017-06-19 19:02:37,316 Epoch[4] Batch [660]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.190553,	
2017-06-19 19:02:43,264 Epoch[4] Batch [670]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.190287,	
2017-06-19 19:02:49,497 Epoch[4] Batch [680]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.190237,	
2017-06-19 19:02:55,514 Epoch[4] Batch [690]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.189931,	
2017-06-19 19:03:01,823 Epoch[4] Batch [700]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.189537,	
2017-06-19 19:03:07,837 Epoch[4] Batch [710]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.189016,	
2017-06-19 19:03:13,786 Epoch[4] Batch [720]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.188652,	
2017-06-19 19:03:19,811 Epoch[4] Batch [730]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.188358,	
2017-06-19 19:03:25,721 Epoch[4] Batch [740]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.188539,	
2017-06-19 19:03:32,338 Epoch[4] Batch [750]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.188553,	
2017-06-19 19:03:38,558 Epoch[4] Batch [760]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.188337,	
2017-06-19 19:03:44,628 Epoch[4] Batch [770]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.188117,	
2017-06-19 19:03:50,290 Epoch[4] Batch [780]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.187558,	
2017-06-19 19:03:56,041 Epoch[4] Batch [790]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.187646,	
2017-06-19 19:04:01,994 Epoch[4] Batch [800]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.187080,	
2017-06-19 19:04:08,553 Epoch[4] Batch [810]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.186864,	
2017-06-19 19:04:14,633 Epoch[4] Batch [820]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.186751,	
2017-06-19 19:04:20,700 Epoch[4] Batch [830]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.186490,	
2017-06-19 19:04:26,461 Epoch[4] Batch [840]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.186380,	
2017-06-19 19:04:32,549 Epoch[4] Batch [850]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.186343,	
2017-06-19 19:04:38,472 Epoch[4] Batch [860]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.186167,	
2017-06-19 19:04:44,557 Epoch[4] Batch [870]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.186055,	
2017-06-19 19:04:50,544 Epoch[4] Batch [880]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.186073,	
2017-06-19 19:04:56,366 Epoch[4] Batch [890]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.185822,	
2017-06-19 19:05:03,262 Epoch[4] Batch [900]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.185659,	
2017-06-19 19:05:10,317 Epoch[4] Batch [910]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.185220,	
2017-06-19 19:05:17,044 Epoch[4] Batch [920]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.184945,	
2017-06-19 19:05:22,842 Epoch[4] Batch [930]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.184643,	
2017-06-19 19:05:28,851 Epoch[4] Batch [940]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.184281,	
2017-06-19 19:05:35,484 Epoch[4] Batch [950]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.183874,	
2017-06-19 19:05:41,155 Epoch[4] Batch [960]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.183659,	
2017-06-19 19:05:46,979 Epoch[4] Batch [970]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.183328,	
2017-06-19 19:05:53,157 Epoch[4] Batch [980]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.183166,	
2017-06-19 19:05:59,661 Epoch[4] Batch [990]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.182897,	
2017-06-19 19:06:06,181 Epoch[4] Batch [1000]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.182872,	
2017-06-19 19:06:13,240 Epoch[4] Batch [1010]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.182468,	
2017-06-19 19:06:20,370 Epoch[4] Batch [1020]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.182135,	
2017-06-19 19:06:26,509 Epoch[4] Batch [1030]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.182130,	
2017-06-19 19:06:32,592 Epoch[4] Batch [1040]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.182030,	
2017-06-19 19:06:38,386 Epoch[4] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.181762,	
2017-06-19 19:06:44,582 Epoch[4] Batch [1060]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.181800,	
2017-06-19 19:06:50,900 Epoch[4] Batch [1070]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.181441,	
2017-06-19 19:06:57,465 Epoch[4] Batch [1080]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.181582,	
2017-06-19 19:07:04,272 Epoch[4] Batch [1090]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.181448,	
2017-06-19 19:07:11,078 Epoch[4] Batch [1100]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.181453,	
2017-06-19 19:07:17,211 Epoch[4] Batch [1110]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.181339,	
2017-06-19 19:07:23,519 Epoch[4] Batch [1120]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.181132,	
2017-06-19 19:07:29,751 Epoch[4] Batch [1130]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.180879,	
2017-06-19 19:07:36,162 Epoch[4] Batch [1140]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.180650,	
2017-06-19 19:07:42,348 Epoch[4] Batch [1150]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.180575,	
2017-06-19 19:07:48,912 Epoch[4] Batch [1160]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.180415,	
2017-06-19 19:07:54,885 Epoch[4] Batch [1170]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.180297,	
2017-06-19 19:08:00,622 Epoch[4] Batch [1180]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.180327,	
2017-06-19 19:08:06,505 Epoch[4] Batch [1190]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.180336,	
2017-06-19 19:08:12,391 Epoch[4] Batch [1200]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.180492,	
2017-06-19 19:08:18,942 Epoch[4] Batch [1210]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.180634,	
2017-06-19 19:08:25,030 Epoch[4] Batch [1220]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.180701,	
2017-06-19 19:08:30,993 Epoch[4] Batch [1230]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.180656,	
2017-06-19 19:08:37,396 Epoch[4] Batch [1240]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.180672,	
2017-06-19 19:08:43,580 Epoch[4] Batch [1250]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.180660,	
2017-06-19 19:08:49,883 Epoch[4] Batch [1260]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.180559,	
2017-06-19 19:08:57,232 Epoch[4] Batch [1270]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.180705,	
2017-06-19 19:09:04,244 Epoch[4] Batch [1280]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.181182,	
2017-06-19 19:09:10,562 Epoch[4] Batch [1290]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.181385,	
2017-06-19 19:09:16,633 Epoch[4] Batch [1300]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.181317,	
2017-06-19 19:09:22,881 Epoch[4] Batch [1310]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.181279,	
2017-06-19 19:09:29,165 Epoch[4] Batch [1320]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.181088,	
2017-06-19 19:09:35,454 Epoch[4] Batch [1330]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.180951,	
2017-06-19 19:09:41,669 Epoch[4] Batch [1340]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.180826,	
2017-06-19 19:09:48,276 Epoch[4] Batch [1350]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.180671,	
2017-06-19 19:09:54,278 Epoch[4] Batch [1360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.180495,	
2017-06-19 19:10:00,414 Epoch[4] Batch [1370]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.180263,	
2017-06-19 19:10:06,760 Epoch[4] Batch [1380]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.180099,	
2017-06-19 19:10:13,555 Epoch[4] Batch [1390]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.179834,	
2017-06-19 19:10:19,921 Epoch[4] Batch [1400]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.179653,	
2017-06-19 19:10:26,065 Epoch[4] Batch [1410]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.179529,	
2017-06-19 19:10:32,435 Epoch[4] Batch [1420]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.179330,	
2017-06-19 19:10:39,058 Epoch[4] Batch [1430]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.179423,	
2017-06-19 19:10:45,275 Epoch[4] Batch [1440]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.179265,	
2017-06-19 19:10:51,866 Epoch[4] Batch [1450]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.179171,	
2017-06-19 19:10:57,751 Epoch[4] Batch [1460]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.179139,	
2017-06-19 19:11:04,251 Epoch[4] Batch [1470]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.179009,	
2017-06-19 19:11:11,078 Epoch[4] Batch [1480]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.179235,	
2017-06-19 19:11:14,959 Epoch[4] Train-FCNLogLoss=0.179124
2017-06-19 19:11:14,959 Epoch[4] Time cost=927.952
2017-06-19 19:11:15,955 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0005.params"
2017-06-19 19:11:17,962 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0005.states"
2017-06-19 19:11:24,948 Epoch[5] Batch [10]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.159511,	
2017-06-19 19:11:31,099 Epoch[5] Batch [20]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.170472,	
2017-06-19 19:11:37,796 Epoch[5] Batch [30]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.171456,	
2017-06-19 19:11:44,425 Epoch[5] Batch [40]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.169142,	
2017-06-19 19:11:50,475 Epoch[5] Batch [50]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.162550,	
2017-06-19 19:11:56,633 Epoch[5] Batch [60]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.157975,	
2017-06-19 19:12:02,973 Epoch[5] Batch [70]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.157706,	
2017-06-19 19:12:09,227 Epoch[5] Batch [80]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.156784,	
2017-06-19 19:12:16,276 Epoch[5] Batch [90]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.159702,	
2017-06-19 19:12:23,210 Epoch[5] Batch [100]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.163248,	
2017-06-19 19:12:29,179 Epoch[5] Batch [110]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.163173,	
2017-06-19 19:12:35,521 Epoch[5] Batch [120]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.162099,	
2017-06-19 19:12:42,322 Epoch[5] Batch [130]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.160955,	
2017-06-19 19:12:48,367 Epoch[5] Batch [140]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.160149,	
2017-06-19 19:12:54,650 Epoch[5] Batch [150]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.160400,	
2017-06-19 19:13:00,654 Epoch[5] Batch [160]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.160478,	
2017-06-19 19:13:07,147 Epoch[5] Batch [170]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.159703,	
2017-06-19 19:13:13,118 Epoch[5] Batch [180]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.159639,	
2017-06-19 19:13:19,279 Epoch[5] Batch [190]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.159574,	
2017-06-19 19:13:25,374 Epoch[5] Batch [200]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.159231,	
2017-06-19 19:13:32,174 Epoch[5] Batch [210]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.157987,	
2017-06-19 19:13:38,502 Epoch[5] Batch [220]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.158587,	
2017-06-19 19:13:44,695 Epoch[5] Batch [230]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.158342,	
2017-06-19 19:13:51,193 Epoch[5] Batch [240]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.158983,	
2017-06-19 19:13:58,538 Epoch[5] Batch [250]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.158844,	
2017-06-19 19:14:04,918 Epoch[5] Batch [260]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.158227,	
2017-06-19 19:14:11,946 Epoch[5] Batch [270]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.157958,	
2017-06-19 19:14:18,361 Epoch[5] Batch [280]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.157141,	
2017-06-19 19:14:24,263 Epoch[5] Batch [290]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.156899,	
2017-06-19 19:14:30,850 Epoch[5] Batch [300]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.157420,	
2017-06-19 19:14:38,010 Epoch[5] Batch [310]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.158711,	
2017-06-19 19:14:44,578 Epoch[5] Batch [320]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.160243,	
2017-06-19 19:14:50,681 Epoch[5] Batch [330]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.160161,	
2017-06-19 19:14:58,131 Epoch[5] Batch [340]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.160214,	
2017-06-19 19:15:05,524 Epoch[5] Batch [350]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.159866,	
2017-06-19 19:15:12,550 Epoch[5] Batch [360]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.160865,	
2017-06-19 19:15:20,151 Epoch[5] Batch [370]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.161245,	
2017-06-19 19:15:27,729 Epoch[5] Batch [380]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.161634,	
2017-06-19 19:15:35,989 Epoch[5] Batch [390]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.161603,	
2017-06-19 19:15:43,392 Epoch[5] Batch [400]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.162376,	
2017-06-19 19:15:50,757 Epoch[5] Batch [410]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.163072,	
2017-06-19 19:15:58,784 Epoch[5] Batch [420]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.162857,	
2017-06-19 19:16:06,321 Epoch[5] Batch [430]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.162705,	
2017-06-19 19:16:13,696 Epoch[5] Batch [440]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.162154,	
2017-06-19 19:16:21,098 Epoch[5] Batch [450]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.162338,	
2017-06-19 19:16:29,031 Epoch[5] Batch [460]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.162456,	
2017-06-19 19:16:36,293 Epoch[5] Batch [470]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.162271,	
2017-06-19 19:16:43,760 Epoch[5] Batch [480]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.162023,	
2017-06-19 19:16:51,173 Epoch[5] Batch [490]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.161991,	
2017-06-19 19:16:58,908 Epoch[5] Batch [500]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.161829,	
2017-06-19 19:17:05,963 Epoch[5] Batch [510]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.161640,	
2017-06-19 19:17:13,594 Epoch[5] Batch [520]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.161318,	
2017-06-19 19:17:20,566 Epoch[5] Batch [530]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.161165,	
2017-06-19 19:17:29,133 Epoch[5] Batch [540]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.161461,	
2017-06-19 19:17:37,442 Epoch[5] Batch [550]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.161524,	
2017-06-19 19:17:45,097 Epoch[5] Batch [560]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.161588,	
2017-06-19 19:17:52,234 Epoch[5] Batch [570]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.161647,	
2017-06-19 19:17:59,872 Epoch[5] Batch [580]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.161959,	
2017-06-19 19:18:06,494 Epoch[5] Batch [590]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.161993,	
2017-06-19 19:18:13,627 Epoch[5] Batch [600]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.162495,	
2017-06-19 19:18:21,107 Epoch[5] Batch [610]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.162350,	
2017-06-19 19:18:28,145 Epoch[5] Batch [620]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.162254,	
2017-06-19 19:18:35,488 Epoch[5] Batch [630]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.162108,	
2017-06-19 19:18:42,558 Epoch[5] Batch [640]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.162058,	
2017-06-19 19:18:50,607 Epoch[5] Batch [650]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.161734,	
2017-06-19 19:18:58,199 Epoch[5] Batch [660]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.161774,	
2017-06-19 19:19:06,260 Epoch[5] Batch [670]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.162020,	
2017-06-19 19:19:14,060 Epoch[5] Batch [680]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.161663,	
2017-06-19 19:19:22,074 Epoch[5] Batch [690]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.161409,	
2017-06-19 19:19:29,449 Epoch[5] Batch [700]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.161359,	
2017-06-19 19:19:37,090 Epoch[5] Batch [710]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.161281,	
2017-06-19 19:19:44,217 Epoch[5] Batch [720]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.161110,	
2017-06-19 19:19:51,266 Epoch[5] Batch [730]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.161134,	
2017-06-19 19:19:58,935 Epoch[5] Batch [740]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.161507,	
2017-06-19 19:20:06,321 Epoch[5] Batch [750]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.161696,	
2017-06-19 19:20:14,382 Epoch[5] Batch [760]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.161575,	
2017-06-19 19:20:22,313 Epoch[5] Batch [770]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.161796,	
2017-06-19 19:20:29,957 Epoch[5] Batch [780]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.162029,	
2017-06-19 19:20:37,757 Epoch[5] Batch [790]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.162427,	
2017-06-19 19:20:45,688 Epoch[5] Batch [800]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.162445,	
2017-06-19 19:20:53,914 Epoch[5] Batch [810]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.162712,	
2017-06-19 19:21:02,031 Epoch[5] Batch [820]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.162787,	
2017-06-19 19:21:10,315 Epoch[5] Batch [830]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.162811,	
2017-06-19 19:21:18,373 Epoch[5] Batch [840]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.162575,	
2017-06-19 19:21:26,601 Epoch[5] Batch [850]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.162275,	
2017-06-19 19:21:34,674 Epoch[5] Batch [860]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.162213,	
2017-06-19 19:21:43,127 Epoch[5] Batch [870]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.162585,	
2017-06-19 19:21:51,248 Epoch[5] Batch [880]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.163863,	
2017-06-19 19:21:59,569 Epoch[5] Batch [890]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.164207,	
2017-06-19 19:22:08,081 Epoch[5] Batch [900]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.164400,	
2017-06-19 19:22:16,410 Epoch[5] Batch [910]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.164520,	
2017-06-19 19:22:24,468 Epoch[5] Batch [920]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.164472,	
2017-06-19 19:22:33,093 Epoch[5] Batch [930]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.164414,	
2017-06-19 19:22:41,675 Epoch[5] Batch [940]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.164351,	
2017-06-19 19:22:50,031 Epoch[5] Batch [950]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.164331,	
2017-06-19 19:22:58,421 Epoch[5] Batch [960]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.164277,	
2017-06-19 19:23:06,746 Epoch[5] Batch [970]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.164220,	
2017-06-19 19:23:15,138 Epoch[5] Batch [980]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.164230,	
2017-06-19 19:23:23,508 Epoch[5] Batch [990]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.164234,	
2017-06-19 19:23:32,052 Epoch[5] Batch [1000]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.164058,	
2017-06-19 19:23:40,322 Epoch[5] Batch [1010]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.164035,	
2017-06-19 19:23:48,736 Epoch[5] Batch [1020]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.164595,	
2017-06-19 19:23:57,120 Epoch[5] Batch [1030]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.164677,	
2017-06-19 19:24:05,396 Epoch[5] Batch [1040]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.164498,	
2017-06-19 19:24:13,647 Epoch[5] Batch [1050]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.164272,	
2017-06-19 19:24:21,947 Epoch[5] Batch [1060]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.164183,	
2017-06-19 19:24:30,274 Epoch[5] Batch [1070]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.163866,	
2017-06-19 19:24:38,723 Epoch[5] Batch [1080]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.163717,	
2017-06-19 19:24:47,009 Epoch[5] Batch [1090]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.163810,	
2017-06-19 19:24:55,541 Epoch[5] Batch [1100]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.163776,	
2017-06-19 19:25:03,865 Epoch[5] Batch [1110]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.163994,	
2017-06-19 19:25:12,146 Epoch[5] Batch [1120]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.163823,	
2017-06-19 19:25:20,515 Epoch[5] Batch [1130]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.163964,	
2017-06-19 19:25:29,165 Epoch[5] Batch [1140]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.163975,	
2017-06-19 19:25:37,453 Epoch[5] Batch [1150]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.163925,	
2017-06-19 19:25:45,726 Epoch[5] Batch [1160]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.163866,	
2017-06-19 19:25:54,019 Epoch[5] Batch [1170]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.163923,	
2017-06-19 19:26:02,198 Epoch[5] Batch [1180]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.163910,	
2017-06-19 19:26:10,861 Epoch[5] Batch [1190]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.163997,	
2017-06-19 19:26:19,228 Epoch[5] Batch [1200]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.163957,	
2017-06-19 19:26:27,755 Epoch[5] Batch [1210]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.163864,	
2017-06-19 19:26:35,998 Epoch[5] Batch [1220]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.163960,	
2017-06-19 19:26:44,355 Epoch[5] Batch [1230]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.163894,	
2017-06-19 19:26:53,015 Epoch[5] Batch [1240]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.163832,	
2017-06-19 19:27:01,116 Epoch[5] Batch [1250]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.163651,	
2017-06-19 19:27:09,325 Epoch[5] Batch [1260]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.163937,	
2017-06-19 19:27:17,766 Epoch[5] Batch [1270]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.163736,	
2017-06-19 19:27:26,059 Epoch[5] Batch [1280]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.163605,	
2017-06-19 19:27:34,038 Epoch[5] Batch [1290]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.163431,	
2017-06-19 19:27:41,293 Epoch[5] Batch [1300]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.163300,	
2017-06-19 19:27:49,464 Epoch[5] Batch [1310]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.163163,	
2017-06-19 19:27:56,666 Epoch[5] Batch [1320]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.163137,	
2017-06-19 19:28:03,529 Epoch[5] Batch [1330]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.162939,	
2017-06-19 19:28:09,878 Epoch[5] Batch [1340]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.162873,	
2017-06-19 19:28:16,303 Epoch[5] Batch [1350]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.162618,	
2017-06-19 19:28:22,851 Epoch[5] Batch [1360]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.162582,	
2017-06-19 19:28:29,143 Epoch[5] Batch [1370]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.162546,	
2017-06-19 19:28:35,459 Epoch[5] Batch [1380]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.162416,	
2017-06-19 19:28:41,997 Epoch[5] Batch [1390]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.162453,	
2017-06-19 19:28:48,630 Epoch[5] Batch [1400]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.162394,	
2017-06-19 19:28:54,924 Epoch[5] Batch [1410]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.162298,	
2017-06-19 19:29:01,069 Epoch[5] Batch [1420]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.162256,	
2017-06-19 19:29:07,632 Epoch[5] Batch [1430]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.162162,	
2017-06-19 19:29:14,514 Epoch[5] Batch [1440]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.162067,	
2017-06-19 19:29:20,969 Epoch[5] Batch [1450]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.162002,	
2017-06-19 19:29:27,448 Epoch[5] Batch [1460]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.161855,	
2017-06-19 19:29:33,787 Epoch[5] Batch [1470]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.161862,	
2017-06-19 19:29:40,201 Epoch[5] Batch [1480]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.161975,	
2017-06-19 19:29:44,049 Epoch[5] Train-FCNLogLoss=0.162020
2017-06-19 19:29:44,049 Epoch[5] Time cost=1106.086
2017-06-19 19:29:44,923 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0006.params"
2017-06-19 19:29:47,177 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0006.states"
2017-06-19 19:29:54,479 Epoch[6] Batch [10]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.161104,	
2017-06-19 19:30:01,320 Epoch[6] Batch [20]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.168385,	
2017-06-19 19:30:07,742 Epoch[6] Batch [30]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.158509,	
2017-06-19 19:30:14,436 Epoch[6] Batch [40]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.158790,	
2017-06-19 19:30:21,150 Epoch[6] Batch [50]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.157795,	
2017-06-19 19:30:28,346 Epoch[6] Batch [60]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.161999,	
2017-06-19 19:30:34,481 Epoch[6] Batch [70]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.160482,	
2017-06-19 19:30:40,600 Epoch[6] Batch [80]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.160076,	
2017-06-19 19:30:47,068 Epoch[6] Batch [90]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.157916,	
2017-06-19 19:30:53,230 Epoch[6] Batch [100]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.156871,	
2017-06-19 19:30:59,541 Epoch[6] Batch [110]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.156939,	
2017-06-19 19:31:05,870 Epoch[6] Batch [120]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.156621,	
2017-06-19 19:31:12,148 Epoch[6] Batch [130]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.154737,	
2017-06-19 19:31:18,134 Epoch[6] Batch [140]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.154508,	
2017-06-19 19:31:24,637 Epoch[6] Batch [150]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.154247,	
2017-06-19 19:31:30,917 Epoch[6] Batch [160]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.153719,	
2017-06-19 19:31:36,586 Epoch[6] Batch [170]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.154064,	
2017-06-19 19:31:42,915 Epoch[6] Batch [180]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.155670,	
2017-06-19 19:31:49,028 Epoch[6] Batch [190]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.155195,	
2017-06-19 19:31:55,428 Epoch[6] Batch [200]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.154884,	
2017-06-19 19:32:01,829 Epoch[6] Batch [210]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.154526,	
2017-06-19 19:32:07,954 Epoch[6] Batch [220]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.154454,	
2017-06-19 19:32:14,448 Epoch[6] Batch [230]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.153826,	
2017-06-19 19:32:20,868 Epoch[6] Batch [240]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.153499,	
2017-06-19 19:32:27,067 Epoch[6] Batch [250]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.153133,	
2017-06-19 19:32:33,638 Epoch[6] Batch [260]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.152343,	
2017-06-19 19:32:39,609 Epoch[6] Batch [270]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.151622,	
2017-06-19 19:32:45,503 Epoch[6] Batch [280]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.151817,	
2017-06-19 19:32:51,627 Epoch[6] Batch [290]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.152183,	
2017-06-19 19:32:57,819 Epoch[6] Batch [300]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.152534,	
2017-06-19 19:33:04,290 Epoch[6] Batch [310]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.153286,	
2017-06-19 19:33:10,459 Epoch[6] Batch [320]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.153425,	
2017-06-19 19:33:16,853 Epoch[6] Batch [330]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.153367,	
2017-06-19 19:33:23,449 Epoch[6] Batch [340]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.153010,	
2017-06-19 19:33:29,637 Epoch[6] Batch [350]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.152833,	
2017-06-19 19:33:35,976 Epoch[6] Batch [360]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.152497,	
2017-06-19 19:33:42,267 Epoch[6] Batch [370]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.152130,	
2017-06-19 19:33:48,208 Epoch[6] Batch [380]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.151845,	
2017-06-19 19:33:54,099 Epoch[6] Batch [390]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.151797,	
2017-06-19 19:34:00,102 Epoch[6] Batch [400]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.151826,	
2017-06-19 19:34:06,301 Epoch[6] Batch [410]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.151576,	
2017-06-19 19:34:13,007 Epoch[6] Batch [420]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.151293,	
2017-06-19 19:34:20,472 Epoch[6] Batch [430]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.151262,	
2017-06-19 19:34:27,065 Epoch[6] Batch [440]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.151565,	
2017-06-19 19:34:33,222 Epoch[6] Batch [450]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.151491,	
2017-06-19 19:34:39,394 Epoch[6] Batch [460]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.151114,	
2017-06-19 19:34:45,552 Epoch[6] Batch [470]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.150845,	
2017-06-19 19:34:51,682 Epoch[6] Batch [480]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.150605,	
2017-06-19 19:34:57,514 Epoch[6] Batch [490]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.150516,	
2017-06-19 19:35:03,431 Epoch[6] Batch [500]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.150294,	
2017-06-19 19:35:10,015 Epoch[6] Batch [510]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.151003,	
2017-06-19 19:35:17,469 Epoch[6] Batch [520]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.151390,	
2017-06-19 19:35:24,690 Epoch[6] Batch [530]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.151117,	
2017-06-19 19:35:32,597 Epoch[6] Batch [540]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.151249,	
2017-06-19 19:35:39,695 Epoch[6] Batch [550]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.151837,	
2017-06-19 19:35:46,979 Epoch[6] Batch [560]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.151789,	
2017-06-19 19:35:54,753 Epoch[6] Batch [570]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.151813,	
2017-06-19 19:36:01,883 Epoch[6] Batch [580]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.152025,	
2017-06-19 19:36:08,890 Epoch[6] Batch [590]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.152109,	
2017-06-19 19:36:16,168 Epoch[6] Batch [600]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.152264,	
2017-06-19 19:36:22,927 Epoch[6] Batch [610]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.152210,	
2017-06-19 19:36:29,665 Epoch[6] Batch [620]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.152142,	
2017-06-19 19:36:37,009 Epoch[6] Batch [630]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.152100,	
2017-06-19 19:36:44,502 Epoch[6] Batch [640]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.152252,	
2017-06-19 19:36:52,734 Epoch[6] Batch [650]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.152002,	
2017-06-19 19:37:00,063 Epoch[6] Batch [660]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.151575,	
2017-06-19 19:37:06,986 Epoch[6] Batch [670]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.151571,	
2017-06-19 19:37:14,808 Epoch[6] Batch [680]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.151417,	
2017-06-19 19:37:22,093 Epoch[6] Batch [690]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.151336,	
2017-06-19 19:37:29,550 Epoch[6] Batch [700]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.151154,	
2017-06-19 19:37:37,605 Epoch[6] Batch [710]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.150835,	
2017-06-19 19:37:45,087 Epoch[6] Batch [720]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.150771,	
2017-06-19 19:37:52,568 Epoch[6] Batch [730]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.150627,	
2017-06-19 19:37:59,968 Epoch[6] Batch [740]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.150469,	
2017-06-19 19:38:07,367 Epoch[6] Batch [750]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.150336,	
2017-06-19 19:38:14,642 Epoch[6] Batch [760]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.150211,	
2017-06-19 19:38:22,331 Epoch[6] Batch [770]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.150053,	
2017-06-19 19:38:29,579 Epoch[6] Batch [780]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.150031,	
2017-06-19 19:38:36,927 Epoch[6] Batch [790]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.149819,	
2017-06-19 19:38:44,173 Epoch[6] Batch [800]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.149767,	
2017-06-19 19:38:51,997 Epoch[6] Batch [810]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.149609,	
2017-06-19 19:38:59,674 Epoch[6] Batch [820]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.149365,	
2017-06-19 19:39:07,408 Epoch[6] Batch [830]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.149402,	
2017-06-19 19:39:15,933 Epoch[6] Batch [840]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.149358,	
2017-06-19 19:39:24,190 Epoch[6] Batch [850]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.149275,	
2017-06-19 19:39:31,536 Epoch[6] Batch [860]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.149316,	
2017-06-19 19:39:38,404 Epoch[6] Batch [870]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.149451,	
2017-06-19 19:39:46,331 Epoch[6] Batch [880]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.149708,	
2017-06-19 19:39:53,923 Epoch[6] Batch [890]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.149531,	
2017-06-19 19:40:02,313 Epoch[6] Batch [900]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.149520,	
2017-06-19 19:40:09,791 Epoch[6] Batch [910]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.149337,	
2017-06-19 19:40:17,411 Epoch[6] Batch [920]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.149205,	
2017-06-19 19:40:24,771 Epoch[6] Batch [930]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.149242,	
2017-06-19 19:40:32,676 Epoch[6] Batch [940]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.149474,	
2017-06-19 19:40:40,206 Epoch[6] Batch [950]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.149678,	
2017-06-19 19:40:48,033 Epoch[6] Batch [960]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.149767,	
2017-06-19 19:40:55,427 Epoch[6] Batch [970]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.149928,	
2017-06-19 19:41:02,885 Epoch[6] Batch [980]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.149960,	
2017-06-19 19:41:10,208 Epoch[6] Batch [990]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.150195,	
2017-06-19 19:41:17,598 Epoch[6] Batch [1000]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.150112,	
2017-06-19 19:41:24,669 Epoch[6] Batch [1010]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.149959,	
2017-06-19 19:41:32,360 Epoch[6] Batch [1020]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.149976,	
2017-06-19 19:41:40,133 Epoch[6] Batch [1030]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.150060,	
2017-06-19 19:41:47,812 Epoch[6] Batch [1040]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.149958,	
2017-06-19 19:41:56,057 Epoch[6] Batch [1050]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.149885,	
2017-06-19 19:42:03,556 Epoch[6] Batch [1060]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.149791,	
2017-06-19 19:42:10,902 Epoch[6] Batch [1070]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.149764,	
2017-06-19 19:42:18,273 Epoch[6] Batch [1080]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.149847,	
2017-06-19 19:42:25,770 Epoch[6] Batch [1090]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.149875,	
2017-06-19 19:42:32,781 Epoch[6] Batch [1100]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.149901,	
2017-06-19 19:42:39,750 Epoch[6] Batch [1110]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.149960,	
2017-06-19 19:42:46,666 Epoch[6] Batch [1120]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.150174,	
2017-06-19 19:42:53,440 Epoch[6] Batch [1130]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.150269,	
2017-06-19 19:43:00,590 Epoch[6] Batch [1140]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.150245,	
2017-06-19 19:43:07,700 Epoch[6] Batch [1150]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.150246,	
2017-06-19 19:43:15,270 Epoch[6] Batch [1160]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.150061,	
2017-06-19 19:43:22,446 Epoch[6] Batch [1170]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.149911,	
2017-06-19 19:43:29,807 Epoch[6] Batch [1180]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.149779,	
2017-06-19 19:43:37,226 Epoch[6] Batch [1190]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.149793,	
2017-06-19 19:43:44,465 Epoch[6] Batch [1200]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.149661,	
2017-06-19 19:43:52,315 Epoch[6] Batch [1210]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.149697,	
2017-06-19 19:44:00,131 Epoch[6] Batch [1220]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.149663,	
2017-06-19 19:44:06,905 Epoch[6] Batch [1230]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.149619,	
2017-06-19 19:44:14,384 Epoch[6] Batch [1240]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.149857,	
2017-06-19 19:44:21,551 Epoch[6] Batch [1250]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.150047,	
2017-06-19 19:44:28,469 Epoch[6] Batch [1260]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.150314,	
2017-06-19 19:44:36,206 Epoch[6] Batch [1270]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.150285,	
2017-06-19 19:44:43,574 Epoch[6] Batch [1280]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.150484,	
2017-06-19 19:44:50,890 Epoch[6] Batch [1290]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.150497,	
2017-06-19 19:44:57,978 Epoch[6] Batch [1300]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.150372,	
2017-06-19 19:45:05,342 Epoch[6] Batch [1310]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.150342,	
2017-06-19 19:45:12,954 Epoch[6] Batch [1320]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.150143,	
2017-06-19 19:45:20,523 Epoch[6] Batch [1330]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.149971,	
2017-06-19 19:45:28,064 Epoch[6] Batch [1340]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.149869,	
2017-06-19 19:45:35,164 Epoch[6] Batch [1350]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.149759,	
2017-06-19 19:45:42,348 Epoch[6] Batch [1360]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.149706,	
2017-06-19 19:45:49,200 Epoch[6] Batch [1370]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.149710,	
2017-06-19 19:45:56,690 Epoch[6] Batch [1380]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.149752,	
2017-06-19 19:46:03,965 Epoch[6] Batch [1390]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.149684,	
2017-06-19 19:46:11,463 Epoch[6] Batch [1400]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.149604,	
2017-06-19 19:46:18,813 Epoch[6] Batch [1410]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.149540,	
2017-06-19 19:46:26,633 Epoch[6] Batch [1420]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.149450,	
2017-06-19 19:46:33,866 Epoch[6] Batch [1430]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.149489,	
2017-06-19 19:46:40,597 Epoch[6] Batch [1440]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.149341,	
2017-06-19 19:46:47,181 Epoch[6] Batch [1450]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.149355,	
2017-06-19 19:46:53,704 Epoch[6] Batch [1460]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.149378,	
2017-06-19 19:47:01,863 Epoch[6] Batch [1470]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.149400,	
2017-06-19 19:47:09,789 Epoch[6] Batch [1480]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.149353,	
2017-06-19 19:47:13,707 Epoch[6] Train-FCNLogLoss=0.149380
2017-06-19 19:47:13,707 Epoch[6] Time cost=1046.530
2017-06-19 19:47:14,668 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0007.params"
2017-06-19 19:47:17,272 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0007.states"
2017-06-19 19:47:25,798 Epoch[7] Batch [10]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.127374,	
2017-06-19 19:47:33,127 Epoch[7] Batch [20]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.134062,	
2017-06-19 19:47:40,548 Epoch[7] Batch [30]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.132342,	
2017-06-19 19:47:47,570 Epoch[7] Batch [40]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.136213,	
2017-06-19 19:47:54,775 Epoch[7] Batch [50]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.137334,	
2017-06-19 19:48:01,763 Epoch[7] Batch [60]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.140231,	
2017-06-19 19:48:09,074 Epoch[7] Batch [70]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.139819,	
2017-06-19 19:48:15,957 Epoch[7] Batch [80]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.141563,	
2017-06-19 19:48:23,245 Epoch[7] Batch [90]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.142095,	
2017-06-19 19:48:30,595 Epoch[7] Batch [100]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.142001,	
2017-06-19 19:48:38,471 Epoch[7] Batch [110]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.141213,	
2017-06-19 19:48:45,984 Epoch[7] Batch [120]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.140712,	
2017-06-19 19:48:53,111 Epoch[7] Batch [130]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.140136,	
2017-06-19 19:49:01,024 Epoch[7] Batch [140]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.139767,	
2017-06-19 19:49:08,731 Epoch[7] Batch [150]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.139654,	
2017-06-19 19:49:15,799 Epoch[7] Batch [160]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.140999,	
2017-06-19 19:49:23,268 Epoch[7] Batch [170]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.141246,	
2017-06-19 19:49:31,254 Epoch[7] Batch [180]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.141684,	
2017-06-19 19:49:39,132 Epoch[7] Batch [190]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.140768,	
2017-06-19 19:49:46,883 Epoch[7] Batch [200]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.141061,	
2017-06-19 19:49:53,936 Epoch[7] Batch [210]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.140895,	
2017-06-19 19:50:01,038 Epoch[7] Batch [220]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.141586,	
2017-06-19 19:50:08,250 Epoch[7] Batch [230]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.141600,	
2017-06-19 19:50:15,168 Epoch[7] Batch [240]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.142291,	
2017-06-19 19:50:22,459 Epoch[7] Batch [250]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.144338,	
2017-06-19 19:50:29,747 Epoch[7] Batch [260]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.145860,	
2017-06-19 19:50:36,796 Epoch[7] Batch [270]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.147853,	
2017-06-19 19:50:43,097 Epoch[7] Batch [280]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.149163,	
2017-06-19 19:50:49,497 Epoch[7] Batch [290]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.151081,	
2017-06-19 19:50:56,498 Epoch[7] Batch [300]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.151303,	
2017-06-19 19:51:03,633 Epoch[7] Batch [310]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.150902,	
2017-06-19 19:51:11,138 Epoch[7] Batch [320]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.151295,	
2017-06-19 19:51:18,309 Epoch[7] Batch [330]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.151580,	
2017-06-19 19:51:25,967 Epoch[7] Batch [340]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.151980,	
2017-06-19 19:51:32,132 Epoch[7] Batch [350]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.154753,	
2017-06-19 19:51:38,956 Epoch[7] Batch [360]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.155453,	
2017-06-19 19:51:45,374 Epoch[7] Batch [370]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.155764,	
2017-06-19 19:51:52,085 Epoch[7] Batch [380]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.156850,	
2017-06-19 19:51:58,306 Epoch[7] Batch [390]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.156644,	
2017-06-19 19:52:06,038 Epoch[7] Batch [400]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.156330,	
2017-06-19 19:52:13,773 Epoch[7] Batch [410]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.156043,	
2017-06-19 19:52:21,108 Epoch[7] Batch [420]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.155996,	
2017-06-19 19:52:29,162 Epoch[7] Batch [430]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.155949,	
2017-06-19 19:52:36,583 Epoch[7] Batch [440]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.155707,	
2017-06-19 19:52:43,564 Epoch[7] Batch [450]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.155459,	
2017-06-19 19:52:51,002 Epoch[7] Batch [460]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.155180,	
2017-06-19 19:52:57,781 Epoch[7] Batch [470]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.154686,	
2017-06-19 19:53:04,989 Epoch[7] Batch [480]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.154300,	
2017-06-19 19:53:12,785 Epoch[7] Batch [490]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.153903,	
2017-06-19 19:53:20,414 Epoch[7] Batch [500]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.153757,	
2017-06-19 19:53:27,982 Epoch[7] Batch [510]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.153544,	
2017-06-19 19:53:35,650 Epoch[7] Batch [520]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.153249,	
2017-06-19 19:53:42,996 Epoch[7] Batch [530]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.152839,	
2017-06-19 19:53:50,394 Epoch[7] Batch [540]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.152739,	
2017-06-19 19:53:57,528 Epoch[7] Batch [550]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.152528,	
2017-06-19 19:54:04,638 Epoch[7] Batch [560]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.152411,	
2017-06-19 19:54:11,937 Epoch[7] Batch [570]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.152266,	
2017-06-19 19:54:18,928 Epoch[7] Batch [580]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.152113,	
2017-06-19 19:54:27,286 Epoch[7] Batch [590]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.151956,	
2017-06-19 19:54:35,293 Epoch[7] Batch [600]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.151854,	
2017-06-19 19:54:42,331 Epoch[7] Batch [610]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.151909,	
2017-06-19 19:54:49,842 Epoch[7] Batch [620]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.151805,	
2017-06-19 19:54:57,340 Epoch[7] Batch [630]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.151702,	
2017-06-19 19:55:05,174 Epoch[7] Batch [640]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.151783,	
2017-06-19 19:55:13,094 Epoch[7] Batch [650]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.151596,	
2017-06-19 19:55:20,110 Epoch[7] Batch [660]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.151235,	
2017-06-19 19:55:24,489 Epoch[7] Batch [670]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.150956,	
2017-06-19 19:55:28,917 Epoch[7] Batch [680]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.150646,	
2017-06-19 19:55:33,223 Epoch[7] Batch [690]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.150317,	
2017-06-19 19:55:37,610 Epoch[7] Batch [700]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.150089,	
2017-06-19 19:55:41,951 Epoch[7] Batch [710]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.149938,	
2017-06-19 19:55:46,274 Epoch[7] Batch [720]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.149808,	
2017-06-19 19:55:50,561 Epoch[7] Batch [730]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.149552,	
2017-06-19 19:55:54,810 Epoch[7] Batch [740]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.149352,	
2017-06-19 19:55:59,251 Epoch[7] Batch [750]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.149315,	
2017-06-19 19:56:03,738 Epoch[7] Batch [760]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.148937,	
2017-06-19 19:56:08,111 Epoch[7] Batch [770]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.148505,	
2017-06-19 19:56:12,457 Epoch[7] Batch [780]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.148387,	
2017-06-19 19:56:16,839 Epoch[7] Batch [790]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.148226,	
2017-06-19 19:56:21,218 Epoch[7] Batch [800]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.148471,	
2017-06-19 19:56:25,581 Epoch[7] Batch [810]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.148274,	
2017-06-19 19:56:29,794 Epoch[7] Batch [820]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.148347,	
2017-06-19 19:56:34,148 Epoch[7] Batch [830]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.148424,	
2017-06-19 19:56:38,559 Epoch[7] Batch [840]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.148661,	
2017-06-19 19:56:42,993 Epoch[7] Batch [850]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.148675,	
2017-06-19 19:56:47,234 Epoch[7] Batch [860]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.148755,	
2017-06-19 19:56:51,678 Epoch[7] Batch [870]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.148789,	
2017-06-19 19:56:56,213 Epoch[7] Batch [880]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.148857,	
2017-06-19 19:57:00,593 Epoch[7] Batch [890]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.148790,	
2017-06-19 19:57:04,826 Epoch[7] Batch [900]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.148514,	
2017-06-19 19:57:09,026 Epoch[7] Batch [910]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.148339,	
2017-06-19 19:57:13,309 Epoch[7] Batch [920]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.148312,	
2017-06-19 19:57:17,720 Epoch[7] Batch [930]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.148294,	
2017-06-19 19:57:21,984 Epoch[7] Batch [940]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.148317,	
2017-06-19 19:57:26,252 Epoch[7] Batch [950]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.148281,	
2017-06-19 19:57:30,470 Epoch[7] Batch [960]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.148204,	
2017-06-19 19:57:34,727 Epoch[7] Batch [970]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.148020,	
2017-06-19 19:57:38,855 Epoch[7] Batch [980]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.147993,	
2017-06-19 19:57:43,112 Epoch[7] Batch [990]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.147909,	
2017-06-19 19:57:47,343 Epoch[7] Batch [1000]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.147709,	
2017-06-19 19:57:51,429 Epoch[7] Batch [1010]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.147642,	
2017-06-19 19:57:55,700 Epoch[7] Batch [1020]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.147444,	
2017-06-19 19:57:59,823 Epoch[7] Batch [1030]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.147197,	
2017-06-19 19:58:03,803 Epoch[7] Batch [1040]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.147166,	
2017-06-19 19:58:07,949 Epoch[7] Batch [1050]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.147235,	
2017-06-19 19:58:12,093 Epoch[7] Batch [1060]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.147260,	
2017-06-19 19:58:16,290 Epoch[7] Batch [1070]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.147288,	
2017-06-19 19:58:20,263 Epoch[7] Batch [1080]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.147125,	
2017-06-19 19:58:24,383 Epoch[7] Batch [1090]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.146951,	
2017-06-19 19:58:28,728 Epoch[7] Batch [1100]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.146855,	
2017-06-19 19:58:32,865 Epoch[7] Batch [1110]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.146734,	
2017-06-19 19:58:37,162 Epoch[7] Batch [1120]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.146811,	
2017-06-19 19:58:41,231 Epoch[7] Batch [1130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.146777,	
2017-06-19 19:58:45,310 Epoch[7] Batch [1140]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.146810,	
2017-06-19 19:58:49,339 Epoch[7] Batch [1150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.146718,	
2017-06-19 19:58:53,522 Epoch[7] Batch [1160]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.146553,	
2017-06-19 19:58:57,598 Epoch[7] Batch [1170]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.146640,	
2017-06-19 19:59:01,781 Epoch[7] Batch [1180]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.146833,	
2017-06-19 19:59:05,863 Epoch[7] Batch [1190]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.146723,	
2017-06-19 19:59:10,041 Epoch[7] Batch [1200]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.146575,	
2017-06-19 19:59:14,086 Epoch[7] Batch [1210]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.146569,	
2017-06-19 19:59:18,212 Epoch[7] Batch [1220]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.146490,	
2017-06-19 19:59:22,401 Epoch[7] Batch [1230]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.146496,	
2017-06-19 19:59:26,544 Epoch[7] Batch [1240]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.146325,	
2017-06-19 19:59:30,668 Epoch[7] Batch [1250]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.146291,	
2017-06-19 19:59:34,774 Epoch[7] Batch [1260]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.146468,	
2017-06-19 19:59:38,990 Epoch[7] Batch [1270]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.146353,	
2017-06-19 19:59:43,259 Epoch[7] Batch [1280]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.146294,	
2017-06-19 19:59:47,373 Epoch[7] Batch [1290]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.146633,	
2017-06-19 19:59:51,394 Epoch[7] Batch [1300]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.146734,	
2017-06-19 19:59:55,461 Epoch[7] Batch [1310]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.146638,	
2017-06-19 19:59:59,538 Epoch[7] Batch [1320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.146489,	
2017-06-19 20:00:03,763 Epoch[7] Batch [1330]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.146407,	
2017-06-19 20:00:07,857 Epoch[7] Batch [1340]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.146304,	
2017-06-19 20:00:11,922 Epoch[7] Batch [1350]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.146181,	
2017-06-19 20:00:15,857 Epoch[7] Batch [1360]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.146077,	
2017-06-19 20:00:19,980 Epoch[7] Batch [1370]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.146197,	
2017-06-19 20:00:24,112 Epoch[7] Batch [1380]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.146517,	
2017-06-19 20:00:28,216 Epoch[7] Batch [1390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.146715,	
2017-06-19 20:00:32,383 Epoch[7] Batch [1400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.146757,	
2017-06-19 20:00:36,497 Epoch[7] Batch [1410]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.146896,	
2017-06-19 20:00:40,586 Epoch[7] Batch [1420]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.147031,	
2017-06-19 20:00:44,802 Epoch[7] Batch [1430]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.147002,	
2017-06-19 20:00:49,052 Epoch[7] Batch [1440]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.147182,	
2017-06-19 20:00:53,169 Epoch[7] Batch [1450]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.147116,	
2017-06-19 20:00:57,260 Epoch[7] Batch [1460]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.147048,	
2017-06-19 20:01:01,306 Epoch[7] Batch [1470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.147041,	
2017-06-19 20:01:05,182 Epoch[7] Batch [1480]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.146951,	
2017-06-19 20:01:07,652 Epoch[7] Train-FCNLogLoss=0.146953
2017-06-19 20:01:07,652 Epoch[7] Time cost=830.380
2017-06-19 20:01:08,496 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0008.params"
2017-06-19 20:01:10,320 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0008.states"
2017-06-19 20:01:15,143 Epoch[8] Batch [10]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.159014,	
2017-06-19 20:01:19,117 Epoch[8] Batch [20]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.150643,	
2017-06-19 20:01:23,353 Epoch[8] Batch [30]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.146608,	
2017-06-19 20:01:27,563 Epoch[8] Batch [40]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.145596,	
2017-06-19 20:01:31,757 Epoch[8] Batch [50]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.144637,	
2017-06-19 20:01:36,036 Epoch[8] Batch [60]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.142173,	
2017-06-19 20:01:40,021 Epoch[8] Batch [70]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.139372,	
2017-06-19 20:01:44,151 Epoch[8] Batch [80]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.138574,	
2017-06-19 20:01:48,274 Epoch[8] Batch [90]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.138716,	
2017-06-19 20:01:52,263 Epoch[8] Batch [100]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.139805,	
2017-06-19 20:01:56,371 Epoch[8] Batch [110]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.138549,	
2017-06-19 20:02:00,524 Epoch[8] Batch [120]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.138912,	
2017-06-19 20:02:04,568 Epoch[8] Batch [130]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.138185,	
2017-06-19 20:02:08,774 Epoch[8] Batch [140]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.138087,	
2017-06-19 20:02:12,800 Epoch[8] Batch [150]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.138033,	
2017-06-19 20:02:16,915 Epoch[8] Batch [160]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.139168,	
2017-06-19 20:02:20,944 Epoch[8] Batch [170]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.139987,	
2017-06-19 20:02:25,166 Epoch[8] Batch [180]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.139784,	
2017-06-19 20:02:29,379 Epoch[8] Batch [190]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.139710,	
2017-06-19 20:02:33,458 Epoch[8] Batch [200]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.139703,	
2017-06-19 20:02:37,564 Epoch[8] Batch [210]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.139587,	
2017-06-19 20:02:41,699 Epoch[8] Batch [220]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.141013,	
2017-06-19 20:02:45,862 Epoch[8] Batch [230]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.141469,	
2017-06-19 20:02:49,988 Epoch[8] Batch [240]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.142111,	
2017-06-19 20:02:54,048 Epoch[8] Batch [250]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.143043,	
2017-06-19 20:02:58,052 Epoch[8] Batch [260]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.143174,	
2017-06-19 20:03:02,320 Epoch[8] Batch [270]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.143437,	
2017-06-19 20:03:06,586 Epoch[8] Batch [280]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.142821,	
2017-06-19 20:03:10,587 Epoch[8] Batch [290]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.142491,	
2017-06-19 20:03:15,118 Epoch[8] Batch [300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.142238,	
2017-06-19 20:03:19,539 Epoch[8] Batch [310]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.141864,	
2017-06-19 20:03:23,723 Epoch[8] Batch [320]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.141304,	
2017-06-19 20:03:28,042 Epoch[8] Batch [330]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.140778,	
2017-06-19 20:03:32,310 Epoch[8] Batch [340]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.140406,	
2017-06-19 20:03:36,460 Epoch[8] Batch [350]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.139898,	
2017-06-19 20:03:40,439 Epoch[8] Batch [360]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.139403,	
2017-06-19 20:03:44,640 Epoch[8] Batch [370]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.139424,	
2017-06-19 20:03:48,813 Epoch[8] Batch [380]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.139266,	
2017-06-19 20:03:53,107 Epoch[8] Batch [390]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.139152,	
2017-06-19 20:03:57,412 Epoch[8] Batch [400]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.139079,	
2017-06-19 20:04:01,611 Epoch[8] Batch [410]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.139097,	
2017-06-19 20:04:06,009 Epoch[8] Batch [420]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.138755,	
2017-06-19 20:04:10,406 Epoch[8] Batch [430]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.138402,	
2017-06-19 20:04:14,639 Epoch[8] Batch [440]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.138174,	
2017-06-19 20:04:18,897 Epoch[8] Batch [450]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.138313,	
2017-06-19 20:04:23,228 Epoch[8] Batch [460]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.138345,	
2017-06-19 20:04:27,464 Epoch[8] Batch [470]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.137981,	
2017-06-19 20:04:31,902 Epoch[8] Batch [480]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.138522,	
2017-06-19 20:04:36,153 Epoch[8] Batch [490]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.138527,	
2017-06-19 20:04:40,343 Epoch[8] Batch [500]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.139071,	
2017-06-19 20:04:44,374 Epoch[8] Batch [510]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.138820,	
2017-06-19 20:04:48,588 Epoch[8] Batch [520]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.138647,	
2017-06-19 20:04:52,806 Epoch[8] Batch [530]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.138532,	
2017-06-19 20:04:57,177 Epoch[8] Batch [540]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.138427,	
2017-06-19 20:05:01,444 Epoch[8] Batch [550]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.138551,	
2017-06-19 20:05:05,649 Epoch[8] Batch [560]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.138791,	
2017-06-19 20:05:09,898 Epoch[8] Batch [570]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.138434,	
2017-06-19 20:05:14,118 Epoch[8] Batch [580]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.138141,	
2017-06-19 20:05:18,403 Epoch[8] Batch [590]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.138062,	
2017-06-19 20:05:22,761 Epoch[8] Batch [600]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.138186,	
2017-06-19 20:05:27,045 Epoch[8] Batch [610]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.138013,	
2017-06-19 20:05:31,410 Epoch[8] Batch [620]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.138138,	
2017-06-19 20:05:35,707 Epoch[8] Batch [630]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.137960,	
2017-06-19 20:05:40,047 Epoch[8] Batch [640]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.137879,	
2017-06-19 20:05:44,240 Epoch[8] Batch [650]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.137820,	
2017-06-19 20:05:48,556 Epoch[8] Batch [660]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.138041,	
2017-06-19 20:05:52,730 Epoch[8] Batch [670]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.138671,	
2017-06-19 20:05:56,796 Epoch[8] Batch [680]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.138752,	
2017-06-19 20:06:01,141 Epoch[8] Batch [690]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.138677,	
2017-06-19 20:06:05,215 Epoch[8] Batch [700]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.138602,	
2017-06-19 20:06:09,280 Epoch[8] Batch [710]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.138717,	
2017-06-19 20:06:13,393 Epoch[8] Batch [720]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.138738,	
2017-06-19 20:06:17,630 Epoch[8] Batch [730]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.138921,	
2017-06-19 20:06:21,704 Epoch[8] Batch [740]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.138635,	
2017-06-19 20:06:25,839 Epoch[8] Batch [750]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.138691,	
2017-06-19 20:06:29,964 Epoch[8] Batch [760]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.138799,	
2017-06-19 20:06:34,083 Epoch[8] Batch [770]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.138749,	
2017-06-19 20:06:38,392 Epoch[8] Batch [780]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.138688,	
2017-06-19 20:06:42,513 Epoch[8] Batch [790]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.138598,	
2017-06-19 20:06:46,536 Epoch[8] Batch [800]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.138524,	
2017-06-19 20:06:50,759 Epoch[8] Batch [810]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.138482,	
2017-06-19 20:06:54,953 Epoch[8] Batch [820]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.138486,	
2017-06-19 20:06:59,153 Epoch[8] Batch [830]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.138602,	
2017-06-19 20:07:03,400 Epoch[8] Batch [840]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.138372,	
2017-06-19 20:07:07,646 Epoch[8] Batch [850]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.138057,	
2017-06-19 20:07:11,977 Epoch[8] Batch [860]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.138106,	
2017-06-19 20:07:16,107 Epoch[8] Batch [870]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.137958,	
2017-06-19 20:07:20,293 Epoch[8] Batch [880]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.137984,	
2017-06-19 20:07:24,672 Epoch[8] Batch [890]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.137967,	
2017-06-19 20:07:28,836 Epoch[8] Batch [900]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.137870,	
2017-06-19 20:07:32,796 Epoch[8] Batch [910]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.137902,	
2017-06-19 20:07:37,028 Epoch[8] Batch [920]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.137849,	
2017-06-19 20:07:41,245 Epoch[8] Batch [930]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.137772,	
2017-06-19 20:07:45,416 Epoch[8] Batch [940]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.137826,	
2017-06-19 20:07:49,604 Epoch[8] Batch [950]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.137760,	
2017-06-19 20:07:53,624 Epoch[8] Batch [960]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.137841,	
2017-06-19 20:07:57,725 Epoch[8] Batch [970]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.137845,	
2017-06-19 20:08:01,939 Epoch[8] Batch [980]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.137761,	
2017-06-19 20:08:05,979 Epoch[8] Batch [990]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.137676,	
2017-06-19 20:08:09,840 Epoch[8] Batch [1000]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.137511,	
2017-06-19 20:08:13,857 Epoch[8] Batch [1010]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.137627,	
2017-06-19 20:08:17,948 Epoch[8] Batch [1020]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.137675,	
2017-06-19 20:08:22,144 Epoch[8] Batch [1030]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.138167,	
2017-06-19 20:08:26,394 Epoch[8] Batch [1040]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.138275,	
2017-06-19 20:08:30,411 Epoch[8] Batch [1050]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.138374,	
2017-06-19 20:08:34,384 Epoch[8] Batch [1060]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.138469,	
2017-06-19 20:08:38,448 Epoch[8] Batch [1070]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.138503,	
2017-06-19 20:08:42,406 Epoch[8] Batch [1080]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.138353,	
2017-06-19 20:08:46,499 Epoch[8] Batch [1090]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.138387,	
2017-06-19 20:08:50,525 Epoch[8] Batch [1100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.138218,	
2017-06-19 20:08:54,630 Epoch[8] Batch [1110]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.138034,	
2017-06-19 20:08:58,654 Epoch[8] Batch [1120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.137947,	
2017-06-19 20:09:02,738 Epoch[8] Batch [1130]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.138150,	
2017-06-19 20:09:06,888 Epoch[8] Batch [1140]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.138128,	
2017-06-19 20:09:10,950 Epoch[8] Batch [1150]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.138082,	
2017-06-19 20:09:14,933 Epoch[8] Batch [1160]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.137955,	
2017-06-19 20:09:19,354 Epoch[8] Batch [1170]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.137805,	
2017-06-19 20:09:23,875 Epoch[8] Batch [1180]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.137736,	
2017-06-19 20:09:28,643 Epoch[8] Batch [1190]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.137701,	
2017-06-19 20:09:33,149 Epoch[8] Batch [1200]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.137805,	
2017-06-19 20:09:37,676 Epoch[8] Batch [1210]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.137693,	
2017-06-19 20:09:41,909 Epoch[8] Batch [1220]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.137767,	
2017-06-19 20:09:46,517 Epoch[8] Batch [1230]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.137511,	
2017-06-19 20:09:51,078 Epoch[8] Batch [1240]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.137514,	
2017-06-19 20:09:55,493 Epoch[8] Batch [1250]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.137475,	
2017-06-19 20:09:59,725 Epoch[8] Batch [1260]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.137380,	
2017-06-19 20:10:04,229 Epoch[8] Batch [1270]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.137402,	
2017-06-19 20:10:08,445 Epoch[8] Batch [1280]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.137242,	
2017-06-19 20:10:13,262 Epoch[8] Batch [1290]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.137185,	
2017-06-19 20:10:17,860 Epoch[8] Batch [1300]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.137108,	
2017-06-19 20:10:22,169 Epoch[8] Batch [1310]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.136980,	
2017-06-19 20:10:26,390 Epoch[8] Batch [1320]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.137152,	
2017-06-19 20:10:30,813 Epoch[8] Batch [1330]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.137142,	
2017-06-19 20:10:34,841 Epoch[8] Batch [1340]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.137162,	
2017-06-19 20:10:39,007 Epoch[8] Batch [1350]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.137093,	
2017-06-19 20:10:43,333 Epoch[8] Batch [1360]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.137079,	
2017-06-19 20:10:47,546 Epoch[8] Batch [1370]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.137002,	
2017-06-19 20:10:51,672 Epoch[8] Batch [1380]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.136920,	
2017-06-19 20:10:55,724 Epoch[8] Batch [1390]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.136963,	
2017-06-19 20:10:59,679 Epoch[8] Batch [1400]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.136881,	
2017-06-19 20:11:03,726 Epoch[8] Batch [1410]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.136903,	
2017-06-19 20:11:07,757 Epoch[8] Batch [1420]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.137127,	
2017-06-19 20:11:11,924 Epoch[8] Batch [1430]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.137118,	
2017-06-19 20:11:15,935 Epoch[8] Batch [1440]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.137172,	
2017-06-19 20:11:20,093 Epoch[8] Batch [1450]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.137092,	
2017-06-19 20:11:24,130 Epoch[8] Batch [1460]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.137264,	
2017-06-19 20:11:28,154 Epoch[8] Batch [1470]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.137184,	
2017-06-19 20:11:32,444 Epoch[8] Batch [1480]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.137110,	
2017-06-19 20:11:34,946 Epoch[8] Train-FCNLogLoss=0.137137
2017-06-19 20:11:34,946 Epoch[8] Time cost=624.626
2017-06-19 20:11:35,850 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0009.params"
2017-06-19 20:11:37,484 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0009.states"
2017-06-19 20:11:42,265 Epoch[9] Batch [10]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.157764,	
2017-06-19 20:11:46,405 Epoch[9] Batch [20]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.149973,	
2017-06-19 20:11:50,675 Epoch[9] Batch [30]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.143984,	
2017-06-19 20:11:54,850 Epoch[9] Batch [40]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.139389,	
2017-06-19 20:11:59,093 Epoch[9] Batch [50]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.139593,	
2017-06-19 20:12:03,311 Epoch[9] Batch [60]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.135902,	
2017-06-19 20:12:07,352 Epoch[9] Batch [70]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.134129,	
2017-06-19 20:12:11,560 Epoch[9] Batch [80]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.133145,	
2017-06-19 20:12:15,554 Epoch[9] Batch [90]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.134230,	
2017-06-19 20:12:19,628 Epoch[9] Batch [100]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.133316,	
2017-06-19 20:12:23,715 Epoch[9] Batch [110]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.136002,	
2017-06-19 20:12:27,903 Epoch[9] Batch [120]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.134590,	
2017-06-19 20:12:32,056 Epoch[9] Batch [130]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.135780,	
2017-06-19 20:12:36,176 Epoch[9] Batch [140]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.134101,	
2017-06-19 20:12:40,257 Epoch[9] Batch [150]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.133894,	
2017-06-19 20:12:44,349 Epoch[9] Batch [160]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.133446,	
2017-06-19 20:12:48,603 Epoch[9] Batch [170]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.133961,	
2017-06-19 20:12:52,827 Epoch[9] Batch [180]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.133673,	
2017-06-19 20:12:56,997 Epoch[9] Batch [190]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.133569,	
2017-06-19 20:13:01,077 Epoch[9] Batch [200]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.133572,	
2017-06-19 20:13:05,138 Epoch[9] Batch [210]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.133603,	
2017-06-19 20:13:09,395 Epoch[9] Batch [220]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.132594,	
2017-06-19 20:13:13,478 Epoch[9] Batch [230]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.132054,	
2017-06-19 20:13:17,669 Epoch[9] Batch [240]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.134527,	
2017-06-19 20:13:21,842 Epoch[9] Batch [250]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.136762,	
2017-06-19 20:13:26,107 Epoch[9] Batch [260]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.138216,	
2017-06-19 20:13:30,054 Epoch[9] Batch [270]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.138767,	
2017-06-19 20:13:34,455 Epoch[9] Batch [280]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.139057,	
2017-06-19 20:13:38,569 Epoch[9] Batch [290]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.139000,	
2017-06-19 20:13:42,683 Epoch[9] Batch [300]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.139598,	
2017-06-19 20:13:46,702 Epoch[9] Batch [310]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.140088,	
2017-06-19 20:13:50,859 Epoch[9] Batch [320]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.139923,	
2017-06-19 20:13:54,893 Epoch[9] Batch [330]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.140470,	
2017-06-19 20:13:59,026 Epoch[9] Batch [340]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.140138,	
2017-06-19 20:14:03,086 Epoch[9] Batch [350]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.139452,	
2017-06-19 20:14:07,170 Epoch[9] Batch [360]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.138972,	
2017-06-19 20:14:11,250 Epoch[9] Batch [370]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.138880,	
2017-06-19 20:14:15,399 Epoch[9] Batch [380]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.138748,	
2017-06-19 20:14:19,366 Epoch[9] Batch [390]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.138912,	
2017-06-19 20:14:23,400 Epoch[9] Batch [400]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.138568,	
2017-06-19 20:14:27,691 Epoch[9] Batch [410]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.138357,	
2017-06-19 20:14:31,690 Epoch[9] Batch [420]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.138379,	
2017-06-19 20:14:35,873 Epoch[9] Batch [430]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.138283,	
2017-06-19 20:14:39,926 Epoch[9] Batch [440]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.137860,	
2017-06-19 20:14:44,290 Epoch[9] Batch [450]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.137867,	
2017-06-19 20:14:48,498 Epoch[9] Batch [460]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.137569,	
2017-06-19 20:14:52,604 Epoch[9] Batch [470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.137991,	
2017-06-19 20:14:56,804 Epoch[9] Batch [480]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.138067,	
2017-06-19 20:15:00,815 Epoch[9] Batch [490]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.137924,	
2017-06-19 20:15:05,064 Epoch[9] Batch [500]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.137764,	
2017-06-19 20:15:09,291 Epoch[9] Batch [510]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.137569,	
2017-06-19 20:15:13,295 Epoch[9] Batch [520]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.137374,	
2017-06-19 20:15:17,275 Epoch[9] Batch [530]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.137226,	
2017-06-19 20:15:21,560 Epoch[9] Batch [540]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.137108,	
2017-06-19 20:15:25,826 Epoch[9] Batch [550]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.137109,	
2017-06-19 20:15:29,945 Epoch[9] Batch [560]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.137100,	
2017-06-19 20:15:34,186 Epoch[9] Batch [570]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.136937,	
2017-06-19 20:15:38,174 Epoch[9] Batch [580]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.136790,	
2017-06-19 20:15:42,305 Epoch[9] Batch [590]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.136647,	
2017-06-19 20:15:46,462 Epoch[9] Batch [600]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.136710,	
2017-06-19 20:15:50,672 Epoch[9] Batch [610]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.136739,	
2017-06-19 20:15:54,778 Epoch[9] Batch [620]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136650,	
2017-06-19 20:15:58,934 Epoch[9] Batch [630]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.136610,	
2017-06-19 20:16:03,218 Epoch[9] Batch [640]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.136397,	
2017-06-19 20:16:07,375 Epoch[9] Batch [650]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.136248,	
2017-06-19 20:16:11,437 Epoch[9] Batch [660]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.136124,	
2017-06-19 20:16:15,642 Epoch[9] Batch [670]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.135878,	
2017-06-19 20:16:19,652 Epoch[9] Batch [680]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.135937,	
2017-06-19 20:16:23,593 Epoch[9] Batch [690]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.136626,	
2017-06-19 20:16:27,825 Epoch[9] Batch [700]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.136692,	
2017-06-19 20:16:31,791 Epoch[9] Batch [710]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.136442,	
2017-06-19 20:16:35,934 Epoch[9] Batch [720]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.136488,	
2017-06-19 20:16:40,097 Epoch[9] Batch [730]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.136495,	
2017-06-19 20:16:44,200 Epoch[9] Batch [740]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.136723,	
2017-06-19 20:16:48,282 Epoch[9] Batch [750]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.136488,	
2017-06-19 20:16:52,527 Epoch[9] Batch [760]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.136111,	
2017-06-19 20:16:56,586 Epoch[9] Batch [770]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.136182,	
2017-06-19 20:17:00,695 Epoch[9] Batch [780]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136107,	
2017-06-19 20:17:04,844 Epoch[9] Batch [790]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.135832,	
2017-06-19 20:17:09,020 Epoch[9] Batch [800]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.135756,	
2017-06-19 20:17:13,238 Epoch[9] Batch [810]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.135625,	
2017-06-19 20:17:17,475 Epoch[9] Batch [820]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.135609,	
2017-06-19 20:17:21,672 Epoch[9] Batch [830]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.135370,	
2017-06-19 20:17:25,703 Epoch[9] Batch [840]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.135125,	
2017-06-19 20:17:29,811 Epoch[9] Batch [850]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.135168,	
2017-06-19 20:17:33,998 Epoch[9] Batch [860]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.135056,	
2017-06-19 20:17:38,112 Epoch[9] Batch [870]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.134930,	
2017-06-19 20:17:42,246 Epoch[9] Batch [880]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.134890,	
2017-06-19 20:17:46,502 Epoch[9] Batch [890]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.135008,	
2017-06-19 20:17:50,583 Epoch[9] Batch [900]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.134999,	
2017-06-19 20:17:54,711 Epoch[9] Batch [910]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.134938,	
2017-06-19 20:17:58,667 Epoch[9] Batch [920]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.134948,	
2017-06-19 20:18:02,777 Epoch[9] Batch [930]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134871,	
2017-06-19 20:18:06,891 Epoch[9] Batch [940]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.134797,	
2017-06-19 20:18:11,070 Epoch[9] Batch [950]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.134714,	
2017-06-19 20:18:15,196 Epoch[9] Batch [960]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.134732,	
2017-06-19 20:18:19,302 Epoch[9] Batch [970]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.134710,	
2017-06-19 20:18:23,422 Epoch[9] Batch [980]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.134755,	
2017-06-19 20:18:27,709 Epoch[9] Batch [990]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.134846,	
2017-06-19 20:18:31,822 Epoch[9] Batch [1000]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134805,	
2017-06-19 20:18:35,985 Epoch[9] Batch [1010]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.134749,	
2017-06-19 20:18:40,097 Epoch[9] Batch [1020]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134704,	
2017-06-19 20:18:44,312 Epoch[9] Batch [1030]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.134799,	
2017-06-19 20:18:48,421 Epoch[9] Batch [1040]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134780,	
2017-06-19 20:18:52,480 Epoch[9] Batch [1050]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.134766,	
2017-06-19 20:18:56,469 Epoch[9] Batch [1060]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.134770,	
2017-06-19 20:19:00,581 Epoch[9] Batch [1070]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134609,	
2017-06-19 20:19:04,864 Epoch[9] Batch [1080]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.134413,	
2017-06-19 20:19:08,938 Epoch[9] Batch [1090]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.134440,	
2017-06-19 20:19:12,864 Epoch[9] Batch [1100]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.134449,	
2017-06-19 20:19:17,089 Epoch[9] Batch [1110]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.134357,	
2017-06-19 20:19:21,351 Epoch[9] Batch [1120]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.134359,	
2017-06-19 20:19:25,659 Epoch[9] Batch [1130]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.134223,	
2017-06-19 20:19:29,950 Epoch[9] Batch [1140]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.134238,	
2017-06-19 20:19:33,823 Epoch[9] Batch [1150]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.134347,	
2017-06-19 20:19:37,891 Epoch[9] Batch [1160]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.134405,	
2017-06-19 20:19:42,040 Epoch[9] Batch [1170]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.134483,	
2017-06-19 20:19:46,176 Epoch[9] Batch [1180]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.134666,	
2017-06-19 20:19:50,380 Epoch[9] Batch [1190]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.134593,	
2017-06-19 20:19:54,592 Epoch[9] Batch [1200]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.134617,	
2017-06-19 20:19:58,754 Epoch[9] Batch [1210]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.134744,	
2017-06-19 20:20:02,927 Epoch[9] Batch [1220]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.134657,	
2017-06-19 20:20:06,955 Epoch[9] Batch [1230]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.134668,	
2017-06-19 20:20:11,013 Epoch[9] Batch [1240]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.134620,	
2017-06-19 20:20:15,112 Epoch[9] Batch [1250]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.134696,	
2017-06-19 20:20:19,339 Epoch[9] Batch [1260]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.134636,	
2017-06-19 20:20:23,415 Epoch[9] Batch [1270]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.134735,	
2017-06-19 20:20:27,677 Epoch[9] Batch [1280]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.134704,	
2017-06-19 20:20:31,755 Epoch[9] Batch [1290]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.134585,	
2017-06-19 20:20:35,820 Epoch[9] Batch [1300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.134567,	
2017-06-19 20:20:40,123 Epoch[9] Batch [1310]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.134490,	
2017-06-19 20:20:44,268 Epoch[9] Batch [1320]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.134415,	
2017-06-19 20:20:48,370 Epoch[9] Batch [1330]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.134306,	
2017-06-19 20:20:52,414 Epoch[9] Batch [1340]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.134221,	
2017-06-19 20:20:56,636 Epoch[9] Batch [1350]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.134198,	
2017-06-19 20:21:01,057 Epoch[9] Batch [1360]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.134182,	
2017-06-19 20:21:05,405 Epoch[9] Batch [1370]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.134161,	
2017-06-19 20:21:09,713 Epoch[9] Batch [1380]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.134113,	
2017-06-19 20:21:14,214 Epoch[9] Batch [1390]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.133978,	
2017-06-19 20:21:18,382 Epoch[9] Batch [1400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.133976,	
2017-06-19 20:21:22,604 Epoch[9] Batch [1410]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.134060,	
2017-06-19 20:21:26,826 Epoch[9] Batch [1420]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.134034,	
2017-06-19 20:21:31,106 Epoch[9] Batch [1430]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.133999,	
2017-06-19 20:21:35,187 Epoch[9] Batch [1440]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.133987,	
2017-06-19 20:21:39,391 Epoch[9] Batch [1450]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.133872,	
2017-06-19 20:21:43,499 Epoch[9] Batch [1460]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.133884,	
2017-06-19 20:21:47,808 Epoch[9] Batch [1470]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.133921,	
2017-06-19 20:21:51,960 Epoch[9] Batch [1480]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.134016,	
2017-06-19 20:21:54,519 Epoch[9] Train-FCNLogLoss=0.134092
2017-06-19 20:21:54,520 Epoch[9] Time cost=617.035
2017-06-19 20:21:55,210 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0010.params"
2017-06-19 20:21:56,948 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0010.states"
2017-06-19 20:22:01,956 Epoch[10] Batch [10]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.171760,	
2017-06-19 20:22:06,153 Epoch[10] Batch [20]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.162729,	
2017-06-19 20:22:10,285 Epoch[10] Batch [30]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.149704,	
2017-06-19 20:22:14,488 Epoch[10] Batch [40]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.149950,	
2017-06-19 20:22:18,708 Epoch[10] Batch [50]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.144404,	
2017-06-19 20:22:23,033 Epoch[10] Batch [60]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.142652,	
2017-06-19 20:22:27,310 Epoch[10] Batch [70]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.139878,	
2017-06-19 20:22:31,359 Epoch[10] Batch [80]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.137411,	
2017-06-19 20:22:35,570 Epoch[10] Batch [90]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.136234,	
2017-06-19 20:22:39,856 Epoch[10] Batch [100]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.135113,	
2017-06-19 20:22:43,890 Epoch[10] Batch [110]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.133989,	
2017-06-19 20:22:48,155 Epoch[10] Batch [120]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.134085,	
2017-06-19 20:22:52,409 Epoch[10] Batch [130]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.133918,	
2017-06-19 20:22:56,714 Epoch[10] Batch [140]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.134023,	
2017-06-19 20:23:01,027 Epoch[10] Batch [150]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.133963,	
2017-06-19 20:23:05,335 Epoch[10] Batch [160]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.133563,	
2017-06-19 20:23:09,408 Epoch[10] Batch [170]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.133670,	
2017-06-19 20:23:13,835 Epoch[10] Batch [180]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.133072,	
2017-06-19 20:23:18,136 Epoch[10] Batch [190]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.133135,	
2017-06-19 20:23:22,482 Epoch[10] Batch [200]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.131780,	
2017-06-19 20:23:26,843 Epoch[10] Batch [210]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.131690,	
2017-06-19 20:23:30,961 Epoch[10] Batch [220]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.130552,	
2017-06-19 20:23:35,199 Epoch[10] Batch [230]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.130398,	
2017-06-19 20:23:39,522 Epoch[10] Batch [240]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.130417,	
2017-06-19 20:23:43,851 Epoch[10] Batch [250]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.129966,	
2017-06-19 20:23:48,160 Epoch[10] Batch [260]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.129198,	
2017-06-19 20:23:52,446 Epoch[10] Batch [270]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.129332,	
2017-06-19 20:23:56,517 Epoch[10] Batch [280]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.129155,	
2017-06-19 20:24:00,875 Epoch[10] Batch [290]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.129770,	
2017-06-19 20:24:05,288 Epoch[10] Batch [300]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.129602,	
2017-06-19 20:24:09,614 Epoch[10] Batch [310]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.130871,	
2017-06-19 20:24:13,726 Epoch[10] Batch [320]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.130924,	
2017-06-19 20:24:17,924 Epoch[10] Batch [330]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.130939,	
2017-06-19 20:24:22,131 Epoch[10] Batch [340]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.131582,	
2017-06-19 20:24:26,278 Epoch[10] Batch [350]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.131858,	
2017-06-19 20:24:30,586 Epoch[10] Batch [360]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.132316,	
2017-06-19 20:24:34,969 Epoch[10] Batch [370]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.132371,	
2017-06-19 20:24:39,165 Epoch[10] Batch [380]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.132359,	
2017-06-19 20:24:43,234 Epoch[10] Batch [390]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.132079,	
2017-06-19 20:24:47,370 Epoch[10] Batch [400]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.131766,	
2017-06-19 20:24:51,583 Epoch[10] Batch [410]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.131852,	
2017-06-19 20:24:55,826 Epoch[10] Batch [420]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.131672,	
2017-06-19 20:25:00,332 Epoch[10] Batch [430]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.131623,	
2017-06-19 20:25:04,701 Epoch[10] Batch [440]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.131409,	
2017-06-19 20:25:09,089 Epoch[10] Batch [450]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.131376,	
2017-06-19 20:25:13,496 Epoch[10] Batch [460]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.131519,	
2017-06-19 20:25:17,785 Epoch[10] Batch [470]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.131652,	
2017-06-19 20:25:21,990 Epoch[10] Batch [480]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.131559,	
2017-06-19 20:25:26,098 Epoch[10] Batch [490]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.131372,	
2017-06-19 20:25:30,267 Epoch[10] Batch [500]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.131164,	
2017-06-19 20:25:34,521 Epoch[10] Batch [510]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.131312,	
2017-06-19 20:25:38,534 Epoch[10] Batch [520]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.131549,	
2017-06-19 20:25:42,739 Epoch[10] Batch [530]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.131793,	
2017-06-19 20:25:46,761 Epoch[10] Batch [540]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.131771,	
2017-06-19 20:25:50,884 Epoch[10] Batch [550]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.131596,	
2017-06-19 20:25:55,069 Epoch[10] Batch [560]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.131291,	
2017-06-19 20:25:59,273 Epoch[10] Batch [570]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.131168,	
2017-06-19 20:26:03,652 Epoch[10] Batch [580]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.131391,	
2017-06-19 20:26:08,214 Epoch[10] Batch [590]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.131255,	
2017-06-19 20:26:12,485 Epoch[10] Batch [600]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.131261,	
2017-06-19 20:26:16,748 Epoch[10] Batch [610]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.131020,	
2017-06-19 20:26:21,070 Epoch[10] Batch [620]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.130933,	
2017-06-19 20:26:25,469 Epoch[10] Batch [630]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.131045,	
2017-06-19 20:26:29,576 Epoch[10] Batch [640]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.131217,	
2017-06-19 20:26:33,642 Epoch[10] Batch [650]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.131152,	
2017-06-19 20:26:37,588 Epoch[10] Batch [660]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.131227,	
2017-06-19 20:26:41,807 Epoch[10] Batch [670]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.131132,	
2017-06-19 20:26:46,023 Epoch[10] Batch [680]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.131173,	
2017-06-19 20:26:50,217 Epoch[10] Batch [690]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.130904,	
2017-06-19 20:26:54,563 Epoch[10] Batch [700]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.130954,	
2017-06-19 20:26:58,966 Epoch[10] Batch [710]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.130757,	
2017-06-19 20:27:03,416 Epoch[10] Batch [720]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.130713,	
2017-06-19 20:27:08,075 Epoch[10] Batch [730]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.130645,	
2017-06-19 20:27:12,238 Epoch[10] Batch [740]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.130548,	
2017-06-19 20:27:16,488 Epoch[10] Batch [750]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.130647,	
2017-06-19 20:27:20,804 Epoch[10] Batch [760]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.130394,	
2017-06-19 20:27:25,291 Epoch[10] Batch [770]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.130320,	
2017-06-19 20:27:29,720 Epoch[10] Batch [780]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.130333,	
2017-06-19 20:27:33,712 Epoch[10] Batch [790]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.130174,	
2017-06-19 20:27:37,842 Epoch[10] Batch [800]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.130068,	
2017-06-19 20:27:41,915 Epoch[10] Batch [810]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130100,	
2017-06-19 20:27:45,994 Epoch[10] Batch [820]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.130212,	
2017-06-19 20:27:50,293 Epoch[10] Batch [830]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.130066,	
2017-06-19 20:27:54,383 Epoch[10] Batch [840]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.130002,	
2017-06-19 20:27:58,506 Epoch[10] Batch [850]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.129844,	
2017-06-19 20:28:02,916 Epoch[10] Batch [860]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.129714,	
2017-06-19 20:28:07,247 Epoch[10] Batch [870]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.129487,	
2017-06-19 20:28:11,833 Epoch[10] Batch [880]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.129356,	
2017-06-19 20:28:16,324 Epoch[10] Batch [890]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.129228,	
2017-06-19 20:28:20,637 Epoch[10] Batch [900]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.129309,	
2017-06-19 20:28:25,052 Epoch[10] Batch [910]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.129737,	
2017-06-19 20:28:29,579 Epoch[10] Batch [920]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.129632,	
2017-06-19 20:28:33,790 Epoch[10] Batch [930]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.129566,	
2017-06-19 20:28:38,029 Epoch[10] Batch [940]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.129556,	
2017-06-19 20:28:42,198 Epoch[10] Batch [950]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.129628,	
2017-06-19 20:28:46,257 Epoch[10] Batch [960]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.129855,	
2017-06-19 20:28:50,495 Epoch[10] Batch [970]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.129802,	
2017-06-19 20:28:54,791 Epoch[10] Batch [980]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.129857,	
2017-06-19 20:28:59,324 Epoch[10] Batch [990]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.129864,	
2017-06-19 20:29:03,537 Epoch[10] Batch [1000]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.130065,	
2017-06-19 20:29:07,965 Epoch[10] Batch [1010]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.130062,	
2017-06-19 20:29:12,487 Epoch[10] Batch [1020]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.130016,	
2017-06-19 20:29:17,090 Epoch[10] Batch [1030]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.129915,	
2017-06-19 20:29:21,568 Epoch[10] Batch [1040]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.129848,	
2017-06-19 20:29:25,838 Epoch[10] Batch [1050]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.130079,	
2017-06-19 20:29:30,213 Epoch[10] Batch [1060]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.130054,	
2017-06-19 20:29:34,749 Epoch[10] Batch [1070]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.130017,	
2017-06-19 20:29:39,201 Epoch[10] Batch [1080]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.130134,	
2017-06-19 20:29:43,667 Epoch[10] Batch [1090]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.130085,	
2017-06-19 20:29:47,974 Epoch[10] Batch [1100]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.130181,	
2017-06-19 20:29:52,313 Epoch[10] Batch [1110]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.130226,	
2017-06-19 20:29:56,842 Epoch[10] Batch [1120]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.130252,	
2017-06-19 20:30:01,585 Epoch[10] Batch [1130]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.130151,	
2017-06-19 20:30:05,749 Epoch[10] Batch [1140]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.130392,	
2017-06-19 20:30:09,969 Epoch[10] Batch [1150]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.130363,	
2017-06-19 20:30:14,121 Epoch[10] Batch [1160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.130199,	
2017-06-19 20:30:18,115 Epoch[10] Batch [1170]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.130327,	
2017-06-19 20:30:22,366 Epoch[10] Batch [1180]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.130306,	
2017-06-19 20:30:26,433 Epoch[10] Batch [1190]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.130256,	
2017-06-19 20:30:30,507 Epoch[10] Batch [1200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130267,	
2017-06-19 20:30:34,581 Epoch[10] Batch [1210]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130282,	
2017-06-19 20:30:39,006 Epoch[10] Batch [1220]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.130352,	
2017-06-19 20:30:43,255 Epoch[10] Batch [1230]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.130262,	
2017-06-19 20:30:47,611 Epoch[10] Batch [1240]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.130311,	
2017-06-19 20:30:52,045 Epoch[10] Batch [1250]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.130339,	
2017-06-19 20:30:56,299 Epoch[10] Batch [1260]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.130204,	
2017-06-19 20:31:00,676 Epoch[10] Batch [1270]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.130167,	
2017-06-19 20:31:05,131 Epoch[10] Batch [1280]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.130158,	
2017-06-19 20:31:09,487 Epoch[10] Batch [1290]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.130090,	
2017-06-19 20:31:13,736 Epoch[10] Batch [1300]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.130084,	
2017-06-19 20:31:18,063 Epoch[10] Batch [1310]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.130164,	
2017-06-19 20:31:22,742 Epoch[10] Batch [1320]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.130342,	
2017-06-19 20:31:27,077 Epoch[10] Batch [1330]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.130323,	
2017-06-19 20:31:31,308 Epoch[10] Batch [1340]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.130317,	
2017-06-19 20:31:35,555 Epoch[10] Batch [1350]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.130290,	
2017-06-19 20:31:39,571 Epoch[10] Batch [1360]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.130257,	
2017-06-19 20:31:43,679 Epoch[10] Batch [1370]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.130301,	
2017-06-19 20:31:47,754 Epoch[10] Batch [1380]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130325,	
2017-06-19 20:31:51,844 Epoch[10] Batch [1390]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.130291,	
2017-06-19 20:31:55,995 Epoch[10] Batch [1400]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.130257,	
2017-06-19 20:32:00,118 Epoch[10] Batch [1410]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.130217,	
2017-06-19 20:32:04,097 Epoch[10] Batch [1420]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.130093,	
2017-06-19 20:32:08,319 Epoch[10] Batch [1430]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.129987,	
2017-06-19 20:32:12,642 Epoch[10] Batch [1440]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.130022,	
2017-06-19 20:32:16,901 Epoch[10] Batch [1450]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.130044,	
2017-06-19 20:32:21,281 Epoch[10] Batch [1460]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.129977,	
2017-06-19 20:32:25,859 Epoch[10] Batch [1470]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.129939,	
2017-06-19 20:32:30,164 Epoch[10] Batch [1480]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.129870,	
2017-06-19 20:32:32,808 Epoch[10] Train-FCNLogLoss=0.129816
2017-06-19 20:32:32,808 Epoch[10] Time cost=635.859
2017-06-19 20:32:33,519 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0011.params"
2017-06-19 20:32:35,160 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0011.states"
2017-06-19 20:32:40,430 Epoch[11] Batch [10]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.111787,	
2017-06-19 20:32:44,684 Epoch[11] Batch [20]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.120538,	
2017-06-19 20:32:48,810 Epoch[11] Batch [30]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.130260,	
2017-06-19 20:32:52,815 Epoch[11] Batch [40]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.130195,	
2017-06-19 20:32:57,065 Epoch[11] Batch [50]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.135122,	
2017-06-19 20:33:01,116 Epoch[11] Batch [60]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.135538,	
2017-06-19 20:33:05,353 Epoch[11] Batch [70]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.136461,	
2017-06-19 20:33:09,416 Epoch[11] Batch [80]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.138615,	
2017-06-19 20:33:13,609 Epoch[11] Batch [90]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.136590,	
2017-06-19 20:33:17,995 Epoch[11] Batch [100]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.135912,	
2017-06-19 20:33:22,201 Epoch[11] Batch [110]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.132931,	
2017-06-19 20:33:26,588 Epoch[11] Batch [120]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.131440,	
2017-06-19 20:33:30,959 Epoch[11] Batch [130]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.131108,	
2017-06-19 20:33:35,222 Epoch[11] Batch [140]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.129277,	
2017-06-19 20:33:39,586 Epoch[11] Batch [150]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.128622,	
2017-06-19 20:33:44,169 Epoch[11] Batch [160]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.128482,	
2017-06-19 20:33:48,537 Epoch[11] Batch [170]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.127049,	
2017-06-19 20:33:52,831 Epoch[11] Batch [180]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.126368,	
2017-06-19 20:33:57,357 Epoch[11] Batch [190]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.126461,	
2017-06-19 20:34:01,562 Epoch[11] Batch [200]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.126021,	
2017-06-19 20:34:06,125 Epoch[11] Batch [210]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.124878,	
2017-06-19 20:34:10,443 Epoch[11] Batch [220]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.126177,	
2017-06-19 20:34:14,971 Epoch[11] Batch [230]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.126516,	
2017-06-19 20:34:19,153 Epoch[11] Batch [240]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.125666,	
2017-06-19 20:34:23,507 Epoch[11] Batch [250]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.124961,	
2017-06-19 20:34:28,117 Epoch[11] Batch [260]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.124903,	
2017-06-19 20:34:32,724 Epoch[11] Batch [270]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.124888,	
2017-06-19 20:34:37,063 Epoch[11] Batch [280]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.124602,	
2017-06-19 20:34:41,429 Epoch[11] Batch [290]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.125033,	
2017-06-19 20:34:45,622 Epoch[11] Batch [300]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.124896,	
2017-06-19 20:34:50,106 Epoch[11] Batch [310]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.124319,	
2017-06-19 20:34:54,341 Epoch[11] Batch [320]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.124245,	
2017-06-19 20:34:58,680 Epoch[11] Batch [330]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.124299,	
2017-06-19 20:35:02,823 Epoch[11] Batch [340]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.124404,	
2017-06-19 20:35:06,866 Epoch[11] Batch [350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.124800,	
2017-06-19 20:35:11,431 Epoch[11] Batch [360]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.124507,	
2017-06-19 20:35:15,657 Epoch[11] Batch [370]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.124344,	
2017-06-19 20:35:19,912 Epoch[11] Batch [380]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.124170,	
2017-06-19 20:35:24,439 Epoch[11] Batch [390]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.124121,	
2017-06-19 20:35:28,738 Epoch[11] Batch [400]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.124308,	
2017-06-19 20:35:32,953 Epoch[11] Batch [410]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.124426,	
2017-06-19 20:35:37,562 Epoch[11] Batch [420]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.124780,	
2017-06-19 20:35:41,961 Epoch[11] Batch [430]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.124763,	
2017-06-19 20:35:46,465 Epoch[11] Batch [440]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.125110,	
2017-06-19 20:35:51,121 Epoch[11] Batch [450]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.125824,	
2017-06-19 20:35:55,336 Epoch[11] Batch [460]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.125542,	
2017-06-19 20:35:59,768 Epoch[11] Batch [470]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.125480,	
2017-06-19 20:36:04,292 Epoch[11] Batch [480]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.125341,	
2017-06-19 20:36:08,689 Epoch[11] Batch [490]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.125492,	
2017-06-19 20:36:13,166 Epoch[11] Batch [500]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.125382,	
2017-06-19 20:36:17,682 Epoch[11] Batch [510]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.125471,	
2017-06-19 20:36:22,173 Epoch[11] Batch [520]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.125122,	
2017-06-19 20:36:26,351 Epoch[11] Batch [530]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.125292,	
2017-06-19 20:36:30,691 Epoch[11] Batch [540]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.125463,	
2017-06-19 20:36:34,833 Epoch[11] Batch [550]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.125435,	
2017-06-19 20:36:39,110 Epoch[11] Batch [560]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.125491,	
2017-06-19 20:36:43,278 Epoch[11] Batch [570]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.125685,	
2017-06-19 20:36:47,331 Epoch[11] Batch [580]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.125809,	
2017-06-19 20:36:51,716 Epoch[11] Batch [590]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.125808,	
2017-06-19 20:36:56,104 Epoch[11] Batch [600]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.126074,	
2017-06-19 20:37:00,386 Epoch[11] Batch [610]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.126034,	
2017-06-19 20:37:04,752 Epoch[11] Batch [620]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.126197,	
2017-06-19 20:37:08,934 Epoch[11] Batch [630]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.126406,	
2017-06-19 20:37:13,435 Epoch[11] Batch [640]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.126247,	
2017-06-19 20:37:17,953 Epoch[11] Batch [650]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.126467,	
2017-06-19 20:37:22,417 Epoch[11] Batch [660]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.126588,	
2017-06-19 20:37:26,736 Epoch[11] Batch [670]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.126604,	
2017-06-19 20:37:31,173 Epoch[11] Batch [680]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.126552,	
2017-06-19 20:37:35,367 Epoch[11] Batch [690]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.126643,	
2017-06-19 20:37:39,774 Epoch[11] Batch [700]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.126710,	
2017-06-19 20:37:43,943 Epoch[11] Batch [710]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.126619,	
2017-06-19 20:37:48,435 Epoch[11] Batch [720]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.126616,	
2017-06-19 20:37:52,564 Epoch[11] Batch [730]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.126594,	
2017-06-19 20:37:56,975 Epoch[11] Batch [740]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.126640,	
2017-06-19 20:38:01,391 Epoch[11] Batch [750]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.126245,	
2017-06-19 20:38:05,672 Epoch[11] Batch [760]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.125994,	
2017-06-19 20:38:09,965 Epoch[11] Batch [770]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.125902,	
2017-06-19 20:38:14,487 Epoch[11] Batch [780]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.126077,	
2017-06-19 20:38:18,701 Epoch[11] Batch [790]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.126178,	
2017-06-19 20:38:22,948 Epoch[11] Batch [800]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.126185,	
2017-06-19 20:38:27,253 Epoch[11] Batch [810]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.126337,	
2017-06-19 20:38:31,453 Epoch[11] Batch [820]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.126276,	
2017-06-19 20:38:35,748 Epoch[11] Batch [830]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.126363,	
2017-06-19 20:38:40,074 Epoch[11] Batch [840]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.126424,	
2017-06-19 20:38:44,307 Epoch[11] Batch [850]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.126337,	
2017-06-19 20:38:48,435 Epoch[11] Batch [860]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.126188,	
2017-06-19 20:38:52,802 Epoch[11] Batch [870]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.126069,	
2017-06-19 20:38:57,262 Epoch[11] Batch [880]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.125943,	
2017-06-19 20:39:01,554 Epoch[11] Batch [890]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.126008,	
2017-06-19 20:39:05,982 Epoch[11] Batch [900]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.125988,	
2017-06-19 20:39:10,377 Epoch[11] Batch [910]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.126269,	
2017-06-19 20:39:14,680 Epoch[11] Batch [920]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.126310,	
2017-06-19 20:39:19,135 Epoch[11] Batch [930]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.126181,	
2017-06-19 20:39:23,641 Epoch[11] Batch [940]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.126330,	
2017-06-19 20:39:28,199 Epoch[11] Batch [950]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.126358,	
2017-06-19 20:39:32,664 Epoch[11] Batch [960]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.126585,	
2017-06-19 20:39:36,666 Epoch[11] Batch [970]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.126842,	
2017-06-19 20:39:40,974 Epoch[11] Batch [980]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.127199,	
2017-06-19 20:39:45,378 Epoch[11] Batch [990]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.127303,	
2017-06-19 20:39:49,565 Epoch[11] Batch [1000]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.127243,	
2017-06-19 20:39:54,223 Epoch[11] Batch [1010]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.127170,	
2017-06-19 20:39:58,601 Epoch[11] Batch [1020]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.127197,	
2017-06-19 20:40:02,761 Epoch[11] Batch [1030]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.127260,	
2017-06-19 20:40:07,154 Epoch[11] Batch [1040]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.127310,	
2017-06-19 20:40:11,653 Epoch[11] Batch [1050]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.127862,	
2017-06-19 20:40:15,982 Epoch[11] Batch [1060]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.127940,	
2017-06-19 20:40:20,338 Epoch[11] Batch [1070]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.128010,	
2017-06-19 20:40:24,565 Epoch[11] Batch [1080]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.128207,	
2017-06-19 20:40:28,977 Epoch[11] Batch [1090]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.128553,	
2017-06-19 20:40:33,320 Epoch[11] Batch [1100]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.128506,	
2017-06-19 20:40:37,642 Epoch[11] Batch [1110]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.128290,	
2017-06-19 20:40:42,045 Epoch[11] Batch [1120]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.128323,	
2017-06-19 20:40:46,796 Epoch[11] Batch [1130]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.128231,	
2017-06-19 20:40:51,343 Epoch[11] Batch [1140]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.128197,	
2017-06-19 20:40:55,846 Epoch[11] Batch [1150]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.128054,	
2017-06-19 20:41:00,225 Epoch[11] Batch [1160]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.128022,	
2017-06-19 20:41:04,476 Epoch[11] Batch [1170]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.128018,	
2017-06-19 20:41:09,287 Epoch[11] Batch [1180]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.128063,	
2017-06-19 20:41:14,240 Epoch[11] Batch [1190]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.127991,	
2017-06-19 20:41:18,654 Epoch[11] Batch [1200]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.127967,	
2017-06-19 20:41:23,065 Epoch[11] Batch [1210]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.127956,	
2017-06-19 20:41:27,409 Epoch[11] Batch [1220]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.127827,	
2017-06-19 20:41:32,193 Epoch[11] Batch [1230]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.127820,	
2017-06-19 20:41:36,684 Epoch[11] Batch [1240]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.128370,	
2017-06-19 20:41:41,086 Epoch[11] Batch [1250]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.128517,	
2017-06-19 20:41:45,477 Epoch[11] Batch [1260]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.128445,	
2017-06-19 20:41:49,939 Epoch[11] Batch [1270]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.128387,	
2017-06-19 20:41:54,051 Epoch[11] Batch [1280]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.128326,	
2017-06-19 20:41:58,226 Epoch[11] Batch [1290]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.128264,	
2017-06-19 20:42:02,417 Epoch[11] Batch [1300]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.128242,	
2017-06-19 20:42:06,672 Epoch[11] Batch [1310]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.128138,	
2017-06-19 20:42:10,815 Epoch[11] Batch [1320]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.128171,	
2017-06-19 20:42:15,198 Epoch[11] Batch [1330]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.128081,	
2017-06-19 20:42:19,808 Epoch[11] Batch [1340]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.128179,	
2017-06-19 20:42:24,394 Epoch[11] Batch [1350]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.128118,	
2017-06-19 20:42:28,860 Epoch[11] Batch [1360]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.128136,	
2017-06-19 20:42:33,161 Epoch[11] Batch [1370]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.128183,	
2017-06-19 20:42:37,735 Epoch[11] Batch [1380]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.128128,	
2017-06-19 20:42:42,289 Epoch[11] Batch [1390]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.128183,	
2017-06-19 20:42:46,783 Epoch[11] Batch [1400]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.128165,	
2017-06-19 20:42:51,026 Epoch[11] Batch [1410]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.128153,	
2017-06-19 20:42:55,272 Epoch[11] Batch [1420]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.128071,	
2017-06-19 20:42:59,523 Epoch[11] Batch [1430]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.128203,	
2017-06-19 20:43:03,532 Epoch[11] Batch [1440]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.128331,	
2017-06-19 20:43:07,749 Epoch[11] Batch [1450]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.128438,	
2017-06-19 20:43:12,102 Epoch[11] Batch [1460]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.128896,	
2017-06-19 20:43:16,506 Epoch[11] Batch [1470]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.129277,	
2017-06-19 20:43:21,108 Epoch[11] Batch [1480]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.129617,	
2017-06-19 20:43:23,683 Epoch[11] Train-FCNLogLoss=0.129698
2017-06-19 20:43:23,683 Epoch[11] Time cost=648.523
2017-06-19 20:43:24,377 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0012.params"
2017-06-19 20:43:25,842 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0012.states"
2017-06-19 20:43:31,106 Epoch[12] Batch [10]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.137360,	
2017-06-19 20:43:35,605 Epoch[12] Batch [20]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.134690,	
2017-06-19 20:43:40,289 Epoch[12] Batch [30]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.134364,	
2017-06-19 20:43:44,863 Epoch[12] Batch [40]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.133860,	
2017-06-19 20:43:49,165 Epoch[12] Batch [50]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.134419,	
2017-06-19 20:43:53,387 Epoch[12] Batch [60]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.135517,	
2017-06-19 20:43:57,369 Epoch[12] Batch [70]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.133549,	
2017-06-19 20:44:01,680 Epoch[12] Batch [80]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.130886,	
2017-06-19 20:44:05,664 Epoch[12] Batch [90]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.130490,	
2017-06-19 20:44:09,934 Epoch[12] Batch [100]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.129891,	
2017-06-19 20:44:14,193 Epoch[12] Batch [110]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.129340,	
2017-06-19 20:44:18,443 Epoch[12] Batch [120]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.129423,	
2017-06-19 20:44:22,847 Epoch[12] Batch [130]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.129572,	
2017-06-19 20:44:27,508 Epoch[12] Batch [140]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.131114,	
2017-06-19 20:44:32,085 Epoch[12] Batch [150]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.131289,	
2017-06-19 20:44:36,398 Epoch[12] Batch [160]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.131663,	
2017-06-19 20:44:41,030 Epoch[12] Batch [170]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.132110,	
2017-06-19 20:44:45,734 Epoch[12] Batch [180]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.132343,	
2017-06-19 20:44:50,340 Epoch[12] Batch [190]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.132570,	
2017-06-19 20:44:54,691 Epoch[12] Batch [200]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.132122,	
2017-06-19 20:44:58,934 Epoch[12] Batch [210]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.131812,	
2017-06-19 20:45:03,538 Epoch[12] Batch [220]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.132914,	
2017-06-19 20:45:08,185 Epoch[12] Batch [230]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.133220,	
2017-06-19 20:45:12,607 Epoch[12] Batch [240]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.133974,	
2017-06-19 20:45:17,208 Epoch[12] Batch [250]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.133705,	
2017-06-19 20:45:21,676 Epoch[12] Batch [260]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.133786,	
2017-06-19 20:45:25,945 Epoch[12] Batch [270]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.134799,	
2017-06-19 20:45:30,055 Epoch[12] Batch [280]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134275,	
2017-06-19 20:45:34,173 Epoch[12] Batch [290]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.134245,	
2017-06-19 20:45:38,694 Epoch[12] Batch [300]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.134635,	
2017-06-19 20:45:42,678 Epoch[12] Batch [310]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.134382,	
2017-06-19 20:45:46,755 Epoch[12] Batch [320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.134780,	
2017-06-19 20:45:51,107 Epoch[12] Batch [330]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.134629,	
2017-06-19 20:45:55,440 Epoch[12] Batch [340]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.134198,	
2017-06-19 20:45:59,749 Epoch[12] Batch [350]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.134805,	
2017-06-19 20:46:04,446 Epoch[12] Batch [360]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.134776,	
2017-06-19 20:46:08,963 Epoch[12] Batch [370]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.134913,	
2017-06-19 20:46:13,507 Epoch[12] Batch [380]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.134667,	
2017-06-19 20:46:17,949 Epoch[12] Batch [390]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.134912,	
2017-06-19 20:46:22,465 Epoch[12] Batch [400]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.135041,	
2017-06-19 20:46:27,186 Epoch[12] Batch [410]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.134796,	
2017-06-19 20:46:31,697 Epoch[12] Batch [420]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.135001,	
2017-06-19 20:46:36,018 Epoch[12] Batch [430]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.135095,	
2017-06-19 20:46:40,047 Epoch[12] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.134690,	
2017-06-19 20:46:44,367 Epoch[12] Batch [450]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.134322,	
2017-06-19 20:46:48,384 Epoch[12] Batch [460]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.134028,	
2017-06-19 20:46:52,654 Epoch[12] Batch [470]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.134457,	
2017-06-19 20:46:56,797 Epoch[12] Batch [480]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.134695,	
2017-06-19 20:47:00,928 Epoch[12] Batch [490]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.135300,	
2017-06-19 20:47:05,752 Epoch[12] Batch [500]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.135223,	
2017-06-19 20:47:10,246 Epoch[12] Batch [510]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.134970,	
2017-06-19 20:47:14,583 Epoch[12] Batch [520]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.134893,	
2017-06-19 20:47:18,988 Epoch[12] Batch [530]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.134595,	
2017-06-19 20:47:23,478 Epoch[12] Batch [540]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.134303,	
2017-06-19 20:47:27,856 Epoch[12] Batch [550]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.133882,	
2017-06-19 20:47:32,205 Epoch[12] Batch [560]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.133638,	
2017-06-19 20:47:36,628 Epoch[12] Batch [570]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.133154,	
2017-06-19 20:47:40,758 Epoch[12] Batch [580]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.133040,	
2017-06-19 20:47:44,964 Epoch[12] Batch [590]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.132835,	
2017-06-19 20:47:48,961 Epoch[12] Batch [600]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.132540,	
2017-06-19 20:47:53,031 Epoch[12] Batch [610]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.132310,	
2017-06-19 20:47:57,294 Epoch[12] Batch [620]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.132468,	
2017-06-19 20:48:01,377 Epoch[12] Batch [630]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.132536,	
2017-06-19 20:48:05,764 Epoch[12] Batch [640]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.132482,	
2017-06-19 20:48:10,264 Epoch[12] Batch [650]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.132310,	
2017-06-19 20:48:14,811 Epoch[12] Batch [660]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.132411,	
2017-06-19 20:48:19,206 Epoch[12] Batch [670]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.132332,	
2017-06-19 20:48:23,675 Epoch[12] Batch [680]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.132318,	
2017-06-19 20:48:28,202 Epoch[12] Batch [690]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.132098,	
2017-06-19 20:48:32,972 Epoch[12] Batch [700]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.131883,	
2017-06-19 20:48:37,657 Epoch[12] Batch [710]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.131978,	
2017-06-19 20:48:41,995 Epoch[12] Batch [720]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.131846,	
2017-06-19 20:48:46,754 Epoch[12] Batch [730]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.131663,	
2017-06-19 20:48:51,124 Epoch[12] Batch [740]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.131825,	
2017-06-19 20:48:55,720 Epoch[12] Batch [750]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.131644,	
2017-06-19 20:49:00,133 Epoch[12] Batch [760]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.131566,	
2017-06-19 20:49:04,505 Epoch[12] Batch [770]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.131506,	
2017-06-19 20:49:08,923 Epoch[12] Batch [780]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.131368,	
2017-06-19 20:49:13,281 Epoch[12] Batch [790]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.131137,	
2017-06-19 20:49:17,841 Epoch[12] Batch [800]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.131063,	
2017-06-19 20:49:22,126 Epoch[12] Batch [810]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.131433,	
2017-06-19 20:49:26,818 Epoch[12] Batch [820]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.131433,	
2017-06-19 20:49:31,130 Epoch[12] Batch [830]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.131553,	
2017-06-19 20:49:35,647 Epoch[12] Batch [840]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.131313,	
2017-06-19 20:49:40,130 Epoch[12] Batch [850]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.131215,	
2017-06-19 20:49:44,518 Epoch[12] Batch [860]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.131019,	
2017-06-19 20:49:49,037 Epoch[12] Batch [870]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.130860,	
2017-06-19 20:49:53,271 Epoch[12] Batch [880]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.130750,	
2017-06-19 20:49:57,481 Epoch[12] Batch [890]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.130663,	
2017-06-19 20:50:01,368 Epoch[12] Batch [900]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.130639,	
2017-06-19 20:50:05,637 Epoch[12] Batch [910]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.130650,	
2017-06-19 20:50:09,808 Epoch[12] Batch [920]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.130722,	
2017-06-19 20:50:13,954 Epoch[12] Batch [930]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.130521,	
2017-06-19 20:50:18,135 Epoch[12] Batch [940]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.130403,	
2017-06-19 20:50:22,769 Epoch[12] Batch [950]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.130406,	
2017-06-19 20:50:27,487 Epoch[12] Batch [960]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.130360,	
2017-06-19 20:50:32,079 Epoch[12] Batch [970]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.130234,	
2017-06-19 20:50:36,894 Epoch[12] Batch [980]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.130129,	
2017-06-19 20:50:42,022 Epoch[12] Batch [990]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.130048,	
2017-06-19 20:50:46,687 Epoch[12] Batch [1000]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.130027,	
2017-06-19 20:50:51,133 Epoch[12] Batch [1010]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.130012,	
2017-06-19 20:50:55,360 Epoch[12] Batch [1020]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.129936,	
2017-06-19 20:50:59,548 Epoch[12] Batch [1030]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.129862,	
2017-06-19 20:51:04,058 Epoch[12] Batch [1040]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.129700,	
2017-06-19 20:51:08,738 Epoch[12] Batch [1050]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.129777,	
2017-06-19 20:51:13,091 Epoch[12] Batch [1060]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.129610,	
2017-06-19 20:51:17,504 Epoch[12] Batch [1070]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.129383,	
2017-06-19 20:51:21,685 Epoch[12] Batch [1080]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.129371,	
2017-06-19 20:51:26,126 Epoch[12] Batch [1090]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.129228,	
2017-06-19 20:51:30,375 Epoch[12] Batch [1100]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.129101,	
2017-06-19 20:51:34,637 Epoch[12] Batch [1110]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.129051,	
2017-06-19 20:51:38,919 Epoch[12] Batch [1120]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.129059,	
2017-06-19 20:51:43,295 Epoch[12] Batch [1130]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.128961,	
2017-06-19 20:51:47,427 Epoch[12] Batch [1140]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.128887,	
2017-06-19 20:51:52,035 Epoch[12] Batch [1150]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.128762,	
2017-06-19 20:51:56,419 Epoch[12] Batch [1160]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.128713,	
2017-06-19 20:52:00,909 Epoch[12] Batch [1170]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.128637,	
2017-06-19 20:52:05,704 Epoch[12] Batch [1180]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.128437,	
2017-06-19 20:52:10,090 Epoch[12] Batch [1190]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.128330,	
2017-06-19 20:52:14,323 Epoch[12] Batch [1200]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.128214,	
2017-06-19 20:52:19,022 Epoch[12] Batch [1210]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.128277,	
2017-06-19 20:52:23,539 Epoch[12] Batch [1220]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.128265,	
2017-06-19 20:52:28,047 Epoch[12] Batch [1230]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.128051,	
2017-06-19 20:52:32,370 Epoch[12] Batch [1240]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.127988,	
2017-06-19 20:52:36,801 Epoch[12] Batch [1250]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.127979,	
2017-06-19 20:52:41,292 Epoch[12] Batch [1260]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.127880,	
2017-06-19 20:52:45,912 Epoch[12] Batch [1270]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.127803,	
2017-06-19 20:52:50,191 Epoch[12] Batch [1280]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.127747,	
2017-06-19 20:52:54,705 Epoch[12] Batch [1290]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.127785,	
2017-06-19 20:52:59,562 Epoch[12] Batch [1300]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.127663,	
2017-06-19 20:53:03,733 Epoch[12] Batch [1310]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.127563,	
2017-06-19 20:53:07,752 Epoch[12] Batch [1320]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.127558,	
2017-06-19 20:53:12,195 Epoch[12] Batch [1330]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.127499,	
2017-06-19 20:53:16,520 Epoch[12] Batch [1340]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.127491,	
2017-06-19 20:53:20,903 Epoch[12] Batch [1350]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.127367,	
2017-06-19 20:53:25,280 Epoch[12] Batch [1360]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.127288,	
2017-06-19 20:53:29,873 Epoch[12] Batch [1370]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.127203,	
2017-06-19 20:53:34,321 Epoch[12] Batch [1380]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.127049,	
2017-06-19 20:53:38,833 Epoch[12] Batch [1390]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.127030,	
2017-06-19 20:53:43,462 Epoch[12] Batch [1400]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.126963,	
2017-06-19 20:53:48,109 Epoch[12] Batch [1410]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.127028,	
2017-06-19 20:53:52,799 Epoch[12] Batch [1420]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.126896,	
2017-06-19 20:53:57,202 Epoch[12] Batch [1430]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.126858,	
2017-06-19 20:54:01,710 Epoch[12] Batch [1440]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.126864,	
2017-06-19 20:54:06,326 Epoch[12] Batch [1450]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.126771,	
2017-06-19 20:54:10,861 Epoch[12] Batch [1460]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.126814,	
2017-06-19 20:54:15,456 Epoch[12] Batch [1470]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.126796,	
2017-06-19 20:54:20,085 Epoch[12] Batch [1480]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.126763,	
2017-06-19 20:54:22,800 Epoch[12] Train-FCNLogLoss=0.126776
2017-06-19 20:54:22,801 Epoch[12] Time cost=656.958
2017-06-19 20:54:23,480 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0013.params"
2017-06-19 20:54:25,069 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0013.states"
2017-06-19 20:54:30,466 Epoch[13] Batch [10]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.119946,	
2017-06-19 20:54:34,822 Epoch[13] Batch [20]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.119399,	
2017-06-19 20:54:39,025 Epoch[13] Batch [30]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.117733,	
2017-06-19 20:54:43,228 Epoch[13] Batch [40]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.116735,	
2017-06-19 20:54:47,460 Epoch[13] Batch [50]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.116974,	
2017-06-19 20:54:51,950 Epoch[13] Batch [60]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.114342,	
2017-06-19 20:54:56,543 Epoch[13] Batch [70]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.115941,	
2017-06-19 20:55:00,733 Epoch[13] Batch [80]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.116718,	
2017-06-19 20:55:05,210 Epoch[13] Batch [90]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.115700,	
2017-06-19 20:55:09,674 Epoch[13] Batch [100]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.114098,	
2017-06-19 20:55:14,124 Epoch[13] Batch [110]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.115235,	
2017-06-19 20:55:18,864 Epoch[13] Batch [120]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.114832,	
2017-06-19 20:55:23,571 Epoch[13] Batch [130]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.116742,	
2017-06-19 20:55:28,164 Epoch[13] Batch [140]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.117045,	
2017-06-19 20:55:32,535 Epoch[13] Batch [150]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.117728,	
2017-06-19 20:55:37,127 Epoch[13] Batch [160]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.118156,	
2017-06-19 20:55:41,656 Epoch[13] Batch [170]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.117391,	
2017-06-19 20:55:45,999 Epoch[13] Batch [180]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.117933,	
2017-06-19 20:55:50,668 Epoch[13] Batch [190]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.117921,	
2017-06-19 20:55:55,370 Epoch[13] Batch [200]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.118291,	
2017-06-19 20:55:59,907 Epoch[13] Batch [210]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.118584,	
2017-06-19 20:56:04,436 Epoch[13] Batch [220]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.118456,	
2017-06-19 20:56:08,720 Epoch[13] Batch [230]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.118951,	
2017-06-19 20:56:13,118 Epoch[13] Batch [240]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.118804,	
2017-06-19 20:56:17,555 Epoch[13] Batch [250]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.119044,	
2017-06-19 20:56:22,014 Epoch[13] Batch [260]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.119332,	
2017-06-19 20:56:26,128 Epoch[13] Batch [270]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.118945,	
2017-06-19 20:56:30,570 Epoch[13] Batch [280]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.118314,	
2017-06-19 20:56:34,808 Epoch[13] Batch [290]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.119361,	
2017-06-19 20:56:39,353 Epoch[13] Batch [300]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.119530,	
2017-06-19 20:56:44,103 Epoch[13] Batch [310]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.119720,	
2017-06-19 20:56:48,755 Epoch[13] Batch [320]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.119647,	
2017-06-19 20:56:53,242 Epoch[13] Batch [330]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.119192,	
2017-06-19 20:56:57,861 Epoch[13] Batch [340]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.119609,	
2017-06-19 20:57:02,321 Epoch[13] Batch [350]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.119836,	
2017-06-19 20:57:06,766 Epoch[13] Batch [360]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.119768,	
2017-06-19 20:57:11,014 Epoch[13] Batch [370]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.119512,	
2017-06-19 20:57:15,370 Epoch[13] Batch [380]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.119251,	
2017-06-19 20:57:19,463 Epoch[13] Batch [390]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.119238,	
2017-06-19 20:57:23,768 Epoch[13] Batch [400]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.119775,	
2017-06-19 20:57:27,828 Epoch[13] Batch [410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.120079,	
2017-06-19 20:57:32,242 Epoch[13] Batch [420]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.120077,	
2017-06-19 20:57:36,314 Epoch[13] Batch [430]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.120230,	
2017-06-19 20:57:40,415 Epoch[13] Batch [440]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.120844,	
2017-06-19 20:57:45,095 Epoch[13] Batch [450]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.120922,	
2017-06-19 20:57:49,634 Epoch[13] Batch [460]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.120606,	
2017-06-19 20:57:54,192 Epoch[13] Batch [470]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.120832,	
2017-06-19 20:57:58,728 Epoch[13] Batch [480]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.120605,	
2017-06-19 20:58:03,449 Epoch[13] Batch [490]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.120248,	
2017-06-19 20:58:08,012 Epoch[13] Batch [500]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.120061,	
2017-06-19 20:58:12,420 Epoch[13] Batch [510]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.120233,	
2017-06-19 20:58:16,943 Epoch[13] Batch [520]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.120160,	
2017-06-19 20:58:21,438 Epoch[13] Batch [530]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.120235,	
2017-06-19 20:58:26,052 Epoch[13] Batch [540]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.120186,	
2017-06-19 20:58:30,698 Epoch[13] Batch [550]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.119980,	
2017-06-19 20:58:35,194 Epoch[13] Batch [560]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.120196,	
2017-06-19 20:58:40,090 Epoch[13] Batch [570]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.120237,	
2017-06-19 20:58:44,612 Epoch[13] Batch [580]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.120224,	
2017-06-19 20:58:49,153 Epoch[13] Batch [590]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.120233,	
2017-06-19 20:58:53,645 Epoch[13] Batch [600]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.120468,	
2017-06-19 20:58:57,924 Epoch[13] Batch [610]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.120458,	
2017-06-19 20:59:02,512 Epoch[13] Batch [620]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.120417,	
2017-06-19 20:59:07,223 Epoch[13] Batch [630]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.120386,	
2017-06-19 20:59:11,908 Epoch[13] Batch [640]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.120232,	
2017-06-19 20:59:16,475 Epoch[13] Batch [650]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.120144,	
2017-06-19 20:59:21,007 Epoch[13] Batch [660]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.120223,	
2017-06-19 20:59:25,581 Epoch[13] Batch [670]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.120185,	
2017-06-19 20:59:29,863 Epoch[13] Batch [680]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.120132,	
2017-06-19 20:59:34,625 Epoch[13] Batch [690]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.120156,	
2017-06-19 20:59:39,528 Epoch[13] Batch [700]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.120108,	
2017-06-19 20:59:44,209 Epoch[13] Batch [710]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.120055,	
2017-06-19 20:59:48,873 Epoch[13] Batch [720]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.120093,	
2017-06-19 20:59:53,156 Epoch[13] Batch [730]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.120120,	
2017-06-19 20:59:57,287 Epoch[13] Batch [740]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.120010,	
2017-06-19 21:00:01,249 Epoch[13] Batch [750]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.119957,	
2017-06-19 21:00:05,395 Epoch[13] Batch [760]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.120051,	
2017-06-19 21:00:09,553 Epoch[13] Batch [770]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.120170,	
2017-06-19 21:00:13,921 Epoch[13] Batch [780]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.120334,	
2017-06-19 21:00:17,881 Epoch[13] Batch [790]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.120425,	
2017-06-19 21:00:22,090 Epoch[13] Batch [800]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.120355,	
2017-06-19 21:00:26,056 Epoch[13] Batch [810]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.120603,	
2017-06-19 21:00:30,077 Epoch[13] Batch [820]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.120674,	
2017-06-19 21:00:34,110 Epoch[13] Batch [830]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.120614,	
2017-06-19 21:00:38,167 Epoch[13] Batch [840]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.120493,	
2017-06-19 21:00:42,178 Epoch[13] Batch [850]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.120349,	
2017-06-19 21:00:46,413 Epoch[13] Batch [860]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.120243,	
2017-06-19 21:00:50,543 Epoch[13] Batch [870]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.120262,	
2017-06-19 21:00:55,233 Epoch[13] Batch [880]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.120175,	
2017-06-19 21:00:59,843 Epoch[13] Batch [890]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.120068,	
2017-06-19 21:01:04,424 Epoch[13] Batch [900]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.120062,	
2017-06-19 21:01:08,995 Epoch[13] Batch [910]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.119899,	
2017-06-19 21:01:13,434 Epoch[13] Batch [920]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.119912,	
2017-06-19 21:01:17,809 Epoch[13] Batch [930]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.120095,	
2017-06-19 21:01:22,395 Epoch[13] Batch [940]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.119985,	
2017-06-19 21:01:26,910 Epoch[13] Batch [950]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.119932,	
2017-06-19 21:01:31,683 Epoch[13] Batch [960]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.119935,	
2017-06-19 21:01:36,411 Epoch[13] Batch [970]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.119837,	
2017-06-19 21:01:40,864 Epoch[13] Batch [980]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.119786,	
2017-06-19 21:01:45,378 Epoch[13] Batch [990]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.119740,	
2017-06-19 21:01:49,944 Epoch[13] Batch [1000]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.119676,	
2017-06-19 21:01:54,646 Epoch[13] Batch [1010]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.119868,	
2017-06-19 21:01:59,375 Epoch[13] Batch [1020]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.119860,	
2017-06-19 21:02:04,012 Epoch[13] Batch [1030]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.119880,	
2017-06-19 21:02:08,607 Epoch[13] Batch [1040]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.119733,	
2017-06-19 21:02:13,024 Epoch[13] Batch [1050]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.119889,	
2017-06-19 21:02:17,616 Epoch[13] Batch [1060]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.119824,	
2017-06-19 21:02:22,207 Epoch[13] Batch [1070]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.119792,	
2017-06-19 21:02:26,906 Epoch[13] Batch [1080]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.119876,	
2017-06-19 21:02:31,346 Epoch[13] Batch [1090]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.119962,	
2017-06-19 21:02:35,908 Epoch[13] Batch [1100]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.120145,	
2017-06-19 21:02:41,015 Epoch[13] Batch [1110]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.120078,	
2017-06-19 21:02:45,511 Epoch[13] Batch [1120]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.120093,	
2017-06-19 21:02:49,991 Epoch[13] Batch [1130]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.120147,	
2017-06-19 21:02:54,820 Epoch[13] Batch [1140]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.120170,	
2017-06-19 21:02:59,233 Epoch[13] Batch [1150]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.120103,	
2017-06-19 21:03:03,717 Epoch[13] Batch [1160]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.120221,	
2017-06-19 21:03:08,175 Epoch[13] Batch [1170]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.120200,	
2017-06-19 21:03:12,456 Epoch[13] Batch [1180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.120180,	
2017-06-19 21:03:16,560 Epoch[13] Batch [1190]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.120246,	
2017-06-19 21:03:20,830 Epoch[13] Batch [1200]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.120312,	
2017-06-19 21:03:25,033 Epoch[13] Batch [1210]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.120224,	
2017-06-19 21:03:29,285 Epoch[13] Batch [1220]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.120391,	
2017-06-19 21:03:33,410 Epoch[13] Batch [1230]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.120391,	
2017-06-19 21:03:37,427 Epoch[13] Batch [1240]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.121689,	
2017-06-19 21:03:41,751 Epoch[13] Batch [1250]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.122406,	
2017-06-19 21:03:46,124 Epoch[13] Batch [1260]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.122769,	
2017-06-19 21:03:50,639 Epoch[13] Batch [1270]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.122880,	
2017-06-19 21:03:55,058 Epoch[13] Batch [1280]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.123021,	
2017-06-19 21:03:59,298 Epoch[13] Batch [1290]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.123374,	
2017-06-19 21:04:03,475 Epoch[13] Batch [1300]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.123789,	
2017-06-19 21:04:07,617 Epoch[13] Batch [1310]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.123862,	
2017-06-19 21:04:11,679 Epoch[13] Batch [1320]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.123871,	
2017-06-19 21:04:15,797 Epoch[13] Batch [1330]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.123997,	
2017-06-19 21:04:19,778 Epoch[13] Batch [1340]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.124113,	
2017-06-19 21:04:24,384 Epoch[13] Batch [1350]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.124283,	
2017-06-19 21:04:28,825 Epoch[13] Batch [1360]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.124427,	
2017-06-19 21:04:33,102 Epoch[13] Batch [1370]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.124514,	
2017-06-19 21:04:37,631 Epoch[13] Batch [1380]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.124473,	
2017-06-19 21:04:42,077 Epoch[13] Batch [1390]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.124570,	
2017-06-19 21:04:46,639 Epoch[13] Batch [1400]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.124524,	
2017-06-19 21:04:51,439 Epoch[13] Batch [1410]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.124589,	
2017-06-19 21:04:55,760 Epoch[13] Batch [1420]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.124680,	
2017-06-19 21:05:00,532 Epoch[13] Batch [1430]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.124742,	
2017-06-19 21:05:04,943 Epoch[13] Batch [1440]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.124804,	
2017-06-19 21:05:09,415 Epoch[13] Batch [1450]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.124790,	
2017-06-19 21:05:14,175 Epoch[13] Batch [1460]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.124845,	
2017-06-19 21:05:19,046 Epoch[13] Batch [1470]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.124807,	
2017-06-19 21:05:23,715 Epoch[13] Batch [1480]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.124920,	
2017-06-19 21:05:26,591 Epoch[13] Train-FCNLogLoss=0.124923
2017-06-19 21:05:26,591 Epoch[13] Time cost=661.522
2017-06-19 21:05:27,273 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0014.params"
2017-06-19 21:05:28,691 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0014.states"
2017-06-19 21:05:34,016 Epoch[14] Batch [10]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.129080,	
2017-06-19 21:05:38,432 Epoch[14] Batch [20]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.121722,	
2017-06-19 21:05:42,768 Epoch[14] Batch [30]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.119041,	
2017-06-19 21:05:46,862 Epoch[14] Batch [40]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.121380,	
2017-06-19 21:05:51,048 Epoch[14] Batch [50]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.119991,	
2017-06-19 21:05:55,262 Epoch[14] Batch [60]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.122846,	
2017-06-19 21:05:59,412 Epoch[14] Batch [70]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.123853,	
2017-06-19 21:06:03,785 Epoch[14] Batch [80]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.124527,	
2017-06-19 21:06:07,816 Epoch[14] Batch [90]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.122539,	
2017-06-19 21:06:12,223 Epoch[14] Batch [100]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.123162,	
2017-06-19 21:06:16,840 Epoch[14] Batch [110]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.125629,	
2017-06-19 21:06:21,354 Epoch[14] Batch [120]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.125185,	
2017-06-19 21:06:25,786 Epoch[14] Batch [130]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.124854,	
2017-06-19 21:06:30,787 Epoch[14] Batch [140]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.125877,	
2017-06-19 21:06:35,391 Epoch[14] Batch [150]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.125316,	
2017-06-19 21:06:40,198 Epoch[14] Batch [160]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.126024,	
2017-06-19 21:06:44,662 Epoch[14] Batch [170]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.125560,	
2017-06-19 21:06:48,912 Epoch[14] Batch [180]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.124751,	
2017-06-19 21:06:53,113 Epoch[14] Batch [190]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.124143,	
2017-06-19 21:06:57,398 Epoch[14] Batch [200]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.124262,	
2017-06-19 21:07:01,661 Epoch[14] Batch [210]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.124386,	
2017-06-19 21:07:06,166 Epoch[14] Batch [220]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.124088,	
2017-06-19 21:07:10,146 Epoch[14] Batch [230]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.124037,	
2017-06-19 21:07:14,693 Epoch[14] Batch [240]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.123619,	
2017-06-19 21:07:19,583 Epoch[14] Batch [250]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.123981,	
2017-06-19 21:07:24,248 Epoch[14] Batch [260]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.123975,	
2017-06-19 21:07:28,897 Epoch[14] Batch [270]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.124103,	
2017-06-19 21:07:33,498 Epoch[14] Batch [280]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.124257,	
2017-06-19 21:07:38,266 Epoch[14] Batch [290]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.124072,	
2017-06-19 21:07:43,023 Epoch[14] Batch [300]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.124142,	
2017-06-19 21:07:47,797 Epoch[14] Batch [310]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.124453,	
2017-06-19 21:07:52,236 Epoch[14] Batch [320]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.124789,	
2017-06-19 21:07:56,643 Epoch[14] Batch [330]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.124685,	
2017-06-19 21:08:01,119 Epoch[14] Batch [340]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.125481,	
2017-06-19 21:08:05,308 Epoch[14] Batch [350]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.125561,	
2017-06-19 21:08:09,477 Epoch[14] Batch [360]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.125702,	
2017-06-19 21:08:13,630 Epoch[14] Batch [370]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.125742,	
2017-06-19 21:08:18,727 Epoch[14] Batch [380]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.125752,	
2017-06-19 21:08:23,583 Epoch[14] Batch [390]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.125793,	
2017-06-19 21:08:28,607 Epoch[14] Batch [400]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.125470,	
2017-06-19 21:08:33,013 Epoch[14] Batch [410]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.125388,	
2017-06-19 21:08:38,054 Epoch[14] Batch [420]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.124779,	
2017-06-19 21:08:42,847 Epoch[14] Batch [430]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.124500,	
2017-06-19 21:08:47,378 Epoch[14] Batch [440]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.124504,	
2017-06-19 21:08:52,024 Epoch[14] Batch [450]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.124231,	
2017-06-19 21:08:57,074 Epoch[14] Batch [460]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.124526,	
2017-06-19 21:09:02,173 Epoch[14] Batch [470]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.124322,	
2017-06-19 21:09:07,063 Epoch[14] Batch [480]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.124378,	
2017-06-19 21:09:11,495 Epoch[14] Batch [490]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.124144,	
2017-06-19 21:09:16,274 Epoch[14] Batch [500]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.124009,	
2017-06-19 21:09:20,913 Epoch[14] Batch [510]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.123851,	
2017-06-19 21:09:25,702 Epoch[14] Batch [520]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.123807,	
2017-06-19 21:09:30,702 Epoch[14] Batch [530]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.123949,	
2017-06-19 21:09:35,710 Epoch[14] Batch [540]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.124111,	
2017-06-19 21:09:40,481 Epoch[14] Batch [550]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.124117,	
2017-06-19 21:09:45,434 Epoch[14] Batch [560]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.126851,	
2017-06-19 21:09:50,036 Epoch[14] Batch [570]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.127389,	
2017-06-19 21:09:55,135 Epoch[14] Batch [580]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.127608,	
2017-06-19 21:10:00,119 Epoch[14] Batch [590]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.127719,	
2017-06-19 21:10:04,588 Epoch[14] Batch [600]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.127909,	
2017-06-19 21:10:09,341 Epoch[14] Batch [610]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.127928,	
2017-06-19 21:10:14,181 Epoch[14] Batch [620]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.127921,	
2017-06-19 21:10:19,253 Epoch[14] Batch [630]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.127957,	
2017-06-19 21:10:24,250 Epoch[14] Batch [640]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.127787,	
2017-06-19 21:10:28,456 Epoch[14] Batch [650]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.127833,	
2017-06-19 21:10:32,782 Epoch[14] Batch [660]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.127657,	
2017-06-19 21:10:36,753 Epoch[14] Batch [670]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.127658,	
2017-06-19 21:10:41,025 Epoch[14] Batch [680]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.127660,	
2017-06-19 21:10:45,488 Epoch[14] Batch [690]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.128195,	
2017-06-19 21:10:49,939 Epoch[14] Batch [700]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.128443,	
2017-06-19 21:10:54,574 Epoch[14] Batch [710]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.128645,	
2017-06-19 21:10:59,319 Epoch[14] Batch [720]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.128695,	
2017-06-19 21:11:03,731 Epoch[14] Batch [730]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.128646,	
2017-06-19 21:11:08,206 Epoch[14] Batch [740]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.128696,	
2017-06-19 21:11:12,999 Epoch[14] Batch [750]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.128641,	
2017-06-19 21:11:17,518 Epoch[14] Batch [760]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.128416,	
2017-06-19 21:11:21,974 Epoch[14] Batch [770]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.128639,	
2017-06-19 21:11:26,806 Epoch[14] Batch [780]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.128450,	
2017-06-19 21:11:31,255 Epoch[14] Batch [790]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.128452,	
2017-06-19 21:11:35,740 Epoch[14] Batch [800]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.128442,	
2017-06-19 21:11:40,503 Epoch[14] Batch [810]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.128418,	
2017-06-19 21:11:45,248 Epoch[14] Batch [820]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.128303,	
2017-06-19 21:11:49,885 Epoch[14] Batch [830]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.128014,	
2017-06-19 21:11:54,675 Epoch[14] Batch [840]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.127916,	
2017-06-19 21:11:59,239 Epoch[14] Batch [850]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.127889,	
2017-06-19 21:12:03,721 Epoch[14] Batch [860]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.128207,	
2017-06-19 21:12:08,544 Epoch[14] Batch [870]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.128414,	
2017-06-19 21:12:13,451 Epoch[14] Batch [880]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.128418,	
2017-06-19 21:12:18,055 Epoch[14] Batch [890]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.128456,	
2017-06-19 21:12:22,807 Epoch[14] Batch [900]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.128870,	
2017-06-19 21:12:27,337 Epoch[14] Batch [910]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.129182,	
2017-06-19 21:12:32,043 Epoch[14] Batch [920]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.129131,	
2017-06-19 21:12:36,673 Epoch[14] Batch [930]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.128992,	
2017-06-19 21:12:41,305 Epoch[14] Batch [940]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.129003,	
2017-06-19 21:12:46,057 Epoch[14] Batch [950]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.129072,	
2017-06-19 21:12:50,784 Epoch[14] Batch [960]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.129067,	
2017-06-19 21:12:55,459 Epoch[14] Batch [970]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.129110,	
2017-06-19 21:13:00,309 Epoch[14] Batch [980]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.129096,	
2017-06-19 21:13:05,057 Epoch[14] Batch [990]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.129040,	
2017-06-19 21:13:09,851 Epoch[14] Batch [1000]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.128911,	
2017-06-19 21:13:14,841 Epoch[14] Batch [1010]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.129217,	
2017-06-19 21:13:19,347 Epoch[14] Batch [1020]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.129350,	
2017-06-19 21:13:24,128 Epoch[14] Batch [1030]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.129272,	
2017-06-19 21:13:28,898 Epoch[14] Batch [1040]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.129398,	
2017-06-19 21:13:33,627 Epoch[14] Batch [1050]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.129256,	
2017-06-19 21:13:38,270 Epoch[14] Batch [1060]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.129101,	
2017-06-19 21:13:42,760 Epoch[14] Batch [1070]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.129051,	
2017-06-19 21:13:47,468 Epoch[14] Batch [1080]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.128988,	
2017-06-19 21:13:52,077 Epoch[14] Batch [1090]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.128935,	
2017-06-19 21:13:56,578 Epoch[14] Batch [1100]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.128809,	
2017-06-19 21:14:01,335 Epoch[14] Batch [1110]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.128700,	
2017-06-19 21:14:05,697 Epoch[14] Batch [1120]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.128677,	
2017-06-19 21:14:10,126 Epoch[14] Batch [1130]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.128636,	
2017-06-19 21:14:14,382 Epoch[14] Batch [1140]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.128502,	
2017-06-19 21:14:19,053 Epoch[14] Batch [1150]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.128434,	
2017-06-19 21:14:23,758 Epoch[14] Batch [1160]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.128202,	
2017-06-19 21:14:28,494 Epoch[14] Batch [1170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.128246,	
2017-06-19 21:14:33,171 Epoch[14] Batch [1180]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.128191,	
2017-06-19 21:14:37,789 Epoch[14] Batch [1190]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.128067,	
2017-06-19 21:14:42,264 Epoch[14] Batch [1200]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.127979,	
2017-06-19 21:14:46,752 Epoch[14] Batch [1210]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.127956,	
2017-06-19 21:14:51,316 Epoch[14] Batch [1220]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.127885,	
2017-06-19 21:14:55,792 Epoch[14] Batch [1230]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.127689,	
2017-06-19 21:15:00,038 Epoch[14] Batch [1240]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.127690,	
2017-06-19 21:15:04,132 Epoch[14] Batch [1250]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.127630,	
2017-06-19 21:15:08,505 Epoch[14] Batch [1260]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.127547,	
2017-06-19 21:15:12,912 Epoch[14] Batch [1270]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.127460,	
2017-06-19 21:15:16,946 Epoch[14] Batch [1280]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.127443,	
2017-06-19 21:15:21,761 Epoch[14] Batch [1290]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.127406,	
2017-06-19 21:15:26,399 Epoch[14] Batch [1300]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.127318,	
2017-06-19 21:15:30,949 Epoch[14] Batch [1310]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.127239,	
2017-06-19 21:15:35,865 Epoch[14] Batch [1320]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.127171,	
2017-06-19 21:15:40,359 Epoch[14] Batch [1330]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.127102,	
2017-06-19 21:15:44,948 Epoch[14] Batch [1340]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.127024,	
2017-06-19 21:15:49,146 Epoch[14] Batch [1350]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.126859,	
2017-06-19 21:15:53,808 Epoch[14] Batch [1360]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.126703,	
2017-06-19 21:15:58,534 Epoch[14] Batch [1370]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.126623,	
2017-06-19 21:16:03,167 Epoch[14] Batch [1380]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.126630,	
2017-06-19 21:16:07,775 Epoch[14] Batch [1390]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.126627,	
2017-06-19 21:16:12,355 Epoch[14] Batch [1400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.126581,	
2017-06-19 21:16:17,084 Epoch[14] Batch [1410]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.126623,	
2017-06-19 21:16:21,494 Epoch[14] Batch [1420]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.126536,	
2017-06-19 21:16:25,768 Epoch[14] Batch [1430]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.126401,	
2017-06-19 21:16:30,009 Epoch[14] Batch [1440]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.126355,	
2017-06-19 21:16:34,154 Epoch[14] Batch [1450]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.126317,	
2017-06-19 21:16:38,289 Epoch[14] Batch [1460]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.126218,	
2017-06-19 21:16:42,385 Epoch[14] Batch [1470]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.126187,	
2017-06-19 21:16:46,653 Epoch[14] Batch [1480]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.126141,	
2017-06-19 21:16:49,178 Epoch[14] Train-FCNLogLoss=0.126072
2017-06-19 21:16:49,178 Epoch[14] Time cost=680.486
2017-06-19 21:16:49,848 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0015.params"
2017-06-19 21:16:51,277 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0015.states"
2017-06-19 21:16:56,278 Epoch[15] Batch [10]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.108214,	
2017-06-19 21:17:00,362 Epoch[15] Batch [20]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110729,	
2017-06-19 21:17:04,654 Epoch[15] Batch [30]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.111780,	
2017-06-19 21:17:08,836 Epoch[15] Batch [40]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112890,	
2017-06-19 21:17:13,095 Epoch[15] Batch [50]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.110533,	
2017-06-19 21:17:17,374 Epoch[15] Batch [60]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.111356,	
2017-06-19 21:17:21,398 Epoch[15] Batch [70]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.113888,	
2017-06-19 21:17:26,107 Epoch[15] Batch [80]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.115099,	
2017-06-19 21:17:30,716 Epoch[15] Batch [90]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.115874,	
2017-06-19 21:17:35,272 Epoch[15] Batch [100]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.115931,	
2017-06-19 21:17:39,928 Epoch[15] Batch [110]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.116213,	
2017-06-19 21:17:44,633 Epoch[15] Batch [120]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.117321,	
2017-06-19 21:17:49,764 Epoch[15] Batch [130]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.116951,	
2017-06-19 21:17:54,293 Epoch[15] Batch [140]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.117189,	
2017-06-19 21:17:58,904 Epoch[15] Batch [150]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.117471,	
2017-06-19 21:18:03,667 Epoch[15] Batch [160]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.117177,	
2017-06-19 21:18:07,844 Epoch[15] Batch [170]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117646,	
2017-06-19 21:18:11,989 Epoch[15] Batch [180]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.117950,	
2017-06-19 21:18:16,164 Epoch[15] Batch [190]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.118278,	
2017-06-19 21:18:20,508 Epoch[15] Batch [200]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.117613,	
2017-06-19 21:18:24,507 Epoch[15] Batch [210]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.117379,	
2017-06-19 21:18:29,185 Epoch[15] Batch [220]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.117569,	
2017-06-19 21:18:33,794 Epoch[15] Batch [230]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.117083,	
2017-06-19 21:18:38,601 Epoch[15] Batch [240]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.116827,	
2017-06-19 21:18:43,095 Epoch[15] Batch [250]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.118012,	
2017-06-19 21:18:47,774 Epoch[15] Batch [260]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.118159,	
2017-06-19 21:18:52,186 Epoch[15] Batch [270]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.118489,	
2017-06-19 21:18:56,726 Epoch[15] Batch [280]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.118442,	
2017-06-19 21:19:01,634 Epoch[15] Batch [290]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.118311,	
2017-06-19 21:19:06,607 Epoch[15] Batch [300]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.118060,	
2017-06-19 21:19:11,189 Epoch[15] Batch [310]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.118178,	
2017-06-19 21:19:15,751 Epoch[15] Batch [320]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.118249,	
2017-06-19 21:19:20,629 Epoch[15] Batch [330]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.119337,	
2017-06-19 21:19:25,183 Epoch[15] Batch [340]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121417,	
2017-06-19 21:19:29,809 Epoch[15] Batch [350]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.122535,	
2017-06-19 21:19:34,332 Epoch[15] Batch [360]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.122620,	
2017-06-19 21:19:38,867 Epoch[15] Batch [370]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.123211,	
2017-06-19 21:19:43,924 Epoch[15] Batch [380]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.123566,	
2017-06-19 21:19:48,818 Epoch[15] Batch [390]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.123581,	
2017-06-19 21:19:53,360 Epoch[15] Batch [400]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.124004,	
2017-06-19 21:19:57,833 Epoch[15] Batch [410]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.123948,	
2017-06-19 21:20:02,449 Epoch[15] Batch [420]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.124137,	
2017-06-19 21:20:07,152 Epoch[15] Batch [430]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.124076,	
2017-06-19 21:20:11,787 Epoch[15] Batch [440]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.124451,	
2017-06-19 21:20:16,514 Epoch[15] Batch [450]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.124431,	
2017-06-19 21:20:21,257 Epoch[15] Batch [460]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.124501,	
2017-06-19 21:20:25,839 Epoch[15] Batch [470]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.124578,	
2017-06-19 21:20:30,649 Epoch[15] Batch [480]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.124572,	
2017-06-19 21:20:35,303 Epoch[15] Batch [490]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.124615,	
2017-06-19 21:20:39,995 Epoch[15] Batch [500]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.124516,	
2017-06-19 21:20:44,487 Epoch[15] Batch [510]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.124556,	
2017-06-19 21:20:49,293 Epoch[15] Batch [520]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.124636,	
2017-06-19 21:20:53,930 Epoch[15] Batch [530]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.124637,	
2017-06-19 21:20:58,418 Epoch[15] Batch [540]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.124465,	
2017-06-19 21:21:03,259 Epoch[15] Batch [550]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.124703,	
2017-06-19 21:21:08,104 Epoch[15] Batch [560]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.124474,	
2017-06-19 21:21:12,763 Epoch[15] Batch [570]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.124566,	
2017-06-19 21:21:17,444 Epoch[15] Batch [580]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.124396,	
2017-06-19 21:21:22,029 Epoch[15] Batch [590]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.124460,	
2017-06-19 21:21:26,498 Epoch[15] Batch [600]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.124623,	
2017-06-19 21:21:31,260 Epoch[15] Batch [610]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.124728,	
2017-06-19 21:21:35,722 Epoch[15] Batch [620]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.124554,	
2017-06-19 21:21:40,346 Epoch[15] Batch [630]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.124313,	
2017-06-19 21:21:45,232 Epoch[15] Batch [640]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.124221,	
2017-06-19 21:21:49,755 Epoch[15] Batch [650]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.124189,	
2017-06-19 21:21:54,141 Epoch[15] Batch [660]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.123952,	
2017-06-19 21:21:58,951 Epoch[15] Batch [670]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.123798,	
2017-06-19 21:22:03,406 Epoch[15] Batch [680]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.123673,	
2017-06-19 21:22:08,391 Epoch[15] Batch [690]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.123795,	
2017-06-19 21:22:13,059 Epoch[15] Batch [700]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.123660,	
2017-06-19 21:22:17,939 Epoch[15] Batch [710]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.123693,	
2017-06-19 21:22:22,681 Epoch[15] Batch [720]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.123573,	
2017-06-19 21:22:27,415 Epoch[15] Batch [730]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.123303,	
2017-06-19 21:22:31,837 Epoch[15] Batch [740]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.123149,	
2017-06-19 21:22:35,890 Epoch[15] Batch [750]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.123050,	
2017-06-19 21:22:40,008 Epoch[15] Batch [760]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.123009,	
2017-06-19 21:22:44,321 Epoch[15] Batch [770]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.122848,	
2017-06-19 21:22:48,609 Epoch[15] Batch [780]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.122710,	
2017-06-19 21:22:53,138 Epoch[15] Batch [790]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.122569,	
2017-06-19 21:22:57,500 Epoch[15] Batch [800]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.122586,	
2017-06-19 21:23:01,786 Epoch[15] Batch [810]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.122542,	
2017-06-19 21:23:06,494 Epoch[15] Batch [820]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.122482,	
2017-06-19 21:23:10,954 Epoch[15] Batch [830]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.122427,	
2017-06-19 21:23:15,598 Epoch[15] Batch [840]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.122304,	
2017-06-19 21:23:20,199 Epoch[15] Batch [850]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.122331,	
2017-06-19 21:23:24,928 Epoch[15] Batch [860]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.122183,	
2017-06-19 21:23:29,849 Epoch[15] Batch [870]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.122138,	
2017-06-19 21:23:34,893 Epoch[15] Batch [880]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.122056,	
2017-06-19 21:23:39,230 Epoch[15] Batch [890]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.122072,	
2017-06-19 21:23:43,677 Epoch[15] Batch [900]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.121929,	
2017-06-19 21:23:47,890 Epoch[15] Batch [910]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.121946,	
2017-06-19 21:23:52,177 Epoch[15] Batch [920]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.121892,	
2017-06-19 21:23:56,465 Epoch[15] Batch [930]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.121979,	
2017-06-19 21:24:00,890 Epoch[15] Batch [940]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.122028,	
2017-06-19 21:24:05,154 Epoch[15] Batch [950]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.121911,	
2017-06-19 21:24:09,291 Epoch[15] Batch [960]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.121835,	
2017-06-19 21:24:13,492 Epoch[15] Batch [970]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.121569,	
2017-06-19 21:24:17,681 Epoch[15] Batch [980]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.121428,	
2017-06-19 21:24:22,259 Epoch[15] Batch [990]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.121459,	
2017-06-19 21:24:27,252 Epoch[15] Batch [1000]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.121538,	
2017-06-19 21:24:31,993 Epoch[15] Batch [1010]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.121523,	
2017-06-19 21:24:36,720 Epoch[15] Batch [1020]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.121419,	
2017-06-19 21:24:41,450 Epoch[15] Batch [1030]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.121381,	
2017-06-19 21:24:46,415 Epoch[15] Batch [1040]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.121476,	
2017-06-19 21:24:51,280 Epoch[15] Batch [1050]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.121434,	
2017-06-19 21:24:55,992 Epoch[15] Batch [1060]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.121388,	
2017-06-19 21:25:00,415 Epoch[15] Batch [1070]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.121390,	
2017-06-19 21:25:05,087 Epoch[15] Batch [1080]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121345,	
2017-06-19 21:25:09,455 Epoch[15] Batch [1090]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.121402,	
2017-06-19 21:25:13,668 Epoch[15] Batch [1100]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.121415,	
2017-06-19 21:25:18,197 Epoch[15] Batch [1110]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.121405,	
2017-06-19 21:25:22,438 Epoch[15] Batch [1120]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.121433,	
2017-06-19 21:25:26,923 Epoch[15] Batch [1130]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.121515,	
2017-06-19 21:25:31,136 Epoch[15] Batch [1140]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.121515,	
2017-06-19 21:25:35,971 Epoch[15] Batch [1150]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.121377,	
2017-06-19 21:25:40,734 Epoch[15] Batch [1160]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.121614,	
2017-06-19 21:25:45,452 Epoch[15] Batch [1170]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.121615,	
2017-06-19 21:25:50,462 Epoch[15] Batch [1180]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.121714,	
2017-06-19 21:25:55,163 Epoch[15] Batch [1190]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.121626,	
2017-06-19 21:25:59,974 Epoch[15] Batch [1200]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.121634,	
2017-06-19 21:26:04,588 Epoch[15] Batch [1210]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.121516,	
2017-06-19 21:26:09,140 Epoch[15] Batch [1220]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121598,	
2017-06-19 21:26:13,247 Epoch[15] Batch [1230]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.121567,	
2017-06-19 21:26:17,436 Epoch[15] Batch [1240]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.121519,	
2017-06-19 21:26:21,764 Epoch[15] Batch [1250]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.121444,	
2017-06-19 21:26:26,063 Epoch[15] Batch [1260]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.121521,	
2017-06-19 21:26:30,308 Epoch[15] Batch [1270]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.121412,	
2017-06-19 21:26:34,461 Epoch[15] Batch [1280]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.121397,	
2017-06-19 21:26:39,175 Epoch[15] Batch [1290]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.121489,	
2017-06-19 21:26:44,059 Epoch[15] Batch [1300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.121615,	
2017-06-19 21:26:48,842 Epoch[15] Batch [1310]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.121650,	
2017-06-19 21:26:53,604 Epoch[15] Batch [1320]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.121560,	
2017-06-19 21:26:58,330 Epoch[15] Batch [1330]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.121460,	
2017-06-19 21:27:03,038 Epoch[15] Batch [1340]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.121457,	
2017-06-19 21:27:07,529 Epoch[15] Batch [1350]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.121529,	
2017-06-19 21:27:11,936 Epoch[15] Batch [1360]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.121445,	
2017-06-19 21:27:16,318 Epoch[15] Batch [1370]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.121363,	
2017-06-19 21:27:20,747 Epoch[15] Batch [1380]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.121573,	
2017-06-19 21:27:24,987 Epoch[15] Batch [1390]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.121476,	
2017-06-19 21:27:29,608 Epoch[15] Batch [1400]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.121446,	
2017-06-19 21:27:33,682 Epoch[15] Batch [1410]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.121389,	
2017-06-19 21:27:38,127 Epoch[15] Batch [1420]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.121294,	
2017-06-19 21:27:42,940 Epoch[15] Batch [1430]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.121202,	
2017-06-19 21:27:47,593 Epoch[15] Batch [1440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.121146,	
2017-06-19 21:27:52,143 Epoch[15] Batch [1450]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121048,	
2017-06-19 21:27:56,767 Epoch[15] Batch [1460]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.121037,	
2017-06-19 21:28:01,524 Epoch[15] Batch [1470]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.121018,	
2017-06-19 21:28:06,425 Epoch[15] Batch [1480]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.121047,	
2017-06-19 21:28:09,164 Epoch[15] Train-FCNLogLoss=0.121046
2017-06-19 21:28:09,164 Epoch[15] Time cost=677.886
2017-06-19 21:28:09,897 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0016.params"
2017-06-19 21:28:11,526 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0016.states"
2017-06-19 21:28:16,857 Epoch[16] Batch [10]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.117210,	
2017-06-19 21:28:21,154 Epoch[16] Batch [20]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.117188,	
2017-06-19 21:28:26,058 Epoch[16] Batch [30]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.122846,	
2017-06-19 21:28:30,423 Epoch[16] Batch [40]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.119228,	
2017-06-19 21:28:34,781 Epoch[16] Batch [50]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.119879,	
2017-06-19 21:28:39,225 Epoch[16] Batch [60]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.119330,	
2017-06-19 21:28:44,294 Epoch[16] Batch [70]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.118176,	
2017-06-19 21:28:48,908 Epoch[16] Batch [80]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.117116,	
2017-06-19 21:28:54,082 Epoch[16] Batch [90]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.116642,	
2017-06-19 21:28:58,958 Epoch[16] Batch [100]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.115609,	
2017-06-19 21:29:03,761 Epoch[16] Batch [110]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.116233,	
2017-06-19 21:29:08,240 Epoch[16] Batch [120]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.116602,	
2017-06-19 21:29:12,946 Epoch[16] Batch [130]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.115744,	
2017-06-19 21:29:17,919 Epoch[16] Batch [140]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.115365,	
2017-06-19 21:29:22,643 Epoch[16] Batch [150]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.114716,	
2017-06-19 21:29:27,336 Epoch[16] Batch [160]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.113995,	
2017-06-19 21:29:32,345 Epoch[16] Batch [170]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.114190,	
2017-06-19 21:29:36,971 Epoch[16] Batch [180]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.113742,	
2017-06-19 21:29:41,961 Epoch[16] Batch [190]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.113129,	
2017-06-19 21:29:46,739 Epoch[16] Batch [200]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.112698,	
2017-06-19 21:29:51,544 Epoch[16] Batch [210]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.114035,	
2017-06-19 21:29:56,195 Epoch[16] Batch [220]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.114547,	
2017-06-19 21:30:01,267 Epoch[16] Batch [230]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.115465,	
2017-06-19 21:30:06,018 Epoch[16] Batch [240]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.115918,	
2017-06-19 21:30:10,870 Epoch[16] Batch [250]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.115710,	
2017-06-19 21:30:15,162 Epoch[16] Batch [260]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.115706,	
2017-06-19 21:30:19,896 Epoch[16] Batch [270]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.115673,	
2017-06-19 21:30:24,892 Epoch[16] Batch [280]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.115136,	
2017-06-19 21:30:29,673 Epoch[16] Batch [290]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.115313,	
2017-06-19 21:30:34,442 Epoch[16] Batch [300]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.116193,	
2017-06-19 21:30:39,177 Epoch[16] Batch [310]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.116869,	
2017-06-19 21:30:44,173 Epoch[16] Batch [320]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.117259,	
2017-06-19 21:30:48,840 Epoch[16] Batch [330]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.117533,	
2017-06-19 21:30:53,609 Epoch[16] Batch [340]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.117752,	
2017-06-19 21:30:58,284 Epoch[16] Batch [350]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.117663,	
2017-06-19 21:31:03,092 Epoch[16] Batch [360]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.118057,	
2017-06-19 21:31:07,745 Epoch[16] Batch [370]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.117590,	
2017-06-19 21:31:12,732 Epoch[16] Batch [380]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.117620,	
2017-06-19 21:31:17,552 Epoch[16] Batch [390]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.117591,	
2017-06-19 21:31:22,423 Epoch[16] Batch [400]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.117735,	
2017-06-19 21:31:27,329 Epoch[16] Batch [410]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.118240,	
2017-06-19 21:31:32,008 Epoch[16] Batch [420]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.118426,	
2017-06-19 21:31:36,687 Epoch[16] Batch [430]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.118574,	
2017-06-19 21:31:41,582 Epoch[16] Batch [440]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.118676,	
2017-06-19 21:31:46,018 Epoch[16] Batch [450]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.118407,	
2017-06-19 21:31:50,802 Epoch[16] Batch [460]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.118480,	
2017-06-19 21:31:55,487 Epoch[16] Batch [470]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.118694,	
2017-06-19 21:32:00,075 Epoch[16] Batch [480]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.118465,	
2017-06-19 21:32:04,377 Epoch[16] Batch [490]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.118367,	
2017-06-19 21:32:08,592 Epoch[16] Batch [500]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.118147,	
2017-06-19 21:32:12,804 Epoch[16] Batch [510]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.117920,	
2017-06-19 21:32:16,877 Epoch[16] Batch [520]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117613,	
2017-06-19 21:32:21,444 Epoch[16] Batch [530]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.117578,	
2017-06-19 21:32:26,331 Epoch[16] Batch [540]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.117242,	
2017-06-19 21:32:31,094 Epoch[16] Batch [550]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.117102,	
2017-06-19 21:32:35,877 Epoch[16] Batch [560]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.116930,	
2017-06-19 21:32:40,079 Epoch[16] Batch [570]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.116761,	
2017-06-19 21:32:44,764 Epoch[16] Batch [580]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.116726,	
2017-06-19 21:32:49,327 Epoch[16] Batch [590]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.116634,	
2017-06-19 21:32:53,789 Epoch[16] Batch [600]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.116564,	
2017-06-19 21:32:58,147 Epoch[16] Batch [610]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.116788,	
2017-06-19 21:33:02,475 Epoch[16] Batch [620]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.116936,	
2017-06-19 21:33:06,597 Epoch[16] Batch [630]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.116760,	
2017-06-19 21:33:10,727 Epoch[16] Batch [640]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.116573,	
2017-06-19 21:33:14,789 Epoch[16] Batch [650]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116812,	
2017-06-19 21:33:18,913 Epoch[16] Batch [660]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117032,	
2017-06-19 21:33:23,190 Epoch[16] Batch [670]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.116996,	
2017-06-19 21:33:27,459 Epoch[16] Batch [680]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.117098,	
2017-06-19 21:33:32,193 Epoch[16] Batch [690]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.117006,	
2017-06-19 21:33:37,129 Epoch[16] Batch [700]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.116661,	
2017-06-19 21:33:42,151 Epoch[16] Batch [710]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.116511,	
2017-06-19 21:33:46,576 Epoch[16] Batch [720]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.116369,	
2017-06-19 21:33:51,256 Epoch[16] Batch [730]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.116247,	
2017-06-19 21:33:56,554 Epoch[16] Batch [740]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116328,	
2017-06-19 21:34:01,016 Epoch[16] Batch [750]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.116168,	
2017-06-19 21:34:05,489 Epoch[16] Batch [760]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.116081,	
2017-06-19 21:34:09,685 Epoch[16] Batch [770]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.116121,	
2017-06-19 21:34:13,695 Epoch[16] Batch [780]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116021,	
2017-06-19 21:34:17,946 Epoch[16] Batch [790]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.116064,	
2017-06-19 21:34:22,494 Epoch[16] Batch [800]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.116042,	
2017-06-19 21:34:26,658 Epoch[16] Batch [810]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.116211,	
2017-06-19 21:34:31,115 Epoch[16] Batch [820]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.116300,	
2017-06-19 21:34:35,954 Epoch[16] Batch [830]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.116273,	
2017-06-19 21:34:40,930 Epoch[16] Batch [840]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.116216,	
2017-06-19 21:34:45,944 Epoch[16] Batch [850]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.116184,	
2017-06-19 21:34:50,568 Epoch[16] Batch [860]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.116341,	
2017-06-19 21:34:55,512 Epoch[16] Batch [870]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.116356,	
2017-06-19 21:35:00,002 Epoch[16] Batch [880]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.116261,	
2017-06-19 21:35:04,576 Epoch[16] Batch [890]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.116325,	
2017-06-19 21:35:08,955 Epoch[16] Batch [900]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.116317,	
2017-06-19 21:35:12,904 Epoch[16] Batch [910]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.116291,	
2017-06-19 21:35:17,187 Epoch[16] Batch [920]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.116181,	
2017-06-19 21:35:21,276 Epoch[16] Batch [930]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116053,	
2017-06-19 21:35:25,556 Epoch[16] Batch [940]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.116072,	
2017-06-19 21:35:29,969 Epoch[16] Batch [950]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.116005,	
2017-06-19 21:35:34,331 Epoch[16] Batch [960]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.115891,	
2017-06-19 21:35:39,327 Epoch[16] Batch [970]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.115773,	
2017-06-19 21:35:43,999 Epoch[16] Batch [980]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.115756,	
2017-06-19 21:35:48,257 Epoch[16] Batch [990]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.115600,	
2017-06-19 21:35:53,397 Epoch[16] Batch [1000]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.115664,	
2017-06-19 21:35:58,053 Epoch[16] Batch [1010]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.115727,	
2017-06-19 21:36:03,114 Epoch[16] Batch [1020]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.115576,	
2017-06-19 21:36:07,883 Epoch[16] Batch [1030]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.115677,	
2017-06-19 21:36:12,243 Epoch[16] Batch [1040]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.115598,	
2017-06-19 21:36:16,593 Epoch[16] Batch [1050]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.115552,	
2017-06-19 21:36:20,968 Epoch[16] Batch [1060]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.115450,	
2017-06-19 21:36:25,417 Epoch[16] Batch [1070]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.115359,	
2017-06-19 21:36:29,671 Epoch[16] Batch [1080]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.115315,	
2017-06-19 21:36:33,991 Epoch[16] Batch [1090]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.115291,	
2017-06-19 21:36:38,431 Epoch[16] Batch [1100]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.115363,	
2017-06-19 21:36:43,170 Epoch[16] Batch [1110]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.115324,	
2017-06-19 21:36:47,805 Epoch[16] Batch [1120]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.115412,	
2017-06-19 21:36:52,497 Epoch[16] Batch [1130]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.115460,	
2017-06-19 21:36:57,104 Epoch[16] Batch [1140]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.115478,	
2017-06-19 21:37:01,803 Epoch[16] Batch [1150]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.115509,	
2017-06-19 21:37:06,474 Epoch[16] Batch [1160]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.115433,	
2017-06-19 21:37:11,369 Epoch[16] Batch [1170]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.115430,	
2017-06-19 21:37:16,080 Epoch[16] Batch [1180]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.115467,	
2017-06-19 21:37:20,755 Epoch[16] Batch [1190]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.115498,	
2017-06-19 21:37:25,448 Epoch[16] Batch [1200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.115494,	
2017-06-19 21:37:30,245 Epoch[16] Batch [1210]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.115436,	
2017-06-19 21:37:34,611 Epoch[16] Batch [1220]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.115456,	
2017-06-19 21:37:39,398 Epoch[16] Batch [1230]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.115424,	
2017-06-19 21:37:44,344 Epoch[16] Batch [1240]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.115278,	
2017-06-19 21:37:48,866 Epoch[16] Batch [1250]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.115219,	
2017-06-19 21:37:53,176 Epoch[16] Batch [1260]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.115212,	
2017-06-19 21:37:57,526 Epoch[16] Batch [1270]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.115278,	
2017-06-19 21:38:01,780 Epoch[16] Batch [1280]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.115226,	
2017-06-19 21:38:06,059 Epoch[16] Batch [1290]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.115376,	
2017-06-19 21:38:10,092 Epoch[16] Batch [1300]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115417,	
2017-06-19 21:38:14,472 Epoch[16] Batch [1310]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.115415,	
2017-06-19 21:38:18,513 Epoch[16] Batch [1320]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.115343,	
2017-06-19 21:38:22,717 Epoch[16] Batch [1330]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.115408,	
2017-06-19 21:38:27,076 Epoch[16] Batch [1340]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.115458,	
2017-06-19 21:38:31,613 Epoch[16] Batch [1350]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.115435,	
2017-06-19 21:38:35,800 Epoch[16] Batch [1360]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.115384,	
2017-06-19 21:38:39,845 Epoch[16] Batch [1370]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.115514,	
2017-06-19 21:38:44,330 Epoch[16] Batch [1380]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.115707,	
2017-06-19 21:38:48,875 Epoch[16] Batch [1390]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.115832,	
2017-06-19 21:38:53,697 Epoch[16] Batch [1400]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.115893,	
2017-06-19 21:38:58,543 Epoch[16] Batch [1410]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.115898,	
2017-06-19 21:39:03,496 Epoch[16] Batch [1420]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.115896,	
2017-06-19 21:39:08,433 Epoch[16] Batch [1430]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.115917,	
2017-06-19 21:39:13,234 Epoch[16] Batch [1440]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.115922,	
2017-06-19 21:39:17,857 Epoch[16] Batch [1450]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.115998,	
2017-06-19 21:39:22,731 Epoch[16] Batch [1460]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.116027,	
2017-06-19 21:39:27,400 Epoch[16] Batch [1470]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.116084,	
2017-06-19 21:39:32,182 Epoch[16] Batch [1480]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.116046,	
2017-06-19 21:39:35,113 Epoch[16] Train-FCNLogLoss=0.116141
2017-06-19 21:39:35,113 Epoch[16] Time cost=683.586
2017-06-19 21:39:35,754 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0017.params"
2017-06-19 21:39:37,340 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0017.states"
2017-06-19 21:39:43,371 Epoch[17] Batch [10]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.135395,	
2017-06-19 21:39:47,976 Epoch[17] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.133545,	
2017-06-19 21:39:52,809 Epoch[17] Batch [30]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.124047,	
2017-06-19 21:39:57,773 Epoch[17] Batch [40]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.122820,	
2017-06-19 21:40:02,804 Epoch[17] Batch [50]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.123216,	
2017-06-19 21:40:07,396 Epoch[17] Batch [60]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.121122,	
2017-06-19 21:40:11,743 Epoch[17] Batch [70]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.124275,	
2017-06-19 21:40:15,916 Epoch[17] Batch [80]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.122443,	
2017-06-19 21:40:20,300 Epoch[17] Batch [90]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.124339,	
2017-06-19 21:40:24,762 Epoch[17] Batch [100]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.123990,	
2017-06-19 21:40:29,022 Epoch[17] Batch [110]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.123614,	
2017-06-19 21:40:33,861 Epoch[17] Batch [120]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.124904,	
2017-06-19 21:40:38,634 Epoch[17] Batch [130]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.124061,	
2017-06-19 21:40:43,220 Epoch[17] Batch [140]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.123858,	
2017-06-19 21:40:48,133 Epoch[17] Batch [150]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.123434,	
2017-06-19 21:40:53,060 Epoch[17] Batch [160]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.122780,	
2017-06-19 21:40:57,760 Epoch[17] Batch [170]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.122365,	
2017-06-19 21:41:02,192 Epoch[17] Batch [180]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.121632,	
2017-06-19 21:41:06,655 Epoch[17] Batch [190]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.120679,	
2017-06-19 21:41:10,717 Epoch[17] Batch [200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.121352,	
2017-06-19 21:41:14,947 Epoch[17] Batch [210]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.122119,	
2017-06-19 21:41:19,367 Epoch[17] Batch [220]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.121250,	
2017-06-19 21:41:23,656 Epoch[17] Batch [230]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.120900,	
2017-06-19 21:41:27,561 Epoch[17] Batch [240]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.120560,	
2017-06-19 21:41:31,841 Epoch[17] Batch [250]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.119960,	
2017-06-19 21:41:36,605 Epoch[17] Batch [260]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.119714,	
2017-06-19 21:41:41,209 Epoch[17] Batch [270]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.119726,	
2017-06-19 21:41:45,865 Epoch[17] Batch [280]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.119649,	
2017-06-19 21:41:50,565 Epoch[17] Batch [290]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.119725,	
2017-06-19 21:41:55,128 Epoch[17] Batch [300]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.119538,	
2017-06-19 21:41:59,782 Epoch[17] Batch [310]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.119681,	
2017-06-19 21:42:04,563 Epoch[17] Batch [320]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.119675,	
2017-06-19 21:42:09,484 Epoch[17] Batch [330]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.119558,	
2017-06-19 21:42:14,374 Epoch[17] Batch [340]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.119348,	
2017-06-19 21:42:18,967 Epoch[17] Batch [350]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.119296,	
2017-06-19 21:42:24,106 Epoch[17] Batch [360]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.119169,	
2017-06-19 21:42:28,809 Epoch[17] Batch [370]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.118823,	
2017-06-19 21:42:33,864 Epoch[17] Batch [380]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.118722,	
2017-06-19 21:42:38,612 Epoch[17] Batch [390]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.118720,	
2017-06-19 21:42:43,757 Epoch[17] Batch [400]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.119172,	
2017-06-19 21:42:48,704 Epoch[17] Batch [410]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.118874,	
2017-06-19 21:42:53,896 Epoch[17] Batch [420]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.118837,	
2017-06-19 21:42:59,031 Epoch[17] Batch [430]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.118657,	
2017-06-19 21:43:03,720 Epoch[17] Batch [440]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.118653,	
2017-06-19 21:43:08,643 Epoch[17] Batch [450]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.118372,	
2017-06-19 21:43:13,707 Epoch[17] Batch [460]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.118289,	
2017-06-19 21:43:18,765 Epoch[17] Batch [470]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.118164,	
2017-06-19 21:43:23,032 Epoch[17] Batch [480]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.117958,	
2017-06-19 21:43:27,181 Epoch[17] Batch [490]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.118084,	
2017-06-19 21:43:31,488 Epoch[17] Batch [500]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.117891,	
2017-06-19 21:43:35,573 Epoch[17] Batch [510]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117535,	
2017-06-19 21:43:39,784 Epoch[17] Batch [520]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.117563,	
2017-06-19 21:43:44,769 Epoch[17] Batch [530]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.117503,	
2017-06-19 21:43:49,770 Epoch[17] Batch [540]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.117418,	
2017-06-19 21:43:54,639 Epoch[17] Batch [550]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.117009,	
2017-06-19 21:44:00,134 Epoch[17] Batch [560]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.116708,	
2017-06-19 21:44:04,791 Epoch[17] Batch [570]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.116476,	
2017-06-19 21:44:09,821 Epoch[17] Batch [580]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.116569,	
2017-06-19 21:44:14,748 Epoch[17] Batch [590]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.116593,	
2017-06-19 21:44:19,723 Epoch[17] Batch [600]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.116507,	
2017-06-19 21:44:25,075 Epoch[17] Batch [610]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116364,	
2017-06-19 21:44:29,887 Epoch[17] Batch [620]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.116304,	
2017-06-19 21:44:34,773 Epoch[17] Batch [630]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.116076,	
2017-06-19 21:44:39,788 Epoch[17] Batch [640]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.115818,	
2017-06-19 21:44:44,326 Epoch[17] Batch [650]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.115637,	
2017-06-19 21:44:49,361 Epoch[17] Batch [660]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.115634,	
2017-06-19 21:44:53,792 Epoch[17] Batch [670]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.115494,	
2017-06-19 21:44:58,371 Epoch[17] Batch [680]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.115233,	
2017-06-19 21:45:02,886 Epoch[17] Batch [690]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.115224,	
2017-06-19 21:45:07,273 Epoch[17] Batch [700]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.115142,	
2017-06-19 21:45:11,631 Epoch[17] Batch [710]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.114925,	
2017-06-19 21:45:15,986 Epoch[17] Batch [720]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.115088,	
2017-06-19 21:45:21,137 Epoch[17] Batch [730]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.114918,	
2017-06-19 21:45:26,025 Epoch[17] Batch [740]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.114816,	
2017-06-19 21:45:31,248 Epoch[17] Batch [750]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.114843,	
2017-06-19 21:45:36,131 Epoch[17] Batch [760]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.114685,	
2017-06-19 21:45:41,051 Epoch[17] Batch [770]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.114627,	
2017-06-19 21:45:46,117 Epoch[17] Batch [780]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.114450,	
2017-06-19 21:45:51,293 Epoch[17] Batch [790]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.114366,	
2017-06-19 21:45:55,913 Epoch[17] Batch [800]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.114269,	
2017-06-19 21:46:00,350 Epoch[17] Batch [810]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.114284,	
2017-06-19 21:46:04,383 Epoch[17] Batch [820]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.114117,	
2017-06-19 21:46:08,493 Epoch[17] Batch [830]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.114311,	
2017-06-19 21:46:12,834 Epoch[17] Batch [840]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.114469,	
2017-06-19 21:46:17,030 Epoch[17] Batch [850]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.114450,	
2017-06-19 21:46:21,566 Epoch[17] Batch [860]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.114362,	
2017-06-19 21:46:25,912 Epoch[17] Batch [870]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.114305,	
2017-06-19 21:46:30,058 Epoch[17] Batch [880]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.114293,	
2017-06-19 21:46:34,247 Epoch[17] Batch [890]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.114187,	
2017-06-19 21:46:38,478 Epoch[17] Batch [900]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.114198,	
2017-06-19 21:46:42,663 Epoch[17] Batch [910]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.114094,	
2017-06-19 21:46:47,087 Epoch[17] Batch [920]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.113965,	
2017-06-19 21:46:51,294 Epoch[17] Batch [930]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.114036,	
2017-06-19 21:46:55,710 Epoch[17] Batch [940]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.114004,	
2017-06-19 21:46:59,841 Epoch[17] Batch [950]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113951,	
2017-06-19 21:47:04,002 Epoch[17] Batch [960]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.113976,	
2017-06-19 21:47:08,137 Epoch[17] Batch [970]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.114063,	
2017-06-19 21:47:12,296 Epoch[17] Batch [980]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.113978,	
2017-06-19 21:47:16,283 Epoch[17] Batch [990]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.113873,	
2017-06-19 21:47:20,445 Epoch[17] Batch [1000]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.113718,	
2017-06-19 21:47:24,669 Epoch[17] Batch [1010]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113707,	
2017-06-19 21:47:28,824 Epoch[17] Batch [1020]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.113593,	
2017-06-19 21:47:33,105 Epoch[17] Batch [1030]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.113609,	
2017-06-19 21:47:37,243 Epoch[17] Batch [1040]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113456,	
2017-06-19 21:47:41,387 Epoch[17] Batch [1050]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113415,	
2017-06-19 21:47:45,610 Epoch[17] Batch [1060]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113325,	
2017-06-19 21:47:49,871 Epoch[17] Batch [1070]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.113351,	
2017-06-19 21:47:54,028 Epoch[17] Batch [1080]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.113302,	
2017-06-19 21:47:58,136 Epoch[17] Batch [1090]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113296,	
2017-06-19 21:48:02,267 Epoch[17] Batch [1100]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113328,	
2017-06-19 21:48:06,382 Epoch[17] Batch [1110]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.113316,	
2017-06-19 21:48:10,729 Epoch[17] Batch [1120]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.113293,	
2017-06-19 21:48:14,888 Epoch[17] Batch [1130]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.113333,	
2017-06-19 21:48:19,178 Epoch[17] Batch [1140]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.113293,	
2017-06-19 21:48:23,271 Epoch[17] Batch [1150]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113331,	
2017-06-19 21:48:27,380 Epoch[17] Batch [1160]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113316,	
2017-06-19 21:48:31,731 Epoch[17] Batch [1170]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.113241,	
2017-06-19 21:48:35,995 Epoch[17] Batch [1180]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.113170,	
2017-06-19 21:48:40,205 Epoch[17] Batch [1190]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.113095,	
2017-06-19 21:48:44,435 Epoch[17] Batch [1200]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.113189,	
2017-06-19 21:48:48,486 Epoch[17] Batch [1210]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113072,	
2017-06-19 21:48:52,611 Epoch[17] Batch [1220]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113022,	
2017-06-19 21:48:56,828 Epoch[17] Batch [1230]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.113004,	
2017-06-19 21:49:01,179 Epoch[17] Batch [1240]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.112971,	
2017-06-19 21:49:05,302 Epoch[17] Batch [1250]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112946,	
2017-06-19 21:49:09,311 Epoch[17] Batch [1260]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113006,	
2017-06-19 21:49:13,352 Epoch[17] Batch [1270]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112917,	
2017-06-19 21:49:17,294 Epoch[17] Batch [1280]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.112885,	
2017-06-19 21:49:21,438 Epoch[17] Batch [1290]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112802,	
2017-06-19 21:49:25,520 Epoch[17] Batch [1300]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112798,	
2017-06-19 21:49:29,592 Epoch[17] Batch [1310]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112732,	
2017-06-19 21:49:33,749 Epoch[17] Batch [1320]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.112775,	
2017-06-19 21:49:37,857 Epoch[17] Batch [1330]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112858,	
2017-06-19 21:49:41,917 Epoch[17] Batch [1340]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113009,	
2017-06-19 21:49:45,961 Epoch[17] Batch [1350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.113045,	
2017-06-19 21:49:50,032 Epoch[17] Batch [1360]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.113066,	
2017-06-19 21:49:54,226 Epoch[17] Batch [1370]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.113133,	
2017-06-19 21:49:58,303 Epoch[17] Batch [1380]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113078,	
2017-06-19 21:50:02,318 Epoch[17] Batch [1390]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113103,	
2017-06-19 21:50:06,204 Epoch[17] Batch [1400]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.113080,	
2017-06-19 21:50:10,453 Epoch[17] Batch [1410]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.113144,	
2017-06-19 21:50:14,579 Epoch[17] Batch [1420]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113071,	
2017-06-19 21:50:18,626 Epoch[17] Batch [1430]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.113112,	
2017-06-19 21:50:22,716 Epoch[17] Batch [1440]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.113082,	
2017-06-19 21:50:26,778 Epoch[17] Batch [1450]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113057,	
2017-06-19 21:50:30,836 Epoch[17] Batch [1460]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.113044,	
2017-06-19 21:50:34,871 Epoch[17] Batch [1470]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113085,	
2017-06-19 21:50:38,884 Epoch[17] Batch [1480]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.113056,	
2017-06-19 21:50:41,323 Epoch[17] Train-FCNLogLoss=0.113060
2017-06-19 21:50:41,323 Epoch[17] Time cost=663.983
2017-06-19 21:50:41,988 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0018.params"
2017-06-19 21:50:43,792 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0018.states"
2017-06-19 21:50:48,656 Epoch[18] Batch [10]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.105276,	
2017-06-19 21:50:52,614 Epoch[18] Batch [20]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.115831,	
2017-06-19 21:50:56,810 Epoch[18] Batch [30]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.113892,	
2017-06-19 21:51:00,949 Epoch[18] Batch [40]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.113949,	
2017-06-19 21:51:04,883 Epoch[18] Batch [50]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.112586,	
2017-06-19 21:51:08,951 Epoch[18] Batch [60]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.111424,	
2017-06-19 21:51:12,910 Epoch[18] Batch [70]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.112891,	
2017-06-19 21:51:16,891 Epoch[18] Batch [80]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113872,	
2017-06-19 21:51:20,919 Epoch[18] Batch [90]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.114065,	
2017-06-19 21:51:24,970 Epoch[18] Batch [100]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.114640,	
2017-06-19 21:51:28,928 Epoch[18] Batch [110]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.114558,	
2017-06-19 21:51:32,980 Epoch[18] Batch [120]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.114770,	
2017-06-19 21:51:37,183 Epoch[18] Batch [130]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.115278,	
2017-06-19 21:51:41,268 Epoch[18] Batch [140]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.114926,	
2017-06-19 21:51:45,304 Epoch[18] Batch [150]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.114935,	
2017-06-19 21:51:49,250 Epoch[18] Batch [160]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.115043,	
2017-06-19 21:51:53,210 Epoch[18] Batch [170]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.117263,	
2017-06-19 21:51:57,385 Epoch[18] Batch [180]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117736,	
2017-06-19 21:52:01,415 Epoch[18] Batch [190]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117151,	
2017-06-19 21:52:05,447 Epoch[18] Batch [200]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116379,	
2017-06-19 21:52:09,546 Epoch[18] Batch [210]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.116007,	
2017-06-19 21:52:13,744 Epoch[18] Batch [220]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.115992,	
2017-06-19 21:52:17,824 Epoch[18] Batch [230]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115447,	
2017-06-19 21:52:22,005 Epoch[18] Batch [240]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.114904,	
2017-06-19 21:52:25,991 Epoch[18] Batch [250]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.114636,	
2017-06-19 21:52:30,063 Epoch[18] Batch [260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.114315,	
2017-06-19 21:52:34,140 Epoch[18] Batch [270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.114350,	
2017-06-19 21:52:38,170 Epoch[18] Batch [280]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113899,	
2017-06-19 21:52:42,158 Epoch[18] Batch [290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.113579,	
2017-06-19 21:52:46,243 Epoch[18] Batch [300]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.113198,	
2017-06-19 21:52:50,342 Epoch[18] Batch [310]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113623,	
2017-06-19 21:52:54,324 Epoch[18] Batch [320]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113487,	
2017-06-19 21:52:58,550 Epoch[18] Batch [330]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113605,	
2017-06-19 21:53:02,465 Epoch[18] Batch [340]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.113748,	
2017-06-19 21:53:06,481 Epoch[18] Batch [350]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113628,	
2017-06-19 21:53:10,625 Epoch[18] Batch [360]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113272,	
2017-06-19 21:53:14,673 Epoch[18] Batch [370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113135,	
2017-06-19 21:53:18,913 Epoch[18] Batch [380]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.113026,	
2017-06-19 21:53:23,012 Epoch[18] Batch [390]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112699,	
2017-06-19 21:53:27,092 Epoch[18] Batch [400]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.112269,	
2017-06-19 21:53:31,098 Epoch[18] Batch [410]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112253,	
2017-06-19 21:53:35,267 Epoch[18] Batch [420]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.112195,	
2017-06-19 21:53:39,199 Epoch[18] Batch [430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.112151,	
2017-06-19 21:53:43,167 Epoch[18] Batch [440]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.112045,	
2017-06-19 21:53:47,206 Epoch[18] Batch [450]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112101,	
2017-06-19 21:53:51,097 Epoch[18] Batch [460]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.112038,	
2017-06-19 21:53:55,223 Epoch[18] Batch [470]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.111912,	
2017-06-19 21:53:59,248 Epoch[18] Batch [480]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111819,	
2017-06-19 21:54:03,340 Epoch[18] Batch [490]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.111517,	
2017-06-19 21:54:07,316 Epoch[18] Batch [500]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111278,	
2017-06-19 21:54:11,210 Epoch[18] Batch [510]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.111132,	
2017-06-19 21:54:15,292 Epoch[18] Batch [520]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111135,	
2017-06-19 21:54:19,238 Epoch[18] Batch [530]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.110997,	
2017-06-19 21:54:23,315 Epoch[18] Batch [540]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.110904,	
2017-06-19 21:54:27,596 Epoch[18] Batch [550]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.110946,	
2017-06-19 21:54:31,708 Epoch[18] Batch [560]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110811,	
2017-06-19 21:54:35,783 Epoch[18] Batch [570]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.110765,	
2017-06-19 21:54:39,904 Epoch[18] Batch [580]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.110823,	
2017-06-19 21:54:44,075 Epoch[18] Batch [590]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.110689,	
2017-06-19 21:54:48,362 Epoch[18] Batch [600]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.110712,	
2017-06-19 21:54:52,710 Epoch[18] Batch [610]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.110625,	
2017-06-19 21:54:57,063 Epoch[18] Batch [620]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.110752,	
2017-06-19 21:55:01,236 Epoch[18] Batch [630]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.110755,	
2017-06-19 21:55:05,431 Epoch[18] Batch [640]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.110929,	
2017-06-19 21:55:09,516 Epoch[18] Batch [650]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110883,	
2017-06-19 21:55:13,805 Epoch[18] Batch [660]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.110670,	
2017-06-19 21:55:17,933 Epoch[18] Batch [670]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.110788,	
2017-06-19 21:55:22,099 Epoch[18] Batch [680]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.110776,	
2017-06-19 21:55:26,310 Epoch[18] Batch [690]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.110741,	
2017-06-19 21:55:30,405 Epoch[18] Batch [700]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110914,	
2017-06-19 21:55:34,612 Epoch[18] Batch [710]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.111024,	
2017-06-19 21:55:38,885 Epoch[18] Batch [720]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.110962,	
2017-06-19 21:55:43,078 Epoch[18] Batch [730]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.110953,	
2017-06-19 21:55:47,331 Epoch[18] Batch [740]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.110881,	
2017-06-19 21:55:51,447 Epoch[18] Batch [750]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110947,	
2017-06-19 21:55:55,655 Epoch[18] Batch [760]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.110808,	
2017-06-19 21:55:59,633 Epoch[18] Batch [770]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.110692,	
2017-06-19 21:56:03,855 Epoch[18] Batch [780]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.110697,	
2017-06-19 21:56:08,102 Epoch[18] Batch [790]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.110782,	
2017-06-19 21:56:12,286 Epoch[18] Batch [800]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.110838,	
2017-06-19 21:56:16,353 Epoch[18] Batch [810]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.110666,	
2017-06-19 21:56:20,545 Epoch[18] Batch [820]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.110577,	
2017-06-19 21:56:24,758 Epoch[18] Batch [830]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.110506,	
2017-06-19 21:56:28,935 Epoch[18] Batch [840]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110480,	
2017-06-19 21:56:33,080 Epoch[18] Batch [850]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.110495,	
2017-06-19 21:56:37,264 Epoch[18] Batch [860]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.110496,	
2017-06-19 21:56:41,562 Epoch[18] Batch [870]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.110673,	
2017-06-19 21:56:45,798 Epoch[18] Batch [880]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.110682,	
2017-06-19 21:56:49,908 Epoch[18] Batch [890]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110746,	
2017-06-19 21:56:54,139 Epoch[18] Batch [900]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.110740,	
2017-06-19 21:56:58,607 Epoch[18] Batch [910]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.110794,	
2017-06-19 21:57:02,796 Epoch[18] Batch [920]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.110787,	
2017-06-19 21:57:07,070 Epoch[18] Batch [930]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.110904,	
2017-06-19 21:57:11,265 Epoch[18] Batch [940]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.110817,	
2017-06-19 21:57:15,647 Epoch[18] Batch [950]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.110707,	
2017-06-19 21:57:19,855 Epoch[18] Batch [960]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.110847,	
2017-06-19 21:57:24,025 Epoch[18] Batch [970]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.110906,	
2017-06-19 21:57:28,141 Epoch[18] Batch [980]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110903,	
2017-06-19 21:57:32,248 Epoch[18] Batch [990]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.110761,	
2017-06-19 21:57:36,469 Epoch[18] Batch [1000]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.110746,	
2017-06-19 21:57:40,836 Epoch[18] Batch [1010]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.110694,	
2017-06-19 21:57:45,076 Epoch[18] Batch [1020]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.110805,	
2017-06-19 21:57:49,195 Epoch[18] Batch [1030]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.110735,	
2017-06-19 21:57:53,402 Epoch[18] Batch [1040]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.110619,	
2017-06-19 21:57:57,632 Epoch[18] Batch [1050]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.110583,	
2017-06-19 21:58:01,741 Epoch[18] Batch [1060]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.110540,	
2017-06-19 21:58:05,843 Epoch[18] Batch [1070]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.110616,	
2017-06-19 21:58:10,163 Epoch[18] Batch [1080]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110755,	
2017-06-19 21:58:14,343 Epoch[18] Batch [1090]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.110819,	
2017-06-19 21:58:18,546 Epoch[18] Batch [1100]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.110686,	
2017-06-19 21:58:22,758 Epoch[18] Batch [1110]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.110753,	
2017-06-19 21:58:27,138 Epoch[18] Batch [1120]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.110760,	
2017-06-19 21:58:31,442 Epoch[18] Batch [1130]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.110725,	
2017-06-19 21:58:35,644 Epoch[18] Batch [1140]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.110765,	
2017-06-19 21:58:39,984 Epoch[18] Batch [1150]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.110811,	
2017-06-19 21:58:44,071 Epoch[18] Batch [1160]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110885,	
2017-06-19 21:58:48,203 Epoch[18] Batch [1170]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.110903,	
2017-06-19 21:58:52,652 Epoch[18] Batch [1180]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.110782,	
2017-06-19 21:58:57,205 Epoch[18] Batch [1190]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.111227,	
2017-06-19 21:59:01,377 Epoch[18] Batch [1200]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.111348,	
2017-06-19 21:59:05,642 Epoch[18] Batch [1210]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.111311,	
2017-06-19 21:59:10,024 Epoch[18] Batch [1220]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.111387,	
2017-06-19 21:59:14,053 Epoch[18] Batch [1230]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111386,	
2017-06-19 21:59:18,201 Epoch[18] Batch [1240]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.111465,	
2017-06-19 21:59:22,198 Epoch[18] Batch [1250]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.111505,	
2017-06-19 21:59:26,182 Epoch[18] Batch [1260]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.111596,	
2017-06-19 21:59:30,299 Epoch[18] Batch [1270]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.111545,	
2017-06-19 21:59:34,366 Epoch[18] Batch [1280]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.111474,	
2017-06-19 21:59:38,380 Epoch[18] Batch [1290]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111441,	
2017-06-19 21:59:42,343 Epoch[18] Batch [1300]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.111472,	
2017-06-19 21:59:46,292 Epoch[18] Batch [1310]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.111447,	
2017-06-19 21:59:50,286 Epoch[18] Batch [1320]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.111437,	
2017-06-19 21:59:54,310 Epoch[18] Batch [1330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111379,	
2017-06-19 21:59:58,380 Epoch[18] Batch [1340]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.111395,	
2017-06-19 22:00:02,583 Epoch[18] Batch [1350]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.111420,	
2017-06-19 22:00:06,608 Epoch[18] Batch [1360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111532,	
2017-06-19 22:00:10,783 Epoch[18] Batch [1370]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.111499,	
2017-06-19 22:00:14,827 Epoch[18] Batch [1380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111447,	
2017-06-19 22:00:18,958 Epoch[18] Batch [1390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111422,	
2017-06-19 22:00:23,027 Epoch[18] Batch [1400]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.111344,	
2017-06-19 22:00:27,219 Epoch[18] Batch [1410]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.111304,	
2017-06-19 22:00:31,127 Epoch[18] Batch [1420]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.111203,	
2017-06-19 22:00:35,127 Epoch[18] Batch [1430]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.111172,	
2017-06-19 22:00:39,258 Epoch[18] Batch [1440]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.111068,	
2017-06-19 22:00:43,406 Epoch[18] Batch [1450]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.111090,	
2017-06-19 22:00:47,407 Epoch[18] Batch [1460]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.111227,	
2017-06-19 22:00:51,554 Epoch[18] Batch [1470]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.111225,	
2017-06-19 22:00:55,461 Epoch[18] Batch [1480]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.111228,	
2017-06-19 22:00:57,933 Epoch[18] Train-FCNLogLoss=0.111260
2017-06-19 22:00:57,933 Epoch[18] Time cost=614.140
2017-06-19 22:00:58,558 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0019.params"
2017-06-19 22:01:00,258 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0019.states"
2017-06-19 22:01:04,997 Epoch[19] Batch [10]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110827,	
2017-06-19 22:01:09,123 Epoch[19] Batch [20]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112612,	
2017-06-19 22:01:13,121 Epoch[19] Batch [30]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.107887,	
2017-06-19 22:01:17,115 Epoch[19] Batch [40]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110694,	
2017-06-19 22:01:21,321 Epoch[19] Batch [50]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.112740,	
2017-06-19 22:01:25,401 Epoch[19] Batch [60]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.111836,	
2017-06-19 22:01:29,526 Epoch[19] Batch [70]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110658,	
2017-06-19 22:01:33,651 Epoch[19] Batch [80]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.111863,	
2017-06-19 22:01:37,876 Epoch[19] Batch [90]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113300,	
2017-06-19 22:01:41,900 Epoch[19] Batch [100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112600,	
2017-06-19 22:01:46,009 Epoch[19] Batch [110]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113194,	
2017-06-19 22:01:50,044 Epoch[19] Batch [120]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112474,	
2017-06-19 22:01:53,960 Epoch[19] Batch [130]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112518,	
2017-06-19 22:01:57,954 Epoch[19] Batch [140]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112608,	
2017-06-19 22:02:01,880 Epoch[19] Batch [150]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.112160,	
2017-06-19 22:02:06,095 Epoch[19] Batch [160]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.112251,	
2017-06-19 22:02:10,135 Epoch[19] Batch [170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111797,	
2017-06-19 22:02:14,144 Epoch[19] Batch [180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.111713,	
2017-06-19 22:02:18,221 Epoch[19] Batch [190]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.111478,	
2017-06-19 22:02:22,339 Epoch[19] Batch [200]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.111027,	
2017-06-19 22:02:26,443 Epoch[19] Batch [210]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111083,	
2017-06-19 22:02:30,529 Epoch[19] Batch [220]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110879,	
2017-06-19 22:02:34,617 Epoch[19] Batch [230]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110837,	
2017-06-19 22:02:38,656 Epoch[19] Batch [240]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110508,	
2017-06-19 22:02:42,820 Epoch[19] Batch [250]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.110588,	
2017-06-19 22:02:46,961 Epoch[19] Batch [260]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110193,	
2017-06-19 22:02:50,860 Epoch[19] Batch [270]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.110584,	
2017-06-19 22:02:54,806 Epoch[19] Batch [280]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.110279,	
2017-06-19 22:02:58,770 Epoch[19] Batch [290]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.110345,	
2017-06-19 22:03:02,863 Epoch[19] Batch [300]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110370,	
2017-06-19 22:03:06,956 Epoch[19] Batch [310]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110408,	
2017-06-19 22:03:11,009 Epoch[19] Batch [320]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.110298,	
2017-06-19 22:03:15,238 Epoch[19] Batch [330]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.110125,	
2017-06-19 22:03:19,336 Epoch[19] Batch [340]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.110415,	
2017-06-19 22:03:23,266 Epoch[19] Batch [350]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110137,	
2017-06-19 22:03:27,277 Epoch[19] Batch [360]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.109850,	
2017-06-19 22:03:31,461 Epoch[19] Batch [370]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.109809,	
2017-06-19 22:03:35,695 Epoch[19] Batch [380]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.109677,	
2017-06-19 22:03:39,777 Epoch[19] Batch [390]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.109834,	
2017-06-19 22:03:43,791 Epoch[19] Batch [400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.109841,	
2017-06-19 22:03:47,812 Epoch[19] Batch [410]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.109708,	
2017-06-19 22:03:51,933 Epoch[19] Batch [420]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.109724,	
2017-06-19 22:03:55,901 Epoch[19] Batch [430]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.109741,	
2017-06-19 22:04:00,074 Epoch[19] Batch [440]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.109549,	
2017-06-19 22:04:04,145 Epoch[19] Batch [450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.109570,	
2017-06-19 22:04:08,178 Epoch[19] Batch [460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.109387,	
2017-06-19 22:04:12,231 Epoch[19] Batch [470]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.109661,	
2017-06-19 22:04:16,425 Epoch[19] Batch [480]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.109945,	
2017-06-19 22:04:20,519 Epoch[19] Batch [490]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.109868,	
2017-06-19 22:04:24,616 Epoch[19] Batch [500]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.109927,	
2017-06-19 22:04:28,865 Epoch[19] Batch [510]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109917,	
2017-06-19 22:04:32,872 Epoch[19] Batch [520]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109904,	
2017-06-19 22:04:37,080 Epoch[19] Batch [530]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.109968,	
2017-06-19 22:04:41,226 Epoch[19] Batch [540]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.109724,	
2017-06-19 22:04:45,316 Epoch[19] Batch [550]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109925,	
2017-06-19 22:04:49,514 Epoch[19] Batch [560]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.109651,	
2017-06-19 22:04:53,665 Epoch[19] Batch [570]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.109744,	
2017-06-19 22:04:57,958 Epoch[19] Batch [580]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.109844,	
2017-06-19 22:05:02,196 Epoch[19] Batch [590]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109760,	
2017-06-19 22:05:06,175 Epoch[19] Batch [600]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.109693,	
2017-06-19 22:05:10,409 Epoch[19] Batch [610]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.109408,	
2017-06-19 22:05:14,862 Epoch[19] Batch [620]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.109230,	
2017-06-19 22:05:19,249 Epoch[19] Batch [630]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.109345,	
2017-06-19 22:05:23,482 Epoch[19] Batch [640]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.109510,	
2017-06-19 22:05:27,735 Epoch[19] Batch [650]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109402,	
2017-06-19 22:05:31,893 Epoch[19] Batch [660]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109392,	
2017-06-19 22:05:36,152 Epoch[19] Batch [670]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.109508,	
2017-06-19 22:05:40,265 Epoch[19] Batch [680]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.109419,	
2017-06-19 22:05:44,565 Epoch[19] Batch [690]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.109277,	
2017-06-19 22:05:48,815 Epoch[19] Batch [700]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109276,	
2017-06-19 22:05:53,086 Epoch[19] Batch [710]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109367,	
2017-06-19 22:05:57,362 Epoch[19] Batch [720]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109430,	
2017-06-19 22:06:01,504 Epoch[19] Batch [730]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.109627,	
2017-06-19 22:06:05,684 Epoch[19] Batch [740]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.109507,	
2017-06-19 22:06:09,997 Epoch[19] Batch [750]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.109359,	
2017-06-19 22:06:14,106 Epoch[19] Batch [760]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.109355,	
2017-06-19 22:06:18,432 Epoch[19] Batch [770]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109152,	
2017-06-19 22:06:22,687 Epoch[19] Batch [780]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.109227,	
2017-06-19 22:06:26,775 Epoch[19] Batch [790]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.109277,	
2017-06-19 22:06:31,125 Epoch[19] Batch [800]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.109293,	
2017-06-19 22:06:35,250 Epoch[19] Batch [810]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.109470,	
2017-06-19 22:06:39,719 Epoch[19] Batch [820]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.109469,	
2017-06-19 22:06:43,949 Epoch[19] Batch [830]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.109556,	
2017-06-19 22:06:48,216 Epoch[19] Batch [840]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.109581,	
2017-06-19 22:06:52,290 Epoch[19] Batch [850]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.109825,	
2017-06-19 22:06:56,561 Epoch[19] Batch [860]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109797,	
2017-06-19 22:07:00,848 Epoch[19] Batch [870]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.109644,	
2017-06-19 22:07:05,067 Epoch[19] Batch [880]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.109496,	
2017-06-19 22:07:09,362 Epoch[19] Batch [890]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.109403,	
2017-06-19 22:07:13,560 Epoch[19] Batch [900]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.109289,	
2017-06-19 22:07:17,911 Epoch[19] Batch [910]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.109289,	
2017-06-19 22:07:22,159 Epoch[19] Batch [920]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.109209,	
2017-06-19 22:07:26,220 Epoch[19] Batch [930]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109214,	
2017-06-19 22:07:30,373 Epoch[19] Batch [940]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.109344,	
2017-06-19 22:07:34,568 Epoch[19] Batch [950]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.109293,	
2017-06-19 22:07:38,870 Epoch[19] Batch [960]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.109266,	
2017-06-19 22:07:43,022 Epoch[19] Batch [970]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.109297,	
2017-06-19 22:07:47,261 Epoch[19] Batch [980]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109277,	
2017-06-19 22:07:51,512 Epoch[19] Batch [990]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109183,	
2017-06-19 22:07:55,702 Epoch[19] Batch [1000]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.109147,	
2017-06-19 22:08:00,067 Epoch[19] Batch [1010]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.109077,	
2017-06-19 22:08:04,342 Epoch[19] Batch [1020]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109122,	
2017-06-19 22:08:08,493 Epoch[19] Batch [1030]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.109112,	
2017-06-19 22:08:12,720 Epoch[19] Batch [1040]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.109095,	
2017-06-19 22:08:16,904 Epoch[19] Batch [1050]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.109087,	
2017-06-19 22:08:21,080 Epoch[19] Batch [1060]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109176,	
2017-06-19 22:08:25,372 Epoch[19] Batch [1070]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.109138,	
2017-06-19 22:08:29,582 Epoch[19] Batch [1080]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.109207,	
2017-06-19 22:08:33,792 Epoch[19] Batch [1090]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.109179,	
2017-06-19 22:08:37,829 Epoch[19] Batch [1100]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.109086,	
2017-06-19 22:08:41,961 Epoch[19] Batch [1110]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.109059,	
2017-06-19 22:08:46,038 Epoch[19] Batch [1120]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109125,	
2017-06-19 22:08:50,208 Epoch[19] Batch [1130]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.109105,	
2017-06-19 22:08:54,409 Epoch[19] Batch [1140]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.109109,	
2017-06-19 22:08:58,530 Epoch[19] Batch [1150]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.109058,	
2017-06-19 22:09:02,694 Epoch[19] Batch [1160]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.109031,	
2017-06-19 22:09:07,100 Epoch[19] Batch [1170]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.109016,	
2017-06-19 22:09:11,130 Epoch[19] Batch [1180]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108864,	
2017-06-19 22:09:15,246 Epoch[19] Batch [1190]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.108746,	
2017-06-19 22:09:19,476 Epoch[19] Batch [1200]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.108761,	
2017-06-19 22:09:23,713 Epoch[19] Batch [1210]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.108807,	
2017-06-19 22:09:27,853 Epoch[19] Batch [1220]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.108703,	
2017-06-19 22:09:32,090 Epoch[19] Batch [1230]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.108723,	
2017-06-19 22:09:36,183 Epoch[19] Batch [1240]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108693,	
2017-06-19 22:09:40,238 Epoch[19] Batch [1250]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108774,	
2017-06-19 22:09:44,265 Epoch[19] Batch [1260]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108653,	
2017-06-19 22:09:48,382 Epoch[19] Batch [1270]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.108665,	
2017-06-19 22:09:52,502 Epoch[19] Batch [1280]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.108570,	
2017-06-19 22:09:56,679 Epoch[19] Batch [1290]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.108502,	
2017-06-19 22:10:00,812 Epoch[19] Batch [1300]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108594,	
2017-06-19 22:10:04,705 Epoch[19] Batch [1310]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.108724,	
2017-06-19 22:10:08,849 Epoch[19] Batch [1320]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.108689,	
2017-06-19 22:10:12,845 Epoch[19] Batch [1330]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.108696,	
2017-06-19 22:10:16,927 Epoch[19] Batch [1340]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.108709,	
2017-06-19 22:10:20,971 Epoch[19] Batch [1350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.108690,	
2017-06-19 22:10:24,939 Epoch[19] Batch [1360]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.108647,	
2017-06-19 22:10:29,095 Epoch[19] Batch [1370]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.108731,	
2017-06-19 22:10:33,261 Epoch[19] Batch [1380]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.108797,	
2017-06-19 22:10:37,391 Epoch[19] Batch [1390]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.108931,	
2017-06-19 22:10:41,524 Epoch[19] Batch [1400]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108881,	
2017-06-19 22:10:45,603 Epoch[19] Batch [1410]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.108867,	
2017-06-19 22:10:49,807 Epoch[19] Batch [1420]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.108998,	
2017-06-19 22:10:53,890 Epoch[19] Batch [1430]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.108961,	
2017-06-19 22:10:57,960 Epoch[19] Batch [1440]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.108941,	
2017-06-19 22:11:01,908 Epoch[19] Batch [1450]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.108977,	
2017-06-19 22:11:05,825 Epoch[19] Batch [1460]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.108964,	
2017-06-19 22:11:09,985 Epoch[19] Batch [1470]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109041,	
2017-06-19 22:11:14,013 Epoch[19] Batch [1480]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.109138,	
2017-06-19 22:11:16,454 Epoch[19] Train-FCNLogLoss=0.109176
2017-06-19 22:11:16,454 Epoch[19] Time cost=616.195
2017-06-19 22:11:17,094 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0020.params"
2017-06-19 22:11:18,859 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0020.states"
2017-06-19 22:11:23,685 Epoch[20] Batch [10]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.131150,	
2017-06-19 22:11:27,584 Epoch[20] Batch [20]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.130387,	
2017-06-19 22:11:31,629 Epoch[20] Batch [30]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.153782,	
2017-06-19 22:11:35,739 Epoch[20] Batch [40]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.157292,	
2017-06-19 22:11:39,771 Epoch[20] Batch [50]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.148892,	
2017-06-19 22:11:43,841 Epoch[20] Batch [60]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.143328,	
2017-06-19 22:11:47,939 Epoch[20] Batch [70]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.141750,	
2017-06-19 22:11:52,083 Epoch[20] Batch [80]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.138496,	
2017-06-19 22:11:56,244 Epoch[20] Batch [90]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.135674,	
2017-06-19 22:12:00,186 Epoch[20] Batch [100]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.133192,	
2017-06-19 22:12:04,207 Epoch[20] Batch [110]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.131189,	
2017-06-19 22:12:08,368 Epoch[20] Batch [120]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.129906,	
2017-06-19 22:12:12,462 Epoch[20] Batch [130]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.128221,	
2017-06-19 22:12:16,521 Epoch[20] Batch [140]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.126495,	
2017-06-19 22:12:20,680 Epoch[20] Batch [150]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.125130,	
2017-06-19 22:12:24,951 Epoch[20] Batch [160]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.124498,	
2017-06-19 22:12:29,090 Epoch[20] Batch [170]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.124009,	
2017-06-19 22:12:33,213 Epoch[20] Batch [180]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.123685,	
2017-06-19 22:12:37,446 Epoch[20] Batch [190]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.123211,	
2017-06-19 22:12:41,678 Epoch[20] Batch [200]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.122766,	
2017-06-19 22:12:45,810 Epoch[20] Batch [210]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.121421,	
2017-06-19 22:12:49,933 Epoch[20] Batch [220]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.120559,	
2017-06-19 22:12:53,980 Epoch[20] Batch [230]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.120335,	
2017-06-19 22:12:58,220 Epoch[20] Batch [240]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.120066,	
2017-06-19 22:13:02,297 Epoch[20] Batch [250]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.119620,	
2017-06-19 22:13:06,290 Epoch[20] Batch [260]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.119233,	
2017-06-19 22:13:10,360 Epoch[20] Batch [270]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.119736,	
2017-06-19 22:13:14,350 Epoch[20] Batch [280]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119001,	
2017-06-19 22:13:18,292 Epoch[20] Batch [290]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.118275,	
2017-06-19 22:13:22,361 Epoch[20] Batch [300]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.118155,	
2017-06-19 22:13:26,430 Epoch[20] Batch [310]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117645,	
2017-06-19 22:13:30,690 Epoch[20] Batch [320]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.117821,	
2017-06-19 22:13:34,801 Epoch[20] Batch [330]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.117718,	
2017-06-19 22:13:39,005 Epoch[20] Batch [340]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.117581,	
2017-06-19 22:13:43,159 Epoch[20] Batch [350]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.116951,	
2017-06-19 22:13:47,236 Epoch[20] Batch [360]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116675,	
2017-06-19 22:13:51,299 Epoch[20] Batch [370]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116422,	
2017-06-19 22:13:55,550 Epoch[20] Batch [380]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.116208,	
2017-06-19 22:13:59,712 Epoch[20] Batch [390]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.116242,	
2017-06-19 22:14:03,930 Epoch[20] Batch [400]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.116400,	
2017-06-19 22:14:07,944 Epoch[20] Batch [410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116206,	
2017-06-19 22:14:12,022 Epoch[20] Batch [420]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115897,	
2017-06-19 22:14:16,073 Epoch[20] Batch [430]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.115552,	
2017-06-19 22:14:20,042 Epoch[20] Batch [440]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.115125,	
2017-06-19 22:14:24,197 Epoch[20] Batch [450]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.114921,	
2017-06-19 22:14:28,159 Epoch[20] Batch [460]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.114626,	
2017-06-19 22:14:32,113 Epoch[20] Batch [470]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.114162,	
2017-06-19 22:14:36,201 Epoch[20] Batch [480]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114278,	
2017-06-19 22:14:40,414 Epoch[20] Batch [490]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.114127,	
2017-06-19 22:14:44,539 Epoch[20] Batch [500]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113828,	
2017-06-19 22:14:48,677 Epoch[20] Batch [510]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113791,	
2017-06-19 22:14:52,704 Epoch[20] Batch [520]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113624,	
2017-06-19 22:14:56,841 Epoch[20] Batch [530]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113874,	
2017-06-19 22:15:01,447 Epoch[20] Batch [540]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.113860,	
2017-06-19 22:15:05,746 Epoch[20] Batch [550]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.113707,	
2017-06-19 22:15:10,063 Epoch[20] Batch [560]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.113838,	
2017-06-19 22:15:14,460 Epoch[20] Batch [570]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.114115,	
2017-06-19 22:15:18,560 Epoch[20] Batch [580]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113962,	
2017-06-19 22:15:22,742 Epoch[20] Batch [590]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.113847,	
2017-06-19 22:15:27,120 Epoch[20] Batch [600]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.113896,	
2017-06-19 22:15:31,327 Epoch[20] Batch [610]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.113891,	
2017-06-19 22:15:35,438 Epoch[20] Batch [620]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.113797,	
2017-06-19 22:15:39,844 Epoch[20] Batch [630]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.113781,	
2017-06-19 22:15:44,135 Epoch[20] Batch [640]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.113655,	
2017-06-19 22:15:48,444 Epoch[20] Batch [650]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.113593,	
2017-06-19 22:15:52,873 Epoch[20] Batch [660]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.113637,	
2017-06-19 22:15:57,112 Epoch[20] Batch [670]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.113890,	
2017-06-19 22:16:01,153 Epoch[20] Batch [680]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113611,	
2017-06-19 22:16:05,467 Epoch[20] Batch [690]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.113513,	
2017-06-19 22:16:09,732 Epoch[20] Batch [700]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.113510,	
2017-06-19 22:16:13,878 Epoch[20] Batch [710]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113298,	
2017-06-19 22:16:17,950 Epoch[20] Batch [720]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113280,	
2017-06-19 22:16:22,091 Epoch[20] Batch [730]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.113252,	
2017-06-19 22:16:26,238 Epoch[20] Batch [740]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112936,	
2017-06-19 22:16:30,544 Epoch[20] Batch [750]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112775,	
2017-06-19 22:16:34,777 Epoch[20] Batch [760]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.112846,	
2017-06-19 22:16:39,009 Epoch[20] Batch [770]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.112714,	
2017-06-19 22:16:43,225 Epoch[20] Batch [780]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.112697,	
2017-06-19 22:16:47,452 Epoch[20] Batch [790]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.112577,	
2017-06-19 22:16:51,764 Epoch[20] Batch [800]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.112524,	
2017-06-19 22:16:56,068 Epoch[20] Batch [810]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112462,	
2017-06-19 22:17:00,340 Epoch[20] Batch [820]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.112466,	
2017-06-19 22:17:04,659 Epoch[20] Batch [830]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.112471,	
2017-06-19 22:17:08,796 Epoch[20] Batch [840]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.112346,	
2017-06-19 22:17:12,946 Epoch[20] Batch [850]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112256,	
2017-06-19 22:17:17,137 Epoch[20] Batch [860]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.112265,	
2017-06-19 22:17:21,539 Epoch[20] Batch [870]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.112323,	
2017-06-19 22:17:25,718 Epoch[20] Batch [880]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112204,	
2017-06-19 22:17:30,047 Epoch[20] Batch [890]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.112258,	
2017-06-19 22:17:34,165 Epoch[20] Batch [900]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112239,	
2017-06-19 22:17:38,311 Epoch[20] Batch [910]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112242,	
2017-06-19 22:17:42,531 Epoch[20] Batch [920]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.112197,	
2017-06-19 22:17:46,796 Epoch[20] Batch [930]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.112206,	
2017-06-19 22:17:50,901 Epoch[20] Batch [940]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112200,	
2017-06-19 22:17:55,111 Epoch[20] Batch [950]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.112061,	
2017-06-19 22:17:59,500 Epoch[20] Batch [960]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.111987,	
2017-06-19 22:18:03,631 Epoch[20] Batch [970]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111905,	
2017-06-19 22:18:07,655 Epoch[20] Batch [980]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111842,	
2017-06-19 22:18:11,873 Epoch[20] Batch [990]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.111742,	
2017-06-19 22:18:16,072 Epoch[20] Batch [1000]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.111591,	
2017-06-19 22:18:20,362 Epoch[20] Batch [1010]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.111530,	
2017-06-19 22:18:24,595 Epoch[20] Batch [1020]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.111446,	
2017-06-19 22:18:29,001 Epoch[20] Batch [1030]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.111400,	
2017-06-19 22:18:33,226 Epoch[20] Batch [1040]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.111338,	
2017-06-19 22:18:37,456 Epoch[20] Batch [1050]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.111306,	
2017-06-19 22:18:41,637 Epoch[20] Batch [1060]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.111431,	
2017-06-19 22:18:45,749 Epoch[20] Batch [1070]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.111274,	
2017-06-19 22:18:50,006 Epoch[20] Batch [1080]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.111330,	
2017-06-19 22:18:54,222 Epoch[20] Batch [1090]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.111325,	
2017-06-19 22:18:58,353 Epoch[20] Batch [1100]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111286,	
2017-06-19 22:19:02,572 Epoch[20] Batch [1110]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.111145,	
2017-06-19 22:19:06,753 Epoch[20] Batch [1120]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.111058,	
2017-06-19 22:19:10,846 Epoch[20] Batch [1130]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.111050,	
2017-06-19 22:19:15,179 Epoch[20] Batch [1140]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.110986,	
2017-06-19 22:19:19,479 Epoch[20] Batch [1150]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.111039,	
2017-06-19 22:19:23,715 Epoch[20] Batch [1160]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.111037,	
2017-06-19 22:19:27,984 Epoch[20] Batch [1170]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.110982,	
2017-06-19 22:19:31,973 Epoch[20] Batch [1180]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.111018,	
2017-06-19 22:19:35,989 Epoch[20] Batch [1190]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110995,	
2017-06-19 22:19:39,932 Epoch[20] Batch [1200]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.110933,	
2017-06-19 22:19:43,889 Epoch[20] Batch [1210]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.110940,	
2017-06-19 22:19:47,923 Epoch[20] Batch [1220]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110883,	
2017-06-19 22:19:51,789 Epoch[20] Batch [1230]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.110851,	
2017-06-19 22:19:55,893 Epoch[20] Batch [1240]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.110920,	
2017-06-19 22:20:00,121 Epoch[20] Batch [1250]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.110857,	
2017-06-19 22:20:04,293 Epoch[20] Batch [1260]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.110782,	
2017-06-19 22:20:08,458 Epoch[20] Batch [1270]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.110683,	
2017-06-19 22:20:12,553 Epoch[20] Batch [1280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110675,	
2017-06-19 22:20:16,728 Epoch[20] Batch [1290]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110536,	
2017-06-19 22:20:20,775 Epoch[20] Batch [1300]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.110457,	
2017-06-19 22:20:24,881 Epoch[20] Batch [1310]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.110384,	
2017-06-19 22:20:29,065 Epoch[20] Batch [1320]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.110332,	
2017-06-19 22:20:33,142 Epoch[20] Batch [1330]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.110209,	
2017-06-19 22:20:37,112 Epoch[20] Batch [1340]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.110172,	
2017-06-19 22:20:41,139 Epoch[20] Batch [1350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110138,	
2017-06-19 22:20:45,162 Epoch[20] Batch [1360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.110100,	
2017-06-19 22:20:49,251 Epoch[20] Batch [1370]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110062,	
2017-06-19 22:20:53,258 Epoch[20] Batch [1380]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109977,	
2017-06-19 22:20:57,342 Epoch[20] Batch [1390]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.109973,	
2017-06-19 22:21:01,360 Epoch[20] Batch [1400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110017,	
2017-06-19 22:21:05,446 Epoch[20] Batch [1410]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110038,	
2017-06-19 22:21:09,540 Epoch[20] Batch [1420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110004,	
2017-06-19 22:21:13,581 Epoch[20] Batch [1430]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109969,	
2017-06-19 22:21:17,446 Epoch[20] Batch [1440]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.109945,	
2017-06-19 22:21:21,459 Epoch[20] Batch [1450]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.109922,	
2017-06-19 22:21:25,573 Epoch[20] Batch [1460]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.109920,	
2017-06-19 22:21:29,599 Epoch[20] Batch [1470]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.109893,	
2017-06-19 22:21:33,576 Epoch[20] Batch [1480]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.109932,	
2017-06-19 22:21:36,064 Epoch[20] Train-FCNLogLoss=0.109929
2017-06-19 22:21:36,064 Epoch[20] Time cost=617.204
2017-06-19 22:21:36,736 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0021.params"
2017-06-19 22:21:38,447 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0021.states"
2017-06-19 22:21:43,080 Epoch[21] Batch [10]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.101842,	
2017-06-19 22:21:47,245 Epoch[21] Batch [20]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.110016,	
2017-06-19 22:21:51,370 Epoch[21] Batch [30]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.111025,	
2017-06-19 22:21:55,429 Epoch[21] Batch [40]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108814,	
2017-06-19 22:21:59,519 Epoch[21] Batch [50]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110047,	
2017-06-19 22:22:03,516 Epoch[21] Batch [60]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.108428,	
2017-06-19 22:22:07,681 Epoch[21] Batch [70]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.106442,	
2017-06-19 22:22:11,769 Epoch[21] Batch [80]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.103891,	
2017-06-19 22:22:15,847 Epoch[21] Batch [90]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103981,	
2017-06-19 22:22:19,702 Epoch[21] Batch [100]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.106317,	
2017-06-19 22:22:23,622 Epoch[21] Batch [110]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.106508,	
2017-06-19 22:22:27,580 Epoch[21] Batch [120]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107941,	
2017-06-19 22:22:31,718 Epoch[21] Batch [130]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.107463,	
2017-06-19 22:22:35,773 Epoch[21] Batch [140]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108251,	
2017-06-19 22:22:39,823 Epoch[21] Batch [150]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.108967,	
2017-06-19 22:22:43,763 Epoch[21] Batch [160]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.109455,	
2017-06-19 22:22:47,640 Epoch[21] Batch [170]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.109394,	
2017-06-19 22:22:51,682 Epoch[21] Batch [180]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109503,	
2017-06-19 22:22:55,699 Epoch[21] Batch [190]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.111425,	
2017-06-19 22:22:59,864 Epoch[21] Batch [200]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.112088,	
2017-06-19 22:23:03,945 Epoch[21] Batch [210]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112715,	
2017-06-19 22:23:08,101 Epoch[21] Batch [220]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112532,	
2017-06-19 22:23:12,105 Epoch[21] Batch [230]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.112316,	
2017-06-19 22:23:16,172 Epoch[21] Batch [240]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.111891,	
2017-06-19 22:23:20,072 Epoch[21] Batch [250]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.111923,	
2017-06-19 22:23:23,932 Epoch[21] Batch [260]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.111707,	
2017-06-19 22:23:28,022 Epoch[21] Batch [270]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.111495,	
2017-06-19 22:23:32,114 Epoch[21] Batch [280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.111208,	
2017-06-19 22:23:36,324 Epoch[21] Batch [290]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.111370,	
2017-06-19 22:23:40,576 Epoch[21] Batch [300]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.110884,	
2017-06-19 22:23:44,718 Epoch[21] Batch [310]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110523,	
2017-06-19 22:23:48,748 Epoch[21] Batch [320]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110062,	
2017-06-19 22:23:52,730 Epoch[21] Batch [330]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.110076,	
2017-06-19 22:23:56,818 Epoch[21] Batch [340]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.109835,	
2017-06-19 22:24:00,759 Epoch[21] Batch [350]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.109698,	
2017-06-19 22:24:04,729 Epoch[21] Batch [360]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.109779,	
2017-06-19 22:24:08,651 Epoch[21] Batch [370]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.109925,	
2017-06-19 22:24:12,736 Epoch[21] Batch [380]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.109889,	
2017-06-19 22:24:16,811 Epoch[21] Batch [390]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.110036,	
2017-06-19 22:24:20,903 Epoch[21] Batch [400]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110004,	
2017-06-19 22:24:25,015 Epoch[21] Batch [410]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.109987,	
2017-06-19 22:24:28,908 Epoch[21] Batch [420]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.110274,	
2017-06-19 22:24:32,950 Epoch[21] Batch [430]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110294,	
2017-06-19 22:24:37,054 Epoch[21] Batch [440]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.110271,	
2017-06-19 22:24:40,918 Epoch[21] Batch [450]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.110174,	
2017-06-19 22:24:44,959 Epoch[21] Batch [460]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110422,	
2017-06-19 22:24:49,101 Epoch[21] Batch [470]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110625,	
2017-06-19 22:24:53,027 Epoch[21] Batch [480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.110416,	
2017-06-19 22:24:57,078 Epoch[21] Batch [490]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.110329,	
2017-06-19 22:25:01,319 Epoch[21] Batch [500]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.110240,	
2017-06-19 22:25:05,548 Epoch[21] Batch [510]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.110165,	
2017-06-19 22:25:09,592 Epoch[21] Batch [520]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110141,	
2017-06-19 22:25:13,848 Epoch[21] Batch [530]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.110124,	
2017-06-19 22:25:17,955 Epoch[21] Batch [540]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.110002,	
2017-06-19 22:25:21,919 Epoch[21] Batch [550]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.110021,	
2017-06-19 22:25:26,259 Epoch[21] Batch [560]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.109752,	
2017-06-19 22:25:30,568 Epoch[21] Batch [570]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.109579,	
2017-06-19 22:25:34,687 Epoch[21] Batch [580]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.109275,	
2017-06-19 22:25:38,941 Epoch[21] Batch [590]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.109146,	
2017-06-19 22:25:43,223 Epoch[21] Batch [600]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.109093,	
2017-06-19 22:25:47,455 Epoch[21] Batch [610]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.109186,	
2017-06-19 22:25:51,730 Epoch[21] Batch [620]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109106,	
2017-06-19 22:25:55,822 Epoch[21] Batch [630]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109174,	
2017-06-19 22:26:00,157 Epoch[21] Batch [640]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.109125,	
2017-06-19 22:26:04,246 Epoch[21] Batch [650]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.108903,	
2017-06-19 22:26:08,428 Epoch[21] Batch [660]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.109010,	
2017-06-19 22:26:12,877 Epoch[21] Batch [670]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.108983,	
2017-06-19 22:26:17,102 Epoch[21] Batch [680]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.108945,	
2017-06-19 22:26:21,265 Epoch[21] Batch [690]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.108962,	
2017-06-19 22:26:25,535 Epoch[21] Batch [700]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.108998,	
2017-06-19 22:26:29,860 Epoch[21] Batch [710]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.108990,	
2017-06-19 22:26:34,109 Epoch[21] Batch [720]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109210,	
2017-06-19 22:26:38,423 Epoch[21] Batch [730]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.109263,	
2017-06-19 22:26:42,673 Epoch[21] Batch [740]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109103,	
2017-06-19 22:26:46,679 Epoch[21] Batch [750]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.109178,	
2017-06-19 22:26:51,083 Epoch[21] Batch [760]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.109262,	
2017-06-19 22:26:55,469 Epoch[21] Batch [770]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.109253,	
2017-06-19 22:26:59,845 Epoch[21] Batch [780]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.109329,	
2017-06-19 22:27:04,128 Epoch[21] Batch [790]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.109394,	
2017-06-19 22:27:08,353 Epoch[21] Batch [800]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.109436,	
2017-06-19 22:27:12,351 Epoch[21] Batch [810]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.109524,	
2017-06-19 22:27:16,382 Epoch[21] Batch [820]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.109577,	
2017-06-19 22:27:20,336 Epoch[21] Batch [830]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.109809,	
2017-06-19 22:27:24,553 Epoch[21] Batch [840]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.110081,	
2017-06-19 22:27:28,711 Epoch[21] Batch [850]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.110040,	
2017-06-19 22:27:33,023 Epoch[21] Batch [860]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.110142,	
2017-06-19 22:27:37,343 Epoch[21] Batch [870]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110087,	
2017-06-19 22:27:41,371 Epoch[21] Batch [880]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110159,	
2017-06-19 22:27:45,703 Epoch[21] Batch [890]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.110117,	
2017-06-19 22:27:49,951 Epoch[21] Batch [900]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.110195,	
2017-06-19 22:27:54,215 Epoch[21] Batch [910]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.110142,	
2017-06-19 22:27:58,473 Epoch[21] Batch [920]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.110053,	
2017-06-19 22:28:02,554 Epoch[21] Batch [930]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.110137,	
2017-06-19 22:28:06,836 Epoch[21] Batch [940]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.110053,	
2017-06-19 22:28:10,992 Epoch[21] Batch [950]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.109900,	
2017-06-19 22:28:15,236 Epoch[21] Batch [960]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.109774,	
2017-06-19 22:28:19,435 Epoch[21] Batch [970]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.109692,	
2017-06-19 22:28:23,604 Epoch[21] Batch [980]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.109693,	
2017-06-19 22:28:27,903 Epoch[21] Batch [990]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.109712,	
2017-06-19 22:28:32,282 Epoch[21] Batch [1000]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.109686,	
2017-06-19 22:28:36,518 Epoch[21] Batch [1010]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109654,	
2017-06-19 22:28:40,866 Epoch[21] Batch [1020]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.109618,	
2017-06-19 22:28:45,153 Epoch[21] Batch [1030]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.109639,	
2017-06-19 22:28:49,363 Epoch[21] Batch [1040]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.109747,	
2017-06-19 22:28:53,519 Epoch[21] Batch [1050]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109671,	
2017-06-19 22:28:57,775 Epoch[21] Batch [1060]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.109589,	
2017-06-19 22:29:02,144 Epoch[21] Batch [1070]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.109691,	
2017-06-19 22:29:06,185 Epoch[21] Batch [1080]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109695,	
2017-06-19 22:29:10,542 Epoch[21] Batch [1090]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.109726,	
2017-06-19 22:29:14,625 Epoch[21] Batch [1100]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.109745,	
2017-06-19 22:29:19,023 Epoch[21] Batch [1110]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.109695,	
2017-06-19 22:29:23,432 Epoch[21] Batch [1120]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.109707,	
2017-06-19 22:29:27,654 Epoch[21] Batch [1130]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.109601,	
2017-06-19 22:29:31,865 Epoch[21] Batch [1140]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.109578,	
2017-06-19 22:29:36,126 Epoch[21] Batch [1150]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.109661,	
2017-06-19 22:29:40,185 Epoch[21] Batch [1160]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109499,	
2017-06-19 22:29:44,292 Epoch[21] Batch [1170]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.109443,	
2017-06-19 22:29:48,338 Epoch[21] Batch [1180]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109337,	
2017-06-19 22:29:52,277 Epoch[21] Batch [1190]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.109302,	
2017-06-19 22:29:56,322 Epoch[21] Batch [1200]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109201,	
2017-06-19 22:30:00,542 Epoch[21] Batch [1210]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.109229,	
2017-06-19 22:30:04,535 Epoch[21] Batch [1220]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.109167,	
2017-06-19 22:30:08,693 Epoch[21] Batch [1230]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109049,	
2017-06-19 22:30:12,774 Epoch[21] Batch [1240]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.109085,	
2017-06-19 22:30:16,789 Epoch[21] Batch [1250]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.109102,	
2017-06-19 22:30:20,900 Epoch[21] Batch [1260]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.109090,	
2017-06-19 22:30:24,931 Epoch[21] Batch [1270]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.109032,	
2017-06-19 22:30:28,989 Epoch[21] Batch [1280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108997,	
2017-06-19 22:30:33,217 Epoch[21] Batch [1290]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.108937,	
2017-06-19 22:30:37,329 Epoch[21] Batch [1300]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.108844,	
2017-06-19 22:30:41,460 Epoch[21] Batch [1310]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108851,	
2017-06-19 22:30:45,524 Epoch[21] Batch [1320]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.108801,	
2017-06-19 22:30:49,614 Epoch[21] Batch [1330]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.108772,	
2017-06-19 22:30:53,634 Epoch[21] Batch [1340]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.108772,	
2017-06-19 22:30:57,632 Epoch[21] Batch [1350]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.108703,	
2017-06-19 22:31:01,674 Epoch[21] Batch [1360]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.108887,	
2017-06-19 22:31:05,854 Epoch[21] Batch [1370]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.109026,	
2017-06-19 22:31:09,837 Epoch[21] Batch [1380]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.109088,	
2017-06-19 22:31:13,854 Epoch[21] Batch [1390]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.109051,	
2017-06-19 22:31:17,983 Epoch[21] Batch [1400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.109014,	
2017-06-19 22:31:21,946 Epoch[21] Batch [1410]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.108943,	
2017-06-19 22:31:25,940 Epoch[21] Batch [1420]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.108851,	
2017-06-19 22:31:29,934 Epoch[21] Batch [1430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.108868,	
2017-06-19 22:31:34,014 Epoch[21] Batch [1440]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.108833,	
2017-06-19 22:31:38,185 Epoch[21] Batch [1450]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.108845,	
2017-06-19 22:31:42,278 Epoch[21] Batch [1460]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108776,	
2017-06-19 22:31:46,333 Epoch[21] Batch [1470]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108760,	
2017-06-19 22:31:50,478 Epoch[21] Batch [1480]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.108750,	
2017-06-19 22:31:53,018 Epoch[21] Train-FCNLogLoss=0.108726
2017-06-19 22:31:53,018 Epoch[21] Time cost=614.571
2017-06-19 22:31:53,689 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0022.params"
2017-06-19 22:31:55,430 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0022.states"
2017-06-19 22:32:00,245 Epoch[22] Batch [10]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.128986,	
2017-06-19 22:32:04,212 Epoch[22] Batch [20]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.111381,	
2017-06-19 22:32:08,392 Epoch[22] Batch [30]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112374,	
2017-06-19 22:32:12,504 Epoch[22] Batch [40]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110148,	
2017-06-19 22:32:16,693 Epoch[22] Batch [50]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.106946,	
2017-06-19 22:32:20,722 Epoch[22] Batch [60]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105793,	
2017-06-19 22:32:24,695 Epoch[22] Batch [70]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.106579,	
2017-06-19 22:32:28,741 Epoch[22] Batch [80]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.106047,	
2017-06-19 22:32:32,829 Epoch[22] Batch [90]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105489,	
2017-06-19 22:32:36,890 Epoch[22] Batch [100]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.105827,	
2017-06-19 22:32:40,913 Epoch[22] Batch [110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.106315,	
2017-06-19 22:32:45,027 Epoch[22] Batch [120]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.106210,	
2017-06-19 22:32:49,076 Epoch[22] Batch [130]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.107259,	
2017-06-19 22:32:53,225 Epoch[22] Batch [140]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107084,	
2017-06-19 22:32:57,182 Epoch[22] Batch [150]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107746,	
2017-06-19 22:33:01,175 Epoch[22] Batch [160]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.107111,	
2017-06-19 22:33:05,097 Epoch[22] Batch [170]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.106973,	
2017-06-19 22:33:09,167 Epoch[22] Batch [180]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106682,	
2017-06-19 22:33:13,302 Epoch[22] Batch [190]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.106393,	
2017-06-19 22:33:17,472 Epoch[22] Batch [200]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106197,	
2017-06-19 22:33:21,541 Epoch[22] Batch [210]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105929,	
2017-06-19 22:33:25,619 Epoch[22] Batch [220]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.106188,	
2017-06-19 22:33:29,577 Epoch[22] Batch [230]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.105740,	
2017-06-19 22:33:33,527 Epoch[22] Batch [240]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105831,	
2017-06-19 22:33:37,600 Epoch[22] Batch [250]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105967,	
2017-06-19 22:33:41,543 Epoch[22] Batch [260]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.105932,	
2017-06-19 22:33:45,577 Epoch[22] Batch [270]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105692,	
2017-06-19 22:33:49,656 Epoch[22] Batch [280]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105648,	
2017-06-19 22:33:53,585 Epoch[22] Batch [290]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105857,	
2017-06-19 22:33:57,658 Epoch[22] Batch [300]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105708,	
2017-06-19 22:34:01,837 Epoch[22] Batch [310]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.106029,	
2017-06-19 22:34:05,809 Epoch[22] Batch [320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.106407,	
2017-06-19 22:34:09,744 Epoch[22] Batch [330]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.108371,	
2017-06-19 22:34:13,747 Epoch[22] Batch [340]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.110703,	
2017-06-19 22:34:17,777 Epoch[22] Batch [350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112140,	
2017-06-19 22:34:21,911 Epoch[22] Batch [360]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112668,	
2017-06-19 22:34:25,893 Epoch[22] Batch [370]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.112935,	
2017-06-19 22:34:30,144 Epoch[22] Batch [380]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.113271,	
2017-06-19 22:34:34,253 Epoch[22] Batch [390]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.113225,	
2017-06-19 22:34:38,540 Epoch[22] Batch [400]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.113110,	
2017-06-19 22:34:42,689 Epoch[22] Batch [410]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112924,	
2017-06-19 22:34:46,697 Epoch[22] Batch [420]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113016,	
2017-06-19 22:34:50,834 Epoch[22] Batch [430]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.112836,	
2017-06-19 22:34:54,967 Epoch[22] Batch [440]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112741,	
2017-06-19 22:34:58,992 Epoch[22] Batch [450]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112635,	
2017-06-19 22:35:02,886 Epoch[22] Batch [460]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.112909,	
2017-06-19 22:35:06,959 Epoch[22] Batch [470]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113755,	
2017-06-19 22:35:10,968 Epoch[22] Batch [480]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113632,	
2017-06-19 22:35:15,238 Epoch[22] Batch [490]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.113913,	
2017-06-19 22:35:19,499 Epoch[22] Batch [500]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.114235,	
2017-06-19 22:35:23,625 Epoch[22] Batch [510]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.114522,	
2017-06-19 22:35:27,790 Epoch[22] Batch [520]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.114486,	
2017-06-19 22:35:31,947 Epoch[22] Batch [530]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.114782,	
2017-06-19 22:35:36,154 Epoch[22] Batch [540]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.114878,	
2017-06-19 22:35:40,318 Epoch[22] Batch [550]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.114646,	
2017-06-19 22:35:44,598 Epoch[22] Batch [560]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.114488,	
2017-06-19 22:35:48,968 Epoch[22] Batch [570]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.114396,	
2017-06-19 22:35:53,284 Epoch[22] Batch [580]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.114342,	
2017-06-19 22:35:57,598 Epoch[22] Batch [590]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.114181,	
2017-06-19 22:36:01,945 Epoch[22] Batch [600]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.114192,	
2017-06-19 22:36:06,283 Epoch[22] Batch [610]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.113965,	
2017-06-19 22:36:10,610 Epoch[22] Batch [620]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.113788,	
2017-06-19 22:36:14,677 Epoch[22] Batch [630]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113785,	
2017-06-19 22:36:19,011 Epoch[22] Batch [640]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.113793,	
2017-06-19 22:36:23,294 Epoch[22] Batch [650]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.113734,	
2017-06-19 22:36:27,658 Epoch[22] Batch [660]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.113615,	
2017-06-19 22:36:31,933 Epoch[22] Batch [670]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.113694,	
2017-06-19 22:36:36,053 Epoch[22] Batch [680]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.113738,	
2017-06-19 22:36:40,295 Epoch[22] Batch [690]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.113687,	
2017-06-19 22:36:44,644 Epoch[22] Batch [700]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.113519,	
2017-06-19 22:36:48,797 Epoch[22] Batch [710]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.113412,	
2017-06-19 22:36:53,006 Epoch[22] Batch [720]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.113132,	
2017-06-19 22:36:57,377 Epoch[22] Batch [730]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.112997,	
2017-06-19 22:37:01,495 Epoch[22] Batch [740]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112921,	
2017-06-19 22:37:05,744 Epoch[22] Batch [750]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.112895,	
2017-06-19 22:37:10,022 Epoch[22] Batch [760]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112855,	
2017-06-19 22:37:14,391 Epoch[22] Batch [770]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.112977,	
2017-06-19 22:37:18,632 Epoch[22] Batch [780]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.112887,	
2017-06-19 22:37:22,709 Epoch[22] Batch [790]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.112846,	
2017-06-19 22:37:26,823 Epoch[22] Batch [800]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112946,	
2017-06-19 22:37:31,005 Epoch[22] Batch [810]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112823,	
2017-06-19 22:37:35,035 Epoch[22] Batch [820]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112820,	
2017-06-19 22:37:39,133 Epoch[22] Batch [830]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112810,	
2017-06-19 22:37:43,253 Epoch[22] Batch [840]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112754,	
2017-06-19 22:37:47,520 Epoch[22] Batch [850]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.112668,	
2017-06-19 22:37:51,740 Epoch[22] Batch [860]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.112735,	
2017-06-19 22:37:56,155 Epoch[22] Batch [870]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.112640,	
2017-06-19 22:38:00,617 Epoch[22] Batch [880]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.112801,	
2017-06-19 22:38:04,908 Epoch[22] Batch [890]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.112787,	
2017-06-19 22:38:09,044 Epoch[22] Batch [900]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.112750,	
2017-06-19 22:38:13,213 Epoch[22] Batch [910]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.112790,	
2017-06-19 22:38:17,491 Epoch[22] Batch [920]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112783,	
2017-06-19 22:38:21,620 Epoch[22] Batch [930]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112930,	
2017-06-19 22:38:25,740 Epoch[22] Batch [940]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112995,	
2017-06-19 22:38:29,906 Epoch[22] Batch [950]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.113020,	
2017-06-19 22:38:34,109 Epoch[22] Batch [960]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.112984,	
2017-06-19 22:38:38,338 Epoch[22] Batch [970]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.112904,	
2017-06-19 22:38:42,609 Epoch[22] Batch [980]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.113008,	
2017-06-19 22:38:46,791 Epoch[22] Batch [990]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112996,	
2017-06-19 22:38:51,040 Epoch[22] Batch [1000]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.113065,	
2017-06-19 22:38:55,110 Epoch[22] Batch [1010]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.113554,	
2017-06-19 22:38:59,303 Epoch[22] Batch [1020]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.113773,	
2017-06-19 22:39:03,422 Epoch[22] Batch [1030]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.113909,	
2017-06-19 22:39:07,790 Epoch[22] Batch [1040]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.113905,	
2017-06-19 22:39:12,175 Epoch[22] Batch [1050]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.114091,	
2017-06-19 22:39:16,249 Epoch[22] Batch [1060]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114354,	
2017-06-19 22:39:20,589 Epoch[22] Batch [1070]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.114274,	
2017-06-19 22:39:24,832 Epoch[22] Batch [1080]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.114273,	
2017-06-19 22:39:29,102 Epoch[22] Batch [1090]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.114231,	
2017-06-19 22:39:33,394 Epoch[22] Batch [1100]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.114159,	
2017-06-19 22:39:37,479 Epoch[22] Batch [1110]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.114176,	
2017-06-19 22:39:41,653 Epoch[22] Batch [1120]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.113968,	
2017-06-19 22:39:45,809 Epoch[22] Batch [1130]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.113773,	
2017-06-19 22:39:50,005 Epoch[22] Batch [1140]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.113816,	
2017-06-19 22:39:53,935 Epoch[22] Batch [1150]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.113828,	
2017-06-19 22:39:58,043 Epoch[22] Batch [1160]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113897,	
2017-06-19 22:40:01,957 Epoch[22] Batch [1170]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.114129,	
2017-06-19 22:40:05,997 Epoch[22] Batch [1180]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114053,	
2017-06-19 22:40:10,082 Epoch[22] Batch [1190]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.114121,	
2017-06-19 22:40:13,960 Epoch[22] Batch [1200]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.114080,	
2017-06-19 22:40:18,124 Epoch[22] Batch [1210]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.114148,	
2017-06-19 22:40:22,142 Epoch[22] Batch [1220]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.114234,	
2017-06-19 22:40:26,345 Epoch[22] Batch [1230]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.114428,	
2017-06-19 22:40:30,445 Epoch[22] Batch [1240]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.114403,	
2017-06-19 22:40:34,541 Epoch[22] Batch [1250]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.114371,	
2017-06-19 22:40:38,683 Epoch[22] Batch [1260]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.114348,	
2017-06-19 22:40:42,783 Epoch[22] Batch [1270]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.114380,	
2017-06-19 22:40:46,973 Epoch[22] Batch [1280]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.114322,	
2017-06-19 22:40:51,150 Epoch[22] Batch [1290]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.114211,	
2017-06-19 22:40:55,044 Epoch[22] Batch [1300]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.114272,	
2017-06-19 22:40:59,175 Epoch[22] Batch [1310]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.114303,	
2017-06-19 22:41:03,285 Epoch[22] Batch [1320]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.114241,	
2017-06-19 22:41:07,194 Epoch[22] Batch [1330]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.114224,	
2017-06-19 22:41:11,277 Epoch[22] Batch [1340]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114157,	
2017-06-19 22:41:15,362 Epoch[22] Batch [1350]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.114148,	
2017-06-19 22:41:19,383 Epoch[22] Batch [1360]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.114103,	
2017-06-19 22:41:23,383 Epoch[22] Batch [1370]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.114029,	
2017-06-19 22:41:27,374 Epoch[22] Batch [1380]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.113969,	
2017-06-19 22:41:31,460 Epoch[22] Batch [1390]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.113843,	
2017-06-19 22:41:35,472 Epoch[22] Batch [1400]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.113843,	
2017-06-19 22:41:39,458 Epoch[22] Batch [1410]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.113805,	
2017-06-19 22:41:43,542 Epoch[22] Batch [1420]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.113721,	
2017-06-19 22:41:47,592 Epoch[22] Batch [1430]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113790,	
2017-06-19 22:41:51,781 Epoch[22] Batch [1440]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.113727,	
2017-06-19 22:41:56,013 Epoch[22] Batch [1450]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.113753,	
2017-06-19 22:41:59,935 Epoch[22] Batch [1460]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.113693,	
2017-06-19 22:42:04,067 Epoch[22] Batch [1470]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113610,	
2017-06-19 22:42:08,057 Epoch[22] Batch [1480]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.113610,	
2017-06-19 22:42:10,554 Epoch[22] Train-FCNLogLoss=0.113506
2017-06-19 22:42:10,554 Epoch[22] Time cost=615.124
2017-06-19 22:42:11,263 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0023.params"
2017-06-19 22:42:12,814 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0023.states"
2017-06-19 22:42:17,751 Epoch[23] Batch [10]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.107671,	
2017-06-19 22:42:21,833 Epoch[23] Batch [20]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116766,	
2017-06-19 22:42:26,016 Epoch[23] Batch [30]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.113600,	
2017-06-19 22:42:30,112 Epoch[23] Batch [40]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.114326,	
2017-06-19 22:42:34,091 Epoch[23] Batch [50]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.110804,	
2017-06-19 22:42:38,158 Epoch[23] Batch [60]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.109641,	
2017-06-19 22:42:42,270 Epoch[23] Batch [70]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.109168,	
2017-06-19 22:42:46,507 Epoch[23] Batch [80]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109395,	
2017-06-19 22:42:50,587 Epoch[23] Batch [90]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.107558,	
2017-06-19 22:42:54,485 Epoch[23] Batch [100]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.107333,	
2017-06-19 22:42:58,629 Epoch[23] Batch [110]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.107290,	
2017-06-19 22:43:02,584 Epoch[23] Batch [120]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.106971,	
2017-06-19 22:43:06,626 Epoch[23] Batch [130]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.107088,	
2017-06-19 22:43:10,750 Epoch[23] Batch [140]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.106741,	
2017-06-19 22:43:14,866 Epoch[23] Batch [150]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.106178,	
2017-06-19 22:43:18,844 Epoch[23] Batch [160]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.106017,	
2017-06-19 22:43:23,001 Epoch[23] Batch [170]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.105823,	
2017-06-19 22:43:27,044 Epoch[23] Batch [180]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.106046,	
2017-06-19 22:43:31,110 Epoch[23] Batch [190]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.106205,	
2017-06-19 22:43:35,082 Epoch[23] Batch [200]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.106777,	
2017-06-19 22:43:39,307 Epoch[23] Batch [210]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.106365,	
2017-06-19 22:43:43,400 Epoch[23] Batch [220]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105966,	
2017-06-19 22:43:47,418 Epoch[23] Batch [230]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105817,	
2017-06-19 22:43:51,427 Epoch[23] Batch [240]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105627,	
2017-06-19 22:43:55,452 Epoch[23] Batch [250]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105826,	
2017-06-19 22:43:59,386 Epoch[23] Batch [260]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.105596,	
2017-06-19 22:44:03,479 Epoch[23] Batch [270]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105618,	
2017-06-19 22:44:07,516 Epoch[23] Batch [280]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105471,	
2017-06-19 22:44:11,532 Epoch[23] Batch [290]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105653,	
2017-06-19 22:44:15,676 Epoch[23] Batch [300]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.105362,	
2017-06-19 22:44:19,778 Epoch[23] Batch [310]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105617,	
2017-06-19 22:44:23,839 Epoch[23] Batch [320]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.105354,	
2017-06-19 22:44:27,776 Epoch[23] Batch [330]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.105292,	
2017-06-19 22:44:31,810 Epoch[23] Batch [340]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105074,	
2017-06-19 22:44:35,882 Epoch[23] Batch [350]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105119,	
2017-06-19 22:44:39,807 Epoch[23] Batch [360]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.105124,	
2017-06-19 22:44:43,807 Epoch[23] Batch [370]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.104950,	
2017-06-19 22:44:48,015 Epoch[23] Batch [380]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.104943,	
2017-06-19 22:44:52,017 Epoch[23] Batch [390]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.104672,	
2017-06-19 22:44:56,153 Epoch[23] Batch [400]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104713,	
2017-06-19 22:45:00,258 Epoch[23] Batch [410]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.104676,	
2017-06-19 22:45:04,192 Epoch[23] Batch [420]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.104994,	
2017-06-19 22:45:08,243 Epoch[23] Batch [430]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105023,	
2017-06-19 22:45:12,317 Epoch[23] Batch [440]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104937,	
2017-06-19 22:45:16,347 Epoch[23] Batch [450]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104878,	
2017-06-19 22:45:20,333 Epoch[23] Batch [460]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.104766,	
2017-06-19 22:45:24,594 Epoch[23] Batch [470]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.104671,	
2017-06-19 22:45:28,794 Epoch[23] Batch [480]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.104644,	
2017-06-19 22:45:33,093 Epoch[23] Batch [490]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.104610,	
2017-06-19 22:45:37,407 Epoch[23] Batch [500]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.104389,	
2017-06-19 22:45:41,575 Epoch[23] Batch [510]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.104296,	
2017-06-19 22:45:45,825 Epoch[23] Batch [520]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.104316,	
2017-06-19 22:45:50,056 Epoch[23] Batch [530]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.104317,	
2017-06-19 22:45:54,209 Epoch[23] Batch [540]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104345,	
2017-06-19 22:45:58,312 Epoch[23] Batch [550]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104398,	
2017-06-19 22:46:02,780 Epoch[23] Batch [560]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.104476,	
2017-06-19 22:46:07,343 Epoch[23] Batch [570]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.104593,	
2017-06-19 22:46:11,536 Epoch[23] Batch [580]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.104669,	
2017-06-19 22:46:15,680 Epoch[23] Batch [590]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104473,	
2017-06-19 22:46:19,990 Epoch[23] Batch [600]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.104344,	
2017-06-19 22:46:24,114 Epoch[23] Batch [610]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.104185,	
2017-06-19 22:46:28,300 Epoch[23] Batch [620]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.104010,	
2017-06-19 22:46:32,313 Epoch[23] Batch [630]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.103876,	
2017-06-19 22:46:36,499 Epoch[23] Batch [640]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.103916,	
2017-06-19 22:46:40,770 Epoch[23] Batch [650]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.103890,	
2017-06-19 22:46:45,020 Epoch[23] Batch [660]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.103876,	
2017-06-19 22:46:49,243 Epoch[23] Batch [670]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.103804,	
2017-06-19 22:46:53,237 Epoch[23] Batch [680]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.103984,	
2017-06-19 22:46:57,488 Epoch[23] Batch [690]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.103790,	
2017-06-19 22:47:01,717 Epoch[23] Batch [700]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.103821,	
2017-06-19 22:47:06,026 Epoch[23] Batch [710]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.103819,	
2017-06-19 22:47:10,287 Epoch[23] Batch [720]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.104662,	
2017-06-19 22:47:14,366 Epoch[23] Batch [730]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105070,	
2017-06-19 22:47:18,647 Epoch[23] Batch [740]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.105190,	
2017-06-19 22:47:22,841 Epoch[23] Batch [750]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.105323,	
2017-06-19 22:47:27,165 Epoch[23] Batch [760]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.105400,	
2017-06-19 22:47:31,399 Epoch[23] Batch [770]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.105488,	
2017-06-19 22:47:35,668 Epoch[23] Batch [780]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.105598,	
2017-06-19 22:47:39,823 Epoch[23] Batch [790]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105484,	
2017-06-19 22:47:44,045 Epoch[23] Batch [800]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.105589,	
2017-06-19 22:47:48,434 Epoch[23] Batch [810]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.105543,	
2017-06-19 22:47:52,597 Epoch[23] Batch [820]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.105545,	
2017-06-19 22:47:56,870 Epoch[23] Batch [830]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.105745,	
2017-06-19 22:48:01,020 Epoch[23] Batch [840]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.105883,	
2017-06-19 22:48:05,207 Epoch[23] Batch [850]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.105976,	
2017-06-19 22:48:09,510 Epoch[23] Batch [860]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106109,	
2017-06-19 22:48:13,721 Epoch[23] Batch [870]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.105994,	
2017-06-19 22:48:17,712 Epoch[23] Batch [880]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.105939,	
2017-06-19 22:48:21,902 Epoch[23] Batch [890]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.105931,	
2017-06-19 22:48:25,926 Epoch[23] Batch [900]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.106015,	
2017-06-19 22:48:30,225 Epoch[23] Batch [910]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.106111,	
2017-06-19 22:48:34,517 Epoch[23] Batch [920]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.106140,	
2017-06-19 22:48:38,650 Epoch[23] Batch [930]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.106260,	
2017-06-19 22:48:43,146 Epoch[23] Batch [940]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.106073,	
2017-06-19 22:48:47,520 Epoch[23] Batch [950]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.106015,	
2017-06-19 22:48:51,833 Epoch[23] Batch [960]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.106049,	
2017-06-19 22:48:56,180 Epoch[23] Batch [970]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.106139,	
2017-06-19 22:49:00,389 Epoch[23] Batch [980]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.106072,	
2017-06-19 22:49:04,769 Epoch[23] Batch [990]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.106029,	
2017-06-19 22:49:09,035 Epoch[23] Batch [1000]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.106055,	
2017-06-19 22:49:13,419 Epoch[23] Batch [1010]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106013,	
2017-06-19 22:49:17,577 Epoch[23] Batch [1020]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.106137,	
2017-06-19 22:49:21,913 Epoch[23] Batch [1030]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.106063,	
2017-06-19 22:49:26,094 Epoch[23] Batch [1040]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.106048,	
2017-06-19 22:49:30,217 Epoch[23] Batch [1050]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.106147,	
2017-06-19 22:49:34,294 Epoch[23] Batch [1060]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.106193,	
2017-06-19 22:49:38,599 Epoch[23] Batch [1070]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.106140,	
2017-06-19 22:49:42,933 Epoch[23] Batch [1080]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.106224,	
2017-06-19 22:49:47,089 Epoch[23] Batch [1090]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.106155,	
2017-06-19 22:49:51,388 Epoch[23] Batch [1100]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106269,	
2017-06-19 22:49:55,619 Epoch[23] Batch [1110]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.106163,	
2017-06-19 22:49:59,709 Epoch[23] Batch [1120]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106110,	
2017-06-19 22:50:03,996 Epoch[23] Batch [1130]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.106171,	
2017-06-19 22:50:08,058 Epoch[23] Batch [1140]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.106257,	
2017-06-19 22:50:12,300 Epoch[23] Batch [1150]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.106206,	
2017-06-19 22:50:16,547 Epoch[23] Batch [1160]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.106237,	
2017-06-19 22:50:20,637 Epoch[23] Batch [1170]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106245,	
2017-06-19 22:50:24,831 Epoch[23] Batch [1180]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.106236,	
2017-06-19 22:50:28,935 Epoch[23] Batch [1190]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106188,	
2017-06-19 22:50:33,079 Epoch[23] Batch [1200]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.106082,	
2017-06-19 22:50:36,914 Epoch[23] Batch [1210]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.106022,	
2017-06-19 22:50:41,047 Epoch[23] Batch [1220]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.106045,	
2017-06-19 22:50:44,995 Epoch[23] Batch [1230]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105976,	
2017-06-19 22:50:48,804 Epoch[23] Batch [1240]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.105876,	
2017-06-19 22:50:52,848 Epoch[23] Batch [1250]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105803,	
2017-06-19 22:50:56,936 Epoch[23] Batch [1260]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105809,	
2017-06-19 22:51:01,079 Epoch[23] Batch [1270]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.105697,	
2017-06-19 22:51:05,174 Epoch[23] Batch [1280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105878,	
2017-06-19 22:51:09,273 Epoch[23] Batch [1290]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105895,	
2017-06-19 22:51:13,546 Epoch[23] Batch [1300]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.105975,	
2017-06-19 22:51:17,599 Epoch[23] Batch [1310]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105944,	
2017-06-19 22:51:21,681 Epoch[23] Batch [1320]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105910,	
2017-06-19 22:51:25,792 Epoch[23] Batch [1330]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105878,	
2017-06-19 22:51:29,800 Epoch[23] Batch [1340]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105898,	
2017-06-19 22:51:33,973 Epoch[23] Batch [1350]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.105939,	
2017-06-19 22:51:37,962 Epoch[23] Batch [1360]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105947,	
2017-06-19 22:51:42,002 Epoch[23] Batch [1370]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105946,	
2017-06-19 22:51:46,002 Epoch[23] Batch [1380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105905,	
2017-06-19 22:51:50,030 Epoch[23] Batch [1390]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105884,	
2017-06-19 22:51:54,230 Epoch[23] Batch [1400]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.105860,	
2017-06-19 22:51:58,163 Epoch[23] Batch [1410]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.105853,	
2017-06-19 22:52:02,156 Epoch[23] Batch [1420]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.105918,	
2017-06-19 22:52:06,201 Epoch[23] Batch [1430]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.105810,	
2017-06-19 22:52:10,356 Epoch[23] Batch [1440]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105795,	
2017-06-19 22:52:14,334 Epoch[23] Batch [1450]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.105730,	
2017-06-19 22:52:18,361 Epoch[23] Batch [1460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105752,	
2017-06-19 22:52:22,525 Epoch[23] Batch [1470]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.105761,	
2017-06-19 22:52:26,726 Epoch[23] Batch [1480]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.105722,	
2017-06-19 22:52:29,013 Epoch[23] Train-FCNLogLoss=0.105727
2017-06-19 22:52:29,013 Epoch[23] Time cost=616.198
2017-06-19 22:52:29,684 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0024.params"
2017-06-19 22:52:31,405 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0024.states"
2017-06-19 22:52:36,268 Epoch[24] Batch [10]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.103110,	
2017-06-19 22:52:40,263 Epoch[24] Batch [20]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.103972,	
2017-06-19 22:52:44,237 Epoch[24] Batch [30]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.101134,	
2017-06-19 22:52:48,393 Epoch[24] Batch [40]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.102993,	
2017-06-19 22:52:52,491 Epoch[24] Batch [50]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.103463,	
2017-06-19 22:52:56,431 Epoch[24] Batch [60]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.103928,	
2017-06-19 22:53:00,577 Epoch[24] Batch [70]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104148,	
2017-06-19 22:53:04,590 Epoch[24] Batch [80]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.104433,	
2017-06-19 22:53:08,781 Epoch[24] Batch [90]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.104269,	
2017-06-19 22:53:12,932 Epoch[24] Batch [100]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.103374,	
2017-06-19 22:53:16,943 Epoch[24] Batch [110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.102936,	
2017-06-19 22:53:20,974 Epoch[24] Batch [120]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103426,	
2017-06-19 22:53:25,169 Epoch[24] Batch [130]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103743,	
2017-06-19 22:53:29,324 Epoch[24] Batch [140]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104860,	
2017-06-19 22:53:33,290 Epoch[24] Batch [150]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.104091,	
2017-06-19 22:53:37,232 Epoch[24] Batch [160]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.104451,	
2017-06-19 22:53:41,294 Epoch[24] Batch [170]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104274,	
2017-06-19 22:53:45,431 Epoch[24] Batch [180]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104793,	
2017-06-19 22:53:49,560 Epoch[24] Batch [190]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.104551,	
2017-06-19 22:53:53,749 Epoch[24] Batch [200]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.104324,	
2017-06-19 22:53:57,947 Epoch[24] Batch [210]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.104591,	
2017-06-19 22:54:02,032 Epoch[24] Batch [220]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104390,	
2017-06-19 22:54:06,098 Epoch[24] Batch [230]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.104407,	
2017-06-19 22:54:10,198 Epoch[24] Batch [240]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104614,	
2017-06-19 22:54:14,396 Epoch[24] Batch [250]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.104640,	
2017-06-19 22:54:18,327 Epoch[24] Batch [260]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.104595,	
2017-06-19 22:54:22,511 Epoch[24] Batch [270]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.104544,	
2017-06-19 22:54:26,717 Epoch[24] Batch [280]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.104429,	
2017-06-19 22:54:30,798 Epoch[24] Batch [290]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.104589,	
2017-06-19 22:54:34,846 Epoch[24] Batch [300]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104581,	
2017-06-19 22:54:39,028 Epoch[24] Batch [310]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.104531,	
2017-06-19 22:54:43,249 Epoch[24] Batch [320]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.104533,	
2017-06-19 22:54:47,271 Epoch[24] Batch [330]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104619,	
2017-06-19 22:54:51,462 Epoch[24] Batch [340]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.104516,	
2017-06-19 22:54:55,609 Epoch[24] Batch [350]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104130,	
2017-06-19 22:54:59,689 Epoch[24] Batch [360]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103951,	
2017-06-19 22:55:03,740 Epoch[24] Batch [370]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104051,	
2017-06-19 22:55:07,775 Epoch[24] Batch [380]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104221,	
2017-06-19 22:55:11,813 Epoch[24] Batch [390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104385,	
2017-06-19 22:55:15,913 Epoch[24] Batch [400]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104221,	
2017-06-19 22:55:19,985 Epoch[24] Batch [410]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104283,	
2017-06-19 22:55:24,136 Epoch[24] Batch [420]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104169,	
2017-06-19 22:55:28,158 Epoch[24] Batch [430]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104389,	
2017-06-19 22:55:32,341 Epoch[24] Batch [440]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.104128,	
2017-06-19 22:55:36,350 Epoch[24] Batch [450]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.104268,	
2017-06-19 22:55:40,460 Epoch[24] Batch [460]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.104120,	
2017-06-19 22:55:44,614 Epoch[24] Batch [470]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.103960,	
2017-06-19 22:55:48,787 Epoch[24] Batch [480]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103948,	
2017-06-19 22:55:52,957 Epoch[24] Batch [490]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103919,	
2017-06-19 22:55:57,484 Epoch[24] Batch [500]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.104085,	
2017-06-19 22:56:02,041 Epoch[24] Batch [510]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.104315,	
2017-06-19 22:56:06,392 Epoch[24] Batch [520]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.104027,	
2017-06-19 22:56:10,451 Epoch[24] Batch [530]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.103898,	
2017-06-19 22:56:15,131 Epoch[24] Batch [540]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.103847,	
2017-06-19 22:56:19,646 Epoch[24] Batch [550]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.103721,	
2017-06-19 22:56:24,092 Epoch[24] Batch [560]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.103768,	
2017-06-19 22:56:28,610 Epoch[24] Batch [570]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.103705,	
2017-06-19 22:56:33,224 Epoch[24] Batch [580]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.103557,	
2017-06-19 22:56:37,606 Epoch[24] Batch [590]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.103513,	
2017-06-19 22:56:42,037 Epoch[24] Batch [600]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.103504,	
2017-06-19 22:56:46,594 Epoch[24] Batch [610]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.103429,	
2017-06-19 22:56:51,246 Epoch[24] Batch [620]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.103400,	
2017-06-19 22:56:55,568 Epoch[24] Batch [630]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.103272,	
2017-06-19 22:57:00,232 Epoch[24] Batch [640]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.103179,	
2017-06-19 22:57:04,526 Epoch[24] Batch [650]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.103280,	
2017-06-19 22:57:08,724 Epoch[24] Batch [660]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103308,	
2017-06-19 22:57:13,125 Epoch[24] Batch [670]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.103512,	
2017-06-19 22:57:17,387 Epoch[24] Batch [680]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.103364,	
2017-06-19 22:57:21,714 Epoch[24] Batch [690]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.103354,	
2017-06-19 22:57:26,117 Epoch[24] Batch [700]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.103322,	
2017-06-19 22:57:30,672 Epoch[24] Batch [710]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.103324,	
2017-06-19 22:57:34,993 Epoch[24] Batch [720]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.103240,	
2017-06-19 22:57:39,132 Epoch[24] Batch [730]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103295,	
2017-06-19 22:57:43,429 Epoch[24] Batch [740]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.103276,	
2017-06-19 22:57:47,952 Epoch[24] Batch [750]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.103269,	
2017-06-19 22:57:52,432 Epoch[24] Batch [760]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.103257,	
2017-06-19 22:57:56,506 Epoch[24] Batch [770]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.103279,	
2017-06-19 22:58:00,627 Epoch[24] Batch [780]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.103321,	
2017-06-19 22:58:04,684 Epoch[24] Batch [790]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.103245,	
2017-06-19 22:58:08,682 Epoch[24] Batch [800]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.103375,	
2017-06-19 22:58:12,725 Epoch[24] Batch [810]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.103359,	
2017-06-19 22:58:16,847 Epoch[24] Batch [820]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.103382,	
2017-06-19 22:58:21,017 Epoch[24] Batch [830]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103444,	
2017-06-19 22:58:25,126 Epoch[24] Batch [840]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103390,	
2017-06-19 22:58:29,254 Epoch[24] Batch [850]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.103240,	
2017-06-19 22:58:33,397 Epoch[24] Batch [860]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103210,	
2017-06-19 22:58:37,495 Epoch[24] Batch [870]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.103205,	
2017-06-19 22:58:41,671 Epoch[24] Batch [880]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.103198,	
2017-06-19 22:58:45,861 Epoch[24] Batch [890]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.103100,	
2017-06-19 22:58:49,974 Epoch[24] Batch [900]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103144,	
2017-06-19 22:58:54,108 Epoch[24] Batch [910]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103100,	
2017-06-19 22:58:58,130 Epoch[24] Batch [920]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103061,	
2017-06-19 22:59:02,246 Epoch[24] Batch [930]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103093,	
2017-06-19 22:59:06,351 Epoch[24] Batch [940]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103172,	
2017-06-19 22:59:10,515 Epoch[24] Batch [950]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.103236,	
2017-06-19 22:59:14,458 Epoch[24] Batch [960]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.103145,	
2017-06-19 22:59:18,783 Epoch[24] Batch [970]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.103205,	
2017-06-19 22:59:22,884 Epoch[24] Batch [980]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.103204,	
2017-06-19 22:59:26,987 Epoch[24] Batch [990]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.103229,	
2017-06-19 22:59:31,125 Epoch[24] Batch [1000]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103273,	
2017-06-19 22:59:35,207 Epoch[24] Batch [1010]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103213,	
2017-06-19 22:59:39,383 Epoch[24] Batch [1020]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.103213,	
2017-06-19 22:59:43,612 Epoch[24] Batch [1030]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.103553,	
2017-06-19 22:59:47,725 Epoch[24] Batch [1040]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103579,	
2017-06-19 22:59:51,968 Epoch[24] Batch [1050]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.103609,	
2017-06-19 22:59:55,954 Epoch[24] Batch [1060]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.103553,	
2017-06-19 23:00:00,096 Epoch[24] Batch [1070]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.103667,	
2017-06-19 23:00:04,299 Epoch[24] Batch [1080]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.103665,	
2017-06-19 23:00:08,433 Epoch[24] Batch [1090]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103627,	
2017-06-19 23:00:12,669 Epoch[24] Batch [1100]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.103569,	
2017-06-19 23:00:16,826 Epoch[24] Batch [1110]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.103522,	
2017-06-19 23:00:20,879 Epoch[24] Batch [1120]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.103493,	
2017-06-19 23:00:24,915 Epoch[24] Batch [1130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103486,	
2017-06-19 23:00:29,021 Epoch[24] Batch [1140]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103440,	
2017-06-19 23:00:33,279 Epoch[24] Batch [1150]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.103450,	
2017-06-19 23:00:37,245 Epoch[24] Batch [1160]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.103549,	
2017-06-19 23:00:41,332 Epoch[24] Batch [1170]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.103546,	
2017-06-19 23:00:45,479 Epoch[24] Batch [1180]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103508,	
2017-06-19 23:00:49,330 Epoch[24] Batch [1190]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.103530,	
2017-06-19 23:00:53,366 Epoch[24] Batch [1200]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103529,	
2017-06-19 23:00:57,442 Epoch[24] Batch [1210]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103388,	
2017-06-19 23:01:01,755 Epoch[24] Batch [1220]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.103538,	
2017-06-19 23:01:05,808 Epoch[24] Batch [1230]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.103461,	
2017-06-19 23:01:09,980 Epoch[24] Batch [1240]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103471,	
2017-06-19 23:01:14,115 Epoch[24] Batch [1250]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103521,	
2017-06-19 23:01:18,311 Epoch[24] Batch [1260]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103486,	
2017-06-19 23:01:22,490 Epoch[24] Batch [1270]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103471,	
2017-06-19 23:01:26,668 Epoch[24] Batch [1280]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103429,	
2017-06-19 23:01:30,695 Epoch[24] Batch [1290]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.103411,	
2017-06-19 23:01:34,813 Epoch[24] Batch [1300]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.103459,	
2017-06-19 23:01:38,964 Epoch[24] Batch [1310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.103412,	
2017-06-19 23:01:43,227 Epoch[24] Batch [1320]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.103498,	
2017-06-19 23:01:47,545 Epoch[24] Batch [1330]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.103442,	
2017-06-19 23:01:51,689 Epoch[24] Batch [1340]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103503,	
2017-06-19 23:01:55,776 Epoch[24] Batch [1350]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.103506,	
2017-06-19 23:01:59,971 Epoch[24] Batch [1360]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.103543,	
2017-06-19 23:02:04,114 Epoch[24] Batch [1370]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.103543,	
2017-06-19 23:02:08,245 Epoch[24] Batch [1380]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103648,	
2017-06-19 23:02:12,508 Epoch[24] Batch [1390]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.103625,	
2017-06-19 23:02:16,689 Epoch[24] Batch [1400]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103578,	
2017-06-19 23:02:20,859 Epoch[24] Batch [1410]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103533,	
2017-06-19 23:02:25,123 Epoch[24] Batch [1420]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.103484,	
2017-06-19 23:02:29,277 Epoch[24] Batch [1430]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.103570,	
2017-06-19 23:02:33,314 Epoch[24] Batch [1440]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103492,	
2017-06-19 23:02:37,525 Epoch[24] Batch [1450]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.103485,	
2017-06-19 23:02:41,659 Epoch[24] Batch [1460]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103475,	
2017-06-19 23:02:45,767 Epoch[24] Batch [1470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103554,	
2017-06-19 23:02:49,844 Epoch[24] Batch [1480]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103508,	
2017-06-19 23:02:52,199 Epoch[24] Train-FCNLogLoss=0.103532
2017-06-19 23:02:52,200 Epoch[24] Time cost=620.794
2017-06-19 23:02:52,894 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0025.params"
2017-06-19 23:02:54,706 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0025.states"
2017-06-19 23:02:59,560 Epoch[25] Batch [10]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112034,	
2017-06-19 23:03:03,733 Epoch[25] Batch [20]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.110436,	
2017-06-19 23:03:07,721 Epoch[25] Batch [30]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105573,	
2017-06-19 23:03:11,776 Epoch[25] Batch [40]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105108,	
2017-06-19 23:03:16,032 Epoch[25] Batch [50]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.104404,	
2017-06-19 23:03:20,217 Epoch[25] Batch [60]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.102051,	
2017-06-19 23:03:24,217 Epoch[25] Batch [70]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.101338,	
2017-06-19 23:03:28,409 Epoch[25] Batch [80]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.099457,	
2017-06-19 23:03:32,550 Epoch[25] Batch [90]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.098911,	
2017-06-19 23:03:36,738 Epoch[25] Batch [100]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.099233,	
2017-06-19 23:03:40,934 Epoch[25] Batch [110]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.099972,	
2017-06-19 23:03:45,139 Epoch[25] Batch [120]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.100427,	
2017-06-19 23:03:49,346 Epoch[25] Batch [130]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.100104,	
2017-06-19 23:03:53,426 Epoch[25] Batch [140]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100121,	
2017-06-19 23:03:57,644 Epoch[25] Batch [150]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.100167,	
2017-06-19 23:04:01,994 Epoch[25] Batch [160]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.100080,	
2017-06-19 23:04:06,028 Epoch[25] Batch [170]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.099996,	
2017-06-19 23:04:09,855 Epoch[25] Batch [180]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.100188,	
2017-06-19 23:04:14,222 Epoch[25] Batch [190]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.099908,	
2017-06-19 23:04:18,505 Epoch[25] Batch [200]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.099921,	
2017-06-19 23:04:22,701 Epoch[25] Batch [210]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100027,	
2017-06-19 23:04:26,772 Epoch[25] Batch [220]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.099577,	
2017-06-19 23:04:30,846 Epoch[25] Batch [230]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.099891,	
2017-06-19 23:04:34,847 Epoch[25] Batch [240]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.100124,	
2017-06-19 23:04:38,992 Epoch[25] Batch [250]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.100327,	
2017-06-19 23:04:43,146 Epoch[25] Batch [260]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.100734,	
2017-06-19 23:04:47,433 Epoch[25] Batch [270]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.100815,	
2017-06-19 23:04:51,700 Epoch[25] Batch [280]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.100672,	
2017-06-19 23:04:55,936 Epoch[25] Batch [290]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100758,	
2017-06-19 23:05:00,172 Epoch[25] Batch [300]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.101115,	
2017-06-19 23:05:04,187 Epoch[25] Batch [310]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101118,	
2017-06-19 23:05:08,278 Epoch[25] Batch [320]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101192,	
2017-06-19 23:05:12,434 Epoch[25] Batch [330]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101289,	
2017-06-19 23:05:16,553 Epoch[25] Batch [340]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.101541,	
2017-06-19 23:05:20,642 Epoch[25] Batch [350]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101500,	
2017-06-19 23:05:24,736 Epoch[25] Batch [360]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101756,	
2017-06-19 23:05:28,822 Epoch[25] Batch [370]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.101884,	
2017-06-19 23:05:32,927 Epoch[25] Batch [380]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.102296,	
2017-06-19 23:05:37,164 Epoch[25] Batch [390]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.102534,	
2017-06-19 23:05:41,205 Epoch[25] Batch [400]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.102679,	
2017-06-19 23:05:45,474 Epoch[25] Batch [410]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.102654,	
2017-06-19 23:05:49,778 Epoch[25] Batch [420]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.102671,	
2017-06-19 23:05:54,008 Epoch[25] Batch [430]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.102816,	
2017-06-19 23:05:58,154 Epoch[25] Batch [440]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.102933,	
2017-06-19 23:06:02,193 Epoch[25] Batch [450]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.102923,	
2017-06-19 23:06:06,341 Epoch[25] Batch [460]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.103111,	
2017-06-19 23:06:10,613 Epoch[25] Batch [470]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.103191,	
2017-06-19 23:06:14,718 Epoch[25] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.103324,	
2017-06-19 23:06:18,874 Epoch[25] Batch [490]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.103212,	
2017-06-19 23:06:22,951 Epoch[25] Batch [500]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103194,	
2017-06-19 23:06:27,085 Epoch[25] Batch [510]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103260,	
2017-06-19 23:06:31,201 Epoch[25] Batch [520]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103449,	
2017-06-19 23:06:35,366 Epoch[25] Batch [530]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.103638,	
2017-06-19 23:06:39,609 Epoch[25] Batch [540]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.103671,	
2017-06-19 23:06:43,686 Epoch[25] Batch [550]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103975,	
2017-06-19 23:06:47,674 Epoch[25] Batch [560]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.103896,	
2017-06-19 23:06:51,763 Epoch[25] Batch [570]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.103914,	
2017-06-19 23:06:55,896 Epoch[25] Batch [580]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.104134,	
2017-06-19 23:07:00,048 Epoch[25] Batch [590]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104106,	
2017-06-19 23:07:04,203 Epoch[25] Batch [600]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104069,	
2017-06-19 23:07:08,212 Epoch[25] Batch [610]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.104085,	
2017-06-19 23:07:12,411 Epoch[25] Batch [620]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103846,	
2017-06-19 23:07:16,523 Epoch[25] Batch [630]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103709,	
2017-06-19 23:07:20,581 Epoch[25] Batch [640]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.103778,	
2017-06-19 23:07:24,625 Epoch[25] Batch [650]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.103734,	
2017-06-19 23:07:28,712 Epoch[25] Batch [660]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.103754,	
2017-06-19 23:07:32,742 Epoch[25] Batch [670]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103597,	
2017-06-19 23:07:36,846 Epoch[25] Batch [680]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.103725,	
2017-06-19 23:07:40,963 Epoch[25] Batch [690]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103733,	
2017-06-19 23:07:44,954 Epoch[25] Batch [700]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.103889,	
2017-06-19 23:07:49,258 Epoch[25] Batch [710]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.103724,	
2017-06-19 23:07:53,425 Epoch[25] Batch [720]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.103733,	
2017-06-19 23:07:57,643 Epoch[25] Batch [730]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.103754,	
2017-06-19 23:08:01,914 Epoch[25] Batch [740]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.103839,	
2017-06-19 23:08:06,376 Epoch[25] Batch [750]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.103738,	
2017-06-19 23:08:10,919 Epoch[25] Batch [760]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.103584,	
2017-06-19 23:08:15,026 Epoch[25] Batch [770]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103629,	
2017-06-19 23:08:19,148 Epoch[25] Batch [780]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.103623,	
2017-06-19 23:08:23,353 Epoch[25] Batch [790]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.103639,	
2017-06-19 23:08:27,502 Epoch[25] Batch [800]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.103817,	
2017-06-19 23:08:31,685 Epoch[25] Batch [810]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.103753,	
2017-06-19 23:08:35,907 Epoch[25] Batch [820]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.103622,	
2017-06-19 23:08:40,066 Epoch[25] Batch [830]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.103517,	
2017-06-19 23:08:44,129 Epoch[25] Batch [840]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.103708,	
2017-06-19 23:08:48,133 Epoch[25] Batch [850]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.103716,	
2017-06-19 23:08:52,295 Epoch[25] Batch [860]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.103677,	
2017-06-19 23:08:56,591 Epoch[25] Batch [870]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.103602,	
2017-06-19 23:09:00,850 Epoch[25] Batch [880]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.103630,	
2017-06-19 23:09:05,123 Epoch[25] Batch [890]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.103632,	
2017-06-19 23:09:09,193 Epoch[25] Batch [900]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.103560,	
2017-06-19 23:09:13,388 Epoch[25] Batch [910]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.103730,	
2017-06-19 23:09:17,532 Epoch[25] Batch [920]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103773,	
2017-06-19 23:09:21,699 Epoch[25] Batch [930]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.103771,	
2017-06-19 23:09:25,877 Epoch[25] Batch [940]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103747,	
2017-06-19 23:09:30,164 Epoch[25] Batch [950]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.103658,	
2017-06-19 23:09:34,399 Epoch[25] Batch [960]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.103659,	
2017-06-19 23:09:38,741 Epoch[25] Batch [970]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.103680,	
2017-06-19 23:09:42,909 Epoch[25] Batch [980]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.103576,	
2017-06-19 23:09:47,114 Epoch[25] Batch [990]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.103573,	
2017-06-19 23:09:51,272 Epoch[25] Batch [1000]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.103566,	
2017-06-19 23:09:55,398 Epoch[25] Batch [1010]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.103508,	
2017-06-19 23:09:59,790 Epoch[25] Batch [1020]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.103438,	
2017-06-19 23:10:04,086 Epoch[25] Batch [1030]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.103396,	
2017-06-19 23:10:08,341 Epoch[25] Batch [1040]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.103360,	
2017-06-19 23:10:12,462 Epoch[25] Batch [1050]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.103313,	
2017-06-19 23:10:16,481 Epoch[25] Batch [1060]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103273,	
2017-06-19 23:10:20,861 Epoch[25] Batch [1070]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.103285,	
2017-06-19 23:10:25,161 Epoch[25] Batch [1080]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.103160,	
2017-06-19 23:10:29,481 Epoch[25] Batch [1090]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.103111,	
2017-06-19 23:10:33,654 Epoch[25] Batch [1100]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103047,	
2017-06-19 23:10:37,850 Epoch[25] Batch [1110]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103020,	
2017-06-19 23:10:41,984 Epoch[25] Batch [1120]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103188,	
2017-06-19 23:10:46,245 Epoch[25] Batch [1130]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.103118,	
2017-06-19 23:10:50,377 Epoch[25] Batch [1140]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103023,	
2017-06-19 23:10:54,657 Epoch[25] Batch [1150]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103153,	
2017-06-19 23:10:59,032 Epoch[25] Batch [1160]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.103134,	
2017-06-19 23:11:03,240 Epoch[25] Batch [1170]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.103125,	
2017-06-19 23:11:07,409 Epoch[25] Batch [1180]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103056,	
2017-06-19 23:11:11,677 Epoch[25] Batch [1190]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.102997,	
2017-06-19 23:11:15,963 Epoch[25] Batch [1200]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.102920,	
2017-06-19 23:11:20,231 Epoch[25] Batch [1210]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.102856,	
2017-06-19 23:11:24,416 Epoch[25] Batch [1220]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.102837,	
2017-06-19 23:11:28,630 Epoch[25] Batch [1230]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.102796,	
2017-06-19 23:11:32,855 Epoch[25] Batch [1240]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.102751,	
2017-06-19 23:11:36,901 Epoch[25] Batch [1250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.102673,	
2017-06-19 23:11:41,133 Epoch[25] Batch [1260]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.102637,	
2017-06-19 23:11:45,319 Epoch[25] Batch [1270]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.102616,	
2017-06-19 23:11:49,914 Epoch[25] Batch [1280]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.102607,	
2017-06-19 23:11:54,116 Epoch[25] Batch [1290]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.102645,	
2017-06-19 23:11:58,606 Epoch[25] Batch [1300]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.102632,	
2017-06-19 23:12:03,232 Epoch[25] Batch [1310]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.102709,	
2017-06-19 23:12:08,177 Epoch[25] Batch [1320]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.102846,	
2017-06-19 23:12:12,568 Epoch[25] Batch [1330]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.102833,	
2017-06-19 23:12:17,055 Epoch[25] Batch [1340]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.102856,	
2017-06-19 23:12:21,461 Epoch[25] Batch [1350]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.102893,	
2017-06-19 23:12:25,970 Epoch[25] Batch [1360]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.103064,	
2017-06-19 23:12:30,531 Epoch[25] Batch [1370]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.103245,	
2017-06-19 23:12:35,091 Epoch[25] Batch [1380]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.103213,	
2017-06-19 23:12:39,649 Epoch[25] Batch [1390]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.103226,	
2017-06-19 23:12:43,951 Epoch[25] Batch [1400]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.103258,	
2017-06-19 23:12:48,526 Epoch[25] Batch [1410]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.103373,	
2017-06-19 23:12:52,899 Epoch[25] Batch [1420]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.103419,	
2017-06-19 23:12:57,367 Epoch[25] Batch [1430]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.103414,	
2017-06-19 23:13:02,162 Epoch[25] Batch [1440]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.103586,	
2017-06-19 23:13:06,812 Epoch[25] Batch [1450]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.103563,	
2017-06-19 23:13:11,097 Epoch[25] Batch [1460]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.103576,	
2017-06-19 23:13:15,408 Epoch[25] Batch [1470]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.103649,	
2017-06-19 23:13:19,684 Epoch[25] Batch [1480]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103663,	
2017-06-19 23:13:22,071 Epoch[25] Train-FCNLogLoss=0.103654
2017-06-19 23:13:22,071 Epoch[25] Time cost=627.365
2017-06-19 23:13:22,855 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0026.params"
2017-06-19 23:13:24,458 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0026.states"
2017-06-19 23:13:29,570 Epoch[26] Batch [10]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.100317,	
2017-06-19 23:13:33,890 Epoch[26] Batch [20]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.107272,	
2017-06-19 23:13:38,516 Epoch[26] Batch [30]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.107731,	
2017-06-19 23:13:42,658 Epoch[26] Batch [40]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.107811,	
2017-06-19 23:13:46,662 Epoch[26] Batch [50]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.105768,	
2017-06-19 23:13:50,863 Epoch[26] Batch [60]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.106121,	
2017-06-19 23:13:54,916 Epoch[26] Batch [70]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104792,	
2017-06-19 23:13:59,077 Epoch[26] Batch [80]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.102700,	
2017-06-19 23:14:03,353 Epoch[26] Batch [90]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.102766,	
2017-06-19 23:14:07,249 Epoch[26] Batch [100]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.103094,	
2017-06-19 23:14:11,276 Epoch[26] Batch [110]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.102919,	
2017-06-19 23:14:15,419 Epoch[26] Batch [120]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.102177,	
2017-06-19 23:14:19,452 Epoch[26] Batch [130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101956,	
2017-06-19 23:14:23,526 Epoch[26] Batch [140]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.102398,	
2017-06-19 23:14:27,711 Epoch[26] Batch [150]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.102680,	
2017-06-19 23:14:31,848 Epoch[26] Batch [160]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101656,	
2017-06-19 23:14:35,945 Epoch[26] Batch [170]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.102364,	
2017-06-19 23:14:40,245 Epoch[26] Batch [180]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.101937,	
2017-06-19 23:14:44,369 Epoch[26] Batch [190]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.102142,	
2017-06-19 23:14:48,460 Epoch[26] Batch [200]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.102136,	
2017-06-19 23:14:52,620 Epoch[26] Batch [210]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101899,	
2017-06-19 23:14:56,736 Epoch[26] Batch [220]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.101935,	
2017-06-19 23:15:00,893 Epoch[26] Batch [230]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101610,	
2017-06-19 23:15:05,029 Epoch[26] Batch [240]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101769,	
2017-06-19 23:15:09,105 Epoch[26] Batch [250]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101842,	
2017-06-19 23:15:13,272 Epoch[26] Batch [260]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.101655,	
2017-06-19 23:15:17,236 Epoch[26] Batch [270]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.101619,	
2017-06-19 23:15:21,414 Epoch[26] Batch [280]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.101258,	
2017-06-19 23:15:25,552 Epoch[26] Batch [290]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101226,	
2017-06-19 23:15:29,589 Epoch[26] Batch [300]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101317,	
2017-06-19 23:15:33,756 Epoch[26] Batch [310]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.101329,	
2017-06-19 23:15:37,861 Epoch[26] Batch [320]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.101553,	
2017-06-19 23:15:42,168 Epoch[26] Batch [330]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.101519,	
2017-06-19 23:15:46,391 Epoch[26] Batch [340]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.101293,	
2017-06-19 23:15:50,616 Epoch[26] Batch [350]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.101147,	
2017-06-19 23:15:54,724 Epoch[26] Batch [360]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.100931,	
2017-06-19 23:15:58,954 Epoch[26] Batch [370]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100744,	
2017-06-19 23:16:02,993 Epoch[26] Batch [380]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.100638,	
2017-06-19 23:16:07,039 Epoch[26] Batch [390]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.100407,	
2017-06-19 23:16:11,283 Epoch[26] Batch [400]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100338,	
2017-06-19 23:16:15,420 Epoch[26] Batch [410]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.100586,	
2017-06-19 23:16:19,637 Epoch[26] Batch [420]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.100493,	
2017-06-19 23:16:23,732 Epoch[26] Batch [430]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100470,	
2017-06-19 23:16:27,815 Epoch[26] Batch [440]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100404,	
2017-06-19 23:16:31,906 Epoch[26] Batch [450]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100163,	
2017-06-19 23:16:36,106 Epoch[26] Batch [460]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.100123,	
2017-06-19 23:16:40,401 Epoch[26] Batch [470]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.100129,	
2017-06-19 23:16:44,488 Epoch[26] Batch [480]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100227,	
2017-06-19 23:16:48,648 Epoch[26] Batch [490]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.100274,	
2017-06-19 23:16:52,846 Epoch[26] Batch [500]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100481,	
2017-06-19 23:16:57,159 Epoch[26] Batch [510]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.100561,	
2017-06-19 23:17:01,358 Epoch[26] Batch [520]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100707,	
2017-06-19 23:17:05,294 Epoch[26] Batch [530]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.100625,	
2017-06-19 23:17:09,488 Epoch[26] Batch [540]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.100729,	
2017-06-19 23:17:13,544 Epoch[26] Batch [550]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100598,	
2017-06-19 23:17:17,754 Epoch[26] Batch [560]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.100445,	
2017-06-19 23:17:21,691 Epoch[26] Batch [570]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.100682,	
2017-06-19 23:17:25,917 Epoch[26] Batch [580]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.100662,	
2017-06-19 23:17:30,078 Epoch[26] Batch [590]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.100493,	
2017-06-19 23:17:34,181 Epoch[26] Batch [600]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.100531,	
2017-06-19 23:17:38,314 Epoch[26] Batch [610]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.100572,	
2017-06-19 23:17:42,448 Epoch[26] Batch [620]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.100476,	
2017-06-19 23:17:46,586 Epoch[26] Batch [630]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.100489,	
2017-06-19 23:17:50,620 Epoch[26] Batch [640]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100521,	
2017-06-19 23:17:54,833 Epoch[26] Batch [650]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.100527,	
2017-06-19 23:17:58,923 Epoch[26] Batch [660]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100535,	
2017-06-19 23:18:02,918 Epoch[26] Batch [670]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.100531,	
2017-06-19 23:18:07,202 Epoch[26] Batch [680]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.100710,	
2017-06-19 23:18:11,362 Epoch[26] Batch [690]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.100858,	
2017-06-19 23:18:15,443 Epoch[26] Batch [700]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101113,	
2017-06-19 23:18:19,542 Epoch[26] Batch [710]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.101057,	
2017-06-19 23:18:23,616 Epoch[26] Batch [720]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101201,	
2017-06-19 23:18:27,787 Epoch[26] Batch [730]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.101292,	
2017-06-19 23:18:31,990 Epoch[26] Batch [740]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.101327,	
2017-06-19 23:18:36,150 Epoch[26] Batch [750]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101319,	
2017-06-19 23:18:40,396 Epoch[26] Batch [760]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.101347,	
2017-06-19 23:18:44,485 Epoch[26] Batch [770]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101264,	
2017-06-19 23:18:48,728 Epoch[26] Batch [780]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.101306,	
2017-06-19 23:18:52,976 Epoch[26] Batch [790]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.101203,	
2017-06-19 23:18:57,057 Epoch[26] Batch [800]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101200,	
2017-06-19 23:19:01,130 Epoch[26] Batch [810]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101307,	
2017-06-19 23:19:05,108 Epoch[26] Batch [820]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.101172,	
2017-06-19 23:19:09,149 Epoch[26] Batch [830]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.101062,	
2017-06-19 23:19:13,214 Epoch[26] Batch [840]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.101016,	
2017-06-19 23:19:17,254 Epoch[26] Batch [850]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.101050,	
2017-06-19 23:19:21,509 Epoch[26] Batch [860]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.100863,	
2017-06-19 23:19:25,705 Epoch[26] Batch [870]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100862,	
2017-06-19 23:19:29,990 Epoch[26] Batch [880]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.100864,	
2017-06-19 23:19:34,133 Epoch[26] Batch [890]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.100929,	
2017-06-19 23:19:38,423 Epoch[26] Batch [900]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.100920,	
2017-06-19 23:19:42,674 Epoch[26] Batch [910]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.101020,	
2017-06-19 23:19:46,913 Epoch[26] Batch [920]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100928,	
2017-06-19 23:19:51,258 Epoch[26] Batch [930]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.100933,	
2017-06-19 23:19:55,359 Epoch[26] Batch [940]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.101009,	
2017-06-19 23:19:59,562 Epoch[26] Batch [950]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.101219,	
2017-06-19 23:20:03,757 Epoch[26] Batch [960]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.101346,	
2017-06-19 23:20:07,885 Epoch[26] Batch [970]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.101401,	
2017-06-19 23:20:12,044 Epoch[26] Batch [980]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101580,	
2017-06-19 23:20:16,152 Epoch[26] Batch [990]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.101528,	
2017-06-19 23:20:20,297 Epoch[26] Batch [1000]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.101571,	
2017-06-19 23:20:24,522 Epoch[26] Batch [1010]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.101666,	
2017-06-19 23:20:28,691 Epoch[26] Batch [1020]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.101732,	
2017-06-19 23:20:32,808 Epoch[26] Batch [1030]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.101691,	
2017-06-19 23:20:36,945 Epoch[26] Batch [1040]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101708,	
2017-06-19 23:20:41,168 Epoch[26] Batch [1050]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.101840,	
2017-06-19 23:20:45,352 Epoch[26] Batch [1060]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.101904,	
2017-06-19 23:20:49,509 Epoch[26] Batch [1070]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101956,	
2017-06-19 23:20:53,527 Epoch[26] Batch [1080]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101958,	
2017-06-19 23:20:57,709 Epoch[26] Batch [1090]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.102038,	
2017-06-19 23:21:01,942 Epoch[26] Batch [1100]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.102031,	
2017-06-19 23:21:06,163 Epoch[26] Batch [1110]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.102060,	
2017-06-19 23:21:10,351 Epoch[26] Batch [1120]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.102112,	
2017-06-19 23:21:14,649 Epoch[26] Batch [1130]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.102073,	
2017-06-19 23:21:18,793 Epoch[26] Batch [1140]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.102055,	
2017-06-19 23:21:22,823 Epoch[26] Batch [1150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.102097,	
2017-06-19 23:21:26,962 Epoch[26] Batch [1160]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.102295,	
2017-06-19 23:21:31,246 Epoch[26] Batch [1170]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.102410,	
2017-06-19 23:21:35,403 Epoch[26] Batch [1180]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.102461,	
2017-06-19 23:21:39,497 Epoch[26] Batch [1190]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.102543,	
2017-06-19 23:21:43,699 Epoch[26] Batch [1200]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.102591,	
2017-06-19 23:21:47,814 Epoch[26] Batch [1210]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.102696,	
2017-06-19 23:21:51,912 Epoch[26] Batch [1220]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.102703,	
2017-06-19 23:21:56,133 Epoch[26] Batch [1230]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.102785,	
2017-06-19 23:22:00,264 Epoch[26] Batch [1240]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.102849,	
2017-06-19 23:22:04,423 Epoch[26] Batch [1250]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.102890,	
2017-06-19 23:22:08,545 Epoch[26] Batch [1260]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.102886,	
2017-06-19 23:22:12,671 Epoch[26] Batch [1270]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.103190,	
2017-06-19 23:22:16,644 Epoch[26] Batch [1280]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.103187,	
2017-06-19 23:22:20,811 Epoch[26] Batch [1290]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.103209,	
2017-06-19 23:22:24,849 Epoch[26] Batch [1300]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103249,	
2017-06-19 23:22:28,963 Epoch[26] Batch [1310]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103361,	
2017-06-19 23:22:32,924 Epoch[26] Batch [1320]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.103288,	
2017-06-19 23:22:37,018 Epoch[26] Batch [1330]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.103308,	
2017-06-19 23:22:41,126 Epoch[26] Batch [1340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103328,	
2017-06-19 23:22:45,009 Epoch[26] Batch [1350]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.103386,	
2017-06-19 23:22:49,192 Epoch[26] Batch [1360]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.103311,	
2017-06-19 23:22:53,337 Epoch[26] Batch [1370]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.103312,	
2017-06-19 23:22:57,497 Epoch[26] Batch [1380]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.103268,	
2017-06-19 23:23:01,627 Epoch[26] Batch [1390]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.103198,	
2017-06-19 23:23:05,736 Epoch[26] Batch [1400]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103173,	
2017-06-19 23:23:09,961 Epoch[26] Batch [1410]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.103083,	
2017-06-19 23:23:14,062 Epoch[26] Batch [1420]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.103050,	
2017-06-19 23:23:17,982 Epoch[26] Batch [1430]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.103072,	
2017-06-19 23:23:22,121 Epoch[26] Batch [1440]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103102,	
2017-06-19 23:23:26,262 Epoch[26] Batch [1450]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.103193,	
2017-06-19 23:23:30,342 Epoch[26] Batch [1460]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103271,	
2017-06-19 23:23:34,434 Epoch[26] Batch [1470]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.103263,	
2017-06-19 23:23:38,634 Epoch[26] Batch [1480]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.103380,	
2017-06-19 23:23:41,112 Epoch[26] Train-FCNLogLoss=0.103395
2017-06-19 23:23:41,112 Epoch[26] Time cost=616.653
2017-06-19 23:23:41,769 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0027.params"
2017-06-19 23:23:43,472 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0027.states"
2017-06-19 23:23:48,332 Epoch[27] Batch [10]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094626,	
2017-06-19 23:23:52,316 Epoch[27] Batch [20]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.102725,	
2017-06-19 23:23:56,764 Epoch[27] Batch [30]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.102537,	
2017-06-19 23:24:01,084 Epoch[27] Batch [40]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.106043,	
2017-06-19 23:24:05,319 Epoch[27] Batch [50]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.106980,	
2017-06-19 23:24:09,752 Epoch[27] Batch [60]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.106137,	
2017-06-19 23:24:13,970 Epoch[27] Batch [70]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.105321,	
2017-06-19 23:24:18,252 Epoch[27] Batch [80]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.103926,	
2017-06-19 23:24:22,422 Epoch[27] Batch [90]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103208,	
2017-06-19 23:24:26,550 Epoch[27] Batch [100]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.102546,	
2017-06-19 23:24:30,782 Epoch[27] Batch [110]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.101886,	
2017-06-19 23:24:35,012 Epoch[27] Batch [120]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.101743,	
2017-06-19 23:24:39,205 Epoch[27] Batch [130]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.102416,	
2017-06-19 23:24:43,404 Epoch[27] Batch [140]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103388,	
2017-06-19 23:24:47,671 Epoch[27] Batch [150]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.103029,	
2017-06-19 23:24:51,788 Epoch[27] Batch [160]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103272,	
2017-06-19 23:24:55,938 Epoch[27] Batch [170]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.103105,	
2017-06-19 23:25:00,201 Epoch[27] Batch [180]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.103567,	
2017-06-19 23:25:04,511 Epoch[27] Batch [190]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.103354,	
2017-06-19 23:25:08,660 Epoch[27] Batch [200]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.103131,	
2017-06-19 23:25:12,898 Epoch[27] Batch [210]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.102790,	
2017-06-19 23:25:17,245 Epoch[27] Batch [220]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.102666,	
2017-06-19 23:25:21,420 Epoch[27] Batch [230]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.102771,	
2017-06-19 23:25:25,637 Epoch[27] Batch [240]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.102426,	
2017-06-19 23:25:29,814 Epoch[27] Batch [250]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.102282,	
2017-06-19 23:25:34,101 Epoch[27] Batch [260]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.102424,	
2017-06-19 23:25:38,222 Epoch[27] Batch [270]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.102191,	
2017-06-19 23:25:42,595 Epoch[27] Batch [280]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.102023,	
2017-06-19 23:25:46,737 Epoch[27] Batch [290]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.102521,	
2017-06-19 23:25:50,733 Epoch[27] Batch [300]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.102827,	
2017-06-19 23:25:54,913 Epoch[27] Batch [310]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.102360,	
2017-06-19 23:25:59,025 Epoch[27] Batch [320]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.102460,	
2017-06-19 23:26:03,310 Epoch[27] Batch [330]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.102431,	
2017-06-19 23:26:07,560 Epoch[27] Batch [340]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.102021,	
2017-06-19 23:26:11,685 Epoch[27] Batch [350]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.101939,	
2017-06-19 23:26:15,916 Epoch[27] Batch [360]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.101809,	
2017-06-19 23:26:20,283 Epoch[27] Batch [370]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101840,	
2017-06-19 23:26:24,515 Epoch[27] Batch [380]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.101884,	
2017-06-19 23:26:28,806 Epoch[27] Batch [390]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.101563,	
2017-06-19 23:26:32,976 Epoch[27] Batch [400]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.101348,	
2017-06-19 23:26:37,246 Epoch[27] Batch [410]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.101260,	
2017-06-19 23:26:41,284 Epoch[27] Batch [420]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101335,	
2017-06-19 23:26:45,550 Epoch[27] Batch [430]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.101158,	
2017-06-19 23:26:49,801 Epoch[27] Batch [440]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.101250,	
2017-06-19 23:26:54,090 Epoch[27] Batch [450]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.101076,	
2017-06-19 23:26:58,354 Epoch[27] Batch [460]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.100960,	
2017-06-19 23:27:02,385 Epoch[27] Batch [470]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101003,	
2017-06-19 23:27:06,691 Epoch[27] Batch [480]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.101278,	
2017-06-19 23:27:10,911 Epoch[27] Batch [490]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.101164,	
2017-06-19 23:27:15,084 Epoch[27] Batch [500]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.100995,	
2017-06-19 23:27:19,300 Epoch[27] Batch [510]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.100803,	
2017-06-19 23:27:23,527 Epoch[27] Batch [520]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.101017,	
2017-06-19 23:27:27,862 Epoch[27] Batch [530]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.101174,	
2017-06-19 23:27:32,124 Epoch[27] Batch [540]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.101021,	
2017-06-19 23:27:36,456 Epoch[27] Batch [550]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.100954,	
2017-06-19 23:27:40,508 Epoch[27] Batch [560]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.100858,	
2017-06-19 23:27:44,710 Epoch[27] Batch [570]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.100907,	
2017-06-19 23:27:48,947 Epoch[27] Batch [580]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.101028,	
2017-06-19 23:27:53,313 Epoch[27] Batch [590]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101042,	
2017-06-19 23:27:57,728 Epoch[27] Batch [600]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.101152,	
2017-06-19 23:28:01,907 Epoch[27] Batch [610]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.101218,	
2017-06-19 23:28:06,170 Epoch[27] Batch [620]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.101169,	
2017-06-19 23:28:10,460 Epoch[27] Batch [630]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.101131,	
2017-06-19 23:28:14,596 Epoch[27] Batch [640]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.101477,	
2017-06-19 23:28:19,134 Epoch[27] Batch [650]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.101307,	
2017-06-19 23:28:23,355 Epoch[27] Batch [660]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.101368,	
2017-06-19 23:28:27,732 Epoch[27] Batch [670]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.101141,	
2017-06-19 23:28:31,989 Epoch[27] Batch [680]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.101205,	
2017-06-19 23:28:36,089 Epoch[27] Batch [690]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.101041,	
2017-06-19 23:28:40,298 Epoch[27] Batch [700]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.101068,	
2017-06-19 23:28:44,545 Epoch[27] Batch [710]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.101037,	
2017-06-19 23:28:48,636 Epoch[27] Batch [720]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101216,	
2017-06-19 23:28:52,637 Epoch[27] Batch [730]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.101178,	
2017-06-19 23:28:56,729 Epoch[27] Batch [740]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101130,	
2017-06-19 23:29:00,839 Epoch[27] Batch [750]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.101214,	
2017-06-19 23:29:04,808 Epoch[27] Batch [760]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.101281,	
2017-06-19 23:29:08,883 Epoch[27] Batch [770]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101198,	
2017-06-19 23:29:12,912 Epoch[27] Batch [780]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.101228,	
2017-06-19 23:29:17,082 Epoch[27] Batch [790]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.101263,	
2017-06-19 23:29:21,038 Epoch[27] Batch [800]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.101329,	
2017-06-19 23:29:25,063 Epoch[27] Batch [810]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.101285,	
2017-06-19 23:29:29,042 Epoch[27] Batch [820]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.101410,	
2017-06-19 23:29:33,246 Epoch[27] Batch [830]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.101313,	
2017-06-19 23:29:37,263 Epoch[27] Batch [840]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101390,	
2017-06-19 23:29:41,181 Epoch[27] Batch [850]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.101435,	
2017-06-19 23:29:45,258 Epoch[27] Batch [860]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101668,	
2017-06-19 23:29:49,201 Epoch[27] Batch [870]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.101687,	
2017-06-19 23:29:53,338 Epoch[27] Batch [880]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101886,	
2017-06-19 23:29:57,352 Epoch[27] Batch [890]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101958,	
2017-06-19 23:30:01,284 Epoch[27] Batch [900]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.101859,	
2017-06-19 23:30:05,222 Epoch[27] Batch [910]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.101807,	
2017-06-19 23:30:09,291 Epoch[27] Batch [920]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101770,	
2017-06-19 23:30:13,346 Epoch[27] Batch [930]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.101678,	
2017-06-19 23:30:17,299 Epoch[27] Batch [940]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.101674,	
2017-06-19 23:30:21,413 Epoch[27] Batch [950]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.101658,	
2017-06-19 23:30:25,595 Epoch[27] Batch [960]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.101628,	
2017-06-19 23:30:29,657 Epoch[27] Batch [970]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101592,	
2017-06-19 23:30:33,712 Epoch[27] Batch [980]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101524,	
2017-06-19 23:30:37,729 Epoch[27] Batch [990]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101589,	
2017-06-19 23:30:41,714 Epoch[27] Batch [1000]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.101756,	
2017-06-19 23:30:45,845 Epoch[27] Batch [1010]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.101766,	
2017-06-19 23:30:49,820 Epoch[27] Batch [1020]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.101863,	
2017-06-19 23:30:53,927 Epoch[27] Batch [1030]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.101818,	
2017-06-19 23:30:58,060 Epoch[27] Batch [1040]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.101743,	
2017-06-19 23:31:02,169 Epoch[27] Batch [1050]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.101724,	
2017-06-19 23:31:06,246 Epoch[27] Batch [1060]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101804,	
2017-06-19 23:31:10,414 Epoch[27] Batch [1070]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.101801,	
2017-06-19 23:31:14,435 Epoch[27] Batch [1080]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.102080,	
2017-06-19 23:31:18,620 Epoch[27] Batch [1090]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.102246,	
2017-06-19 23:31:22,742 Epoch[27] Batch [1100]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.102500,	
2017-06-19 23:31:26,900 Epoch[27] Batch [1110]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.102791,	
2017-06-19 23:31:30,866 Epoch[27] Batch [1120]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.102911,	
2017-06-19 23:31:34,993 Epoch[27] Batch [1130]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.103595,	
2017-06-19 23:31:39,132 Epoch[27] Batch [1140]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104323,	
2017-06-19 23:31:43,176 Epoch[27] Batch [1150]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104865,	
2017-06-19 23:31:47,343 Epoch[27] Batch [1160]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.106622,	
2017-06-19 23:31:51,381 Epoch[27] Batch [1170]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.107555,	
2017-06-19 23:31:55,432 Epoch[27] Batch [1180]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108107,	
2017-06-19 23:31:59,528 Epoch[27] Batch [1190]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108501,	
2017-06-19 23:32:03,651 Epoch[27] Batch [1200]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.108756,	
2017-06-19 23:32:07,744 Epoch[27] Batch [1210]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108989,	
2017-06-19 23:32:11,878 Epoch[27] Batch [1220]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.109147,	
2017-06-19 23:32:15,892 Epoch[27] Batch [1230]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.109155,	
2017-06-19 23:32:19,964 Epoch[27] Batch [1240]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.109257,	
2017-06-19 23:32:23,948 Epoch[27] Batch [1250]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.109257,	
2017-06-19 23:32:28,120 Epoch[27] Batch [1260]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.109452,	
2017-06-19 23:32:32,127 Epoch[27] Batch [1270]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109626,	
2017-06-19 23:32:36,316 Epoch[27] Batch [1280]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.109729,	
2017-06-19 23:32:40,372 Epoch[27] Batch [1290]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.109864,	
2017-06-19 23:32:44,527 Epoch[27] Batch [1300]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.109892,	
2017-06-19 23:32:48,541 Epoch[27] Batch [1310]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.109922,	
2017-06-19 23:32:52,619 Epoch[27] Batch [1320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109986,	
2017-06-19 23:32:56,814 Epoch[27] Batch [1330]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.109991,	
2017-06-19 23:33:00,927 Epoch[27] Batch [1340]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.109985,	
2017-06-19 23:33:05,028 Epoch[27] Batch [1350]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.110251,	
2017-06-19 23:33:09,083 Epoch[27] Batch [1360]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110407,	
2017-06-19 23:33:13,110 Epoch[27] Batch [1370]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110530,	
2017-06-19 23:33:17,167 Epoch[27] Batch [1380]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110458,	
2017-06-19 23:33:21,160 Epoch[27] Batch [1390]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110522,	
2017-06-19 23:33:25,214 Epoch[27] Batch [1400]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.110573,	
2017-06-19 23:33:29,238 Epoch[27] Batch [1410]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.110506,	
2017-06-19 23:33:33,366 Epoch[27] Batch [1420]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.110431,	
2017-06-19 23:33:37,454 Epoch[27] Batch [1430]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110454,	
2017-06-19 23:33:41,538 Epoch[27] Batch [1440]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.110396,	
2017-06-19 23:33:45,571 Epoch[27] Batch [1450]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110501,	
2017-06-19 23:33:49,620 Epoch[27] Batch [1460]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.110458,	
2017-06-19 23:33:53,718 Epoch[27] Batch [1470]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.110506,	
2017-06-19 23:33:57,809 Epoch[27] Batch [1480]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110481,	
2017-06-19 23:34:00,297 Epoch[27] Train-FCNLogLoss=0.110483
2017-06-19 23:34:00,297 Epoch[27] Time cost=616.825
2017-06-19 23:34:00,945 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0028.params"
2017-06-19 23:34:02,430 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0028.states"
2017-06-19 23:34:07,275 Epoch[28] Batch [10]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.099851,	
2017-06-19 23:34:11,317 Epoch[28] Batch [20]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.099198,	
2017-06-19 23:34:15,551 Epoch[28] Batch [30]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.097497,	
2017-06-19 23:34:19,619 Epoch[28] Batch [40]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.099183,	
2017-06-19 23:34:23,795 Epoch[28] Batch [50]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.101771,	
2017-06-19 23:34:28,092 Epoch[28] Batch [60]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.103070,	
2017-06-19 23:34:32,384 Epoch[28] Batch [70]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.102331,	
2017-06-19 23:34:36,735 Epoch[28] Batch [80]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.102396,	
2017-06-19 23:34:41,043 Epoch[28] Batch [90]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.103884,	
2017-06-19 23:34:45,138 Epoch[28] Batch [100]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.104198,	
2017-06-19 23:34:49,181 Epoch[28] Batch [110]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104793,	
2017-06-19 23:34:53,246 Epoch[28] Batch [120]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.104930,	
2017-06-19 23:34:57,498 Epoch[28] Batch [130]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.104139,	
2017-06-19 23:35:01,697 Epoch[28] Batch [140]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103919,	
2017-06-19 23:35:05,837 Epoch[28] Batch [150]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.104692,	
2017-06-19 23:35:10,100 Epoch[28] Batch [160]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.105572,	
2017-06-19 23:35:14,318 Epoch[28] Batch [170]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.106007,	
2017-06-19 23:35:18,654 Epoch[28] Batch [180]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.105727,	
2017-06-19 23:35:22,977 Epoch[28] Batch [190]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.106777,	
2017-06-19 23:35:27,190 Epoch[28] Batch [200]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.106892,	
2017-06-19 23:35:31,123 Epoch[28] Batch [210]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.106849,	
2017-06-19 23:35:35,311 Epoch[28] Batch [220]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.106607,	
2017-06-19 23:35:39,671 Epoch[28] Batch [230]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.106422,	
2017-06-19 23:35:44,002 Epoch[28] Batch [240]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.106659,	
2017-06-19 23:35:48,011 Epoch[28] Batch [250]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.106831,	
2017-06-19 23:35:52,461 Epoch[28] Batch [260]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.107029,	
2017-06-19 23:35:56,571 Epoch[28] Batch [270]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.106549,	
2017-06-19 23:36:00,704 Epoch[28] Batch [280]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.106648,	
2017-06-19 23:36:04,896 Epoch[28] Batch [290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.106772,	
2017-06-19 23:36:09,177 Epoch[28] Batch [300]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.106630,	
2017-06-19 23:36:13,401 Epoch[28] Batch [310]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.106400,	
2017-06-19 23:36:17,639 Epoch[28] Batch [320]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.106281,	
2017-06-19 23:36:21,794 Epoch[28] Batch [330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.106074,	
2017-06-19 23:36:25,947 Epoch[28] Batch [340]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105875,	
2017-06-19 23:36:30,157 Epoch[28] Batch [350]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.105984,	
2017-06-19 23:36:34,537 Epoch[28] Batch [360]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.105680,	
2017-06-19 23:36:38,821 Epoch[28] Batch [370]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.105588,	
2017-06-19 23:36:43,124 Epoch[28] Batch [380]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.105404,	
2017-06-19 23:36:47,358 Epoch[28] Batch [390]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.105300,	
2017-06-19 23:36:51,671 Epoch[28] Batch [400]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.104930,	
2017-06-19 23:36:55,775 Epoch[28] Batch [410]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104890,	
2017-06-19 23:37:00,431 Epoch[28] Batch [420]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.104722,	
2017-06-19 23:37:04,827 Epoch[28] Batch [430]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.104769,	
2017-06-19 23:37:09,278 Epoch[28] Batch [440]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.104718,	
2017-06-19 23:37:13,785 Epoch[28] Batch [450]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.104526,	
2017-06-19 23:37:18,216 Epoch[28] Batch [460]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.104650,	
2017-06-19 23:37:22,859 Epoch[28] Batch [470]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.104398,	
2017-06-19 23:37:27,211 Epoch[28] Batch [480]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.104299,	
2017-06-19 23:37:31,753 Epoch[28] Batch [490]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.104301,	
2017-06-19 23:37:36,405 Epoch[28] Batch [500]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.104147,	
2017-06-19 23:37:41,029 Epoch[28] Batch [510]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.104002,	
2017-06-19 23:37:45,366 Epoch[28] Batch [520]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.103826,	
2017-06-19 23:37:49,730 Epoch[28] Batch [530]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.103801,	
2017-06-19 23:37:54,171 Epoch[28] Batch [540]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.103807,	
2017-06-19 23:37:58,823 Epoch[28] Batch [550]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.103976,	
2017-06-19 23:38:03,063 Epoch[28] Batch [560]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.103916,	
2017-06-19 23:38:07,838 Epoch[28] Batch [570]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.103920,	
2017-06-19 23:38:12,265 Epoch[28] Batch [580]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.103706,	
2017-06-19 23:38:16,781 Epoch[28] Batch [590]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.103831,	
2017-06-19 23:38:21,220 Epoch[28] Batch [600]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.103876,	
2017-06-19 23:38:25,842 Epoch[28] Batch [610]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.103662,	
2017-06-19 23:38:30,294 Epoch[28] Batch [620]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.103587,	
2017-06-19 23:38:34,598 Epoch[28] Batch [630]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.103768,	
2017-06-19 23:38:39,274 Epoch[28] Batch [640]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.103804,	
2017-06-19 23:38:44,176 Epoch[28] Batch [650]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.103864,	
2017-06-19 23:38:48,440 Epoch[28] Batch [660]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.103855,	
2017-06-19 23:38:52,908 Epoch[28] Batch [670]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.103693,	
2017-06-19 23:38:57,684 Epoch[28] Batch [680]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.103521,	
2017-06-19 23:39:02,150 Epoch[28] Batch [690]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.103476,	
2017-06-19 23:39:06,796 Epoch[28] Batch [700]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.103440,	
2017-06-19 23:39:11,421 Epoch[28] Batch [710]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.103320,	
2017-06-19 23:39:15,906 Epoch[28] Batch [720]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.103285,	
2017-06-19 23:39:20,441 Epoch[28] Batch [730]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.103341,	
2017-06-19 23:39:24,917 Epoch[28] Batch [740]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.103311,	
2017-06-19 23:39:29,162 Epoch[28] Batch [750]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.103402,	
2017-06-19 23:39:33,397 Epoch[28] Batch [760]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.103476,	
2017-06-19 23:39:37,835 Epoch[28] Batch [770]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.103365,	
2017-06-19 23:39:42,473 Epoch[28] Batch [780]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.103244,	
2017-06-19 23:39:46,891 Epoch[28] Batch [790]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.103105,	
2017-06-19 23:39:51,380 Epoch[28] Batch [800]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.102941,	
2017-06-19 23:39:55,640 Epoch[28] Batch [810]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.102838,	
2017-06-19 23:40:00,298 Epoch[28] Batch [820]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.102834,	
2017-06-19 23:40:04,705 Epoch[28] Batch [830]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.102805,	
2017-06-19 23:40:09,079 Epoch[28] Batch [840]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.102912,	
2017-06-19 23:40:13,596 Epoch[28] Batch [850]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.103050,	
2017-06-19 23:40:17,949 Epoch[28] Batch [860]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.103078,	
2017-06-19 23:40:22,365 Epoch[28] Batch [870]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103156,	
2017-06-19 23:40:26,985 Epoch[28] Batch [880]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.103083,	
2017-06-19 23:40:31,341 Epoch[28] Batch [890]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.103136,	
2017-06-19 23:40:35,716 Epoch[28] Batch [900]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.103041,	
2017-06-19 23:40:40,328 Epoch[28] Batch [910]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.103035,	
2017-06-19 23:40:44,856 Epoch[28] Batch [920]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.102982,	
2017-06-19 23:40:49,436 Epoch[28] Batch [930]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.103111,	
2017-06-19 23:40:53,790 Epoch[28] Batch [940]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.102972,	
2017-06-19 23:40:58,647 Epoch[28] Batch [950]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.102821,	
2017-06-19 23:41:02,898 Epoch[28] Batch [960]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.102654,	
2017-06-19 23:41:07,171 Epoch[28] Batch [970]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.102616,	
2017-06-19 23:41:11,813 Epoch[28] Batch [980]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.102567,	
2017-06-19 23:41:16,517 Epoch[28] Batch [990]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.102520,	
2017-06-19 23:41:20,570 Epoch[28] Batch [1000]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.102545,	
2017-06-19 23:41:25,083 Epoch[28] Batch [1010]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.102375,	
2017-06-19 23:41:29,524 Epoch[28] Batch [1020]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.102381,	
2017-06-19 23:41:33,862 Epoch[28] Batch [1030]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.102396,	
2017-06-19 23:41:38,509 Epoch[28] Batch [1040]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.102384,	
2017-06-19 23:41:43,287 Epoch[28] Batch [1050]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.102411,	
2017-06-19 23:41:47,509 Epoch[28] Batch [1060]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.102327,	
2017-06-19 23:41:51,829 Epoch[28] Batch [1070]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.102361,	
2017-06-19 23:41:56,171 Epoch[28] Batch [1080]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.102377,	
2017-06-19 23:42:00,699 Epoch[28] Batch [1090]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.102344,	
2017-06-19 23:42:05,354 Epoch[28] Batch [1100]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.102261,	
2017-06-19 23:42:10,047 Epoch[28] Batch [1110]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.102241,	
2017-06-19 23:42:14,649 Epoch[28] Batch [1120]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.102131,	
2017-06-19 23:42:19,381 Epoch[28] Batch [1130]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.102035,	
2017-06-19 23:42:23,986 Epoch[28] Batch [1140]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.102018,	
2017-06-19 23:42:28,452 Epoch[28] Batch [1150]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.102027,	
2017-06-19 23:42:33,000 Epoch[28] Batch [1160]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.101967,	
2017-06-19 23:42:37,636 Epoch[28] Batch [1170]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.101975,	
2017-06-19 23:42:42,138 Epoch[28] Batch [1180]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.101946,	
2017-06-19 23:42:46,975 Epoch[28] Batch [1190]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.101958,	
2017-06-19 23:42:51,341 Epoch[28] Batch [1200]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101989,	
2017-06-19 23:42:55,772 Epoch[28] Batch [1210]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.102050,	
2017-06-19 23:43:00,391 Epoch[28] Batch [1220]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.102064,	
2017-06-19 23:43:05,013 Epoch[28] Batch [1230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.102062,	
2017-06-19 23:43:09,303 Epoch[28] Batch [1240]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.102069,	
2017-06-19 23:43:13,912 Epoch[28] Batch [1250]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.102109,	
2017-06-19 23:43:18,374 Epoch[28] Batch [1260]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.102108,	
2017-06-19 23:43:22,935 Epoch[28] Batch [1270]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.102078,	
2017-06-19 23:43:27,462 Epoch[28] Batch [1280]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.101988,	
2017-06-19 23:43:32,108 Epoch[28] Batch [1290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.101988,	
2017-06-19 23:43:36,810 Epoch[28] Batch [1300]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.102005,	
2017-06-19 23:43:41,358 Epoch[28] Batch [1310]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.102051,	
2017-06-19 23:43:45,841 Epoch[28] Batch [1320]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.102076,	
2017-06-19 23:43:50,279 Epoch[28] Batch [1330]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.102048,	
2017-06-19 23:43:54,696 Epoch[28] Batch [1340]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.102168,	
2017-06-19 23:43:59,118 Epoch[28] Batch [1350]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.102235,	
2017-06-19 23:44:03,854 Epoch[28] Batch [1360]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.102297,	
2017-06-19 23:44:08,351 Epoch[28] Batch [1370]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.102271,	
2017-06-19 23:44:12,567 Epoch[28] Batch [1380]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.102310,	
2017-06-19 23:44:16,917 Epoch[28] Batch [1390]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.102226,	
2017-06-19 23:44:21,110 Epoch[28] Batch [1400]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.102205,	
2017-06-19 23:44:25,487 Epoch[28] Batch [1410]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.102175,	
2017-06-19 23:44:29,961 Epoch[28] Batch [1420]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102166,	
2017-06-19 23:44:34,327 Epoch[28] Batch [1430]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.102170,	
2017-06-19 23:44:39,030 Epoch[28] Batch [1440]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.102200,	
2017-06-19 23:44:43,731 Epoch[28] Batch [1450]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.102272,	
2017-06-19 23:44:48,498 Epoch[28] Batch [1460]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.102272,	
2017-06-19 23:44:53,080 Epoch[28] Batch [1470]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.102191,	
2017-06-19 23:44:57,483 Epoch[28] Batch [1480]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.102220,	
2017-06-19 23:45:00,192 Epoch[28] Train-FCNLogLoss=0.102201
2017-06-19 23:45:00,192 Epoch[28] Time cost=657.762
2017-06-19 23:45:01,020 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0029.params"
2017-06-19 23:45:02,635 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0029.states"
2017-06-19 23:45:07,767 Epoch[29] Batch [10]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.093841,	
2017-06-19 23:45:12,307 Epoch[29] Batch [20]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.095217,	
2017-06-19 23:45:17,049 Epoch[29] Batch [30]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.095173,	
2017-06-19 23:45:21,590 Epoch[29] Batch [40]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.094814,	
2017-06-19 23:45:25,956 Epoch[29] Batch [50]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.096331,	
2017-06-19 23:45:30,537 Epoch[29] Batch [60]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.096945,	
2017-06-19 23:45:35,067 Epoch[29] Batch [70]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.097643,	
2017-06-19 23:45:39,805 Epoch[29] Batch [80]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.097110,	
2017-06-19 23:45:44,247 Epoch[29] Batch [90]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.098330,	
2017-06-19 23:45:49,073 Epoch[29] Batch [100]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.098152,	
2017-06-19 23:45:53,552 Epoch[29] Batch [110]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.097904,	
2017-06-19 23:45:57,766 Epoch[29] Batch [120]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.097632,	
2017-06-19 23:46:02,216 Epoch[29] Batch [130]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.097791,	
2017-06-19 23:46:06,899 Epoch[29] Batch [140]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.097794,	
2017-06-19 23:46:11,321 Epoch[29] Batch [150]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.098416,	
2017-06-19 23:46:15,385 Epoch[29] Batch [160]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.098290,	
2017-06-19 23:46:19,756 Epoch[29] Batch [170]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.098044,	
2017-06-19 23:46:24,349 Epoch[29] Batch [180]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.098638,	
2017-06-19 23:46:28,750 Epoch[29] Batch [190]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098861,	
2017-06-19 23:46:33,200 Epoch[29] Batch [200]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.099107,	
2017-06-19 23:46:38,076 Epoch[29] Batch [210]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.099261,	
2017-06-19 23:46:42,417 Epoch[29] Batch [220]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.098830,	
2017-06-19 23:46:46,938 Epoch[29] Batch [230]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.098510,	
2017-06-19 23:46:51,439 Epoch[29] Batch [240]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.098555,	
2017-06-19 23:46:55,730 Epoch[29] Batch [250]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.098348,	
2017-06-19 23:47:00,219 Epoch[29] Batch [260]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.097927,	
2017-06-19 23:47:04,653 Epoch[29] Batch [270]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.097701,	
2017-06-19 23:47:09,307 Epoch[29] Batch [280]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.097820,	
2017-06-19 23:47:13,710 Epoch[29] Batch [290]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.097784,	
2017-06-19 23:47:18,393 Epoch[29] Batch [300]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.097961,	
2017-06-19 23:47:22,704 Epoch[29] Batch [310]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097979,	
2017-06-19 23:47:27,283 Epoch[29] Batch [320]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.098392,	
2017-06-19 23:47:31,856 Epoch[29] Batch [330]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.098297,	
2017-06-19 23:47:36,522 Epoch[29] Batch [340]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.098159,	
2017-06-19 23:47:40,940 Epoch[29] Batch [350]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.098120,	
2017-06-19 23:47:45,655 Epoch[29] Batch [360]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.097921,	
2017-06-19 23:47:50,037 Epoch[29] Batch [370]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.097708,	
2017-06-19 23:47:54,347 Epoch[29] Batch [380]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097487,	
2017-06-19 23:47:58,882 Epoch[29] Batch [390]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.097554,	
2017-06-19 23:48:03,344 Epoch[29] Batch [400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.097552,	
2017-06-19 23:48:07,857 Epoch[29] Batch [410]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.097435,	
2017-06-19 23:48:12,378 Epoch[29] Batch [420]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097464,	
2017-06-19 23:48:17,030 Epoch[29] Batch [430]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.097486,	
2017-06-19 23:48:21,711 Epoch[29] Batch [440]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.097074,	
2017-06-19 23:48:26,030 Epoch[29] Batch [450]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097031,	
2017-06-19 23:48:30,529 Epoch[29] Batch [460]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.097078,	
2017-06-19 23:48:35,172 Epoch[29] Batch [470]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.097160,	
2017-06-19 23:48:39,522 Epoch[29] Batch [480]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.097137,	
2017-06-19 23:48:43,663 Epoch[29] Batch [490]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097245,	
2017-06-19 23:48:48,269 Epoch[29] Batch [500]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.097217,	
2017-06-19 23:48:52,670 Epoch[29] Batch [510]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.097298,	
2017-06-19 23:48:57,027 Epoch[29] Batch [520]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.097351,	
2017-06-19 23:49:01,470 Epoch[29] Batch [530]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.097365,	
2017-06-19 23:49:05,942 Epoch[29] Batch [540]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.097296,	
2017-06-19 23:49:10,068 Epoch[29] Batch [550]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097199,	
2017-06-19 23:49:14,852 Epoch[29] Batch [560]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.097296,	
2017-06-19 23:49:19,439 Epoch[29] Batch [570]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.097425,	
2017-06-19 23:49:23,768 Epoch[29] Batch [580]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.097395,	
2017-06-19 23:49:28,349 Epoch[29] Batch [590]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.097304,	
2017-06-19 23:49:32,687 Epoch[29] Batch [600]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.097328,	
2017-06-19 23:49:37,154 Epoch[29] Batch [610]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097258,	
2017-06-19 23:49:41,342 Epoch[29] Batch [620]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.097349,	
2017-06-19 23:49:45,732 Epoch[29] Batch [630]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097445,	
2017-06-19 23:49:50,064 Epoch[29] Batch [640]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.097388,	
2017-06-19 23:49:54,363 Epoch[29] Batch [650]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.097683,	
2017-06-19 23:49:58,909 Epoch[29] Batch [660]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.097898,	
2017-06-19 23:50:03,116 Epoch[29] Batch [670]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.097710,	
2017-06-19 23:50:07,508 Epoch[29] Batch [680]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097866,	
2017-06-19 23:50:11,899 Epoch[29] Batch [690]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097936,	
2017-06-19 23:50:16,527 Epoch[29] Batch [700]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.097801,	
2017-06-19 23:50:21,046 Epoch[29] Batch [710]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097898,	
2017-06-19 23:50:25,643 Epoch[29] Batch [720]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.097991,	
2017-06-19 23:50:30,141 Epoch[29] Batch [730]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.098023,	
2017-06-19 23:50:34,364 Epoch[29] Batch [740]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.097928,	
2017-06-19 23:50:38,574 Epoch[29] Batch [750]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.098057,	
2017-06-19 23:50:43,255 Epoch[29] Batch [760]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.098149,	
2017-06-19 23:50:47,749 Epoch[29] Batch [770]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.098110,	
2017-06-19 23:50:52,293 Epoch[29] Batch [780]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.098071,	
2017-06-19 23:50:56,784 Epoch[29] Batch [790]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.097974,	
2017-06-19 23:51:01,162 Epoch[29] Batch [800]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.098021,	
2017-06-19 23:51:05,794 Epoch[29] Batch [810]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.098007,	
2017-06-19 23:51:10,287 Epoch[29] Batch [820]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.097933,	
2017-06-19 23:51:14,604 Epoch[29] Batch [830]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.097939,	
2017-06-19 23:51:18,989 Epoch[29] Batch [840]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.098123,	
2017-06-19 23:51:23,191 Epoch[29] Batch [850]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.098194,	
2017-06-19 23:51:27,739 Epoch[29] Batch [860]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.098274,	
2017-06-19 23:51:32,253 Epoch[29] Batch [870]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.098125,	
2017-06-19 23:51:36,726 Epoch[29] Batch [880]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.098186,	
2017-06-19 23:51:41,127 Epoch[29] Batch [890]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098135,	
2017-06-19 23:51:45,504 Epoch[29] Batch [900]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.098071,	
2017-06-19 23:51:49,948 Epoch[29] Batch [910]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.098087,	
2017-06-19 23:51:54,532 Epoch[29] Batch [920]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.098171,	
2017-06-19 23:51:58,652 Epoch[29] Batch [930]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.098177,	
2017-06-19 23:52:02,931 Epoch[29] Batch [940]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.098233,	
2017-06-19 23:52:07,271 Epoch[29] Batch [950]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.098384,	
2017-06-19 23:52:11,713 Epoch[29] Batch [960]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.098512,	
2017-06-19 23:52:16,223 Epoch[29] Batch [970]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.098665,	
2017-06-19 23:52:20,777 Epoch[29] Batch [980]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.098726,	
2017-06-19 23:52:25,357 Epoch[29] Batch [990]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.098687,	
2017-06-19 23:52:30,205 Epoch[29] Batch [1000]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.098814,	
2017-06-19 23:52:34,590 Epoch[29] Batch [1010]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.098733,	
2017-06-19 23:52:38,954 Epoch[29] Batch [1020]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.098809,	
2017-06-19 23:52:43,371 Epoch[29] Batch [1030]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.098859,	
2017-06-19 23:52:47,984 Epoch[29] Batch [1040]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.098894,	
2017-06-19 23:52:52,431 Epoch[29] Batch [1050]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.098913,	
2017-06-19 23:52:57,320 Epoch[29] Batch [1060]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.098969,	
2017-06-19 23:53:01,923 Epoch[29] Batch [1070]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.098955,	
2017-06-19 23:53:06,570 Epoch[29] Batch [1080]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.099026,	
2017-06-19 23:53:11,007 Epoch[29] Batch [1090]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.098997,	
2017-06-19 23:53:15,656 Epoch[29] Batch [1100]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.099005,	
2017-06-19 23:53:20,198 Epoch[29] Batch [1110]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.099000,	
2017-06-19 23:53:24,494 Epoch[29] Batch [1120]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.098982,	
2017-06-19 23:53:29,084 Epoch[29] Batch [1130]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.099053,	
2017-06-19 23:53:33,622 Epoch[29] Batch [1140]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.099177,	
2017-06-19 23:53:37,962 Epoch[29] Batch [1150]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.099190,	
2017-06-19 23:53:42,707 Epoch[29] Batch [1160]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099286,	
2017-06-19 23:53:47,317 Epoch[29] Batch [1170]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.099278,	
2017-06-19 23:53:51,777 Epoch[29] Batch [1180]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.099256,	
2017-06-19 23:53:56,387 Epoch[29] Batch [1190]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.099276,	
2017-06-19 23:54:00,895 Epoch[29] Batch [1200]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.099230,	
2017-06-19 23:54:05,252 Epoch[29] Batch [1210]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.099294,	
2017-06-19 23:54:09,884 Epoch[29] Batch [1220]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.099260,	
2017-06-19 23:54:14,374 Epoch[29] Batch [1230]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.099241,	
2017-06-19 23:54:19,091 Epoch[29] Batch [1240]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.099233,	
2017-06-19 23:54:23,577 Epoch[29] Batch [1250]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.099257,	
2017-06-19 23:54:27,932 Epoch[29] Batch [1260]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.099332,	
2017-06-19 23:54:32,510 Epoch[29] Batch [1270]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.099371,	
2017-06-19 23:54:36,901 Epoch[29] Batch [1280]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.099453,	
2017-06-19 23:54:41,038 Epoch[29] Batch [1290]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.099363,	
2017-06-19 23:54:45,423 Epoch[29] Batch [1300]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.099388,	
2017-06-19 23:54:50,072 Epoch[29] Batch [1310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.099431,	
2017-06-19 23:54:54,640 Epoch[29] Batch [1320]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.099342,	
2017-06-19 23:54:59,318 Epoch[29] Batch [1330]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.099297,	
2017-06-19 23:55:03,890 Epoch[29] Batch [1340]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.099243,	
2017-06-19 23:55:08,396 Epoch[29] Batch [1350]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.099247,	
2017-06-19 23:55:12,749 Epoch[29] Batch [1360]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.099244,	
2017-06-19 23:55:17,256 Epoch[29] Batch [1370]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.099188,	
2017-06-19 23:55:21,672 Epoch[29] Batch [1380]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.099160,	
2017-06-19 23:55:26,011 Epoch[29] Batch [1390]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.099133,	
2017-06-19 23:55:30,318 Epoch[29] Batch [1400]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.099125,	
2017-06-19 23:55:34,781 Epoch[29] Batch [1410]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.099126,	
2017-06-19 23:55:39,352 Epoch[29] Batch [1420]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.099088,	
2017-06-19 23:55:43,937 Epoch[29] Batch [1430]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.099035,	
2017-06-19 23:55:48,513 Epoch[29] Batch [1440]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.098976,	
2017-06-19 23:55:53,164 Epoch[29] Batch [1450]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.098938,	
2017-06-19 23:55:57,532 Epoch[29] Batch [1460]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.098975,	
2017-06-19 23:56:02,019 Epoch[29] Batch [1470]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.098926,	
2017-06-19 23:56:06,757 Epoch[29] Batch [1480]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.098897,	
2017-06-19 23:56:09,338 Epoch[29] Train-FCNLogLoss=0.098855
2017-06-19 23:56:09,338 Epoch[29] Time cost=666.702
2017-06-19 23:56:10,131 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0030.params"
2017-06-19 23:56:11,872 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0030.states"
2017-06-19 23:56:17,333 Epoch[30] Batch [10]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087375,	
2017-06-19 23:56:21,872 Epoch[30] Batch [20]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090671,	
2017-06-19 23:56:26,258 Epoch[30] Batch [30]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.091619,	
2017-06-19 23:56:30,627 Epoch[30] Batch [40]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.094439,	
2017-06-19 23:56:34,842 Epoch[30] Batch [50]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.093813,	
2017-06-19 23:56:39,102 Epoch[30] Batch [60]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094178,	
2017-06-19 23:56:43,612 Epoch[30] Batch [70]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.092598,	
2017-06-19 23:56:48,392 Epoch[30] Batch [80]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.091760,	
2017-06-19 23:56:53,077 Epoch[30] Batch [90]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092511,	
2017-06-19 23:56:57,652 Epoch[30] Batch [100]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092057,	
2017-06-19 23:57:02,116 Epoch[30] Batch [110]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.092304,	
2017-06-19 23:57:06,497 Epoch[30] Batch [120]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.092491,	
2017-06-19 23:57:11,067 Epoch[30] Batch [130]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.093070,	
2017-06-19 23:57:15,813 Epoch[30] Batch [140]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.093434,	
2017-06-19 23:57:20,135 Epoch[30] Batch [150]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.094877,	
2017-06-19 23:57:24,603 Epoch[30] Batch [160]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.094988,	
2017-06-19 23:57:28,906 Epoch[30] Batch [170]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.095835,	
2017-06-19 23:57:33,234 Epoch[30] Batch [180]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.095348,	
2017-06-19 23:57:37,881 Epoch[30] Batch [190]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.095825,	
2017-06-19 23:57:42,547 Epoch[30] Batch [200]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.096893,	
2017-06-19 23:57:46,994 Epoch[30] Batch [210]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.098531,	
2017-06-19 23:57:51,621 Epoch[30] Batch [220]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.098315,	
2017-06-19 23:57:56,000 Epoch[30] Batch [230]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.098020,	
2017-06-19 23:58:00,609 Epoch[30] Batch [240]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.098126,	
2017-06-19 23:58:05,134 Epoch[30] Batch [250]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.098320,	
2017-06-19 23:58:09,733 Epoch[30] Batch [260]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.098114,	
2017-06-19 23:58:14,236 Epoch[30] Batch [270]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.098333,	
2017-06-19 23:58:18,703 Epoch[30] Batch [280]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.098475,	
2017-06-19 23:58:23,382 Epoch[30] Batch [290]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.098314,	
2017-06-19 23:58:27,871 Epoch[30] Batch [300]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.097992,	
2017-06-19 23:58:32,213 Epoch[30] Batch [310]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.098049,	
2017-06-19 23:58:36,700 Epoch[30] Batch [320]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.097958,	
2017-06-19 23:58:41,186 Epoch[30] Batch [330]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.097769,	
2017-06-19 23:58:45,909 Epoch[30] Batch [340]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.097563,	
2017-06-19 23:58:50,465 Epoch[30] Batch [350]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.097494,	
2017-06-19 23:58:55,318 Epoch[30] Batch [360]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.097730,	
2017-06-19 23:58:59,804 Epoch[30] Batch [370]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.097571,	
2017-06-19 23:59:04,260 Epoch[30] Batch [380]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.097555,	
2017-06-19 23:59:08,780 Epoch[30] Batch [390]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097667,	
2017-06-19 23:59:13,171 Epoch[30] Batch [400]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097667,	
2017-06-19 23:59:17,497 Epoch[30] Batch [410]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.098067,	
2017-06-19 23:59:21,938 Epoch[30] Batch [420]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.098092,	
2017-06-19 23:59:26,449 Epoch[30] Batch [430]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.098218,	
2017-06-19 23:59:30,821 Epoch[30] Batch [440]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.098143,	
2017-06-19 23:59:35,249 Epoch[30] Batch [450]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.098160,	
2017-06-19 23:59:39,857 Epoch[30] Batch [460]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.097906,	
2017-06-19 23:59:44,175 Epoch[30] Batch [470]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097928,	
2017-06-19 23:59:48,358 Epoch[30] Batch [480]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.098058,	
2017-06-19 23:59:53,083 Epoch[30] Batch [490]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.098045,	
2017-06-19 23:59:57,342 Epoch[30] Batch [500]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.098021,	
2017-06-20 00:00:01,795 Epoch[30] Batch [510]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.098059,	
2017-06-20 00:00:05,994 Epoch[30] Batch [520]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.098046,	
2017-06-20 00:00:10,250 Epoch[30] Batch [530]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.097938,	
2017-06-20 00:00:14,629 Epoch[30] Batch [540]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.098072,	
2017-06-20 00:00:19,229 Epoch[30] Batch [550]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.098176,	
2017-06-20 00:00:23,838 Epoch[30] Batch [560]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.097992,	
2017-06-20 00:00:28,232 Epoch[30] Batch [570]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.097880,	
2017-06-20 00:00:32,470 Epoch[30] Batch [580]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.097817,	
2017-06-20 00:00:36,822 Epoch[30] Batch [590]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.097912,	
2017-06-20 00:00:41,101 Epoch[30] Batch [600]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097962,	
2017-06-20 00:00:45,449 Epoch[30] Batch [610]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.098054,	
2017-06-20 00:00:49,927 Epoch[30] Batch [620]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.098113,	
2017-06-20 00:00:54,461 Epoch[30] Batch [630]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.098184,	
2017-06-20 00:00:58,744 Epoch[30] Batch [640]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.098095,	
2017-06-20 00:01:03,310 Epoch[30] Batch [650]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.098098,	
2017-06-20 00:01:07,516 Epoch[30] Batch [660]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.098035,	
2017-06-20 00:01:11,878 Epoch[30] Batch [670]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.097922,	
2017-06-20 00:01:16,348 Epoch[30] Batch [680]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.098034,	
2017-06-20 00:01:20,557 Epoch[30] Batch [690]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.097997,	
2017-06-20 00:01:24,950 Epoch[30] Batch [700]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097994,	
2017-06-20 00:01:29,355 Epoch[30] Batch [710]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.098018,	
2017-06-20 00:01:33,725 Epoch[30] Batch [720]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.098198,	
2017-06-20 00:01:38,180 Epoch[30] Batch [730]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.098266,	
2017-06-20 00:01:42,610 Epoch[30] Batch [740]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.098271,	
2017-06-20 00:01:47,319 Epoch[30] Batch [750]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.098312,	
2017-06-20 00:01:51,625 Epoch[30] Batch [760]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.098338,	
2017-06-20 00:01:56,360 Epoch[30] Batch [770]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.098323,	
2017-06-20 00:02:00,880 Epoch[30] Batch [780]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.098336,	
2017-06-20 00:02:05,283 Epoch[30] Batch [790]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098377,	
2017-06-20 00:02:09,625 Epoch[30] Batch [800]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.098311,	
2017-06-20 00:02:14,008 Epoch[30] Batch [810]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.098243,	
2017-06-20 00:02:18,623 Epoch[30] Batch [820]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.098158,	
2017-06-20 00:02:22,920 Epoch[30] Batch [830]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.098138,	
2017-06-20 00:02:27,676 Epoch[30] Batch [840]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098141,	
2017-06-20 00:02:32,038 Epoch[30] Batch [850]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.098091,	
2017-06-20 00:02:36,660 Epoch[30] Batch [860]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.098121,	
2017-06-20 00:02:41,017 Epoch[30] Batch [870]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.098112,	
2017-06-20 00:02:45,619 Epoch[30] Batch [880]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.098172,	
2017-06-20 00:02:50,079 Epoch[30] Batch [890]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.098265,	
2017-06-20 00:02:54,401 Epoch[30] Batch [900]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.098350,	
2017-06-20 00:02:58,753 Epoch[30] Batch [910]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.098386,	
2017-06-20 00:03:03,185 Epoch[30] Batch [920]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.098320,	
2017-06-20 00:03:07,584 Epoch[30] Batch [930]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098454,	
2017-06-20 00:03:12,229 Epoch[30] Batch [940]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.098350,	
2017-06-20 00:03:16,878 Epoch[30] Batch [950]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.098234,	
2017-06-20 00:03:21,362 Epoch[30] Batch [960]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.098150,	
2017-06-20 00:03:25,913 Epoch[30] Batch [970]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.098207,	
2017-06-20 00:03:30,458 Epoch[30] Batch [980]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.098266,	
2017-06-20 00:03:34,858 Epoch[30] Batch [990]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098169,	
2017-06-20 00:03:39,598 Epoch[30] Batch [1000]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.098192,	
2017-06-20 00:03:44,099 Epoch[30] Batch [1010]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.098152,	
2017-06-20 00:03:48,602 Epoch[30] Batch [1020]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.098111,	
2017-06-20 00:03:53,055 Epoch[30] Batch [1030]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.098221,	
2017-06-20 00:03:57,861 Epoch[30] Batch [1040]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.098160,	
2017-06-20 00:04:02,483 Epoch[30] Batch [1050]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.098179,	
2017-06-20 00:04:07,214 Epoch[30] Batch [1060]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.098082,	
2017-06-20 00:04:11,777 Epoch[30] Batch [1070]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.098033,	
2017-06-20 00:04:16,351 Epoch[30] Batch [1080]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.097998,	
2017-06-20 00:04:20,979 Epoch[30] Batch [1090]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.097940,	
2017-06-20 00:04:25,372 Epoch[30] Batch [1100]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097920,	
2017-06-20 00:04:29,620 Epoch[30] Batch [1110]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.097918,	
2017-06-20 00:04:34,333 Epoch[30] Batch [1120]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.097879,	
2017-06-20 00:04:38,643 Epoch[30] Batch [1130]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097861,	
2017-06-20 00:04:42,924 Epoch[30] Batch [1140]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097841,	
2017-06-20 00:04:47,310 Epoch[30] Batch [1150]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.097802,	
2017-06-20 00:04:52,049 Epoch[30] Batch [1160]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.097803,	
2017-06-20 00:04:56,566 Epoch[30] Batch [1170]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.097817,	
2017-06-20 00:05:01,365 Epoch[30] Batch [1180]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.097828,	
2017-06-20 00:05:06,025 Epoch[30] Batch [1190]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.097749,	
2017-06-20 00:05:10,854 Epoch[30] Batch [1200]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.097780,	
2017-06-20 00:05:15,198 Epoch[30] Batch [1210]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.097760,	
2017-06-20 00:05:19,504 Epoch[30] Batch [1220]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.097743,	
2017-06-20 00:05:23,880 Epoch[30] Batch [1230]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.097890,	
2017-06-20 00:05:28,639 Epoch[30] Batch [1240]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.097886,	
2017-06-20 00:05:33,311 Epoch[30] Batch [1250]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.097847,	
2017-06-20 00:05:37,897 Epoch[30] Batch [1260]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.097842,	
2017-06-20 00:05:42,249 Epoch[30] Batch [1270]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.097832,	
2017-06-20 00:05:46,349 Epoch[30] Batch [1280]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097815,	
2017-06-20 00:05:50,792 Epoch[30] Batch [1290]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.097764,	
2017-06-20 00:05:55,372 Epoch[30] Batch [1300]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.097722,	
2017-06-20 00:05:59,769 Epoch[30] Batch [1310]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.097710,	
2017-06-20 00:06:04,147 Epoch[30] Batch [1320]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.097741,	
2017-06-20 00:06:08,837 Epoch[30] Batch [1330]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.097710,	
2017-06-20 00:06:13,333 Epoch[30] Batch [1340]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.097660,	
2017-06-20 00:06:17,916 Epoch[30] Batch [1350]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.097799,	
2017-06-20 00:06:22,133 Epoch[30] Batch [1360]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.097840,	
2017-06-20 00:06:26,802 Epoch[30] Batch [1370]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.097744,	
2017-06-20 00:06:31,399 Epoch[30] Batch [1380]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.097713,	
2017-06-20 00:06:35,827 Epoch[30] Batch [1390]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.097694,	
2017-06-20 00:06:40,515 Epoch[30] Batch [1400]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.097666,	
2017-06-20 00:06:45,217 Epoch[30] Batch [1410]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.097623,	
2017-06-20 00:06:49,821 Epoch[30] Batch [1420]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.097635,	
2017-06-20 00:06:53,984 Epoch[30] Batch [1430]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.097659,	
2017-06-20 00:06:58,483 Epoch[30] Batch [1440]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.097654,	
2017-06-20 00:07:03,066 Epoch[30] Batch [1450]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.097690,	
2017-06-20 00:07:07,515 Epoch[30] Batch [1460]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.097683,	
2017-06-20 00:07:12,139 Epoch[30] Batch [1470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.097713,	
2017-06-20 00:07:16,661 Epoch[30] Batch [1480]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097694,	
2017-06-20 00:07:19,520 Epoch[30] Train-FCNLogLoss=0.097651
2017-06-20 00:07:19,520 Epoch[30] Time cost=667.647
2017-06-20 00:07:20,316 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0031.params"
2017-06-20 00:07:21,739 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0031.states"
2017-06-20 00:07:27,201 Epoch[31] Batch [10]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.094606,	
2017-06-20 00:07:31,749 Epoch[31] Batch [20]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092562,	
2017-06-20 00:07:36,195 Epoch[31] Batch [30]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.092776,	
2017-06-20 00:07:40,968 Epoch[31] Batch [40]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092533,	
2017-06-20 00:07:45,647 Epoch[31] Batch [50]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.094677,	
2017-06-20 00:07:50,300 Epoch[31] Batch [60]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.096148,	
2017-06-20 00:07:54,657 Epoch[31] Batch [70]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.096860,	
2017-06-20 00:07:58,901 Epoch[31] Batch [80]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.096313,	
2017-06-20 00:08:03,595 Epoch[31] Batch [90]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.097849,	
2017-06-20 00:08:07,968 Epoch[31] Batch [100]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.098156,	
2017-06-20 00:08:12,300 Epoch[31] Batch [110]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097951,	
2017-06-20 00:08:17,056 Epoch[31] Batch [120]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.097627,	
2017-06-20 00:08:21,726 Epoch[31] Batch [130]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.098438,	
2017-06-20 00:08:26,024 Epoch[31] Batch [140]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.099084,	
2017-06-20 00:08:30,801 Epoch[31] Batch [150]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.099127,	
2017-06-20 00:08:35,160 Epoch[31] Batch [160]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.099141,	
2017-06-20 00:08:39,796 Epoch[31] Batch [170]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.098605,	
2017-06-20 00:08:44,430 Epoch[31] Batch [180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.098892,	
2017-06-20 00:08:49,016 Epoch[31] Batch [190]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.098642,	
2017-06-20 00:08:53,215 Epoch[31] Batch [200]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.098056,	
2017-06-20 00:08:57,623 Epoch[31] Batch [210]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.098235,	
2017-06-20 00:09:02,221 Epoch[31] Batch [220]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.097534,	
2017-06-20 00:09:06,549 Epoch[31] Batch [230]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.097562,	
2017-06-20 00:09:10,850 Epoch[31] Batch [240]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.097969,	
2017-06-20 00:09:15,431 Epoch[31] Batch [250]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.098426,	
2017-06-20 00:09:19,822 Epoch[31] Batch [260]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.098170,	
2017-06-20 00:09:24,401 Epoch[31] Batch [270]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.098105,	
2017-06-20 00:09:28,949 Epoch[31] Batch [280]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.097844,	
2017-06-20 00:09:33,117 Epoch[31] Batch [290]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.098063,	
2017-06-20 00:09:37,323 Epoch[31] Batch [300]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.098252,	
2017-06-20 00:09:41,692 Epoch[31] Batch [310]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.098528,	
2017-06-20 00:09:46,620 Epoch[31] Batch [320]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.098353,	
2017-06-20 00:09:51,247 Epoch[31] Batch [330]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.098352,	
2017-06-20 00:09:56,003 Epoch[31] Batch [340]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098396,	
2017-06-20 00:10:00,480 Epoch[31] Batch [350]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.098200,	
2017-06-20 00:10:04,995 Epoch[31] Batch [360]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.098191,	
2017-06-20 00:10:09,448 Epoch[31] Batch [370]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.098123,	
2017-06-20 00:10:13,865 Epoch[31] Batch [380]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.097790,	
2017-06-20 00:10:18,392 Epoch[31] Batch [390]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.097701,	
2017-06-20 00:10:23,113 Epoch[31] Batch [400]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.097659,	
2017-06-20 00:10:27,681 Epoch[31] Batch [410]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.097761,	
2017-06-20 00:10:32,264 Epoch[31] Batch [420]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.097619,	
2017-06-20 00:10:36,562 Epoch[31] Batch [430]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.097618,	
2017-06-20 00:10:40,884 Epoch[31] Batch [440]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097619,	
2017-06-20 00:10:45,541 Epoch[31] Batch [450]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.097584,	
2017-06-20 00:10:50,123 Epoch[31] Batch [460]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.097747,	
2017-06-20 00:10:54,473 Epoch[31] Batch [470]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.097749,	
2017-06-20 00:10:58,905 Epoch[31] Batch [480]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.097957,	
2017-06-20 00:11:03,098 Epoch[31] Batch [490]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.098063,	
2017-06-20 00:11:07,606 Epoch[31] Batch [500]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.098148,	
2017-06-20 00:11:12,176 Epoch[31] Batch [510]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.098199,	
2017-06-20 00:11:16,357 Epoch[31] Batch [520]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.098103,	
2017-06-20 00:11:20,804 Epoch[31] Batch [530]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.097980,	
2017-06-20 00:11:25,254 Epoch[31] Batch [540]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.097858,	
2017-06-20 00:11:29,405 Epoch[31] Batch [550]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.098040,	
2017-06-20 00:11:33,659 Epoch[31] Batch [560]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.098195,	
2017-06-20 00:11:38,078 Epoch[31] Batch [570]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.098103,	
2017-06-20 00:11:42,416 Epoch[31] Batch [580]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.098049,	
2017-06-20 00:11:46,915 Epoch[31] Batch [590]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.098028,	
2017-06-20 00:11:51,479 Epoch[31] Batch [600]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.097918,	
2017-06-20 00:11:56,033 Epoch[31] Batch [610]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.097900,	
2017-06-20 00:12:00,718 Epoch[31] Batch [620]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.097791,	
2017-06-20 00:12:05,263 Epoch[31] Batch [630]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.097716,	
2017-06-20 00:12:09,977 Epoch[31] Batch [640]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.097712,	
2017-06-20 00:12:14,532 Epoch[31] Batch [650]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.097669,	
2017-06-20 00:12:19,019 Epoch[31] Batch [660]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.097770,	
2017-06-20 00:12:23,561 Epoch[31] Batch [670]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.097693,	
2017-06-20 00:12:28,227 Epoch[31] Batch [680]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.097650,	
2017-06-20 00:12:32,841 Epoch[31] Batch [690]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.097677,	
2017-06-20 00:12:37,555 Epoch[31] Batch [700]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.097648,	
2017-06-20 00:12:42,043 Epoch[31] Batch [710]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.097689,	
2017-06-20 00:12:46,466 Epoch[31] Batch [720]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.097656,	
2017-06-20 00:12:50,988 Epoch[31] Batch [730]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097600,	
2017-06-20 00:12:55,279 Epoch[31] Batch [740]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.097718,	
2017-06-20 00:12:59,603 Epoch[31] Batch [750]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.097913,	
2017-06-20 00:13:04,085 Epoch[31] Batch [760]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.099170,	
2017-06-20 00:13:08,649 Epoch[31] Batch [770]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.100005,	
2017-06-20 00:13:13,131 Epoch[31] Batch [780]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.100332,	
2017-06-20 00:13:17,546 Epoch[31] Batch [790]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.100575,	
2017-06-20 00:13:22,140 Epoch[31] Batch [800]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.100648,	
2017-06-20 00:13:26,601 Epoch[31] Batch [810]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.100713,	
2017-06-20 00:13:31,099 Epoch[31] Batch [820]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.100907,	
2017-06-20 00:13:35,334 Epoch[31] Batch [830]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.100904,	
2017-06-20 00:13:39,755 Epoch[31] Batch [840]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.100915,	
2017-06-20 00:13:44,040 Epoch[31] Batch [850]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.100973,	
2017-06-20 00:13:48,517 Epoch[31] Batch [860]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.101107,	
2017-06-20 00:13:52,939 Epoch[31] Batch [870]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.101205,	
2017-06-20 00:13:57,594 Epoch[31] Batch [880]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.101307,	
2017-06-20 00:14:02,365 Epoch[31] Batch [890]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.101316,	
2017-06-20 00:14:06,402 Epoch[31] Batch [900]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101286,	
2017-06-20 00:14:10,845 Epoch[31] Batch [910]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.101446,	
2017-06-20 00:14:15,438 Epoch[31] Batch [920]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.101449,	
2017-06-20 00:14:19,887 Epoch[31] Batch [930]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.101613,	
2017-06-20 00:14:24,646 Epoch[31] Batch [940]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.101699,	
2017-06-20 00:14:29,065 Epoch[31] Batch [950]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.101666,	
2017-06-20 00:14:33,550 Epoch[31] Batch [960]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.101781,	
2017-06-20 00:14:38,047 Epoch[31] Batch [970]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.101730,	
2017-06-20 00:14:42,662 Epoch[31] Batch [980]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.101720,	
2017-06-20 00:14:46,965 Epoch[31] Batch [990]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.101775,	
2017-06-20 00:14:51,305 Epoch[31] Batch [1000]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.101695,	
2017-06-20 00:14:55,627 Epoch[31] Batch [1010]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.101600,	
2017-06-20 00:14:59,974 Epoch[31] Batch [1020]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.101772,	
2017-06-20 00:15:04,717 Epoch[31] Batch [1030]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.101887,	
2017-06-20 00:15:09,374 Epoch[31] Batch [1040]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.101916,	
2017-06-20 00:15:13,829 Epoch[31] Batch [1050]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.101880,	
2017-06-20 00:15:18,270 Epoch[31] Batch [1060]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.101832,	
2017-06-20 00:15:22,844 Epoch[31] Batch [1070]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.101798,	
2017-06-20 00:15:27,196 Epoch[31] Batch [1080]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.101780,	
2017-06-20 00:15:31,701 Epoch[31] Batch [1090]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.101783,	
2017-06-20 00:15:36,209 Epoch[31] Batch [1100]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.101766,	
2017-06-20 00:15:40,685 Epoch[31] Batch [1110]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.101661,	
2017-06-20 00:15:44,896 Epoch[31] Batch [1120]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.101662,	
2017-06-20 00:15:49,407 Epoch[31] Batch [1130]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.101597,	
2017-06-20 00:15:53,940 Epoch[31] Batch [1140]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.101680,	
2017-06-20 00:15:57,995 Epoch[31] Batch [1150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.101663,	
2017-06-20 00:16:02,518 Epoch[31] Batch [1160]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.101598,	
2017-06-20 00:16:07,062 Epoch[31] Batch [1170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.101488,	
2017-06-20 00:16:11,536 Epoch[31] Batch [1180]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.101481,	
2017-06-20 00:16:15,870 Epoch[31] Batch [1190]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.101987,	
2017-06-20 00:16:20,158 Epoch[31] Batch [1200]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.102098,	
2017-06-20 00:16:24,634 Epoch[31] Batch [1210]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102255,	
2017-06-20 00:16:28,970 Epoch[31] Batch [1220]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.102257,	
2017-06-20 00:16:33,624 Epoch[31] Batch [1230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.102418,	
2017-06-20 00:16:38,100 Epoch[31] Batch [1240]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102439,	
2017-06-20 00:16:42,472 Epoch[31] Batch [1250]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.102442,	
2017-06-20 00:16:47,008 Epoch[31] Batch [1260]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.102391,	
2017-06-20 00:16:51,617 Epoch[31] Batch [1270]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.102343,	
2017-06-20 00:16:56,015 Epoch[31] Batch [1280]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.102390,	
2017-06-20 00:17:00,587 Epoch[31] Batch [1290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.102424,	
2017-06-20 00:17:05,178 Epoch[31] Batch [1300]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.102405,	
2017-06-20 00:17:09,607 Epoch[31] Batch [1310]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.102449,	
2017-06-20 00:17:14,624 Epoch[31] Batch [1320]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.102359,	
2017-06-20 00:17:18,795 Epoch[31] Batch [1330]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.102264,	
2017-06-20 00:17:23,489 Epoch[31] Batch [1340]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.102277,	
2017-06-20 00:17:27,947 Epoch[31] Batch [1350]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.102149,	
2017-06-20 00:17:32,272 Epoch[31] Batch [1360]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.102128,	
2017-06-20 00:17:36,952 Epoch[31] Batch [1370]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.102102,	
2017-06-20 00:17:41,213 Epoch[31] Batch [1380]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.102070,	
2017-06-20 00:17:45,859 Epoch[31] Batch [1390]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.102111,	
2017-06-20 00:17:50,332 Epoch[31] Batch [1400]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102145,	
2017-06-20 00:17:54,737 Epoch[31] Batch [1410]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.102167,	
2017-06-20 00:17:59,204 Epoch[31] Batch [1420]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.102086,	
2017-06-20 00:18:03,421 Epoch[31] Batch [1430]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.101988,	
2017-06-20 00:18:07,688 Epoch[31] Batch [1440]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.101927,	
2017-06-20 00:18:12,031 Epoch[31] Batch [1450]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.101877,	
2017-06-20 00:18:16,602 Epoch[31] Batch [1460]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.101778,	
2017-06-20 00:18:21,300 Epoch[31] Batch [1470]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.101742,	
2017-06-20 00:18:25,685 Epoch[31] Batch [1480]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.101710,	
2017-06-20 00:18:28,102 Epoch[31] Train-FCNLogLoss=0.101668
2017-06-20 00:18:28,103 Epoch[31] Time cost=666.363
2017-06-20 00:18:28,915 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0032.params"
2017-06-20 00:18:30,655 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0032.states"
2017-06-20 00:18:36,292 Epoch[32] Batch [10]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.104217,	
2017-06-20 00:18:40,835 Epoch[32] Batch [20]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.098591,	
2017-06-20 00:18:45,286 Epoch[32] Batch [30]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.098631,	
2017-06-20 00:18:49,841 Epoch[32] Batch [40]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.102477,	
2017-06-20 00:18:54,478 Epoch[32] Batch [50]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107767,	
2017-06-20 00:18:59,104 Epoch[32] Batch [60]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112554,	
2017-06-20 00:19:03,640 Epoch[32] Batch [70]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.110021,	
2017-06-20 00:19:08,220 Epoch[32] Batch [80]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.113493,	
2017-06-20 00:19:12,877 Epoch[32] Batch [90]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.115157,	
2017-06-20 00:19:17,415 Epoch[32] Batch [100]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.115635,	
2017-06-20 00:19:21,570 Epoch[32] Batch [110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.118376,	
2017-06-20 00:19:26,129 Epoch[32] Batch [120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.118806,	
2017-06-20 00:19:30,345 Epoch[32] Batch [130]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.118573,	
2017-06-20 00:19:34,940 Epoch[32] Batch [140]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.118795,	
2017-06-20 00:19:39,290 Epoch[32] Batch [150]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.118609,	
2017-06-20 00:19:43,756 Epoch[32] Batch [160]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.117317,	
2017-06-20 00:19:48,422 Epoch[32] Batch [170]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.116877,	
2017-06-20 00:19:52,987 Epoch[32] Batch [180]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.115981,	
2017-06-20 00:19:57,512 Epoch[32] Batch [190]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.114664,	
2017-06-20 00:20:01,862 Epoch[32] Batch [200]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.113835,	
2017-06-20 00:20:06,337 Epoch[32] Batch [210]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.113742,	
2017-06-20 00:20:10,931 Epoch[32] Batch [220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.112983,	
2017-06-20 00:20:15,468 Epoch[32] Batch [230]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.113061,	
2017-06-20 00:20:19,962 Epoch[32] Batch [240]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.113341,	
2017-06-20 00:20:24,675 Epoch[32] Batch [250]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.113066,	
2017-06-20 00:20:29,556 Epoch[32] Batch [260]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.112736,	
2017-06-20 00:20:33,853 Epoch[32] Batch [270]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.112555,	
2017-06-20 00:20:38,538 Epoch[32] Batch [280]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.112139,	
2017-06-20 00:20:42,774 Epoch[32] Batch [290]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.111610,	
2017-06-20 00:20:47,245 Epoch[32] Batch [300]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.111101,	
2017-06-20 00:20:51,891 Epoch[32] Batch [310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.110756,	
2017-06-20 00:20:56,103 Epoch[32] Batch [320]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.110567,	
2017-06-20 00:21:00,619 Epoch[32] Batch [330]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110079,	
2017-06-20 00:21:05,131 Epoch[32] Batch [340]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.109832,	
2017-06-20 00:21:09,864 Epoch[32] Batch [350]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109296,	
2017-06-20 00:21:14,538 Epoch[32] Batch [360]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.108866,	
2017-06-20 00:21:18,978 Epoch[32] Batch [370]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108609,	
2017-06-20 00:21:23,581 Epoch[32] Batch [380]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108665,	
2017-06-20 00:21:28,019 Epoch[32] Batch [390]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108443,	
2017-06-20 00:21:32,665 Epoch[32] Batch [400]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.108459,	
2017-06-20 00:21:37,060 Epoch[32] Batch [410]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.108059,	
2017-06-20 00:21:41,469 Epoch[32] Batch [420]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.107924,	
2017-06-20 00:21:45,870 Epoch[32] Batch [430]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.107660,	
2017-06-20 00:21:50,420 Epoch[32] Batch [440]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.107453,	
2017-06-20 00:21:54,843 Epoch[32] Batch [450]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.107146,	
2017-06-20 00:21:59,378 Epoch[32] Batch [460]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.106859,	
2017-06-20 00:22:03,596 Epoch[32] Batch [470]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.106707,	
2017-06-20 00:22:07,965 Epoch[32] Batch [480]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.106523,	
2017-06-20 00:22:12,559 Epoch[32] Batch [490]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.106270,	
2017-06-20 00:22:17,178 Epoch[32] Batch [500]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.106119,	
2017-06-20 00:22:21,754 Epoch[32] Batch [510]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.106112,	
2017-06-20 00:22:26,350 Epoch[32] Batch [520]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.106026,	
2017-06-20 00:22:30,742 Epoch[32] Batch [530]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.105706,	
2017-06-20 00:22:35,152 Epoch[32] Batch [540]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.105658,	
2017-06-20 00:22:39,655 Epoch[32] Batch [550]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.105416,	
2017-06-20 00:22:44,320 Epoch[32] Batch [560]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.105430,	
2017-06-20 00:22:48,861 Epoch[32] Batch [570]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.105335,	
2017-06-20 00:22:53,245 Epoch[32] Batch [580]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.105112,	
2017-06-20 00:22:58,074 Epoch[32] Batch [590]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.104948,	
2017-06-20 00:23:02,684 Epoch[32] Batch [600]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.104722,	
2017-06-20 00:23:07,239 Epoch[32] Batch [610]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.104755,	
2017-06-20 00:23:11,778 Epoch[32] Batch [620]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.104729,	
2017-06-20 00:23:16,234 Epoch[32] Batch [630]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.104545,	
2017-06-20 00:23:20,568 Epoch[32] Batch [640]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.104411,	
2017-06-20 00:23:24,937 Epoch[32] Batch [650]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.104257,	
2017-06-20 00:23:29,323 Epoch[32] Batch [660]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.104209,	
2017-06-20 00:23:33,713 Epoch[32] Batch [670]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.104175,	
2017-06-20 00:23:38,186 Epoch[32] Batch [680]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.104150,	
2017-06-20 00:23:42,552 Epoch[32] Batch [690]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.104114,	
2017-06-20 00:23:47,040 Epoch[32] Batch [700]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104133,	
2017-06-20 00:23:51,222 Epoch[32] Batch [710]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103981,	
2017-06-20 00:23:55,544 Epoch[32] Batch [720]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.103714,	
2017-06-20 00:24:00,095 Epoch[32] Batch [730]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.103608,	
2017-06-20 00:24:04,441 Epoch[32] Batch [740]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.103506,	
2017-06-20 00:24:09,011 Epoch[32] Batch [750]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.103256,	
2017-06-20 00:24:13,517 Epoch[32] Batch [760]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.103164,	
2017-06-20 00:24:18,097 Epoch[32] Batch [770]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.103218,	
2017-06-20 00:24:22,818 Epoch[32] Batch [780]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.103158,	
2017-06-20 00:24:27,580 Epoch[32] Batch [790]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.102981,	
2017-06-20 00:24:31,960 Epoch[32] Batch [800]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.102886,	
2017-06-20 00:24:36,442 Epoch[32] Batch [810]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.102812,	
2017-06-20 00:24:41,113 Epoch[32] Batch [820]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.102791,	
2017-06-20 00:24:45,719 Epoch[32] Batch [830]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.102748,	
2017-06-20 00:24:50,229 Epoch[32] Batch [840]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.102625,	
2017-06-20 00:24:54,713 Epoch[32] Batch [850]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.102503,	
2017-06-20 00:24:59,170 Epoch[32] Batch [860]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.102479,	
2017-06-20 00:25:03,836 Epoch[32] Batch [870]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.102379,	
2017-06-20 00:25:08,362 Epoch[32] Batch [880]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.102192,	
2017-06-20 00:25:13,159 Epoch[32] Batch [890]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.102127,	
2017-06-20 00:25:17,403 Epoch[32] Batch [900]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.101973,	
2017-06-20 00:25:21,817 Epoch[32] Batch [910]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.102030,	
2017-06-20 00:25:26,552 Epoch[32] Batch [920]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.101821,	
2017-06-20 00:25:30,849 Epoch[32] Batch [930]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.101765,	
2017-06-20 00:25:35,827 Epoch[32] Batch [940]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.101970,	
2017-06-20 00:25:40,394 Epoch[32] Batch [950]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.102001,	
2017-06-20 00:25:44,614 Epoch[32] Batch [960]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.101958,	
2017-06-20 00:25:48,973 Epoch[32] Batch [970]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.101920,	
2017-06-20 00:25:53,554 Epoch[32] Batch [980]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.101953,	
2017-06-20 00:25:57,865 Epoch[32] Batch [990]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.101882,	
2017-06-20 00:26:02,364 Epoch[32] Batch [1000]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.101825,	
2017-06-20 00:26:06,984 Epoch[32] Batch [1010]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.101797,	
2017-06-20 00:26:11,357 Epoch[32] Batch [1020]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.101714,	
2017-06-20 00:26:15,972 Epoch[32] Batch [1030]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.101616,	
2017-06-20 00:26:20,232 Epoch[32] Batch [1040]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.101539,	
2017-06-20 00:26:24,402 Epoch[32] Batch [1050]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.101444,	
2017-06-20 00:26:28,624 Epoch[32] Batch [1060]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.101391,	
2017-06-20 00:26:33,341 Epoch[32] Batch [1070]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.101301,	
2017-06-20 00:26:37,865 Epoch[32] Batch [1080]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.101223,	
2017-06-20 00:26:42,062 Epoch[32] Batch [1090]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.101126,	
2017-06-20 00:26:46,481 Epoch[32] Batch [1100]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.100955,	
2017-06-20 00:26:51,076 Epoch[32] Batch [1110]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.100856,	
2017-06-20 00:26:55,604 Epoch[32] Batch [1120]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.100702,	
2017-06-20 00:26:59,977 Epoch[32] Batch [1130]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.100701,	
2017-06-20 00:27:04,450 Epoch[32] Batch [1140]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.100609,	
2017-06-20 00:27:08,685 Epoch[32] Batch [1150]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100532,	
2017-06-20 00:27:13,382 Epoch[32] Batch [1160]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.100429,	
2017-06-20 00:27:17,837 Epoch[32] Batch [1170]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.100468,	
2017-06-20 00:27:22,391 Epoch[32] Batch [1180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.100568,	
2017-06-20 00:27:26,842 Epoch[32] Batch [1190]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.100514,	
2017-06-20 00:27:31,588 Epoch[32] Batch [1200]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.100550,	
2017-06-20 00:27:35,817 Epoch[32] Batch [1210]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100597,	
2017-06-20 00:27:40,159 Epoch[32] Batch [1220]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.100532,	
2017-06-20 00:27:44,558 Epoch[32] Batch [1230]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.100642,	
2017-06-20 00:27:48,903 Epoch[32] Batch [1240]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.100610,	
2017-06-20 00:27:53,241 Epoch[32] Batch [1250]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.100816,	
2017-06-20 00:27:57,940 Epoch[32] Batch [1260]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.100771,	
2017-06-20 00:28:02,607 Epoch[32] Batch [1270]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.100787,	
2017-06-20 00:28:07,128 Epoch[32] Batch [1280]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.100766,	
2017-06-20 00:28:11,817 Epoch[32] Batch [1290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.100794,	
2017-06-20 00:28:16,459 Epoch[32] Batch [1300]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.100736,	
2017-06-20 00:28:20,996 Epoch[32] Batch [1310]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.100671,	
2017-06-20 00:28:25,663 Epoch[32] Batch [1320]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.100593,	
2017-06-20 00:28:29,925 Epoch[32] Batch [1330]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.100492,	
2017-06-20 00:28:34,148 Epoch[32] Batch [1340]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.100475,	
2017-06-20 00:28:38,682 Epoch[32] Batch [1350]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.100526,	
2017-06-20 00:28:43,065 Epoch[32] Batch [1360]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.100503,	
2017-06-20 00:28:47,639 Epoch[32] Batch [1370]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.100443,	
2017-06-20 00:28:51,941 Epoch[32] Batch [1380]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.100433,	
2017-06-20 00:28:56,258 Epoch[32] Batch [1390]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.100416,	
2017-06-20 00:29:00,684 Epoch[32] Batch [1400]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.100405,	
2017-06-20 00:29:05,016 Epoch[32] Batch [1410]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.100350,	
2017-06-20 00:29:09,597 Epoch[32] Batch [1420]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.100361,	
2017-06-20 00:29:14,072 Epoch[32] Batch [1430]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.100274,	
2017-06-20 00:29:18,734 Epoch[32] Batch [1440]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.100281,	
2017-06-20 00:29:23,249 Epoch[32] Batch [1450]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.100295,	
2017-06-20 00:29:27,592 Epoch[32] Batch [1460]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.100346,	
2017-06-20 00:29:32,201 Epoch[32] Batch [1470]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.100322,	
2017-06-20 00:29:36,492 Epoch[32] Batch [1480]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.100363,	
2017-06-20 00:29:39,020 Epoch[32] Train-FCNLogLoss=0.100316
2017-06-20 00:29:39,020 Epoch[32] Time cost=668.364
2017-06-20 00:29:39,777 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0033.params"
2017-06-20 00:29:41,430 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0033.states"
2017-06-20 00:29:46,400 Epoch[33] Batch [10]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097976,	
2017-06-20 00:29:51,171 Epoch[33] Batch [20]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.097652,	
2017-06-20 00:29:55,549 Epoch[33] Batch [30]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.097194,	
2017-06-20 00:30:00,116 Epoch[33] Batch [40]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.098742,	
2017-06-20 00:30:04,552 Epoch[33] Batch [50]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.100140,	
2017-06-20 00:30:09,056 Epoch[33] Batch [60]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.097941,	
2017-06-20 00:30:13,578 Epoch[33] Batch [70]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097966,	
2017-06-20 00:30:17,795 Epoch[33] Batch [80]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.098677,	
2017-06-20 00:30:22,480 Epoch[33] Batch [90]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.098969,	
2017-06-20 00:30:27,218 Epoch[33] Batch [100]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.097142,	
2017-06-20 00:30:31,639 Epoch[33] Batch [110]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.097157,	
2017-06-20 00:30:36,277 Epoch[33] Batch [120]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.097275,	
2017-06-20 00:30:40,639 Epoch[33] Batch [130]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.096723,	
2017-06-20 00:30:45,062 Epoch[33] Batch [140]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.096518,	
2017-06-20 00:30:49,833 Epoch[33] Batch [150]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.096550,	
2017-06-20 00:30:54,434 Epoch[33] Batch [160]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.096828,	
2017-06-20 00:30:59,003 Epoch[33] Batch [170]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.096628,	
2017-06-20 00:31:03,661 Epoch[33] Batch [180]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.096774,	
2017-06-20 00:31:08,387 Epoch[33] Batch [190]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.096102,	
2017-06-20 00:31:12,924 Epoch[33] Batch [200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.095859,	
2017-06-20 00:31:17,536 Epoch[33] Batch [210]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.095564,	
2017-06-20 00:31:22,127 Epoch[33] Batch [220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.095755,	
2017-06-20 00:31:26,509 Epoch[33] Batch [230]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095956,	
2017-06-20 00:31:30,824 Epoch[33] Batch [240]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.095946,	
2017-06-20 00:31:35,147 Epoch[33] Batch [250]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095460,	
2017-06-20 00:31:39,604 Epoch[33] Batch [260]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.095155,	
2017-06-20 00:31:43,960 Epoch[33] Batch [270]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.095276,	
2017-06-20 00:31:48,662 Epoch[33] Batch [280]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.095248,	
2017-06-20 00:31:53,040 Epoch[33] Batch [290]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.095127,	
2017-06-20 00:31:57,693 Epoch[33] Batch [300]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.094900,	
2017-06-20 00:32:02,244 Epoch[33] Batch [310]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.094893,	
2017-06-20 00:32:06,973 Epoch[33] Batch [320]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.094785,	
2017-06-20 00:32:11,227 Epoch[33] Batch [330]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.094651,	
2017-06-20 00:32:15,582 Epoch[33] Batch [340]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.094647,	
2017-06-20 00:32:20,255 Epoch[33] Batch [350]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.094862,	
2017-06-20 00:32:24,532 Epoch[33] Batch [360]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094771,	
2017-06-20 00:32:29,031 Epoch[33] Batch [370]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.094741,	
2017-06-20 00:32:33,622 Epoch[33] Batch [380]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.094958,	
2017-06-20 00:32:38,363 Epoch[33] Batch [390]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.095154,	
2017-06-20 00:32:42,891 Epoch[33] Batch [400]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.095084,	
2017-06-20 00:32:47,107 Epoch[33] Batch [410]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094896,	
2017-06-20 00:32:51,517 Epoch[33] Batch [420]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.094626,	
2017-06-20 00:32:56,036 Epoch[33] Batch [430]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.094513,	
2017-06-20 00:33:00,519 Epoch[33] Batch [440]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.094468,	
2017-06-20 00:33:05,354 Epoch[33] Batch [450]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.094300,	
2017-06-20 00:33:09,915 Epoch[33] Batch [460]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.094580,	
2017-06-20 00:33:14,478 Epoch[33] Batch [470]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.094771,	
2017-06-20 00:33:18,639 Epoch[33] Batch [480]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.094796,	
2017-06-20 00:33:23,162 Epoch[33] Batch [490]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.094845,	
2017-06-20 00:33:27,237 Epoch[33] Batch [500]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094725,	
2017-06-20 00:33:31,552 Epoch[33] Batch [510]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.094639,	
2017-06-20 00:33:35,944 Epoch[33] Batch [520]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.094474,	
2017-06-20 00:33:40,424 Epoch[33] Batch [530]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.094439,	
2017-06-20 00:33:45,079 Epoch[33] Batch [540]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.094274,	
2017-06-20 00:33:49,334 Epoch[33] Batch [550]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.094183,	
2017-06-20 00:33:53,595 Epoch[33] Batch [560]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094150,	
2017-06-20 00:33:58,197 Epoch[33] Batch [570]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.094232,	
2017-06-20 00:34:02,609 Epoch[33] Batch [580]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.094279,	
2017-06-20 00:34:07,150 Epoch[33] Batch [590]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.094273,	
2017-06-20 00:34:11,640 Epoch[33] Batch [600]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.094412,	
2017-06-20 00:34:15,925 Epoch[33] Batch [610]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.094416,	
2017-06-20 00:34:20,422 Epoch[33] Batch [620]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.094277,	
2017-06-20 00:34:24,883 Epoch[33] Batch [630]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.094306,	
2017-06-20 00:34:29,456 Epoch[33] Batch [640]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.094439,	
2017-06-20 00:34:33,448 Epoch[33] Batch [650]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094387,	
2017-06-20 00:34:37,885 Epoch[33] Batch [660]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.094461,	
2017-06-20 00:34:42,153 Epoch[33] Batch [670]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.094254,	
2017-06-20 00:34:46,591 Epoch[33] Batch [680]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.094200,	
2017-06-20 00:34:51,114 Epoch[33] Batch [690]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.094170,	
2017-06-20 00:34:55,734 Epoch[33] Batch [700]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.093992,	
2017-06-20 00:35:00,297 Epoch[33] Batch [710]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.094018,	
2017-06-20 00:35:04,501 Epoch[33] Batch [720]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.093945,	
2017-06-20 00:35:08,679 Epoch[33] Batch [730]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093755,	
2017-06-20 00:35:13,142 Epoch[33] Batch [740]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.093792,	
2017-06-20 00:35:17,754 Epoch[33] Batch [750]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.093801,	
2017-06-20 00:35:22,389 Epoch[33] Batch [760]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.093900,	
2017-06-20 00:35:26,915 Epoch[33] Batch [770]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.093926,	
2017-06-20 00:35:31,270 Epoch[33] Batch [780]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.094095,	
2017-06-20 00:35:35,532 Epoch[33] Batch [790]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.094087,	
2017-06-20 00:35:39,890 Epoch[33] Batch [800]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.094088,	
2017-06-20 00:35:44,427 Epoch[33] Batch [810]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.094115,	
2017-06-20 00:35:48,852 Epoch[33] Batch [820]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.094071,	
2017-06-20 00:35:53,481 Epoch[33] Batch [830]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.094208,	
2017-06-20 00:35:58,068 Epoch[33] Batch [840]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.094257,	
2017-06-20 00:36:02,485 Epoch[33] Batch [850]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.094179,	
2017-06-20 00:36:06,833 Epoch[33] Batch [860]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.094228,	
2017-06-20 00:36:11,335 Epoch[33] Batch [870]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.094187,	
2017-06-20 00:36:15,723 Epoch[33] Batch [880]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.094128,	
2017-06-20 00:36:20,313 Epoch[33] Batch [890]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.094150,	
2017-06-20 00:36:24,533 Epoch[33] Batch [900]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.094085,	
2017-06-20 00:36:29,161 Epoch[33] Batch [910]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.094232,	
2017-06-20 00:36:33,653 Epoch[33] Batch [920]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.094235,	
2017-06-20 00:36:37,969 Epoch[33] Batch [930]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.094278,	
2017-06-20 00:36:42,597 Epoch[33] Batch [940]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.094321,	
2017-06-20 00:36:47,457 Epoch[33] Batch [950]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.094444,	
2017-06-20 00:36:51,933 Epoch[33] Batch [960]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.094387,	
2017-06-20 00:36:56,249 Epoch[33] Batch [970]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.094463,	
2017-06-20 00:37:01,112 Epoch[33] Batch [980]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.094528,	
2017-06-20 00:37:05,573 Epoch[33] Batch [990]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.094569,	
2017-06-20 00:37:09,831 Epoch[33] Batch [1000]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094800,	
2017-06-20 00:37:14,042 Epoch[33] Batch [1010]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094758,	
2017-06-20 00:37:18,649 Epoch[33] Batch [1020]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.094722,	
2017-06-20 00:37:23,329 Epoch[33] Batch [1030]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.094720,	
2017-06-20 00:37:27,958 Epoch[33] Batch [1040]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.094821,	
2017-06-20 00:37:32,657 Epoch[33] Batch [1050]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.094725,	
2017-06-20 00:37:37,343 Epoch[33] Batch [1060]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.094761,	
2017-06-20 00:37:41,600 Epoch[33] Batch [1070]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.094804,	
2017-06-20 00:37:46,315 Epoch[33] Batch [1080]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.094879,	
2017-06-20 00:37:51,056 Epoch[33] Batch [1090]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.094864,	
2017-06-20 00:37:55,812 Epoch[33] Batch [1100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.094809,	
2017-06-20 00:38:00,268 Epoch[33] Batch [1110]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.094915,	
2017-06-20 00:38:05,091 Epoch[33] Batch [1120]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.094905,	
2017-06-20 00:38:09,752 Epoch[33] Batch [1130]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095037,	
2017-06-20 00:38:14,327 Epoch[33] Batch [1140]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.095129,	
2017-06-20 00:38:18,822 Epoch[33] Batch [1150]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.095108,	
2017-06-20 00:38:23,326 Epoch[33] Batch [1160]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095165,	
2017-06-20 00:38:27,713 Epoch[33] Batch [1170]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095154,	
2017-06-20 00:38:32,123 Epoch[33] Batch [1180]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.095281,	
2017-06-20 00:38:36,858 Epoch[33] Batch [1190]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.095358,	
2017-06-20 00:38:41,224 Epoch[33] Batch [1200]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.095338,	
2017-06-20 00:38:45,626 Epoch[33] Batch [1210]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.095405,	
2017-06-20 00:38:49,937 Epoch[33] Batch [1220]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.095296,	
2017-06-20 00:38:54,587 Epoch[33] Batch [1230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.095342,	
2017-06-20 00:38:59,099 Epoch[33] Batch [1240]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.095330,	
2017-06-20 00:39:03,484 Epoch[33] Batch [1250]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.095256,	
2017-06-20 00:39:07,673 Epoch[33] Batch [1260]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095199,	
2017-06-20 00:39:11,989 Epoch[33] Batch [1270]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.095137,	
2017-06-20 00:39:16,003 Epoch[33] Batch [1280]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.095090,	
2017-06-20 00:39:20,257 Epoch[33] Batch [1290]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.095067,	
2017-06-20 00:39:24,705 Epoch[33] Batch [1300]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.095138,	
2017-06-20 00:39:29,143 Epoch[33] Batch [1310]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.095151,	
2017-06-20 00:39:33,604 Epoch[33] Batch [1320]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.095147,	
2017-06-20 00:39:37,964 Epoch[33] Batch [1330]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095133,	
2017-06-20 00:39:42,616 Epoch[33] Batch [1340]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.095130,	
2017-06-20 00:39:47,214 Epoch[33] Batch [1350]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.095185,	
2017-06-20 00:39:51,741 Epoch[33] Batch [1360]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.095211,	
2017-06-20 00:39:56,510 Epoch[33] Batch [1370]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.095224,	
2017-06-20 00:40:01,144 Epoch[33] Batch [1380]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.095312,	
2017-06-20 00:40:05,943 Epoch[33] Batch [1390]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.095299,	
2017-06-20 00:40:10,569 Epoch[33] Batch [1400]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.095252,	
2017-06-20 00:40:14,892 Epoch[33] Batch [1410]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095151,	
2017-06-20 00:40:19,520 Epoch[33] Batch [1420]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.095128,	
2017-06-20 00:40:23,933 Epoch[33] Batch [1430]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.095147,	
2017-06-20 00:40:28,267 Epoch[33] Batch [1440]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.095115,	
2017-06-20 00:40:32,549 Epoch[33] Batch [1450]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.095086,	
2017-06-20 00:40:37,088 Epoch[33] Batch [1460]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.095080,	
2017-06-20 00:40:41,466 Epoch[33] Batch [1470]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.095038,	
2017-06-20 00:40:46,307 Epoch[33] Batch [1480]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.095096,	
2017-06-20 00:40:48,812 Epoch[33] Train-FCNLogLoss=0.095033
2017-06-20 00:40:48,812 Epoch[33] Time cost=667.382
2017-06-20 00:40:49,624 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0034.params"
2017-06-20 00:40:51,913 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0034.states"
2017-06-20 00:40:57,377 Epoch[34] Batch [10]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089720,	
2017-06-20 00:41:01,782 Epoch[34] Batch [20]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.097113,	
2017-06-20 00:41:06,297 Epoch[34] Batch [30]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.094555,	
2017-06-20 00:41:10,778 Epoch[34] Batch [40]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.096282,	
2017-06-20 00:41:15,197 Epoch[34] Batch [50]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.094300,	
2017-06-20 00:41:19,816 Epoch[34] Batch [60]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.094571,	
2017-06-20 00:41:24,134 Epoch[34] Batch [70]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.093819,	
2017-06-20 00:41:28,238 Epoch[34] Batch [80]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092294,	
2017-06-20 00:41:32,738 Epoch[34] Batch [90]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090959,	
2017-06-20 00:41:36,718 Epoch[34] Batch [100]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.090943,	
2017-06-20 00:41:41,114 Epoch[34] Batch [110]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090932,	
2017-06-20 00:41:45,442 Epoch[34] Batch [120]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.091054,	
2017-06-20 00:41:49,701 Epoch[34] Batch [130]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.091029,	
2017-06-20 00:41:53,826 Epoch[34] Batch [140]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.090907,	
2017-06-20 00:41:58,256 Epoch[34] Batch [150]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.091182,	
2017-06-20 00:42:02,573 Epoch[34] Batch [160]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.091162,	
2017-06-20 00:42:06,839 Epoch[34] Batch [170]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.091530,	
2017-06-20 00:42:11,025 Epoch[34] Batch [180]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.091533,	
2017-06-20 00:42:15,356 Epoch[34] Batch [190]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.092212,	
2017-06-20 00:42:19,717 Epoch[34] Batch [200]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.092100,	
2017-06-20 00:42:23,987 Epoch[34] Batch [210]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.092308,	
2017-06-20 00:42:28,337 Epoch[34] Batch [220]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.091950,	
2017-06-20 00:42:32,905 Epoch[34] Batch [230]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092525,	
2017-06-20 00:42:37,679 Epoch[34] Batch [240]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092165,	
2017-06-20 00:42:41,971 Epoch[34] Batch [250]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.092336,	
2017-06-20 00:42:46,529 Epoch[34] Batch [260]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092261,	
2017-06-20 00:42:50,812 Epoch[34] Batch [270]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.092221,	
2017-06-20 00:42:55,171 Epoch[34] Batch [280]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.092005,	
2017-06-20 00:42:59,716 Epoch[34] Batch [290]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091777,	
2017-06-20 00:43:04,054 Epoch[34] Batch [300]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.091741,	
2017-06-20 00:43:08,660 Epoch[34] Batch [310]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091739,	
2017-06-20 00:43:13,180 Epoch[34] Batch [320]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.091810,	
2017-06-20 00:43:17,624 Epoch[34] Batch [330]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.091647,	
2017-06-20 00:43:22,341 Epoch[34] Batch [340]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091470,	
2017-06-20 00:43:26,809 Epoch[34] Batch [350]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091532,	
2017-06-20 00:43:31,266 Epoch[34] Batch [360]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091440,	
2017-06-20 00:43:35,588 Epoch[34] Batch [370]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.091517,	
2017-06-20 00:43:40,209 Epoch[34] Batch [380]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091835,	
2017-06-20 00:43:44,651 Epoch[34] Batch [390]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.091954,	
2017-06-20 00:43:48,789 Epoch[34] Batch [400]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.092037,	
2017-06-20 00:43:53,528 Epoch[34] Batch [410]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092678,	
2017-06-20 00:43:57,770 Epoch[34] Batch [420]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.092574,	
2017-06-20 00:44:02,357 Epoch[34] Batch [430]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092471,	
2017-06-20 00:44:06,873 Epoch[34] Batch [440]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092385,	
2017-06-20 00:44:10,999 Epoch[34] Batch [450]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092636,	
2017-06-20 00:44:15,626 Epoch[34] Batch [460]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.092756,	
2017-06-20 00:44:20,345 Epoch[34] Batch [470]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.092868,	
2017-06-20 00:44:24,882 Epoch[34] Batch [480]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.092974,	
2017-06-20 00:44:29,718 Epoch[34] Batch [490]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.093140,	
2017-06-20 00:44:34,503 Epoch[34] Batch [500]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.093207,	
2017-06-20 00:44:38,859 Epoch[34] Batch [510]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.093306,	
2017-06-20 00:44:43,607 Epoch[34] Batch [520]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.093351,	
2017-06-20 00:44:47,981 Epoch[34] Batch [530]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.093479,	
2017-06-20 00:44:52,441 Epoch[34] Batch [540]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.093557,	
2017-06-20 00:44:56,955 Epoch[34] Batch [550]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.093699,	
2017-06-20 00:45:01,461 Epoch[34] Batch [560]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.093778,	
2017-06-20 00:45:05,826 Epoch[34] Batch [570]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.093835,	
2017-06-20 00:45:10,225 Epoch[34] Batch [580]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.093823,	
2017-06-20 00:45:14,785 Epoch[34] Batch [590]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.093783,	
2017-06-20 00:45:19,631 Epoch[34] Batch [600]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.093653,	
2017-06-20 00:45:24,340 Epoch[34] Batch [610]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.093508,	
2017-06-20 00:45:28,605 Epoch[34] Batch [620]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.093322,	
2017-06-20 00:45:32,924 Epoch[34] Batch [630]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.093299,	
2017-06-20 00:45:37,227 Epoch[34] Batch [640]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.093316,	
2017-06-20 00:45:41,533 Epoch[34] Batch [650]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.093178,	
2017-06-20 00:45:46,168 Epoch[34] Batch [660]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.093298,	
2017-06-20 00:45:50,418 Epoch[34] Batch [670]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.093232,	
2017-06-20 00:45:54,806 Epoch[34] Batch [680]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.093232,	
2017-06-20 00:45:59,314 Epoch[34] Batch [690]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.093272,	
2017-06-20 00:46:03,932 Epoch[34] Batch [700]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.093134,	
2017-06-20 00:46:08,821 Epoch[34] Batch [710]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.093164,	
2017-06-20 00:46:13,301 Epoch[34] Batch [720]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.093203,	
2017-06-20 00:46:17,948 Epoch[34] Batch [730]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.093165,	
2017-06-20 00:46:22,022 Epoch[34] Batch [740]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.093174,	
2017-06-20 00:46:26,581 Epoch[34] Batch [750]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.093278,	
2017-06-20 00:46:30,814 Epoch[34] Batch [760]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.093303,	
2017-06-20 00:46:35,336 Epoch[34] Batch [770]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.093273,	
2017-06-20 00:46:39,832 Epoch[34] Batch [780]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.093300,	
2017-06-20 00:46:44,629 Epoch[34] Batch [790]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.093340,	
2017-06-20 00:46:49,307 Epoch[34] Batch [800]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.093318,	
2017-06-20 00:46:53,729 Epoch[34] Batch [810]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.093394,	
2017-06-20 00:46:57,885 Epoch[34] Batch [820]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.093430,	
2017-06-20 00:47:02,662 Epoch[34] Batch [830]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.093337,	
2017-06-20 00:47:07,144 Epoch[34] Batch [840]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.093283,	
2017-06-20 00:47:11,352 Epoch[34] Batch [850]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.093266,	
2017-06-20 00:47:15,752 Epoch[34] Batch [860]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.093316,	
2017-06-20 00:47:20,383 Epoch[34] Batch [870]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.093357,	
2017-06-20 00:47:25,066 Epoch[34] Batch [880]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.093394,	
2017-06-20 00:47:29,605 Epoch[34] Batch [890]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.093316,	
2017-06-20 00:47:34,137 Epoch[34] Batch [900]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.093190,	
2017-06-20 00:47:38,555 Epoch[34] Batch [910]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.093159,	
2017-06-20 00:47:42,984 Epoch[34] Batch [920]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.093249,	
2017-06-20 00:47:47,747 Epoch[34] Batch [930]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.093389,	
2017-06-20 00:47:52,293 Epoch[34] Batch [940]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.093419,	
2017-06-20 00:47:57,038 Epoch[34] Batch [950]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.093404,	
2017-06-20 00:48:01,667 Epoch[34] Batch [960]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.093379,	
2017-06-20 00:48:06,191 Epoch[34] Batch [970]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.093394,	
2017-06-20 00:48:10,686 Epoch[34] Batch [980]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.093336,	
2017-06-20 00:48:15,419 Epoch[34] Batch [990]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.093284,	
2017-06-20 00:48:20,008 Epoch[34] Batch [1000]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.093133,	
2017-06-20 00:48:24,226 Epoch[34] Batch [1010]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.093219,	
2017-06-20 00:48:28,963 Epoch[34] Batch [1020]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.093274,	
2017-06-20 00:48:33,343 Epoch[34] Batch [1030]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.093299,	
2017-06-20 00:48:37,528 Epoch[34] Batch [1040]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.093290,	
2017-06-20 00:48:41,730 Epoch[34] Batch [1050]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.093286,	
2017-06-20 00:48:46,011 Epoch[34] Batch [1060]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.093386,	
2017-06-20 00:48:50,374 Epoch[34] Batch [1070]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.093383,	
2017-06-20 00:48:55,201 Epoch[34] Batch [1080]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.093422,	
2017-06-20 00:48:59,825 Epoch[34] Batch [1090]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.093430,	
2017-06-20 00:49:04,262 Epoch[34] Batch [1100]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.093394,	
2017-06-20 00:49:08,653 Epoch[34] Batch [1110]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.093396,	
2017-06-20 00:49:12,987 Epoch[34] Batch [1120]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.093376,	
2017-06-20 00:49:17,419 Epoch[34] Batch [1130]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.093449,	
2017-06-20 00:49:21,767 Epoch[34] Batch [1140]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.093402,	
2017-06-20 00:49:26,116 Epoch[34] Batch [1150]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.093347,	
2017-06-20 00:49:30,616 Epoch[34] Batch [1160]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.093347,	
2017-06-20 00:49:35,045 Epoch[34] Batch [1170]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.093388,	
2017-06-20 00:49:39,330 Epoch[34] Batch [1180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.093503,	
2017-06-20 00:49:43,655 Epoch[34] Batch [1190]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.093486,	
2017-06-20 00:49:48,169 Epoch[34] Batch [1200]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.093468,	
2017-06-20 00:49:52,598 Epoch[34] Batch [1210]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.093453,	
2017-06-20 00:49:56,890 Epoch[34] Batch [1220]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.093479,	
2017-06-20 00:50:01,643 Epoch[34] Batch [1230]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.093422,	
2017-06-20 00:50:06,195 Epoch[34] Batch [1240]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.093367,	
2017-06-20 00:50:10,808 Epoch[34] Batch [1250]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.093406,	
2017-06-20 00:50:15,276 Epoch[34] Batch [1260]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.093446,	
2017-06-20 00:50:19,685 Epoch[34] Batch [1270]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.093419,	
2017-06-20 00:50:24,281 Epoch[34] Batch [1280]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.093453,	
2017-06-20 00:50:28,851 Epoch[34] Batch [1290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.093506,	
2017-06-20 00:50:33,414 Epoch[34] Batch [1300]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.093469,	
2017-06-20 00:50:37,851 Epoch[34] Batch [1310]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.093503,	
2017-06-20 00:50:42,619 Epoch[34] Batch [1320]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.093489,	
2017-06-20 00:50:47,241 Epoch[34] Batch [1330]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.093533,	
2017-06-20 00:50:51,229 Epoch[34] Batch [1340]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.093583,	
2017-06-20 00:50:56,027 Epoch[34] Batch [1350]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.093605,	
2017-06-20 00:51:00,212 Epoch[34] Batch [1360]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.093635,	
2017-06-20 00:51:04,715 Epoch[34] Batch [1370]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.093628,	
2017-06-20 00:51:09,066 Epoch[34] Batch [1380]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.093611,	
2017-06-20 00:51:13,613 Epoch[34] Batch [1390]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.093567,	
2017-06-20 00:51:18,031 Epoch[34] Batch [1400]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.093558,	
2017-06-20 00:51:22,743 Epoch[34] Batch [1410]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.093577,	
2017-06-20 00:51:27,349 Epoch[34] Batch [1420]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.093618,	
2017-06-20 00:51:31,714 Epoch[34] Batch [1430]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.093667,	
2017-06-20 00:51:36,226 Epoch[34] Batch [1440]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.093705,	
2017-06-20 00:51:40,754 Epoch[34] Batch [1450]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.093748,	
2017-06-20 00:51:45,407 Epoch[34] Batch [1460]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.093791,	
2017-06-20 00:51:50,106 Epoch[34] Batch [1470]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.093808,	
2017-06-20 00:51:54,888 Epoch[34] Batch [1480]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.093756,	
2017-06-20 00:51:57,528 Epoch[34] Train-FCNLogLoss=0.093760
2017-06-20 00:51:57,528 Epoch[34] Time cost=665.615
2017-06-20 00:51:58,306 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0035.params"
2017-06-20 00:52:00,041 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0035.states"
2017-06-20 00:52:05,233 Epoch[35] Batch [10]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.098723,	
2017-06-20 00:52:09,372 Epoch[35] Batch [20]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.099435,	
2017-06-20 00:52:13,967 Epoch[35] Batch [30]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.097330,	
2017-06-20 00:52:18,188 Epoch[35] Batch [40]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095874,	
2017-06-20 00:52:22,707 Epoch[35] Batch [50]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.096086,	
2017-06-20 00:52:27,237 Epoch[35] Batch [60]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.093612,	
2017-06-20 00:52:31,427 Epoch[35] Batch [70]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.092825,	
2017-06-20 00:52:35,797 Epoch[35] Batch [80]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.092311,	
2017-06-20 00:52:40,217 Epoch[35] Batch [90]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.091965,	
2017-06-20 00:52:44,795 Epoch[35] Batch [100]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092532,	
2017-06-20 00:52:49,410 Epoch[35] Batch [110]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.094926,	
2017-06-20 00:52:54,092 Epoch[35] Batch [120]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.095161,	
2017-06-20 00:52:58,654 Epoch[35] Batch [130]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.095095,	
2017-06-20 00:53:03,241 Epoch[35] Batch [140]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.095129,	
2017-06-20 00:53:07,876 Epoch[35] Batch [150]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.094421,	
2017-06-20 00:53:12,510 Epoch[35] Batch [160]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.094064,	
2017-06-20 00:53:16,925 Epoch[35] Batch [170]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.093595,	
2017-06-20 00:53:21,457 Epoch[35] Batch [180]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.093647,	
2017-06-20 00:53:25,950 Epoch[35] Batch [190]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.093408,	
2017-06-20 00:53:30,383 Epoch[35] Batch [200]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.093667,	
2017-06-20 00:53:34,973 Epoch[35] Batch [210]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.094538,	
2017-06-20 00:53:39,703 Epoch[35] Batch [220]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.094719,	
2017-06-20 00:53:44,453 Epoch[35] Batch [230]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.094445,	
2017-06-20 00:53:48,888 Epoch[35] Batch [240]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.094492,	
2017-06-20 00:53:53,316 Epoch[35] Batch [250]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.094140,	
2017-06-20 00:53:57,917 Epoch[35] Batch [260]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.094148,	
2017-06-20 00:54:02,702 Epoch[35] Batch [270]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.094524,	
2017-06-20 00:54:07,337 Epoch[35] Batch [280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.094474,	
2017-06-20 00:54:11,763 Epoch[35] Batch [290]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.094763,	
2017-06-20 00:54:16,177 Epoch[35] Batch [300]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.094942,	
2017-06-20 00:54:20,287 Epoch[35] Batch [310]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095029,	
2017-06-20 00:54:24,695 Epoch[35] Batch [320]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.095324,	
2017-06-20 00:54:29,019 Epoch[35] Batch [330]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095275,	
2017-06-20 00:54:33,525 Epoch[35] Batch [340]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095083,	
2017-06-20 00:54:38,219 Epoch[35] Batch [350]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.095157,	
2017-06-20 00:54:42,616 Epoch[35] Batch [360]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.094845,	
2017-06-20 00:54:47,168 Epoch[35] Batch [370]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.094827,	
2017-06-20 00:54:51,338 Epoch[35] Batch [380]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.094912,	
2017-06-20 00:54:55,639 Epoch[35] Batch [390]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094813,	
2017-06-20 00:54:59,907 Epoch[35] Batch [400]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095058,	
2017-06-20 00:55:04,449 Epoch[35] Batch [410]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.095312,	
2017-06-20 00:55:08,542 Epoch[35] Batch [420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095452,	
2017-06-20 00:55:12,968 Epoch[35] Batch [430]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095483,	
2017-06-20 00:55:17,213 Epoch[35] Batch [440]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.095532,	
2017-06-20 00:55:21,781 Epoch[35] Batch [450]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.095485,	
2017-06-20 00:55:26,343 Epoch[35] Batch [460]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.095183,	
2017-06-20 00:55:30,715 Epoch[35] Batch [470]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095082,	
2017-06-20 00:55:35,171 Epoch[35] Batch [480]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.095111,	
2017-06-20 00:55:39,518 Epoch[35] Batch [490]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095064,	
2017-06-20 00:55:44,031 Epoch[35] Batch [500]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.095253,	
2017-06-20 00:55:48,495 Epoch[35] Batch [510]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.095141,	
2017-06-20 00:55:52,986 Epoch[35] Batch [520]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.095197,	
2017-06-20 00:55:57,384 Epoch[35] Batch [530]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095020,	
2017-06-20 00:56:01,743 Epoch[35] Batch [540]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.095040,	
2017-06-20 00:56:06,033 Epoch[35] Batch [550]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.095120,	
2017-06-20 00:56:10,611 Epoch[35] Batch [560]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.095103,	
2017-06-20 00:56:14,971 Epoch[35] Batch [570]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.095270,	
2017-06-20 00:56:19,439 Epoch[35] Batch [580]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.095230,	
2017-06-20 00:56:23,542 Epoch[35] Batch [590]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095189,	
2017-06-20 00:56:28,070 Epoch[35] Batch [600]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.095050,	
2017-06-20 00:56:32,731 Epoch[35] Batch [610]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095188,	
2017-06-20 00:56:37,338 Epoch[35] Batch [620]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.095119,	
2017-06-20 00:56:41,990 Epoch[35] Batch [630]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.095121,	
2017-06-20 00:56:46,219 Epoch[35] Batch [640]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.095122,	
2017-06-20 00:56:50,965 Epoch[35] Batch [650]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.095191,	
2017-06-20 00:56:55,446 Epoch[35] Batch [660]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.095205,	
2017-06-20 00:57:00,047 Epoch[35] Batch [670]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.095254,	
2017-06-20 00:57:04,802 Epoch[35] Batch [680]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.095256,	
2017-06-20 00:57:09,504 Epoch[35] Batch [690]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.095478,	
2017-06-20 00:57:14,315 Epoch[35] Batch [700]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.095394,	
2017-06-20 00:57:18,813 Epoch[35] Batch [710]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.095404,	
2017-06-20 00:57:23,322 Epoch[35] Batch [720]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.095268,	
2017-06-20 00:57:27,825 Epoch[35] Batch [730]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095217,	
2017-06-20 00:57:31,997 Epoch[35] Batch [740]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095204,	
2017-06-20 00:57:36,649 Epoch[35] Batch [750]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.095236,	
2017-06-20 00:57:41,172 Epoch[35] Batch [760]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.095361,	
2017-06-20 00:57:45,444 Epoch[35] Batch [770]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.095485,	
2017-06-20 00:57:49,771 Epoch[35] Batch [780]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095449,	
2017-06-20 00:57:54,455 Epoch[35] Batch [790]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.095359,	
2017-06-20 00:57:58,862 Epoch[35] Batch [800]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.095395,	
2017-06-20 00:58:03,281 Epoch[35] Batch [810]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.095355,	
2017-06-20 00:58:07,773 Epoch[35] Batch [820]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.095341,	
2017-06-20 00:58:12,290 Epoch[35] Batch [830]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.095290,	
2017-06-20 00:58:17,025 Epoch[35] Batch [840]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.095417,	
2017-06-20 00:58:21,648 Epoch[35] Batch [850]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.095352,	
2017-06-20 00:58:26,365 Epoch[35] Batch [860]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.095396,	
2017-06-20 00:58:30,762 Epoch[35] Batch [870]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095369,	
2017-06-20 00:58:35,394 Epoch[35] Batch [880]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.095234,	
2017-06-20 00:58:40,029 Epoch[35] Batch [890]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.095246,	
2017-06-20 00:58:44,807 Epoch[35] Batch [900]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.095201,	
2017-06-20 00:58:49,286 Epoch[35] Batch [910]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.095245,	
2017-06-20 00:58:53,814 Epoch[35] Batch [920]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.095121,	
2017-06-20 00:58:58,483 Epoch[35] Batch [930]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.095122,	
2017-06-20 00:59:03,392 Epoch[35] Batch [940]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.095177,	
2017-06-20 00:59:08,123 Epoch[35] Batch [950]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.095216,	
2017-06-20 00:59:12,630 Epoch[35] Batch [960]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095255,	
2017-06-20 00:59:17,058 Epoch[35] Batch [970]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095328,	
2017-06-20 00:59:21,930 Epoch[35] Batch [980]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.095378,	
2017-06-20 00:59:26,727 Epoch[35] Batch [990]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.095256,	
2017-06-20 00:59:31,642 Epoch[35] Batch [1000]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.095228,	
2017-06-20 00:59:36,156 Epoch[35] Batch [1010]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.095231,	
2017-06-20 00:59:40,869 Epoch[35] Batch [1020]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.095231,	
2017-06-20 00:59:45,796 Epoch[35] Batch [1030]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.095187,	
2017-06-20 00:59:50,474 Epoch[35] Batch [1040]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.095118,	
2017-06-20 00:59:55,094 Epoch[35] Batch [1050]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.095103,	
2017-06-20 00:59:59,731 Epoch[35] Batch [1060]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.095074,	
2017-06-20 01:00:04,281 Epoch[35] Batch [1070]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.095057,	
2017-06-20 01:00:08,977 Epoch[35] Batch [1080]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.095037,	
2017-06-20 01:00:13,745 Epoch[35] Batch [1090]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.095013,	
2017-06-20 01:00:18,356 Epoch[35] Batch [1100]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.095040,	
2017-06-20 01:00:23,043 Epoch[35] Batch [1110]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.094960,	
2017-06-20 01:00:27,658 Epoch[35] Batch [1120]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.095017,	
2017-06-20 01:00:32,306 Epoch[35] Batch [1130]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.095005,	
2017-06-20 01:00:36,755 Epoch[35] Batch [1140]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.095018,	
2017-06-20 01:00:41,266 Epoch[35] Batch [1150]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.095082,	
2017-06-20 01:00:45,706 Epoch[35] Batch [1160]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.095034,	
2017-06-20 01:00:50,089 Epoch[35] Batch [1170]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.094968,	
2017-06-20 01:00:54,567 Epoch[35] Batch [1180]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.094851,	
2017-06-20 01:00:58,862 Epoch[35] Batch [1190]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094773,	
2017-06-20 01:01:03,474 Epoch[35] Batch [1200]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.094774,	
2017-06-20 01:01:08,186 Epoch[35] Batch [1210]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.094853,	
2017-06-20 01:01:12,652 Epoch[35] Batch [1220]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.094753,	
2017-06-20 01:01:17,596 Epoch[35] Batch [1230]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.094707,	
2017-06-20 01:01:21,911 Epoch[35] Batch [1240]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.094612,	
2017-06-20 01:01:26,619 Epoch[35] Batch [1250]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.094481,	
2017-06-20 01:01:30,963 Epoch[35] Batch [1260]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.094450,	
2017-06-20 01:01:35,667 Epoch[35] Batch [1270]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.094340,	
2017-06-20 01:01:40,181 Epoch[35] Batch [1280]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.094293,	
2017-06-20 01:01:44,727 Epoch[35] Batch [1290]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.094288,	
2017-06-20 01:01:49,300 Epoch[35] Batch [1300]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.094243,	
2017-06-20 01:01:53,637 Epoch[35] Batch [1310]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.094275,	
2017-06-20 01:01:58,090 Epoch[35] Batch [1320]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.094284,	
2017-06-20 01:02:02,971 Epoch[35] Batch [1330]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.094256,	
2017-06-20 01:02:07,667 Epoch[35] Batch [1340]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.094207,	
2017-06-20 01:02:12,582 Epoch[35] Batch [1350]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.094168,	
2017-06-20 01:02:17,293 Epoch[35] Batch [1360]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.094175,	
2017-06-20 01:02:21,968 Epoch[35] Batch [1370]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.094122,	
2017-06-20 01:02:26,508 Epoch[35] Batch [1380]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.094134,	
2017-06-20 01:02:31,356 Epoch[35] Batch [1390]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.094095,	
2017-06-20 01:02:35,936 Epoch[35] Batch [1400]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.094198,	
2017-06-20 01:02:40,474 Epoch[35] Batch [1410]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.094136,	
2017-06-20 01:02:45,110 Epoch[35] Batch [1420]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.094145,	
2017-06-20 01:02:49,421 Epoch[35] Batch [1430]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.094060,	
2017-06-20 01:02:54,104 Epoch[35] Batch [1440]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.094126,	
2017-06-20 01:02:58,741 Epoch[35] Batch [1450]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.094169,	
2017-06-20 01:03:03,459 Epoch[35] Batch [1460]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.094150,	
2017-06-20 01:03:08,084 Epoch[35] Batch [1470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.094160,	
2017-06-20 01:03:12,873 Epoch[35] Batch [1480]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.094120,	
2017-06-20 01:03:15,750 Epoch[35] Train-FCNLogLoss=0.094089
2017-06-20 01:03:15,750 Epoch[35] Time cost=675.709
2017-06-20 01:03:16,589 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0036.params"
2017-06-20 01:03:18,161 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0036.states"
2017-06-20 01:03:23,549 Epoch[36] Batch [10]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.083836,	
2017-06-20 01:03:28,024 Epoch[36] Batch [20]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091700,	
2017-06-20 01:03:32,593 Epoch[36] Batch [30]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091852,	
2017-06-20 01:03:37,118 Epoch[36] Batch [40]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092434,	
2017-06-20 01:03:41,642 Epoch[36] Batch [50]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.093031,	
2017-06-20 01:03:46,349 Epoch[36] Batch [60]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091033,	
2017-06-20 01:03:51,007 Epoch[36] Batch [70]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092184,	
2017-06-20 01:03:55,801 Epoch[36] Batch [80]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.091408,	
2017-06-20 01:04:00,301 Epoch[36] Batch [90]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.092006,	
2017-06-20 01:04:05,004 Epoch[36] Batch [100]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091552,	
2017-06-20 01:04:09,671 Epoch[36] Batch [110]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.092127,	
2017-06-20 01:04:14,315 Epoch[36] Batch [120]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092489,	
2017-06-20 01:04:18,725 Epoch[36] Batch [130]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.092076,	
2017-06-20 01:04:23,243 Epoch[36] Batch [140]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.091927,	
2017-06-20 01:04:27,915 Epoch[36] Batch [150]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092241,	
2017-06-20 01:04:32,393 Epoch[36] Batch [160]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.092344,	
2017-06-20 01:04:36,717 Epoch[36] Batch [170]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.092570,	
2017-06-20 01:04:41,274 Epoch[36] Batch [180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092714,	
2017-06-20 01:04:45,854 Epoch[36] Batch [190]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092795,	
2017-06-20 01:04:50,551 Epoch[36] Batch [200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.092497,	
2017-06-20 01:04:55,171 Epoch[36] Batch [210]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092512,	
2017-06-20 01:04:59,686 Epoch[36] Batch [220]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092242,	
2017-06-20 01:05:03,999 Epoch[36] Batch [230]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.092092,	
2017-06-20 01:05:08,399 Epoch[36] Batch [240]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.091928,	
2017-06-20 01:05:13,029 Epoch[36] Batch [250]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091795,	
2017-06-20 01:05:17,444 Epoch[36] Batch [260]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091601,	
2017-06-20 01:05:22,028 Epoch[36] Batch [270]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091185,	
2017-06-20 01:05:26,677 Epoch[36] Batch [280]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091136,	
2017-06-20 01:05:31,180 Epoch[36] Batch [290]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.091538,	
2017-06-20 01:05:35,831 Epoch[36] Batch [300]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091419,	
2017-06-20 01:05:40,574 Epoch[36] Batch [310]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.091608,	
2017-06-20 01:05:45,044 Epoch[36] Batch [320]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.092045,	
2017-06-20 01:05:49,634 Epoch[36] Batch [330]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092349,	
2017-06-20 01:05:54,099 Epoch[36] Batch [340]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.092222,	
2017-06-20 01:05:58,431 Epoch[36] Batch [350]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.092322,	
2017-06-20 01:06:03,189 Epoch[36] Batch [360]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092669,	
2017-06-20 01:06:07,863 Epoch[36] Batch [370]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092621,	
2017-06-20 01:06:12,400 Epoch[36] Batch [380]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.092909,	
2017-06-20 01:06:17,174 Epoch[36] Batch [390]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092902,	
2017-06-20 01:06:21,739 Epoch[36] Batch [400]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092934,	
2017-06-20 01:06:26,642 Epoch[36] Batch [410]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092709,	
2017-06-20 01:06:31,166 Epoch[36] Batch [420]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092919,	
2017-06-20 01:06:35,974 Epoch[36] Batch [430]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092834,	
2017-06-20 01:06:40,643 Epoch[36] Batch [440]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.092803,	
2017-06-20 01:06:45,404 Epoch[36] Batch [450]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.092834,	
2017-06-20 01:06:50,118 Epoch[36] Batch [460]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.093453,	
2017-06-20 01:06:54,674 Epoch[36] Batch [470]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.093630,	
2017-06-20 01:06:59,488 Epoch[36] Batch [480]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.093751,	
2017-06-20 01:07:03,917 Epoch[36] Batch [490]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.093954,	
2017-06-20 01:07:08,684 Epoch[36] Batch [500]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.093978,	
2017-06-20 01:07:13,179 Epoch[36] Batch [510]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.094253,	
2017-06-20 01:07:17,629 Epoch[36] Batch [520]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.094265,	
2017-06-20 01:07:22,350 Epoch[36] Batch [530]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.094035,	
2017-06-20 01:07:26,914 Epoch[36] Batch [540]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.094047,	
2017-06-20 01:07:31,077 Epoch[36] Batch [550]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.094130,	
2017-06-20 01:07:35,584 Epoch[36] Batch [560]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.094233,	
2017-06-20 01:07:40,187 Epoch[36] Batch [570]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.094368,	
2017-06-20 01:07:44,755 Epoch[36] Batch [580]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.094369,	
2017-06-20 01:07:49,093 Epoch[36] Batch [590]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.094356,	
2017-06-20 01:07:53,559 Epoch[36] Batch [600]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.094239,	
2017-06-20 01:07:58,255 Epoch[36] Batch [610]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.094274,	
2017-06-20 01:08:02,554 Epoch[36] Batch [620]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094156,	
2017-06-20 01:08:07,424 Epoch[36] Batch [630]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.094048,	
2017-06-20 01:08:11,937 Epoch[36] Batch [640]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.094052,	
2017-06-20 01:08:16,411 Epoch[36] Batch [650]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.093975,	
2017-06-20 01:08:21,108 Epoch[36] Batch [660]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.093811,	
2017-06-20 01:08:25,500 Epoch[36] Batch [670]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.093731,	
2017-06-20 01:08:29,609 Epoch[36] Batch [680]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093721,	
2017-06-20 01:08:34,157 Epoch[36] Batch [690]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.093575,	
2017-06-20 01:08:38,647 Epoch[36] Batch [700]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.093625,	
2017-06-20 01:08:43,310 Epoch[36] Batch [710]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.093785,	
2017-06-20 01:08:47,788 Epoch[36] Batch [720]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.093910,	
2017-06-20 01:08:52,582 Epoch[36] Batch [730]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.093864,	
2017-06-20 01:08:56,806 Epoch[36] Batch [740]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.093693,	
2017-06-20 01:09:01,256 Epoch[36] Batch [750]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.093758,	
2017-06-20 01:09:05,632 Epoch[36] Batch [760]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.093818,	
2017-06-20 01:09:10,177 Epoch[36] Batch [770]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.093888,	
2017-06-20 01:09:14,820 Epoch[36] Batch [780]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.093910,	
2017-06-20 01:09:19,300 Epoch[36] Batch [790]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.093955,	
2017-06-20 01:09:23,927 Epoch[36] Batch [800]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.093909,	
2017-06-20 01:09:28,495 Epoch[36] Batch [810]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.093891,	
2017-06-20 01:09:33,217 Epoch[36] Batch [820]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.093881,	
2017-06-20 01:09:37,705 Epoch[36] Batch [830]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.093821,	
2017-06-20 01:09:42,003 Epoch[36] Batch [840]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.093821,	
2017-06-20 01:09:46,678 Epoch[36] Batch [850]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.093856,	
2017-06-20 01:09:51,178 Epoch[36] Batch [860]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.093900,	
2017-06-20 01:09:55,622 Epoch[36] Batch [870]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.093818,	
2017-06-20 01:10:00,204 Epoch[36] Batch [880]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.093784,	
2017-06-20 01:10:04,952 Epoch[36] Batch [890]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.093768,	
2017-06-20 01:10:09,581 Epoch[36] Batch [900]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.093875,	
2017-06-20 01:10:14,319 Epoch[36] Batch [910]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.093868,	
2017-06-20 01:10:18,876 Epoch[36] Batch [920]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.093818,	
2017-06-20 01:10:23,409 Epoch[36] Batch [930]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.093818,	
2017-06-20 01:10:27,918 Epoch[36] Batch [940]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.093813,	
2017-06-20 01:10:32,776 Epoch[36] Batch [950]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.093798,	
2017-06-20 01:10:37,506 Epoch[36] Batch [960]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.093826,	
2017-06-20 01:10:42,184 Epoch[36] Batch [970]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.093812,	
2017-06-20 01:10:46,539 Epoch[36] Batch [980]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.093814,	
2017-06-20 01:10:51,019 Epoch[36] Batch [990]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.093820,	
2017-06-20 01:10:56,016 Epoch[36] Batch [1000]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.093793,	
2017-06-20 01:11:00,866 Epoch[36] Batch [1010]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.093733,	
2017-06-20 01:11:05,266 Epoch[36] Batch [1020]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.093716,	
2017-06-20 01:11:09,975 Epoch[36] Batch [1030]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.093654,	
2017-06-20 01:11:14,517 Epoch[36] Batch [1040]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.093620,	
2017-06-20 01:11:19,054 Epoch[36] Batch [1050]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.093540,	
2017-06-20 01:11:23,476 Epoch[36] Batch [1060]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.093405,	
2017-06-20 01:11:28,280 Epoch[36] Batch [1070]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.093438,	
2017-06-20 01:11:32,725 Epoch[36] Batch [1080]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.093464,	
2017-06-20 01:11:37,276 Epoch[36] Batch [1090]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.093489,	
2017-06-20 01:11:42,076 Epoch[36] Batch [1100]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.093690,	
2017-06-20 01:11:46,810 Epoch[36] Batch [1110]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.093745,	
2017-06-20 01:11:51,245 Epoch[36] Batch [1120]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.093674,	
2017-06-20 01:11:55,826 Epoch[36] Batch [1130]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.093640,	
2017-06-20 01:12:00,365 Epoch[36] Batch [1140]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.093575,	
2017-06-20 01:12:04,536 Epoch[36] Batch [1150]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.093653,	
2017-06-20 01:12:09,008 Epoch[36] Batch [1160]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.093618,	
2017-06-20 01:12:13,791 Epoch[36] Batch [1170]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.093631,	
2017-06-20 01:12:18,383 Epoch[36] Batch [1180]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.093631,	
2017-06-20 01:12:22,787 Epoch[36] Batch [1190]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.093616,	
2017-06-20 01:12:27,436 Epoch[36] Batch [1200]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.093567,	
2017-06-20 01:12:32,033 Epoch[36] Batch [1210]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.093533,	
2017-06-20 01:12:36,391 Epoch[36] Batch [1220]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.093487,	
2017-06-20 01:12:41,046 Epoch[36] Batch [1230]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.093506,	
2017-06-20 01:12:45,468 Epoch[36] Batch [1240]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.093492,	
2017-06-20 01:12:49,924 Epoch[36] Batch [1250]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.093596,	
2017-06-20 01:12:54,563 Epoch[36] Batch [1260]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.093659,	
2017-06-20 01:12:59,268 Epoch[36] Batch [1270]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.093720,	
2017-06-20 01:13:03,836 Epoch[36] Batch [1280]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.093715,	
2017-06-20 01:13:08,354 Epoch[36] Batch [1290]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.093653,	
2017-06-20 01:13:12,626 Epoch[36] Batch [1300]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.093662,	
2017-06-20 01:13:17,085 Epoch[36] Batch [1310]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.093698,	
2017-06-20 01:13:21,607 Epoch[36] Batch [1320]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.093685,	
2017-06-20 01:13:25,899 Epoch[36] Batch [1330]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.093721,	
2017-06-20 01:13:30,399 Epoch[36] Batch [1340]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.093725,	
2017-06-20 01:13:35,375 Epoch[36] Batch [1350]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.093831,	
2017-06-20 01:13:40,168 Epoch[36] Batch [1360]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.093922,	
2017-06-20 01:13:44,841 Epoch[36] Batch [1370]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.094000,	
2017-06-20 01:13:49,121 Epoch[36] Batch [1380]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.093967,	
2017-06-20 01:13:53,882 Epoch[36] Batch [1390]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.093995,	
2017-06-20 01:13:58,484 Epoch[36] Batch [1400]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.093962,	
2017-06-20 01:14:03,092 Epoch[36] Batch [1410]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.093946,	
2017-06-20 01:14:07,390 Epoch[36] Batch [1420]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.093914,	
2017-06-20 01:14:12,107 Epoch[36] Batch [1430]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.093883,	
2017-06-20 01:14:16,589 Epoch[36] Batch [1440]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.093890,	
2017-06-20 01:14:21,008 Epoch[36] Batch [1450]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.093947,	
2017-06-20 01:14:25,325 Epoch[36] Batch [1460]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.093911,	
2017-06-20 01:14:29,769 Epoch[36] Batch [1470]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.093883,	
2017-06-20 01:14:34,427 Epoch[36] Batch [1480]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.093898,	
2017-06-20 01:14:37,268 Epoch[36] Train-FCNLogLoss=0.093993
2017-06-20 01:14:37,268 Epoch[36] Time cost=679.107
2017-06-20 01:14:38,014 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0037.params"
2017-06-20 01:14:39,677 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0037.states"
2017-06-20 01:14:45,244 Epoch[37] Batch [10]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090632,	
2017-06-20 01:14:49,741 Epoch[37] Batch [20]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091649,	
2017-06-20 01:14:54,434 Epoch[37] Batch [30]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091265,	
2017-06-20 01:14:59,181 Epoch[37] Batch [40]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.091653,	
2017-06-20 01:15:03,687 Epoch[37] Batch [50]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.091108,	
2017-06-20 01:15:08,109 Epoch[37] Batch [60]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.090256,	
2017-06-20 01:15:13,015 Epoch[37] Batch [70]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.090216,	
2017-06-20 01:15:17,357 Epoch[37] Batch [80]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.090949,	
2017-06-20 01:15:22,088 Epoch[37] Batch [90]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091479,	
2017-06-20 01:15:26,883 Epoch[37] Batch [100]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.090784,	
2017-06-20 01:15:31,513 Epoch[37] Batch [110]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090409,	
2017-06-20 01:15:36,001 Epoch[37] Batch [120]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091001,	
2017-06-20 01:15:40,604 Epoch[37] Batch [130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090982,	
2017-06-20 01:15:45,323 Epoch[37] Batch [140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090378,	
2017-06-20 01:15:49,725 Epoch[37] Batch [150]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.090087,	
2017-06-20 01:15:53,879 Epoch[37] Batch [160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.089999,	
2017-06-20 01:15:58,060 Epoch[37] Batch [170]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.089855,	
2017-06-20 01:16:02,701 Epoch[37] Batch [180]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089554,	
2017-06-20 01:16:07,247 Epoch[37] Batch [190]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089659,	
2017-06-20 01:16:11,854 Epoch[37] Batch [200]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.089566,	
2017-06-20 01:16:16,150 Epoch[37] Batch [210]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.089981,	
2017-06-20 01:16:20,598 Epoch[37] Batch [220]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090079,	
2017-06-20 01:16:25,186 Epoch[37] Batch [230]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.090147,	
2017-06-20 01:16:29,709 Epoch[37] Batch [240]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.090360,	
2017-06-20 01:16:34,167 Epoch[37] Batch [250]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.090313,	
2017-06-20 01:16:38,587 Epoch[37] Batch [260]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.090194,	
2017-06-20 01:16:43,134 Epoch[37] Batch [270]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090343,	
2017-06-20 01:16:47,871 Epoch[37] Batch [280]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090613,	
2017-06-20 01:16:52,793 Epoch[37] Batch [290]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.090901,	
2017-06-20 01:16:57,539 Epoch[37] Batch [300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.091287,	
2017-06-20 01:17:02,401 Epoch[37] Batch [310]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.091395,	
2017-06-20 01:17:06,994 Epoch[37] Batch [320]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.091968,	
2017-06-20 01:17:11,533 Epoch[37] Batch [330]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.100167,	
2017-06-20 01:17:16,180 Epoch[37] Batch [340]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.105674,	
2017-06-20 01:17:20,528 Epoch[37] Batch [350]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.108744,	
2017-06-20 01:17:25,122 Epoch[37] Batch [360]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.110515,	
2017-06-20 01:17:29,897 Epoch[37] Batch [370]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.114438,	
2017-06-20 01:17:34,550 Epoch[37] Batch [380]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.116101,	
2017-06-20 01:17:38,930 Epoch[37] Batch [390]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.120415,	
2017-06-20 01:17:43,669 Epoch[37] Batch [400]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.123617,	
2017-06-20 01:17:48,448 Epoch[37] Batch [410]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.124819,	
2017-06-20 01:17:52,818 Epoch[37] Batch [420]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.125407,	
2017-06-20 01:17:57,251 Epoch[37] Batch [430]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.126644,	
2017-06-20 01:18:01,917 Epoch[37] Batch [440]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.127169,	
2017-06-20 01:18:06,509 Epoch[37] Batch [450]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.127355,	
2017-06-20 01:18:11,053 Epoch[37] Batch [460]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.127258,	
2017-06-20 01:18:15,753 Epoch[37] Batch [470]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.127260,	
2017-06-20 01:18:20,224 Epoch[37] Batch [480]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.127925,	
2017-06-20 01:18:24,887 Epoch[37] Batch [490]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.127918,	
2017-06-20 01:18:29,338 Epoch[37] Batch [500]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.127756,	
2017-06-20 01:18:33,793 Epoch[37] Batch [510]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.127175,	
2017-06-20 01:18:38,496 Epoch[37] Batch [520]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.127278,	
2017-06-20 01:18:42,884 Epoch[37] Batch [530]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.127519,	
2017-06-20 01:18:47,610 Epoch[37] Batch [540]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.127601,	
2017-06-20 01:18:52,278 Epoch[37] Batch [550]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.127484,	
2017-06-20 01:18:56,872 Epoch[37] Batch [560]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.127508,	
2017-06-20 01:19:01,458 Epoch[37] Batch [570]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.127478,	
2017-06-20 01:19:06,026 Epoch[37] Batch [580]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.127617,	
2017-06-20 01:19:10,722 Epoch[37] Batch [590]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.129500,	
2017-06-20 01:19:15,350 Epoch[37] Batch [600]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.130829,	
2017-06-20 01:19:19,688 Epoch[37] Batch [610]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.131555,	
2017-06-20 01:19:24,330 Epoch[37] Batch [620]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.131478,	
2017-06-20 01:19:28,843 Epoch[37] Batch [630]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.132100,	
2017-06-20 01:19:33,479 Epoch[37] Batch [640]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.132280,	
2017-06-20 01:19:38,119 Epoch[37] Batch [650]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.132617,	
2017-06-20 01:19:42,731 Epoch[37] Batch [660]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.132865,	
2017-06-20 01:19:47,572 Epoch[37] Batch [670]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.133264,	
2017-06-20 01:19:52,140 Epoch[37] Batch [680]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.133081,	
2017-06-20 01:19:56,485 Epoch[37] Batch [690]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.133657,	
2017-06-20 01:20:01,106 Epoch[37] Batch [700]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.134204,	
2017-06-20 01:20:05,607 Epoch[37] Batch [710]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.134021,	
2017-06-20 01:20:10,083 Epoch[37] Batch [720]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.134054,	
2017-06-20 01:20:15,016 Epoch[37] Batch [730]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.133938,	
2017-06-20 01:20:19,740 Epoch[37] Batch [740]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.133647,	
2017-06-20 01:20:24,619 Epoch[37] Batch [750]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.133617,	
2017-06-20 01:20:29,468 Epoch[37] Batch [760]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.133815,	
2017-06-20 01:20:33,926 Epoch[37] Batch [770]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.133853,	
2017-06-20 01:20:38,626 Epoch[37] Batch [780]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.133708,	
2017-06-20 01:20:42,995 Epoch[37] Batch [790]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.133518,	
2017-06-20 01:20:47,669 Epoch[37] Batch [800]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.133295,	
2017-06-20 01:20:52,143 Epoch[37] Batch [810]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.132934,	
2017-06-20 01:20:56,785 Epoch[37] Batch [820]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.132588,	
2017-06-20 01:21:01,245 Epoch[37] Batch [830]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.132315,	
2017-06-20 01:21:05,851 Epoch[37] Batch [840]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.131844,	
2017-06-20 01:21:10,576 Epoch[37] Batch [850]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.131650,	
2017-06-20 01:21:15,308 Epoch[37] Batch [860]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.131448,	
2017-06-20 01:21:19,753 Epoch[37] Batch [870]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.131192,	
2017-06-20 01:21:24,190 Epoch[37] Batch [880]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.130805,	
2017-06-20 01:21:28,790 Epoch[37] Batch [890]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.130708,	
2017-06-20 01:21:33,714 Epoch[37] Batch [900]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.130505,	
2017-06-20 01:21:38,348 Epoch[37] Batch [910]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.130445,	
2017-06-20 01:21:43,088 Epoch[37] Batch [920]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.130162,	
2017-06-20 01:21:47,756 Epoch[37] Batch [930]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.129845,	
2017-06-20 01:21:52,349 Epoch[37] Batch [940]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.129668,	
2017-06-20 01:21:57,069 Epoch[37] Batch [950]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.129490,	
2017-06-20 01:22:01,629 Epoch[37] Batch [960]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.129357,	
2017-06-20 01:22:06,539 Epoch[37] Batch [970]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.128972,	
2017-06-20 01:22:11,229 Epoch[37] Batch [980]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.129061,	
2017-06-20 01:22:15,710 Epoch[37] Batch [990]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.128962,	
2017-06-20 01:22:20,405 Epoch[37] Batch [1000]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.128688,	
2017-06-20 01:22:24,660 Epoch[37] Batch [1010]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.128474,	
2017-06-20 01:22:29,483 Epoch[37] Batch [1020]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.128348,	
2017-06-20 01:22:34,014 Epoch[37] Batch [1030]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.128210,	
2017-06-20 01:22:38,768 Epoch[37] Batch [1040]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.127921,	
2017-06-20 01:22:43,284 Epoch[37] Batch [1050]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.127959,	
2017-06-20 01:22:47,703 Epoch[37] Batch [1060]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.128137,	
2017-06-20 01:22:52,178 Epoch[37] Batch [1070]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.128176,	
2017-06-20 01:22:57,055 Epoch[37] Batch [1080]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.128077,	
2017-06-20 01:23:01,519 Epoch[37] Batch [1090]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.128018,	
2017-06-20 01:23:06,081 Epoch[37] Batch [1100]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.127868,	
2017-06-20 01:23:10,934 Epoch[37] Batch [1110]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.128163,	
2017-06-20 01:23:15,586 Epoch[37] Batch [1120]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.128209,	
2017-06-20 01:23:20,220 Epoch[37] Batch [1130]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.128336,	
2017-06-20 01:23:24,639 Epoch[37] Batch [1140]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.128249,	
2017-06-20 01:23:29,386 Epoch[37] Batch [1150]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.128110,	
2017-06-20 01:23:34,207 Epoch[37] Batch [1160]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.127852,	
2017-06-20 01:23:38,918 Epoch[37] Batch [1170]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.127624,	
2017-06-20 01:23:43,464 Epoch[37] Batch [1180]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.127420,	
2017-06-20 01:23:47,848 Epoch[37] Batch [1190]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.127612,	
2017-06-20 01:23:52,391 Epoch[37] Batch [1200]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.128769,	
2017-06-20 01:23:56,796 Epoch[37] Batch [1210]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.129470,	
2017-06-20 01:24:01,660 Epoch[37] Batch [1220]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.130076,	
2017-06-20 01:24:06,230 Epoch[37] Batch [1230]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.130407,	
2017-06-20 01:24:10,904 Epoch[37] Batch [1240]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.130772,	
2017-06-20 01:24:15,261 Epoch[37] Batch [1250]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.130855,	
2017-06-20 01:24:19,633 Epoch[37] Batch [1260]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.130930,	
2017-06-20 01:24:24,043 Epoch[37] Batch [1270]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.130827,	
2017-06-20 01:24:28,282 Epoch[37] Batch [1280]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.130665,	
2017-06-20 01:24:32,979 Epoch[37] Batch [1290]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.130470,	
2017-06-20 01:24:37,731 Epoch[37] Batch [1300]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.130424,	
2017-06-20 01:24:42,322 Epoch[37] Batch [1310]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.130274,	
2017-06-20 01:24:47,279 Epoch[37] Batch [1320]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.130235,	
2017-06-20 01:24:51,828 Epoch[37] Batch [1330]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.130283,	
2017-06-20 01:24:56,313 Epoch[37] Batch [1340]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.130135,	
2017-06-20 01:25:00,641 Epoch[37] Batch [1350]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.130062,	
2017-06-20 01:25:05,199 Epoch[37] Batch [1360]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.129950,	
2017-06-20 01:25:09,407 Epoch[37] Batch [1370]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.129966,	
2017-06-20 01:25:14,085 Epoch[37] Batch [1380]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.129927,	
2017-06-20 01:25:18,762 Epoch[37] Batch [1390]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.129950,	
2017-06-20 01:25:23,069 Epoch[37] Batch [1400]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.129890,	
2017-06-20 01:25:27,632 Epoch[37] Batch [1410]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.129766,	
2017-06-20 01:25:32,220 Epoch[37] Batch [1420]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.129606,	
2017-06-20 01:25:36,407 Epoch[37] Batch [1430]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.129469,	
2017-06-20 01:25:41,195 Epoch[37] Batch [1440]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.129353,	
2017-06-20 01:25:45,825 Epoch[37] Batch [1450]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.129163,	
2017-06-20 01:25:50,421 Epoch[37] Batch [1460]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.128900,	
2017-06-20 01:25:55,151 Epoch[37] Batch [1470]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.128704,	
2017-06-20 01:25:59,684 Epoch[37] Batch [1480]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.128599,	
2017-06-20 01:26:02,299 Epoch[37] Train-FCNLogLoss=0.128491
2017-06-20 01:26:02,299 Epoch[37] Time cost=682.622
2017-06-20 01:26:03,080 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0038.params"
2017-06-20 01:26:04,728 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0038.states"
2017-06-20 01:26:10,452 Epoch[38] Batch [10]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.111006,	
2017-06-20 01:26:15,163 Epoch[38] Batch [20]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.105774,	
2017-06-20 01:26:19,812 Epoch[38] Batch [30]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.108474,	
2017-06-20 01:26:23,961 Epoch[38] Batch [40]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.111374,	
2017-06-20 01:26:28,175 Epoch[38] Batch [50]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.114652,	
2017-06-20 01:26:32,681 Epoch[38] Batch [60]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.113500,	
2017-06-20 01:26:37,352 Epoch[38] Batch [70]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.111034,	
2017-06-20 01:26:41,847 Epoch[38] Batch [80]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.110481,	
2017-06-20 01:26:46,275 Epoch[38] Batch [90]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.110434,	
2017-06-20 01:26:50,925 Epoch[38] Batch [100]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.111547,	
2017-06-20 01:26:55,423 Epoch[38] Batch [110]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.110698,	
2017-06-20 01:26:59,951 Epoch[38] Batch [120]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.109764,	
2017-06-20 01:27:04,457 Epoch[38] Batch [130]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.110524,	
2017-06-20 01:27:08,696 Epoch[38] Batch [140]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.111903,	
2017-06-20 01:27:13,345 Epoch[38] Batch [150]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.111936,	
2017-06-20 01:27:17,782 Epoch[38] Batch [160]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111862,	
2017-06-20 01:27:22,572 Epoch[38] Batch [170]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.112663,	
2017-06-20 01:27:27,160 Epoch[38] Batch [180]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.112805,	
2017-06-20 01:27:31,600 Epoch[38] Batch [190]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.112908,	
2017-06-20 01:27:36,295 Epoch[38] Batch [200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.113802,	
2017-06-20 01:27:40,745 Epoch[38] Batch [210]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.113616,	
2017-06-20 01:27:45,225 Epoch[38] Batch [220]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.113685,	
2017-06-20 01:27:49,951 Epoch[38] Batch [230]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.112937,	
2017-06-20 01:27:54,598 Epoch[38] Batch [240]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.112669,	
2017-06-20 01:27:59,221 Epoch[38] Batch [250]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112343,	
2017-06-20 01:28:03,645 Epoch[38] Batch [260]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.112243,	
2017-06-20 01:28:08,128 Epoch[38] Batch [270]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.111517,	
2017-06-20 01:28:12,664 Epoch[38] Batch [280]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.111201,	
2017-06-20 01:28:17,021 Epoch[38] Batch [290]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.111753,	
2017-06-20 01:28:21,288 Epoch[38] Batch [300]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.111493,	
2017-06-20 01:28:25,991 Epoch[38] Batch [310]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.111828,	
2017-06-20 01:28:30,494 Epoch[38] Batch [320]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.111564,	
2017-06-20 01:28:35,126 Epoch[38] Batch [330]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.111198,	
2017-06-20 01:28:39,557 Epoch[38] Batch [340]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.112256,	
2017-06-20 01:28:44,354 Epoch[38] Batch [350]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.112857,	
2017-06-20 01:28:48,790 Epoch[38] Batch [360]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.113330,	
2017-06-20 01:28:53,322 Epoch[38] Batch [370]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.113866,	
2017-06-20 01:28:57,898 Epoch[38] Batch [380]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.113753,	
2017-06-20 01:29:02,323 Epoch[38] Batch [390]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.113603,	
2017-06-20 01:29:06,542 Epoch[38] Batch [400]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.113361,	
2017-06-20 01:29:11,331 Epoch[38] Batch [410]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.113080,	
2017-06-20 01:29:16,023 Epoch[38] Batch [420]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.113319,	
2017-06-20 01:29:20,344 Epoch[38] Batch [430]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.113566,	
2017-06-20 01:29:24,763 Epoch[38] Batch [440]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.113628,	
2017-06-20 01:29:29,680 Epoch[38] Batch [450]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.113295,	
2017-06-20 01:29:34,504 Epoch[38] Batch [460]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.113069,	
2017-06-20 01:29:39,255 Epoch[38] Batch [470]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.112941,	
2017-06-20 01:29:43,718 Epoch[38] Batch [480]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.112872,	
2017-06-20 01:29:48,256 Epoch[38] Batch [490]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112732,	
2017-06-20 01:29:52,936 Epoch[38] Batch [500]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.112458,	
2017-06-20 01:29:57,368 Epoch[38] Batch [510]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.112231,	
2017-06-20 01:30:01,517 Epoch[38] Batch [520]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.111946,	
2017-06-20 01:30:06,082 Epoch[38] Batch [530]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.111810,	
2017-06-20 01:30:10,509 Epoch[38] Batch [540]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.111695,	
2017-06-20 01:30:15,383 Epoch[38] Batch [550]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.111575,	
2017-06-20 01:30:20,109 Epoch[38] Batch [560]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.111581,	
2017-06-20 01:30:24,731 Epoch[38] Batch [570]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.111626,	
2017-06-20 01:30:29,389 Epoch[38] Batch [580]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.111560,	
2017-06-20 01:30:33,777 Epoch[38] Batch [590]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.111447,	
2017-06-20 01:30:38,006 Epoch[38] Batch [600]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.111298,	
2017-06-20 01:30:42,740 Epoch[38] Batch [610]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.111004,	
2017-06-20 01:30:47,377 Epoch[38] Batch [620]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.111172,	
2017-06-20 01:30:52,245 Epoch[38] Batch [630]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.110975,	
2017-06-20 01:30:56,682 Epoch[38] Batch [640]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.110811,	
2017-06-20 01:31:01,268 Epoch[38] Batch [650]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.110889,	
2017-06-20 01:31:05,959 Epoch[38] Batch [660]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.111470,	
2017-06-20 01:31:10,971 Epoch[38] Batch [670]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.111537,	
2017-06-20 01:31:15,482 Epoch[38] Batch [680]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.111597,	
2017-06-20 01:31:20,067 Epoch[38] Batch [690]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.113242,	
2017-06-20 01:31:24,627 Epoch[38] Batch [700]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.114018,	
2017-06-20 01:31:28,927 Epoch[38] Batch [710]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.114854,	
2017-06-20 01:31:33,536 Epoch[38] Batch [720]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.116453,	
2017-06-20 01:31:38,322 Epoch[38] Batch [730]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.116760,	
2017-06-20 01:31:43,107 Epoch[38] Batch [740]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.117208,	
2017-06-20 01:31:47,641 Epoch[38] Batch [750]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.117277,	
2017-06-20 01:31:52,252 Epoch[38] Batch [760]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.117360,	
2017-06-20 01:31:56,948 Epoch[38] Batch [770]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.117536,	
2017-06-20 01:32:01,403 Epoch[38] Batch [780]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.117569,	
2017-06-20 01:32:06,098 Epoch[38] Batch [790]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.117599,	
2017-06-20 01:32:10,896 Epoch[38] Batch [800]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.117433,	
2017-06-20 01:32:15,238 Epoch[38] Batch [810]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.117487,	
2017-06-20 01:32:20,141 Epoch[38] Batch [820]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.117458,	
2017-06-20 01:32:24,514 Epoch[38] Batch [830]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.117634,	
2017-06-20 01:32:29,170 Epoch[38] Batch [840]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.117600,	
2017-06-20 01:32:33,790 Epoch[38] Batch [850]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.117596,	
2017-06-20 01:32:38,582 Epoch[38] Batch [860]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.117425,	
2017-06-20 01:32:43,297 Epoch[38] Batch [870]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.117259,	
2017-06-20 01:32:48,046 Epoch[38] Batch [880]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.117121,	
2017-06-20 01:32:52,548 Epoch[38] Batch [890]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.116898,	
2017-06-20 01:32:57,190 Epoch[38] Batch [900]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.116695,	
2017-06-20 01:33:01,862 Epoch[38] Batch [910]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.116424,	
2017-06-20 01:33:06,499 Epoch[38] Batch [920]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.116327,	
2017-06-20 01:33:11,186 Epoch[38] Batch [930]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.116353,	
2017-06-20 01:33:15,778 Epoch[38] Batch [940]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.116262,	
2017-06-20 01:33:20,268 Epoch[38] Batch [950]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.116216,	
2017-06-20 01:33:24,597 Epoch[38] Batch [960]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.116085,	
2017-06-20 01:33:29,092 Epoch[38] Batch [970]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116086,	
2017-06-20 01:33:33,617 Epoch[38] Batch [980]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.116027,	
2017-06-20 01:33:38,040 Epoch[38] Batch [990]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.115890,	
2017-06-20 01:33:42,303 Epoch[38] Batch [1000]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.115846,	
2017-06-20 01:33:46,774 Epoch[38] Batch [1010]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.115681,	
2017-06-20 01:33:51,346 Epoch[38] Batch [1020]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.115680,	
2017-06-20 01:33:56,074 Epoch[38] Batch [1030]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.115605,	
2017-06-20 01:34:00,907 Epoch[38] Batch [1040]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.115488,	
2017-06-20 01:34:05,416 Epoch[38] Batch [1050]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.115491,	
2017-06-20 01:34:10,059 Epoch[38] Batch [1060]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.115305,	
2017-06-20 01:34:14,814 Epoch[38] Batch [1070]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.115314,	
2017-06-20 01:34:19,342 Epoch[38] Batch [1080]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.115219,	
2017-06-20 01:34:23,923 Epoch[38] Batch [1090]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.115021,	
2017-06-20 01:34:28,584 Epoch[38] Batch [1100]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.114936,	
2017-06-20 01:34:33,219 Epoch[38] Batch [1110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.114774,	
2017-06-20 01:34:37,879 Epoch[38] Batch [1120]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.114618,	
2017-06-20 01:34:42,714 Epoch[38] Batch [1130]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.114458,	
2017-06-20 01:34:47,341 Epoch[38] Batch [1140]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.114497,	
2017-06-20 01:34:52,006 Epoch[38] Batch [1150]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.114492,	
2017-06-20 01:34:56,533 Epoch[38] Batch [1160]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.114393,	
2017-06-20 01:35:00,905 Epoch[38] Batch [1170]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.114237,	
2017-06-20 01:35:05,601 Epoch[38] Batch [1180]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.114199,	
2017-06-20 01:35:10,138 Epoch[38] Batch [1190]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.114155,	
2017-06-20 01:35:14,763 Epoch[38] Batch [1200]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.114073,	
2017-06-20 01:35:19,133 Epoch[38] Batch [1210]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.114080,	
2017-06-20 01:35:23,966 Epoch[38] Batch [1220]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.113926,	
2017-06-20 01:35:28,507 Epoch[38] Batch [1230]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.113951,	
2017-06-20 01:35:33,338 Epoch[38] Batch [1240]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.113855,	
2017-06-20 01:35:38,055 Epoch[38] Batch [1250]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.113653,	
2017-06-20 01:35:42,697 Epoch[38] Batch [1260]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.113620,	
2017-06-20 01:35:47,317 Epoch[38] Batch [1270]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.113463,	
2017-06-20 01:35:51,759 Epoch[38] Batch [1280]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.113370,	
2017-06-20 01:35:56,601 Epoch[38] Batch [1290]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.113425,	
2017-06-20 01:36:01,073 Epoch[38] Batch [1300]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.113397,	
2017-06-20 01:36:05,524 Epoch[38] Batch [1310]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.113333,	
2017-06-20 01:36:10,191 Epoch[38] Batch [1320]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.113422,	
2017-06-20 01:36:14,648 Epoch[38] Batch [1330]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.113500,	
2017-06-20 01:36:19,357 Epoch[38] Batch [1340]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.113525,	
2017-06-20 01:36:24,038 Epoch[38] Batch [1350]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.113510,	
2017-06-20 01:36:28,586 Epoch[38] Batch [1360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.113397,	
2017-06-20 01:36:33,355 Epoch[38] Batch [1370]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.113310,	
2017-06-20 01:36:38,076 Epoch[38] Batch [1380]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.113260,	
2017-06-20 01:36:42,498 Epoch[38] Batch [1390]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.113142,	
2017-06-20 01:36:47,200 Epoch[38] Batch [1400]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.113074,	
2017-06-20 01:36:51,593 Epoch[38] Batch [1410]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.112959,	
2017-06-20 01:36:55,957 Epoch[38] Batch [1420]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.112872,	
2017-06-20 01:37:00,302 Epoch[38] Batch [1430]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.112742,	
2017-06-20 01:37:04,479 Epoch[38] Batch [1440]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112687,	
2017-06-20 01:37:08,944 Epoch[38] Batch [1450]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.112526,	
2017-06-20 01:37:13,482 Epoch[38] Batch [1460]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112475,	
2017-06-20 01:37:17,839 Epoch[38] Batch [1470]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.112381,	
2017-06-20 01:37:22,269 Epoch[38] Batch [1480]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.112327,	
2017-06-20 01:37:25,062 Epoch[38] Train-FCNLogLoss=0.112341
2017-06-20 01:37:25,062 Epoch[38] Time cost=680.334
2017-06-20 01:37:25,880 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0039.params"
2017-06-20 01:37:27,525 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0039.states"
2017-06-20 01:37:33,011 Epoch[39] Batch [10]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.107981,	
2017-06-20 01:37:37,666 Epoch[39] Batch [20]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.106358,	
2017-06-20 01:37:42,244 Epoch[39] Batch [30]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.103576,	
2017-06-20 01:37:46,376 Epoch[39] Batch [40]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103369,	
2017-06-20 01:37:50,652 Epoch[39] Batch [50]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.101412,	
2017-06-20 01:37:55,394 Epoch[39] Batch [60]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.100495,	
2017-06-20 01:38:00,175 Epoch[39] Batch [70]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.099901,	
2017-06-20 01:38:04,948 Epoch[39] Batch [80]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.099244,	
2017-06-20 01:38:09,704 Epoch[39] Batch [90]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.099918,	
2017-06-20 01:38:14,239 Epoch[39] Batch [100]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.098953,	
2017-06-20 01:38:19,212 Epoch[39] Batch [110]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.098555,	
2017-06-20 01:38:24,050 Epoch[39] Batch [120]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.099521,	
2017-06-20 01:38:28,847 Epoch[39] Batch [130]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.099621,	
2017-06-20 01:38:33,351 Epoch[39] Batch [140]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.099168,	
2017-06-20 01:38:37,853 Epoch[39] Batch [150]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.098857,	
2017-06-20 01:38:42,402 Epoch[39] Batch [160]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.098953,	
2017-06-20 01:38:47,209 Epoch[39] Batch [170]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.099093,	
2017-06-20 01:38:51,756 Epoch[39] Batch [180]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.098974,	
2017-06-20 01:38:56,339 Epoch[39] Batch [190]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.099066,	
2017-06-20 01:39:01,115 Epoch[39] Batch [200]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.099644,	
2017-06-20 01:39:05,999 Epoch[39] Batch [210]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.099774,	
2017-06-20 01:39:10,484 Epoch[39] Batch [220]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.099520,	
2017-06-20 01:39:15,173 Epoch[39] Batch [230]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.099625,	
2017-06-20 01:39:19,927 Epoch[39] Batch [240]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098905,	
2017-06-20 01:39:24,630 Epoch[39] Batch [250]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.098569,	
2017-06-20 01:39:29,290 Epoch[39] Batch [260]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.098478,	
2017-06-20 01:39:33,936 Epoch[39] Batch [270]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.098087,	
2017-06-20 01:39:38,549 Epoch[39] Batch [280]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.098157,	
2017-06-20 01:39:43,005 Epoch[39] Batch [290]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.098441,	
2017-06-20 01:39:47,749 Epoch[39] Batch [300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.098580,	
2017-06-20 01:39:52,543 Epoch[39] Batch [310]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.098399,	
2017-06-20 01:39:57,392 Epoch[39] Batch [320]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.098828,	
2017-06-20 01:40:01,797 Epoch[39] Batch [330]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099146,	
2017-06-20 01:40:06,229 Epoch[39] Batch [340]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.099310,	
2017-06-20 01:40:10,768 Epoch[39] Batch [350]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.099321,	
2017-06-20 01:40:15,308 Epoch[39] Batch [360]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.099418,	
2017-06-20 01:40:19,580 Epoch[39] Batch [370]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.099263,	
2017-06-20 01:40:24,102 Epoch[39] Batch [380]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.099009,	
2017-06-20 01:40:28,717 Epoch[39] Batch [390]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.099320,	
2017-06-20 01:40:33,697 Epoch[39] Batch [400]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.099162,	
2017-06-20 01:40:38,257 Epoch[39] Batch [410]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.099071,	
2017-06-20 01:40:42,513 Epoch[39] Batch [420]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.099268,	
2017-06-20 01:40:47,374 Epoch[39] Batch [430]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.099265,	
2017-06-20 01:40:51,795 Epoch[39] Batch [440]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.099120,	
2017-06-20 01:40:56,573 Epoch[39] Batch [450]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.099134,	
2017-06-20 01:41:01,067 Epoch[39] Batch [460]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.099144,	
2017-06-20 01:41:05,598 Epoch[39] Batch [470]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.098910,	
2017-06-20 01:41:10,074 Epoch[39] Batch [480]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.098848,	
2017-06-20 01:41:14,911 Epoch[39] Batch [490]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.098646,	
2017-06-20 01:41:19,841 Epoch[39] Batch [500]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.098693,	
2017-06-20 01:41:24,618 Epoch[39] Batch [510]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.098589,	
2017-06-20 01:41:29,093 Epoch[39] Batch [520]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.098478,	
2017-06-20 01:41:33,411 Epoch[39] Batch [530]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.098411,	
2017-06-20 01:41:38,250 Epoch[39] Batch [540]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.098600,	
2017-06-20 01:41:42,957 Epoch[39] Batch [550]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.098683,	
2017-06-20 01:41:47,730 Epoch[39] Batch [560]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.098678,	
2017-06-20 01:41:52,083 Epoch[39] Batch [570]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.098635,	
2017-06-20 01:41:56,310 Epoch[39] Batch [580]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.098441,	
2017-06-20 01:42:00,581 Epoch[39] Batch [590]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.098365,	
2017-06-20 01:42:04,820 Epoch[39] Batch [600]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.098452,	
2017-06-20 01:42:09,316 Epoch[39] Batch [610]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.098330,	
2017-06-20 01:42:13,870 Epoch[39] Batch [620]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.098410,	
2017-06-20 01:42:18,590 Epoch[39] Batch [630]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.098364,	
2017-06-20 01:42:23,309 Epoch[39] Batch [640]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.098221,	
2017-06-20 01:42:27,865 Epoch[39] Batch [650]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.098267,	
2017-06-20 01:42:31,912 Epoch[39] Batch [660]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.098071,	
2017-06-20 01:42:36,541 Epoch[39] Batch [670]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.098074,	
2017-06-20 01:42:41,016 Epoch[39] Batch [680]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.097980,	
2017-06-20 01:42:45,519 Epoch[39] Batch [690]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.098103,	
2017-06-20 01:42:50,312 Epoch[39] Batch [700]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.097966,	
2017-06-20 01:42:54,972 Epoch[39] Batch [710]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.097885,	
2017-06-20 01:42:59,615 Epoch[39] Batch [720]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.097763,	
2017-06-20 01:43:04,174 Epoch[39] Batch [730]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.097632,	
2017-06-20 01:43:08,816 Epoch[39] Batch [740]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.097543,	
2017-06-20 01:43:13,365 Epoch[39] Batch [750]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.097542,	
2017-06-20 01:43:17,701 Epoch[39] Batch [760]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097536,	
2017-06-20 01:43:22,036 Epoch[39] Batch [770]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097599,	
2017-06-20 01:43:26,688 Epoch[39] Batch [780]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.097689,	
2017-06-20 01:43:31,447 Epoch[39] Batch [790]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.097631,	
2017-06-20 01:43:36,346 Epoch[39] Batch [800]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.097708,	
2017-06-20 01:43:41,201 Epoch[39] Batch [810]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.097568,	
2017-06-20 01:43:45,978 Epoch[39] Batch [820]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.097628,	
2017-06-20 01:43:50,707 Epoch[39] Batch [830]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.097587,	
2017-06-20 01:43:55,649 Epoch[39] Batch [840]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.097561,	
2017-06-20 01:44:00,142 Epoch[39] Batch [850]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.097680,	
2017-06-20 01:44:04,478 Epoch[39] Batch [860]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097653,	
2017-06-20 01:44:09,090 Epoch[39] Batch [870]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.097567,	
2017-06-20 01:44:13,829 Epoch[39] Batch [880]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.097534,	
2017-06-20 01:44:18,534 Epoch[39] Batch [890]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.097481,	
2017-06-20 01:44:23,246 Epoch[39] Batch [900]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.097345,	
2017-06-20 01:44:27,660 Epoch[39] Batch [910]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.097244,	
2017-06-20 01:44:32,351 Epoch[39] Batch [920]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.097083,	
2017-06-20 01:44:37,123 Epoch[39] Batch [930]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.097071,	
2017-06-20 01:44:41,889 Epoch[39] Batch [940]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.097091,	
2017-06-20 01:44:46,383 Epoch[39] Batch [950]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.097007,	
2017-06-20 01:44:50,695 Epoch[39] Batch [960]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.096894,	
2017-06-20 01:44:55,406 Epoch[39] Batch [970]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.096883,	
2017-06-20 01:45:00,166 Epoch[39] Batch [980]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.096854,	
2017-06-20 01:45:04,877 Epoch[39] Batch [990]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.096780,	
2017-06-20 01:45:09,585 Epoch[39] Batch [1000]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.096707,	
2017-06-20 01:45:14,002 Epoch[39] Batch [1010]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.097081,	
2017-06-20 01:45:18,808 Epoch[39] Batch [1020]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.097191,	
2017-06-20 01:45:23,429 Epoch[39] Batch [1030]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.097435,	
2017-06-20 01:45:28,051 Epoch[39] Batch [1040]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.097409,	
2017-06-20 01:45:32,517 Epoch[39] Batch [1050]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097264,	
2017-06-20 01:45:37,247 Epoch[39] Batch [1060]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.097292,	
2017-06-20 01:45:41,841 Epoch[39] Batch [1070]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.097306,	
2017-06-20 01:45:46,370 Epoch[39] Batch [1080]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.097335,	
2017-06-20 01:45:51,113 Epoch[39] Batch [1090]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.097313,	
2017-06-20 01:45:55,640 Epoch[39] Batch [1100]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.097303,	
2017-06-20 01:46:00,161 Epoch[39] Batch [1110]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097219,	
2017-06-20 01:46:04,421 Epoch[39] Batch [1120]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.097212,	
2017-06-20 01:46:08,885 Epoch[39] Batch [1130]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097191,	
2017-06-20 01:46:13,363 Epoch[39] Batch [1140]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.097278,	
2017-06-20 01:46:17,669 Epoch[39] Batch [1150]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.097211,	
2017-06-20 01:46:22,248 Epoch[39] Batch [1160]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.097184,	
2017-06-20 01:46:26,691 Epoch[39] Batch [1170]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.097190,	
2017-06-20 01:46:31,142 Epoch[39] Batch [1180]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.097173,	
2017-06-20 01:46:35,841 Epoch[39] Batch [1190]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.097152,	
2017-06-20 01:46:40,817 Epoch[39] Batch [1200]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.097155,	
2017-06-20 01:46:45,394 Epoch[39] Batch [1210]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.097131,	
2017-06-20 01:46:49,968 Epoch[39] Batch [1220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.097172,	
2017-06-20 01:46:54,710 Epoch[39] Batch [1230]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.097165,	
2017-06-20 01:46:59,499 Epoch[39] Batch [1240]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.097105,	
2017-06-20 01:47:04,216 Epoch[39] Batch [1250]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.097167,	
2017-06-20 01:47:09,190 Epoch[39] Batch [1260]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.097181,	
2017-06-20 01:47:13,646 Epoch[39] Batch [1270]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.097200,	
2017-06-20 01:47:18,309 Epoch[39] Batch [1280]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.097170,	
2017-06-20 01:47:22,716 Epoch[39] Batch [1290]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.097168,	
2017-06-20 01:47:27,248 Epoch[39] Batch [1300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.097138,	
2017-06-20 01:47:31,819 Epoch[39] Batch [1310]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.097077,	
2017-06-20 01:47:36,331 Epoch[39] Batch [1320]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.097067,	
2017-06-20 01:47:40,683 Epoch[39] Batch [1330]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.097021,	
2017-06-20 01:47:45,125 Epoch[39] Batch [1340]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.097004,	
2017-06-20 01:47:49,331 Epoch[39] Batch [1350]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.096964,	
2017-06-20 01:47:54,065 Epoch[39] Batch [1360]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.096987,	
2017-06-20 01:47:58,788 Epoch[39] Batch [1370]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.097025,	
2017-06-20 01:48:03,493 Epoch[39] Batch [1380]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.097018,	
2017-06-20 01:48:08,278 Epoch[39] Batch [1390]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.097157,	
2017-06-20 01:48:12,736 Epoch[39] Batch [1400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.097133,	
2017-06-20 01:48:17,610 Epoch[39] Batch [1410]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.097172,	
2017-06-20 01:48:22,204 Epoch[39] Batch [1420]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.097270,	
2017-06-20 01:48:26,664 Epoch[39] Batch [1430]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.097330,	
2017-06-20 01:48:30,784 Epoch[39] Batch [1440]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097452,	
2017-06-20 01:48:35,362 Epoch[39] Batch [1450]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.097453,	
2017-06-20 01:48:39,888 Epoch[39] Batch [1460]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.097445,	
2017-06-20 01:48:44,833 Epoch[39] Batch [1470]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.097437,	
2017-06-20 01:48:49,570 Epoch[39] Batch [1480]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.097418,	
2017-06-20 01:48:52,425 Epoch[39] Train-FCNLogLoss=0.097407
2017-06-20 01:48:52,425 Epoch[39] Time cost=684.900
2017-06-20 01:48:53,083 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0040.params"
2017-06-20 01:48:54,566 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0040.states"
2017-06-20 01:49:00,318 Epoch[40] Batch [10]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086321,	
2017-06-20 01:49:04,987 Epoch[40] Batch [20]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.091175,	
2017-06-20 01:49:09,491 Epoch[40] Batch [30]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095111,	
2017-06-20 01:49:14,099 Epoch[40] Batch [40]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.095251,	
2017-06-20 01:49:18,761 Epoch[40] Batch [50]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.097906,	
2017-06-20 01:49:23,392 Epoch[40] Batch [60]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.095587,	
2017-06-20 01:49:27,957 Epoch[40] Batch [70]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.094828,	
2017-06-20 01:49:32,726 Epoch[40] Batch [80]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.095066,	
2017-06-20 01:49:37,515 Epoch[40] Batch [90]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.095113,	
2017-06-20 01:49:42,447 Epoch[40] Batch [100]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.096379,	
2017-06-20 01:49:46,915 Epoch[40] Batch [110]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.096580,	
2017-06-20 01:49:51,381 Epoch[40] Batch [120]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097266,	
2017-06-20 01:49:56,181 Epoch[40] Batch [130]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.097131,	
2017-06-20 01:50:00,708 Epoch[40] Batch [140]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.097083,	
2017-06-20 01:50:05,377 Epoch[40] Batch [150]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.097074,	
2017-06-20 01:50:09,843 Epoch[40] Batch [160]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.096687,	
2017-06-20 01:50:14,246 Epoch[40] Batch [170]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.096527,	
2017-06-20 01:50:19,270 Epoch[40] Batch [180]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.095916,	
2017-06-20 01:50:23,985 Epoch[40] Batch [190]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.095996,	
2017-06-20 01:50:28,341 Epoch[40] Batch [200]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.096052,	
2017-06-20 01:50:33,047 Epoch[40] Batch [210]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.096025,	
2017-06-20 01:50:37,829 Epoch[40] Batch [220]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.096323,	
2017-06-20 01:50:42,556 Epoch[40] Batch [230]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.096428,	
2017-06-20 01:50:47,344 Epoch[40] Batch [240]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.096132,	
2017-06-20 01:50:51,831 Epoch[40] Batch [250]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.095792,	
2017-06-20 01:50:56,397 Epoch[40] Batch [260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.095675,	
2017-06-20 01:51:00,913 Epoch[40] Batch [270]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.095746,	
2017-06-20 01:51:05,417 Epoch[40] Batch [280]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095795,	
2017-06-20 01:51:10,149 Epoch[40] Batch [290]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.095581,	
2017-06-20 01:51:14,822 Epoch[40] Batch [300]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.095522,	
2017-06-20 01:51:19,461 Epoch[40] Batch [310]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.095360,	
2017-06-20 01:51:24,122 Epoch[40] Batch [320]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095007,	
2017-06-20 01:51:28,896 Epoch[40] Batch [330]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.095253,	
2017-06-20 01:51:33,611 Epoch[40] Batch [340]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.095151,	
2017-06-20 01:51:38,081 Epoch[40] Batch [350]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.095004,	
2017-06-20 01:51:42,689 Epoch[40] Batch [360]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.095176,	
2017-06-20 01:51:47,166 Epoch[40] Batch [370]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.095194,	
2017-06-20 01:51:51,762 Epoch[40] Batch [380]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.095002,	
2017-06-20 01:51:56,598 Epoch[40] Batch [390]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.094924,	
2017-06-20 01:52:01,292 Epoch[40] Batch [400]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.094806,	
2017-06-20 01:52:05,514 Epoch[40] Batch [410]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094871,	
2017-06-20 01:52:09,906 Epoch[40] Batch [420]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.095271,	
2017-06-20 01:52:14,543 Epoch[40] Batch [430]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.095308,	
2017-06-20 01:52:18,938 Epoch[40] Batch [440]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095525,	
2017-06-20 01:52:23,515 Epoch[40] Batch [450]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.095528,	
2017-06-20 01:52:27,978 Epoch[40] Batch [460]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.095539,	
2017-06-20 01:52:32,995 Epoch[40] Batch [470]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.095276,	
2017-06-20 01:52:37,733 Epoch[40] Batch [480]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.095415,	
2017-06-20 01:52:42,484 Epoch[40] Batch [490]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.095345,	
2017-06-20 01:52:47,028 Epoch[40] Batch [500]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.095282,	
2017-06-20 01:52:51,610 Epoch[40] Batch [510]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.095204,	
2017-06-20 01:52:55,279 Update[60000]: Change learning rate to 5.00000e-05
2017-06-20 01:52:56,036 Epoch[40] Batch [520]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095122,	
2017-06-20 01:53:01,112 Epoch[40] Batch [530]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.095306,	
2017-06-20 01:53:05,598 Epoch[40] Batch [540]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.095209,	
2017-06-20 01:53:09,764 Epoch[40] Batch [550]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095258,	
2017-06-20 01:53:14,218 Epoch[40] Batch [560]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.095231,	
2017-06-20 01:53:18,923 Epoch[40] Batch [570]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.095460,	
2017-06-20 01:53:23,267 Epoch[40] Batch [580]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.095337,	
2017-06-20 01:53:27,777 Epoch[40] Batch [590]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.095161,	
2017-06-20 01:53:32,522 Epoch[40] Batch [600]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.095195,	
2017-06-20 01:53:36,969 Epoch[40] Batch [610]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.095121,	
2017-06-20 01:53:41,724 Epoch[40] Batch [620]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.094912,	
2017-06-20 01:53:46,401 Epoch[40] Batch [630]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.094846,	
2017-06-20 01:53:50,670 Epoch[40] Batch [640]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.094767,	
2017-06-20 01:53:55,052 Epoch[40] Batch [650]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.094834,	
2017-06-20 01:53:59,407 Epoch[40] Batch [660]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.094735,	
2017-06-20 01:54:04,156 Epoch[40] Batch [670]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.094573,	
2017-06-20 01:54:08,956 Epoch[40] Batch [680]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.094317,	
2017-06-20 01:54:13,517 Epoch[40] Batch [690]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.094156,	
2017-06-20 01:54:18,433 Epoch[40] Batch [700]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.094096,	
2017-06-20 01:54:23,001 Epoch[40] Batch [710]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.094121,	
2017-06-20 01:54:27,629 Epoch[40] Batch [720]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.094092,	
2017-06-20 01:54:32,122 Epoch[40] Batch [730]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.094090,	
2017-06-20 01:54:36,686 Epoch[40] Batch [740]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.094063,	
2017-06-20 01:54:41,251 Epoch[40] Batch [750]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.093897,	
2017-06-20 01:54:45,708 Epoch[40] Batch [760]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.093868,	
2017-06-20 01:54:50,190 Epoch[40] Batch [770]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.093908,	
2017-06-20 01:54:54,951 Epoch[40] Batch [780]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.093748,	
2017-06-20 01:54:59,562 Epoch[40] Batch [790]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.093572,	
2017-06-20 01:55:03,863 Epoch[40] Batch [800]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.093509,	
2017-06-20 01:55:08,349 Epoch[40] Batch [810]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.093533,	
2017-06-20 01:55:12,671 Epoch[40] Batch [820]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.093477,	
2017-06-20 01:55:17,398 Epoch[40] Batch [830]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.093353,	
2017-06-20 01:55:21,961 Epoch[40] Batch [840]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.093367,	
2017-06-20 01:55:26,859 Epoch[40] Batch [850]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.093494,	
2017-06-20 01:55:31,475 Epoch[40] Batch [860]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.093604,	
2017-06-20 01:55:36,093 Epoch[40] Batch [870]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.093627,	
2017-06-20 01:55:40,622 Epoch[40] Batch [880]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.093618,	
2017-06-20 01:55:44,953 Epoch[40] Batch [890]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.093522,	
2017-06-20 01:55:49,588 Epoch[40] Batch [900]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.093443,	
2017-06-20 01:55:54,102 Epoch[40] Batch [910]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.093425,	
2017-06-20 01:55:58,660 Epoch[40] Batch [920]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.093239,	
2017-06-20 01:56:03,395 Epoch[40] Batch [930]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.093236,	
2017-06-20 01:56:07,965 Epoch[40] Batch [940]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.093310,	
2017-06-20 01:56:12,465 Epoch[40] Batch [950]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.093196,	
2017-06-20 01:56:17,237 Epoch[40] Batch [960]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.093220,	
2017-06-20 01:56:21,820 Epoch[40] Batch [970]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.093122,	
2017-06-20 01:56:26,399 Epoch[40] Batch [980]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092994,	
2017-06-20 01:56:31,305 Epoch[40] Batch [990]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.093020,	
2017-06-20 01:56:36,003 Epoch[40] Batch [1000]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.092964,	
2017-06-20 01:56:40,711 Epoch[40] Batch [1010]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.092917,	
2017-06-20 01:56:45,108 Epoch[40] Batch [1020]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.092888,	
2017-06-20 01:56:49,740 Epoch[40] Batch [1030]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.092888,	
2017-06-20 01:56:54,151 Epoch[40] Batch [1040]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.092739,	
2017-06-20 01:56:59,022 Epoch[40] Batch [1050]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.092732,	
2017-06-20 01:57:03,632 Epoch[40] Batch [1060]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.092718,	
2017-06-20 01:57:08,544 Epoch[40] Batch [1070]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.092757,	
2017-06-20 01:57:13,373 Epoch[40] Batch [1080]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092717,	
2017-06-20 01:57:17,796 Epoch[40] Batch [1090]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.092708,	
2017-06-20 01:57:22,542 Epoch[40] Batch [1100]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.092701,	
2017-06-20 01:57:27,085 Epoch[40] Batch [1110]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092655,	
2017-06-20 01:57:32,010 Epoch[40] Batch [1120]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.092590,	
2017-06-20 01:57:36,752 Epoch[40] Batch [1130]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092543,	
2017-06-20 01:57:41,447 Epoch[40] Batch [1140]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.092557,	
2017-06-20 01:57:46,100 Epoch[40] Batch [1150]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.092623,	
2017-06-20 01:57:50,623 Epoch[40] Batch [1160]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092608,	
2017-06-20 01:57:55,096 Epoch[40] Batch [1170]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092637,	
2017-06-20 01:57:59,700 Epoch[40] Batch [1180]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092657,	
2017-06-20 01:58:04,416 Epoch[40] Batch [1190]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.092652,	
2017-06-20 01:58:09,339 Epoch[40] Batch [1200]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092599,	
2017-06-20 01:58:14,031 Epoch[40] Batch [1210]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092495,	
2017-06-20 01:58:18,564 Epoch[40] Batch [1220]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.092480,	
2017-06-20 01:58:23,309 Epoch[40] Batch [1230]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.092471,	
2017-06-20 01:58:28,090 Epoch[40] Batch [1240]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.092492,	
2017-06-20 01:58:32,990 Epoch[40] Batch [1250]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092361,	
2017-06-20 01:58:37,829 Epoch[40] Batch [1260]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092324,	
2017-06-20 01:58:42,228 Epoch[40] Batch [1270]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.092322,	
2017-06-20 01:58:46,587 Epoch[40] Batch [1280]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.092292,	
2017-06-20 01:58:51,208 Epoch[40] Batch [1290]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092307,	
2017-06-20 01:58:55,951 Epoch[40] Batch [1300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.092264,	
2017-06-20 01:59:00,809 Epoch[40] Batch [1310]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.092253,	
2017-06-20 01:59:05,429 Epoch[40] Batch [1320]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092230,	
2017-06-20 01:59:09,908 Epoch[40] Batch [1330]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.092246,	
2017-06-20 01:59:14,910 Epoch[40] Batch [1340]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.092242,	
2017-06-20 01:59:19,657 Epoch[40] Batch [1350]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.092208,	
2017-06-20 01:59:24,283 Epoch[40] Batch [1360]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.092145,	
2017-06-20 01:59:28,841 Epoch[40] Batch [1370]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092103,	
2017-06-20 01:59:33,495 Epoch[40] Batch [1380]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.092148,	
2017-06-20 01:59:38,169 Epoch[40] Batch [1390]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092113,	
2017-06-20 01:59:42,807 Epoch[40] Batch [1400]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.092164,	
2017-06-20 01:59:47,545 Epoch[40] Batch [1410]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092206,	
2017-06-20 01:59:52,124 Epoch[40] Batch [1420]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092166,	
2017-06-20 01:59:56,663 Epoch[40] Batch [1430]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092177,	
2017-06-20 02:00:01,199 Epoch[40] Batch [1440]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.092120,	
2017-06-20 02:00:06,009 Epoch[40] Batch [1450]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092064,	
2017-06-20 02:00:10,435 Epoch[40] Batch [1460]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.092047,	
2017-06-20 02:00:15,283 Epoch[40] Batch [1470]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091979,	
2017-06-20 02:00:19,989 Epoch[40] Batch [1480]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091991,	
2017-06-20 02:00:22,822 Epoch[40] Train-FCNLogLoss=0.091978
2017-06-20 02:00:22,822 Epoch[40] Time cost=688.256
2017-06-20 02:00:23,641 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0041.params"
2017-06-20 02:00:25,375 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0041.states"
2017-06-20 02:00:30,893 Epoch[41] Batch [10]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091015,	
2017-06-20 02:00:35,290 Epoch[41] Batch [20]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.091675,	
2017-06-20 02:00:39,851 Epoch[41] Batch [30]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090298,	
2017-06-20 02:00:44,008 Epoch[41] Batch [40]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.090364,	
2017-06-20 02:00:48,580 Epoch[41] Batch [50]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.089938,	
2017-06-20 02:00:53,034 Epoch[41] Batch [60]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091295,	
2017-06-20 02:00:57,429 Epoch[41] Batch [70]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.091444,	
2017-06-20 02:01:01,567 Epoch[41] Batch [80]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.090267,	
2017-06-20 02:01:05,966 Epoch[41] Batch [90]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.089653,	
2017-06-20 02:01:10,829 Epoch[41] Batch [100]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089871,	
2017-06-20 02:01:15,458 Epoch[41] Batch [110]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090033,	
2017-06-20 02:01:20,220 Epoch[41] Batch [120]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089724,	
2017-06-20 02:01:24,987 Epoch[41] Batch [130]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089579,	
2017-06-20 02:01:29,868 Epoch[41] Batch [140]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089549,	
2017-06-20 02:01:34,422 Epoch[41] Batch [150]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.090005,	
2017-06-20 02:01:38,726 Epoch[41] Batch [160]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.090110,	
2017-06-20 02:01:43,461 Epoch[41] Batch [170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090210,	
2017-06-20 02:01:48,127 Epoch[41] Batch [180]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090046,	
2017-06-20 02:01:52,485 Epoch[41] Batch [190]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089961,	
2017-06-20 02:01:57,098 Epoch[41] Batch [200]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.090432,	
2017-06-20 02:02:01,598 Epoch[41] Batch [210]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090265,	
2017-06-20 02:02:05,822 Epoch[41] Batch [220]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.090259,	
2017-06-20 02:02:10,408 Epoch[41] Batch [230]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.090046,	
2017-06-20 02:02:15,081 Epoch[41] Batch [240]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089822,	
2017-06-20 02:02:19,645 Epoch[41] Batch [250]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089781,	
2017-06-20 02:02:24,475 Epoch[41] Batch [260]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089844,	
2017-06-20 02:02:29,258 Epoch[41] Batch [270]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089634,	
2017-06-20 02:02:34,013 Epoch[41] Batch [280]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089788,	
2017-06-20 02:02:38,635 Epoch[41] Batch [290]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.089814,	
2017-06-20 02:02:43,128 Epoch[41] Batch [300]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089696,	
2017-06-20 02:02:47,776 Epoch[41] Batch [310]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089698,	
2017-06-20 02:02:52,486 Epoch[41] Batch [320]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089551,	
2017-06-20 02:02:56,745 Epoch[41] Batch [330]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.089809,	
2017-06-20 02:03:01,258 Epoch[41] Batch [340]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089901,	
2017-06-20 02:03:05,919 Epoch[41] Batch [350]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089851,	
2017-06-20 02:03:10,134 Epoch[41] Batch [360]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.089637,	
2017-06-20 02:03:14,666 Epoch[41] Batch [370]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089888,	
2017-06-20 02:03:19,146 Epoch[41] Batch [380]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089841,	
2017-06-20 02:03:23,848 Epoch[41] Batch [390]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089892,	
2017-06-20 02:03:28,204 Epoch[41] Batch [400]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089840,	
2017-06-20 02:03:32,870 Epoch[41] Batch [410]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089683,	
2017-06-20 02:03:37,754 Epoch[41] Batch [420]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.090045,	
2017-06-20 02:03:42,515 Epoch[41] Batch [430]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.090035,	
2017-06-20 02:03:47,332 Epoch[41] Batch [440]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.090164,	
2017-06-20 02:03:51,469 Epoch[41] Batch [450]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.090124,	
2017-06-20 02:03:55,865 Epoch[41] Batch [460]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090182,	
2017-06-20 02:04:00,544 Epoch[41] Batch [470]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090322,	
2017-06-20 02:04:05,350 Epoch[41] Batch [480]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.090280,	
2017-06-20 02:04:10,033 Epoch[41] Batch [490]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090344,	
2017-06-20 02:04:14,364 Epoch[41] Batch [500]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.090296,	
2017-06-20 02:04:19,186 Epoch[41] Batch [510]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090259,	
2017-06-20 02:04:23,977 Epoch[41] Batch [520]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.090178,	
2017-06-20 02:04:28,591 Epoch[41] Batch [530]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.090017,	
2017-06-20 02:04:33,379 Epoch[41] Batch [540]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089926,	
2017-06-20 02:04:38,064 Epoch[41] Batch [550]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089872,	
2017-06-20 02:04:42,586 Epoch[41] Batch [560]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.089931,	
2017-06-20 02:04:47,213 Epoch[41] Batch [570]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089898,	
2017-06-20 02:04:51,719 Epoch[41] Batch [580]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089846,	
2017-06-20 02:04:56,721 Epoch[41] Batch [590]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.089960,	
2017-06-20 02:05:01,535 Epoch[41] Batch [600]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.089963,	
2017-06-20 02:05:06,106 Epoch[41] Batch [610]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.089863,	
2017-06-20 02:05:10,786 Epoch[41] Batch [620]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089994,	
2017-06-20 02:05:15,064 Epoch[41] Batch [630]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.090009,	
2017-06-20 02:05:19,660 Epoch[41] Batch [640]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090095,	
2017-06-20 02:05:24,311 Epoch[41] Batch [650]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090030,	
2017-06-20 02:05:28,570 Epoch[41] Batch [660]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.090039,	
2017-06-20 02:05:32,799 Epoch[41] Batch [670]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.089937,	
2017-06-20 02:05:37,505 Epoch[41] Batch [680]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089971,	
2017-06-20 02:05:42,076 Epoch[41] Batch [690]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090039,	
2017-06-20 02:05:46,836 Epoch[41] Batch [700]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089893,	
2017-06-20 02:05:51,350 Epoch[41] Batch [710]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089869,	
2017-06-20 02:05:56,257 Epoch[41] Batch [720]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089677,	
2017-06-20 02:06:00,816 Epoch[41] Batch [730]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.089822,	
2017-06-20 02:06:05,608 Epoch[41] Batch [740]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089817,	
2017-06-20 02:06:09,920 Epoch[41] Batch [750]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.089634,	
2017-06-20 02:06:14,659 Epoch[41] Batch [760]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089586,	
2017-06-20 02:06:18,958 Epoch[41] Batch [770]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.089602,	
2017-06-20 02:06:23,646 Epoch[41] Batch [780]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089683,	
2017-06-20 02:06:28,226 Epoch[41] Batch [790]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089854,	
2017-06-20 02:06:32,982 Epoch[41] Batch [800]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089768,	
2017-06-20 02:06:37,537 Epoch[41] Batch [810]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.089810,	
2017-06-20 02:06:42,221 Epoch[41] Batch [820]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089842,	
2017-06-20 02:06:46,871 Epoch[41] Batch [830]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089893,	
2017-06-20 02:06:51,803 Epoch[41] Batch [840]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.089862,	
2017-06-20 02:06:56,213 Epoch[41] Batch [850]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089849,	
2017-06-20 02:07:00,454 Epoch[41] Batch [860]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.089836,	
2017-06-20 02:07:04,970 Epoch[41] Batch [870]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089837,	
2017-06-20 02:07:09,560 Epoch[41] Batch [880]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089869,	
2017-06-20 02:07:14,236 Epoch[41] Batch [890]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089771,	
2017-06-20 02:07:18,615 Epoch[41] Batch [900]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.089818,	
2017-06-20 02:07:23,446 Epoch[41] Batch [910]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089868,	
2017-06-20 02:07:28,261 Epoch[41] Batch [920]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.089930,	
2017-06-20 02:07:32,752 Epoch[41] Batch [930]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.089873,	
2017-06-20 02:07:37,459 Epoch[41] Batch [940]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089816,	
2017-06-20 02:07:42,104 Epoch[41] Batch [950]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089965,	
2017-06-20 02:07:46,771 Epoch[41] Batch [960]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090037,	
2017-06-20 02:07:51,590 Epoch[41] Batch [970]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.089987,	
2017-06-20 02:07:56,291 Epoch[41] Batch [980]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089996,	
2017-06-20 02:08:00,900 Epoch[41] Batch [990]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.089944,	
2017-06-20 02:08:05,635 Epoch[41] Batch [1000]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089971,	
2017-06-20 02:08:10,485 Epoch[41] Batch [1010]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090018,	
2017-06-20 02:08:15,103 Epoch[41] Batch [1020]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090033,	
2017-06-20 02:08:19,611 Epoch[41] Batch [1030]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.090083,	
2017-06-20 02:08:24,269 Epoch[41] Batch [1040]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090046,	
2017-06-20 02:08:29,193 Epoch[41] Batch [1050]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.090060,	
2017-06-20 02:08:33,835 Epoch[41] Batch [1060]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.090138,	
2017-06-20 02:08:37,989 Epoch[41] Batch [1070]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.090134,	
2017-06-20 02:08:42,375 Epoch[41] Batch [1080]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090074,	
2017-06-20 02:08:46,915 Epoch[41] Batch [1090]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090122,	
2017-06-20 02:08:51,212 Epoch[41] Batch [1100]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.090108,	
2017-06-20 02:08:55,597 Epoch[41] Batch [1110]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090163,	
2017-06-20 02:09:00,043 Epoch[41] Batch [1120]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090166,	
2017-06-20 02:09:04,646 Epoch[41] Batch [1130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090153,	
2017-06-20 02:09:09,183 Epoch[41] Batch [1140]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090153,	
2017-06-20 02:09:13,617 Epoch[41] Batch [1150]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090050,	
2017-06-20 02:09:18,278 Epoch[41] Batch [1160]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.090036,	
2017-06-20 02:09:23,054 Epoch[41] Batch [1170]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.090023,	
2017-06-20 02:09:27,644 Epoch[41] Batch [1180]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089963,	
2017-06-20 02:09:32,493 Epoch[41] Batch [1190]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090014,	
2017-06-20 02:09:37,271 Epoch[41] Batch [1200]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089987,	
2017-06-20 02:09:41,706 Epoch[41] Batch [1210]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.089972,	
2017-06-20 02:09:46,178 Epoch[41] Batch [1220]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.089874,	
2017-06-20 02:09:50,743 Epoch[41] Batch [1230]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089868,	
2017-06-20 02:09:55,156 Epoch[41] Batch [1240]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089889,	
2017-06-20 02:09:59,961 Epoch[41] Batch [1250]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089832,	
2017-06-20 02:10:04,465 Epoch[41] Batch [1260]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089992,	
2017-06-20 02:10:09,315 Epoch[41] Batch [1270]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090016,	
2017-06-20 02:10:14,044 Epoch[41] Batch [1280]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090010,	
2017-06-20 02:10:18,651 Epoch[41] Batch [1290]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090004,	
2017-06-20 02:10:23,003 Epoch[41] Batch [1300]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.090028,	
2017-06-20 02:10:27,282 Epoch[41] Batch [1310]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.089997,	
2017-06-20 02:10:31,751 Epoch[41] Batch [1320]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.089987,	
2017-06-20 02:10:36,373 Epoch[41] Batch [1330]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090023,	
2017-06-20 02:10:40,953 Epoch[41] Batch [1340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089988,	
2017-06-20 02:10:45,517 Epoch[41] Batch [1350]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089945,	
2017-06-20 02:10:50,150 Epoch[41] Batch [1360]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089960,	
2017-06-20 02:10:54,586 Epoch[41] Batch [1370]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.089987,	
2017-06-20 02:10:59,028 Epoch[41] Batch [1380]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.089954,	
2017-06-20 02:11:03,530 Epoch[41] Batch [1390]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089930,	
2017-06-20 02:11:07,939 Epoch[41] Batch [1400]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089992,	
2017-06-20 02:11:12,529 Epoch[41] Batch [1410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089993,	
2017-06-20 02:11:17,192 Epoch[41] Batch [1420]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.090027,	
2017-06-20 02:11:21,572 Epoch[41] Batch [1430]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.089992,	
2017-06-20 02:11:26,279 Epoch[41] Batch [1440]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.090033,	
2017-06-20 02:11:30,752 Epoch[41] Batch [1450]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090082,	
2017-06-20 02:11:35,504 Epoch[41] Batch [1460]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090072,	
2017-06-20 02:11:40,103 Epoch[41] Batch [1470]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090094,	
2017-06-20 02:11:44,839 Epoch[41] Batch [1480]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090114,	
2017-06-20 02:11:47,631 Epoch[41] Train-FCNLogLoss=0.090110
2017-06-20 02:11:47,631 Epoch[41] Time cost=682.255
2017-06-20 02:11:48,383 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0042.params"
2017-06-20 02:11:50,037 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0042.states"
2017-06-20 02:11:55,271 Epoch[42] Batch [10]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.081476,	
2017-06-20 02:11:59,765 Epoch[42] Batch [20]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.092717,	
2017-06-20 02:12:04,851 Epoch[42] Batch [30]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.091182,	
2017-06-20 02:12:09,686 Epoch[42] Batch [40]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092916,	
2017-06-20 02:12:14,163 Epoch[42] Batch [50]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.093111,	
2017-06-20 02:12:18,721 Epoch[42] Batch [60]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092439,	
2017-06-20 02:12:23,529 Epoch[42] Batch [70]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092278,	
2017-06-20 02:12:28,215 Epoch[42] Batch [80]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092124,	
2017-06-20 02:12:32,730 Epoch[42] Batch [90]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091982,	
2017-06-20 02:12:37,147 Epoch[42] Batch [100]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091109,	
2017-06-20 02:12:41,801 Epoch[42] Batch [110]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089960,	
2017-06-20 02:12:46,363 Epoch[42] Batch [120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089830,	
2017-06-20 02:12:51,035 Epoch[42] Batch [130]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089640,	
2017-06-20 02:12:55,599 Epoch[42] Batch [140]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089689,	
2017-06-20 02:13:00,299 Epoch[42] Batch [150]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089795,	
2017-06-20 02:13:05,107 Epoch[42] Batch [160]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089605,	
2017-06-20 02:13:09,502 Epoch[42] Batch [170]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089884,	
2017-06-20 02:13:14,176 Epoch[42] Batch [180]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089822,	
2017-06-20 02:13:19,004 Epoch[42] Batch [190]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090315,	
2017-06-20 02:13:23,203 Epoch[42] Batch [200]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.090232,	
2017-06-20 02:13:27,873 Epoch[42] Batch [210]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090376,	
2017-06-20 02:13:32,436 Epoch[42] Batch [220]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089980,	
2017-06-20 02:13:36,990 Epoch[42] Batch [230]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.089435,	
2017-06-20 02:13:41,567 Epoch[42] Batch [240]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089780,	
2017-06-20 02:13:46,265 Epoch[42] Batch [250]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089825,	
2017-06-20 02:13:50,974 Epoch[42] Batch [260]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089755,	
2017-06-20 02:13:55,570 Epoch[42] Batch [270]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089550,	
2017-06-20 02:14:00,323 Epoch[42] Batch [280]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089523,	
2017-06-20 02:14:05,185 Epoch[42] Batch [290]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089681,	
2017-06-20 02:14:09,741 Epoch[42] Batch [300]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.089934,	
2017-06-20 02:14:14,168 Epoch[42] Batch [310]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.089887,	
2017-06-20 02:14:18,670 Epoch[42] Batch [320]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089946,	
2017-06-20 02:14:23,288 Epoch[42] Batch [330]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090364,	
2017-06-20 02:14:27,491 Epoch[42] Batch [340]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.090376,	
2017-06-20 02:14:32,018 Epoch[42] Batch [350]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.090246,	
2017-06-20 02:14:36,728 Epoch[42] Batch [360]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090055,	
2017-06-20 02:14:41,320 Epoch[42] Batch [370]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090050,	
2017-06-20 02:14:45,668 Epoch[42] Batch [380]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.089894,	
2017-06-20 02:14:50,167 Epoch[42] Batch [390]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089843,	
2017-06-20 02:14:54,926 Epoch[42] Batch [400]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089912,	
2017-06-20 02:14:59,528 Epoch[42] Batch [410]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089789,	
2017-06-20 02:15:03,806 Epoch[42] Batch [420]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.089603,	
2017-06-20 02:15:08,632 Epoch[42] Batch [430]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089662,	
2017-06-20 02:15:13,584 Epoch[42] Batch [440]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089510,	
2017-06-20 02:15:18,065 Epoch[42] Batch [450]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089641,	
2017-06-20 02:15:22,720 Epoch[42] Batch [460]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089586,	
2017-06-20 02:15:27,447 Epoch[42] Batch [470]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089571,	
2017-06-20 02:15:31,914 Epoch[42] Batch [480]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.089573,	
2017-06-20 02:15:36,612 Epoch[42] Batch [490]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089571,	
2017-06-20 02:15:40,792 Epoch[42] Batch [500]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.089519,	
2017-06-20 02:15:45,388 Epoch[42] Batch [510]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089559,	
2017-06-20 02:15:50,065 Epoch[42] Batch [520]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089449,	
2017-06-20 02:15:54,751 Epoch[42] Batch [530]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089543,	
2017-06-20 02:15:59,230 Epoch[42] Batch [540]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089628,	
2017-06-20 02:16:03,981 Epoch[42] Batch [550]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089497,	
2017-06-20 02:16:08,579 Epoch[42] Batch [560]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089617,	
2017-06-20 02:16:13,156 Epoch[42] Batch [570]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089591,	
2017-06-20 02:16:17,747 Epoch[42] Batch [580]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089601,	
2017-06-20 02:16:22,254 Epoch[42] Batch [590]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089579,	
2017-06-20 02:16:26,964 Epoch[42] Batch [600]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089584,	
2017-06-20 02:16:31,630 Epoch[42] Batch [610]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089459,	
2017-06-20 02:16:36,274 Epoch[42] Batch [620]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089490,	
2017-06-20 02:16:40,906 Epoch[42] Batch [630]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089495,	
2017-06-20 02:16:45,503 Epoch[42] Batch [640]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089277,	
2017-06-20 02:16:50,456 Epoch[42] Batch [650]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089445,	
2017-06-20 02:16:54,948 Epoch[42] Batch [660]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.089462,	
2017-06-20 02:16:59,748 Epoch[42] Batch [670]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.089509,	
2017-06-20 02:17:04,460 Epoch[42] Batch [680]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089596,	
2017-06-20 02:17:08,811 Epoch[42] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.089330,	
2017-06-20 02:17:13,599 Epoch[42] Batch [700]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089556,	
2017-06-20 02:17:18,363 Epoch[42] Batch [710]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089597,	
2017-06-20 02:17:23,062 Epoch[42] Batch [720]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089552,	
2017-06-20 02:17:27,752 Epoch[42] Batch [730]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089521,	
2017-06-20 02:17:32,661 Epoch[42] Batch [740]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089592,	
2017-06-20 02:17:37,213 Epoch[42] Batch [750]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089537,	
2017-06-20 02:17:41,608 Epoch[42] Batch [760]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-20 02:17:46,102 Epoch[42] Batch [770]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089534,	
2017-06-20 02:17:50,790 Epoch[42] Batch [780]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089541,	
2017-06-20 02:17:55,746 Epoch[42] Batch [790]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.089477,	
2017-06-20 02:18:00,465 Epoch[42] Batch [800]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089394,	
2017-06-20 02:18:04,998 Epoch[42] Batch [810]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089361,	
2017-06-20 02:18:09,507 Epoch[42] Batch [820]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.089295,	
2017-06-20 02:18:14,012 Epoch[42] Batch [830]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089191,	
2017-06-20 02:18:18,492 Epoch[42] Batch [840]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089158,	
2017-06-20 02:18:23,149 Epoch[42] Batch [850]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089238,	
2017-06-20 02:18:27,661 Epoch[42] Batch [860]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.089345,	
2017-06-20 02:18:32,410 Epoch[42] Batch [870]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089378,	
2017-06-20 02:18:37,102 Epoch[42] Batch [880]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089483,	
2017-06-20 02:18:41,433 Epoch[42] Batch [890]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.089517,	
2017-06-20 02:18:45,733 Epoch[42] Batch [900]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.089431,	
2017-06-20 02:18:50,356 Epoch[42] Batch [910]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089425,	
2017-06-20 02:18:55,183 Epoch[42] Batch [920]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089464,	
2017-06-20 02:18:59,979 Epoch[42] Batch [930]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089449,	
2017-06-20 02:19:04,639 Epoch[42] Batch [940]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089462,	
2017-06-20 02:19:08,983 Epoch[42] Batch [950]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.089412,	
2017-06-20 02:19:13,608 Epoch[42] Batch [960]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089465,	
2017-06-20 02:19:17,928 Epoch[42] Batch [970]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.089467,	
2017-06-20 02:19:22,556 Epoch[42] Batch [980]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089413,	
2017-06-20 02:19:27,189 Epoch[42] Batch [990]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089405,	
2017-06-20 02:19:31,786 Epoch[42] Batch [1000]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089362,	
2017-06-20 02:19:36,363 Epoch[42] Batch [1010]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089439,	
2017-06-20 02:19:40,717 Epoch[42] Batch [1020]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.089377,	
2017-06-20 02:19:44,978 Epoch[42] Batch [1030]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.089373,	
2017-06-20 02:19:49,714 Epoch[42] Batch [1040]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089340,	
2017-06-20 02:19:54,315 Epoch[42] Batch [1050]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089333,	
2017-06-20 02:19:58,943 Epoch[42] Batch [1060]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089415,	
2017-06-20 02:20:03,582 Epoch[42] Batch [1070]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089371,	
2017-06-20 02:20:08,095 Epoch[42] Batch [1080]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089370,	
2017-06-20 02:20:12,958 Epoch[42] Batch [1090]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089359,	
2017-06-20 02:20:17,501 Epoch[42] Batch [1100]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.089289,	
2017-06-20 02:20:22,146 Epoch[42] Batch [1110]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089265,	
2017-06-20 02:20:26,846 Epoch[42] Batch [1120]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089276,	
2017-06-20 02:20:31,355 Epoch[42] Batch [1130]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.089305,	
2017-06-20 02:20:36,064 Epoch[42] Batch [1140]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089271,	
2017-06-20 02:20:40,544 Epoch[42] Batch [1150]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089300,	
2017-06-20 02:20:45,242 Epoch[42] Batch [1160]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089238,	
2017-06-20 02:20:49,610 Epoch[42] Batch [1170]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.089204,	
2017-06-20 02:20:54,258 Epoch[42] Batch [1180]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089134,	
2017-06-20 02:20:58,953 Epoch[42] Batch [1190]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089127,	
2017-06-20 02:21:03,691 Epoch[42] Batch [1200]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089158,	
2017-06-20 02:21:08,396 Epoch[42] Batch [1210]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089248,	
2017-06-20 02:21:13,080 Epoch[42] Batch [1220]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089280,	
2017-06-20 02:21:17,744 Epoch[42] Batch [1230]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089336,	
2017-06-20 02:21:22,387 Epoch[42] Batch [1240]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089320,	
2017-06-20 02:21:26,585 Epoch[42] Batch [1250]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.089418,	
2017-06-20 02:21:31,479 Epoch[42] Batch [1260]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089453,	
2017-06-20 02:21:36,289 Epoch[42] Batch [1270]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089434,	
2017-06-20 02:21:41,019 Epoch[42] Batch [1280]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089437,	
2017-06-20 02:21:45,511 Epoch[42] Batch [1290]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.089443,	
2017-06-20 02:21:50,024 Epoch[42] Batch [1300]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089426,	
2017-06-20 02:21:54,918 Epoch[42] Batch [1310]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.089410,	
2017-06-20 02:21:59,759 Epoch[42] Batch [1320]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.089359,	
2017-06-20 02:22:04,759 Epoch[42] Batch [1330]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.089347,	
2017-06-20 02:22:09,544 Epoch[42] Batch [1340]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089371,	
2017-06-20 02:22:14,003 Epoch[42] Batch [1350]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.089392,	
2017-06-20 02:22:18,579 Epoch[42] Batch [1360]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089336,	
2017-06-20 02:22:23,258 Epoch[42] Batch [1370]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089321,	
2017-06-20 02:22:27,897 Epoch[42] Batch [1380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089320,	
2017-06-20 02:22:32,479 Epoch[42] Batch [1390]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089329,	
2017-06-20 02:22:37,421 Epoch[42] Batch [1400]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089281,	
2017-06-20 02:22:42,100 Epoch[42] Batch [1410]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089281,	
2017-06-20 02:22:47,114 Epoch[42] Batch [1420]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.089293,	
2017-06-20 02:22:51,886 Epoch[42] Batch [1430]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089254,	
2017-06-20 02:22:56,806 Epoch[42] Batch [1440]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.089250,	
2017-06-20 02:23:01,599 Epoch[42] Batch [1450]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089252,	
2017-06-20 02:23:06,389 Epoch[42] Batch [1460]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089290,	
2017-06-20 02:23:11,304 Epoch[42] Batch [1470]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089321,	
2017-06-20 02:23:15,792 Epoch[42] Batch [1480]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.089308,	
2017-06-20 02:23:18,801 Epoch[42] Train-FCNLogLoss=0.089269
2017-06-20 02:23:18,802 Epoch[42] Time cost=688.764
2017-06-20 02:23:19,574 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0043.params"
2017-06-20 02:23:21,188 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0043.states"
2017-06-20 02:23:26,477 Epoch[43] Batch [10]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.091649,	
2017-06-20 02:23:31,048 Epoch[43] Batch [20]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090729,	
2017-06-20 02:23:35,949 Epoch[43] Batch [30]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.091044,	
2017-06-20 02:23:40,739 Epoch[43] Batch [40]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089260,	
2017-06-20 02:23:45,467 Epoch[43] Batch [50]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089511,	
2017-06-20 02:23:50,421 Epoch[43] Batch [60]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.090912,	
2017-06-20 02:23:54,864 Epoch[43] Batch [70]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090479,	
2017-06-20 02:23:59,638 Epoch[43] Batch [80]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.090742,	
2017-06-20 02:24:04,268 Epoch[43] Batch [90]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090362,	
2017-06-20 02:24:08,723 Epoch[43] Batch [100]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.090726,	
2017-06-20 02:24:13,280 Epoch[43] Batch [110]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091027,	
2017-06-20 02:24:17,899 Epoch[43] Batch [120]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090395,	
2017-06-20 02:24:22,683 Epoch[43] Batch [130]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090179,	
2017-06-20 02:24:27,512 Epoch[43] Batch [140]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.090258,	
2017-06-20 02:24:32,236 Epoch[43] Batch [150]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090274,	
2017-06-20 02:24:36,834 Epoch[43] Batch [160]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090579,	
2017-06-20 02:24:41,596 Epoch[43] Batch [170]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089969,	
2017-06-20 02:24:46,187 Epoch[43] Batch [180]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089689,	
2017-06-20 02:24:50,850 Epoch[43] Batch [190]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089589,	
2017-06-20 02:24:55,330 Epoch[43] Batch [200]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089434,	
2017-06-20 02:24:59,832 Epoch[43] Batch [210]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089222,	
2017-06-20 02:25:04,674 Epoch[43] Batch [220]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.089209,	
2017-06-20 02:25:09,253 Epoch[43] Batch [230]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089506,	
2017-06-20 02:25:13,787 Epoch[43] Batch [240]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.089380,	
2017-06-20 02:25:18,243 Epoch[43] Batch [250]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.089586,	
2017-06-20 02:25:22,918 Epoch[43] Batch [260]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089521,	
2017-06-20 02:25:27,581 Epoch[43] Batch [270]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089535,	
2017-06-20 02:25:32,056 Epoch[43] Batch [280]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.089220,	
2017-06-20 02:25:36,653 Epoch[43] Batch [290]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089085,	
2017-06-20 02:25:41,456 Epoch[43] Batch [300]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.089089,	
2017-06-20 02:25:46,377 Epoch[43] Batch [310]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088854,	
2017-06-20 02:25:51,015 Epoch[43] Batch [320]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-20 02:25:55,913 Epoch[43] Batch [330]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-20 02:26:00,307 Epoch[43] Batch [340]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.088834,	
2017-06-20 02:26:04,920 Epoch[43] Batch [350]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088730,	
2017-06-20 02:26:09,493 Epoch[43] Batch [360]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088619,	
2017-06-20 02:26:14,163 Epoch[43] Batch [370]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088454,	
2017-06-20 02:26:18,816 Epoch[43] Batch [380]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088369,	
2017-06-20 02:26:23,564 Epoch[43] Batch [390]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.088494,	
2017-06-20 02:26:27,997 Epoch[43] Batch [400]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088436,	
2017-06-20 02:26:32,810 Epoch[43] Batch [410]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088459,	
2017-06-20 02:26:37,449 Epoch[43] Batch [420]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088397,	
2017-06-20 02:26:42,154 Epoch[43] Batch [430]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088348,	
2017-06-20 02:26:46,586 Epoch[43] Batch [440]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088310,	
2017-06-20 02:26:51,463 Epoch[43] Batch [450]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088555,	
2017-06-20 02:26:56,215 Epoch[43] Batch [460]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088555,	
2017-06-20 02:27:00,743 Epoch[43] Batch [470]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088528,	
2017-06-20 02:27:05,398 Epoch[43] Batch [480]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088478,	
2017-06-20 02:27:09,917 Epoch[43] Batch [490]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088270,	
2017-06-20 02:27:14,211 Epoch[43] Batch [500]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.088436,	
2017-06-20 02:27:18,791 Epoch[43] Batch [510]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.088341,	
2017-06-20 02:27:23,472 Epoch[43] Batch [520]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088518,	
2017-06-20 02:27:28,319 Epoch[43] Batch [530]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088556,	
2017-06-20 02:27:32,790 Epoch[43] Batch [540]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088548,	
2017-06-20 02:27:37,565 Epoch[43] Batch [550]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088844,	
2017-06-20 02:27:42,175 Epoch[43] Batch [560]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088870,	
2017-06-20 02:27:46,805 Epoch[43] Batch [570]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088869,	
2017-06-20 02:27:51,375 Epoch[43] Batch [580]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088671,	
2017-06-20 02:27:55,973 Epoch[43] Batch [590]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-20 02:28:00,874 Epoch[43] Batch [600]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-20 02:28:05,450 Epoch[43] Batch [610]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088713,	
2017-06-20 02:28:10,169 Epoch[43] Batch [620]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088699,	
2017-06-20 02:28:14,602 Epoch[43] Batch [630]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088504,	
2017-06-20 02:28:19,155 Epoch[43] Batch [640]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088541,	
2017-06-20 02:28:23,976 Epoch[43] Batch [650]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088727,	
2017-06-20 02:28:28,536 Epoch[43] Batch [660]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.088612,	
2017-06-20 02:28:33,008 Epoch[43] Batch [670]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088797,	
2017-06-20 02:28:37,623 Epoch[43] Batch [680]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088843,	
2017-06-20 02:28:42,043 Epoch[43] Batch [690]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-20 02:28:46,498 Epoch[43] Batch [700]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.089037,	
2017-06-20 02:28:51,079 Epoch[43] Batch [710]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089053,	
2017-06-20 02:28:55,887 Epoch[43] Batch [720]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088968,	
2017-06-20 02:29:00,661 Epoch[43] Batch [730]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088994,	
2017-06-20 02:29:05,574 Epoch[43] Batch [740]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089000,	
2017-06-20 02:29:10,174 Epoch[43] Batch [750]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089069,	
2017-06-20 02:29:14,583 Epoch[43] Batch [760]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089071,	
2017-06-20 02:29:18,897 Epoch[43] Batch [770]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.089018,	
2017-06-20 02:29:23,412 Epoch[43] Batch [780]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088955,	
2017-06-20 02:29:28,023 Epoch[43] Batch [790]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.089003,	
2017-06-20 02:29:32,746 Epoch[43] Batch [800]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089081,	
2017-06-20 02:29:37,159 Epoch[43] Batch [810]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.089173,	
2017-06-20 02:29:41,552 Epoch[43] Batch [820]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089261,	
2017-06-20 02:29:46,362 Epoch[43] Batch [830]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089245,	
2017-06-20 02:29:51,141 Epoch[43] Batch [840]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089220,	
2017-06-20 02:29:55,453 Epoch[43] Batch [850]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.089178,	
2017-06-20 02:29:59,568 Epoch[43] Batch [860]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.089243,	
2017-06-20 02:30:04,104 Epoch[43] Batch [870]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.089274,	
2017-06-20 02:30:08,875 Epoch[43] Batch [880]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089208,	
2017-06-20 02:30:13,535 Epoch[43] Batch [890]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089117,	
2017-06-20 02:30:18,334 Epoch[43] Batch [900]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089125,	
2017-06-20 02:30:22,967 Epoch[43] Batch [910]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089118,	
2017-06-20 02:30:27,636 Epoch[43] Batch [920]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089046,	
2017-06-20 02:30:32,049 Epoch[43] Batch [930]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.089026,	
2017-06-20 02:30:36,683 Epoch[43] Batch [940]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089052,	
2017-06-20 02:30:41,304 Epoch[43] Batch [950]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.089125,	
2017-06-20 02:30:46,130 Epoch[43] Batch [960]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089134,	
2017-06-20 02:30:50,834 Epoch[43] Batch [970]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089265,	
2017-06-20 02:30:55,277 Epoch[43] Batch [980]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.089199,	
2017-06-20 02:30:59,853 Epoch[43] Batch [990]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089207,	
2017-06-20 02:31:04,209 Epoch[43] Batch [1000]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089251,	
2017-06-20 02:31:08,993 Epoch[43] Batch [1010]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089290,	
2017-06-20 02:31:13,806 Epoch[43] Batch [1020]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.089331,	
2017-06-20 02:31:18,029 Epoch[43] Batch [1030]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.089329,	
2017-06-20 02:31:22,420 Epoch[43] Batch [1040]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.089287,	
2017-06-20 02:31:27,061 Epoch[43] Batch [1050]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089313,	
2017-06-20 02:31:31,723 Epoch[43] Batch [1060]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089228,	
2017-06-20 02:31:36,128 Epoch[43] Batch [1070]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.089221,	
2017-06-20 02:31:40,620 Epoch[43] Batch [1080]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089296,	
2017-06-20 02:31:45,166 Epoch[43] Batch [1090]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089363,	
2017-06-20 02:31:49,854 Epoch[43] Batch [1100]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089419,	
2017-06-20 02:31:54,439 Epoch[43] Batch [1110]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089456,	
2017-06-20 02:31:59,404 Epoch[43] Batch [1120]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089451,	
2017-06-20 02:32:03,925 Epoch[43] Batch [1130]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.089375,	
2017-06-20 02:32:08,698 Epoch[43] Batch [1140]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089365,	
2017-06-20 02:32:13,455 Epoch[43] Batch [1150]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089324,	
2017-06-20 02:32:18,107 Epoch[43] Batch [1160]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089330,	
2017-06-20 02:32:23,007 Epoch[43] Batch [1170]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089297,	
2017-06-20 02:32:27,663 Epoch[43] Batch [1180]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089279,	
2017-06-20 02:32:32,406 Epoch[43] Batch [1190]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089268,	
2017-06-20 02:32:36,980 Epoch[43] Batch [1200]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.089241,	
2017-06-20 02:32:41,547 Epoch[43] Batch [1210]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089211,	
2017-06-20 02:32:45,975 Epoch[43] Batch [1220]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.089185,	
2017-06-20 02:32:50,745 Epoch[43] Batch [1230]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089154,	
2017-06-20 02:32:55,404 Epoch[43] Batch [1240]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089149,	
2017-06-20 02:32:59,831 Epoch[43] Batch [1250]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.089244,	
2017-06-20 02:33:04,226 Epoch[43] Batch [1260]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089269,	
2017-06-20 02:33:08,778 Epoch[43] Batch [1270]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089244,	
2017-06-20 02:33:13,349 Epoch[43] Batch [1280]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.089173,	
2017-06-20 02:33:18,009 Epoch[43] Batch [1290]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089068,	
2017-06-20 02:33:22,547 Epoch[43] Batch [1300]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.089083,	
2017-06-20 02:33:26,866 Epoch[43] Batch [1310]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.089134,	
2017-06-20 02:33:31,507 Epoch[43] Batch [1320]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089151,	
2017-06-20 02:33:36,102 Epoch[43] Batch [1330]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089155,	
2017-06-20 02:33:40,739 Epoch[43] Batch [1340]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089143,	
2017-06-20 02:33:45,005 Epoch[43] Batch [1350]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.089088,	
2017-06-20 02:33:49,809 Epoch[43] Batch [1360]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.089045,	
2017-06-20 02:33:54,455 Epoch[43] Batch [1370]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089110,	
2017-06-20 02:33:59,143 Epoch[43] Batch [1380]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089133,	
2017-06-20 02:34:03,759 Epoch[43] Batch [1390]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.089066,	
2017-06-20 02:34:08,513 Epoch[43] Batch [1400]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089049,	
2017-06-20 02:34:13,337 Epoch[43] Batch [1410]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089083,	
2017-06-20 02:34:17,791 Epoch[43] Batch [1420]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.089019,	
2017-06-20 02:34:22,498 Epoch[43] Batch [1430]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089029,	
2017-06-20 02:34:27,010 Epoch[43] Batch [1440]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088947,	
2017-06-20 02:34:31,352 Epoch[43] Batch [1450]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088903,	
2017-06-20 02:34:35,963 Epoch[43] Batch [1460]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088868,	
2017-06-20 02:34:40,712 Epoch[43] Batch [1470]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088882,	
2017-06-20 02:34:45,533 Epoch[43] Batch [1480]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088879,	
2017-06-20 02:34:48,242 Epoch[43] Train-FCNLogLoss=0.088840
2017-06-20 02:34:48,243 Epoch[43] Time cost=687.055
2017-06-20 02:34:49,131 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0044.params"
2017-06-20 02:34:50,833 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0044.states"
2017-06-20 02:34:56,357 Epoch[44] Batch [10]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.093228,	
2017-06-20 02:35:01,129 Epoch[44] Batch [20]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.093438,	
2017-06-20 02:35:05,861 Epoch[44] Batch [30]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.092403,	
2017-06-20 02:35:10,301 Epoch[44] Batch [40]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.090855,	
2017-06-20 02:35:14,702 Epoch[44] Batch [50]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.089356,	
2017-06-20 02:35:19,334 Epoch[44] Batch [60]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087444,	
2017-06-20 02:35:23,921 Epoch[44] Batch [70]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.087628,	
2017-06-20 02:35:28,475 Epoch[44] Batch [80]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088080,	
2017-06-20 02:35:32,710 Epoch[44] Batch [90]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.087897,	
2017-06-20 02:35:37,081 Epoch[44] Batch [100]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-20 02:35:41,655 Epoch[44] Batch [110]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087617,	
2017-06-20 02:35:46,461 Epoch[44] Batch [120]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.087725,	
2017-06-20 02:35:51,300 Epoch[44] Batch [130]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088310,	
2017-06-20 02:35:55,947 Epoch[44] Batch [140]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087774,	
2017-06-20 02:36:00,515 Epoch[44] Batch [150]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.088018,	
2017-06-20 02:36:05,197 Epoch[44] Batch [160]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087958,	
2017-06-20 02:36:10,143 Epoch[44] Batch [170]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.087984,	
2017-06-20 02:36:14,505 Epoch[44] Batch [180]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.088323,	
2017-06-20 02:36:19,137 Epoch[44] Batch [190]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088123,	
2017-06-20 02:36:23,719 Epoch[44] Batch [200]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-20 02:36:28,476 Epoch[44] Batch [210]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088786,	
2017-06-20 02:36:33,139 Epoch[44] Batch [220]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088812,	
2017-06-20 02:36:37,785 Epoch[44] Batch [230]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-20 02:36:42,581 Epoch[44] Batch [240]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088648,	
2017-06-20 02:36:47,284 Epoch[44] Batch [250]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088292,	
2017-06-20 02:36:51,967 Epoch[44] Batch [260]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088215,	
2017-06-20 02:36:56,663 Epoch[44] Batch [270]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087900,	
2017-06-20 02:37:00,968 Epoch[44] Batch [280]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087701,	
2017-06-20 02:37:05,538 Epoch[44] Batch [290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088057,	
2017-06-20 02:37:10,377 Epoch[44] Batch [300]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088322,	
2017-06-20 02:37:15,254 Epoch[44] Batch [310]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088107,	
2017-06-20 02:37:19,925 Epoch[44] Batch [320]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087795,	
2017-06-20 02:37:24,539 Epoch[44] Batch [330]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087540,	
2017-06-20 02:37:28,714 Epoch[44] Batch [340]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.087355,	
2017-06-20 02:37:33,127 Epoch[44] Batch [350]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087595,	
2017-06-20 02:37:37,838 Epoch[44] Batch [360]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087450,	
2017-06-20 02:37:42,551 Epoch[44] Batch [370]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087298,	
2017-06-20 02:37:47,214 Epoch[44] Batch [380]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087285,	
2017-06-20 02:37:51,812 Epoch[44] Batch [390]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087567,	
2017-06-20 02:37:56,284 Epoch[44] Batch [400]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087445,	
2017-06-20 02:38:00,668 Epoch[44] Batch [410]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-20 02:38:05,408 Epoch[44] Batch [420]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087501,	
2017-06-20 02:38:09,881 Epoch[44] Batch [430]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087484,	
2017-06-20 02:38:14,529 Epoch[44] Batch [440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087472,	
2017-06-20 02:38:18,984 Epoch[44] Batch [450]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087289,	
2017-06-20 02:38:23,398 Epoch[44] Batch [460]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087280,	
2017-06-20 02:38:28,059 Epoch[44] Batch [470]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087433,	
2017-06-20 02:38:32,790 Epoch[44] Batch [480]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087501,	
2017-06-20 02:38:37,204 Epoch[44] Batch [490]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-20 02:38:41,773 Epoch[44] Batch [500]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087480,	
2017-06-20 02:38:46,431 Epoch[44] Batch [510]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.087438,	
2017-06-20 02:38:50,948 Epoch[44] Batch [520]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087603,	
2017-06-20 02:38:55,457 Epoch[44] Batch [530]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087893,	
2017-06-20 02:39:00,027 Epoch[44] Batch [540]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087915,	
2017-06-20 02:39:04,388 Epoch[44] Batch [550]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087926,	
2017-06-20 02:39:08,908 Epoch[44] Batch [560]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088132,	
2017-06-20 02:39:13,714 Epoch[44] Batch [570]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088154,	
2017-06-20 02:39:18,368 Epoch[44] Batch [580]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088122,	
2017-06-20 02:39:22,893 Epoch[44] Batch [590]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.088159,	
2017-06-20 02:39:27,175 Epoch[44] Batch [600]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.088072,	
2017-06-20 02:39:31,837 Epoch[44] Batch [610]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087979,	
2017-06-20 02:39:36,545 Epoch[44] Batch [620]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088057,	
2017-06-20 02:39:41,330 Epoch[44] Batch [630]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088138,	
2017-06-20 02:39:45,810 Epoch[44] Batch [640]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088248,	
2017-06-20 02:39:50,294 Epoch[44] Batch [650]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.088249,	
2017-06-20 02:39:54,998 Epoch[44] Batch [660]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088488,	
2017-06-20 02:39:59,274 Epoch[44] Batch [670]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.088529,	
2017-06-20 02:40:03,924 Epoch[44] Batch [680]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088456,	
2017-06-20 02:40:08,713 Epoch[44] Batch [690]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088508,	
2017-06-20 02:40:13,450 Epoch[44] Batch [700]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088455,	
2017-06-20 02:40:18,282 Epoch[44] Batch [710]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088357,	
2017-06-20 02:40:22,988 Epoch[44] Batch [720]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088296,	
2017-06-20 02:40:27,714 Epoch[44] Batch [730]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088223,	
2017-06-20 02:40:31,856 Epoch[44] Batch [740]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.088323,	
2017-06-20 02:40:36,681 Epoch[44] Batch [750]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088372,	
2017-06-20 02:40:41,491 Epoch[44] Batch [760]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088366,	
2017-06-20 02:40:46,348 Epoch[44] Batch [770]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088294,	
2017-06-20 02:40:51,188 Epoch[44] Batch [780]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088328,	
2017-06-20 02:40:55,654 Epoch[44] Batch [790]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.088166,	
2017-06-20 02:41:00,685 Epoch[44] Batch [800]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088197,	
2017-06-20 02:41:04,982 Epoch[44] Batch [810]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.088214,	
2017-06-20 02:41:09,522 Epoch[44] Batch [820]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088209,	
2017-06-20 02:41:13,941 Epoch[44] Batch [830]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088304,	
2017-06-20 02:41:18,312 Epoch[44] Batch [840]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.088312,	
2017-06-20 02:41:22,671 Epoch[44] Batch [850]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.088322,	
2017-06-20 02:41:27,029 Epoch[44] Batch [860]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.088321,	
2017-06-20 02:41:31,609 Epoch[44] Batch [870]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088309,	
2017-06-20 02:41:35,973 Epoch[44] Batch [880]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088434,	
2017-06-20 02:41:40,691 Epoch[44] Batch [890]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088294,	
2017-06-20 02:41:45,052 Epoch[44] Batch [900]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.088254,	
2017-06-20 02:41:49,543 Epoch[44] Batch [910]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.088260,	
2017-06-20 02:41:54,204 Epoch[44] Batch [920]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088257,	
2017-06-20 02:41:58,906 Epoch[44] Batch [930]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088301,	
2017-06-20 02:42:03,720 Epoch[44] Batch [940]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088250,	
2017-06-20 02:42:08,160 Epoch[44] Batch [950]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.088228,	
2017-06-20 02:42:12,763 Epoch[44] Batch [960]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088116,	
2017-06-20 02:42:16,959 Epoch[44] Batch [970]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088123,	
2017-06-20 02:42:21,455 Epoch[44] Batch [980]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088114,	
2017-06-20 02:42:26,308 Epoch[44] Batch [990]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088177,	
2017-06-20 02:42:30,806 Epoch[44] Batch [1000]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088218,	
2017-06-20 02:42:35,024 Epoch[44] Batch [1010]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.088311,	
2017-06-20 02:42:39,558 Epoch[44] Batch [1020]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088363,	
2017-06-20 02:42:43,885 Epoch[44] Batch [1030]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.088451,	
2017-06-20 02:42:48,767 Epoch[44] Batch [1040]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088586,	
2017-06-20 02:42:53,382 Epoch[44] Batch [1050]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088567,	
2017-06-20 02:42:58,063 Epoch[44] Batch [1060]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088555,	
2017-06-20 02:43:02,323 Epoch[44] Batch [1070]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.088562,	
2017-06-20 02:43:06,995 Epoch[44] Batch [1080]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088469,	
2017-06-20 02:43:11,497 Epoch[44] Batch [1090]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088437,	
2017-06-20 02:43:16,120 Epoch[44] Batch [1100]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.088425,	
2017-06-20 02:43:20,573 Epoch[44] Batch [1110]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-20 02:43:25,131 Epoch[44] Batch [1120]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088445,	
2017-06-20 02:43:29,596 Epoch[44] Batch [1130]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.088414,	
2017-06-20 02:43:34,065 Epoch[44] Batch [1140]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088420,	
2017-06-20 02:43:38,854 Epoch[44] Batch [1150]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088553,	
2017-06-20 02:43:43,552 Epoch[44] Batch [1160]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088616,	
2017-06-20 02:43:48,093 Epoch[44] Batch [1170]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088633,	
2017-06-20 02:43:52,831 Epoch[44] Batch [1180]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088668,	
2017-06-20 02:43:57,279 Epoch[44] Batch [1190]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.088678,	
2017-06-20 02:44:01,773 Epoch[44] Batch [1200]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088622,	
2017-06-20 02:44:06,469 Epoch[44] Batch [1210]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088646,	
2017-06-20 02:44:11,174 Epoch[44] Batch [1220]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088635,	
2017-06-20 02:44:16,210 Epoch[44] Batch [1230]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-20 02:44:21,200 Epoch[44] Batch [1240]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-20 02:44:25,918 Epoch[44] Batch [1250]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088590,	
2017-06-20 02:44:30,771 Epoch[44] Batch [1260]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088538,	
2017-06-20 02:44:35,345 Epoch[44] Batch [1270]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088507,	
2017-06-20 02:44:39,994 Epoch[44] Batch [1280]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088570,	
2017-06-20 02:44:44,294 Epoch[44] Batch [1290]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.088649,	
2017-06-20 02:44:49,049 Epoch[44] Batch [1300]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088675,	
2017-06-20 02:44:53,947 Epoch[44] Batch [1310]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088687,	
2017-06-20 02:44:58,685 Epoch[44] Batch [1320]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088644,	
2017-06-20 02:45:03,477 Epoch[44] Batch [1330]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088587,	
2017-06-20 02:45:08,202 Epoch[44] Batch [1340]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088578,	
2017-06-20 02:45:12,553 Epoch[44] Batch [1350]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.088574,	
2017-06-20 02:45:17,185 Epoch[44] Batch [1360]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-20 02:45:21,324 Epoch[44] Batch [1370]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.088580,	
2017-06-20 02:45:25,638 Epoch[44] Batch [1380]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088519,	
2017-06-20 02:45:30,022 Epoch[44] Batch [1390]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088496,	
2017-06-20 02:45:34,563 Epoch[44] Batch [1400]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088503,	
2017-06-20 02:45:39,136 Epoch[44] Batch [1410]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088496,	
2017-06-20 02:45:43,654 Epoch[44] Batch [1420]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088538,	
2017-06-20 02:45:48,191 Epoch[44] Batch [1430]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088504,	
2017-06-20 02:45:52,929 Epoch[44] Batch [1440]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088518,	
2017-06-20 02:45:57,409 Epoch[44] Batch [1450]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088562,	
2017-06-20 02:46:02,122 Epoch[44] Batch [1460]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088614,	
2017-06-20 02:46:06,708 Epoch[44] Batch [1470]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.088597,	
2017-06-20 02:46:11,507 Epoch[44] Batch [1480]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088627,	
2017-06-20 02:46:14,235 Epoch[44] Train-FCNLogLoss=0.088640
2017-06-20 02:46:14,235 Epoch[44] Time cost=683.402
2017-06-20 02:46:15,065 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0045.params"
2017-06-20 02:46:16,738 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0045.states"
2017-06-20 02:46:22,364 Epoch[45] Batch [10]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092344,	
2017-06-20 02:46:26,828 Epoch[45] Batch [20]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.096043,	
2017-06-20 02:46:31,657 Epoch[45] Batch [30]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.094174,	
2017-06-20 02:46:36,478 Epoch[45] Batch [40]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.094266,	
2017-06-20 02:46:41,319 Epoch[45] Batch [50]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092762,	
2017-06-20 02:46:46,061 Epoch[45] Batch [60]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092392,	
2017-06-20 02:46:50,674 Epoch[45] Batch [70]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.090983,	
2017-06-20 02:46:55,010 Epoch[45] Batch [80]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.089387,	
2017-06-20 02:46:59,723 Epoch[45] Batch [90]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089473,	
2017-06-20 02:47:04,210 Epoch[45] Batch [100]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.088279,	
2017-06-20 02:47:08,736 Epoch[45] Batch [110]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.088130,	
2017-06-20 02:47:13,369 Epoch[45] Batch [120]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088122,	
2017-06-20 02:47:17,917 Epoch[45] Batch [130]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089281,	
2017-06-20 02:47:22,637 Epoch[45] Batch [140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089297,	
2017-06-20 02:47:26,996 Epoch[45] Batch [150]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089142,	
2017-06-20 02:47:31,276 Epoch[45] Batch [160]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.089374,	
2017-06-20 02:47:35,807 Epoch[45] Batch [170]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089287,	
2017-06-20 02:47:40,422 Epoch[45] Batch [180]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.089514,	
2017-06-20 02:47:45,024 Epoch[45] Batch [190]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089374,	
2017-06-20 02:47:49,252 Epoch[45] Batch [200]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.089313,	
2017-06-20 02:47:53,451 Epoch[45] Batch [210]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.090147,	
2017-06-20 02:47:57,896 Epoch[45] Batch [220]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090142,	
2017-06-20 02:48:02,805 Epoch[45] Batch [230]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.090219,	
2017-06-20 02:48:07,048 Epoch[45] Batch [240]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.090133,	
2017-06-20 02:48:11,385 Epoch[45] Batch [250]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.089765,	
2017-06-20 02:48:15,804 Epoch[45] Batch [260]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.089816,	
2017-06-20 02:48:20,416 Epoch[45] Batch [270]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.089804,	
2017-06-20 02:48:24,832 Epoch[45] Batch [280]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.089766,	
2017-06-20 02:48:29,504 Epoch[45] Batch [290]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089656,	
2017-06-20 02:48:34,033 Epoch[45] Batch [300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089447,	
2017-06-20 02:48:38,614 Epoch[45] Batch [310]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089259,	
2017-06-20 02:48:43,232 Epoch[45] Batch [320]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.089173,	
2017-06-20 02:48:48,186 Epoch[45] Batch [330]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.089057,	
2017-06-20 02:48:52,940 Epoch[45] Batch [340]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088986,	
2017-06-20 02:48:57,724 Epoch[45] Batch [350]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089004,	
2017-06-20 02:49:02,482 Epoch[45] Batch [360]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088942,	
2017-06-20 02:49:06,911 Epoch[45] Batch [370]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.088901,	
2017-06-20 02:49:11,454 Epoch[45] Batch [380]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088898,	
2017-06-20 02:49:15,877 Epoch[45] Batch [390]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088871,	
2017-06-20 02:49:20,293 Epoch[45] Batch [400]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.088952,	
2017-06-20 02:49:24,846 Epoch[45] Batch [410]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089023,	
2017-06-20 02:49:29,762 Epoch[45] Batch [420]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088985,	
2017-06-20 02:49:34,240 Epoch[45] Batch [430]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089212,	
2017-06-20 02:49:38,970 Epoch[45] Batch [440]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089068,	
2017-06-20 02:49:43,604 Epoch[45] Batch [450]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088958,	
2017-06-20 02:49:48,266 Epoch[45] Batch [460]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088838,	
2017-06-20 02:49:52,773 Epoch[45] Batch [470]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.088783,	
2017-06-20 02:49:57,244 Epoch[45] Batch [480]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088475,	
2017-06-20 02:50:02,021 Epoch[45] Batch [490]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088631,	
2017-06-20 02:50:06,623 Epoch[45] Batch [500]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088757,	
2017-06-20 02:50:10,928 Epoch[45] Batch [510]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.088786,	
2017-06-20 02:50:15,239 Epoch[45] Batch [520]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.088761,	
2017-06-20 02:50:19,744 Epoch[45] Batch [530]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.088692,	
2017-06-20 02:50:24,279 Epoch[45] Batch [540]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-20 02:50:28,768 Epoch[45] Batch [550]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.088572,	
2017-06-20 02:50:33,247 Epoch[45] Batch [560]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088668,	
2017-06-20 02:50:37,856 Epoch[45] Batch [570]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088634,	
2017-06-20 02:50:42,727 Epoch[45] Batch [580]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088563,	
2017-06-20 02:50:47,425 Epoch[45] Batch [590]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088530,	
2017-06-20 02:50:52,059 Epoch[45] Batch [600]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-20 02:50:56,888 Epoch[45] Batch [610]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088606,	
2017-06-20 02:51:01,701 Epoch[45] Batch [620]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088580,	
2017-06-20 02:51:06,306 Epoch[45] Batch [630]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088659,	
2017-06-20 02:51:10,891 Epoch[45] Batch [640]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.088618,	
2017-06-20 02:51:15,441 Epoch[45] Batch [650]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088699,	
2017-06-20 02:51:20,313 Epoch[45] Batch [660]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088748,	
2017-06-20 02:51:25,235 Epoch[45] Batch [670]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088629,	
2017-06-20 02:51:30,270 Epoch[45] Batch [680]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088623,	
2017-06-20 02:51:35,056 Epoch[45] Batch [690]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088569,	
2017-06-20 02:51:39,864 Epoch[45] Batch [700]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088548,	
2017-06-20 02:51:44,788 Epoch[45] Batch [710]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088608,	
2017-06-20 02:51:49,313 Epoch[45] Batch [720]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.088680,	
2017-06-20 02:51:54,078 Epoch[45] Batch [730]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088467,	
2017-06-20 02:51:58,724 Epoch[45] Batch [740]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088665,	
2017-06-20 02:52:03,623 Epoch[45] Batch [750]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088759,	
2017-06-20 02:52:07,898 Epoch[45] Batch [760]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.088734,	
2017-06-20 02:52:12,614 Epoch[45] Batch [770]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-20 02:52:17,419 Epoch[45] Batch [780]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088728,	
2017-06-20 02:52:22,057 Epoch[45] Batch [790]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-20 02:52:26,689 Epoch[45] Batch [800]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-20 02:52:31,429 Epoch[45] Batch [810]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-20 02:52:36,390 Epoch[45] Batch [820]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088827,	
2017-06-20 02:52:40,967 Epoch[45] Batch [830]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088885,	
2017-06-20 02:52:45,294 Epoch[45] Batch [840]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.088834,	
2017-06-20 02:52:49,851 Epoch[45] Batch [850]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088804,	
2017-06-20 02:52:54,547 Epoch[45] Batch [860]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088772,	
2017-06-20 02:52:59,269 Epoch[45] Batch [870]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088720,	
2017-06-20 02:53:04,080 Epoch[45] Batch [880]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088657,	
2017-06-20 02:53:08,554 Epoch[45] Batch [890]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.088597,	
2017-06-20 02:53:12,955 Epoch[45] Batch [900]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.088562,	
2017-06-20 02:53:17,470 Epoch[45] Batch [910]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088571,	
2017-06-20 02:53:22,071 Epoch[45] Batch [920]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088542,	
2017-06-20 02:53:26,602 Epoch[45] Batch [930]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088587,	
2017-06-20 02:53:31,258 Epoch[45] Batch [940]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088651,	
2017-06-20 02:53:35,944 Epoch[45] Batch [950]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088694,	
2017-06-20 02:53:40,587 Epoch[45] Batch [960]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088579,	
2017-06-20 02:53:45,056 Epoch[45] Batch [970]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088535,	
2017-06-20 02:53:49,575 Epoch[45] Batch [980]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088532,	
2017-06-20 02:53:54,343 Epoch[45] Batch [990]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088572,	
2017-06-20 02:53:58,668 Epoch[45] Batch [1000]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.088508,	
2017-06-20 02:54:02,992 Epoch[45] Batch [1010]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.088568,	
2017-06-20 02:54:07,753 Epoch[45] Batch [1020]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088599,	
2017-06-20 02:54:12,467 Epoch[45] Batch [1030]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088603,	
2017-06-20 02:54:17,107 Epoch[45] Batch [1040]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088541,	
2017-06-20 02:54:21,491 Epoch[45] Batch [1050]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088583,	
2017-06-20 02:54:26,148 Epoch[45] Batch [1060]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088611,	
2017-06-20 02:54:30,814 Epoch[45] Batch [1070]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088689,	
2017-06-20 02:54:35,498 Epoch[45] Batch [1080]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088624,	
2017-06-20 02:54:40,196 Epoch[45] Batch [1090]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088550,	
2017-06-20 02:54:44,607 Epoch[45] Batch [1100]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088541,	
2017-06-20 02:54:49,253 Epoch[45] Batch [1110]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088536,	
2017-06-20 02:54:53,814 Epoch[45] Batch [1120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.088410,	
2017-06-20 02:54:58,500 Epoch[45] Batch [1130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088380,	
2017-06-20 02:55:03,219 Epoch[45] Batch [1140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088433,	
2017-06-20 02:55:07,420 Epoch[45] Batch [1150]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.088477,	
2017-06-20 02:55:11,996 Epoch[45] Batch [1160]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088463,	
2017-06-20 02:55:16,588 Epoch[45] Batch [1170]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088524,	
2017-06-20 02:55:21,076 Epoch[45] Batch [1180]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.088527,	
2017-06-20 02:55:25,285 Epoch[45] Batch [1190]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-20 02:55:29,779 Epoch[45] Batch [1200]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088546,	
2017-06-20 02:55:34,335 Epoch[45] Batch [1210]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088499,	
2017-06-20 02:55:38,927 Epoch[45] Batch [1220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088505,	
2017-06-20 02:55:43,141 Epoch[45] Batch [1230]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.088453,	
2017-06-20 02:55:47,829 Epoch[45] Batch [1240]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.088507,	
2017-06-20 02:55:52,707 Epoch[45] Batch [1250]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088622,	
2017-06-20 02:55:57,549 Epoch[45] Batch [1260]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088585,	
2017-06-20 02:56:02,149 Epoch[45] Batch [1270]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088473,	
2017-06-20 02:56:06,752 Epoch[45] Batch [1280]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088436,	
2017-06-20 02:56:11,500 Epoch[45] Batch [1290]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088456,	
2017-06-20 02:56:16,230 Epoch[45] Batch [1300]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-20 02:56:20,714 Epoch[45] Batch [1310]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.088510,	
2017-06-20 02:56:25,325 Epoch[45] Batch [1320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088504,	
2017-06-20 02:56:29,873 Epoch[45] Batch [1330]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088476,	
2017-06-20 02:56:34,147 Epoch[45] Batch [1340]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.088476,	
2017-06-20 02:56:38,401 Epoch[45] Batch [1350]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.088467,	
2017-06-20 02:56:42,613 Epoch[45] Batch [1360]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-20 02:56:46,955 Epoch[45] Batch [1370]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088446,	
2017-06-20 02:56:51,733 Epoch[45] Batch [1380]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088410,	
2017-06-20 02:56:56,550 Epoch[45] Batch [1390]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088371,	
2017-06-20 02:57:01,090 Epoch[45] Batch [1400]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088380,	
2017-06-20 02:57:05,700 Epoch[45] Batch [1410]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088380,	
2017-06-20 02:57:09,868 Epoch[45] Batch [1420]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.088332,	
2017-06-20 02:57:14,619 Epoch[45] Batch [1430]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088316,	
2017-06-20 02:57:19,271 Epoch[45] Batch [1440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088323,	
2017-06-20 02:57:24,061 Epoch[45] Batch [1450]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088330,	
2017-06-20 02:57:28,843 Epoch[45] Batch [1460]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088296,	
2017-06-20 02:57:33,723 Epoch[45] Batch [1470]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088274,	
2017-06-20 02:57:38,128 Epoch[45] Batch [1480]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.088259,	
2017-06-20 02:57:40,714 Epoch[45] Train-FCNLogLoss=0.088229
2017-06-20 02:57:40,714 Epoch[45] Time cost=683.975
2017-06-20 02:57:41,529 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0046.params"
2017-06-20 02:57:43,339 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0046.states"
2017-06-20 02:57:48,597 Epoch[46] Batch [10]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.089131,	
2017-06-20 02:57:53,081 Epoch[46] Batch [20]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.084308,	
2017-06-20 02:57:57,755 Epoch[46] Batch [30]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.085518,	
2017-06-20 02:58:02,321 Epoch[46] Batch [40]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.085636,	
2017-06-20 02:58:07,041 Epoch[46] Batch [50]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.085571,	
2017-06-20 02:58:11,891 Epoch[46] Batch [60]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087285,	
2017-06-20 02:58:16,442 Epoch[46] Batch [70]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088160,	
2017-06-20 02:58:21,179 Epoch[46] Batch [80]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.087989,	
2017-06-20 02:58:25,744 Epoch[46] Batch [90]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087948,	
2017-06-20 02:58:30,350 Epoch[46] Batch [100]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088553,	
2017-06-20 02:58:34,809 Epoch[46] Batch [110]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.088564,	
2017-06-20 02:58:39,252 Epoch[46] Batch [120]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.088511,	
2017-06-20 02:58:43,545 Epoch[46] Batch [130]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.088481,	
2017-06-20 02:58:48,085 Epoch[46] Batch [140]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087517,	
2017-06-20 02:58:52,892 Epoch[46] Batch [150]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088344,	
2017-06-20 02:58:57,724 Epoch[46] Batch [160]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088276,	
2017-06-20 02:59:02,030 Epoch[46] Batch [170]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.088816,	
2017-06-20 02:59:06,791 Epoch[46] Batch [180]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088769,	
2017-06-20 02:59:11,359 Epoch[46] Batch [190]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.088420,	
2017-06-20 02:59:15,915 Epoch[46] Batch [200]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088385,	
2017-06-20 02:59:20,594 Epoch[46] Batch [210]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088093,	
2017-06-20 02:59:24,939 Epoch[46] Batch [220]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088318,	
2017-06-20 02:59:29,825 Epoch[46] Batch [230]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088210,	
2017-06-20 02:59:34,299 Epoch[46] Batch [240]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087963,	
2017-06-20 02:59:39,008 Epoch[46] Batch [250]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.087984,	
2017-06-20 02:59:43,613 Epoch[46] Batch [260]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087898,	
2017-06-20 02:59:48,213 Epoch[46] Batch [270]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087739,	
2017-06-20 02:59:52,880 Epoch[46] Batch [280]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087734,	
2017-06-20 02:59:57,373 Epoch[46] Batch [290]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087675,	
2017-06-20 03:00:01,927 Epoch[46] Batch [300]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087893,	
2017-06-20 03:00:06,143 Epoch[46] Batch [310]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.087517,	
2017-06-20 03:00:10,363 Epoch[46] Batch [320]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.087595,	
2017-06-20 03:00:14,870 Epoch[46] Batch [330]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087606,	
2017-06-20 03:00:19,658 Epoch[46] Batch [340]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087551,	
2017-06-20 03:00:24,358 Epoch[46] Batch [350]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087776,	
2017-06-20 03:00:28,421 Epoch[46] Batch [360]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.087584,	
2017-06-20 03:00:32,937 Epoch[46] Batch [370]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087788,	
2017-06-20 03:00:37,564 Epoch[46] Batch [380]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.087914,	
2017-06-20 03:00:42,010 Epoch[46] Batch [390]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.088076,	
2017-06-20 03:00:46,769 Epoch[46] Batch [400]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088194,	
2017-06-20 03:00:51,215 Epoch[46] Batch [410]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.088355,	
2017-06-20 03:00:56,007 Epoch[46] Batch [420]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088460,	
2017-06-20 03:01:00,666 Epoch[46] Batch [430]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088343,	
2017-06-20 03:01:05,574 Epoch[46] Batch [440]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.088356,	
2017-06-20 03:01:10,131 Epoch[46] Batch [450]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088083,	
2017-06-20 03:01:14,598 Epoch[46] Batch [460]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088101,	
2017-06-20 03:01:19,357 Epoch[46] Batch [470]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088026,	
2017-06-20 03:01:24,203 Epoch[46] Batch [480]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.088029,	
2017-06-20 03:01:28,824 Epoch[46] Batch [490]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088119,	
2017-06-20 03:01:33,395 Epoch[46] Batch [500]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088086,	
2017-06-20 03:01:38,045 Epoch[46] Batch [510]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088159,	
2017-06-20 03:01:42,300 Epoch[46] Batch [520]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.088364,	
2017-06-20 03:01:47,006 Epoch[46] Batch [530]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088225,	
2017-06-20 03:01:51,472 Epoch[46] Batch [540]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.088278,	
2017-06-20 03:01:56,158 Epoch[46] Batch [550]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088201,	
2017-06-20 03:02:00,820 Epoch[46] Batch [560]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088490,	
2017-06-20 03:02:05,595 Epoch[46] Batch [570]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088429,	
2017-06-20 03:02:10,105 Epoch[46] Batch [580]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088580,	
2017-06-20 03:02:14,768 Epoch[46] Batch [590]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-20 03:02:19,523 Epoch[46] Batch [600]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088560,	
2017-06-20 03:02:24,230 Epoch[46] Batch [610]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088634,	
2017-06-20 03:02:28,962 Epoch[46] Batch [620]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088557,	
2017-06-20 03:02:33,659 Epoch[46] Batch [630]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088676,	
2017-06-20 03:02:38,012 Epoch[46] Batch [640]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088775,	
2017-06-20 03:02:42,528 Epoch[46] Batch [650]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088827,	
2017-06-20 03:02:47,120 Epoch[46] Batch [660]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-20 03:02:51,986 Epoch[46] Batch [670]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.088642,	
2017-06-20 03:02:56,535 Epoch[46] Batch [680]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088598,	
2017-06-20 03:03:01,312 Epoch[46] Batch [690]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088643,	
2017-06-20 03:03:05,842 Epoch[46] Batch [700]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088575,	
2017-06-20 03:03:10,636 Epoch[46] Batch [710]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088605,	
2017-06-20 03:03:15,315 Epoch[46] Batch [720]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-20 03:03:20,103 Epoch[46] Batch [730]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.088789,	
2017-06-20 03:03:24,715 Epoch[46] Batch [740]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088830,	
2017-06-20 03:03:29,214 Epoch[46] Batch [750]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088955,	
2017-06-20 03:03:33,953 Epoch[46] Batch [760]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088931,	
2017-06-20 03:03:38,380 Epoch[46] Batch [770]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.088947,	
2017-06-20 03:03:42,895 Epoch[46] Batch [780]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088989,	
2017-06-20 03:03:47,412 Epoch[46] Batch [790]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089134,	
2017-06-20 03:03:51,758 Epoch[46] Batch [800]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.089057,	
2017-06-20 03:03:56,178 Epoch[46] Batch [810]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088970,	
2017-06-20 03:04:00,569 Epoch[46] Batch [820]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.088992,	
2017-06-20 03:04:05,365 Epoch[46] Batch [830]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088980,	
2017-06-20 03:04:10,151 Epoch[46] Batch [840]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088929,	
2017-06-20 03:04:14,874 Epoch[46] Batch [850]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088906,	
2017-06-20 03:04:19,637 Epoch[46] Batch [860]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089003,	
2017-06-20 03:04:24,344 Epoch[46] Batch [870]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089059,	
2017-06-20 03:04:28,923 Epoch[46] Batch [880]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089028,	
2017-06-20 03:04:33,801 Epoch[46] Batch [890]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088989,	
2017-06-20 03:04:38,606 Epoch[46] Batch [900]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089007,	
2017-06-20 03:04:43,270 Epoch[46] Batch [910]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088879,	
2017-06-20 03:04:47,694 Epoch[46] Batch [920]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.088975,	
2017-06-20 03:04:52,366 Epoch[46] Batch [930]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088871,	
2017-06-20 03:04:57,146 Epoch[46] Batch [940]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088867,	
2017-06-20 03:05:01,491 Epoch[46] Batch [950]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088915,	
2017-06-20 03:05:06,417 Epoch[46] Batch [960]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088870,	
2017-06-20 03:05:10,693 Epoch[46] Batch [970]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.088851,	
2017-06-20 03:05:15,167 Epoch[46] Batch [980]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.088739,	
2017-06-20 03:05:20,008 Epoch[46] Batch [990]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088709,	
2017-06-20 03:05:24,586 Epoch[46] Batch [1000]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088774,	
2017-06-20 03:05:29,100 Epoch[46] Batch [1010]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088799,	
2017-06-20 03:05:33,620 Epoch[46] Batch [1020]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-20 03:05:38,327 Epoch[46] Batch [1030]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088640,	
2017-06-20 03:05:42,889 Epoch[46] Batch [1040]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.088486,	
2017-06-20 03:05:47,667 Epoch[46] Batch [1050]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088350,	
2017-06-20 03:05:52,233 Epoch[46] Batch [1060]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.088255,	
2017-06-20 03:05:56,680 Epoch[46] Batch [1070]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.088241,	
2017-06-20 03:06:01,451 Epoch[46] Batch [1080]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088265,	
2017-06-20 03:06:06,124 Epoch[46] Batch [1090]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088288,	
2017-06-20 03:06:10,572 Epoch[46] Batch [1100]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.088314,	
2017-06-20 03:06:15,153 Epoch[46] Batch [1110]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.088348,	
2017-06-20 03:06:19,707 Epoch[46] Batch [1120]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088411,	
2017-06-20 03:06:24,246 Epoch[46] Batch [1130]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088319,	
2017-06-20 03:06:28,710 Epoch[46] Batch [1140]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.088214,	
2017-06-20 03:06:33,406 Epoch[46] Batch [1150]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088255,	
2017-06-20 03:06:38,020 Epoch[46] Batch [1160]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088252,	
2017-06-20 03:06:42,850 Epoch[46] Batch [1170]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088282,	
2017-06-20 03:06:47,332 Epoch[46] Batch [1180]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088373,	
2017-06-20 03:06:52,199 Epoch[46] Batch [1190]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.088371,	
2017-06-20 03:06:56,614 Epoch[46] Batch [1200]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.088381,	
2017-06-20 03:07:01,224 Epoch[46] Batch [1210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088388,	
2017-06-20 03:07:05,552 Epoch[46] Batch [1220]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.088437,	
2017-06-20 03:07:10,054 Epoch[46] Batch [1230]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088385,	
2017-06-20 03:07:14,820 Epoch[46] Batch [1240]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088371,	
2017-06-20 03:07:19,617 Epoch[46] Batch [1250]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088325,	
2017-06-20 03:07:23,793 Epoch[46] Batch [1260]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.088243,	
2017-06-20 03:07:28,389 Epoch[46] Batch [1270]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088208,	
2017-06-20 03:07:33,027 Epoch[46] Batch [1280]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088182,	
2017-06-20 03:07:37,456 Epoch[46] Batch [1290]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.088182,	
2017-06-20 03:07:41,847 Epoch[46] Batch [1300]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.088185,	
2017-06-20 03:07:46,540 Epoch[46] Batch [1310]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088160,	
2017-06-20 03:07:51,490 Epoch[46] Batch [1320]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.088158,	
2017-06-20 03:07:56,258 Epoch[46] Batch [1330]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088221,	
2017-06-20 03:08:01,068 Epoch[46] Batch [1340]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088217,	
2017-06-20 03:08:05,731 Epoch[46] Batch [1350]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088232,	
2017-06-20 03:08:10,701 Epoch[46] Batch [1360]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088194,	
2017-06-20 03:08:15,109 Epoch[46] Batch [1370]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088116,	
2017-06-20 03:08:19,809 Epoch[46] Batch [1380]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088094,	
2017-06-20 03:08:24,212 Epoch[46] Batch [1390]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.088130,	
2017-06-20 03:08:28,579 Epoch[46] Batch [1400]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.088096,	
2017-06-20 03:08:33,403 Epoch[46] Batch [1410]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088054,	
2017-06-20 03:08:37,951 Epoch[46] Batch [1420]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088037,	
2017-06-20 03:08:42,648 Epoch[46] Batch [1430]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088073,	
2017-06-20 03:08:47,370 Epoch[46] Batch [1440]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088140,	
2017-06-20 03:08:51,509 Epoch[46] Batch [1450]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.088155,	
2017-06-20 03:08:56,022 Epoch[46] Batch [1460]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088092,	
2017-06-20 03:09:00,632 Epoch[46] Batch [1470]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088141,	
2017-06-20 03:09:05,116 Epoch[46] Batch [1480]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.088157,	
2017-06-20 03:09:07,848 Epoch[46] Train-FCNLogLoss=0.088180
2017-06-20 03:09:07,848 Epoch[46] Time cost=684.508
2017-06-20 03:09:08,657 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0047.params"
2017-06-20 03:09:10,373 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0047.states"
2017-06-20 03:09:16,002 Epoch[47] Batch [10]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.085465,	
2017-06-20 03:09:20,701 Epoch[47] Batch [20]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.085257,	
2017-06-20 03:09:25,209 Epoch[47] Batch [30]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.085562,	
2017-06-20 03:09:29,906 Epoch[47] Batch [40]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.086107,	
2017-06-20 03:09:34,760 Epoch[47] Batch [50]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086309,	
2017-06-20 03:09:39,446 Epoch[47] Batch [60]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.085356,	
2017-06-20 03:09:44,057 Epoch[47] Batch [70]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.085578,	
2017-06-20 03:09:48,676 Epoch[47] Batch [80]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.085538,	
2017-06-20 03:09:53,384 Epoch[47] Batch [90]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.085504,	
2017-06-20 03:09:58,230 Epoch[47] Batch [100]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086233,	
2017-06-20 03:10:02,841 Epoch[47] Batch [110]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.085735,	
2017-06-20 03:10:07,545 Epoch[47] Batch [120]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.085791,	
2017-06-20 03:10:12,176 Epoch[47] Batch [130]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.086343,	
2017-06-20 03:10:16,802 Epoch[47] Batch [140]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.085663,	
2017-06-20 03:10:21,465 Epoch[47] Batch [150]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.086177,	
2017-06-20 03:10:26,082 Epoch[47] Batch [160]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.085867,	
2017-06-20 03:10:30,780 Epoch[47] Batch [170]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.085714,	
2017-06-20 03:10:35,195 Epoch[47] Batch [180]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.085509,	
2017-06-20 03:10:39,849 Epoch[47] Batch [190]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.085747,	
2017-06-20 03:10:44,413 Epoch[47] Batch [200]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.086632,	
2017-06-20 03:10:48,908 Epoch[47] Batch [210]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.086343,	
2017-06-20 03:10:53,355 Epoch[47] Batch [220]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.086413,	
2017-06-20 03:10:58,181 Epoch[47] Batch [230]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086410,	
2017-06-20 03:11:02,809 Epoch[47] Batch [240]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086147,	
2017-06-20 03:11:07,433 Epoch[47] Batch [250]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086333,	
2017-06-20 03:11:11,728 Epoch[47] Batch [260]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.086580,	
2017-06-20 03:11:16,671 Epoch[47] Batch [270]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086846,	
2017-06-20 03:11:21,366 Epoch[47] Batch [280]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087112,	
2017-06-20 03:11:25,998 Epoch[47] Batch [290]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087287,	
2017-06-20 03:11:30,394 Epoch[47] Batch [300]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087312,	
2017-06-20 03:11:34,871 Epoch[47] Batch [310]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087143,	
2017-06-20 03:11:39,411 Epoch[47] Batch [320]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.086974,	
2017-06-20 03:11:43,939 Epoch[47] Batch [330]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.086981,	
2017-06-20 03:11:48,935 Epoch[47] Batch [340]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086742,	
2017-06-20 03:11:53,678 Epoch[47] Batch [350]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.086858,	
2017-06-20 03:11:58,161 Epoch[47] Batch [360]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086740,	
2017-06-20 03:12:02,710 Epoch[47] Batch [370]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086954,	
2017-06-20 03:12:07,504 Epoch[47] Batch [380]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086950,	
2017-06-20 03:12:11,835 Epoch[47] Batch [390]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.086831,	
2017-06-20 03:12:16,449 Epoch[47] Batch [400]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.086983,	
2017-06-20 03:12:21,197 Epoch[47] Batch [410]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087062,	
2017-06-20 03:12:25,621 Epoch[47] Batch [420]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087128,	
2017-06-20 03:12:30,220 Epoch[47] Batch [430]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.086839,	
2017-06-20 03:12:34,737 Epoch[47] Batch [440]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.086965,	
2017-06-20 03:12:39,363 Epoch[47] Batch [450]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.087214,	
2017-06-20 03:12:43,992 Epoch[47] Batch [460]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087264,	
2017-06-20 03:12:48,339 Epoch[47] Batch [470]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087312,	
2017-06-20 03:12:53,018 Epoch[47] Batch [480]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087514,	
2017-06-20 03:12:57,423 Epoch[47] Batch [490]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087468,	
2017-06-20 03:13:01,711 Epoch[47] Batch [500]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087414,	
2017-06-20 03:13:05,892 Epoch[47] Batch [510]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087371,	
2017-06-20 03:13:10,579 Epoch[47] Batch [520]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087301,	
2017-06-20 03:13:15,322 Epoch[47] Batch [530]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087154,	
2017-06-20 03:13:19,921 Epoch[47] Batch [540]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087220,	
2017-06-20 03:13:24,506 Epoch[47] Batch [550]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.087327,	
2017-06-20 03:13:29,105 Epoch[47] Batch [560]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087400,	
2017-06-20 03:13:33,578 Epoch[47] Batch [570]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087217,	
2017-06-20 03:13:38,427 Epoch[47] Batch [580]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087154,	
2017-06-20 03:13:42,832 Epoch[47] Batch [590]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087209,	
2017-06-20 03:13:47,421 Epoch[47] Batch [600]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.087272,	
2017-06-20 03:13:51,911 Epoch[47] Batch [610]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087367,	
2017-06-20 03:13:56,431 Epoch[47] Batch [620]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087423,	
2017-06-20 03:14:01,192 Epoch[47] Batch [630]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087396,	
2017-06-20 03:14:05,793 Epoch[47] Batch [640]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087354,	
2017-06-20 03:14:10,021 Epoch[47] Batch [650]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087257,	
2017-06-20 03:14:14,731 Epoch[47] Batch [660]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087208,	
2017-06-20 03:14:19,493 Epoch[47] Batch [670]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087125,	
2017-06-20 03:14:24,027 Epoch[47] Batch [680]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087023,	
2017-06-20 03:14:28,853 Epoch[47] Batch [690]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087041,	
2017-06-20 03:14:33,746 Epoch[47] Batch [700]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.086935,	
2017-06-20 03:14:38,495 Epoch[47] Batch [710]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087016,	
2017-06-20 03:14:43,110 Epoch[47] Batch [720]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087035,	
2017-06-20 03:14:48,032 Epoch[47] Batch [730]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.087100,	
2017-06-20 03:14:52,611 Epoch[47] Batch [740]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087096,	
2017-06-20 03:14:57,400 Epoch[47] Batch [750]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087068,	
2017-06-20 03:15:01,999 Epoch[47] Batch [760]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087076,	
2017-06-20 03:15:06,937 Epoch[47] Batch [770]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.087156,	
2017-06-20 03:15:11,834 Epoch[47] Batch [780]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087145,	
2017-06-20 03:15:16,639 Epoch[47] Batch [790]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087196,	
2017-06-20 03:15:21,299 Epoch[47] Batch [800]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087175,	
2017-06-20 03:15:26,115 Epoch[47] Batch [810]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087159,	
2017-06-20 03:15:30,453 Epoch[47] Batch [820]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087173,	
2017-06-20 03:15:35,222 Epoch[47] Batch [830]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.087197,	
2017-06-20 03:15:39,794 Epoch[47] Batch [840]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087278,	
2017-06-20 03:15:44,396 Epoch[47] Batch [850]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087220,	
2017-06-20 03:15:49,146 Epoch[47] Batch [860]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087275,	
2017-06-20 03:15:53,789 Epoch[47] Batch [870]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087293,	
2017-06-20 03:15:58,251 Epoch[47] Batch [880]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087389,	
2017-06-20 03:16:02,859 Epoch[47] Batch [890]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.087370,	
2017-06-20 03:16:07,395 Epoch[47] Batch [900]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087306,	
2017-06-20 03:16:11,872 Epoch[47] Batch [910]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087239,	
2017-06-20 03:16:16,629 Epoch[47] Batch [920]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087214,	
2017-06-20 03:16:21,101 Epoch[47] Batch [930]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087226,	
2017-06-20 03:16:25,767 Epoch[47] Batch [940]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087275,	
2017-06-20 03:16:30,593 Epoch[47] Batch [950]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.087206,	
2017-06-20 03:16:35,269 Epoch[47] Batch [960]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087227,	
2017-06-20 03:16:40,114 Epoch[47] Batch [970]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.087210,	
2017-06-20 03:16:44,538 Epoch[47] Batch [980]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087257,	
2017-06-20 03:16:48,902 Epoch[47] Batch [990]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087259,	
2017-06-20 03:16:53,338 Epoch[47] Batch [1000]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087325,	
2017-06-20 03:16:58,068 Epoch[47] Batch [1010]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087270,	
2017-06-20 03:17:02,586 Epoch[47] Batch [1020]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087313,	
2017-06-20 03:17:07,361 Epoch[47] Batch [1030]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087325,	
2017-06-20 03:17:12,148 Epoch[47] Batch [1040]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087341,	
2017-06-20 03:17:16,940 Epoch[47] Batch [1050]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087378,	
2017-06-20 03:17:21,658 Epoch[47] Batch [1060]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.087447,	
2017-06-20 03:17:26,432 Epoch[47] Batch [1070]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087360,	
2017-06-20 03:17:30,761 Epoch[47] Batch [1080]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087298,	
2017-06-20 03:17:35,539 Epoch[47] Batch [1090]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087331,	
2017-06-20 03:17:39,896 Epoch[47] Batch [1100]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-20 03:17:44,591 Epoch[47] Batch [1110]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-20 03:17:49,292 Epoch[47] Batch [1120]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087498,	
2017-06-20 03:17:53,906 Epoch[47] Batch [1130]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087480,	
2017-06-20 03:17:58,657 Epoch[47] Batch [1140]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087520,	
2017-06-20 03:18:03,112 Epoch[47] Batch [1150]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087544,	
2017-06-20 03:18:07,740 Epoch[47] Batch [1160]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087559,	
2017-06-20 03:18:12,254 Epoch[47] Batch [1170]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-20 03:18:16,779 Epoch[47] Batch [1180]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087542,	
2017-06-20 03:18:21,346 Epoch[47] Batch [1190]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-20 03:18:25,818 Epoch[47] Batch [1200]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087548,	
2017-06-20 03:18:30,057 Epoch[47] Batch [1210]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087580,	
2017-06-20 03:18:34,592 Epoch[47] Batch [1220]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087614,	
2017-06-20 03:18:39,238 Epoch[47] Batch [1230]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087695,	
2017-06-20 03:18:43,936 Epoch[47] Batch [1240]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087724,	
2017-06-20 03:18:48,751 Epoch[47] Batch [1250]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087680,	
2017-06-20 03:18:53,345 Epoch[47] Batch [1260]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087736,	
2017-06-20 03:18:58,004 Epoch[47] Batch [1270]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.087726,	
2017-06-20 03:19:02,725 Epoch[47] Batch [1280]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.087789,	
2017-06-20 03:19:07,485 Epoch[47] Batch [1290]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-20 03:19:12,461 Epoch[47] Batch [1300]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087645,	
2017-06-20 03:19:17,209 Epoch[47] Batch [1310]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087609,	
2017-06-20 03:19:21,818 Epoch[47] Batch [1320]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.087602,	
2017-06-20 03:19:26,194 Epoch[47] Batch [1330]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087563,	
2017-06-20 03:19:30,925 Epoch[47] Batch [1340]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087629,	
2017-06-20 03:19:35,630 Epoch[47] Batch [1350]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.087629,	
2017-06-20 03:19:40,311 Epoch[47] Batch [1360]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087637,	
2017-06-20 03:19:45,080 Epoch[47] Batch [1370]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.087670,	
2017-06-20 03:19:49,619 Epoch[47] Batch [1380]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087659,	
2017-06-20 03:19:54,339 Epoch[47] Batch [1390]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.087636,	
2017-06-20 03:19:59,161 Epoch[47] Batch [1400]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087663,	
2017-06-20 03:20:03,867 Epoch[47] Batch [1410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.087694,	
2017-06-20 03:20:08,372 Epoch[47] Batch [1420]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087721,	
2017-06-20 03:20:13,034 Epoch[47] Batch [1430]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087803,	
2017-06-20 03:20:17,799 Epoch[47] Batch [1440]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087842,	
2017-06-20 03:20:22,493 Epoch[47] Batch [1450]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087814,	
2017-06-20 03:20:27,231 Epoch[47] Batch [1460]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087785,	
2017-06-20 03:20:31,967 Epoch[47] Batch [1470]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.087843,	
2017-06-20 03:20:36,598 Epoch[47] Batch [1480]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087774,	
2017-06-20 03:20:39,489 Epoch[47] Train-FCNLogLoss=0.087751
2017-06-20 03:20:39,490 Epoch[47] Time cost=689.117
2017-06-20 03:20:40,322 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0048.params"
2017-06-20 03:20:41,972 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0048.states"
2017-06-20 03:20:47,481 Epoch[48] Batch [10]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089827,	
2017-06-20 03:20:52,012 Epoch[48] Batch [20]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.092751,	
2017-06-20 03:20:56,525 Epoch[48] Batch [30]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091180,	
2017-06-20 03:21:01,018 Epoch[48] Batch [40]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089445,	
2017-06-20 03:21:05,433 Epoch[48] Batch [50]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.089557,	
2017-06-20 03:21:09,929 Epoch[48] Batch [60]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089210,	
2017-06-20 03:21:14,587 Epoch[48] Batch [70]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089459,	
2017-06-20 03:21:19,471 Epoch[48] Batch [80]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088838,	
2017-06-20 03:21:24,358 Epoch[48] Batch [90]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088271,	
2017-06-20 03:21:29,188 Epoch[48] Batch [100]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088869,	
2017-06-20 03:21:33,860 Epoch[48] Batch [110]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088975,	
2017-06-20 03:21:38,752 Epoch[48] Batch [120]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.089152,	
2017-06-20 03:21:42,851 Epoch[48] Batch [130]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.089065,	
2017-06-20 03:21:47,469 Epoch[48] Batch [140]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088793,	
2017-06-20 03:21:52,121 Epoch[48] Batch [150]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088324,	
2017-06-20 03:21:56,773 Epoch[48] Batch [160]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088329,	
2017-06-20 03:22:01,548 Epoch[48] Batch [170]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088362,	
2017-06-20 03:22:06,183 Epoch[48] Batch [180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088082,	
2017-06-20 03:22:10,372 Epoch[48] Batch [190]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.087686,	
2017-06-20 03:22:15,093 Epoch[48] Batch [200]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.087621,	
2017-06-20 03:22:19,713 Epoch[48] Batch [210]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088071,	
2017-06-20 03:22:24,105 Epoch[48] Batch [220]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.088076,	
2017-06-20 03:22:28,493 Epoch[48] Batch [230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087838,	
2017-06-20 03:22:33,165 Epoch[48] Batch [240]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088008,	
2017-06-20 03:22:37,588 Epoch[48] Batch [250]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.088235,	
2017-06-20 03:22:41,784 Epoch[48] Batch [260]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.088271,	
2017-06-20 03:22:46,899 Epoch[48] Batch [270]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088485,	
2017-06-20 03:22:51,761 Epoch[48] Batch [280]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088472,	
2017-06-20 03:22:56,145 Epoch[48] Batch [290]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.088274,	
2017-06-20 03:23:00,540 Epoch[48] Batch [300]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.088146,	
2017-06-20 03:23:05,248 Epoch[48] Batch [310]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088397,	
2017-06-20 03:23:09,860 Epoch[48] Batch [320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088035,	
2017-06-20 03:23:14,691 Epoch[48] Batch [330]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088136,	
2017-06-20 03:23:19,261 Epoch[48] Batch [340]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088134,	
2017-06-20 03:23:23,814 Epoch[48] Batch [350]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.087696,	
2017-06-20 03:23:27,886 Epoch[48] Batch [360]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-20 03:23:32,780 Epoch[48] Batch [370]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087531,	
2017-06-20 03:23:37,642 Epoch[48] Batch [380]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087530,	
2017-06-20 03:23:42,243 Epoch[48] Batch [390]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087535,	
2017-06-20 03:23:46,804 Epoch[48] Batch [400]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087995,	
2017-06-20 03:23:51,731 Epoch[48] Batch [410]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088278,	
2017-06-20 03:23:56,202 Epoch[48] Batch [420]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-20 03:24:00,748 Epoch[48] Batch [430]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.088225,	
2017-06-20 03:24:05,439 Epoch[48] Batch [440]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.088151,	
2017-06-20 03:24:10,217 Epoch[48] Batch [450]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088058,	
2017-06-20 03:24:15,045 Epoch[48] Batch [460]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088010,	
2017-06-20 03:24:19,387 Epoch[48] Batch [470]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.087945,	
2017-06-20 03:24:23,632 Epoch[48] Batch [480]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087762,	
2017-06-20 03:24:28,508 Epoch[48] Batch [490]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.087838,	
2017-06-20 03:24:33,004 Epoch[48] Batch [500]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087846,	
2017-06-20 03:24:37,765 Epoch[48] Batch [510]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087858,	
2017-06-20 03:24:42,588 Epoch[48] Batch [520]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087774,	
2017-06-20 03:24:47,391 Epoch[48] Batch [530]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087760,	
2017-06-20 03:24:51,983 Epoch[48] Batch [540]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087835,	
2017-06-20 03:24:56,656 Epoch[48] Batch [550]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087639,	
2017-06-20 03:25:01,150 Epoch[48] Batch [560]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087548,	
2017-06-20 03:25:05,971 Epoch[48] Batch [570]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087591,	
2017-06-20 03:25:10,551 Epoch[48] Batch [580]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.087756,	
2017-06-20 03:25:15,168 Epoch[48] Batch [590]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087736,	
2017-06-20 03:25:19,783 Epoch[48] Batch [600]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087626,	
2017-06-20 03:25:24,597 Epoch[48] Batch [610]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087504,	
2017-06-20 03:25:28,974 Epoch[48] Batch [620]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087433,	
2017-06-20 03:25:33,793 Epoch[48] Batch [630]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087431,	
2017-06-20 03:25:38,439 Epoch[48] Batch [640]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087436,	
2017-06-20 03:25:42,807 Epoch[48] Batch [650]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087574,	
2017-06-20 03:25:47,425 Epoch[48] Batch [660]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087442,	
2017-06-20 03:25:51,944 Epoch[48] Batch [670]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087455,	
2017-06-20 03:25:56,422 Epoch[48] Batch [680]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087604,	
2017-06-20 03:26:01,302 Epoch[48] Batch [690]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.087568,	
2017-06-20 03:26:05,848 Epoch[48] Batch [700]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-20 03:26:10,243 Epoch[48] Batch [710]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087521,	
2017-06-20 03:26:14,917 Epoch[48] Batch [720]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087589,	
2017-06-20 03:26:19,694 Epoch[48] Batch [730]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087483,	
2017-06-20 03:26:24,494 Epoch[48] Batch [740]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087440,	
2017-06-20 03:26:29,270 Epoch[48] Batch [750]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087393,	
2017-06-20 03:26:33,542 Epoch[48] Batch [760]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087431,	
2017-06-20 03:26:38,203 Epoch[48] Batch [770]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087426,	
2017-06-20 03:26:42,926 Epoch[48] Batch [780]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.087327,	
2017-06-20 03:26:47,683 Epoch[48] Batch [790]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087295,	
2017-06-20 03:26:52,328 Epoch[48] Batch [800]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087410,	
2017-06-20 03:26:57,026 Epoch[48] Batch [810]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087507,	
2017-06-20 03:27:02,021 Epoch[48] Batch [820]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.087660,	
2017-06-20 03:27:06,340 Epoch[48] Batch [830]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087659,	
2017-06-20 03:27:11,006 Epoch[48] Batch [840]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087665,	
2017-06-20 03:27:15,980 Epoch[48] Batch [850]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.087654,	
2017-06-20 03:27:20,451 Epoch[48] Batch [860]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087551,	
2017-06-20 03:27:25,202 Epoch[48] Batch [870]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-20 03:27:29,823 Epoch[48] Batch [880]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087640,	
2017-06-20 03:27:34,747 Epoch[48] Batch [890]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.087615,	
2017-06-20 03:27:39,413 Epoch[48] Batch [900]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087522,	
2017-06-20 03:27:44,185 Epoch[48] Batch [910]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087532,	
2017-06-20 03:27:48,942 Epoch[48] Batch [920]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087485,	
2017-06-20 03:27:53,454 Epoch[48] Batch [930]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087595,	
2017-06-20 03:27:57,821 Epoch[48] Batch [940]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087635,	
2017-06-20 03:28:02,717 Epoch[48] Batch [950]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087676,	
2017-06-20 03:28:07,200 Epoch[48] Batch [960]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087679,	
2017-06-20 03:28:11,587 Epoch[48] Batch [970]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087547,	
2017-06-20 03:28:16,058 Epoch[48] Batch [980]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087472,	
2017-06-20 03:28:20,146 Epoch[48] Batch [990]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.087414,	
2017-06-20 03:28:24,870 Epoch[48] Batch [1000]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-20 03:28:29,393 Epoch[48] Batch [1010]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087434,	
2017-06-20 03:28:34,327 Epoch[48] Batch [1020]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.087455,	
2017-06-20 03:28:39,092 Epoch[48] Batch [1030]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087448,	
2017-06-20 03:28:43,655 Epoch[48] Batch [1040]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087384,	
2017-06-20 03:28:48,305 Epoch[48] Batch [1050]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.087367,	
2017-06-20 03:28:52,932 Epoch[48] Batch [1060]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.087406,	
2017-06-20 03:28:57,556 Epoch[48] Batch [1070]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.087351,	
2017-06-20 03:29:01,991 Epoch[48] Batch [1080]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087490,	
2017-06-20 03:29:06,380 Epoch[48] Batch [1090]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087529,	
2017-06-20 03:29:10,791 Epoch[48] Batch [1100]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087523,	
2017-06-20 03:29:15,502 Epoch[48] Batch [1110]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087540,	
2017-06-20 03:29:20,059 Epoch[48] Batch [1120]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-20 03:29:24,295 Epoch[48] Batch [1130]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087557,	
2017-06-20 03:29:28,851 Epoch[48] Batch [1140]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087538,	
2017-06-20 03:29:33,711 Epoch[48] Batch [1150]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087557,	
2017-06-20 03:29:38,496 Epoch[48] Batch [1160]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087522,	
2017-06-20 03:29:43,252 Epoch[48] Batch [1170]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087480,	
2017-06-20 03:29:47,916 Epoch[48] Batch [1180]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087504,	
2017-06-20 03:29:52,404 Epoch[48] Batch [1190]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087543,	
2017-06-20 03:29:57,200 Epoch[48] Batch [1200]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.087584,	
2017-06-20 03:30:01,729 Epoch[48] Batch [1210]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-20 03:30:06,320 Epoch[48] Batch [1220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087595,	
2017-06-20 03:30:10,971 Epoch[48] Batch [1230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.087585,	
2017-06-20 03:30:15,398 Epoch[48] Batch [1240]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087670,	
2017-06-20 03:30:20,149 Epoch[48] Batch [1250]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087577,	
2017-06-20 03:30:24,812 Epoch[48] Batch [1260]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087583,	
2017-06-20 03:30:29,388 Epoch[48] Batch [1270]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087556,	
2017-06-20 03:30:33,985 Epoch[48] Batch [1280]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087636,	
2017-06-20 03:30:38,481 Epoch[48] Batch [1290]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-20 03:30:42,968 Epoch[48] Batch [1300]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087634,	
2017-06-20 03:30:47,769 Epoch[48] Batch [1310]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087695,	
2017-06-20 03:30:52,454 Epoch[48] Batch [1320]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087639,	
2017-06-20 03:30:57,028 Epoch[48] Batch [1330]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087657,	
2017-06-20 03:31:01,720 Epoch[48] Batch [1340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087653,	
2017-06-20 03:31:06,367 Epoch[48] Batch [1350]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087673,	
2017-06-20 03:31:11,059 Epoch[48] Batch [1360]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087716,	
2017-06-20 03:31:15,617 Epoch[48] Batch [1370]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087790,	
2017-06-20 03:31:20,198 Epoch[48] Batch [1380]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.087718,	
2017-06-20 03:31:24,846 Epoch[48] Batch [1390]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087689,	
2017-06-20 03:31:29,293 Epoch[48] Batch [1400]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087652,	
2017-06-20 03:31:33,508 Epoch[48] Batch [1410]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.087644,	
2017-06-20 03:31:37,931 Epoch[48] Batch [1420]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-20 03:31:42,503 Epoch[48] Batch [1430]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087602,	
2017-06-20 03:31:47,218 Epoch[48] Batch [1440]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.087538,	
2017-06-20 03:31:51,956 Epoch[48] Batch [1450]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087595,	
2017-06-20 03:31:56,638 Epoch[48] Batch [1460]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087629,	
2017-06-20 03:32:00,772 Epoch[48] Batch [1470]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087597,	
2017-06-20 03:32:05,324 Epoch[48] Batch [1480]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.087639,	
2017-06-20 03:32:07,886 Epoch[48] Train-FCNLogLoss=0.087689
2017-06-20 03:32:07,886 Epoch[48] Time cost=685.913
2017-06-20 03:32:08,705 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0049.params"
2017-06-20 03:32:10,790 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0049.states"
2017-06-20 03:32:15,798 Epoch[49] Batch [10]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100105,	
2017-06-20 03:32:20,470 Epoch[49] Batch [20]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090359,	
2017-06-20 03:32:24,984 Epoch[49] Batch [30]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091130,	
2017-06-20 03:32:29,440 Epoch[49] Batch [40]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091125,	
2017-06-20 03:32:33,939 Epoch[49] Batch [50]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090564,	
2017-06-20 03:32:38,353 Epoch[49] Batch [60]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091586,	
2017-06-20 03:32:42,888 Epoch[49] Batch [70]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.090819,	
2017-06-20 03:32:47,497 Epoch[49] Batch [80]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091248,	
2017-06-20 03:32:52,184 Epoch[49] Batch [90]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090004,	
2017-06-20 03:32:57,061 Epoch[49] Batch [100]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089677,	
2017-06-20 03:33:01,716 Epoch[49] Batch [110]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089294,	
2017-06-20 03:33:06,390 Epoch[49] Batch [120]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088148,	
2017-06-20 03:33:10,558 Epoch[49] Batch [130]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.088099,	
2017-06-20 03:33:14,964 Epoch[49] Batch [140]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.088301,	
2017-06-20 03:33:19,470 Epoch[49] Batch [150]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.088616,	
2017-06-20 03:33:24,168 Epoch[49] Batch [160]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.088924,	
2017-06-20 03:33:28,692 Epoch[49] Batch [170]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.088580,	
2017-06-20 03:33:33,476 Epoch[49] Batch [180]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088705,	
2017-06-20 03:33:38,112 Epoch[49] Batch [190]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089139,	
2017-06-20 03:33:42,534 Epoch[49] Batch [200]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.089212,	
2017-06-20 03:33:47,279 Epoch[49] Batch [210]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.088836,	
2017-06-20 03:33:52,034 Epoch[49] Batch [220]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089020,	
2017-06-20 03:33:56,368 Epoch[49] Batch [230]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.089081,	
2017-06-20 03:34:01,232 Epoch[49] Batch [240]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089070,	
2017-06-20 03:34:05,912 Epoch[49] Batch [250]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088972,	
2017-06-20 03:34:10,515 Epoch[49] Batch [260]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088825,	
2017-06-20 03:34:15,037 Epoch[49] Batch [270]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088846,	
2017-06-20 03:34:19,645 Epoch[49] Batch [280]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088731,	
2017-06-20 03:34:24,292 Epoch[49] Batch [290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088514,	
2017-06-20 03:34:29,257 Epoch[49] Batch [300]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088181,	
2017-06-20 03:34:33,846 Epoch[49] Batch [310]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.088074,	
2017-06-20 03:34:38,410 Epoch[49] Batch [320]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087933,	
2017-06-20 03:34:42,787 Epoch[49] Batch [330]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.088043,	
2017-06-20 03:34:47,353 Epoch[49] Batch [340]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087995,	
2017-06-20 03:34:51,793 Epoch[49] Batch [350]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.087940,	
2017-06-20 03:34:56,417 Epoch[49] Batch [360]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.087665,	
2017-06-20 03:35:00,922 Epoch[49] Batch [370]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-20 03:35:05,437 Epoch[49] Batch [380]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087906,	
2017-06-20 03:35:10,175 Epoch[49] Batch [390]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087940,	
2017-06-20 03:35:14,522 Epoch[49] Batch [400]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087831,	
2017-06-20 03:35:18,917 Epoch[49] Batch [410]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087962,	
2017-06-20 03:35:23,383 Epoch[49] Batch [420]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.088014,	
2017-06-20 03:35:28,052 Epoch[49] Batch [430]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088162,	
2017-06-20 03:35:32,639 Epoch[49] Batch [440]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.088216,	
2017-06-20 03:35:37,047 Epoch[49] Batch [450]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088123,	
2017-06-20 03:35:41,456 Epoch[49] Batch [460]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087956,	
2017-06-20 03:35:46,341 Epoch[49] Batch [470]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088150,	
2017-06-20 03:35:50,804 Epoch[49] Batch [480]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087995,	
2017-06-20 03:35:55,469 Epoch[49] Batch [490]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088176,	
2017-06-20 03:36:00,045 Epoch[49] Batch [500]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088222,	
2017-06-20 03:36:04,522 Epoch[49] Batch [510]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.088269,	
2017-06-20 03:36:09,284 Epoch[49] Batch [520]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-20 03:36:13,883 Epoch[49] Batch [530]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088431,	
2017-06-20 03:36:18,839 Epoch[49] Batch [540]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088348,	
2017-06-20 03:36:23,205 Epoch[49] Batch [550]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.088251,	
2017-06-20 03:36:27,662 Epoch[49] Batch [560]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.088118,	
2017-06-20 03:36:32,228 Epoch[49] Batch [570]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.088024,	
2017-06-20 03:36:36,479 Epoch[49] Batch [580]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.088108,	
2017-06-20 03:36:41,226 Epoch[49] Batch [590]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.088190,	
2017-06-20 03:36:45,984 Epoch[49] Batch [600]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088133,	
2017-06-20 03:36:50,299 Epoch[49] Batch [610]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088192,	
2017-06-20 03:36:54,447 Epoch[49] Batch [620]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.088180,	
2017-06-20 03:36:59,136 Epoch[49] Batch [630]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.088131,	
2017-06-20 03:37:03,880 Epoch[49] Batch [640]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.088242,	
2017-06-20 03:37:08,478 Epoch[49] Batch [650]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.088088,	
2017-06-20 03:37:13,167 Epoch[49] Batch [660]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.088298,	
2017-06-20 03:37:18,084 Epoch[49] Batch [670]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088081,	
2017-06-20 03:37:22,572 Epoch[49] Batch [680]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.088166,	
2017-06-20 03:37:27,245 Epoch[49] Batch [690]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088115,	
2017-06-20 03:37:31,864 Epoch[49] Batch [700]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088230,	
2017-06-20 03:37:36,671 Epoch[49] Batch [710]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088122,	
2017-06-20 03:37:41,323 Epoch[49] Batch [720]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088037,	
2017-06-20 03:37:46,052 Epoch[49] Batch [730]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087967,	
2017-06-20 03:37:50,613 Epoch[49] Batch [740]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087882,	
2017-06-20 03:37:55,311 Epoch[49] Batch [750]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087906,	
2017-06-20 03:37:59,838 Epoch[49] Batch [760]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087859,	
2017-06-20 03:38:04,507 Epoch[49] Batch [770]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087847,	
2017-06-20 03:38:08,881 Epoch[49] Batch [780]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087887,	
2017-06-20 03:38:13,440 Epoch[49] Batch [790]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087820,	
2017-06-20 03:38:18,083 Epoch[49] Batch [800]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087799,	
2017-06-20 03:38:22,605 Epoch[49] Batch [810]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087714,	
2017-06-20 03:38:27,284 Epoch[49] Batch [820]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087670,	
2017-06-20 03:38:31,923 Epoch[49] Batch [830]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087624,	
2017-06-20 03:38:36,499 Epoch[49] Batch [840]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087699,	
2017-06-20 03:38:41,320 Epoch[49] Batch [850]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087756,	
2017-06-20 03:38:45,992 Epoch[49] Batch [860]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087728,	
2017-06-20 03:38:50,651 Epoch[49] Batch [870]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.087652,	
2017-06-20 03:38:55,225 Epoch[49] Batch [880]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087620,	
2017-06-20 03:38:59,634 Epoch[49] Batch [890]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087598,	
2017-06-20 03:39:04,085 Epoch[49] Batch [900]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087677,	
2017-06-20 03:39:08,705 Epoch[49] Batch [910]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087621,	
2017-06-20 03:39:13,308 Epoch[49] Batch [920]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087482,	
2017-06-20 03:39:17,993 Epoch[49] Batch [930]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087383,	
2017-06-20 03:39:22,542 Epoch[49] Batch [940]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.087386,	
2017-06-20 03:39:27,389 Epoch[49] Batch [950]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087369,	
2017-06-20 03:39:31,526 Epoch[49] Batch [960]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.087390,	
2017-06-20 03:39:36,144 Epoch[49] Batch [970]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087403,	
2017-06-20 03:39:41,167 Epoch[49] Batch [980]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087467,	
2017-06-20 03:39:45,500 Epoch[49] Batch [990]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087502,	
2017-06-20 03:39:49,735 Epoch[49] Batch [1000]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.087537,	
2017-06-20 03:39:54,262 Epoch[49] Batch [1010]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087463,	
2017-06-20 03:39:58,992 Epoch[49] Batch [1020]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087411,	
2017-06-20 03:40:03,677 Epoch[49] Batch [1030]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087406,	
2017-06-20 03:40:07,864 Epoch[49] Batch [1040]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.087388,	
2017-06-20 03:40:12,580 Epoch[49] Batch [1050]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.087433,	
2017-06-20 03:40:17,448 Epoch[49] Batch [1060]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.087466,	
2017-06-20 03:40:21,901 Epoch[49] Batch [1070]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087537,	
2017-06-20 03:40:26,699 Epoch[49] Batch [1080]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.087556,	
2017-06-20 03:40:31,499 Epoch[49] Batch [1090]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087478,	
2017-06-20 03:40:36,102 Epoch[49] Batch [1100]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087519,	
2017-06-20 03:40:40,421 Epoch[49] Batch [1110]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087524,	
2017-06-20 03:40:44,727 Epoch[49] Batch [1120]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087463,	
2017-06-20 03:40:49,225 Epoch[49] Batch [1130]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087497,	
2017-06-20 03:40:53,817 Epoch[49] Batch [1140]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087528,	
2017-06-20 03:40:58,409 Epoch[49] Batch [1150]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087529,	
2017-06-20 03:41:03,139 Epoch[49] Batch [1160]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087635,	
2017-06-20 03:41:07,951 Epoch[49] Batch [1170]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087606,	
2017-06-20 03:41:12,788 Epoch[49] Batch [1180]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.087577,	
2017-06-20 03:41:17,336 Epoch[49] Batch [1190]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.087562,	
2017-06-20 03:41:21,912 Epoch[49] Batch [1200]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087543,	
2017-06-20 03:41:26,222 Epoch[49] Batch [1210]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.087497,	
2017-06-20 03:41:30,759 Epoch[49] Batch [1220]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087453,	
2017-06-20 03:41:35,560 Epoch[49] Batch [1230]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.087450,	
2017-06-20 03:41:40,142 Epoch[49] Batch [1240]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.087531,	
2017-06-20 03:41:44,759 Epoch[49] Batch [1250]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087617,	
2017-06-20 03:41:49,325 Epoch[49] Batch [1260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087712,	
2017-06-20 03:41:53,991 Epoch[49] Batch [1270]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087774,	
2017-06-20 03:41:59,002 Epoch[49] Batch [1280]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087749,	
2017-06-20 03:42:03,766 Epoch[49] Batch [1290]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-20 03:42:07,968 Epoch[49] Batch [1300]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087700,	
2017-06-20 03:42:12,659 Epoch[49] Batch [1310]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087696,	
2017-06-20 03:42:17,122 Epoch[49] Batch [1320]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087681,	
2017-06-20 03:42:21,800 Epoch[49] Batch [1330]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087723,	
2017-06-20 03:42:26,269 Epoch[49] Batch [1340]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087754,	
2017-06-20 03:42:31,051 Epoch[49] Batch [1350]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087724,	
2017-06-20 03:42:35,658 Epoch[49] Batch [1360]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.087697,	
2017-06-20 03:42:40,567 Epoch[49] Batch [1370]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.087680,	
2017-06-20 03:42:45,189 Epoch[49] Batch [1380]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087631,	
2017-06-20 03:42:49,745 Epoch[49] Batch [1390]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087639,	
2017-06-20 03:42:54,107 Epoch[49] Batch [1400]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087637,	
2017-06-20 03:42:58,745 Epoch[49] Batch [1410]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087685,	
2017-06-20 03:43:03,206 Epoch[49] Batch [1420]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087730,	
2017-06-20 03:43:07,468 Epoch[49] Batch [1430]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-20 03:43:12,247 Epoch[49] Batch [1440]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087669,	
2017-06-20 03:43:16,748 Epoch[49] Batch [1450]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087625,	
2017-06-20 03:43:21,319 Epoch[49] Batch [1460]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-20 03:43:26,047 Epoch[49] Batch [1470]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087661,	
2017-06-20 03:43:30,812 Epoch[49] Batch [1480]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.087607,	
2017-06-20 03:43:33,459 Epoch[49] Train-FCNLogLoss=0.087595
2017-06-20 03:43:33,459 Epoch[49] Time cost=682.668
2017-06-20 03:43:34,173 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0050.params"
2017-06-20 03:43:35,996 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0050.states"
2017-06-20 03:43:41,563 Epoch[50] Batch [10]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090808,	
2017-06-20 03:43:45,959 Epoch[50] Batch [20]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090434,	
2017-06-20 03:43:50,649 Epoch[50] Batch [30]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.086594,	
2017-06-20 03:43:55,271 Epoch[50] Batch [40]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.087487,	
2017-06-20 03:43:59,859 Epoch[50] Batch [50]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.088379,	
2017-06-20 03:44:04,500 Epoch[50] Batch [60]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087695,	
2017-06-20 03:44:09,054 Epoch[50] Batch [70]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.088803,	
2017-06-20 03:44:13,690 Epoch[50] Batch [80]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088840,	
2017-06-20 03:44:17,928 Epoch[50] Batch [90]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.089038,	
2017-06-20 03:44:22,222 Epoch[50] Batch [100]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.090075,	
2017-06-20 03:44:26,525 Epoch[50] Batch [110]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.089499,	
2017-06-20 03:44:31,234 Epoch[50] Batch [120]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089180,	
2017-06-20 03:44:35,590 Epoch[50] Batch [130]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089181,	
2017-06-20 03:44:40,006 Epoch[50] Batch [140]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.088983,	
2017-06-20 03:44:44,626 Epoch[50] Batch [150]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088756,	
2017-06-20 03:44:49,086 Epoch[50] Batch [160]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.089114,	
2017-06-20 03:44:53,852 Epoch[50] Batch [170]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089549,	
2017-06-20 03:44:58,427 Epoch[50] Batch [180]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089473,	
2017-06-20 03:45:03,068 Epoch[50] Batch [190]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089601,	
2017-06-20 03:45:07,564 Epoch[50] Batch [200]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088849,	
2017-06-20 03:45:12,570 Epoch[50] Batch [210]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088849,	
2017-06-20 03:45:17,106 Epoch[50] Batch [220]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088679,	
2017-06-20 03:45:21,635 Epoch[50] Batch [230]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088572,	
2017-06-20 03:45:26,364 Epoch[50] Batch [240]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088428,	
2017-06-20 03:45:31,253 Epoch[50] Batch [250]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088133,	
2017-06-20 03:45:36,031 Epoch[50] Batch [260]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088061,	
2017-06-20 03:45:40,553 Epoch[50] Batch [270]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087591,	
2017-06-20 03:45:45,023 Epoch[50] Batch [280]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087632,	
2017-06-20 03:45:49,642 Epoch[50] Batch [290]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087567,	
2017-06-20 03:45:54,005 Epoch[50] Batch [300]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087390,	
2017-06-20 03:45:58,608 Epoch[50] Batch [310]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087321,	
2017-06-20 03:46:03,138 Epoch[50] Batch [320]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.087272,	
2017-06-20 03:46:07,608 Epoch[50] Batch [330]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-20 03:46:12,149 Epoch[50] Batch [340]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087422,	
2017-06-20 03:46:16,652 Epoch[50] Batch [350]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087248,	
2017-06-20 03:46:21,020 Epoch[50] Batch [360]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087439,	
2017-06-20 03:46:25,319 Epoch[50] Batch [370]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087579,	
2017-06-20 03:46:29,839 Epoch[50] Batch [380]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087647,	
2017-06-20 03:46:34,665 Epoch[50] Batch [390]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087567,	
2017-06-20 03:46:39,259 Epoch[50] Batch [400]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087659,	
2017-06-20 03:46:43,619 Epoch[50] Batch [410]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.087611,	
2017-06-20 03:46:48,236 Epoch[50] Batch [420]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087800,	
2017-06-20 03:46:52,730 Epoch[50] Batch [430]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087880,	
2017-06-20 03:46:57,637 Epoch[50] Batch [440]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.087762,	
2017-06-20 03:47:02,038 Epoch[50] Batch [450]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-20 03:47:06,532 Epoch[50] Batch [460]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087591,	
2017-06-20 03:47:11,270 Epoch[50] Batch [470]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087472,	
2017-06-20 03:47:16,263 Epoch[50] Batch [480]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.087582,	
2017-06-20 03:47:20,733 Epoch[50] Batch [490]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087456,	
2017-06-20 03:47:25,504 Epoch[50] Batch [500]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087483,	
2017-06-20 03:47:30,416 Epoch[50] Batch [510]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.087412,	
2017-06-20 03:47:35,116 Epoch[50] Batch [520]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087273,	
2017-06-20 03:47:39,802 Epoch[50] Batch [530]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087304,	
2017-06-20 03:47:44,376 Epoch[50] Batch [540]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087172,	
2017-06-20 03:47:48,993 Epoch[50] Batch [550]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087245,	
2017-06-20 03:47:53,439 Epoch[50] Batch [560]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087242,	
2017-06-20 03:47:57,911 Epoch[50] Batch [570]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087171,	
2017-06-20 03:48:02,108 Epoch[50] Batch [580]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.087204,	
2017-06-20 03:48:06,972 Epoch[50] Batch [590]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.087340,	
2017-06-20 03:48:11,689 Epoch[50] Batch [600]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.087257,	
2017-06-20 03:48:16,292 Epoch[50] Batch [610]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.087196,	
2017-06-20 03:48:21,339 Epoch[50] Batch [620]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087246,	
2017-06-20 03:48:25,910 Epoch[50] Batch [630]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087210,	
2017-06-20 03:48:30,434 Epoch[50] Batch [640]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087295,	
2017-06-20 03:48:35,207 Epoch[50] Batch [650]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087315,	
2017-06-20 03:48:39,759 Epoch[50] Batch [660]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.087291,	
2017-06-20 03:48:44,411 Epoch[50] Batch [670]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.087378,	
2017-06-20 03:48:48,882 Epoch[50] Batch [680]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087408,	
2017-06-20 03:48:53,328 Epoch[50] Batch [690]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087446,	
2017-06-20 03:48:57,906 Epoch[50] Batch [700]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087521,	
2017-06-20 03:49:02,544 Epoch[50] Batch [710]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087580,	
2017-06-20 03:49:07,323 Epoch[50] Batch [720]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087592,	
2017-06-20 03:49:11,657 Epoch[50] Batch [730]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087557,	
2017-06-20 03:49:16,346 Epoch[50] Batch [740]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087671,	
2017-06-20 03:49:20,940 Epoch[50] Batch [750]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087761,	
2017-06-20 03:49:25,444 Epoch[50] Batch [760]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087889,	
2017-06-20 03:49:30,435 Epoch[50] Batch [770]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087764,	
2017-06-20 03:49:35,478 Epoch[50] Batch [780]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087832,	
2017-06-20 03:49:40,236 Epoch[50] Batch [790]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087808,	
2017-06-20 03:49:44,967 Epoch[50] Batch [800]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.087729,	
2017-06-20 03:49:49,617 Epoch[50] Batch [810]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.087797,	
2017-06-20 03:49:54,030 Epoch[50] Batch [820]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087896,	
2017-06-20 03:49:59,023 Epoch[50] Batch [830]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.087895,	
2017-06-20 03:50:03,587 Epoch[50] Batch [840]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087893,	
2017-06-20 03:50:08,059 Epoch[50] Batch [850]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087797,	
2017-06-20 03:50:12,537 Epoch[50] Batch [860]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087833,	
2017-06-20 03:50:17,101 Epoch[50] Batch [870]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087729,	
2017-06-20 03:50:21,953 Epoch[50] Batch [880]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.087663,	
2017-06-20 03:50:26,705 Epoch[50] Batch [890]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087644,	
2017-06-20 03:50:31,692 Epoch[50] Batch [900]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087716,	
2017-06-20 03:50:36,009 Epoch[50] Batch [910]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087781,	
2017-06-20 03:50:40,548 Epoch[50] Batch [920]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087854,	
2017-06-20 03:50:45,218 Epoch[50] Batch [930]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087904,	
2017-06-20 03:50:49,950 Epoch[50] Batch [940]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.087841,	
2017-06-20 03:50:54,645 Epoch[50] Batch [950]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087785,	
2017-06-20 03:50:59,320 Epoch[50] Batch [960]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087809,	
2017-06-20 03:51:03,605 Epoch[50] Batch [970]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087804,	
2017-06-20 03:51:08,189 Epoch[50] Batch [980]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.087768,	
2017-06-20 03:51:12,510 Epoch[50] Batch [990]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087780,	
2017-06-20 03:51:17,223 Epoch[50] Batch [1000]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087749,	
2017-06-20 03:51:22,204 Epoch[50] Batch [1010]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087720,	
2017-06-20 03:51:27,022 Epoch[50] Batch [1020]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087736,	
2017-06-20 03:51:31,786 Epoch[50] Batch [1030]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087701,	
2017-06-20 03:51:36,461 Epoch[50] Batch [1040]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-20 03:51:40,973 Epoch[50] Batch [1050]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087686,	
2017-06-20 03:51:45,521 Epoch[50] Batch [1060]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.087613,	
2017-06-20 03:51:50,450 Epoch[50] Batch [1070]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.087473,	
2017-06-20 03:51:54,975 Epoch[50] Batch [1080]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087523,	
2017-06-20 03:51:59,468 Epoch[50] Batch [1090]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087520,	
2017-06-20 03:52:04,219 Epoch[50] Batch [1100]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087507,	
2017-06-20 03:52:08,913 Epoch[50] Batch [1110]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087432,	
2017-06-20 03:52:13,506 Epoch[50] Batch [1120]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-20 03:52:18,492 Epoch[50] Batch [1130]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087487,	
2017-06-20 03:52:22,969 Epoch[50] Batch [1140]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087487,	
2017-06-20 03:52:27,527 Epoch[50] Batch [1150]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087497,	
2017-06-20 03:52:32,270 Epoch[50] Batch [1160]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087491,	
2017-06-20 03:52:36,652 Epoch[50] Batch [1170]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.087445,	
2017-06-20 03:52:41,069 Epoch[50] Batch [1180]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087382,	
2017-06-20 03:52:45,772 Epoch[50] Batch [1190]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.087425,	
2017-06-20 03:52:50,439 Epoch[50] Batch [1200]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-20 03:52:55,004 Epoch[50] Batch [1210]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087499,	
2017-06-20 03:52:59,761 Epoch[50] Batch [1220]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087493,	
2017-06-20 03:53:04,674 Epoch[50] Batch [1230]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.087523,	
2017-06-20 03:53:09,378 Epoch[50] Batch [1240]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.087577,	
2017-06-20 03:53:14,092 Epoch[50] Batch [1250]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087539,	
2017-06-20 03:53:18,427 Epoch[50] Batch [1260]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087519,	
2017-06-20 03:53:23,134 Epoch[50] Batch [1270]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.087519,	
2017-06-20 03:53:27,605 Epoch[50] Batch [1280]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.087499,	
2017-06-20 03:53:32,043 Epoch[50] Batch [1290]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.087644,	
2017-06-20 03:53:36,628 Epoch[50] Batch [1300]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.087699,	
2017-06-20 03:53:41,046 Epoch[50] Batch [1310]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087741,	
2017-06-20 03:53:45,813 Epoch[50] Batch [1320]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.087743,	
2017-06-20 03:53:50,450 Epoch[50] Batch [1330]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087750,	
2017-06-20 03:53:55,140 Epoch[50] Batch [1340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087780,	
2017-06-20 03:53:59,794 Epoch[50] Batch [1350]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.087834,	
2017-06-20 03:54:04,461 Epoch[50] Batch [1360]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087893,	
2017-06-20 03:54:08,956 Epoch[50] Batch [1370]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087884,	
2017-06-20 03:54:13,697 Epoch[50] Batch [1380]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087840,	
2017-06-20 03:54:18,416 Epoch[50] Batch [1390]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.087857,	
2017-06-20 03:54:22,950 Epoch[50] Batch [1400]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087896,	
2017-06-20 03:54:27,772 Epoch[50] Batch [1410]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087894,	
2017-06-20 03:54:32,433 Epoch[50] Batch [1420]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087885,	
2017-06-20 03:54:36,854 Epoch[50] Batch [1430]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.087934,	
2017-06-20 03:54:41,568 Epoch[50] Batch [1440]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087907,	
2017-06-20 03:54:46,206 Epoch[50] Batch [1450]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087892,	
2017-06-20 03:54:50,579 Epoch[50] Batch [1460]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087886,	
2017-06-20 03:54:55,336 Epoch[50] Batch [1470]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087829,	
2017-06-20 03:54:59,731 Epoch[50] Batch [1480]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087825,	
2017-06-20 03:55:02,263 Epoch[50] Train-FCNLogLoss=0.087807
2017-06-20 03:55:02,263 Epoch[50] Time cost=686.266
2017-06-20 03:55:02,983 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0051.params"
2017-06-20 03:55:04,703 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0051.states"
2017-06-20 03:55:10,145 Epoch[51] Batch [10]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.083471,	
2017-06-20 03:55:14,689 Epoch[51] Batch [20]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.082955,	
2017-06-20 03:55:19,098 Epoch[51] Batch [30]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087615,	
2017-06-20 03:55:23,649 Epoch[51] Batch [40]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088463,	
2017-06-20 03:55:28,012 Epoch[51] Batch [50]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.088785,	
2017-06-20 03:55:32,639 Epoch[51] Batch [60]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.090298,	
2017-06-20 03:55:37,220 Epoch[51] Batch [70]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091472,	
2017-06-20 03:55:41,749 Epoch[51] Batch [80]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.090628,	
2017-06-20 03:55:46,143 Epoch[51] Batch [90]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.089689,	
2017-06-20 03:55:50,776 Epoch[51] Batch [100]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089515,	
2017-06-20 03:55:55,157 Epoch[51] Batch [110]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.089510,	
2017-06-20 03:55:59,731 Epoch[51] Batch [120]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088927,	
2017-06-20 03:56:04,127 Epoch[51] Batch [130]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.088187,	
2017-06-20 03:56:08,781 Epoch[51] Batch [140]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.088649,	
2017-06-20 03:56:13,590 Epoch[51] Batch [150]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088386,	
2017-06-20 03:56:18,388 Epoch[51] Batch [160]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.088334,	
2017-06-20 03:56:22,753 Epoch[51] Batch [170]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087957,	
2017-06-20 03:56:27,677 Epoch[51] Batch [180]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-20 03:56:32,533 Epoch[51] Batch [190]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088362,	
2017-06-20 03:56:37,255 Epoch[51] Batch [200]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088087,	
2017-06-20 03:56:41,741 Epoch[51] Batch [210]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087586,	
2017-06-20 03:56:46,323 Epoch[51] Batch [220]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.087591,	
2017-06-20 03:56:50,789 Epoch[51] Batch [230]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087316,	
2017-06-20 03:56:55,151 Epoch[51] Batch [240]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087271,	
2017-06-20 03:57:00,166 Epoch[51] Batch [250]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.087417,	
2017-06-20 03:57:04,626 Epoch[51] Batch [260]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087064,	
2017-06-20 03:57:09,306 Epoch[51] Batch [270]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087026,	
2017-06-20 03:57:14,021 Epoch[51] Batch [280]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.087249,	
2017-06-20 03:57:18,785 Epoch[51] Batch [290]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087303,	
2017-06-20 03:57:23,486 Epoch[51] Batch [300]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087304,	
2017-06-20 03:57:28,274 Epoch[51] Batch [310]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087254,	
2017-06-20 03:57:32,882 Epoch[51] Batch [320]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.087432,	
2017-06-20 03:57:37,513 Epoch[51] Batch [330]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087434,	
2017-06-20 03:57:42,132 Epoch[51] Batch [340]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087398,	
2017-06-20 03:57:46,901 Epoch[51] Batch [350]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.087540,	
2017-06-20 03:57:51,728 Epoch[51] Batch [360]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087524,	
2017-06-20 03:57:56,055 Epoch[51] Batch [370]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-20 03:58:00,772 Epoch[51] Batch [380]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.087909,	
2017-06-20 03:58:05,589 Epoch[51] Batch [390]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087823,	
2017-06-20 03:58:10,127 Epoch[51] Batch [400]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087713,	
2017-06-20 03:58:14,586 Epoch[51] Batch [410]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087684,	
2017-06-20 03:58:19,228 Epoch[51] Batch [420]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087941,	
2017-06-20 03:58:23,843 Epoch[51] Batch [430]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088039,	
2017-06-20 03:58:28,610 Epoch[51] Batch [440]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088058,	
2017-06-20 03:58:33,006 Epoch[51] Batch [450]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087938,	
2017-06-20 03:58:37,569 Epoch[51] Batch [460]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087735,	
2017-06-20 03:58:42,247 Epoch[51] Batch [470]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.087576,	
2017-06-20 03:58:46,661 Epoch[51] Batch [480]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087542,	
2017-06-20 03:58:51,277 Epoch[51] Batch [490]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087593,	
2017-06-20 03:58:55,609 Epoch[51] Batch [500]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087469,	
2017-06-20 03:59:00,323 Epoch[51] Batch [510]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087530,	
2017-06-20 03:59:04,938 Epoch[51] Batch [520]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087574,	
2017-06-20 03:59:09,571 Epoch[51] Batch [530]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087615,	
2017-06-20 03:59:14,438 Epoch[51] Batch [540]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.087507,	
2017-06-20 03:59:18,947 Epoch[51] Batch [550]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087551,	
2017-06-20 03:59:23,130 Epoch[51] Batch [560]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.087534,	
2017-06-20 03:59:27,517 Epoch[51] Batch [570]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087544,	
2017-06-20 03:59:32,012 Epoch[51] Batch [580]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087479,	
2017-06-20 03:59:36,771 Epoch[51] Batch [590]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.087251,	
2017-06-20 03:59:41,343 Epoch[51] Batch [600]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087159,	
2017-06-20 03:59:46,140 Epoch[51] Batch [610]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.087181,	
2017-06-20 03:59:50,574 Epoch[51] Batch [620]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087090,	
2017-06-20 03:59:55,352 Epoch[51] Batch [630]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.087141,	
2017-06-20 03:59:59,705 Epoch[51] Batch [640]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087135,	
2017-06-20 04:00:04,339 Epoch[51] Batch [650]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087052,	
2017-06-20 04:00:09,247 Epoch[51] Batch [660]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.086936,	
2017-06-20 04:00:14,093 Epoch[51] Batch [670]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086993,	
2017-06-20 04:00:18,933 Epoch[51] Batch [680]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086951,	
2017-06-20 04:00:23,717 Epoch[51] Batch [690]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087023,	
2017-06-20 04:00:28,077 Epoch[51] Batch [700]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086962,	
2017-06-20 04:00:32,526 Epoch[51] Batch [710]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.086859,	
2017-06-20 04:00:37,215 Epoch[51] Batch [720]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.086854,	
2017-06-20 04:00:41,801 Epoch[51] Batch [730]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.086926,	
2017-06-20 04:00:46,669 Epoch[51] Batch [740]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086944,	
2017-06-20 04:00:51,032 Epoch[51] Batch [750]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.086829,	
2017-06-20 04:00:55,510 Epoch[51] Batch [760]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086759,	
2017-06-20 04:00:59,913 Epoch[51] Batch [770]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086718,	
2017-06-20 04:01:04,584 Epoch[51] Batch [780]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.086770,	
2017-06-20 04:01:09,330 Epoch[51] Batch [790]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.086850,	
2017-06-20 04:01:14,303 Epoch[51] Batch [800]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.086879,	
2017-06-20 04:01:18,874 Epoch[51] Batch [810]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087070,	
2017-06-20 04:01:23,193 Epoch[51] Batch [820]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087054,	
2017-06-20 04:01:28,010 Epoch[51] Batch [830]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087010,	
2017-06-20 04:01:32,543 Epoch[51] Batch [840]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.086945,	
2017-06-20 04:01:36,927 Epoch[51] Batch [850]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086834,	
2017-06-20 04:01:41,709 Epoch[51] Batch [860]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086625,	
2017-06-20 04:01:46,496 Epoch[51] Batch [870]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086727,	
2017-06-20 04:01:51,026 Epoch[51] Batch [880]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.086786,	
2017-06-20 04:01:55,406 Epoch[51] Batch [890]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.086820,	
2017-06-20 04:01:59,979 Epoch[51] Batch [900]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.086843,	
2017-06-20 04:02:04,640 Epoch[51] Batch [910]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.086761,	
2017-06-20 04:02:09,265 Epoch[51] Batch [920]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086750,	
2017-06-20 04:02:14,041 Epoch[51] Batch [930]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.086777,	
2017-06-20 04:02:18,783 Epoch[51] Batch [940]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.086839,	
2017-06-20 04:02:23,332 Epoch[51] Batch [950]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.086783,	
2017-06-20 04:02:27,929 Epoch[51] Batch [960]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.086778,	
2017-06-20 04:02:32,678 Epoch[51] Batch [970]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.086812,	
2017-06-20 04:02:37,378 Epoch[51] Batch [980]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.086835,	
2017-06-20 04:02:42,162 Epoch[51] Batch [990]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086831,	
2017-06-20 04:02:46,812 Epoch[51] Batch [1000]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086862,	
2017-06-20 04:02:51,278 Epoch[51] Batch [1010]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.086880,	
2017-06-20 04:02:56,192 Epoch[51] Batch [1020]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.086898,	
2017-06-20 04:03:00,843 Epoch[51] Batch [1030]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086929,	
2017-06-20 04:03:05,370 Epoch[51] Batch [1040]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086941,	
2017-06-20 04:03:09,904 Epoch[51] Batch [1050]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.086918,	
2017-06-20 04:03:14,635 Epoch[51] Batch [1060]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.086938,	
2017-06-20 04:03:19,284 Epoch[51] Batch [1070]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086957,	
2017-06-20 04:03:24,014 Epoch[51] Batch [1080]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087041,	
2017-06-20 04:03:28,810 Epoch[51] Batch [1090]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.087030,	
2017-06-20 04:03:33,323 Epoch[51] Batch [1100]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087067,	
2017-06-20 04:03:37,672 Epoch[51] Batch [1110]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087160,	
2017-06-20 04:03:42,394 Epoch[51] Batch [1120]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.087121,	
2017-06-20 04:03:47,177 Epoch[51] Batch [1130]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.087167,	
2017-06-20 04:03:51,927 Epoch[51] Batch [1140]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087174,	
2017-06-20 04:03:56,235 Epoch[51] Batch [1150]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087108,	
2017-06-20 04:04:00,909 Epoch[51] Batch [1160]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087059,	
2017-06-20 04:04:05,523 Epoch[51] Batch [1170]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087038,	
2017-06-20 04:04:10,080 Epoch[51] Batch [1180]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087009,	
2017-06-20 04:04:14,857 Epoch[51] Batch [1190]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086980,	
2017-06-20 04:04:19,671 Epoch[51] Batch [1200]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087005,	
2017-06-20 04:04:24,502 Epoch[51] Batch [1210]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.086982,	
2017-06-20 04:04:29,379 Epoch[51] Batch [1220]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.086963,	
2017-06-20 04:04:34,073 Epoch[51] Batch [1230]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087039,	
2017-06-20 04:04:38,699 Epoch[51] Batch [1240]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.087025,	
2017-06-20 04:04:43,209 Epoch[51] Batch [1250]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087113,	
2017-06-20 04:04:47,647 Epoch[51] Batch [1260]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.087179,	
2017-06-20 04:04:51,682 Epoch[51] Batch [1270]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.087195,	
2017-06-20 04:04:56,220 Epoch[51] Batch [1280]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087240,	
2017-06-20 04:05:01,101 Epoch[51] Batch [1290]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.087202,	
2017-06-20 04:05:05,989 Epoch[51] Batch [1300]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.087189,	
2017-06-20 04:05:10,440 Epoch[51] Batch [1310]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087187,	
2017-06-20 04:05:15,352 Epoch[51] Batch [1320]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.087227,	
2017-06-20 04:05:20,145 Epoch[51] Batch [1330]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087245,	
2017-06-20 04:05:24,646 Epoch[51] Batch [1340]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087224,	
2017-06-20 04:05:29,199 Epoch[51] Batch [1350]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.087079,	
2017-06-20 04:05:33,675 Epoch[51] Batch [1360]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.087116,	
2017-06-20 04:05:38,273 Epoch[51] Batch [1370]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087096,	
2017-06-20 04:05:42,961 Epoch[51] Batch [1380]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087093,	
2017-06-20 04:05:47,775 Epoch[51] Batch [1390]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087057,	
2017-06-20 04:05:52,449 Epoch[51] Batch [1400]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087006,	
2017-06-20 04:05:57,287 Epoch[51] Batch [1410]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.087110,	
2017-06-20 04:06:02,078 Epoch[51] Batch [1420]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087168,	
2017-06-20 04:06:06,894 Epoch[51] Batch [1430]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.087232,	
2017-06-20 04:06:11,597 Epoch[51] Batch [1440]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087264,	
2017-06-20 04:06:15,977 Epoch[51] Batch [1450]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.087268,	
2017-06-20 04:06:20,079 Epoch[51] Batch [1460]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.087264,	
2017-06-20 04:06:24,657 Epoch[51] Batch [1470]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087308,	
2017-06-20 04:06:29,351 Epoch[51] Batch [1480]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087310,	
2017-06-20 04:06:32,154 Epoch[51] Train-FCNLogLoss=0.087303
2017-06-20 04:06:32,154 Epoch[51] Time cost=687.451
2017-06-20 04:06:32,954 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0052.params"
2017-06-20 04:06:34,654 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0052.states"
2017-06-20 04:06:39,748 Epoch[52] Batch [10]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.092527,	
2017-06-20 04:06:44,013 Epoch[52] Batch [20]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.089466,	
2017-06-20 04:06:48,587 Epoch[52] Batch [30]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089236,	
2017-06-20 04:06:52,965 Epoch[52] Batch [40]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.089778,	
2017-06-20 04:06:57,332 Epoch[52] Batch [50]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.089293,	
2017-06-20 04:07:01,902 Epoch[52] Batch [60]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.089627,	
2017-06-20 04:07:06,368 Epoch[52] Batch [70]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.089179,	
2017-06-20 04:07:11,064 Epoch[52] Batch [80]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088353,	
2017-06-20 04:07:15,668 Epoch[52] Batch [90]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088520,	
2017-06-20 04:07:20,427 Epoch[52] Batch [100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087588,	
2017-06-20 04:07:25,176 Epoch[52] Batch [110]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087441,	
2017-06-20 04:07:29,997 Epoch[52] Batch [120]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.087260,	
2017-06-20 04:07:34,786 Epoch[52] Batch [130]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.086617,	
2017-06-20 04:07:39,431 Epoch[52] Batch [140]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.086292,	
2017-06-20 04:07:44,368 Epoch[52] Batch [150]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086376,	
2017-06-20 04:07:49,069 Epoch[52] Batch [160]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.086143,	
2017-06-20 04:07:53,879 Epoch[52] Batch [170]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.086659,	
2017-06-20 04:07:58,918 Epoch[52] Batch [180]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.086665,	
2017-06-20 04:08:03,702 Epoch[52] Batch [190]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-20 04:08:08,699 Epoch[52] Batch [200]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086647,	
2017-06-20 04:08:13,598 Epoch[52] Batch [210]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086496,	
2017-06-20 04:08:18,412 Epoch[52] Batch [220]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.086648,	
2017-06-20 04:08:22,916 Epoch[52] Batch [230]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.086730,	
2017-06-20 04:08:27,472 Epoch[52] Batch [240]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.086637,	
2017-06-20 04:08:32,323 Epoch[52] Batch [250]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086633,	
2017-06-20 04:08:36,857 Epoch[52] Batch [260]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087054,	
2017-06-20 04:08:41,374 Epoch[52] Batch [270]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.086759,	
2017-06-20 04:08:45,863 Epoch[52] Batch [280]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.086885,	
2017-06-20 04:08:50,134 Epoch[52] Batch [290]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.086848,	
2017-06-20 04:08:54,945 Epoch[52] Batch [300]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.087141,	
2017-06-20 04:08:59,562 Epoch[52] Batch [310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087189,	
2017-06-20 04:09:04,065 Epoch[52] Batch [320]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087238,	
2017-06-20 04:09:08,899 Epoch[52] Batch [330]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.087224,	
2017-06-20 04:09:13,303 Epoch[52] Batch [340]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087152,	
2017-06-20 04:09:17,786 Epoch[52] Batch [350]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087131,	
2017-06-20 04:09:22,511 Epoch[52] Batch [360]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.086940,	
2017-06-20 04:09:27,123 Epoch[52] Batch [370]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087174,	
2017-06-20 04:09:31,858 Epoch[52] Batch [380]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.087155,	
2017-06-20 04:09:36,410 Epoch[52] Batch [390]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.087143,	
2017-06-20 04:09:40,966 Epoch[52] Batch [400]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087214,	
2017-06-20 04:09:45,559 Epoch[52] Batch [410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.087022,	
2017-06-20 04:09:50,028 Epoch[52] Batch [420]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086920,	
2017-06-20 04:09:54,855 Epoch[52] Batch [430]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086814,	
2017-06-20 04:09:59,509 Epoch[52] Batch [440]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.086673,	
2017-06-20 04:10:04,000 Epoch[52] Batch [450]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.086730,	
2017-06-20 04:10:08,604 Epoch[52] Batch [460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.086754,	
2017-06-20 04:10:13,240 Epoch[52] Batch [470]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086627,	
2017-06-20 04:10:18,162 Epoch[52] Batch [480]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.086744,	
2017-06-20 04:10:22,779 Epoch[52] Batch [490]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.086891,	
2017-06-20 04:10:27,038 Epoch[52] Batch [500]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086923,	
2017-06-20 04:10:31,442 Epoch[52] Batch [510]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.086893,	
2017-06-20 04:10:36,300 Epoch[52] Batch [520]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.086808,	
2017-06-20 04:10:40,896 Epoch[52] Batch [530]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.086788,	
2017-06-20 04:10:45,334 Epoch[52] Batch [540]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.086827,	
2017-06-20 04:10:49,560 Epoch[52] Batch [550]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.086805,	
2017-06-20 04:10:54,133 Epoch[52] Batch [560]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.086795,	
2017-06-20 04:10:58,701 Epoch[52] Batch [570]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.086853,	
2017-06-20 04:11:03,295 Epoch[52] Batch [580]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.086883,	
2017-06-20 04:11:08,091 Epoch[52] Batch [590]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086783,	
2017-06-20 04:11:12,722 Epoch[52] Batch [600]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.086824,	
2017-06-20 04:11:17,078 Epoch[52] Batch [610]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.086732,	
2017-06-20 04:11:21,477 Epoch[52] Batch [620]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.086529,	
2017-06-20 04:11:26,198 Epoch[52] Batch [630]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.086570,	
2017-06-20 04:11:30,876 Epoch[52] Batch [640]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.086484,	
2017-06-20 04:11:35,753 Epoch[52] Batch [650]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.086451,	
2017-06-20 04:11:40,481 Epoch[52] Batch [660]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.086310,	
2017-06-20 04:11:44,986 Epoch[52] Batch [670]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.086282,	
2017-06-20 04:11:49,655 Epoch[52] Batch [680]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.086388,	
2017-06-20 04:11:54,060 Epoch[52] Batch [690]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.086378,	
2017-06-20 04:11:58,916 Epoch[52] Batch [700]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086477,	
2017-06-20 04:12:03,456 Epoch[52] Batch [710]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.086411,	
2017-06-20 04:12:08,199 Epoch[52] Batch [720]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.086477,	
2017-06-20 04:12:12,801 Epoch[52] Batch [730]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.086539,	
2017-06-20 04:12:17,576 Epoch[52] Batch [740]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.086575,	
2017-06-20 04:12:22,209 Epoch[52] Batch [750]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086543,	
2017-06-20 04:12:26,397 Epoch[52] Batch [760]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.086513,	
2017-06-20 04:12:31,049 Epoch[52] Batch [770]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086550,	
2017-06-20 04:12:35,516 Epoch[52] Batch [780]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086448,	
2017-06-20 04:12:39,842 Epoch[52] Batch [790]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.086465,	
2017-06-20 04:12:44,299 Epoch[52] Batch [800]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.086558,	
2017-06-20 04:12:49,173 Epoch[52] Batch [810]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086620,	
2017-06-20 04:12:53,653 Epoch[52] Batch [820]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086589,	
2017-06-20 04:12:58,437 Epoch[52] Batch [830]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086783,	
2017-06-20 04:13:03,011 Epoch[52] Batch [840]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.086818,	
2017-06-20 04:13:07,674 Epoch[52] Batch [850]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.086735,	
2017-06-20 04:13:12,314 Epoch[52] Batch [860]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086788,	
2017-06-20 04:13:16,702 Epoch[52] Batch [870]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086686,	
2017-06-20 04:13:21,417 Epoch[52] Batch [880]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.086781,	
2017-06-20 04:13:26,010 Epoch[52] Batch [890]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.086731,	
2017-06-20 04:13:30,729 Epoch[52] Batch [900]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.086707,	
2017-06-20 04:13:35,333 Epoch[52] Batch [910]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.086732,	
2017-06-20 04:13:39,867 Epoch[52] Batch [920]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.086653,	
2017-06-20 04:13:44,567 Epoch[52] Batch [930]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.086655,	
2017-06-20 04:13:49,377 Epoch[52] Batch [940]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.086650,	
2017-06-20 04:13:53,801 Epoch[52] Batch [950]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.086606,	
2017-06-20 04:13:58,677 Epoch[52] Batch [960]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.086643,	
2017-06-20 04:14:03,044 Epoch[52] Batch [970]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.086578,	
2017-06-20 04:14:07,532 Epoch[52] Batch [980]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.086486,	
2017-06-20 04:14:12,221 Epoch[52] Batch [990]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.086439,	
2017-06-20 04:14:17,246 Epoch[52] Batch [1000]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.086359,	
2017-06-20 04:14:21,862 Epoch[52] Batch [1010]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.086456,	
2017-06-20 04:14:26,915 Epoch[52] Batch [1020]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.086402,	
2017-06-20 04:14:31,548 Epoch[52] Batch [1030]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086446,	
2017-06-20 04:14:36,190 Epoch[52] Batch [1040]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086490,	
2017-06-20 04:14:40,806 Epoch[52] Batch [1050]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.086493,	
2017-06-20 04:14:45,123 Epoch[52] Batch [1060]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086446,	
2017-06-20 04:14:49,706 Epoch[52] Batch [1070]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.086417,	
2017-06-20 04:14:54,731 Epoch[52] Batch [1080]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.086407,	
2017-06-20 04:14:59,379 Epoch[52] Batch [1090]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.086510,	
2017-06-20 04:15:03,937 Epoch[52] Batch [1100]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.086435,	
2017-06-20 04:15:08,424 Epoch[52] Batch [1110]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086372,	
2017-06-20 04:15:12,926 Epoch[52] Batch [1120]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.086431,	
2017-06-20 04:15:17,395 Epoch[52] Batch [1130]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086397,	
2017-06-20 04:15:21,849 Epoch[52] Batch [1140]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.086357,	
2017-06-20 04:15:26,467 Epoch[52] Batch [1150]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.086360,	
2017-06-20 04:15:30,704 Epoch[52] Batch [1160]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.086431,	
2017-06-20 04:15:35,393 Epoch[52] Batch [1170]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.086465,	
2017-06-20 04:15:39,998 Epoch[52] Batch [1180]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.086494,	
2017-06-20 04:15:44,809 Epoch[52] Batch [1190]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.086570,	
2017-06-20 04:15:49,358 Epoch[52] Batch [1200]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086550,	
2017-06-20 04:15:54,097 Epoch[52] Batch [1210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.086595,	
2017-06-20 04:15:58,682 Epoch[52] Batch [1220]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.086667,	
2017-06-20 04:16:03,318 Epoch[52] Batch [1230]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086716,	
2017-06-20 04:16:07,845 Epoch[52] Batch [1240]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086712,	
2017-06-20 04:16:12,212 Epoch[52] Batch [1250]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.086737,	
2017-06-20 04:16:16,827 Epoch[52] Batch [1260]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.086823,	
2017-06-20 04:16:21,622 Epoch[52] Batch [1270]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086752,	
2017-06-20 04:16:26,388 Epoch[52] Batch [1280]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.086742,	
2017-06-20 04:16:30,860 Epoch[52] Batch [1290]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086790,	
2017-06-20 04:16:35,478 Epoch[52] Batch [1300]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.086757,	
2017-06-20 04:16:39,962 Epoch[52] Batch [1310]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086805,	
2017-06-20 04:16:44,302 Epoch[52] Batch [1320]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.086844,	
2017-06-20 04:16:48,774 Epoch[52] Batch [1330]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086918,	
2017-06-20 04:16:53,422 Epoch[52] Batch [1340]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087007,	
2017-06-20 04:16:58,017 Epoch[52] Batch [1350]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.086997,	
2017-06-20 04:17:02,593 Epoch[52] Batch [1360]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.087104,	
2017-06-20 04:17:07,110 Epoch[52] Batch [1370]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.087127,	
2017-06-20 04:17:11,821 Epoch[52] Batch [1380]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087203,	
2017-06-20 04:17:16,513 Epoch[52] Batch [1390]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087153,	
2017-06-20 04:17:20,963 Epoch[52] Batch [1400]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087169,	
2017-06-20 04:17:25,591 Epoch[52] Batch [1410]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087221,	
2017-06-20 04:17:30,145 Epoch[52] Batch [1420]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087175,	
2017-06-20 04:17:34,848 Epoch[52] Batch [1430]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087180,	
2017-06-20 04:17:39,491 Epoch[52] Batch [1440]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087200,	
2017-06-20 04:17:43,760 Epoch[52] Batch [1450]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.087147,	
2017-06-20 04:17:48,508 Epoch[52] Batch [1460]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087151,	
2017-06-20 04:17:52,878 Epoch[52] Batch [1470]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087226,	
2017-06-20 04:17:57,355 Epoch[52] Batch [1480]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087224,	
2017-06-20 04:18:00,226 Epoch[52] Train-FCNLogLoss=0.087274
2017-06-20 04:18:00,226 Epoch[52] Time cost=685.572
2017-06-20 04:18:01,077 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0053.params"
2017-06-20 04:18:02,765 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3-0053.states"
2017-06-20 04:18:02,774 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_dilatedoffset3x3',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn_dilatedoffset3x3'}

2017-06-20 04:18:57,983 testing 4/500 data 0.6507s net 0.3266s post 0.0117s
2017-06-20 04:18:58,632 testing 8/500 data 0.5183s net 0.2889s post 0.0118s
2017-06-20 04:18:59,338 testing 12/500 data 0.4954s net 0.2758s post 0.0102s
2017-06-20 04:18:59,919 testing 16/500 data 0.4533s net 0.2687s post 0.0094s
2017-06-20 04:19:00,651 testing 20/500 data 0.4571s net 0.2653s post 0.0090s
2017-06-20 04:19:01,403 testing 24/500 data 0.4629s net 0.2625s post 0.0095s
2017-06-20 04:19:02,020 testing 28/500 data 0.4483s net 0.2605s post 0.0092s
2017-06-20 04:19:02,595 testing 32/500 data 0.4320s net 0.2586s post 0.0095s
2017-06-20 04:19:03,299 testing 36/500 data 0.4337s net 0.2577s post 0.0093s
2017-06-20 04:19:04,034 testing 40/500 data 0.4380s net 0.2567s post 0.0094s
2017-06-20 04:19:04,720 testing 44/500 data 0.4370s net 0.2558s post 0.0096s
2017-06-20 04:19:05,314 testing 48/500 data 0.4287s net 0.2553s post 0.0094s
2017-06-20 04:19:05,901 testing 52/500 data 0.4212s net 0.2547s post 0.0092s
2017-06-20 04:19:06,513 testing 56/500 data 0.4166s net 0.2543s post 0.0090s
2017-06-20 04:19:07,177 testing 60/500 data 0.4162s net 0.2539s post 0.0089s
2017-06-20 04:19:07,771 testing 64/500 data 0.4109s net 0.2536s post 0.0091s
2017-06-20 04:19:08,363 testing 68/500 data 0.4066s net 0.2533s post 0.0089s
2017-06-20 04:19:09,076 testing 72/500 data 0.4094s net 0.2530s post 0.0088s
2017-06-20 04:19:09,695 testing 76/500 data 0.4068s net 0.2527s post 0.0090s
2017-06-20 04:19:10,366 testing 80/500 data 0.4073s net 0.2524s post 0.0089s
2017-06-20 04:19:11,058 testing 84/500 data 0.4084s net 0.2522s post 0.0090s
2017-06-20 04:19:11,717 testing 88/500 data 0.4082s net 0.2520s post 0.0090s
2017-06-20 04:19:12,444 testing 92/500 data 0.4108s net 0.2519s post 0.0091s
2017-06-20 04:19:13,079 testing 96/500 data 0.4096s net 0.2516s post 0.0090s
2017-06-20 04:19:13,743 testing 100/500 data 0.4096s net 0.2515s post 0.0089s
2017-06-20 04:19:14,465 testing 104/500 data 0.4117s net 0.2514s post 0.0089s
2017-06-20 04:19:15,058 testing 108/500 data 0.4090s net 0.2513s post 0.0088s
2017-06-20 04:19:15,611 testing 112/500 data 0.4050s net 0.2512s post 0.0087s
2017-06-20 04:19:16,159 testing 116/500 data 0.4011s net 0.2510s post 0.0087s
2017-06-20 04:19:16,850 testing 120/500 data 0.4021s net 0.2510s post 0.0087s
2017-06-20 04:19:17,531 testing 124/500 data 0.4029s net 0.2509s post 0.0087s
2017-06-20 04:19:18,230 testing 128/500 data 0.4041s net 0.2509s post 0.0087s
2017-06-20 04:19:18,805 testing 132/500 data 0.4015s net 0.2508s post 0.0087s
2017-06-20 04:19:19,488 testing 136/500 data 0.4022s net 0.2507s post 0.0087s
2017-06-20 04:19:20,208 testing 140/500 data 0.4038s net 0.2507s post 0.0087s
2017-06-20 04:19:20,924 testing 144/500 data 0.4054s net 0.2507s post 0.0087s
2017-06-20 04:19:21,620 testing 148/500 data 0.4063s net 0.2505s post 0.0088s
2017-06-20 04:19:22,355 testing 152/500 data 0.4081s net 0.2505s post 0.0088s
2017-06-20 04:19:23,007 testing 156/500 data 0.4077s net 0.2505s post 0.0088s
2017-06-20 04:19:23,555 testing 160/500 data 0.4049s net 0.2504s post 0.0088s
2017-06-20 04:19:24,257 testing 164/500 data 0.4058s net 0.2503s post 0.0088s
2017-06-20 04:19:24,940 testing 168/500 data 0.4063s net 0.2503s post 0.0088s
2017-06-20 04:19:25,704 testing 172/500 data 0.4085s net 0.2503s post 0.0089s
2017-06-20 04:19:26,425 testing 176/500 data 0.4097s net 0.2503s post 0.0089s
2017-06-20 04:19:27,045 testing 180/500 data 0.4087s net 0.2502s post 0.0089s
2017-06-20 04:19:27,762 testing 184/500 data 0.4098s net 0.2502s post 0.0089s
2017-06-20 04:19:28,416 testing 188/500 data 0.4096s net 0.2502s post 0.0088s
2017-06-20 04:19:29,133 testing 192/500 data 0.4105s net 0.2502s post 0.0089s
2017-06-20 04:19:29,829 testing 196/500 data 0.4111s net 0.2502s post 0.0088s
2017-06-20 04:19:30,595 testing 200/500 data 0.4129s net 0.2502s post 0.0089s
2017-06-20 04:19:31,353 testing 204/500 data 0.4146s net 0.2502s post 0.0089s
2017-06-20 04:19:32,121 testing 208/500 data 0.4163s net 0.2502s post 0.0090s
2017-06-20 04:19:32,799 testing 212/500 data 0.4163s net 0.2502s post 0.0091s
2017-06-20 04:19:33,530 testing 216/500 data 0.4173s net 0.2501s post 0.0091s
2017-06-20 04:19:34,267 testing 220/500 data 0.4185s net 0.2501s post 0.0091s
2017-06-20 04:19:34,977 testing 224/500 data 0.4191s net 0.2501s post 0.0091s
2017-06-20 04:19:35,603 testing 228/500 data 0.4181s net 0.2501s post 0.0091s
2017-06-20 04:19:36,271 testing 232/500 data 0.4179s net 0.2501s post 0.0092s
2017-06-20 04:19:36,870 testing 236/500 data 0.4167s net 0.2500s post 0.0091s
2017-06-20 04:19:37,606 testing 240/500 data 0.4177s net 0.2501s post 0.0091s
2017-06-20 04:19:38,245 testing 244/500 data 0.4171s net 0.2500s post 0.0091s
2017-06-20 04:19:38,803 testing 248/500 data 0.4153s net 0.2500s post 0.0091s
2017-06-20 04:19:39,379 testing 252/500 data 0.4137s net 0.2499s post 0.0092s
2017-06-20 04:19:40,021 testing 256/500 data 0.4133s net 0.2499s post 0.0091s
2017-06-20 04:19:40,731 testing 260/500 data 0.4138s net 0.2499s post 0.0092s
2017-06-20 04:19:41,296 testing 264/500 data 0.4121s net 0.2500s post 0.0092s
2017-06-20 04:19:42,046 testing 268/500 data 0.4132s net 0.2500s post 0.0092s
2017-06-20 04:19:42,742 testing 272/500 data 0.4136s net 0.2500s post 0.0092s
2017-06-20 04:19:43,333 testing 276/500 data 0.4124s net 0.2500s post 0.0092s
2017-06-20 04:19:43,890 testing 280/500 data 0.4108s net 0.2500s post 0.0092s
2017-06-20 04:19:44,606 testing 284/500 data 0.4114s net 0.2500s post 0.0093s
2017-06-20 04:19:45,257 testing 288/500 data 0.4112s net 0.2499s post 0.0092s
2017-06-20 04:19:45,968 testing 292/500 data 0.4116s net 0.2500s post 0.0093s
2017-06-20 04:19:46,682 testing 296/500 data 0.4122s net 0.2500s post 0.0093s
2017-06-20 04:19:47,257 testing 300/500 data 0.4109s net 0.2500s post 0.0093s
2017-06-20 04:19:47,837 testing 304/500 data 0.4097s net 0.2500s post 0.0093s
2017-06-20 04:19:48,393 testing 308/500 data 0.4082s net 0.2500s post 0.0093s
2017-06-20 04:19:49,023 testing 312/500 data 0.4078s net 0.2500s post 0.0093s
2017-06-20 04:19:49,656 testing 316/500 data 0.4073s net 0.2500s post 0.0093s
2017-06-20 04:19:50,233 testing 320/500 data 0.4063s net 0.2500s post 0.0093s
2017-06-20 04:19:50,955 testing 324/500 data 0.4069s net 0.2499s post 0.0093s
2017-06-20 04:19:51,702 testing 328/500 data 0.4079s net 0.2500s post 0.0093s
2017-06-20 04:19:52,331 testing 332/500 data 0.4074s net 0.2500s post 0.0093s
2017-06-20 04:19:53,033 testing 336/500 data 0.4078s net 0.2500s post 0.0093s
2017-06-20 04:19:53,835 testing 340/500 data 0.4094s net 0.2500s post 0.0093s
2017-06-20 04:19:54,529 testing 344/500 data 0.4097s net 0.2500s post 0.0094s
2017-06-20 04:19:55,096 testing 348/500 data 0.4085s net 0.2499s post 0.0094s
2017-06-20 04:19:55,661 testing 352/500 data 0.4073s net 0.2499s post 0.0094s
2017-06-20 04:19:56,234 testing 356/500 data 0.4062s net 0.2499s post 0.0094s
2017-06-20 04:19:56,792 testing 360/500 data 0.4051s net 0.2499s post 0.0094s
2017-06-20 04:19:57,546 testing 364/500 data 0.4060s net 0.2499s post 0.0094s
2017-06-20 04:19:58,272 testing 368/500 data 0.4067s net 0.2499s post 0.0094s
2017-06-20 04:19:59,006 testing 372/500 data 0.4074s net 0.2499s post 0.0094s
2017-06-20 04:19:59,739 testing 376/500 data 0.4081s net 0.2500s post 0.0094s
2017-06-20 04:20:00,408 testing 380/500 data 0.4081s net 0.2500s post 0.0095s
2017-06-20 04:20:01,164 testing 384/500 data 0.4090s net 0.2500s post 0.0094s
2017-06-20 04:20:01,807 testing 388/500 data 0.4088s net 0.2500s post 0.0095s
2017-06-20 04:20:02,460 testing 392/500 data 0.4086s net 0.2500s post 0.0094s
2017-06-20 04:20:03,235 testing 396/500 data 0.4097s net 0.2500s post 0.0095s
2017-06-20 04:20:03,976 testing 400/500 data 0.4104s net 0.2500s post 0.0094s
2017-06-20 04:20:04,619 testing 404/500 data 0.4101s net 0.2500s post 0.0095s
2017-06-20 04:20:05,321 testing 408/500 data 0.4105s net 0.2500s post 0.0094s
2017-06-20 04:20:06,016 testing 412/500 data 0.4107s net 0.2500s post 0.0095s
2017-06-20 04:20:06,762 testing 416/500 data 0.4114s net 0.2500s post 0.0094s
2017-06-20 04:20:07,364 testing 420/500 data 0.4108s net 0.2500s post 0.0095s
2017-06-20 04:20:07,935 testing 424/500 data 0.4098s net 0.2500s post 0.0094s
2017-06-20 04:20:08,639 testing 428/500 data 0.4101s net 0.2500s post 0.0095s
2017-06-20 04:20:09,375 testing 432/500 data 0.4107s net 0.2500s post 0.0094s
2017-06-20 04:20:10,071 testing 436/500 data 0.4110s net 0.2500s post 0.0094s
2017-06-20 04:20:10,803 testing 440/500 data 0.4116s net 0.2500s post 0.0094s
2017-06-20 04:20:11,401 testing 444/500 data 0.4109s net 0.2500s post 0.0094s
2017-06-20 04:20:11,972 testing 448/500 data 0.4101s net 0.2500s post 0.0094s
2017-06-20 04:20:12,678 testing 452/500 data 0.4103s net 0.2500s post 0.0094s
2017-06-20 04:20:13,362 testing 456/500 data 0.4105s net 0.2500s post 0.0094s
2017-06-20 04:20:14,091 testing 460/500 data 0.4110s net 0.2501s post 0.0094s
2017-06-20 04:20:14,770 testing 464/500 data 0.4111s net 0.2501s post 0.0094s
2017-06-20 04:20:15,346 testing 468/500 data 0.4102s net 0.2501s post 0.0094s
2017-06-20 04:20:16,096 testing 472/500 data 0.4109s net 0.2501s post 0.0094s
2017-06-20 04:20:16,883 testing 476/500 data 0.4119s net 0.2501s post 0.0094s
2017-06-20 04:20:17,680 testing 480/500 data 0.4129s net 0.2501s post 0.0094s
2017-06-20 04:20:18,366 testing 484/500 data 0.4130s net 0.2501s post 0.0094s
2017-06-20 04:20:19,070 testing 488/500 data 0.4132s net 0.2501s post 0.0094s
2017-06-20 04:20:19,813 testing 492/500 data 0.4138s net 0.2501s post 0.0094s
2017-06-20 04:20:20,519 testing 496/500 data 0.4141s net 0.2501s post 0.0094s
2017-06-20 04:20:21,109 testing 500/500 data 0.4134s net 0.2501s post 0.0094s
2017-06-20 04:22:02,530 evaluate segmentation: 

2017-06-20 04:22:02,530 IU_array:

2017-06-20 04:22:02,530 0.98032
2017-06-20 04:22:02,530 0.83953
2017-06-20 04:22:02,531 0.91558
2017-06-20 04:22:02,531 0.57276
2017-06-20 04:22:02,531 0.57283
2017-06-20 04:22:02,531 0.54249
2017-06-20 04:22:02,531 0.63924
2017-06-20 04:22:02,531 0.73182
2017-06-20 04:22:02,531 0.91419
2017-06-20 04:22:02,531 0.63004
2017-06-20 04:22:02,531 0.93594
2017-06-20 04:22:02,531 0.78199
2017-06-20 04:22:02,531 0.58692
2017-06-20 04:22:02,531 0.93676
2017-06-20 04:22:02,531 0.63947
2017-06-20 04:22:02,531 0.85904
2017-06-20 04:22:02,531 0.70135
2017-06-20 04:22:02,531 0.63681
2017-06-20 04:22:02,531 0.74371
2017-06-20 04:22:02,531 meanIU:0.74531

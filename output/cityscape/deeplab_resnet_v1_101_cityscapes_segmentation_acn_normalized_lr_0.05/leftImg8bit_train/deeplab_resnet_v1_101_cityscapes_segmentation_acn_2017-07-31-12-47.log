2017-07-31 12:47:30,147 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-31 12:48:37,406 Epoch[0] Batch [10]	Speed: 3.71 samples/sec	Train-FCNLogLoss=2.890072,	
2017-07-31 12:48:48,983 Epoch[0] Batch [20]	Speed: 3.46 samples/sec	Train-FCNLogLoss=2.769619,	
2017-07-31 12:48:56,406 Epoch[0] Batch [30]	Speed: 5.39 samples/sec	Train-FCNLogLoss=2.553733,	
2017-07-31 12:49:02,582 Epoch[0] Batch [40]	Speed: 6.48 samples/sec	Train-FCNLogLoss=2.345018,	
2017-07-31 12:49:06,923 Epoch[0] Batch [50]	Speed: 9.22 samples/sec	Train-FCNLogLoss=2.139393,	
2017-07-31 12:49:10,906 Epoch[0] Batch [60]	Speed: 10.04 samples/sec	Train-FCNLogLoss=1.964814,	
2017-07-31 12:49:15,085 Epoch[0] Batch [70]	Speed: 9.57 samples/sec	Train-FCNLogLoss=1.819690,	
2017-07-31 12:49:19,103 Epoch[0] Batch [80]	Speed: 9.96 samples/sec	Train-FCNLogLoss=1.693833,	
2017-07-31 12:49:23,119 Epoch[0] Batch [90]	Speed: 9.96 samples/sec	Train-FCNLogLoss=1.595791,	
2017-07-31 12:49:27,239 Epoch[0] Batch [100]	Speed: 9.71 samples/sec	Train-FCNLogLoss=1.507409,	
2017-07-31 12:49:31,433 Epoch[0] Batch [110]	Speed: 9.54 samples/sec	Train-FCNLogLoss=1.448721,	
2017-07-31 12:49:35,763 Epoch[0] Batch [120]	Speed: 9.24 samples/sec	Train-FCNLogLoss=1.379455,	
2017-07-31 12:49:39,702 Epoch[0] Batch [130]	Speed: 10.16 samples/sec	Train-FCNLogLoss=1.319089,	
2017-07-31 12:49:43,761 Epoch[0] Batch [140]	Speed: 9.86 samples/sec	Train-FCNLogLoss=1.264548,	
2017-07-31 12:49:47,810 Epoch[0] Batch [150]	Speed: 9.88 samples/sec	Train-FCNLogLoss=1.214986,	
2017-07-31 12:49:51,902 Epoch[0] Batch [160]	Speed: 9.78 samples/sec	Train-FCNLogLoss=1.177149,	
2017-07-31 12:49:55,989 Epoch[0] Batch [170]	Speed: 9.79 samples/sec	Train-FCNLogLoss=1.143116,	
2017-07-31 12:50:00,297 Epoch[0] Batch [180]	Speed: 9.29 samples/sec	Train-FCNLogLoss=1.113815,	
2017-07-31 12:50:04,459 Epoch[0] Batch [190]	Speed: 9.61 samples/sec	Train-FCNLogLoss=1.085813,	
2017-07-31 12:50:08,433 Epoch[0] Batch [200]	Speed: 10.07 samples/sec	Train-FCNLogLoss=1.056530,	
2017-07-31 12:50:12,750 Epoch[0] Batch [210]	Speed: 9.27 samples/sec	Train-FCNLogLoss=1.027729,	
2017-07-31 12:50:16,759 Epoch[0] Batch [220]	Speed: 9.98 samples/sec	Train-FCNLogLoss=1.004549,	
2017-07-31 12:50:20,964 Epoch[0] Batch [230]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.982253,	
2017-07-31 12:50:25,324 Epoch[0] Batch [240]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.960046,	
2017-07-31 12:50:29,540 Epoch[0] Batch [250]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.942387,	
2017-07-31 12:50:33,634 Epoch[0] Batch [260]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.924748,	
2017-07-31 12:50:37,828 Epoch[0] Batch [270]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.904167,	
2017-07-31 12:50:42,002 Epoch[0] Batch [280]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.890814,	
2017-07-31 12:50:45,989 Epoch[0] Batch [290]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.877816,	
2017-07-31 12:50:50,095 Epoch[0] Batch [300]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.862263,	
2017-07-31 12:50:54,003 Epoch[0] Batch [310]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.847829,	
2017-07-31 12:50:58,098 Epoch[0] Batch [320]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.836043,	
2017-07-31 12:51:02,243 Epoch[0] Batch [330]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.822584,	
2017-07-31 12:51:06,841 Epoch[0] Batch [340]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.809707,	
2017-07-31 12:51:10,864 Epoch[0] Batch [350]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.798847,	
2017-07-31 12:51:14,999 Epoch[0] Batch [360]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.788092,	
2017-07-31 12:51:19,212 Epoch[0] Batch [370]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.778369,	
2017-07-31 12:51:23,257 Epoch[0] Batch [380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.768447,	
2017-07-31 12:51:27,516 Epoch[0] Batch [390]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.756998,	
2017-07-31 12:51:31,695 Epoch[0] Batch [400]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.747608,	
2017-07-31 12:51:35,720 Epoch[0] Batch [410]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.739901,	
2017-07-31 12:51:39,886 Epoch[0] Batch [420]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.732658,	
2017-07-31 12:51:44,071 Epoch[0] Batch [430]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.728169,	
2017-07-31 12:51:48,301 Epoch[0] Batch [440]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.721023,	
2017-07-31 12:51:52,459 Epoch[0] Batch [450]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.714098,	
2017-07-31 12:51:56,519 Epoch[0] Batch [460]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.706912,	
2017-07-31 12:52:00,673 Epoch[0] Batch [470]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.700536,	
2017-07-31 12:52:04,698 Epoch[0] Batch [480]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.693586,	
2017-07-31 12:52:08,929 Epoch[0] Batch [490]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.687188,	
2017-07-31 12:52:13,135 Epoch[0] Batch [500]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.682937,	
2017-07-31 12:52:17,306 Epoch[0] Batch [510]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.677319,	
2017-07-31 12:52:21,577 Epoch[0] Batch [520]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.672159,	
2017-07-31 12:52:25,875 Epoch[0] Batch [530]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.666364,	
2017-07-31 12:52:30,397 Epoch[0] Batch [540]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.659949,	
2017-07-31 12:52:34,674 Epoch[0] Batch [550]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.655000,	
2017-07-31 12:52:39,448 Epoch[0] Batch [560]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.649878,	
2017-07-31 12:52:43,785 Epoch[0] Batch [570]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.645147,	
2017-07-31 12:52:48,588 Epoch[0] Batch [580]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.640736,	
2017-07-31 12:52:53,202 Epoch[0] Batch [590]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.634954,	
2017-07-31 12:52:57,791 Epoch[0] Batch [600]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.632471,	
2017-07-31 12:53:02,405 Epoch[0] Batch [610]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.628972,	
2017-07-31 12:53:07,735 Epoch[0] Batch [620]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.625146,	
2017-07-31 12:53:12,016 Epoch[0] Batch [630]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.620291,	
2017-07-31 12:53:16,403 Epoch[0] Batch [640]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.615399,	
2017-07-31 12:53:20,608 Epoch[0] Batch [650]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.612506,	
2017-07-31 12:53:24,945 Epoch[0] Batch [660]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.608098,	
2017-07-31 12:53:29,363 Epoch[0] Batch [670]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.603952,	
2017-07-31 12:53:33,885 Epoch[0] Batch [680]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.600267,	
2017-07-31 12:53:38,342 Epoch[0] Batch [690]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.597174,	
2017-07-31 12:53:43,154 Epoch[0] Batch [700]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.593784,	
2017-07-31 12:53:47,530 Epoch[0] Batch [710]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.589761,	
2017-07-31 12:53:51,960 Epoch[0] Batch [720]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.586673,	
2017-07-31 12:53:56,376 Epoch[0] Batch [730]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.582846,	
2017-07-31 12:54:00,887 Epoch[0] Batch [740]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.579323,	
2017-07-31 12:54:05,254 Epoch[0] Batch [750]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.576061,	
2017-07-31 12:54:09,823 Epoch[0] Batch [760]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.572917,	
2017-07-31 12:54:14,583 Epoch[0] Batch [770]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.570911,	
2017-07-31 12:54:19,042 Epoch[0] Batch [780]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.568158,	
2017-07-31 12:54:23,727 Epoch[0] Batch [790]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.565122,	
2017-07-31 12:54:28,555 Epoch[0] Batch [800]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.562173,	
2017-07-31 12:54:33,396 Epoch[0] Batch [810]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.559383,	
2017-07-31 12:54:38,060 Epoch[0] Batch [820]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.556320,	
2017-07-31 12:54:42,671 Epoch[0] Batch [830]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.553610,	
2017-07-31 12:54:47,023 Epoch[0] Batch [840]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.551692,	
2017-07-31 12:54:51,587 Epoch[0] Batch [850]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.549863,	
2017-07-31 12:54:56,291 Epoch[0] Batch [860]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.547237,	
2017-07-31 12:55:01,147 Epoch[0] Batch [870]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.544813,	
2017-07-31 12:55:05,894 Epoch[0] Batch [880]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.542674,	
2017-07-31 12:55:10,524 Epoch[0] Batch [890]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.540382,	
2017-07-31 12:55:15,298 Epoch[0] Batch [900]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.538700,	
2017-07-31 12:55:20,428 Epoch[0] Batch [910]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.536695,	
2017-07-31 12:55:25,075 Epoch[0] Batch [920]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.534916,	
2017-07-31 12:55:29,968 Epoch[0] Batch [930]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.532693,	
2017-07-31 12:55:34,643 Epoch[0] Batch [940]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.530297,	
2017-07-31 12:55:39,329 Epoch[0] Batch [950]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.528140,	
2017-07-31 12:55:44,104 Epoch[0] Batch [960]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.525621,	
2017-07-31 12:55:49,076 Epoch[0] Batch [970]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.522939,	
2017-07-31 12:55:54,078 Epoch[0] Batch [980]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.521133,	
2017-07-31 12:55:58,875 Epoch[0] Batch [990]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.519686,	
2017-07-31 12:56:03,687 Epoch[0] Batch [1000]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.517279,	
2017-07-31 12:56:08,019 Epoch[0] Batch [1010]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.516908,	
2017-07-31 12:56:12,584 Epoch[0] Batch [1020]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.517466,	
2017-07-31 12:56:17,448 Epoch[0] Batch [1030]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.519717,	
2017-07-31 12:56:22,275 Epoch[0] Batch [1040]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.520369,	
2017-07-31 12:56:27,184 Epoch[0] Batch [1050]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.520317,	
2017-07-31 12:56:31,760 Epoch[0] Batch [1060]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.519569,	
2017-07-31 12:56:36,126 Epoch[0] Batch [1070]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.518446,	
2017-07-31 12:56:40,121 Epoch[0] Batch [1080]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.517652,	
2017-07-31 12:56:44,107 Epoch[0] Batch [1090]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.517862,	
2017-07-31 12:56:48,094 Epoch[0] Batch [1100]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.516647,	
2017-07-31 12:56:52,094 Epoch[0] Batch [1110]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.515437,	
2017-07-31 12:56:56,302 Epoch[0] Batch [1120]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.513997,	
2017-07-31 12:57:00,340 Epoch[0] Batch [1130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.512820,	
2017-07-31 12:57:04,433 Epoch[0] Batch [1140]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.511738,	
2017-07-31 12:57:08,663 Epoch[0] Batch [1150]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.510346,	
2017-07-31 12:57:12,634 Epoch[0] Batch [1160]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.509814,	
2017-07-31 12:57:16,918 Epoch[0] Batch [1170]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.508629,	
2017-07-31 12:57:21,133 Epoch[0] Batch [1180]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.507274,	
2017-07-31 12:57:25,042 Epoch[0] Batch [1190]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.506267,	
2017-07-31 12:57:28,985 Epoch[0] Batch [1200]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.505136,	
2017-07-31 12:57:33,005 Epoch[0] Batch [1210]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.504289,	
2017-07-31 12:57:37,071 Epoch[0] Batch [1220]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.503331,	
2017-07-31 12:57:41,265 Epoch[0] Batch [1230]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.502798,	
2017-07-31 12:57:45,201 Epoch[0] Batch [1240]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.501874,	
2017-07-31 12:57:49,208 Epoch[0] Batch [1250]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.500885,	
2017-07-31 12:57:53,228 Epoch[0] Batch [1260]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.499580,	
2017-07-31 12:57:57,416 Epoch[0] Batch [1270]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.498343,	
2017-07-31 12:58:01,431 Epoch[0] Batch [1280]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.497167,	
2017-07-31 12:58:05,513 Epoch[0] Batch [1290]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.495519,	
2017-07-31 12:58:09,586 Epoch[0] Batch [1300]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.494775,	
2017-07-31 12:58:13,776 Epoch[0] Batch [1310]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.493923,	
2017-07-31 12:58:17,855 Epoch[0] Batch [1320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.492632,	
2017-07-31 12:58:21,846 Epoch[0] Batch [1330]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.491205,	
2017-07-31 12:58:25,871 Epoch[0] Batch [1340]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.489974,	
2017-07-31 12:58:29,896 Epoch[0] Batch [1350]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.488820,	
2017-07-31 12:58:33,839 Epoch[0] Batch [1360]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.487728,	
2017-07-31 12:58:38,057 Epoch[0] Batch [1370]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.486298,	
2017-07-31 12:58:42,185 Epoch[0] Batch [1380]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.484672,	
2017-07-31 12:58:46,317 Epoch[0] Batch [1390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.483024,	
2017-07-31 12:58:51,007 Epoch[0] Batch [1400]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.481527,	
2017-07-31 12:58:55,135 Epoch[0] Batch [1410]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.480408,	
2017-07-31 12:58:59,411 Epoch[0] Batch [1420]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.479109,	
2017-07-31 12:59:03,419 Epoch[0] Batch [1430]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.478359,	
2017-07-31 12:59:07,345 Epoch[0] Batch [1440]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.477608,	
2017-07-31 12:59:11,512 Epoch[0] Batch [1450]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.476930,	
2017-07-31 12:59:15,683 Epoch[0] Batch [1460]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.475835,	
2017-07-31 12:59:19,713 Epoch[0] Batch [1470]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.474828,	
2017-07-31 12:59:23,794 Epoch[0] Batch [1480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.473764,	
2017-07-31 12:59:26,308 Epoch[0] Train-FCNLogLoss=0.473090
2017-07-31 12:59:26,308 Epoch[0] Time cost=671.506
2017-07-31 12:59:27,473 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-31 12:59:31,947 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-31 12:59:36,725 Epoch[1] Batch [10]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.297021,	
2017-07-31 12:59:40,492 Epoch[1] Batch [20]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.301090,	
2017-07-31 12:59:44,330 Epoch[1] Batch [30]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.302048,	
2017-07-31 12:59:48,064 Epoch[1] Batch [40]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.316774,	
2017-07-31 12:59:51,790 Epoch[1] Batch [50]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.321139,	
2017-07-31 12:59:55,475 Epoch[1] Batch [60]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.316174,	
2017-07-31 12:59:59,211 Epoch[1] Batch [70]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.311938,	
2017-07-31 13:00:02,977 Epoch[1] Batch [80]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.305962,	
2017-07-31 13:00:07,745 Epoch[1] Batch [90]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.312880,	
2017-07-31 13:00:11,464 Epoch[1] Batch [100]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.315651,	
2017-07-31 13:00:15,325 Epoch[1] Batch [110]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.314522,	
2017-07-31 13:00:21,144 Epoch[1] Batch [120]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.314269,	
2017-07-31 13:00:25,165 Epoch[1] Batch [130]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.313898,	
2017-07-31 13:00:28,961 Epoch[1] Batch [140]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.309081,	
2017-07-31 13:00:32,815 Epoch[1] Batch [150]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.306480,	
2017-07-31 13:00:36,579 Epoch[1] Batch [160]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.302447,	
2017-07-31 13:00:40,371 Epoch[1] Batch [170]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.303142,	
2017-07-31 13:00:44,203 Epoch[1] Batch [180]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.301614,	
2017-07-31 13:00:48,239 Epoch[1] Batch [190]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.305019,	
2017-07-31 13:00:52,156 Epoch[1] Batch [200]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.303613,	
2017-07-31 13:00:55,970 Epoch[1] Batch [210]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.302864,	
2017-07-31 13:00:59,723 Epoch[1] Batch [220]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.300247,	
2017-07-31 13:01:03,524 Epoch[1] Batch [230]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.299295,	
2017-07-31 13:01:07,365 Epoch[1] Batch [240]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.299545,	
2017-07-31 13:01:11,124 Epoch[1] Batch [250]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.301592,	
2017-07-31 13:01:15,438 Epoch[1] Batch [260]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.304109,	
2017-07-31 13:01:19,464 Epoch[1] Batch [270]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.306043,	
2017-07-31 13:01:23,494 Epoch[1] Batch [280]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.306786,	
2017-07-31 13:01:27,466 Epoch[1] Batch [290]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.307201,	
2017-07-31 13:01:31,514 Epoch[1] Batch [300]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.305386,	
2017-07-31 13:01:35,428 Epoch[1] Batch [310]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.305186,	
2017-07-31 13:01:39,555 Epoch[1] Batch [320]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.305264,	
2017-07-31 13:01:43,634 Epoch[1] Batch [330]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.305458,	
2017-07-31 13:01:47,786 Epoch[1] Batch [340]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.304404,	
2017-07-31 13:01:52,042 Epoch[1] Batch [350]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.303854,	
2017-07-31 13:01:55,838 Epoch[1] Batch [360]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.302957,	
2017-07-31 13:01:59,664 Epoch[1] Batch [370]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.302081,	
2017-07-31 13:02:04,598 Epoch[1] Batch [380]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.302078,	
2017-07-31 13:02:08,729 Epoch[1] Batch [390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.302544,	
2017-07-31 13:02:12,511 Epoch[1] Batch [400]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.301857,	
2017-07-31 13:02:17,256 Epoch[1] Batch [410]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.302191,	
2017-07-31 13:02:21,089 Epoch[1] Batch [420]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.300854,	
2017-07-31 13:02:25,246 Epoch[1] Batch [430]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.300077,	
2017-07-31 13:02:30,313 Epoch[1] Batch [440]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.299766,	
2017-07-31 13:02:34,608 Epoch[1] Batch [450]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.299165,	
2017-07-31 13:02:38,643 Epoch[1] Batch [460]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.299294,	
2017-07-31 13:02:42,798 Epoch[1] Batch [470]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.298881,	
2017-07-31 13:02:46,505 Epoch[1] Batch [480]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.298633,	
2017-07-31 13:02:51,080 Epoch[1] Batch [490]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.297323,	
2017-07-31 13:02:54,917 Epoch[1] Batch [500]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.296622,	
2017-07-31 13:02:58,692 Epoch[1] Batch [510]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.295259,	
2017-07-31 13:03:02,488 Epoch[1] Batch [520]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.294323,	
2017-07-31 13:03:07,383 Epoch[1] Batch [530]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.292845,	
2017-07-31 13:03:11,205 Epoch[1] Batch [540]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.291701,	
2017-07-31 13:03:15,886 Epoch[1] Batch [550]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.290313,	
2017-07-31 13:03:19,745 Epoch[1] Batch [560]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.290853,	
2017-07-31 13:03:23,907 Epoch[1] Batch [570]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.290548,	
2017-07-31 13:03:27,680 Epoch[1] Batch [580]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.289582,	
2017-07-31 13:03:32,325 Epoch[1] Batch [590]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.288955,	
2017-07-31 13:03:36,264 Epoch[1] Batch [600]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.289098,	
2017-07-31 13:03:40,356 Epoch[1] Batch [610]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.288445,	
2017-07-31 13:03:44,435 Epoch[1] Batch [620]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.288685,	
2017-07-31 13:03:48,274 Epoch[1] Batch [630]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.288017,	
2017-07-31 13:03:52,192 Epoch[1] Batch [640]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.287469,	
2017-07-31 13:03:56,015 Epoch[1] Batch [650]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.286359,	
2017-07-31 13:04:00,274 Epoch[1] Batch [660]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.285577,	
2017-07-31 13:04:04,244 Epoch[1] Batch [670]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.284744,	
2017-07-31 13:04:08,116 Epoch[1] Batch [680]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.283731,	
2017-07-31 13:04:11,900 Epoch[1] Batch [690]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.283002,	
2017-07-31 13:04:15,735 Epoch[1] Batch [700]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.282146,	
2017-07-31 13:04:19,649 Epoch[1] Batch [710]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.280914,	
2017-07-31 13:04:23,531 Epoch[1] Batch [720]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.280131,	
2017-07-31 13:04:27,389 Epoch[1] Batch [730]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.279459,	
2017-07-31 13:04:31,747 Epoch[1] Batch [740]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.278182,	
2017-07-31 13:04:35,668 Epoch[1] Batch [750]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.277034,	
2017-07-31 13:04:39,463 Epoch[1] Batch [760]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.276958,	
2017-07-31 13:04:43,580 Epoch[1] Batch [770]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.276519,	
2017-07-31 13:04:48,058 Epoch[1] Batch [780]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.276192,	
2017-07-31 13:04:52,175 Epoch[1] Batch [790]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.275675,	
2017-07-31 13:04:56,451 Epoch[1] Batch [800]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.275782,	
2017-07-31 13:05:00,207 Epoch[1] Batch [810]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.275696,	
2017-07-31 13:05:04,964 Epoch[1] Batch [820]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.275301,	
2017-07-31 13:05:08,797 Epoch[1] Batch [830]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.274539,	
2017-07-31 13:05:12,677 Epoch[1] Batch [840]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.273981,	
2017-07-31 13:05:16,524 Epoch[1] Batch [850]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.273269,	
2017-07-31 13:05:20,476 Epoch[1] Batch [860]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.272353,	
2017-07-31 13:05:24,458 Epoch[1] Batch [870]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.271943,	
2017-07-31 13:05:28,436 Epoch[1] Batch [880]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.271127,	
2017-07-31 13:05:32,355 Epoch[1] Batch [890]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.270491,	
2017-07-31 13:05:36,297 Epoch[1] Batch [900]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.270201,	
2017-07-31 13:05:40,228 Epoch[1] Batch [910]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.269996,	
2017-07-31 13:05:44,102 Epoch[1] Batch [920]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.269408,	
2017-07-31 13:05:48,014 Epoch[1] Batch [930]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.269006,	
2017-07-31 13:05:51,920 Epoch[1] Batch [940]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.268775,	
2017-07-31 13:05:55,884 Epoch[1] Batch [950]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.268574,	
2017-07-31 13:05:59,774 Epoch[1] Batch [960]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.268579,	
2017-07-31 13:06:03,816 Epoch[1] Batch [970]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.268301,	
2017-07-31 13:06:07,655 Epoch[1] Batch [980]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.267638,	
2017-07-31 13:06:11,517 Epoch[1] Batch [990]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.266941,	
2017-07-31 13:06:15,363 Epoch[1] Batch [1000]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.266651,	
2017-07-31 13:06:19,235 Epoch[1] Batch [1010]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.266202,	
2017-07-31 13:06:23,142 Epoch[1] Batch [1020]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.265828,	
2017-07-31 13:06:27,079 Epoch[1] Batch [1030]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.265366,	
2017-07-31 13:06:31,122 Epoch[1] Batch [1040]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.264995,	
2017-07-31 13:06:35,031 Epoch[1] Batch [1050]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.264525,	
2017-07-31 13:06:38,924 Epoch[1] Batch [1060]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.263977,	
2017-07-31 13:06:42,971 Epoch[1] Batch [1070]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.263986,	
2017-07-31 13:06:46,912 Epoch[1] Batch [1080]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.263738,	
2017-07-31 13:06:50,826 Epoch[1] Batch [1090]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.263688,	
2017-07-31 13:06:54,823 Epoch[1] Batch [1100]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.263515,	
2017-07-31 13:06:58,805 Epoch[1] Batch [1110]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.263289,	
2017-07-31 13:07:02,711 Epoch[1] Batch [1120]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.262766,	
2017-07-31 13:07:06,745 Epoch[1] Batch [1130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.262742,	
2017-07-31 13:07:10,583 Epoch[1] Batch [1140]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.262347,	
2017-07-31 13:07:14,604 Epoch[1] Batch [1150]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.261879,	
2017-07-31 13:07:18,620 Epoch[1] Batch [1160]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.262257,	
2017-07-31 13:07:22,584 Epoch[1] Batch [1170]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.262137,	
2017-07-31 13:07:26,661 Epoch[1] Batch [1180]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.261841,	
2017-07-31 13:07:30,556 Epoch[1] Batch [1190]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.261811,	
2017-07-31 13:07:34,566 Epoch[1] Batch [1200]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.261650,	
2017-07-31 13:07:38,616 Epoch[1] Batch [1210]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.261133,	
2017-07-31 13:07:42,481 Epoch[1] Batch [1220]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.260736,	
2017-07-31 13:07:46,352 Epoch[1] Batch [1230]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.260244,	
2017-07-31 13:07:50,223 Epoch[1] Batch [1240]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.259923,	
2017-07-31 13:07:55,732 Epoch[1] Batch [1250]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.259873,	
2017-07-31 13:07:59,845 Epoch[1] Batch [1260]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.259515,	
2017-07-31 13:08:03,737 Epoch[1] Batch [1270]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.259164,	
2017-07-31 13:08:07,767 Epoch[1] Batch [1280]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.259202,	
2017-07-31 13:08:11,631 Epoch[1] Batch [1290]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.258816,	
2017-07-31 13:08:15,552 Epoch[1] Batch [1300]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.258367,	
2017-07-31 13:08:19,342 Epoch[1] Batch [1310]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.257871,	
2017-07-31 13:08:23,326 Epoch[1] Batch [1320]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.257540,	
2017-07-31 13:08:27,202 Epoch[1] Batch [1330]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.257432,	
2017-07-31 13:08:31,198 Epoch[1] Batch [1340]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.256975,	
2017-07-31 13:08:35,166 Epoch[1] Batch [1350]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.256709,	
2017-07-31 13:08:39,040 Epoch[1] Batch [1360]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.256758,	
2017-07-31 13:08:42,822 Epoch[1] Batch [1370]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.256454,	
2017-07-31 13:08:46,784 Epoch[1] Batch [1380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.256029,	
2017-07-31 13:08:50,833 Epoch[1] Batch [1390]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.255585,	
2017-07-31 13:08:54,764 Epoch[1] Batch [1400]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.255269,	
2017-07-31 13:08:58,649 Epoch[1] Batch [1410]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.255069,	
2017-07-31 13:09:02,395 Epoch[1] Batch [1420]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.254565,	
2017-07-31 13:09:06,455 Epoch[1] Batch [1430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.254135,	
2017-07-31 13:09:10,275 Epoch[1] Batch [1440]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.253866,	
2017-07-31 13:09:14,257 Epoch[1] Batch [1450]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.253733,	
2017-07-31 13:09:18,086 Epoch[1] Batch [1460]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.253955,	
2017-07-31 13:09:22,007 Epoch[1] Batch [1470]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.253696,	
2017-07-31 13:09:26,096 Epoch[1] Batch [1480]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.253551,	
2017-07-31 13:09:28,399 Epoch[1] Train-FCNLogLoss=0.253365
2017-07-31 13:09:28,399 Epoch[1] Time cost=596.451
2017-07-31 13:09:29,344 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.params"
2017-07-31 13:09:33,168 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.states"
2017-07-31 13:09:37,654 Epoch[2] Batch [10]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.208333,	
2017-07-31 13:09:41,484 Epoch[2] Batch [20]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.203341,	
2017-07-31 13:09:45,423 Epoch[2] Batch [30]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.215120,	
2017-07-31 13:09:49,188 Epoch[2] Batch [40]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.213300,	
2017-07-31 13:09:53,029 Epoch[2] Batch [50]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.213293,	
2017-07-31 13:09:56,804 Epoch[2] Batch [60]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.216711,	
2017-07-31 13:10:00,726 Epoch[2] Batch [70]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.211066,	
2017-07-31 13:10:04,638 Epoch[2] Batch [80]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.212342,	
2017-07-31 13:10:08,498 Epoch[2] Batch [90]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.210615,	
2017-07-31 13:10:12,375 Epoch[2] Batch [100]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.214040,	
2017-07-31 13:10:16,300 Epoch[2] Batch [110]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.213134,	
2017-07-31 13:10:20,205 Epoch[2] Batch [120]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.214527,	
2017-07-31 13:10:24,018 Epoch[2] Batch [130]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.214958,	
2017-07-31 13:10:27,941 Epoch[2] Batch [140]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.214996,	
2017-07-31 13:10:31,790 Epoch[2] Batch [150]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.213100,	
2017-07-31 13:10:35,736 Epoch[2] Batch [160]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.218514,	
2017-07-31 13:10:39,656 Epoch[2] Batch [170]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.219559,	
2017-07-31 13:10:43,636 Epoch[2] Batch [180]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.220847,	
2017-07-31 13:10:47,526 Epoch[2] Batch [190]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.219092,	
2017-07-31 13:10:51,490 Epoch[2] Batch [200]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.217867,	
2017-07-31 13:10:55,451 Epoch[2] Batch [210]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.216710,	
2017-07-31 13:10:59,309 Epoch[2] Batch [220]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.216167,	
2017-07-31 13:11:03,202 Epoch[2] Batch [230]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.216051,	
2017-07-31 13:11:07,132 Epoch[2] Batch [240]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.217481,	
2017-07-31 13:11:11,029 Epoch[2] Batch [250]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.216152,	
2017-07-31 13:11:15,017 Epoch[2] Batch [260]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.215486,	
2017-07-31 13:11:18,822 Epoch[2] Batch [270]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.214581,	
2017-07-31 13:11:22,771 Epoch[2] Batch [280]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.215477,	
2017-07-31 13:11:26,798 Epoch[2] Batch [290]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.214354,	
2017-07-31 13:11:30,674 Epoch[2] Batch [300]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.213148,	
2017-07-31 13:11:34,533 Epoch[2] Batch [310]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.212683,	
2017-07-31 13:11:38,350 Epoch[2] Batch [320]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.212849,	
2017-07-31 13:11:42,305 Epoch[2] Batch [330]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.214179,	
2017-07-31 13:11:46,320 Epoch[2] Batch [340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.214283,	
2017-07-31 13:11:50,190 Epoch[2] Batch [350]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.214754,	
2017-07-31 13:11:54,146 Epoch[2] Batch [360]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.216080,	
2017-07-31 13:11:58,023 Epoch[2] Batch [370]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.215820,	
2017-07-31 13:12:01,918 Epoch[2] Batch [380]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.215514,	
2017-07-31 13:12:05,882 Epoch[2] Batch [390]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.215875,	
2017-07-31 13:12:09,766 Epoch[2] Batch [400]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.215272,	
2017-07-31 13:12:13,705 Epoch[2] Batch [410]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.214362,	
2017-07-31 13:12:17,537 Epoch[2] Batch [420]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.214249,	
2017-07-31 13:12:21,398 Epoch[2] Batch [430]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.213777,	
2017-07-31 13:12:25,337 Epoch[2] Batch [440]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.213605,	
2017-07-31 13:12:29,322 Epoch[2] Batch [450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.212938,	
2017-07-31 13:12:33,191 Epoch[2] Batch [460]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.212583,	
2017-07-31 13:12:37,060 Epoch[2] Batch [470]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.211360,	
2017-07-31 13:12:41,032 Epoch[2] Batch [480]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.210499,	
2017-07-31 13:12:44,908 Epoch[2] Batch [490]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.210020,	
2017-07-31 13:12:48,747 Epoch[2] Batch [500]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.210283,	
2017-07-31 13:12:52,634 Epoch[2] Batch [510]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.209706,	
2017-07-31 13:12:56,512 Epoch[2] Batch [520]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.209548,	
2017-07-31 13:13:00,485 Epoch[2] Batch [530]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.209367,	
2017-07-31 13:13:04,347 Epoch[2] Batch [540]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.209719,	
2017-07-31 13:13:08,166 Epoch[2] Batch [550]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.210075,	
2017-07-31 13:13:11,982 Epoch[2] Batch [560]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.209744,	
2017-07-31 13:13:16,052 Epoch[2] Batch [570]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.209878,	
2017-07-31 13:13:20,194 Epoch[2] Batch [580]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.209309,	
2017-07-31 13:13:24,100 Epoch[2] Batch [590]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.209548,	
2017-07-31 13:13:28,106 Epoch[2] Batch [600]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.210067,	
2017-07-31 13:13:31,985 Epoch[2] Batch [610]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.210530,	
2017-07-31 13:13:35,827 Epoch[2] Batch [620]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.210347,	
2017-07-31 13:13:39,638 Epoch[2] Batch [630]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.210605,	
2017-07-31 13:13:43,508 Epoch[2] Batch [640]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.210537,	
2017-07-31 13:13:47,471 Epoch[2] Batch [650]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.210500,	
2017-07-31 13:13:51,594 Epoch[2] Batch [660]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.210583,	
2017-07-31 13:13:55,621 Epoch[2] Batch [670]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.210419,	
2017-07-31 13:13:59,527 Epoch[2] Batch [680]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.211387,	
2017-07-31 13:14:03,359 Epoch[2] Batch [690]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.212184,	
2017-07-31 13:14:07,230 Epoch[2] Batch [700]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.212491,	
2017-07-31 13:14:11,059 Epoch[2] Batch [710]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.212590,	
2017-07-31 13:14:14,822 Epoch[2] Batch [720]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.212659,	
2017-07-31 13:14:18,747 Epoch[2] Batch [730]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.212378,	
2017-07-31 13:14:22,771 Epoch[2] Batch [740]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.212322,	
2017-07-31 13:14:26,575 Epoch[2] Batch [750]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.212112,	
2017-07-31 13:14:30,447 Epoch[2] Batch [760]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.212088,	
2017-07-31 13:14:34,316 Epoch[2] Batch [770]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.212040,	
2017-07-31 13:14:38,319 Epoch[2] Batch [780]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.212174,	
2017-07-31 13:14:42,261 Epoch[2] Batch [790]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.212332,	
2017-07-31 13:14:46,170 Epoch[2] Batch [800]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.212197,	
2017-07-31 13:14:50,114 Epoch[2] Batch [810]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.211955,	
2017-07-31 13:14:54,057 Epoch[2] Batch [820]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.212223,	
2017-07-31 13:14:57,919 Epoch[2] Batch [830]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.212197,	
2017-07-31 13:15:02,156 Epoch[2] Batch [840]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.212327,	
2017-07-31 13:15:06,160 Epoch[2] Batch [850]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.212279,	
2017-07-31 13:15:09,994 Epoch[2] Batch [860]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.212592,	
2017-07-31 13:15:13,985 Epoch[2] Batch [870]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.213075,	
2017-07-31 13:15:17,931 Epoch[2] Batch [880]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.213021,	
2017-07-31 13:15:22,017 Epoch[2] Batch [890]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.212936,	
2017-07-31 13:15:26,061 Epoch[2] Batch [900]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.213116,	
2017-07-31 13:15:29,804 Epoch[2] Batch [910]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.213047,	
2017-07-31 13:15:34,436 Epoch[2] Batch [920]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.212934,	
2017-07-31 13:15:38,448 Epoch[2] Batch [930]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.213047,	
2017-07-31 13:15:42,362 Epoch[2] Batch [940]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.212521,	
2017-07-31 13:15:46,228 Epoch[2] Batch [950]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.212417,	
2017-07-31 13:15:50,053 Epoch[2] Batch [960]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.211971,	
2017-07-31 13:15:54,027 Epoch[2] Batch [970]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.211755,	
2017-07-31 13:15:57,949 Epoch[2] Batch [980]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.211343,	
2017-07-31 13:16:01,881 Epoch[2] Batch [990]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.211409,	
2017-07-31 13:16:05,896 Epoch[2] Batch [1000]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.211368,	
2017-07-31 13:16:09,829 Epoch[2] Batch [1010]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.211156,	
2017-07-31 13:16:13,761 Epoch[2] Batch [1020]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.210982,	
2017-07-31 13:16:17,633 Epoch[2] Batch [1030]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.210518,	
2017-07-31 13:16:21,475 Epoch[2] Batch [1040]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.210547,	
2017-07-31 13:16:25,457 Epoch[2] Batch [1050]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.210585,	
2017-07-31 13:16:29,372 Epoch[2] Batch [1060]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.210548,	
2017-07-31 13:16:33,264 Epoch[2] Batch [1070]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.210561,	
2017-07-31 13:16:37,260 Epoch[2] Batch [1080]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.210489,	
2017-07-31 13:16:41,090 Epoch[2] Batch [1090]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.210033,	
2017-07-31 13:16:45,115 Epoch[2] Batch [1100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.210028,	
2017-07-31 13:16:49,019 Epoch[2] Batch [1110]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.209667,	
2017-07-31 13:16:53,003 Epoch[2] Batch [1120]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.210011,	
2017-07-31 13:16:56,793 Epoch[2] Batch [1130]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.209922,	
2017-07-31 13:17:00,962 Epoch[2] Batch [1140]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.210148,	
2017-07-31 13:17:04,785 Epoch[2] Batch [1150]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.211717,	
2017-07-31 13:17:08,654 Epoch[2] Batch [1160]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.213719,	
2017-07-31 13:17:12,609 Epoch[2] Batch [1170]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.214493,	
2017-07-31 13:17:16,555 Epoch[2] Batch [1180]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.215271,	
2017-07-31 13:17:20,466 Epoch[2] Batch [1190]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.215808,	
2017-07-31 13:17:24,372 Epoch[2] Batch [1200]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.216344,	
2017-07-31 13:17:28,257 Epoch[2] Batch [1210]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.216932,	
2017-07-31 13:17:32,118 Epoch[2] Batch [1220]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.216986,	
2017-07-31 13:17:36,195 Epoch[2] Batch [1230]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.217070,	
2017-07-31 13:17:40,166 Epoch[2] Batch [1240]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.216991,	
2017-07-31 13:17:44,233 Epoch[2] Batch [1250]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.216707,	
2017-07-31 13:17:48,126 Epoch[2] Batch [1260]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.217265,	
2017-07-31 13:17:52,027 Epoch[2] Batch [1270]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.217127,	
2017-07-31 13:17:55,914 Epoch[2] Batch [1280]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.216978,	
2017-07-31 13:17:59,979 Epoch[2] Batch [1290]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.216884,	
2017-07-31 13:18:03,989 Epoch[2] Batch [1300]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.216523,	
2017-07-31 13:18:07,835 Epoch[2] Batch [1310]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.216376,	
2017-07-31 13:18:11,803 Epoch[2] Batch [1320]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.216237,	
2017-07-31 13:18:15,727 Epoch[2] Batch [1330]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.217113,	
2017-07-31 13:18:19,715 Epoch[2] Batch [1340]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.217594,	
2017-07-31 13:18:23,627 Epoch[2] Batch [1350]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.217554,	
2017-07-31 13:18:27,510 Epoch[2] Batch [1360]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.217663,	
2017-07-31 13:18:31,700 Epoch[2] Batch [1370]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.217494,	
2017-07-31 13:18:35,602 Epoch[2] Batch [1380]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.217317,	
2017-07-31 13:18:39,825 Epoch[2] Batch [1390]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.216967,	
2017-07-31 13:18:43,567 Epoch[2] Batch [1400]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.217101,	
2017-07-31 13:18:47,557 Epoch[2] Batch [1410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.216950,	
2017-07-31 13:18:51,522 Epoch[2] Batch [1420]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.216831,	
2017-07-31 13:18:55,454 Epoch[2] Batch [1430]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.216655,	
2017-07-31 13:18:59,484 Epoch[2] Batch [1440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.216340,	
2017-07-31 13:19:03,395 Epoch[2] Batch [1450]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.216219,	
2017-07-31 13:19:07,288 Epoch[2] Batch [1460]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.216373,	
2017-07-31 13:19:11,191 Epoch[2] Batch [1470]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.216376,	
2017-07-31 13:19:15,076 Epoch[2] Batch [1480]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.216294,	
2017-07-31 13:19:17,425 Epoch[2] Train-FCNLogLoss=0.216187
2017-07-31 13:19:17,426 Epoch[2] Time cost=584.257
2017-07-31 13:19:18,388 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.params"
2017-07-31 13:19:22,650 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.states"
2017-07-31 13:19:27,622 Epoch[3] Batch [10]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.213473,	
2017-07-31 13:19:31,742 Epoch[3] Batch [20]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.216244,	
2017-07-31 13:19:36,094 Epoch[3] Batch [30]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.214615,	
2017-07-31 13:19:40,057 Epoch[3] Batch [40]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.215448,	
2017-07-31 13:19:44,369 Epoch[3] Batch [50]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.212950,	
2017-07-31 13:19:48,509 Epoch[3] Batch [60]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.212420,	
2017-07-31 13:19:52,730 Epoch[3] Batch [70]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.214095,	
2017-07-31 13:19:56,872 Epoch[3] Batch [80]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.210055,	
2017-07-31 13:20:00,910 Epoch[3] Batch [90]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.211234,	
2017-07-31 13:20:05,081 Epoch[3] Batch [100]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.210971,	
2017-07-31 13:20:09,226 Epoch[3] Batch [110]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.210466,	
2017-07-31 13:20:13,403 Epoch[3] Batch [120]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.209752,	
2017-07-31 13:20:17,388 Epoch[3] Batch [130]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.208184,	
2017-07-31 13:20:21,560 Epoch[3] Batch [140]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.209096,	
2017-07-31 13:20:25,643 Epoch[3] Batch [150]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.208735,	
2017-07-31 13:20:29,892 Epoch[3] Batch [160]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.207705,	
2017-07-31 13:20:34,038 Epoch[3] Batch [170]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.206537,	
2017-07-31 13:20:38,127 Epoch[3] Batch [180]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.205667,	
2017-07-31 13:20:42,350 Epoch[3] Batch [190]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.205334,	
2017-07-31 13:20:46,401 Epoch[3] Batch [200]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.205529,	
2017-07-31 13:20:50,557 Epoch[3] Batch [210]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.204444,	
2017-07-31 13:20:54,640 Epoch[3] Batch [220]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.204548,	
2017-07-31 13:20:58,720 Epoch[3] Batch [230]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.203889,	
2017-07-31 13:21:02,989 Epoch[3] Batch [240]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.203482,	
2017-07-31 13:21:07,089 Epoch[3] Batch [250]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.204017,	
2017-07-31 13:21:11,376 Epoch[3] Batch [260]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.204036,	
2017-07-31 13:21:15,461 Epoch[3] Batch [270]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.204591,	
2017-07-31 13:21:19,405 Epoch[3] Batch [280]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.203427,	
2017-07-31 13:21:23,462 Epoch[3] Batch [290]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.202185,	
2017-07-31 13:21:27,556 Epoch[3] Batch [300]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.202678,	
2017-07-31 13:21:31,732 Epoch[3] Batch [310]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.202099,	
2017-07-31 13:21:35,888 Epoch[3] Batch [320]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.201788,	
2017-07-31 13:21:39,860 Epoch[3] Batch [330]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.201968,	
2017-07-31 13:21:44,107 Epoch[3] Batch [340]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.201325,	
2017-07-31 13:21:48,365 Epoch[3] Batch [350]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.200109,	
2017-07-31 13:21:52,340 Epoch[3] Batch [360]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.200612,	
2017-07-31 13:21:56,422 Epoch[3] Batch [370]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.200628,	
2017-07-31 13:22:00,649 Epoch[3] Batch [380]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.201350,	
2017-07-31 13:22:04,676 Epoch[3] Batch [390]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.201163,	
2017-07-31 13:22:08,966 Epoch[3] Batch [400]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.201177,	
2017-07-31 13:22:13,041 Epoch[3] Batch [410]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.201444,	
2017-07-31 13:22:17,109 Epoch[3] Batch [420]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.201595,	
2017-07-31 13:22:21,219 Epoch[3] Batch [430]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.201064,	
2017-07-31 13:22:25,433 Epoch[3] Batch [440]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.200780,	
2017-07-31 13:22:29,439 Epoch[3] Batch [450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.200872,	
2017-07-31 13:22:33,541 Epoch[3] Batch [460]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.200316,	
2017-07-31 13:22:37,627 Epoch[3] Batch [470]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.199442,	
2017-07-31 13:22:41,895 Epoch[3] Batch [480]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.199483,	
2017-07-31 13:22:45,965 Epoch[3] Batch [490]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.199303,	
2017-07-31 13:22:50,164 Epoch[3] Batch [500]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.198710,	
2017-07-31 13:22:54,333 Epoch[3] Batch [510]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.198341,	
2017-07-31 13:22:58,363 Epoch[3] Batch [520]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.198367,	
2017-07-31 13:23:02,361 Epoch[3] Batch [530]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.198300,	
2017-07-31 13:23:06,509 Epoch[3] Batch [540]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.198964,	
2017-07-31 13:23:10,668 Epoch[3] Batch [550]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.199477,	
2017-07-31 13:23:14,758 Epoch[3] Batch [560]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.199240,	
2017-07-31 13:23:19,163 Epoch[3] Batch [570]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.199002,	
2017-07-31 13:23:23,425 Epoch[3] Batch [580]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.198579,	
2017-07-31 13:23:27,458 Epoch[3] Batch [590]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.198143,	
2017-07-31 13:23:31,497 Epoch[3] Batch [600]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.198077,	
2017-07-31 13:23:35,619 Epoch[3] Batch [610]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.198238,	
2017-07-31 13:23:39,685 Epoch[3] Batch [620]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.197801,	
2017-07-31 13:23:43,627 Epoch[3] Batch [630]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.197072,	
2017-07-31 13:23:47,697 Epoch[3] Batch [640]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.196808,	
2017-07-31 13:23:51,628 Epoch[3] Batch [650]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.196749,	
2017-07-31 13:23:55,708 Epoch[3] Batch [660]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.196411,	
2017-07-31 13:23:59,627 Epoch[3] Batch [670]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.196012,	
2017-07-31 13:24:03,631 Epoch[3] Batch [680]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.195736,	
2017-07-31 13:24:07,726 Epoch[3] Batch [690]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.195273,	
2017-07-31 13:24:11,921 Epoch[3] Batch [700]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.195357,	
2017-07-31 13:24:16,219 Epoch[3] Batch [710]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.195150,	
2017-07-31 13:24:20,425 Epoch[3] Batch [720]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.194564,	
2017-07-31 13:24:24,559 Epoch[3] Batch [730]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.194341,	
2017-07-31 13:24:28,692 Epoch[3] Batch [740]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.194105,	
2017-07-31 13:24:32,665 Epoch[3] Batch [750]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.194337,	
2017-07-31 13:24:36,714 Epoch[3] Batch [760]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.194098,	
2017-07-31 13:24:41,136 Epoch[3] Batch [770]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.193801,	
2017-07-31 13:24:45,363 Epoch[3] Batch [780]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.193854,	
2017-07-31 13:24:49,491 Epoch[3] Batch [790]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.193776,	
2017-07-31 13:24:53,759 Epoch[3] Batch [800]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.193350,	
2017-07-31 13:24:58,041 Epoch[3] Batch [810]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.193313,	
2017-07-31 13:25:02,412 Epoch[3] Batch [820]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.193212,	
2017-07-31 13:25:06,663 Epoch[3] Batch [830]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.193174,	
2017-07-31 13:25:10,893 Epoch[3] Batch [840]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.192880,	
2017-07-31 13:25:15,047 Epoch[3] Batch [850]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.192578,	
2017-07-31 13:25:19,361 Epoch[3] Batch [860]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.192552,	
2017-07-31 13:25:23,588 Epoch[3] Batch [870]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.193184,	
2017-07-31 13:25:27,830 Epoch[3] Batch [880]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.193696,	
2017-07-31 13:25:32,572 Epoch[3] Batch [890]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.193816,	
2017-07-31 13:25:36,860 Epoch[3] Batch [900]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.193609,	
2017-07-31 13:25:41,038 Epoch[3] Batch [910]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.194055,	
2017-07-31 13:25:45,065 Epoch[3] Batch [920]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.194365,	
2017-07-31 13:25:49,366 Epoch[3] Batch [930]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.194134,	
2017-07-31 13:25:53,622 Epoch[3] Batch [940]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.193765,	
2017-07-31 13:25:57,770 Epoch[3] Batch [950]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.193464,	
2017-07-31 13:26:01,725 Epoch[3] Batch [960]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.193098,	
2017-07-31 13:26:05,721 Epoch[3] Batch [970]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.192965,	
2017-07-31 13:26:09,704 Epoch[3] Batch [980]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.192713,	
2017-07-31 13:26:13,745 Epoch[3] Batch [990]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.192353,	
2017-07-31 13:26:17,916 Epoch[3] Batch [1000]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.192099,	
2017-07-31 13:26:22,038 Epoch[3] Batch [1010]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.192052,	
2017-07-31 13:26:26,224 Epoch[3] Batch [1020]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.192177,	
2017-07-31 13:26:30,310 Epoch[3] Batch [1030]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.192277,	
2017-07-31 13:26:34,449 Epoch[3] Batch [1040]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.192709,	
2017-07-31 13:26:38,617 Epoch[3] Batch [1050]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.192660,	
2017-07-31 13:26:42,833 Epoch[3] Batch [1060]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.192828,	
2017-07-31 13:26:47,071 Epoch[3] Batch [1070]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.192563,	
2017-07-31 13:26:51,216 Epoch[3] Batch [1080]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.192678,	
2017-07-31 13:26:55,240 Epoch[3] Batch [1090]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.192915,	
2017-07-31 13:26:59,395 Epoch[3] Batch [1100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.192928,	
2017-07-31 13:27:03,513 Epoch[3] Batch [1110]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.192779,	
2017-07-31 13:27:07,577 Epoch[3] Batch [1120]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.192964,	
2017-07-31 13:27:11,791 Epoch[3] Batch [1130]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.192716,	
2017-07-31 13:27:15,891 Epoch[3] Batch [1140]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.193048,	
2017-07-31 13:27:19,880 Epoch[3] Batch [1150]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.193144,	
2017-07-31 13:27:24,012 Epoch[3] Batch [1160]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.192821,	
2017-07-31 13:27:28,024 Epoch[3] Batch [1170]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.192775,	
2017-07-31 13:27:32,300 Epoch[3] Batch [1180]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.192627,	
2017-07-31 13:27:36,420 Epoch[3] Batch [1190]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.192453,	
2017-07-31 13:27:40,706 Epoch[3] Batch [1200]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.192633,	
2017-07-31 13:27:44,879 Epoch[3] Batch [1210]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.192459,	
2017-07-31 13:27:48,961 Epoch[3] Batch [1220]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.192173,	
2017-07-31 13:27:52,993 Epoch[3] Batch [1230]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.192227,	
2017-07-31 13:27:57,421 Epoch[3] Batch [1240]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.192066,	
2017-07-31 13:28:01,656 Epoch[3] Batch [1250]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.191900,	
2017-07-31 13:28:05,786 Epoch[3] Batch [1260]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.192154,	
2017-07-31 13:28:09,916 Epoch[3] Batch [1270]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.191956,	
2017-07-31 13:28:13,921 Epoch[3] Batch [1280]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.192131,	
2017-07-31 13:28:17,999 Epoch[3] Batch [1290]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.191984,	
2017-07-31 13:28:22,038 Epoch[3] Batch [1300]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.191851,	
2017-07-31 13:28:25,998 Epoch[3] Batch [1310]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.192132,	
2017-07-31 13:28:30,103 Epoch[3] Batch [1320]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.191938,	
2017-07-31 13:28:34,100 Epoch[3] Batch [1330]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.191757,	
2017-07-31 13:28:37,966 Epoch[3] Batch [1340]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.191586,	
2017-07-31 13:28:42,085 Epoch[3] Batch [1350]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.191572,	
2017-07-31 13:28:46,175 Epoch[3] Batch [1360]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.191401,	
2017-07-31 13:28:50,286 Epoch[3] Batch [1370]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.191543,	
2017-07-31 13:28:54,539 Epoch[3] Batch [1380]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.191595,	
2017-07-31 13:28:58,809 Epoch[3] Batch [1390]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.191574,	
2017-07-31 13:29:02,873 Epoch[3] Batch [1400]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.191572,	
2017-07-31 13:29:06,906 Epoch[3] Batch [1410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.191754,	
2017-07-31 13:29:11,044 Epoch[3] Batch [1420]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.191713,	
2017-07-31 13:29:15,222 Epoch[3] Batch [1430]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.191697,	
2017-07-31 13:29:19,326 Epoch[3] Batch [1440]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.191432,	
2017-07-31 13:29:23,587 Epoch[3] Batch [1450]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.191252,	
2017-07-31 13:29:27,706 Epoch[3] Batch [1460]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.191022,	
2017-07-31 13:29:32,349 Epoch[3] Batch [1470]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.190832,	
2017-07-31 13:29:36,492 Epoch[3] Batch [1480]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.190628,	
2017-07-31 13:29:38,888 Epoch[3] Train-FCNLogLoss=0.190559
2017-07-31 13:29:38,889 Epoch[3] Time cost=616.238
2017-07-31 13:29:39,698 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.params"
2017-07-31 13:29:43,563 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.states"
2017-07-31 13:29:48,231 Epoch[4] Batch [10]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.147791,	
2017-07-31 13:29:52,390 Epoch[4] Batch [20]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.149812,	
2017-07-31 13:29:57,192 Epoch[4] Batch [30]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.156080,	
2017-07-31 13:30:01,438 Epoch[4] Batch [40]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.160980,	
2017-07-31 13:30:05,418 Epoch[4] Batch [50]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.164362,	
2017-07-31 13:30:09,421 Epoch[4] Batch [60]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.167807,	
2017-07-31 13:30:13,431 Epoch[4] Batch [70]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.167804,	
2017-07-31 13:30:17,451 Epoch[4] Batch [80]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.168455,	
2017-07-31 13:30:21,581 Epoch[4] Batch [90]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.168538,	
2017-07-31 13:30:26,091 Epoch[4] Batch [100]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.169490,	
2017-07-31 13:30:30,518 Epoch[4] Batch [110]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.167698,	
2017-07-31 13:30:34,797 Epoch[4] Batch [120]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.168289,	
2017-07-31 13:30:39,062 Epoch[4] Batch [130]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.169976,	
2017-07-31 13:30:43,411 Epoch[4] Batch [140]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.169202,	
2017-07-31 13:30:47,729 Epoch[4] Batch [150]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.169868,	
2017-07-31 13:30:51,790 Epoch[4] Batch [160]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.170782,	
2017-07-31 13:30:56,129 Epoch[4] Batch [170]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.171070,	
2017-07-31 13:31:00,387 Epoch[4] Batch [180]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.171610,	
2017-07-31 13:31:04,627 Epoch[4] Batch [190]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.171297,	
2017-07-31 13:31:08,687 Epoch[4] Batch [200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.172796,	
2017-07-31 13:31:13,242 Epoch[4] Batch [210]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.172808,	
2017-07-31 13:31:17,668 Epoch[4] Batch [220]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.172474,	
2017-07-31 13:31:21,851 Epoch[4] Batch [230]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.173253,	
2017-07-31 13:31:26,030 Epoch[4] Batch [240]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.174533,	
2017-07-31 13:31:30,592 Epoch[4] Batch [250]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.175615,	
2017-07-31 13:31:34,478 Epoch[4] Batch [260]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.175230,	
2017-07-31 13:31:38,788 Epoch[4] Batch [270]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.174985,	
2017-07-31 13:31:42,778 Epoch[4] Batch [280]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.175499,	
2017-07-31 13:31:46,781 Epoch[4] Batch [290]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.174750,	
2017-07-31 13:31:51,076 Epoch[4] Batch [300]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.174101,	
2017-07-31 13:31:55,353 Epoch[4] Batch [310]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.174005,	
2017-07-31 13:31:59,433 Epoch[4] Batch [320]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.174756,	
2017-07-31 13:32:03,592 Epoch[4] Batch [330]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.175130,	
2017-07-31 13:32:07,702 Epoch[4] Batch [340]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.175068,	
2017-07-31 13:32:11,896 Epoch[4] Batch [350]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.174848,	
2017-07-31 13:32:16,000 Epoch[4] Batch [360]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.175022,	
2017-07-31 13:32:20,394 Epoch[4] Batch [370]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.174543,	
2017-07-31 13:32:24,523 Epoch[4] Batch [380]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.173691,	
2017-07-31 13:32:28,784 Epoch[4] Batch [390]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.174078,	
2017-07-31 13:32:33,108 Epoch[4] Batch [400]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.173718,	
2017-07-31 13:32:37,444 Epoch[4] Batch [410]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.173256,	
2017-07-31 13:32:41,493 Epoch[4] Batch [420]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.172916,	
2017-07-31 13:32:45,730 Epoch[4] Batch [430]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.172460,	
2017-07-31 13:32:49,820 Epoch[4] Batch [440]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.172335,	
2017-07-31 13:32:54,192 Epoch[4] Batch [450]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.172237,	
2017-07-31 13:32:58,194 Epoch[4] Batch [460]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.172130,	
2017-07-31 13:33:02,318 Epoch[4] Batch [470]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.171783,	
2017-07-31 13:33:06,409 Epoch[4] Batch [480]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.172499,	
2017-07-31 13:33:10,407 Epoch[4] Batch [490]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.172670,	
2017-07-31 13:33:14,641 Epoch[4] Batch [500]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.172553,	
2017-07-31 13:33:18,888 Epoch[4] Batch [510]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.172709,	
2017-07-31 13:33:22,851 Epoch[4] Batch [520]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.172330,	
2017-07-31 13:33:27,114 Epoch[4] Batch [530]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.172270,	
2017-07-31 13:33:31,210 Epoch[4] Batch [540]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.172076,	
2017-07-31 13:33:35,192 Epoch[4] Batch [550]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.172111,	
2017-07-31 13:33:39,186 Epoch[4] Batch [560]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.171946,	
2017-07-31 13:33:43,287 Epoch[4] Batch [570]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.172205,	
2017-07-31 13:33:47,422 Epoch[4] Batch [580]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.171827,	
2017-07-31 13:33:51,384 Epoch[4] Batch [590]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.172511,	
2017-07-31 13:33:55,479 Epoch[4] Batch [600]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.172263,	
2017-07-31 13:33:59,483 Epoch[4] Batch [610]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.172200,	
2017-07-31 13:34:03,566 Epoch[4] Batch [620]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.172171,	
2017-07-31 13:34:07,627 Epoch[4] Batch [630]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.172592,	
2017-07-31 13:34:11,905 Epoch[4] Batch [640]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.172385,	
2017-07-31 13:34:15,908 Epoch[4] Batch [650]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.172552,	
2017-07-31 13:34:19,954 Epoch[4] Batch [660]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.172565,	
2017-07-31 13:34:23,998 Epoch[4] Batch [670]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.172611,	
2017-07-31 13:34:28,036 Epoch[4] Batch [680]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.172401,	
2017-07-31 13:34:32,318 Epoch[4] Batch [690]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.172267,	
2017-07-31 13:34:36,415 Epoch[4] Batch [700]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.171964,	
2017-07-31 13:34:40,463 Epoch[4] Batch [710]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.171646,	
2017-07-31 13:34:44,615 Epoch[4] Batch [720]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.171173,	
2017-07-31 13:34:48,871 Epoch[4] Batch [730]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.171149,	
2017-07-31 13:34:52,997 Epoch[4] Batch [740]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.170994,	
2017-07-31 13:34:57,109 Epoch[4] Batch [750]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.170880,	
2017-07-31 13:35:01,227 Epoch[4] Batch [760]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.170901,	
2017-07-31 13:35:05,396 Epoch[4] Batch [770]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.171114,	
2017-07-31 13:35:09,491 Epoch[4] Batch [780]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.171286,	
2017-07-31 13:35:13,628 Epoch[4] Batch [790]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.171468,	
2017-07-31 13:35:17,798 Epoch[4] Batch [800]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.171563,	
2017-07-31 13:35:21,984 Epoch[4] Batch [810]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.171249,	
2017-07-31 13:35:26,150 Epoch[4] Batch [820]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.171207,	
2017-07-31 13:35:30,285 Epoch[4] Batch [830]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.171615,	
2017-07-31 13:35:34,341 Epoch[4] Batch [840]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.172162,	
2017-07-31 13:35:38,302 Epoch[4] Batch [850]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.172322,	
2017-07-31 13:35:42,294 Epoch[4] Batch [860]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.172371,	
2017-07-31 13:35:46,403 Epoch[4] Batch [870]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.172587,	
2017-07-31 13:35:50,372 Epoch[4] Batch [880]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.172373,	
2017-07-31 13:35:54,448 Epoch[4] Batch [890]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.172533,	
2017-07-31 13:35:58,461 Epoch[4] Batch [900]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.172377,	
2017-07-31 13:36:02,604 Epoch[4] Batch [910]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.172524,	
2017-07-31 13:36:07,004 Epoch[4] Batch [920]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.172535,	
2017-07-31 13:36:11,107 Epoch[4] Batch [930]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.172797,	
2017-07-31 13:36:15,173 Epoch[4] Batch [940]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.173115,	
2017-07-31 13:36:19,391 Epoch[4] Batch [950]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.173579,	
2017-07-31 13:36:23,667 Epoch[4] Batch [960]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.173775,	
2017-07-31 13:36:27,892 Epoch[4] Batch [970]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.174128,	
2017-07-31 13:36:31,937 Epoch[4] Batch [980]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.174046,	
2017-07-31 13:36:36,054 Epoch[4] Batch [990]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.174109,	
2017-07-31 13:36:40,234 Epoch[4] Batch [1000]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.174022,	
2017-07-31 13:36:44,414 Epoch[4] Batch [1010]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.174168,	
2017-07-31 13:36:48,448 Epoch[4] Batch [1020]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.174348,	
2017-07-31 13:36:52,559 Epoch[4] Batch [1030]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.174443,	
2017-07-31 13:36:56,681 Epoch[4] Batch [1040]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.174627,	
2017-07-31 13:37:00,916 Epoch[4] Batch [1050]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.174670,	
2017-07-31 13:37:04,994 Epoch[4] Batch [1060]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.174680,	
2017-07-31 13:37:09,225 Epoch[4] Batch [1070]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.174745,	
2017-07-31 13:37:13,375 Epoch[4] Batch [1080]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.174734,	
2017-07-31 13:37:17,430 Epoch[4] Batch [1090]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.174592,	
2017-07-31 13:37:21,415 Epoch[4] Batch [1100]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.174383,	
2017-07-31 13:37:25,428 Epoch[4] Batch [1110]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.174263,	
2017-07-31 13:37:29,425 Epoch[4] Batch [1120]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.174101,	
2017-07-31 13:37:33,486 Epoch[4] Batch [1130]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.173983,	
2017-07-31 13:37:37,456 Epoch[4] Batch [1140]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.173825,	
2017-07-31 13:37:42,099 Epoch[4] Batch [1150]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.173989,	
2017-07-31 13:37:46,069 Epoch[4] Batch [1160]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.173828,	
2017-07-31 13:37:50,867 Epoch[4] Batch [1170]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.173758,	
2017-07-31 13:37:55,202 Epoch[4] Batch [1180]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.173512,	
2017-07-31 13:37:59,216 Epoch[4] Batch [1190]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.173353,	
2017-07-31 13:38:03,615 Epoch[4] Batch [1200]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.173171,	
2017-07-31 13:38:07,819 Epoch[4] Batch [1210]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.173143,	
2017-07-31 13:38:12,927 Epoch[4] Batch [1220]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.173292,	
2017-07-31 13:38:17,067 Epoch[4] Batch [1230]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.173399,	
2017-07-31 13:38:21,599 Epoch[4] Batch [1240]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.173612,	
2017-07-31 13:38:26,244 Epoch[4] Batch [1250]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.173651,	
2017-07-31 13:38:30,127 Epoch[4] Batch [1260]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.173681,	
2017-07-31 13:38:34,201 Epoch[4] Batch [1270]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.173629,	
2017-07-31 13:38:38,346 Epoch[4] Batch [1280]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.173471,	
2017-07-31 13:38:42,537 Epoch[4] Batch [1290]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.173243,	
2017-07-31 13:38:46,583 Epoch[4] Batch [1300]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.173075,	
2017-07-31 13:38:50,546 Epoch[4] Batch [1310]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.173021,	
2017-07-31 13:38:54,775 Epoch[4] Batch [1320]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.173032,	
2017-07-31 13:38:58,887 Epoch[4] Batch [1330]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.172881,	
2017-07-31 13:39:03,102 Epoch[4] Batch [1340]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.172881,	
2017-07-31 13:39:07,223 Epoch[4] Batch [1350]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.172736,	
2017-07-31 13:39:11,290 Epoch[4] Batch [1360]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.172643,	
2017-07-31 13:39:15,421 Epoch[4] Batch [1370]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.172670,	
2017-07-31 13:39:19,596 Epoch[4] Batch [1380]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.172468,	
2017-07-31 13:39:23,813 Epoch[4] Batch [1390]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.172433,	
2017-07-31 13:39:27,781 Epoch[4] Batch [1400]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.172244,	
2017-07-31 13:39:31,920 Epoch[4] Batch [1410]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.172318,	
2017-07-31 13:39:36,085 Epoch[4] Batch [1420]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.172546,	
2017-07-31 13:39:40,258 Epoch[4] Batch [1430]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.172869,	
2017-07-31 13:39:44,385 Epoch[4] Batch [1440]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.172735,	
2017-07-31 13:39:48,529 Epoch[4] Batch [1450]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.172701,	
2017-07-31 13:39:52,722 Epoch[4] Batch [1460]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.172625,	
2017-07-31 13:39:56,876 Epoch[4] Batch [1470]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.172422,	
2017-07-31 13:40:00,992 Epoch[4] Batch [1480]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.172594,	
2017-07-31 13:40:03,421 Epoch[4] Train-FCNLogLoss=0.172553
2017-07-31 13:40:03,421 Epoch[4] Time cost=619.857
2017-07-31 13:40:04,564 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.params"
2017-07-31 13:40:08,790 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.states"
2017-07-31 13:40:13,741 Epoch[5] Batch [10]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.160795,	
2017-07-31 13:40:17,767 Epoch[5] Batch [20]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.144830,	
2017-07-31 13:40:22,016 Epoch[5] Batch [30]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.152041,	
2017-07-31 13:40:26,283 Epoch[5] Batch [40]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.148213,	
2017-07-31 13:40:30,426 Epoch[5] Batch [50]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.147301,	
2017-07-31 13:40:34,686 Epoch[5] Batch [60]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.151996,	
2017-07-31 13:40:38,781 Epoch[5] Batch [70]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.157196,	
2017-07-31 13:40:42,830 Epoch[5] Batch [80]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.158243,	
2017-07-31 13:40:46,855 Epoch[5] Batch [90]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.156928,	
2017-07-31 13:40:51,008 Epoch[5] Batch [100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.158124,	
2017-07-31 13:40:55,081 Epoch[5] Batch [110]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.158991,	
2017-07-31 13:40:59,142 Epoch[5] Batch [120]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.159687,	
2017-07-31 13:41:03,234 Epoch[5] Batch [130]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.160646,	
2017-07-31 13:41:07,338 Epoch[5] Batch [140]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.161618,	
2017-07-31 13:41:11,472 Epoch[5] Batch [150]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.161869,	
2017-07-31 13:41:15,517 Epoch[5] Batch [160]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.162308,	
2017-07-31 13:41:19,536 Epoch[5] Batch [170]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.163273,	
2017-07-31 13:41:23,643 Epoch[5] Batch [180]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.163507,	
2017-07-31 13:41:27,615 Epoch[5] Batch [190]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.162133,	
2017-07-31 13:41:31,734 Epoch[5] Batch [200]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.162460,	
2017-07-31 13:41:35,826 Epoch[5] Batch [210]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.161058,	
2017-07-31 13:41:39,756 Epoch[5] Batch [220]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.161075,	
2017-07-31 13:41:43,820 Epoch[5] Batch [230]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.160930,	
2017-07-31 13:41:47,866 Epoch[5] Batch [240]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.160170,	
2017-07-31 13:41:52,146 Epoch[5] Batch [250]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.160937,	
2017-07-31 13:41:56,185 Epoch[5] Batch [260]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.160255,	
2017-07-31 13:42:00,310 Epoch[5] Batch [270]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.160432,	
2017-07-31 13:42:04,301 Epoch[5] Batch [280]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.160627,	
2017-07-31 13:42:08,392 Epoch[5] Batch [290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.160912,	
2017-07-31 13:42:12,399 Epoch[5] Batch [300]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.161638,	
2017-07-31 13:42:16,520 Epoch[5] Batch [310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.161640,	
2017-07-31 13:42:20,577 Epoch[5] Batch [320]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.161513,	
2017-07-31 13:42:24,600 Epoch[5] Batch [330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.161330,	
2017-07-31 13:42:28,643 Epoch[5] Batch [340]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.161753,	
2017-07-31 13:42:32,697 Epoch[5] Batch [350]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.162194,	
2017-07-31 13:42:36,871 Epoch[5] Batch [360]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.163021,	
2017-07-31 13:42:41,067 Epoch[5] Batch [370]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.164067,	
2017-07-31 13:42:45,481 Epoch[5] Batch [380]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.163747,	
2017-07-31 13:42:49,625 Epoch[5] Batch [390]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.165103,	
2017-07-31 13:42:53,680 Epoch[5] Batch [400]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.165238,	
2017-07-31 13:42:57,841 Epoch[5] Batch [410]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.165030,	
2017-07-31 13:43:02,442 Epoch[5] Batch [420]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.165727,	
2017-07-31 13:43:06,675 Epoch[5] Batch [430]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.165727,	
2017-07-31 13:43:10,976 Epoch[5] Batch [440]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.165688,	
2017-07-31 13:43:15,262 Epoch[5] Batch [450]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.165941,	
2017-07-31 13:43:19,450 Epoch[5] Batch [460]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.165717,	
2017-07-31 13:43:23,558 Epoch[5] Batch [470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.165727,	
2017-07-31 13:43:27,676 Epoch[5] Batch [480]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.166067,	
2017-07-31 13:43:32,152 Epoch[5] Batch [490]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.167205,	
2017-07-31 13:43:36,509 Epoch[5] Batch [500]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.167164,	
2017-07-31 13:43:40,502 Epoch[5] Batch [510]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.167239,	
2017-07-31 13:43:44,655 Epoch[5] Batch [520]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.167336,	
2017-07-31 13:43:48,804 Epoch[5] Batch [530]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.167086,	
2017-07-31 13:43:52,980 Epoch[5] Batch [540]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.166983,	
2017-07-31 13:43:57,166 Epoch[5] Batch [550]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.166645,	
2017-07-31 13:44:01,165 Epoch[5] Batch [560]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.166708,	
2017-07-31 13:44:05,221 Epoch[5] Batch [570]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.166396,	
2017-07-31 13:44:09,262 Epoch[5] Batch [580]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.166212,	
2017-07-31 13:44:13,404 Epoch[5] Batch [590]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.165946,	
2017-07-31 13:44:17,708 Epoch[5] Batch [600]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.165834,	
2017-07-31 13:44:21,952 Epoch[5] Batch [610]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.165146,	
2017-07-31 13:44:26,024 Epoch[5] Batch [620]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.164627,	
2017-07-31 13:44:30,097 Epoch[5] Batch [630]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.164318,	
2017-07-31 13:44:34,408 Epoch[5] Batch [640]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.164228,	
2017-07-31 13:44:38,384 Epoch[5] Batch [650]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.163907,	
2017-07-31 13:44:42,444 Epoch[5] Batch [660]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.163931,	
2017-07-31 13:44:46,656 Epoch[5] Batch [670]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.163668,	
2017-07-31 13:44:50,796 Epoch[5] Batch [680]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.163703,	
2017-07-31 13:44:54,848 Epoch[5] Batch [690]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.163754,	
2017-07-31 13:44:58,950 Epoch[5] Batch [700]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.163846,	
2017-07-31 13:45:03,205 Epoch[5] Batch [710]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.163446,	
2017-07-31 13:45:07,454 Epoch[5] Batch [720]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.163170,	
2017-07-31 13:45:11,671 Epoch[5] Batch [730]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.162826,	
2017-07-31 13:45:15,890 Epoch[5] Batch [740]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.163097,	
2017-07-31 13:45:19,964 Epoch[5] Batch [750]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.162708,	
2017-07-31 13:45:23,953 Epoch[5] Batch [760]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.162611,	
2017-07-31 13:45:28,149 Epoch[5] Batch [770]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.162302,	
2017-07-31 13:45:32,305 Epoch[5] Batch [780]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.162180,	
2017-07-31 13:45:36,424 Epoch[5] Batch [790]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.162473,	
2017-07-31 13:45:40,568 Epoch[5] Batch [800]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.162779,	
2017-07-31 13:45:44,778 Epoch[5] Batch [810]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.162913,	
2017-07-31 13:45:48,865 Epoch[5] Batch [820]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.163267,	
2017-07-31 13:45:52,946 Epoch[5] Batch [830]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.162943,	
2017-07-31 13:45:57,149 Epoch[5] Batch [840]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.162996,	
2017-07-31 13:46:01,415 Epoch[5] Batch [850]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.163031,	
2017-07-31 13:46:05,612 Epoch[5] Batch [860]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.162872,	
2017-07-31 13:46:09,704 Epoch[5] Batch [870]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.162828,	
2017-07-31 13:46:13,735 Epoch[5] Batch [880]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.162782,	
2017-07-31 13:46:17,852 Epoch[5] Batch [890]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.162629,	
2017-07-31 13:46:21,917 Epoch[5] Batch [900]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.162903,	
2017-07-31 13:46:26,209 Epoch[5] Batch [910]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.163169,	
2017-07-31 13:46:30,409 Epoch[5] Batch [920]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.163212,	
2017-07-31 13:46:34,708 Epoch[5] Batch [930]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.163139,	
2017-07-31 13:46:38,850 Epoch[5] Batch [940]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.163233,	
2017-07-31 13:46:42,938 Epoch[5] Batch [950]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.163413,	
2017-07-31 13:46:47,006 Epoch[5] Batch [960]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.163798,	
2017-07-31 13:46:51,369 Epoch[5] Batch [970]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.163793,	
2017-07-31 13:46:55,534 Epoch[5] Batch [980]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.163875,	
2017-07-31 13:46:59,609 Epoch[5] Batch [990]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.163768,	
2017-07-31 13:47:03,744 Epoch[5] Batch [1000]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.163637,	
2017-07-31 13:47:07,786 Epoch[5] Batch [1010]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.163650,	
2017-07-31 13:47:11,912 Epoch[5] Batch [1020]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.163484,	
2017-07-31 13:47:16,104 Epoch[5] Batch [1030]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.163459,	
2017-07-31 13:47:20,149 Epoch[5] Batch [1040]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.163748,	
2017-07-31 13:47:24,497 Epoch[5] Batch [1050]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.164196,	
2017-07-31 13:47:28,905 Epoch[5] Batch [1060]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.164277,	
2017-07-31 13:47:32,902 Epoch[5] Batch [1070]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.164366,	
2017-07-31 13:47:36,970 Epoch[5] Batch [1080]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.164736,	
2017-07-31 13:47:41,222 Epoch[5] Batch [1090]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.164771,	
2017-07-31 13:47:45,400 Epoch[5] Batch [1100]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.164625,	
2017-07-31 13:47:49,411 Epoch[5] Batch [1110]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.164809,	
2017-07-31 13:47:53,690 Epoch[5] Batch [1120]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.164978,	
2017-07-31 13:47:57,910 Epoch[5] Batch [1130]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.165342,	
2017-07-31 13:48:02,236 Epoch[5] Batch [1140]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.165573,	
2017-07-31 13:48:06,504 Epoch[5] Batch [1150]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.165455,	
2017-07-31 13:48:10,624 Epoch[5] Batch [1160]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.165421,	
2017-07-31 13:48:14,709 Epoch[5] Batch [1170]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.165396,	
2017-07-31 13:48:18,889 Epoch[5] Batch [1180]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.165268,	
2017-07-31 13:48:22,850 Epoch[5] Batch [1190]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.165160,	
2017-07-31 13:48:26,892 Epoch[5] Batch [1200]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.165216,	
2017-07-31 13:48:31,222 Epoch[5] Batch [1210]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.165111,	
2017-07-31 13:48:35,507 Epoch[5] Batch [1220]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.165328,	
2017-07-31 13:48:39,504 Epoch[5] Batch [1230]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.165397,	
2017-07-31 13:48:43,556 Epoch[5] Batch [1240]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.165430,	
2017-07-31 13:48:47,682 Epoch[5] Batch [1250]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.165435,	
2017-07-31 13:48:51,886 Epoch[5] Batch [1260]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.165350,	
2017-07-31 13:48:55,843 Epoch[5] Batch [1270]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.165335,	
2017-07-31 13:48:59,776 Epoch[5] Batch [1280]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.165611,	
2017-07-31 13:49:03,761 Epoch[5] Batch [1290]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.165638,	
2017-07-31 13:49:07,802 Epoch[5] Batch [1300]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.165509,	
2017-07-31 13:49:11,995 Epoch[5] Batch [1310]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.165486,	
2017-07-31 13:49:16,072 Epoch[5] Batch [1320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.165492,	
2017-07-31 13:49:20,062 Epoch[5] Batch [1330]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.165480,	
2017-07-31 13:49:24,275 Epoch[5] Batch [1340]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.165376,	
2017-07-31 13:49:28,477 Epoch[5] Batch [1350]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.165372,	
2017-07-31 13:49:32,699 Epoch[5] Batch [1360]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.165189,	
2017-07-31 13:49:36,860 Epoch[5] Batch [1370]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.165023,	
2017-07-31 13:49:40,998 Epoch[5] Batch [1380]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.164850,	
2017-07-31 13:49:44,976 Epoch[5] Batch [1390]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.164939,	
2017-07-31 13:49:49,190 Epoch[5] Batch [1400]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.164928,	
2017-07-31 13:49:53,217 Epoch[5] Batch [1410]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.164890,	
2017-07-31 13:49:57,279 Epoch[5] Batch [1420]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.164894,	
2017-07-31 13:50:01,532 Epoch[5] Batch [1430]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.164921,	
2017-07-31 13:50:05,697 Epoch[5] Batch [1440]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.164890,	
2017-07-31 13:50:09,915 Epoch[5] Batch [1450]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.164821,	
2017-07-31 13:50:14,305 Epoch[5] Batch [1460]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.164653,	
2017-07-31 13:50:18,452 Epoch[5] Batch [1470]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.164713,	
2017-07-31 13:50:22,669 Epoch[5] Batch [1480]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.164741,	
2017-07-31 13:50:25,262 Epoch[5] Train-FCNLogLoss=0.164656
2017-07-31 13:50:25,262 Epoch[5] Time cost=616.471
2017-07-31 13:50:26,400 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.params"
2017-07-31 13:50:30,648 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.states"
2017-07-31 13:50:35,454 Epoch[6] Batch [10]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.154685,	
2017-07-31 13:50:39,607 Epoch[6] Batch [20]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.164266,	
2017-07-31 13:50:43,755 Epoch[6] Batch [30]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.160222,	
2017-07-31 13:50:47,825 Epoch[6] Batch [40]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.155461,	
2017-07-31 13:50:51,919 Epoch[6] Batch [50]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.152914,	
2017-07-31 13:50:56,079 Epoch[6] Batch [60]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.152410,	
2017-07-31 13:51:00,149 Epoch[6] Batch [70]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.157811,	
2017-07-31 13:51:04,384 Epoch[6] Batch [80]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.157032,	
2017-07-31 13:51:08,431 Epoch[6] Batch [90]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.153886,	
2017-07-31 13:51:12,494 Epoch[6] Batch [100]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.154045,	
2017-07-31 13:51:16,683 Epoch[6] Batch [110]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.151856,	
2017-07-31 13:51:20,712 Epoch[6] Batch [120]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.153581,	
2017-07-31 13:51:24,727 Epoch[6] Batch [130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.153595,	
2017-07-31 13:51:28,876 Epoch[6] Batch [140]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.154395,	
2017-07-31 13:51:33,015 Epoch[6] Batch [150]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.153342,	
2017-07-31 13:51:37,073 Epoch[6] Batch [160]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.152300,	
2017-07-31 13:51:41,472 Epoch[6] Batch [170]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.151925,	
2017-07-31 13:51:45,582 Epoch[6] Batch [180]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.151980,	
2017-07-31 13:51:49,707 Epoch[6] Batch [190]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.152573,	
2017-07-31 13:51:53,928 Epoch[6] Batch [200]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.153195,	
2017-07-31 13:51:58,028 Epoch[6] Batch [210]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.155030,	
2017-07-31 13:52:02,074 Epoch[6] Batch [220]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.154662,	
2017-07-31 13:52:06,181 Epoch[6] Batch [230]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.153075,	
2017-07-31 13:52:10,246 Epoch[6] Batch [240]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.152988,	
2017-07-31 13:52:14,276 Epoch[6] Batch [250]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.152842,	
2017-07-31 13:52:18,236 Epoch[6] Batch [260]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.152745,	
2017-07-31 13:52:22,432 Epoch[6] Batch [270]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.153697,	
2017-07-31 13:52:26,527 Epoch[6] Batch [280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.153421,	
2017-07-31 13:52:30,599 Epoch[6] Batch [290]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.154298,	
2017-07-31 13:52:34,847 Epoch[6] Batch [300]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.155079,	
2017-07-31 13:52:39,226 Epoch[6] Batch [310]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.155141,	
2017-07-31 13:52:43,190 Epoch[6] Batch [320]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.154880,	
2017-07-31 13:52:47,490 Epoch[6] Batch [330]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.154912,	
2017-07-31 13:52:51,579 Epoch[6] Batch [340]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.154736,	
2017-07-31 13:52:55,576 Epoch[6] Batch [350]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.154257,	
2017-07-31 13:52:59,652 Epoch[6] Batch [360]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.153609,	
2017-07-31 13:53:03,949 Epoch[6] Batch [370]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.153697,	
2017-07-31 13:53:08,056 Epoch[6] Batch [380]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.153082,	
2017-07-31 13:53:12,189 Epoch[6] Batch [390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.153257,	
2017-07-31 13:53:16,285 Epoch[6] Batch [400]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.152909,	
2017-07-31 13:53:20,426 Epoch[6] Batch [410]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.152641,	
2017-07-31 13:53:24,631 Epoch[6] Batch [420]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.152375,	
2017-07-31 13:53:28,622 Epoch[6] Batch [430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.152313,	
2017-07-31 13:53:32,616 Epoch[6] Batch [440]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.152556,	
2017-07-31 13:53:36,695 Epoch[6] Batch [450]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.152507,	
2017-07-31 13:53:40,958 Epoch[6] Batch [460]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.152209,	
2017-07-31 13:53:44,981 Epoch[6] Batch [470]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.152624,	
2017-07-31 13:53:49,123 Epoch[6] Batch [480]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.152578,	
2017-07-31 13:53:53,221 Epoch[6] Batch [490]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.152626,	
2017-07-31 13:53:57,267 Epoch[6] Batch [500]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.152408,	
2017-07-31 13:54:01,839 Epoch[6] Batch [510]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.152485,	
2017-07-31 13:54:06,434 Epoch[6] Batch [520]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.152243,	
2017-07-31 13:54:10,706 Epoch[6] Batch [530]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.152330,	
2017-07-31 13:54:14,947 Epoch[6] Batch [540]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.152200,	
2017-07-31 13:54:20,649 Epoch[6] Batch [550]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.151994,	
2017-07-31 13:54:24,717 Epoch[6] Batch [560]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.152005,	
2017-07-31 13:54:28,879 Epoch[6] Batch [570]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.151624,	
2017-07-31 13:54:32,818 Epoch[6] Batch [580]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.151515,	
2017-07-31 13:54:36,948 Epoch[6] Batch [590]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.151089,	
2017-07-31 13:54:41,222 Epoch[6] Batch [600]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.151420,	
2017-07-31 13:54:46,479 Epoch[6] Batch [610]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.151295,	
2017-07-31 13:54:51,051 Epoch[6] Batch [620]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.151417,	
2017-07-31 13:54:54,999 Epoch[6] Batch [630]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.151140,	
2017-07-31 13:54:58,929 Epoch[6] Batch [640]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.151190,	
2017-07-31 13:55:04,189 Epoch[6] Batch [650]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.151212,	
2017-07-31 13:55:08,976 Epoch[6] Batch [660]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.150943,	
2017-07-31 13:55:14,062 Epoch[6] Batch [670]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.151150,	
2017-07-31 13:55:18,158 Epoch[6] Batch [680]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.151188,	
2017-07-31 13:55:22,200 Epoch[6] Batch [690]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.151280,	
2017-07-31 13:55:26,379 Epoch[6] Batch [700]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.151245,	
2017-07-31 13:55:30,383 Epoch[6] Batch [710]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.151410,	
2017-07-31 13:55:34,636 Epoch[6] Batch [720]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.151759,	
2017-07-31 13:55:38,719 Epoch[6] Batch [730]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.151774,	
2017-07-31 13:55:42,860 Epoch[6] Batch [740]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.151874,	
2017-07-31 13:55:46,882 Epoch[6] Batch [750]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.152147,	
2017-07-31 13:55:50,985 Epoch[6] Batch [760]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.151937,	
2017-07-31 13:55:55,067 Epoch[6] Batch [770]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.152056,	
2017-07-31 13:55:59,201 Epoch[6] Batch [780]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.152277,	
2017-07-31 13:56:03,710 Epoch[6] Batch [790]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.152173,	
2017-07-31 13:56:07,736 Epoch[6] Batch [800]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.152487,	
2017-07-31 13:56:11,822 Epoch[6] Batch [810]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.152328,	
2017-07-31 13:56:15,841 Epoch[6] Batch [820]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.152538,	
2017-07-31 13:56:19,854 Epoch[6] Batch [830]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.152616,	
2017-07-31 13:56:23,963 Epoch[6] Batch [840]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.152833,	
2017-07-31 13:56:28,116 Epoch[6] Batch [850]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.152927,	
2017-07-31 13:56:32,253 Epoch[6] Batch [860]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.152962,	
2017-07-31 13:56:36,481 Epoch[6] Batch [870]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.153430,	
2017-07-31 13:56:40,745 Epoch[6] Batch [880]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.153599,	
2017-07-31 13:56:44,802 Epoch[6] Batch [890]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.153638,	
2017-07-31 13:56:48,952 Epoch[6] Batch [900]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.153822,	
2017-07-31 13:56:52,994 Epoch[6] Batch [910]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.153832,	
2017-07-31 13:56:57,152 Epoch[6] Batch [920]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.153840,	
2017-07-31 13:57:01,379 Epoch[6] Batch [930]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.153777,	
2017-07-31 13:57:05,424 Epoch[6] Batch [940]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.153641,	
2017-07-31 13:57:09,698 Epoch[6] Batch [950]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.153516,	
2017-07-31 13:57:13,865 Epoch[6] Batch [960]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.153417,	
2017-07-31 13:57:18,005 Epoch[6] Batch [970]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.153314,	
2017-07-31 13:57:22,239 Epoch[6] Batch [980]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.153234,	
2017-07-31 13:57:26,369 Epoch[6] Batch [990]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.153145,	
2017-07-31 13:57:30,472 Epoch[6] Batch [1000]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.153069,	
2017-07-31 13:57:34,591 Epoch[6] Batch [1010]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.153206,	
2017-07-31 13:57:38,721 Epoch[6] Batch [1020]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.153248,	
2017-07-31 13:57:43,008 Epoch[6] Batch [1030]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.153148,	
2017-07-31 13:57:47,147 Epoch[6] Batch [1040]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.153151,	
2017-07-31 13:57:51,786 Epoch[6] Batch [1050]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.153048,	
2017-07-31 13:57:55,960 Epoch[6] Batch [1060]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.153043,	
2017-07-31 13:58:00,399 Epoch[6] Batch [1070]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.152941,	
2017-07-31 13:58:04,564 Epoch[6] Batch [1080]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.152907,	
2017-07-31 13:58:08,730 Epoch[6] Batch [1090]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.152916,	
2017-07-31 13:58:12,654 Epoch[6] Batch [1100]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.152816,	
2017-07-31 13:58:16,714 Epoch[6] Batch [1110]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.152929,	
2017-07-31 13:58:20,716 Epoch[6] Batch [1120]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.152991,	
2017-07-31 13:58:24,831 Epoch[6] Batch [1130]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.153145,	
2017-07-31 13:58:28,961 Epoch[6] Batch [1140]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.153434,	
2017-07-31 13:58:33,107 Epoch[6] Batch [1150]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.153751,	
2017-07-31 13:58:37,246 Epoch[6] Batch [1160]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.153803,	
2017-07-31 13:58:41,457 Epoch[6] Batch [1170]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.154020,	
2017-07-31 13:58:45,546 Epoch[6] Batch [1180]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.153957,	
2017-07-31 13:58:49,644 Epoch[6] Batch [1190]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.153938,	
2017-07-31 13:58:53,758 Epoch[6] Batch [1200]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.153890,	
2017-07-31 13:58:57,994 Epoch[6] Batch [1210]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.154131,	
2017-07-31 13:59:02,153 Epoch[6] Batch [1220]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.154187,	
2017-07-31 13:59:06,102 Epoch[6] Batch [1230]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.154131,	
2017-07-31 13:59:10,100 Epoch[6] Batch [1240]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.154023,	
2017-07-31 13:59:14,201 Epoch[6] Batch [1250]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.154274,	
2017-07-31 13:59:18,232 Epoch[6] Batch [1260]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.154333,	
2017-07-31 13:59:22,415 Epoch[6] Batch [1270]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.154483,	
2017-07-31 13:59:26,472 Epoch[6] Batch [1280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.154412,	
2017-07-31 13:59:30,497 Epoch[6] Batch [1290]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.154496,	
2017-07-31 13:59:34,652 Epoch[6] Batch [1300]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.154469,	
2017-07-31 13:59:38,770 Epoch[6] Batch [1310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.154391,	
2017-07-31 13:59:42,847 Epoch[6] Batch [1320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.154412,	
2017-07-31 13:59:46,926 Epoch[6] Batch [1330]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.154694,	
2017-07-31 13:59:51,715 Epoch[6] Batch [1340]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.154794,	
2017-07-31 13:59:56,508 Epoch[6] Batch [1350]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.154760,	
2017-07-31 14:00:00,843 Epoch[6] Batch [1360]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.154660,	
2017-07-31 14:00:05,030 Epoch[6] Batch [1370]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.154756,	
2017-07-31 14:00:10,369 Epoch[6] Batch [1380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.154925,	
2017-07-31 14:00:14,799 Epoch[6] Batch [1390]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.155186,	
2017-07-31 14:00:19,343 Epoch[6] Batch [1400]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.155177,	
2017-07-31 14:00:23,438 Epoch[6] Batch [1410]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.155309,	
2017-07-31 14:00:28,110 Epoch[6] Batch [1420]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.155494,	
2017-07-31 14:00:32,102 Epoch[6] Batch [1430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.155657,	
2017-07-31 14:00:36,386 Epoch[6] Batch [1440]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.156598,	
2017-07-31 14:00:40,640 Epoch[6] Batch [1450]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.157457,	
2017-07-31 14:00:44,704 Epoch[6] Batch [1460]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.158276,	
2017-07-31 14:00:48,723 Epoch[6] Batch [1470]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.158495,	
2017-07-31 14:00:52,856 Epoch[6] Batch [1480]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.158809,	
2017-07-31 14:00:55,247 Epoch[6] Train-FCNLogLoss=0.158917
2017-07-31 14:00:55,247 Epoch[6] Time cost=624.599
2017-07-31 14:00:56,154 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.params"
2017-07-31 14:00:59,361 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.states"
2017-07-31 14:01:04,963 Epoch[7] Batch [10]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.153732,	
2017-07-31 14:01:09,603 Epoch[7] Batch [20]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.156723,	
2017-07-31 14:01:14,142 Epoch[7] Batch [30]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.159486,	
2017-07-31 14:01:18,158 Epoch[7] Batch [40]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.157426,	
2017-07-31 14:01:22,518 Epoch[7] Batch [50]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.163196,	
2017-07-31 14:01:28,046 Epoch[7] Batch [60]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.161204,	
2017-07-31 14:01:32,306 Epoch[7] Batch [70]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.163395,	
2017-07-31 14:01:36,387 Epoch[7] Batch [80]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.165431,	
2017-07-31 14:01:40,385 Epoch[7] Batch [90]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.163655,	
2017-07-31 14:01:44,378 Epoch[7] Batch [100]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.165268,	
2017-07-31 14:01:48,389 Epoch[7] Batch [110]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.164899,	
2017-07-31 14:01:52,262 Epoch[7] Batch [120]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.165535,	
2017-07-31 14:01:56,331 Epoch[7] Batch [130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.166980,	
2017-07-31 14:02:00,226 Epoch[7] Batch [140]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.165997,	
2017-07-31 14:02:04,182 Epoch[7] Batch [150]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.166452,	
2017-07-31 14:02:08,172 Epoch[7] Batch [160]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.166845,	
2017-07-31 14:02:12,190 Epoch[7] Batch [170]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.167789,	
2017-07-31 14:02:16,322 Epoch[7] Batch [180]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.166758,	
2017-07-31 14:02:20,245 Epoch[7] Batch [190]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.166998,	
2017-07-31 14:02:24,381 Epoch[7] Batch [200]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.165700,	
2017-07-31 14:02:28,552 Epoch[7] Batch [210]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.164592,	
2017-07-31 14:02:32,528 Epoch[7] Batch [220]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.166053,	
2017-07-31 14:02:36,653 Epoch[7] Batch [230]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.165683,	
2017-07-31 14:02:40,659 Epoch[7] Batch [240]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.164707,	
2017-07-31 14:02:44,595 Epoch[7] Batch [250]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.163638,	
2017-07-31 14:02:48,497 Epoch[7] Batch [260]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.163588,	
2017-07-31 14:02:52,564 Epoch[7] Batch [270]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.163566,	
2017-07-31 14:02:56,436 Epoch[7] Batch [280]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.163019,	
2017-07-31 14:03:00,385 Epoch[7] Batch [290]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.163424,	
2017-07-31 14:03:04,716 Epoch[7] Batch [300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.163422,	
2017-07-31 14:03:08,756 Epoch[7] Batch [310]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.163218,	
2017-07-31 14:03:12,909 Epoch[7] Batch [320]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.162497,	
2017-07-31 14:03:16,900 Epoch[7] Batch [330]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.161743,	
2017-07-31 14:03:20,966 Epoch[7] Batch [340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.161184,	
2017-07-31 14:03:25,003 Epoch[7] Batch [350]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.160924,	
2017-07-31 14:03:29,086 Epoch[7] Batch [360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.160532,	
2017-07-31 14:03:33,087 Epoch[7] Batch [370]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.160133,	
2017-07-31 14:03:37,153 Epoch[7] Batch [380]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.159801,	
2017-07-31 14:03:41,083 Epoch[7] Batch [390]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.159322,	
2017-07-31 14:03:45,016 Epoch[7] Batch [400]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.159445,	
2017-07-31 14:03:48,944 Epoch[7] Batch [410]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.159167,	
2017-07-31 14:03:52,979 Epoch[7] Batch [420]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.158770,	
2017-07-31 14:03:57,042 Epoch[7] Batch [430]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.157804,	
2017-07-31 14:04:00,964 Epoch[7] Batch [440]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.157941,	
2017-07-31 14:04:04,976 Epoch[7] Batch [450]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.157650,	
2017-07-31 14:04:08,842 Epoch[7] Batch [460]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.157358,	
2017-07-31 14:04:13,182 Epoch[7] Batch [470]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.156944,	
2017-07-31 14:04:17,217 Epoch[7] Batch [480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.156627,	
2017-07-31 14:04:21,124 Epoch[7] Batch [490]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.156255,	
2017-07-31 14:04:25,077 Epoch[7] Batch [500]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.156040,	
2017-07-31 14:04:29,220 Epoch[7] Batch [510]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.155752,	
2017-07-31 14:04:33,177 Epoch[7] Batch [520]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.155890,	
2017-07-31 14:04:37,129 Epoch[7] Batch [530]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.155579,	
2017-07-31 14:04:41,075 Epoch[7] Batch [540]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.155834,	
2017-07-31 14:04:45,285 Epoch[7] Batch [550]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.155569,	
2017-07-31 14:04:49,289 Epoch[7] Batch [560]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.155417,	
2017-07-31 14:04:53,562 Epoch[7] Batch [570]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.155797,	
2017-07-31 14:04:57,662 Epoch[7] Batch [580]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.155636,	
2017-07-31 14:05:01,719 Epoch[7] Batch [590]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.155352,	
2017-07-31 14:05:05,663 Epoch[7] Batch [600]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.155349,	
2017-07-31 14:05:09,806 Epoch[7] Batch [610]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.155645,	
2017-07-31 14:05:13,786 Epoch[7] Batch [620]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.155333,	
2017-07-31 14:05:17,860 Epoch[7] Batch [630]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.155461,	
2017-07-31 14:05:21,881 Epoch[7] Batch [640]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.155184,	
2017-07-31 14:05:25,728 Epoch[7] Batch [650]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.154976,	
2017-07-31 14:05:29,667 Epoch[7] Batch [660]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.154695,	
2017-07-31 14:05:33,857 Epoch[7] Batch [670]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.154488,	
2017-07-31 14:05:38,087 Epoch[7] Batch [680]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.154308,	
2017-07-31 14:05:42,122 Epoch[7] Batch [690]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.154208,	
2017-07-31 14:05:46,465 Epoch[7] Batch [700]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.154233,	
2017-07-31 14:05:50,612 Epoch[7] Batch [710]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.154430,	
2017-07-31 14:05:54,601 Epoch[7] Batch [720]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.154196,	
2017-07-31 14:05:58,430 Epoch[7] Batch [730]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.154294,	
2017-07-31 14:06:02,380 Epoch[7] Batch [740]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.154198,	
2017-07-31 14:06:06,512 Epoch[7] Batch [750]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.154167,	
2017-07-31 14:06:10,568 Epoch[7] Batch [760]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.154320,	
2017-07-31 14:06:14,476 Epoch[7] Batch [770]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.153897,	
2017-07-31 14:06:18,370 Epoch[7] Batch [780]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.153962,	
2017-07-31 14:06:22,502 Epoch[7] Batch [790]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.154071,	
2017-07-31 14:06:26,561 Epoch[7] Batch [800]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.153908,	
2017-07-31 14:06:30,582 Epoch[7] Batch [810]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.153742,	
2017-07-31 14:06:34,608 Epoch[7] Batch [820]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.153852,	
2017-07-31 14:06:38,640 Epoch[7] Batch [830]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.154019,	
2017-07-31 14:06:42,684 Epoch[7] Batch [840]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.153956,	
2017-07-31 14:06:46,718 Epoch[7] Batch [850]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.153983,	
2017-07-31 14:06:50,733 Epoch[7] Batch [860]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.153767,	
2017-07-31 14:06:54,829 Epoch[7] Batch [870]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.153714,	
2017-07-31 14:06:58,785 Epoch[7] Batch [880]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.153687,	
2017-07-31 14:07:02,866 Epoch[7] Batch [890]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.153798,	
2017-07-31 14:07:06,899 Epoch[7] Batch [900]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.153686,	
2017-07-31 14:07:10,781 Epoch[7] Batch [910]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.153815,	
2017-07-31 14:07:14,856 Epoch[7] Batch [920]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.153865,	
2017-07-31 14:07:18,800 Epoch[7] Batch [930]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.154023,	
2017-07-31 14:07:22,734 Epoch[7] Batch [940]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.153913,	
2017-07-31 14:07:26,834 Epoch[7] Batch [950]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.153778,	
2017-07-31 14:07:30,880 Epoch[7] Batch [960]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.153812,	
2017-07-31 14:07:34,876 Epoch[7] Batch [970]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.153734,	
2017-07-31 14:07:38,797 Epoch[7] Batch [980]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.153651,	
2017-07-31 14:07:42,850 Epoch[7] Batch [990]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.153796,	
2017-07-31 14:07:46,941 Epoch[7] Batch [1000]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.153695,	
2017-07-31 14:07:50,965 Epoch[7] Batch [1010]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.153679,	
2017-07-31 14:07:54,999 Epoch[7] Batch [1020]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.153592,	
2017-07-31 14:07:58,972 Epoch[7] Batch [1030]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.153449,	
2017-07-31 14:08:02,993 Epoch[7] Batch [1040]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.153455,	
2017-07-31 14:08:07,018 Epoch[7] Batch [1050]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.153366,	
2017-07-31 14:08:11,149 Epoch[7] Batch [1060]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.153252,	
2017-07-31 14:08:15,108 Epoch[7] Batch [1070]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.153071,	
2017-07-31 14:08:19,215 Epoch[7] Batch [1080]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.153008,	
2017-07-31 14:08:23,272 Epoch[7] Batch [1090]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.153057,	
2017-07-31 14:08:27,427 Epoch[7] Batch [1100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.152947,	
2017-07-31 14:08:31,597 Epoch[7] Batch [1110]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.152944,	
2017-07-31 14:08:35,623 Epoch[7] Batch [1120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.152881,	
2017-07-31 14:08:39,695 Epoch[7] Batch [1130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.152850,	
2017-07-31 14:08:43,765 Epoch[7] Batch [1140]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.152792,	
2017-07-31 14:08:47,672 Epoch[7] Batch [1150]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.152924,	
2017-07-31 14:08:51,807 Epoch[7] Batch [1160]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.152811,	
2017-07-31 14:08:55,710 Epoch[7] Batch [1170]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.152759,	
2017-07-31 14:08:59,870 Epoch[7] Batch [1180]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.152604,	
2017-07-31 14:09:03,899 Epoch[7] Batch [1190]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.152684,	
2017-07-31 14:09:07,943 Epoch[7] Batch [1200]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.152641,	
2017-07-31 14:09:12,218 Epoch[7] Batch [1210]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.152515,	
2017-07-31 14:09:16,171 Epoch[7] Batch [1220]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.152708,	
2017-07-31 14:09:19,998 Epoch[7] Batch [1230]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.152700,	
2017-07-31 14:09:23,917 Epoch[7] Batch [1240]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.152793,	
2017-07-31 14:09:27,986 Epoch[7] Batch [1250]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.152787,	
2017-07-31 14:09:31,959 Epoch[7] Batch [1260]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.152833,	
2017-07-31 14:09:35,927 Epoch[7] Batch [1270]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.152724,	
2017-07-31 14:09:39,866 Epoch[7] Batch [1280]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.152760,	
2017-07-31 14:09:43,948 Epoch[7] Batch [1290]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.152775,	
2017-07-31 14:09:47,959 Epoch[7] Batch [1300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.152675,	
2017-07-31 14:09:52,036 Epoch[7] Batch [1310]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.152607,	
2017-07-31 14:09:56,112 Epoch[7] Batch [1320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.152604,	
2017-07-31 14:10:00,064 Epoch[7] Batch [1330]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.152536,	
2017-07-31 14:10:04,259 Epoch[7] Batch [1340]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.152612,	
2017-07-31 14:10:08,318 Epoch[7] Batch [1350]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.152736,	
2017-07-31 14:10:12,501 Epoch[7] Batch [1360]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.153135,	
2017-07-31 14:10:16,574 Epoch[7] Batch [1370]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.153363,	
2017-07-31 14:10:20,560 Epoch[7] Batch [1380]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.153786,	
2017-07-31 14:10:24,567 Epoch[7] Batch [1390]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.154373,	
2017-07-31 14:10:28,619 Epoch[7] Batch [1400]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.154526,	
2017-07-31 14:10:32,704 Epoch[7] Batch [1410]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.154588,	
2017-07-31 14:10:36,887 Epoch[7] Batch [1420]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.154537,	
2017-07-31 14:10:41,016 Epoch[7] Batch [1430]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.154670,	
2017-07-31 14:10:44,995 Epoch[7] Batch [1440]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.154816,	
2017-07-31 14:10:48,979 Epoch[7] Batch [1450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.154808,	
2017-07-31 14:10:53,115 Epoch[7] Batch [1460]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.154756,	
2017-07-31 14:10:57,088 Epoch[7] Batch [1470]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.154778,	
2017-07-31 14:11:01,051 Epoch[7] Batch [1480]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.154693,	
2017-07-31 14:11:03,509 Epoch[7] Train-FCNLogLoss=0.154811
2017-07-31 14:11:03,509 Epoch[7] Time cost=604.148
2017-07-31 14:11:04,345 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.params"
2017-07-31 14:11:07,623 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.states"
2017-07-31 14:11:12,247 Epoch[8] Batch [10]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.162121,	
2017-07-31 14:11:16,430 Epoch[8] Batch [20]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.162498,	
2017-07-31 14:11:20,422 Epoch[8] Batch [30]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.158365,	
2017-07-31 14:11:24,559 Epoch[8] Batch [40]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.157397,	
2017-07-31 14:11:28,567 Epoch[8] Batch [50]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.154298,	
2017-07-31 14:11:32,541 Epoch[8] Batch [60]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.154483,	
2017-07-31 14:11:36,609 Epoch[8] Batch [70]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.152625,	
2017-07-31 14:11:40,625 Epoch[8] Batch [80]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.152438,	
2017-07-31 14:11:44,646 Epoch[8] Batch [90]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.155331,	
2017-07-31 14:11:48,668 Epoch[8] Batch [100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.155755,	
2017-07-31 14:11:52,703 Epoch[8] Batch [110]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.153721,	
2017-07-31 14:11:56,792 Epoch[8] Batch [120]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.155556,	
2017-07-31 14:12:00,860 Epoch[8] Batch [130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.155419,	
2017-07-31 14:12:04,880 Epoch[8] Batch [140]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.157509,	
2017-07-31 14:12:08,940 Epoch[8] Batch [150]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.156188,	
2017-07-31 14:12:12,992 Epoch[8] Batch [160]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.155351,	
2017-07-31 14:12:16,942 Epoch[8] Batch [170]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.155406,	
2017-07-31 14:12:21,026 Epoch[8] Batch [180]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.155158,	
2017-07-31 14:12:24,986 Epoch[8] Batch [190]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.155178,	
2017-07-31 14:12:29,065 Epoch[8] Batch [200]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.154999,	
2017-07-31 14:12:32,996 Epoch[8] Batch [210]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.155018,	
2017-07-31 14:12:36,920 Epoch[8] Batch [220]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.154128,	
2017-07-31 14:12:40,898 Epoch[8] Batch [230]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.152871,	
2017-07-31 14:12:44,998 Epoch[8] Batch [240]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.152611,	
2017-07-31 14:12:49,019 Epoch[8] Batch [250]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.152134,	
2017-07-31 14:12:52,949 Epoch[8] Batch [260]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.152255,	
2017-07-31 14:12:57,105 Epoch[8] Batch [270]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.151585,	
2017-07-31 14:13:01,150 Epoch[8] Batch [280]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.152028,	
2017-07-31 14:13:05,184 Epoch[8] Batch [290]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.151271,	
2017-07-31 14:13:09,210 Epoch[8] Batch [300]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.151049,	
2017-07-31 14:13:13,155 Epoch[8] Batch [310]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.150145,	
2017-07-31 14:13:17,149 Epoch[8] Batch [320]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.150013,	
2017-07-31 14:13:21,221 Epoch[8] Batch [330]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.149803,	
2017-07-31 14:13:25,374 Epoch[8] Batch [340]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.149612,	
2017-07-31 14:13:29,368 Epoch[8] Batch [350]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.149581,	
2017-07-31 14:13:33,405 Epoch[8] Batch [360]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.149874,	
2017-07-31 14:13:37,428 Epoch[8] Batch [370]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.149455,	
2017-07-31 14:13:41,514 Epoch[8] Batch [380]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.149457,	
2017-07-31 14:13:45,570 Epoch[8] Batch [390]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.149643,	
2017-07-31 14:13:49,600 Epoch[8] Batch [400]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.150256,	
2017-07-31 14:13:53,718 Epoch[8] Batch [410]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.150888,	
2017-07-31 14:13:57,647 Epoch[8] Batch [420]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.150493,	
2017-07-31 14:14:01,733 Epoch[8] Batch [430]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.150867,	
2017-07-31 14:14:05,761 Epoch[8] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.150626,	
2017-07-31 14:14:09,829 Epoch[8] Batch [450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.150623,	
2017-07-31 14:14:13,846 Epoch[8] Batch [460]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.150844,	
2017-07-31 14:14:17,914 Epoch[8] Batch [470]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.150595,	
2017-07-31 14:14:21,912 Epoch[8] Batch [480]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.150523,	
2017-07-31 14:14:26,135 Epoch[8] Batch [490]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.150429,	
2017-07-31 14:14:30,318 Epoch[8] Batch [500]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.150418,	
2017-07-31 14:14:34,293 Epoch[8] Batch [510]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.150467,	
2017-07-31 14:14:38,276 Epoch[8] Batch [520]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.150368,	
2017-07-31 14:14:42,290 Epoch[8] Batch [530]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.150076,	
2017-07-31 14:14:46,644 Epoch[8] Batch [540]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.149476,	
2017-07-31 14:14:50,538 Epoch[8] Batch [550]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.149374,	
2017-07-31 14:14:54,487 Epoch[8] Batch [560]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.148802,	
2017-07-31 14:14:58,456 Epoch[8] Batch [570]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.148643,	
2017-07-31 14:15:02,449 Epoch[8] Batch [580]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.148638,	
2017-07-31 14:15:06,560 Epoch[8] Batch [590]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.148544,	
2017-07-31 14:15:10,591 Epoch[8] Batch [600]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.148512,	
2017-07-31 14:15:14,606 Epoch[8] Batch [610]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.148409,	
2017-07-31 14:15:18,754 Epoch[8] Batch [620]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.148291,	
2017-07-31 14:15:22,760 Epoch[8] Batch [630]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.148446,	
2017-07-31 14:15:26,692 Epoch[8] Batch [640]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.148337,	
2017-07-31 14:15:30,805 Epoch[8] Batch [650]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.148357,	
2017-07-31 14:15:35,000 Epoch[8] Batch [660]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.148243,	
2017-07-31 14:15:39,118 Epoch[8] Batch [670]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.148232,	
2017-07-31 14:15:43,162 Epoch[8] Batch [680]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.148386,	
2017-07-31 14:15:47,174 Epoch[8] Batch [690]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.148394,	
2017-07-31 14:15:51,341 Epoch[8] Batch [700]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.148316,	
2017-07-31 14:15:55,422 Epoch[8] Batch [710]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.148532,	
2017-07-31 14:15:59,621 Epoch[8] Batch [720]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.148537,	
2017-07-31 14:16:03,676 Epoch[8] Batch [730]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.148510,	
2017-07-31 14:16:07,664 Epoch[8] Batch [740]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.148779,	
2017-07-31 14:16:11,756 Epoch[8] Batch [750]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.149715,	
2017-07-31 14:16:15,775 Epoch[8] Batch [760]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.150428,	
2017-07-31 14:16:19,715 Epoch[8] Batch [770]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.151097,	
2017-07-31 14:16:23,709 Epoch[8] Batch [780]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.151532,	
2017-07-31 14:16:27,618 Epoch[8] Batch [790]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.151456,	
2017-07-31 14:16:31,603 Epoch[8] Batch [800]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.151630,	
2017-07-31 14:16:35,668 Epoch[8] Batch [810]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.151560,	
2017-07-31 14:16:39,668 Epoch[8] Batch [820]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.151638,	
2017-07-31 14:16:43,711 Epoch[8] Batch [830]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.151450,	
2017-07-31 14:16:47,888 Epoch[8] Batch [840]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.151370,	
2017-07-31 14:16:51,860 Epoch[8] Batch [850]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.151625,	
2017-07-31 14:16:55,856 Epoch[8] Batch [860]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.151836,	
2017-07-31 14:16:59,887 Epoch[8] Batch [870]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.152138,	
2017-07-31 14:17:03,768 Epoch[8] Batch [880]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.152266,	
2017-07-31 14:17:08,018 Epoch[8] Batch [890]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.152282,	
2017-07-31 14:17:11,977 Epoch[8] Batch [900]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.152330,	
2017-07-31 14:17:15,985 Epoch[8] Batch [910]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.152125,	
2017-07-31 14:17:20,121 Epoch[8] Batch [920]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.151958,	
2017-07-31 14:17:24,181 Epoch[8] Batch [930]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.151896,	
2017-07-31 14:17:28,360 Epoch[8] Batch [940]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.151847,	
2017-07-31 14:17:32,381 Epoch[8] Batch [950]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.151922,	
2017-07-31 14:17:36,410 Epoch[8] Batch [960]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.151798,	
2017-07-31 14:17:40,477 Epoch[8] Batch [970]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.151842,	
2017-07-31 14:17:44,478 Epoch[8] Batch [980]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.151742,	
2017-07-31 14:17:48,452 Epoch[8] Batch [990]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.151918,	
2017-07-31 14:17:52,504 Epoch[8] Batch [1000]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.152092,	
2017-07-31 14:17:56,693 Epoch[8] Batch [1010]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.152518,	
2017-07-31 14:18:00,759 Epoch[8] Batch [1020]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.152499,	
2017-07-31 14:18:04,717 Epoch[8] Batch [1030]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.152517,	
2017-07-31 14:18:08,819 Epoch[8] Batch [1040]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.152635,	
2017-07-31 14:18:12,676 Epoch[8] Batch [1050]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.152649,	
2017-07-31 14:18:16,595 Epoch[8] Batch [1060]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.152559,	
2017-07-31 14:18:20,623 Epoch[8] Batch [1070]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.152556,	
2017-07-31 14:18:24,637 Epoch[8] Batch [1080]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.152584,	
2017-07-31 14:18:28,748 Epoch[8] Batch [1090]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.152477,	
2017-07-31 14:18:32,828 Epoch[8] Batch [1100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.152579,	
2017-07-31 14:18:36,879 Epoch[8] Batch [1110]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.152516,	
2017-07-31 14:18:40,816 Epoch[8] Batch [1120]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.152549,	
2017-07-31 14:18:44,882 Epoch[8] Batch [1130]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.152473,	
2017-07-31 14:18:48,812 Epoch[8] Batch [1140]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.152426,	
2017-07-31 14:18:52,921 Epoch[8] Batch [1150]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.152456,	
2017-07-31 14:18:56,896 Epoch[8] Batch [1160]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.152438,	
2017-07-31 14:19:00,889 Epoch[8] Batch [1170]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.152290,	
2017-07-31 14:19:05,093 Epoch[8] Batch [1180]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.152352,	
2017-07-31 14:19:09,093 Epoch[8] Batch [1190]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.152146,	
2017-07-31 14:19:13,285 Epoch[8] Batch [1200]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.152091,	
2017-07-31 14:19:17,264 Epoch[8] Batch [1210]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.152074,	
2017-07-31 14:19:21,469 Epoch[8] Batch [1220]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.152012,	
2017-07-31 14:19:25,565 Epoch[8] Batch [1230]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.151909,	
2017-07-31 14:19:29,603 Epoch[8] Batch [1240]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.151834,	
2017-07-31 14:19:33,648 Epoch[8] Batch [1250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.151846,	
2017-07-31 14:19:37,688 Epoch[8] Batch [1260]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.151787,	
2017-07-31 14:19:41,696 Epoch[8] Batch [1270]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.151689,	
2017-07-31 14:19:45,646 Epoch[8] Batch [1280]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.151517,	
2017-07-31 14:19:49,625 Epoch[8] Batch [1290]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.151561,	
2017-07-31 14:19:53,812 Epoch[8] Batch [1300]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.151425,	
2017-07-31 14:19:57,962 Epoch[8] Batch [1310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.151462,	
2017-07-31 14:20:02,021 Epoch[8] Batch [1320]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.151347,	
2017-07-31 14:20:06,177 Epoch[8] Batch [1330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.151191,	
2017-07-31 14:20:10,234 Epoch[8] Batch [1340]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.150952,	
2017-07-31 14:20:14,209 Epoch[8] Batch [1350]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.150926,	
2017-07-31 14:20:18,427 Epoch[8] Batch [1360]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.150840,	
2017-07-31 14:20:22,371 Epoch[8] Batch [1370]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.150798,	
2017-07-31 14:20:26,613 Epoch[8] Batch [1380]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.150632,	
2017-07-31 14:20:30,772 Epoch[8] Batch [1390]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.150614,	
2017-07-31 14:20:34,811 Epoch[8] Batch [1400]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.150620,	
2017-07-31 14:20:38,952 Epoch[8] Batch [1410]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.150637,	
2017-07-31 14:20:42,879 Epoch[8] Batch [1420]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.150703,	
2017-07-31 14:20:46,893 Epoch[8] Batch [1430]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.150597,	
2017-07-31 14:20:51,034 Epoch[8] Batch [1440]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.150518,	
2017-07-31 14:20:55,166 Epoch[8] Batch [1450]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.150535,	
2017-07-31 14:20:59,204 Epoch[8] Batch [1460]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.150565,	
2017-07-31 14:21:03,137 Epoch[8] Batch [1470]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.150470,	
2017-07-31 14:21:07,349 Epoch[8] Batch [1480]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.150427,	
2017-07-31 14:21:09,746 Epoch[8] Train-FCNLogLoss=0.150346
2017-07-31 14:21:09,747 Epoch[8] Time cost=602.123
2017-07-31 14:21:10,753 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.params"
2017-07-31 14:21:14,329 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.states"
2017-07-31 14:21:19,273 Epoch[9] Batch [10]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.125932,	
2017-07-31 14:21:23,551 Epoch[9] Batch [20]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.138602,	
2017-07-31 14:21:27,763 Epoch[9] Batch [30]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.144029,	
2017-07-31 14:21:31,953 Epoch[9] Batch [40]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.149357,	
2017-07-31 14:21:36,195 Epoch[9] Batch [50]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.149327,	
2017-07-31 14:21:40,488 Epoch[9] Batch [60]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.150823,	
2017-07-31 14:21:44,674 Epoch[9] Batch [70]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.156342,	
2017-07-31 14:21:48,760 Epoch[9] Batch [80]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.156537,	
2017-07-31 14:21:52,920 Epoch[9] Batch [90]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.157013,	
2017-07-31 14:21:57,067 Epoch[9] Batch [100]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.156221,	
2017-07-31 14:22:01,273 Epoch[9] Batch [110]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.156351,	
2017-07-31 14:22:05,402 Epoch[9] Batch [120]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.153579,	
2017-07-31 14:22:09,574 Epoch[9] Batch [130]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.152444,	
2017-07-31 14:22:13,885 Epoch[9] Batch [140]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.151264,	
2017-07-31 14:22:18,021 Epoch[9] Batch [150]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.149890,	
2017-07-31 14:22:22,167 Epoch[9] Batch [160]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.148913,	
2017-07-31 14:22:26,437 Epoch[9] Batch [170]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.148377,	
2017-07-31 14:22:30,843 Epoch[9] Batch [180]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.147680,	
2017-07-31 14:22:35,162 Epoch[9] Batch [190]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.147118,	
2017-07-31 14:22:39,327 Epoch[9] Batch [200]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.146350,	
2017-07-31 14:22:43,552 Epoch[9] Batch [210]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.145976,	
2017-07-31 14:22:47,714 Epoch[9] Batch [220]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.145604,	
2017-07-31 14:22:52,009 Epoch[9] Batch [230]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.146109,	
2017-07-31 14:22:56,228 Epoch[9] Batch [240]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.146036,	
2017-07-31 14:23:00,394 Epoch[9] Batch [250]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.145049,	
2017-07-31 14:23:04,744 Epoch[9] Batch [260]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.145507,	
2017-07-31 14:23:09,218 Epoch[9] Batch [270]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.145316,	
2017-07-31 14:23:13,422 Epoch[9] Batch [280]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.145627,	
2017-07-31 14:23:17,584 Epoch[9] Batch [290]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.145479,	
2017-07-31 14:23:21,815 Epoch[9] Batch [300]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.145098,	
2017-07-31 14:23:25,990 Epoch[9] Batch [310]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.144970,	
2017-07-31 14:23:30,201 Epoch[9] Batch [320]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.144371,	
2017-07-31 14:23:34,386 Epoch[9] Batch [330]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.143616,	
2017-07-31 14:23:38,628 Epoch[9] Batch [340]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.144484,	
2017-07-31 14:23:42,787 Epoch[9] Batch [350]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.145032,	
2017-07-31 14:23:46,966 Epoch[9] Batch [360]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.144989,	
2017-07-31 14:23:51,310 Epoch[9] Batch [370]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.145897,	
2017-07-31 14:23:55,639 Epoch[9] Batch [380]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.146006,	
2017-07-31 14:23:59,889 Epoch[9] Batch [390]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.146118,	
2017-07-31 14:24:04,133 Epoch[9] Batch [400]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.145801,	
2017-07-31 14:24:08,308 Epoch[9] Batch [410]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.145503,	
2017-07-31 14:24:12,662 Epoch[9] Batch [420]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.145291,	
2017-07-31 14:24:16,835 Epoch[9] Batch [430]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.145666,	
2017-07-31 14:24:21,017 Epoch[9] Batch [440]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.145667,	
2017-07-31 14:24:25,102 Epoch[9] Batch [450]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.145217,	
2017-07-31 14:24:29,370 Epoch[9] Batch [460]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.145168,	
2017-07-31 14:24:33,625 Epoch[9] Batch [470]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.145140,	
2017-07-31 14:24:37,899 Epoch[9] Batch [480]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.144937,	
2017-07-31 14:24:42,146 Epoch[9] Batch [490]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.145414,	
2017-07-31 14:24:46,417 Epoch[9] Batch [500]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.145437,	
2017-07-31 14:24:50,816 Epoch[9] Batch [510]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.145766,	
2017-07-31 14:24:55,471 Epoch[9] Batch [520]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.145547,	
2017-07-31 14:24:59,766 Epoch[9] Batch [530]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.145150,	
2017-07-31 14:25:04,251 Epoch[9] Batch [540]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.145112,	
2017-07-31 14:25:08,631 Epoch[9] Batch [550]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.144855,	
2017-07-31 14:25:13,018 Epoch[9] Batch [560]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.145781,	
2017-07-31 14:25:17,762 Epoch[9] Batch [570]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.145846,	
2017-07-31 14:25:21,916 Epoch[9] Batch [580]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.146017,	
2017-07-31 14:25:26,007 Epoch[9] Batch [590]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.146503,	
2017-07-31 14:25:30,251 Epoch[9] Batch [600]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.147460,	
2017-07-31 14:25:34,606 Epoch[9] Batch [610]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.147713,	
2017-07-31 14:25:38,842 Epoch[9] Batch [620]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.147527,	
2017-07-31 14:25:43,009 Epoch[9] Batch [630]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.147408,	
2017-07-31 14:25:47,551 Epoch[9] Batch [640]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.147610,	
2017-07-31 14:25:51,901 Epoch[9] Batch [650]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.147704,	
2017-07-31 14:25:56,231 Epoch[9] Batch [660]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.147517,	
2017-07-31 14:26:00,684 Epoch[9] Batch [670]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.147551,	
2017-07-31 14:26:05,224 Epoch[9] Batch [680]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.147589,	
2017-07-31 14:26:09,386 Epoch[9] Batch [690]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.147560,	
2017-07-31 14:26:13,764 Epoch[9] Batch [700]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.147275,	
2017-07-31 14:26:18,101 Epoch[9] Batch [710]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.146858,	
2017-07-31 14:26:22,417 Epoch[9] Batch [720]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.146886,	
2017-07-31 14:26:26,784 Epoch[9] Batch [730]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.146778,	
2017-07-31 14:26:31,086 Epoch[9] Batch [740]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.146552,	
2017-07-31 14:26:35,216 Epoch[9] Batch [750]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.146508,	
2017-07-31 14:26:39,358 Epoch[9] Batch [760]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.146631,	
2017-07-31 14:26:43,610 Epoch[9] Batch [770]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.146457,	
2017-07-31 14:26:47,834 Epoch[9] Batch [780]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.146489,	
2017-07-31 14:26:52,014 Epoch[9] Batch [790]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.146286,	
2017-07-31 14:26:56,162 Epoch[9] Batch [800]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.146216,	
2017-07-31 14:27:00,323 Epoch[9] Batch [810]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.146359,	
2017-07-31 14:27:04,743 Epoch[9] Batch [820]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.146220,	
2017-07-31 14:27:09,112 Epoch[9] Batch [830]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.146350,	
2017-07-31 14:27:13,500 Epoch[9] Batch [840]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.146547,	
2017-07-31 14:27:17,872 Epoch[9] Batch [850]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.146463,	
2017-07-31 14:27:22,148 Epoch[9] Batch [860]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.146323,	
2017-07-31 14:27:26,361 Epoch[9] Batch [870]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.146204,	
2017-07-31 14:27:30,757 Epoch[9] Batch [880]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.146046,	
2017-07-31 14:27:35,089 Epoch[9] Batch [890]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.146024,	
2017-07-31 14:27:39,307 Epoch[9] Batch [900]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.146090,	
2017-07-31 14:27:43,658 Epoch[9] Batch [910]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.146004,	
2017-07-31 14:27:47,768 Epoch[9] Batch [920]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.145861,	
2017-07-31 14:27:52,300 Epoch[9] Batch [930]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.145776,	
2017-07-31 14:27:56,633 Epoch[9] Batch [940]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.145768,	
2017-07-31 14:28:00,945 Epoch[9] Batch [950]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.145517,	
2017-07-31 14:28:05,346 Epoch[9] Batch [960]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.145474,	
2017-07-31 14:28:09,563 Epoch[9] Batch [970]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.145312,	
2017-07-31 14:28:13,824 Epoch[9] Batch [980]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.145249,	
2017-07-31 14:28:18,161 Epoch[9] Batch [990]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.145134,	
2017-07-31 14:28:22,549 Epoch[9] Batch [1000]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.145118,	
2017-07-31 14:28:27,034 Epoch[9] Batch [1010]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.144948,	
2017-07-31 14:28:31,264 Epoch[9] Batch [1020]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.144822,	
2017-07-31 14:28:35,462 Epoch[9] Batch [1030]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.144618,	
2017-07-31 14:28:39,624 Epoch[9] Batch [1040]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.144386,	
2017-07-31 14:28:43,931 Epoch[9] Batch [1050]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.144378,	
2017-07-31 14:28:48,448 Epoch[9] Batch [1060]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.144241,	
2017-07-31 14:28:52,736 Epoch[9] Batch [1070]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.144360,	
2017-07-31 14:28:56,947 Epoch[9] Batch [1080]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.144246,	
2017-07-31 14:29:01,090 Epoch[9] Batch [1090]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.144258,	
2017-07-31 14:29:05,574 Epoch[9] Batch [1100]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.144222,	
2017-07-31 14:29:09,880 Epoch[9] Batch [1110]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.144075,	
2017-07-31 14:29:14,723 Epoch[9] Batch [1120]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.143963,	
2017-07-31 14:29:19,029 Epoch[9] Batch [1130]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.143963,	
2017-07-31 14:29:23,542 Epoch[9] Batch [1140]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.143766,	
2017-07-31 14:29:28,007 Epoch[9] Batch [1150]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.143696,	
2017-07-31 14:29:32,527 Epoch[9] Batch [1160]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.143755,	
2017-07-31 14:29:36,835 Epoch[9] Batch [1170]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.144000,	
2017-07-31 14:29:41,003 Epoch[9] Batch [1180]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.143920,	
2017-07-31 14:29:45,325 Epoch[9] Batch [1190]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.143875,	
2017-07-31 14:29:49,581 Epoch[9] Batch [1200]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.143711,	
2017-07-31 14:29:53,885 Epoch[9] Batch [1210]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.143693,	
2017-07-31 14:29:58,399 Epoch[9] Batch [1220]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.143766,	
2017-07-31 14:30:02,720 Epoch[9] Batch [1230]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.144054,	
2017-07-31 14:30:06,918 Epoch[9] Batch [1240]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.144045,	
2017-07-31 14:30:11,035 Epoch[9] Batch [1250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.144021,	
2017-07-31 14:30:15,581 Epoch[9] Batch [1260]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.143933,	
2017-07-31 14:30:20,086 Epoch[9] Batch [1270]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.143801,	
2017-07-31 14:30:24,502 Epoch[9] Batch [1280]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.143667,	
2017-07-31 14:30:28,781 Epoch[9] Batch [1290]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.143656,	
2017-07-31 14:30:33,049 Epoch[9] Batch [1300]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.143718,	
2017-07-31 14:30:37,467 Epoch[9] Batch [1310]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.143704,	
2017-07-31 14:30:41,682 Epoch[9] Batch [1320]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.143585,	
2017-07-31 14:30:45,796 Epoch[9] Batch [1330]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.143622,	
2017-07-31 14:30:50,194 Epoch[9] Batch [1340]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.143674,	
2017-07-31 14:30:54,324 Epoch[9] Batch [1350]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.143708,	
2017-07-31 14:30:58,557 Epoch[9] Batch [1360]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.143780,	
2017-07-31 14:31:02,975 Epoch[9] Batch [1370]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.143624,	
2017-07-31 14:31:07,355 Epoch[9] Batch [1380]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.143629,	
2017-07-31 14:31:11,733 Epoch[9] Batch [1390]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.143668,	
2017-07-31 14:31:15,843 Epoch[9] Batch [1400]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.143590,	
2017-07-31 14:31:19,972 Epoch[9] Batch [1410]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.143652,	
2017-07-31 14:31:24,644 Epoch[9] Batch [1420]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.143664,	
2017-07-31 14:31:29,276 Epoch[9] Batch [1430]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.143610,	
2017-07-31 14:31:33,797 Epoch[9] Batch [1440]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.143596,	
2017-07-31 14:31:38,283 Epoch[9] Batch [1450]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.143559,	
2017-07-31 14:31:42,555 Epoch[9] Batch [1460]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.143736,	
2017-07-31 14:31:46,860 Epoch[9] Batch [1470]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.143858,	
2017-07-31 14:31:50,969 Epoch[9] Batch [1480]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.143785,	
2017-07-31 14:31:54,276 Epoch[9] Train-FCNLogLoss=0.143729
2017-07-31 14:31:54,276 Epoch[9] Time cost=639.946
2017-07-31 14:31:55,082 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.params"
2017-07-31 14:31:58,489 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.states"
2017-07-31 14:32:03,653 Epoch[10] Batch [10]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.149566,	
2017-07-31 14:32:08,259 Epoch[10] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.140706,	
2017-07-31 14:32:12,909 Epoch[10] Batch [30]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.147750,	
2017-07-31 14:32:17,082 Epoch[10] Batch [40]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.142716,	
2017-07-31 14:32:21,858 Epoch[10] Batch [50]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.140822,	
2017-07-31 14:32:27,293 Epoch[10] Batch [60]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.138685,	
2017-07-31 14:32:31,887 Epoch[10] Batch [70]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.138760,	
2017-07-31 14:32:36,164 Epoch[10] Batch [80]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.137372,	
2017-07-31 14:32:40,405 Epoch[10] Batch [90]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.137854,	
2017-07-31 14:32:44,589 Epoch[10] Batch [100]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.136694,	
2017-07-31 14:32:48,883 Epoch[10] Batch [110]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.136339,	
2017-07-31 14:32:53,436 Epoch[10] Batch [120]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.136249,	
2017-07-31 14:32:57,767 Epoch[10] Batch [130]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.136464,	
2017-07-31 14:33:02,142 Epoch[10] Batch [140]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.136494,	
2017-07-31 14:33:06,477 Epoch[10] Batch [150]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.135628,	
2017-07-31 14:33:10,622 Epoch[10] Batch [160]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136194,	
2017-07-31 14:33:14,842 Epoch[10] Batch [170]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.136622,	
2017-07-31 14:33:19,099 Epoch[10] Batch [180]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.135465,	
2017-07-31 14:33:23,465 Epoch[10] Batch [190]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.135978,	
2017-07-31 14:33:27,673 Epoch[10] Batch [200]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.135714,	
2017-07-31 14:33:31,866 Epoch[10] Batch [210]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.135734,	
2017-07-31 14:33:35,981 Epoch[10] Batch [220]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.136752,	
2017-07-31 14:33:40,406 Epoch[10] Batch [230]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.137074,	
2017-07-31 14:33:44,708 Epoch[10] Batch [240]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.137230,	
2017-07-31 14:33:49,187 Epoch[10] Batch [250]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.137296,	
2017-07-31 14:33:53,553 Epoch[10] Batch [260]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.137093,	
2017-07-31 14:33:57,828 Epoch[10] Batch [270]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.136338,	
2017-07-31 14:34:02,469 Epoch[10] Batch [280]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.136647,	
2017-07-31 14:34:06,817 Epoch[10] Batch [290]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.136545,	
2017-07-31 14:34:11,037 Epoch[10] Batch [300]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.136542,	
2017-07-31 14:34:15,409 Epoch[10] Batch [310]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.136215,	
2017-07-31 14:34:19,704 Epoch[10] Batch [320]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.135950,	
2017-07-31 14:34:24,051 Epoch[10] Batch [330]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.135837,	
2017-07-31 14:34:28,550 Epoch[10] Batch [340]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.135626,	
2017-07-31 14:34:32,682 Epoch[10] Batch [350]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.135800,	
2017-07-31 14:34:36,767 Epoch[10] Batch [360]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.136022,	
2017-07-31 14:34:41,267 Epoch[10] Batch [370]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.136007,	
2017-07-31 14:34:45,455 Epoch[10] Batch [380]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.135931,	
2017-07-31 14:34:49,623 Epoch[10] Batch [390]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.135809,	
2017-07-31 14:34:53,842 Epoch[10] Batch [400]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.136310,	
2017-07-31 14:34:58,122 Epoch[10] Batch [410]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.135937,	
2017-07-31 14:35:02,571 Epoch[10] Batch [420]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.135793,	
2017-07-31 14:35:07,094 Epoch[10] Batch [430]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.136446,	
2017-07-31 14:35:11,378 Epoch[10] Batch [440]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.136458,	
2017-07-31 14:35:15,684 Epoch[10] Batch [450]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.136499,	
2017-07-31 14:35:19,951 Epoch[10] Batch [460]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.136708,	
2017-07-31 14:35:24,425 Epoch[10] Batch [470]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.137329,	
2017-07-31 14:35:28,735 Epoch[10] Batch [480]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.137763,	
2017-07-31 14:35:33,741 Epoch[10] Batch [490]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.137928,	
2017-07-31 14:35:37,913 Epoch[10] Batch [500]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.137967,	
2017-07-31 14:35:42,350 Epoch[10] Batch [510]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.138401,	
2017-07-31 14:35:47,042 Epoch[10] Batch [520]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.138288,	
2017-07-31 14:35:51,296 Epoch[10] Batch [530]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.138404,	
2017-07-31 14:35:55,652 Epoch[10] Batch [540]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.138562,	
2017-07-31 14:36:00,120 Epoch[10] Batch [550]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.139139,	
2017-07-31 14:36:04,787 Epoch[10] Batch [560]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.138970,	
2017-07-31 14:36:09,342 Epoch[10] Batch [570]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.139018,	
2017-07-31 14:36:13,825 Epoch[10] Batch [580]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.138710,	
2017-07-31 14:36:18,508 Epoch[10] Batch [590]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.138825,	
2017-07-31 14:36:22,967 Epoch[10] Batch [600]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.138608,	
2017-07-31 14:36:27,669 Epoch[10] Batch [610]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.138357,	
2017-07-31 14:36:32,093 Epoch[10] Batch [620]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.138240,	
2017-07-31 14:36:36,461 Epoch[10] Batch [630]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.138235,	
2017-07-31 14:36:40,663 Epoch[10] Batch [640]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.138172,	
2017-07-31 14:36:45,157 Epoch[10] Batch [650]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.138278,	
2017-07-31 14:36:49,423 Epoch[10] Batch [660]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.138614,	
2017-07-31 14:36:54,000 Epoch[10] Batch [670]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.138646,	
2017-07-31 14:36:58,310 Epoch[10] Batch [680]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.138464,	
2017-07-31 14:37:02,629 Epoch[10] Batch [690]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.138491,	
2017-07-31 14:37:06,908 Epoch[10] Batch [700]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.138380,	
2017-07-31 14:37:11,661 Epoch[10] Batch [710]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.138158,	
2017-07-31 14:37:15,869 Epoch[10] Batch [720]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.138128,	
2017-07-31 14:37:20,183 Epoch[10] Batch [730]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.138193,	
2017-07-31 14:37:24,554 Epoch[10] Batch [740]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.138039,	
2017-07-31 14:37:28,800 Epoch[10] Batch [750]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.138006,	
2017-07-31 14:37:33,456 Epoch[10] Batch [760]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.138069,	
2017-07-31 14:37:38,184 Epoch[10] Batch [770]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.137974,	
2017-07-31 14:37:42,482 Epoch[10] Batch [780]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.138157,	
2017-07-31 14:37:46,981 Epoch[10] Batch [790]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.138154,	
2017-07-31 14:37:51,118 Epoch[10] Batch [800]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.138183,	
2017-07-31 14:37:55,693 Epoch[10] Batch [810]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.138169,	
2017-07-31 14:38:00,035 Epoch[10] Batch [820]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.138104,	
2017-07-31 14:38:04,317 Epoch[10] Batch [830]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.138205,	
2017-07-31 14:38:08,620 Epoch[10] Batch [840]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.138269,	
2017-07-31 14:38:12,792 Epoch[10] Batch [850]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.138193,	
2017-07-31 14:38:17,196 Epoch[10] Batch [860]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.138157,	
2017-07-31 14:38:21,482 Epoch[10] Batch [870]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.138101,	
2017-07-31 14:38:25,663 Epoch[10] Batch [880]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.138031,	
2017-07-31 14:38:30,283 Epoch[10] Batch [890]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.137952,	
2017-07-31 14:38:34,690 Epoch[10] Batch [900]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.137853,	
2017-07-31 14:38:38,990 Epoch[10] Batch [910]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.137926,	
2017-07-31 14:38:43,297 Epoch[10] Batch [920]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.138016,	
2017-07-31 14:38:47,705 Epoch[10] Batch [930]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.138139,	
2017-07-31 14:38:52,501 Epoch[10] Batch [940]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.138242,	
2017-07-31 14:38:57,060 Epoch[10] Batch [950]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.138545,	
2017-07-31 14:39:01,377 Epoch[10] Batch [960]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.138463,	
2017-07-31 14:39:06,094 Epoch[10] Batch [970]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.138717,	
2017-07-31 14:39:10,650 Epoch[10] Batch [980]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.138589,	
2017-07-31 14:39:15,360 Epoch[10] Batch [990]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.138476,	
2017-07-31 14:39:19,666 Epoch[10] Batch [1000]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.138421,	
2017-07-31 14:39:24,250 Epoch[10] Batch [1010]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.138645,	
2017-07-31 14:39:28,685 Epoch[10] Batch [1020]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.138579,	
2017-07-31 14:39:33,020 Epoch[10] Batch [1030]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.138385,	
2017-07-31 14:39:37,539 Epoch[10] Batch [1040]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.138390,	
2017-07-31 14:39:41,794 Epoch[10] Batch [1050]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.138236,	
2017-07-31 14:39:46,131 Epoch[10] Batch [1060]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.138355,	
2017-07-31 14:39:50,427 Epoch[10] Batch [1070]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.138333,	
2017-07-31 14:39:54,863 Epoch[10] Batch [1080]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.138406,	
2017-07-31 14:39:59,357 Epoch[10] Batch [1090]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.138404,	
2017-07-31 14:40:03,560 Epoch[10] Batch [1100]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.138473,	
2017-07-31 14:40:08,000 Epoch[10] Batch [1110]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.138453,	
2017-07-31 14:40:12,193 Epoch[10] Batch [1120]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.138481,	
2017-07-31 14:40:16,617 Epoch[10] Batch [1130]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.138432,	
2017-07-31 14:40:20,878 Epoch[10] Batch [1140]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.138572,	
2017-07-31 14:40:25,081 Epoch[10] Batch [1150]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.138877,	
2017-07-31 14:40:29,261 Epoch[10] Batch [1160]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.138894,	
2017-07-31 14:40:33,381 Epoch[10] Batch [1170]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.138868,	
2017-07-31 14:40:38,031 Epoch[10] Batch [1180]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.138825,	
2017-07-31 14:40:42,237 Epoch[10] Batch [1190]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.138845,	
2017-07-31 14:40:46,387 Epoch[10] Batch [1200]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.138792,	
2017-07-31 14:40:50,730 Epoch[10] Batch [1210]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.138897,	
2017-07-31 14:40:55,303 Epoch[10] Batch [1220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.138909,	
2017-07-31 14:40:59,560 Epoch[10] Batch [1230]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.138933,	
2017-07-31 14:41:03,898 Epoch[10] Batch [1240]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.138999,	
2017-07-31 14:41:08,263 Epoch[10] Batch [1250]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.139074,	
2017-07-31 14:41:12,645 Epoch[10] Batch [1260]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.139170,	
2017-07-31 14:41:16,787 Epoch[10] Batch [1270]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.138992,	
2017-07-31 14:41:21,100 Epoch[10] Batch [1280]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.139045,	
2017-07-31 14:41:25,477 Epoch[10] Batch [1290]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.138996,	
2017-07-31 14:41:30,205 Epoch[10] Batch [1300]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.139032,	
2017-07-31 14:41:34,484 Epoch[10] Batch [1310]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.139016,	
2017-07-31 14:41:38,959 Epoch[10] Batch [1320]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.139008,	
2017-07-31 14:41:43,346 Epoch[10] Batch [1330]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.139078,	
2017-07-31 14:41:47,801 Epoch[10] Batch [1340]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.138928,	
2017-07-31 14:41:52,140 Epoch[10] Batch [1350]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.138844,	
2017-07-31 14:41:56,520 Epoch[10] Batch [1360]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.138735,	
2017-07-31 14:42:00,918 Epoch[10] Batch [1370]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.138775,	
2017-07-31 14:42:05,416 Epoch[10] Batch [1380]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.138639,	
2017-07-31 14:42:09,690 Epoch[10] Batch [1390]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.138634,	
2017-07-31 14:42:14,034 Epoch[10] Batch [1400]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.138607,	
2017-07-31 14:42:18,378 Epoch[10] Batch [1410]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.138537,	
2017-07-31 14:42:22,689 Epoch[10] Batch [1420]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.138604,	
2017-07-31 14:42:27,332 Epoch[10] Batch [1430]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.138508,	
2017-07-31 14:42:31,791 Epoch[10] Batch [1440]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.138442,	
2017-07-31 14:42:36,236 Epoch[10] Batch [1450]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.138504,	
2017-07-31 14:42:40,702 Epoch[10] Batch [1460]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.138456,	
2017-07-31 14:42:45,042 Epoch[10] Batch [1470]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.138537,	
2017-07-31 14:42:49,268 Epoch[10] Batch [1480]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.138537,	
2017-07-31 14:42:51,785 Epoch[10] Train-FCNLogLoss=0.138656
2017-07-31 14:42:51,785 Epoch[10] Time cost=653.296
2017-07-31 14:42:52,631 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.params"
2017-07-31 14:42:55,940 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.states"
2017-07-31 14:43:00,837 Epoch[11] Batch [10]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.159890,	
2017-07-31 14:43:05,137 Epoch[11] Batch [20]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.156334,	
2017-07-31 14:43:09,303 Epoch[11] Batch [30]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.154239,	
2017-07-31 14:43:13,391 Epoch[11] Batch [40]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.150415,	
2017-07-31 14:43:17,460 Epoch[11] Batch [50]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.149515,	
2017-07-31 14:43:21,717 Epoch[11] Batch [60]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.148867,	
2017-07-31 14:43:25,879 Epoch[11] Batch [70]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.146920,	
2017-07-31 14:43:29,910 Epoch[11] Batch [80]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.143582,	
2017-07-31 14:43:34,054 Epoch[11] Batch [90]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.141149,	
2017-07-31 14:43:38,149 Epoch[11] Batch [100]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.140715,	
2017-07-31 14:43:42,450 Epoch[11] Batch [110]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.140885,	
2017-07-31 14:43:46,582 Epoch[11] Batch [120]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.140023,	
2017-07-31 14:43:50,723 Epoch[11] Batch [130]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.141013,	
2017-07-31 14:43:54,896 Epoch[11] Batch [140]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.140653,	
2017-07-31 14:43:59,071 Epoch[11] Batch [150]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.141156,	
2017-07-31 14:44:03,100 Epoch[11] Batch [160]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.141826,	
2017-07-31 14:44:07,250 Epoch[11] Batch [170]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.140494,	
2017-07-31 14:44:11,309 Epoch[11] Batch [180]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.139908,	
2017-07-31 14:44:15,441 Epoch[11] Batch [190]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.139431,	
2017-07-31 14:44:19,568 Epoch[11] Batch [200]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.138648,	
2017-07-31 14:44:23,678 Epoch[11] Batch [210]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.137983,	
2017-07-31 14:44:27,635 Epoch[11] Batch [220]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.137953,	
2017-07-31 14:44:31,811 Epoch[11] Batch [230]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.138176,	
2017-07-31 14:44:36,007 Epoch[11] Batch [240]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.138844,	
2017-07-31 14:44:40,051 Epoch[11] Batch [250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.138349,	
2017-07-31 14:44:44,183 Epoch[11] Batch [260]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.137852,	
2017-07-31 14:44:48,483 Epoch[11] Batch [270]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.137469,	
2017-07-31 14:44:52,590 Epoch[11] Batch [280]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136884,	
2017-07-31 14:44:56,837 Epoch[11] Batch [290]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.136566,	
2017-07-31 14:45:00,844 Epoch[11] Batch [300]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.136319,	
2017-07-31 14:45:04,978 Epoch[11] Batch [310]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.136004,	
2017-07-31 14:45:09,196 Epoch[11] Batch [320]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.136389,	
2017-07-31 14:45:13,452 Epoch[11] Batch [330]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.136312,	
2017-07-31 14:45:17,601 Epoch[11] Batch [340]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.136071,	
2017-07-31 14:45:21,635 Epoch[11] Batch [350]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.135646,	
2017-07-31 14:45:25,641 Epoch[11] Batch [360]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.135786,	
2017-07-31 14:45:29,767 Epoch[11] Batch [370]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.135706,	
2017-07-31 14:45:33,819 Epoch[11] Batch [380]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.135911,	
2017-07-31 14:45:37,922 Epoch[11] Batch [390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.135906,	
2017-07-31 14:45:42,139 Epoch[11] Batch [400]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.135569,	
2017-07-31 14:45:46,571 Epoch[11] Batch [410]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.135558,	
2017-07-31 14:45:50,772 Epoch[11] Batch [420]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.135340,	
2017-07-31 14:45:54,989 Epoch[11] Batch [430]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.135092,	
2017-07-31 14:45:59,261 Epoch[11] Batch [440]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.135193,	
2017-07-31 14:46:03,333 Epoch[11] Batch [450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.135097,	
2017-07-31 14:46:07,483 Epoch[11] Batch [460]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.135060,	
2017-07-31 14:46:11,755 Epoch[11] Batch [470]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.135130,	
2017-07-31 14:46:15,852 Epoch[11] Batch [480]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.134671,	
2017-07-31 14:46:20,170 Epoch[11] Batch [490]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.134628,	
2017-07-31 14:46:24,449 Epoch[11] Batch [500]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.134603,	
2017-07-31 14:46:28,973 Epoch[11] Batch [510]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.134817,	
2017-07-31 14:46:33,493 Epoch[11] Batch [520]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.135014,	
2017-07-31 14:46:37,620 Epoch[11] Batch [530]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.135183,	
2017-07-31 14:46:41,712 Epoch[11] Batch [540]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.135047,	
2017-07-31 14:46:45,878 Epoch[11] Batch [550]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.135382,	
2017-07-31 14:46:50,010 Epoch[11] Batch [560]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.135007,	
2017-07-31 14:46:54,408 Epoch[11] Batch [570]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.135081,	
2017-07-31 14:46:58,679 Epoch[11] Batch [580]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.135173,	
2017-07-31 14:47:02,800 Epoch[11] Batch [590]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.135093,	
2017-07-31 14:47:06,923 Epoch[11] Batch [600]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.134949,	
2017-07-31 14:47:11,201 Epoch[11] Batch [610]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.134806,	
2017-07-31 14:47:15,287 Epoch[11] Batch [620]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.134888,	
2017-07-31 14:47:20,914 Epoch[11] Batch [630]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.134951,	
2017-07-31 14:47:25,495 Epoch[11] Batch [640]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.134807,	
2017-07-31 14:47:30,202 Epoch[11] Batch [650]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.134789,	
2017-07-31 14:47:34,126 Epoch[11] Batch [660]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.134696,	
2017-07-31 14:47:38,369 Epoch[11] Batch [670]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.134828,	
2017-07-31 14:47:42,413 Epoch[11] Batch [680]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.134772,	
2017-07-31 14:47:46,859 Epoch[11] Batch [690]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.134786,	
2017-07-31 14:47:51,194 Epoch[11] Batch [700]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.134599,	
2017-07-31 14:47:55,255 Epoch[11] Batch [710]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.134711,	
2017-07-31 14:47:59,336 Epoch[11] Batch [720]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.134570,	
2017-07-31 14:48:03,528 Epoch[11] Batch [730]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.134341,	
2017-07-31 14:48:07,675 Epoch[11] Batch [740]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.134331,	
2017-07-31 14:48:11,776 Epoch[11] Batch [750]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.134350,	
2017-07-31 14:48:15,968 Epoch[11] Batch [760]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.134245,	
2017-07-31 14:48:20,199 Epoch[11] Batch [770]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.134173,	
2017-07-31 14:48:24,284 Epoch[11] Batch [780]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.133882,	
2017-07-31 14:48:28,493 Epoch[11] Batch [790]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.133845,	
2017-07-31 14:48:32,633 Epoch[11] Batch [800]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.133762,	
2017-07-31 14:48:36,885 Epoch[11] Batch [810]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.133782,	
2017-07-31 14:48:41,220 Epoch[11] Batch [820]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.133698,	
2017-07-31 14:48:45,375 Epoch[11] Batch [830]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.133637,	
2017-07-31 14:48:49,407 Epoch[11] Batch [840]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.133634,	
2017-07-31 14:48:53,592 Epoch[11] Batch [850]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.133589,	
2017-07-31 14:48:57,754 Epoch[11] Batch [860]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.133463,	
2017-07-31 14:49:01,895 Epoch[11] Batch [870]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.133392,	
2017-07-31 14:49:06,155 Epoch[11] Batch [880]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.133654,	
2017-07-31 14:49:10,227 Epoch[11] Batch [890]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.133623,	
2017-07-31 14:49:14,764 Epoch[11] Batch [900]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.133791,	
2017-07-31 14:49:19,046 Epoch[11] Batch [910]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.133698,	
2017-07-31 14:49:23,238 Epoch[11] Batch [920]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.133734,	
2017-07-31 14:49:27,228 Epoch[11] Batch [930]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.133896,	
2017-07-31 14:49:31,484 Epoch[11] Batch [940]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.134164,	
2017-07-31 14:49:35,700 Epoch[11] Batch [950]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.133896,	
2017-07-31 14:49:39,821 Epoch[11] Batch [960]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.134099,	
2017-07-31 14:49:43,991 Epoch[11] Batch [970]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.134111,	
2017-07-31 14:49:48,166 Epoch[11] Batch [980]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.134224,	
2017-07-31 14:49:52,277 Epoch[11] Batch [990]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134116,	
2017-07-31 14:49:56,379 Epoch[11] Batch [1000]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.134072,	
2017-07-31 14:50:00,465 Epoch[11] Batch [1010]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.134099,	
2017-07-31 14:50:04,670 Epoch[11] Batch [1020]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.133959,	
2017-07-31 14:50:08,842 Epoch[11] Batch [1030]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.133915,	
2017-07-31 14:50:12,931 Epoch[11] Batch [1040]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.133969,	
2017-07-31 14:50:17,005 Epoch[11] Batch [1050]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.134012,	
2017-07-31 14:50:21,251 Epoch[11] Batch [1060]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.133972,	
2017-07-31 14:50:25,413 Epoch[11] Batch [1070]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.133999,	
2017-07-31 14:50:29,454 Epoch[11] Batch [1080]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.133866,	
2017-07-31 14:50:33,628 Epoch[11] Batch [1090]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.133922,	
2017-07-31 14:50:37,651 Epoch[11] Batch [1100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.133794,	
2017-07-31 14:50:42,071 Epoch[11] Batch [1110]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.133759,	
2017-07-31 14:50:46,457 Epoch[11] Batch [1120]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.133672,	
2017-07-31 14:50:50,506 Epoch[11] Batch [1130]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.133749,	
2017-07-31 14:50:54,716 Epoch[11] Batch [1140]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.133692,	
2017-07-31 14:50:58,839 Epoch[11] Batch [1150]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.133681,	
2017-07-31 14:51:02,947 Epoch[11] Batch [1160]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.133513,	
2017-07-31 14:51:06,949 Epoch[11] Batch [1170]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.133510,	
2017-07-31 14:51:11,197 Epoch[11] Batch [1180]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.133464,	
2017-07-31 14:51:15,247 Epoch[11] Batch [1190]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.133562,	
2017-07-31 14:51:19,350 Epoch[11] Batch [1200]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.133618,	
2017-07-31 14:51:23,487 Epoch[11] Batch [1210]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.133400,	
2017-07-31 14:51:27,611 Epoch[11] Batch [1220]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.133318,	
2017-07-31 14:51:31,754 Epoch[11] Batch [1230]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.133304,	
2017-07-31 14:51:35,829 Epoch[11] Batch [1240]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.133254,	
2017-07-31 14:51:39,876 Epoch[11] Batch [1250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.133222,	
2017-07-31 14:51:44,065 Epoch[11] Batch [1260]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.133246,	
2017-07-31 14:51:48,237 Epoch[11] Batch [1270]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.133267,	
2017-07-31 14:51:52,357 Epoch[11] Batch [1280]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.133264,	
2017-07-31 14:51:56,548 Epoch[11] Batch [1290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.133328,	
2017-07-31 14:52:00,740 Epoch[11] Batch [1300]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.133292,	
2017-07-31 14:52:04,796 Epoch[11] Batch [1310]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.133202,	
2017-07-31 14:52:08,764 Epoch[11] Batch [1320]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.133200,	
2017-07-31 14:52:12,856 Epoch[11] Batch [1330]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.133347,	
2017-07-31 14:52:17,108 Epoch[11] Batch [1340]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.133434,	
2017-07-31 14:52:21,246 Epoch[11] Batch [1350]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.133696,	
2017-07-31 14:52:25,394 Epoch[11] Batch [1360]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.133779,	
2017-07-31 14:52:29,545 Epoch[11] Batch [1370]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.133933,	
2017-07-31 14:52:33,702 Epoch[11] Batch [1380]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.133976,	
2017-07-31 14:52:37,940 Epoch[11] Batch [1390]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.134222,	
2017-07-31 14:52:42,209 Epoch[11] Batch [1400]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.134333,	
2017-07-31 14:52:46,636 Epoch[11] Batch [1410]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.134312,	
2017-07-31 14:52:50,774 Epoch[11] Batch [1420]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.134413,	
2017-07-31 14:52:54,844 Epoch[11] Batch [1430]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.134453,	
2017-07-31 14:52:58,986 Epoch[11] Batch [1440]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.134469,	
2017-07-31 14:53:03,120 Epoch[11] Batch [1450]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.134507,	
2017-07-31 14:53:07,198 Epoch[11] Batch [1460]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.134539,	
2017-07-31 14:53:11,408 Epoch[11] Batch [1470]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.134511,	
2017-07-31 14:53:15,580 Epoch[11] Batch [1480]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.134617,	
2017-07-31 14:53:18,088 Epoch[11] Train-FCNLogLoss=0.134590
2017-07-31 14:53:18,088 Epoch[11] Time cost=622.148
2017-07-31 14:53:18,975 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.params"
2017-07-31 14:53:22,304 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.states"
2017-07-31 14:53:27,522 Epoch[12] Batch [10]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.140746,	
2017-07-31 14:53:32,611 Epoch[12] Batch [20]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.135955,	
2017-07-31 14:53:38,004 Epoch[12] Batch [30]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.144769,	
2017-07-31 14:53:42,875 Epoch[12] Batch [40]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.141543,	
2017-07-31 14:53:47,739 Epoch[12] Batch [50]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.145148,	
2017-07-31 14:53:52,961 Epoch[12] Batch [60]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.144999,	
2017-07-31 14:53:57,340 Epoch[12] Batch [70]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.142768,	
2017-07-31 14:54:01,776 Epoch[12] Batch [80]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.140801,	
2017-07-31 14:54:06,539 Epoch[12] Batch [90]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.139364,	
2017-07-31 14:54:11,522 Epoch[12] Batch [100]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.139891,	
2017-07-31 14:54:16,526 Epoch[12] Batch [110]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.140644,	
2017-07-31 14:54:21,144 Epoch[12] Batch [120]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.140422,	
2017-07-31 14:54:25,561 Epoch[12] Batch [130]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.138918,	
2017-07-31 14:54:30,394 Epoch[12] Batch [140]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.138215,	
2017-07-31 14:54:34,971 Epoch[12] Batch [150]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.138638,	
2017-07-31 14:54:39,409 Epoch[12] Batch [160]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.138433,	
2017-07-31 14:54:43,998 Epoch[12] Batch [170]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.137789,	
2017-07-31 14:54:48,513 Epoch[12] Batch [180]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.137235,	
2017-07-31 14:54:53,170 Epoch[12] Batch [190]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.136157,	
2017-07-31 14:54:57,542 Epoch[12] Batch [200]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.135815,	
2017-07-31 14:55:01,950 Epoch[12] Batch [210]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.135637,	
2017-07-31 14:55:06,593 Epoch[12] Batch [220]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.135391,	
2017-07-31 14:55:11,858 Epoch[12] Batch [230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.135423,	
2017-07-31 14:55:16,907 Epoch[12] Batch [240]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.135568,	
2017-07-31 14:55:21,572 Epoch[12] Batch [250]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.135919,	
2017-07-31 14:55:26,162 Epoch[12] Batch [260]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.135728,	
2017-07-31 14:55:31,007 Epoch[12] Batch [270]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.135539,	
2017-07-31 14:55:35,995 Epoch[12] Batch [280]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.135236,	
2017-07-31 14:55:40,454 Epoch[12] Batch [290]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.134742,	
2017-07-31 14:55:44,802 Epoch[12] Batch [300]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.134307,	
2017-07-31 14:55:49,342 Epoch[12] Batch [310]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.134063,	
2017-07-31 14:55:54,074 Epoch[12] Batch [320]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.133886,	
2017-07-31 14:55:59,260 Epoch[12] Batch [330]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.133959,	
2017-07-31 14:56:03,949 Epoch[12] Batch [340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.133919,	
2017-07-31 14:56:08,646 Epoch[12] Batch [350]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.133570,	
2017-07-31 14:56:13,622 Epoch[12] Batch [360]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.133697,	
2017-07-31 14:56:18,243 Epoch[12] Batch [370]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.134075,	
2017-07-31 14:56:22,655 Epoch[12] Batch [380]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.134052,	
2017-07-31 14:56:27,749 Epoch[12] Batch [390]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.133939,	
2017-07-31 14:56:32,432 Epoch[12] Batch [400]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.133941,	
2017-07-31 14:56:36,897 Epoch[12] Batch [410]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.133730,	
2017-07-31 14:56:41,291 Epoch[12] Batch [420]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.133428,	
2017-07-31 14:56:45,786 Epoch[12] Batch [430]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.133130,	
2017-07-31 14:56:50,566 Epoch[12] Batch [440]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.132940,	
2017-07-31 14:56:55,647 Epoch[12] Batch [450]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.132864,	
2017-07-31 14:57:00,283 Epoch[12] Batch [460]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.133160,	
2017-07-31 14:57:05,716 Epoch[12] Batch [470]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.133042,	
2017-07-31 14:57:10,665 Epoch[12] Batch [480]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.132805,	
2017-07-31 14:57:15,228 Epoch[12] Batch [490]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.132690,	
2017-07-31 14:57:19,793 Epoch[12] Batch [500]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.132651,	
2017-07-31 14:57:24,717 Epoch[12] Batch [510]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.132955,	
2017-07-31 14:57:29,774 Epoch[12] Batch [520]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.133250,	
2017-07-31 14:57:34,684 Epoch[12] Batch [530]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.133136,	
2017-07-31 14:57:39,280 Epoch[12] Batch [540]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.133087,	
2017-07-31 14:57:43,710 Epoch[12] Batch [550]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.133097,	
2017-07-31 14:57:48,358 Epoch[12] Batch [560]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.132918,	
2017-07-31 14:57:53,028 Epoch[12] Batch [570]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.133013,	
2017-07-31 14:57:57,745 Epoch[12] Batch [580]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.132883,	
2017-07-31 14:58:02,488 Epoch[12] Batch [590]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.132774,	
2017-07-31 14:58:07,022 Epoch[12] Batch [600]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.132556,	
2017-07-31 14:58:11,549 Epoch[12] Batch [610]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.132520,	
2017-07-31 14:58:16,668 Epoch[12] Batch [620]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.132332,	
2017-07-31 14:58:21,252 Epoch[12] Batch [630]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.132120,	
2017-07-31 14:58:26,089 Epoch[12] Batch [640]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.132291,	
2017-07-31 14:58:31,662 Epoch[12] Batch [650]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.132129,	
2017-07-31 14:58:36,555 Epoch[12] Batch [660]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.132257,	
2017-07-31 14:58:41,345 Epoch[12] Batch [670]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.132391,	
2017-07-31 14:58:46,092 Epoch[12] Batch [680]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.132406,	
2017-07-31 14:58:50,604 Epoch[12] Batch [690]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.132263,	
2017-07-31 14:58:56,125 Epoch[12] Batch [700]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.132148,	
2017-07-31 14:59:01,250 Epoch[12] Batch [710]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.132033,	
2017-07-31 14:59:06,303 Epoch[12] Batch [720]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.131957,	
2017-07-31 14:59:11,596 Epoch[12] Batch [730]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.131784,	
2017-07-31 14:59:16,753 Epoch[12] Batch [740]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.131680,	
2017-07-31 14:59:21,662 Epoch[12] Batch [750]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.131920,	
2017-07-31 14:59:26,169 Epoch[12] Batch [760]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.131797,	
2017-07-31 14:59:30,967 Epoch[12] Batch [770]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.131643,	
2017-07-31 14:59:35,777 Epoch[12] Batch [780]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.131757,	
2017-07-31 14:59:40,816 Epoch[12] Batch [790]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.131521,	
2017-07-31 14:59:45,439 Epoch[12] Batch [800]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.131490,	
2017-07-31 14:59:49,802 Epoch[12] Batch [810]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.131767,	
2017-07-31 14:59:54,311 Epoch[12] Batch [820]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.131968,	
2017-07-31 14:59:59,201 Epoch[12] Batch [830]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.132065,	
2017-07-31 15:00:04,028 Epoch[12] Batch [840]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.132398,	
2017-07-31 15:00:09,233 Epoch[12] Batch [850]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.132378,	
2017-07-31 15:00:13,561 Epoch[12] Batch [860]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.132299,	
2017-07-31 15:00:18,237 Epoch[12] Batch [870]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.132427,	
2017-07-31 15:00:22,708 Epoch[12] Batch [880]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.132331,	
2017-07-31 15:00:27,907 Epoch[12] Batch [890]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.132356,	
2017-07-31 15:00:32,695 Epoch[12] Batch [900]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.132231,	
2017-07-31 15:00:37,220 Epoch[12] Batch [910]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.132102,	
2017-07-31 15:00:42,225 Epoch[12] Batch [920]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.132059,	
2017-07-31 15:00:47,275 Epoch[12] Batch [930]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.132057,	
2017-07-31 15:00:52,230 Epoch[12] Batch [940]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.132306,	
2017-07-31 15:00:57,237 Epoch[12] Batch [950]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.132248,	
2017-07-31 15:01:01,980 Epoch[12] Batch [960]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.132365,	
2017-07-31 15:01:06,799 Epoch[12] Batch [970]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.132613,	
2017-07-31 15:01:11,244 Epoch[12] Batch [980]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.132635,	
2017-07-31 15:01:15,690 Epoch[12] Batch [990]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.132671,	
2017-07-31 15:01:20,323 Epoch[12] Batch [1000]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.132985,	
2017-07-31 15:01:25,812 Epoch[12] Batch [1010]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.133007,	
2017-07-31 15:01:30,425 Epoch[12] Batch [1020]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.133059,	
2017-07-31 15:01:35,016 Epoch[12] Batch [1030]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.133046,	
2017-07-31 15:01:39,786 Epoch[12] Batch [1040]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.132991,	
2017-07-31 15:01:44,498 Epoch[12] Batch [1050]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.133029,	
2017-07-31 15:01:49,095 Epoch[12] Batch [1060]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.132906,	
2017-07-31 15:01:53,789 Epoch[12] Batch [1070]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.133103,	
2017-07-31 15:01:58,313 Epoch[12] Batch [1080]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.133306,	
2017-07-31 15:02:02,697 Epoch[12] Batch [1090]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.133450,	
2017-07-31 15:02:07,242 Epoch[12] Batch [1100]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.133628,	
2017-07-31 15:02:11,714 Epoch[12] Batch [1110]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.133622,	
2017-07-31 15:02:17,116 Epoch[12] Batch [1120]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.133566,	
2017-07-31 15:02:21,836 Epoch[12] Batch [1130]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.133489,	
2017-07-31 15:02:26,198 Epoch[12] Batch [1140]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.133508,	
2017-07-31 15:02:30,833 Epoch[12] Batch [1150]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.133477,	
2017-07-31 15:02:35,197 Epoch[12] Batch [1160]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.133726,	
2017-07-31 15:02:40,035 Epoch[12] Batch [1170]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.133677,	
2017-07-31 15:02:44,718 Epoch[12] Batch [1180]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.133621,	
2017-07-31 15:02:49,279 Epoch[12] Batch [1190]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.133472,	
2017-07-31 15:02:53,823 Epoch[12] Batch [1200]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.133627,	
2017-07-31 15:02:58,255 Epoch[12] Batch [1210]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.133616,	
2017-07-31 15:03:03,119 Epoch[12] Batch [1220]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.133651,	
2017-07-31 15:03:07,976 Epoch[12] Batch [1230]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.133418,	
2017-07-31 15:03:12,346 Epoch[12] Batch [1240]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.133388,	
2017-07-31 15:03:16,887 Epoch[12] Batch [1250]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.133331,	
2017-07-31 15:03:21,748 Epoch[12] Batch [1260]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.133317,	
2017-07-31 15:03:26,820 Epoch[12] Batch [1270]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.133350,	
2017-07-31 15:03:31,544 Epoch[12] Batch [1280]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.133287,	
2017-07-31 15:03:36,789 Epoch[12] Batch [1290]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.133174,	
2017-07-31 15:03:41,917 Epoch[12] Batch [1300]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.133121,	
2017-07-31 15:03:46,525 Epoch[12] Batch [1310]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.133089,	
2017-07-31 15:03:51,505 Epoch[12] Batch [1320]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.133084,	
2017-07-31 15:03:55,934 Epoch[12] Batch [1330]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.133092,	
2017-07-31 15:04:00,481 Epoch[12] Batch [1340]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.133131,	
2017-07-31 15:04:05,685 Epoch[12] Batch [1350]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.133123,	
2017-07-31 15:04:10,299 Epoch[12] Batch [1360]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.133220,	
2017-07-31 15:04:14,760 Epoch[12] Batch [1370]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.133343,	
2017-07-31 15:04:19,061 Epoch[12] Batch [1380]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.133535,	
2017-07-31 15:04:23,896 Epoch[12] Batch [1390]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.133669,	
2017-07-31 15:04:29,086 Epoch[12] Batch [1400]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.133676,	
2017-07-31 15:04:34,221 Epoch[12] Batch [1410]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.133861,	
2017-07-31 15:04:39,633 Epoch[12] Batch [1420]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.133973,	
2017-07-31 15:04:44,970 Epoch[12] Batch [1430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133988,	
2017-07-31 15:04:49,847 Epoch[12] Batch [1440]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.134043,	
2017-07-31 15:04:54,367 Epoch[12] Batch [1450]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.134014,	
2017-07-31 15:04:59,454 Epoch[12] Batch [1460]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.134025,	
2017-07-31 15:05:04,079 Epoch[12] Batch [1470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.133970,	
2017-07-31 15:05:09,034 Epoch[12] Batch [1480]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.133964,	
2017-07-31 15:05:12,467 Epoch[12] Train-FCNLogLoss=0.133989
2017-07-31 15:05:12,467 Epoch[12] Time cost=710.163
2017-07-31 15:05:13,462 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.params"
2017-07-31 15:05:16,767 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.states"
2017-07-31 15:05:22,676 Epoch[13] Batch [10]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.124645,	
2017-07-31 15:05:27,522 Epoch[13] Batch [20]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.132516,	
2017-07-31 15:05:33,062 Epoch[13] Batch [30]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.132045,	
2017-07-31 15:05:38,270 Epoch[13] Batch [40]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.133004,	
2017-07-31 15:05:43,263 Epoch[13] Batch [50]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.130112,	
2017-07-31 15:05:48,364 Epoch[13] Batch [60]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.132341,	
2017-07-31 15:05:53,409 Epoch[13] Batch [70]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.132113,	
2017-07-31 15:05:58,687 Epoch[13] Batch [80]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.133898,	
2017-07-31 15:06:03,642 Epoch[13] Batch [90]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.132100,	
2017-07-31 15:06:08,777 Epoch[13] Batch [100]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.131651,	
2017-07-31 15:06:14,061 Epoch[13] Batch [110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130913,	
2017-07-31 15:06:19,294 Epoch[13] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.130304,	
2017-07-31 15:06:24,490 Epoch[13] Batch [130]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.131156,	
2017-07-31 15:06:29,732 Epoch[13] Batch [140]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.130555,	
2017-07-31 15:06:34,864 Epoch[13] Batch [150]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.131038,	
2017-07-31 15:06:40,161 Epoch[13] Batch [160]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.131593,	
2017-07-31 15:06:45,544 Epoch[13] Batch [170]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.130879,	
2017-07-31 15:06:50,869 Epoch[13] Batch [180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131311,	
2017-07-31 15:06:56,231 Epoch[13] Batch [190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131051,	
2017-07-31 15:07:01,449 Epoch[13] Batch [200]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.130793,	
2017-07-31 15:07:06,335 Epoch[13] Batch [210]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.130827,	
2017-07-31 15:07:11,252 Epoch[13] Batch [220]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.130734,	
2017-07-31 15:07:16,481 Epoch[13] Batch [230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.130332,	
2017-07-31 15:07:21,590 Epoch[13] Batch [240]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.129745,	
2017-07-31 15:07:26,923 Epoch[13] Batch [250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.129672,	
2017-07-31 15:07:32,077 Epoch[13] Batch [260]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.130062,	
2017-07-31 15:07:37,353 Epoch[13] Batch [270]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130117,	
2017-07-31 15:07:42,687 Epoch[13] Batch [280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130029,	
2017-07-31 15:07:47,784 Epoch[13] Batch [290]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.129926,	
2017-07-31 15:07:53,080 Epoch[13] Batch [300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.129733,	
2017-07-31 15:07:58,051 Epoch[13] Batch [310]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.129714,	
2017-07-31 15:08:03,209 Epoch[13] Batch [320]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.129917,	
2017-07-31 15:08:08,285 Epoch[13] Batch [330]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.129811,	
2017-07-31 15:08:13,743 Epoch[13] Batch [340]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.130156,	
2017-07-31 15:08:19,056 Epoch[13] Batch [350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.129997,	
2017-07-31 15:08:24,214 Epoch[13] Batch [360]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.129805,	
2017-07-31 15:08:29,374 Epoch[13] Batch [370]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.129605,	
2017-07-31 15:08:34,480 Epoch[13] Batch [380]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.129714,	
2017-07-31 15:08:39,684 Epoch[13] Batch [390]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.129868,	
2017-07-31 15:08:44,898 Epoch[13] Batch [400]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.129565,	
2017-07-31 15:08:50,012 Epoch[13] Batch [410]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.129489,	
2017-07-31 15:08:55,055 Epoch[13] Batch [420]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.129712,	
2017-07-31 15:09:00,111 Epoch[13] Batch [430]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.129667,	
2017-07-31 15:09:05,099 Epoch[13] Batch [440]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.129271,	
2017-07-31 15:09:10,604 Epoch[13] Batch [450]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.129426,	
2017-07-31 15:09:15,690 Epoch[13] Batch [460]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.129285,	
2017-07-31 15:09:20,905 Epoch[13] Batch [470]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.129057,	
2017-07-31 15:09:26,237 Epoch[13] Batch [480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.129088,	
2017-07-31 15:09:31,560 Epoch[13] Batch [490]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.129049,	
2017-07-31 15:09:36,617 Epoch[13] Batch [500]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.128881,	
2017-07-31 15:09:42,115 Epoch[13] Batch [510]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.128795,	
2017-07-31 15:09:47,531 Epoch[13] Batch [520]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.128758,	
2017-07-31 15:09:52,895 Epoch[13] Batch [530]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.128768,	
2017-07-31 15:09:58,237 Epoch[13] Batch [540]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.128558,	
2017-07-31 15:10:03,652 Epoch[13] Batch [550]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.128696,	
2017-07-31 15:10:08,964 Epoch[13] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.128293,	
2017-07-31 15:10:14,049 Epoch[13] Batch [570]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.128450,	
2017-07-31 15:10:18,907 Epoch[13] Batch [580]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.128436,	
2017-07-31 15:10:24,172 Epoch[13] Batch [590]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.128682,	
2017-07-31 15:10:29,397 Epoch[13] Batch [600]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.128824,	
2017-07-31 15:10:34,537 Epoch[13] Batch [610]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.129020,	
2017-07-31 15:10:39,699 Epoch[13] Batch [620]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.128872,	
2017-07-31 15:10:44,845 Epoch[13] Batch [630]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.129022,	
2017-07-31 15:10:50,095 Epoch[13] Batch [640]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.129044,	
2017-07-31 15:10:54,881 Epoch[13] Batch [650]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.129188,	
2017-07-31 15:10:59,975 Epoch[13] Batch [660]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.129265,	
2017-07-31 15:11:05,320 Epoch[13] Batch [670]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.129461,	
2017-07-31 15:11:10,753 Epoch[13] Batch [680]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.129453,	
2017-07-31 15:11:16,292 Epoch[13] Batch [690]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.129273,	
2017-07-31 15:11:21,430 Epoch[13] Batch [700]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.129287,	
2017-07-31 15:11:26,732 Epoch[13] Batch [710]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.129216,	
2017-07-31 15:11:31,875 Epoch[13] Batch [720]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.129233,	
2017-07-31 15:11:37,218 Epoch[13] Batch [730]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129176,	
2017-07-31 15:11:42,444 Epoch[13] Batch [740]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.129204,	
2017-07-31 15:11:47,656 Epoch[13] Batch [750]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.129346,	
2017-07-31 15:11:52,712 Epoch[13] Batch [760]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.129420,	
2017-07-31 15:11:58,072 Epoch[13] Batch [770]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.129154,	
2017-07-31 15:12:03,558 Epoch[13] Batch [780]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.129106,	
2017-07-31 15:12:09,223 Epoch[13] Batch [790]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.129320,	
2017-07-31 15:12:15,168 Epoch[13] Batch [800]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.129502,	
2017-07-31 15:12:20,932 Epoch[13] Batch [810]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.129658,	
2017-07-31 15:12:26,566 Epoch[13] Batch [820]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.129521,	
2017-07-31 15:12:32,472 Epoch[13] Batch [830]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.129559,	
2017-07-31 15:12:38,462 Epoch[13] Batch [840]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.129551,	
2017-07-31 15:12:44,736 Epoch[13] Batch [850]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.129393,	
2017-07-31 15:12:51,118 Epoch[13] Batch [860]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.130015,	
2017-07-31 15:12:57,428 Epoch[13] Batch [870]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.130107,	
2017-07-31 15:13:03,986 Epoch[13] Batch [880]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.130108,	
2017-07-31 15:13:10,745 Epoch[13] Batch [890]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.130080,	
2017-07-31 15:13:17,702 Epoch[13] Batch [900]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.130301,	
2017-07-31 15:13:24,653 Epoch[13] Batch [910]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.130323,	
2017-07-31 15:13:31,143 Epoch[13] Batch [920]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.130644,	
2017-07-31 15:13:38,005 Epoch[13] Batch [930]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.130930,	
2017-07-31 15:13:45,054 Epoch[13] Batch [940]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.130953,	
2017-07-31 15:13:51,988 Epoch[13] Batch [950]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.130875,	
2017-07-31 15:13:59,026 Epoch[13] Batch [960]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.130752,	
2017-07-31 15:14:06,007 Epoch[13] Batch [970]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.130807,	
2017-07-31 15:14:12,937 Epoch[13] Batch [980]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.130825,	
2017-07-31 15:14:19,900 Epoch[13] Batch [990]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.130874,	
2017-07-31 15:14:26,889 Epoch[13] Batch [1000]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.130958,	
2017-07-31 15:14:33,821 Epoch[13] Batch [1010]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.130898,	
2017-07-31 15:14:40,819 Epoch[13] Batch [1020]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.130767,	
2017-07-31 15:14:47,731 Epoch[13] Batch [1030]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.130707,	
2017-07-31 15:14:54,860 Epoch[13] Batch [1040]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.130684,	
2017-07-31 15:15:01,892 Epoch[13] Batch [1050]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.130762,	
2017-07-31 15:15:08,850 Epoch[13] Batch [1060]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.130713,	
2017-07-31 15:15:15,875 Epoch[13] Batch [1070]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.130634,	
2017-07-31 15:15:22,865 Epoch[13] Batch [1080]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.130483,	
2017-07-31 15:15:29,771 Epoch[13] Batch [1090]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.130375,	
2017-07-31 15:15:36,814 Epoch[13] Batch [1100]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.130410,	
2017-07-31 15:15:43,722 Epoch[13] Batch [1110]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.130184,	
2017-07-31 15:15:50,800 Epoch[13] Batch [1120]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.130186,	
2017-07-31 15:15:57,830 Epoch[13] Batch [1130]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.130177,	
2017-07-31 15:16:04,896 Epoch[13] Batch [1140]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.130325,	
2017-07-31 15:16:11,944 Epoch[13] Batch [1150]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.130223,	
2017-07-31 15:16:19,041 Epoch[13] Batch [1160]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.130190,	
2017-07-31 15:16:26,036 Epoch[13] Batch [1170]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.130013,	
2017-07-31 15:16:33,112 Epoch[13] Batch [1180]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.129970,	
2017-07-31 15:16:40,035 Epoch[13] Batch [1190]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.130014,	
2017-07-31 15:16:47,137 Epoch[13] Batch [1200]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.130104,	
2017-07-31 15:16:54,209 Epoch[13] Batch [1210]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.130005,	
2017-07-31 15:17:01,115 Epoch[13] Batch [1220]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.129935,	
2017-07-31 15:17:08,143 Epoch[13] Batch [1230]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.130201,	
2017-07-31 15:17:15,155 Epoch[13] Batch [1240]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.130108,	
2017-07-31 15:17:22,179 Epoch[13] Batch [1250]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.130124,	
2017-07-31 15:17:29,166 Epoch[13] Batch [1260]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.130061,	
2017-07-31 15:17:36,070 Epoch[13] Batch [1270]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.130090,	
2017-07-31 15:17:43,064 Epoch[13] Batch [1280]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.130233,	
2017-07-31 15:17:50,073 Epoch[13] Batch [1290]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.130374,	
2017-07-31 15:17:57,051 Epoch[13] Batch [1300]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.130372,	
2017-07-31 15:18:04,071 Epoch[13] Batch [1310]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.130403,	
2017-07-31 15:18:11,143 Epoch[13] Batch [1320]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.130424,	
2017-07-31 15:18:18,283 Epoch[13] Batch [1330]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.130360,	
2017-07-31 15:18:25,177 Epoch[13] Batch [1340]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.130442,	
2017-07-31 15:18:32,219 Epoch[13] Batch [1350]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.130327,	
2017-07-31 15:18:39,259 Epoch[13] Batch [1360]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.130237,	
2017-07-31 15:18:46,308 Epoch[13] Batch [1370]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.130215,	
2017-07-31 15:18:53,354 Epoch[13] Batch [1380]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.129965,	
2017-07-31 15:19:00,214 Epoch[13] Batch [1390]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.129915,	
2017-07-31 15:19:07,197 Epoch[13] Batch [1400]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.129976,	
2017-07-31 15:19:14,249 Epoch[13] Batch [1410]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.129967,	
2017-07-31 15:19:21,274 Epoch[13] Batch [1420]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.129913,	
2017-07-31 15:19:28,244 Epoch[13] Batch [1430]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.129908,	
2017-07-31 15:19:35,203 Epoch[13] Batch [1440]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.129913,	
2017-07-31 15:19:42,263 Epoch[13] Batch [1450]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.129966,	
2017-07-31 15:19:49,410 Epoch[13] Batch [1460]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.129938,	
2017-07-31 15:19:56,467 Epoch[13] Batch [1470]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.129899,	
2017-07-31 15:20:03,358 Epoch[13] Batch [1480]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.129823,	
2017-07-31 15:20:07,524 Epoch[13] Train-FCNLogLoss=0.129848
2017-07-31 15:20:07,525 Epoch[13] Time cost=890.757
2017-07-31 15:20:08,687 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.params"
2017-07-31 15:20:12,090 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.states"
2017-07-31 15:20:18,514 Epoch[14] Batch [10]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.129118,	
2017-07-31 15:20:24,214 Epoch[14] Batch [20]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.125769,	
2017-07-31 15:20:29,664 Epoch[14] Batch [30]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.127681,	
2017-07-31 15:20:35,038 Epoch[14] Batch [40]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.127032,	
2017-07-31 15:20:40,364 Epoch[14] Batch [50]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.127830,	
2017-07-31 15:20:46,040 Epoch[14] Batch [60]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.127096,	
2017-07-31 15:20:51,520 Epoch[14] Batch [70]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.128989,	
2017-07-31 15:20:56,955 Epoch[14] Batch [80]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.130545,	
2017-07-31 15:21:02,222 Epoch[14] Batch [90]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.130711,	
2017-07-31 15:21:07,845 Epoch[14] Batch [100]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.130713,	
2017-07-31 15:21:13,638 Epoch[14] Batch [110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.130143,	
2017-07-31 15:21:18,922 Epoch[14] Batch [120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.128840,	
2017-07-31 15:21:24,069 Epoch[14] Batch [130]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.128599,	
2017-07-31 15:21:29,294 Epoch[14] Batch [140]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.128398,	
2017-07-31 15:21:34,272 Epoch[14] Batch [150]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.128493,	
2017-07-31 15:21:39,342 Epoch[14] Batch [160]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.129542,	
2017-07-31 15:21:44,439 Epoch[14] Batch [170]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.128292,	
2017-07-31 15:21:49,395 Epoch[14] Batch [180]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.128932,	
2017-07-31 15:21:54,657 Epoch[14] Batch [190]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.128872,	
2017-07-31 15:21:59,791 Epoch[14] Batch [200]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.128466,	
2017-07-31 15:22:04,729 Epoch[14] Batch [210]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.128565,	
2017-07-31 15:22:09,493 Epoch[14] Batch [220]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.128968,	
2017-07-31 15:22:14,066 Epoch[14] Batch [230]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.128534,	
2017-07-31 15:22:18,563 Epoch[14] Batch [240]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.128228,	
2017-07-31 15:22:23,143 Epoch[14] Batch [250]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.128502,	
2017-07-31 15:22:27,898 Epoch[14] Batch [260]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.128447,	
2017-07-31 15:22:32,808 Epoch[14] Batch [270]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.128065,	
2017-07-31 15:22:37,803 Epoch[14] Batch [280]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.128463,	
2017-07-31 15:22:43,185 Epoch[14] Batch [290]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.127847,	
2017-07-31 15:22:48,246 Epoch[14] Batch [300]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.127947,	
2017-07-31 15:22:53,658 Epoch[14] Batch [310]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.127491,	
2017-07-31 15:22:58,854 Epoch[14] Batch [320]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.127977,	
2017-07-31 15:23:03,843 Epoch[14] Batch [330]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.128431,	
2017-07-31 15:23:08,838 Epoch[14] Batch [340]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.129033,	
2017-07-31 15:23:14,266 Epoch[14] Batch [350]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.129021,	
2017-07-31 15:23:19,290 Epoch[14] Batch [360]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.129094,	
2017-07-31 15:23:24,421 Epoch[14] Batch [370]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.129497,	
2017-07-31 15:23:30,004 Epoch[14] Batch [380]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.129745,	
2017-07-31 15:23:34,954 Epoch[14] Batch [390]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.130267,	
2017-07-31 15:23:40,268 Epoch[14] Batch [400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130110,	
2017-07-31 15:23:45,400 Epoch[14] Batch [410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.130508,	
2017-07-31 15:23:50,115 Epoch[14] Batch [420]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.130025,	
2017-07-31 15:23:55,491 Epoch[14] Batch [430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.129814,	
2017-07-31 15:24:00,409 Epoch[14] Batch [440]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.130045,	
2017-07-31 15:24:05,521 Epoch[14] Batch [450]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.129650,	
2017-07-31 15:24:10,596 Epoch[14] Batch [460]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.129637,	
2017-07-31 15:24:15,225 Epoch[14] Batch [470]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.129982,	
2017-07-31 15:24:20,201 Epoch[14] Batch [480]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.130046,	
2017-07-31 15:24:25,469 Epoch[14] Batch [490]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.129945,	
2017-07-31 15:24:30,822 Epoch[14] Batch [500]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.129692,	
2017-07-31 15:24:36,250 Epoch[14] Batch [510]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.129794,	
2017-07-31 15:24:41,048 Epoch[14] Batch [520]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.129973,	
2017-07-31 15:24:45,879 Epoch[14] Batch [530]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.130110,	
2017-07-31 15:24:51,212 Epoch[14] Batch [540]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130064,	
2017-07-31 15:24:56,634 Epoch[14] Batch [550]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.130182,	
2017-07-31 15:25:01,944 Epoch[14] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130207,	
2017-07-31 15:25:07,122 Epoch[14] Batch [570]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.130022,	
2017-07-31 15:25:12,705 Epoch[14] Batch [580]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.129887,	
2017-07-31 15:25:17,759 Epoch[14] Batch [590]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.129923,	
2017-07-31 15:25:22,656 Epoch[14] Batch [600]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.130022,	
2017-07-31 15:25:27,958 Epoch[14] Batch [610]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.129763,	
2017-07-31 15:25:32,991 Epoch[14] Batch [620]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.129703,	
2017-07-31 15:25:38,021 Epoch[14] Batch [630]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.129562,	
2017-07-31 15:25:43,241 Epoch[14] Batch [640]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.129644,	
2017-07-31 15:25:48,475 Epoch[14] Batch [650]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.129948,	
2017-07-31 15:25:53,915 Epoch[14] Batch [660]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.129999,	
2017-07-31 15:25:59,409 Epoch[14] Batch [670]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.130490,	
2017-07-31 15:26:04,682 Epoch[14] Batch [680]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.131170,	
2017-07-31 15:26:09,784 Epoch[14] Batch [690]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.130897,	
2017-07-31 15:26:15,395 Epoch[14] Batch [700]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.130813,	
2017-07-31 15:26:20,885 Epoch[14] Batch [710]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.130756,	
2017-07-31 15:26:26,205 Epoch[14] Batch [720]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130710,	
2017-07-31 15:26:31,201 Epoch[14] Batch [730]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.130497,	
2017-07-31 15:26:35,603 Epoch[14] Batch [740]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.130189,	
2017-07-31 15:26:39,844 Epoch[14] Batch [750]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.130052,	
2017-07-31 15:26:43,713 Epoch[14] Batch [760]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.129966,	
2017-07-31 15:26:47,439 Epoch[14] Batch [770]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.129853,	
2017-07-31 15:26:51,188 Epoch[14] Batch [780]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.129764,	
2017-07-31 15:26:55,067 Epoch[14] Batch [790]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.129740,	
2017-07-31 15:26:58,814 Epoch[14] Batch [800]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.129660,	
2017-07-31 15:27:02,521 Epoch[14] Batch [810]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.129957,	
2017-07-31 15:27:06,346 Epoch[14] Batch [820]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.129911,	
2017-07-31 15:27:10,377 Epoch[14] Batch [830]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.129996,	
2017-07-31 15:27:14,434 Epoch[14] Batch [840]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.129991,	
2017-07-31 15:27:18,313 Epoch[14] Batch [850]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.130042,	
2017-07-31 15:27:22,103 Epoch[14] Batch [860]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.130116,	
2017-07-31 15:27:25,847 Epoch[14] Batch [870]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.130015,	
2017-07-31 15:27:29,594 Epoch[14] Batch [880]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.129940,	
2017-07-31 15:27:33,327 Epoch[14] Batch [890]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.129986,	
2017-07-31 15:27:37,056 Epoch[14] Batch [900]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.129756,	
2017-07-31 15:27:40,888 Epoch[14] Batch [910]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.129900,	
2017-07-31 15:27:44,638 Epoch[14] Batch [920]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.129738,	
2017-07-31 15:27:48,556 Epoch[14] Batch [930]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.129728,	
2017-07-31 15:27:52,399 Epoch[14] Batch [940]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.129484,	
2017-07-31 15:27:56,238 Epoch[14] Batch [950]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.129535,	
2017-07-31 15:28:00,165 Epoch[14] Batch [960]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.129523,	
2017-07-31 15:28:03,891 Epoch[14] Batch [970]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.129816,	
2017-07-31 15:28:07,681 Epoch[14] Batch [980]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.129745,	
2017-07-31 15:28:11,465 Epoch[14] Batch [990]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.130073,	
2017-07-31 15:28:15,310 Epoch[14] Batch [1000]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.130063,	
2017-07-31 15:28:19,116 Epoch[14] Batch [1010]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.130135,	
2017-07-31 15:28:22,955 Epoch[14] Batch [1020]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.130214,	
2017-07-31 15:28:26,812 Epoch[14] Batch [1030]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.130260,	
2017-07-31 15:28:30,700 Epoch[14] Batch [1040]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.130363,	
2017-07-31 15:28:34,468 Epoch[14] Batch [1050]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.130343,	
2017-07-31 15:28:38,263 Epoch[14] Batch [1060]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.130263,	
2017-07-31 15:28:42,050 Epoch[14] Batch [1070]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.130254,	
2017-07-31 15:28:45,852 Epoch[14] Batch [1080]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.130273,	
2017-07-31 15:28:49,688 Epoch[14] Batch [1090]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.130105,	
2017-07-31 15:28:53,475 Epoch[14] Batch [1100]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.130039,	
2017-07-31 15:28:57,240 Epoch[14] Batch [1110]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.130029,	
2017-07-31 15:29:01,183 Epoch[14] Batch [1120]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.130101,	
2017-07-31 15:29:04,937 Epoch[14] Batch [1130]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.130112,	
2017-07-31 15:29:08,881 Epoch[14] Batch [1140]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.130220,	
2017-07-31 15:29:13,033 Epoch[14] Batch [1150]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.130411,	
2017-07-31 15:29:16,783 Epoch[14] Batch [1160]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.130318,	
2017-07-31 15:29:20,626 Epoch[14] Batch [1170]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.130245,	
2017-07-31 15:29:24,364 Epoch[14] Batch [1180]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.130307,	
2017-07-31 15:29:28,190 Epoch[14] Batch [1190]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.130248,	
2017-07-31 15:29:31,932 Epoch[14] Batch [1200]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.130263,	
2017-07-31 15:29:35,688 Epoch[14] Batch [1210]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.130153,	
2017-07-31 15:29:39,480 Epoch[14] Batch [1220]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.130048,	
2017-07-31 15:29:43,367 Epoch[14] Batch [1230]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.129963,	
2017-07-31 15:29:47,058 Epoch[14] Batch [1240]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.129957,	
2017-07-31 15:29:50,908 Epoch[14] Batch [1250]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.129846,	
2017-07-31 15:29:54,743 Epoch[14] Batch [1260]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.129884,	
2017-07-31 15:29:58,635 Epoch[14] Batch [1270]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.129719,	
2017-07-31 15:30:02,440 Epoch[14] Batch [1280]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.129653,	
2017-07-31 15:30:06,302 Epoch[14] Batch [1290]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.129565,	
2017-07-31 15:30:10,136 Epoch[14] Batch [1300]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.129402,	
2017-07-31 15:30:13,923 Epoch[14] Batch [1310]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.129263,	
2017-07-31 15:30:17,916 Epoch[14] Batch [1320]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.129227,	
2017-07-31 15:30:21,746 Epoch[14] Batch [1330]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.129012,	
2017-07-31 15:30:25,696 Epoch[14] Batch [1340]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.128902,	
2017-07-31 15:30:29,459 Epoch[14] Batch [1350]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.128824,	
2017-07-31 15:30:33,493 Epoch[14] Batch [1360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.128884,	
2017-07-31 15:30:37,248 Epoch[14] Batch [1370]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.128784,	
2017-07-31 15:30:41,104 Epoch[14] Batch [1380]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.128641,	
2017-07-31 15:30:44,908 Epoch[14] Batch [1390]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.128627,	
2017-07-31 15:30:48,692 Epoch[14] Batch [1400]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.128556,	
2017-07-31 15:30:52,513 Epoch[14] Batch [1410]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.128669,	
2017-07-31 15:30:56,594 Epoch[14] Batch [1420]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.128712,	
2017-07-31 15:31:00,465 Epoch[14] Batch [1430]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.128820,	
2017-07-31 15:31:04,419 Epoch[14] Batch [1440]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.128822,	
2017-07-31 15:31:08,889 Epoch[14] Batch [1450]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.128746,	
2017-07-31 15:31:13,213 Epoch[14] Batch [1460]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.128659,	
2017-07-31 15:31:17,130 Epoch[14] Batch [1470]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.128639,	
2017-07-31 15:31:20,947 Epoch[14] Batch [1480]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.128633,	
2017-07-31 15:31:23,164 Epoch[14] Train-FCNLogLoss=0.128663
2017-07-31 15:31:23,165 Epoch[14] Time cost=671.074
2017-07-31 15:31:23,962 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.params"
2017-07-31 15:31:25,463 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.states"
2017-07-31 15:31:30,159 Epoch[15] Batch [10]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.133273,	
2017-07-31 15:31:34,029 Epoch[15] Batch [20]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.127004,	
2017-07-31 15:31:37,838 Epoch[15] Batch [30]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.121125,	
2017-07-31 15:31:41,584 Epoch[15] Batch [40]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.119683,	
2017-07-31 15:31:45,926 Epoch[15] Batch [50]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.118459,	
2017-07-31 15:31:49,844 Epoch[15] Batch [60]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.118139,	
2017-07-31 15:31:53,906 Epoch[15] Batch [70]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.119564,	
2017-07-31 15:31:57,854 Epoch[15] Batch [80]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.121607,	
2017-07-31 15:32:01,526 Epoch[15] Batch [90]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.120673,	
2017-07-31 15:32:05,355 Epoch[15] Batch [100]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.120080,	
2017-07-31 15:32:09,642 Epoch[15] Batch [110]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.119201,	
2017-07-31 15:32:13,388 Epoch[15] Batch [120]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.119309,	
2017-07-31 15:32:17,202 Epoch[15] Batch [130]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.119372,	
2017-07-31 15:32:21,262 Epoch[15] Batch [140]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.119298,	
2017-07-31 15:32:25,498 Epoch[15] Batch [150]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.119833,	
2017-07-31 15:32:29,646 Epoch[15] Batch [160]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.120711,	
2017-07-31 15:32:33,487 Epoch[15] Batch [170]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.121787,	
2017-07-31 15:32:37,500 Epoch[15] Batch [180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.121413,	
2017-07-31 15:32:41,665 Epoch[15] Batch [190]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.122628,	
2017-07-31 15:32:45,527 Epoch[15] Batch [200]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.123112,	
2017-07-31 15:32:49,268 Epoch[15] Batch [210]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.123609,	
2017-07-31 15:32:53,213 Epoch[15] Batch [220]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.123741,	
2017-07-31 15:32:57,100 Epoch[15] Batch [230]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.123224,	
2017-07-31 15:33:01,018 Epoch[15] Batch [240]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.123198,	
2017-07-31 15:33:04,934 Epoch[15] Batch [250]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.123169,	
2017-07-31 15:33:08,913 Epoch[15] Batch [260]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.123133,	
2017-07-31 15:33:12,874 Epoch[15] Batch [270]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.123292,	
2017-07-31 15:33:16,629 Epoch[15] Batch [280]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.123137,	
2017-07-31 15:33:20,628 Epoch[15] Batch [290]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.122827,	
2017-07-31 15:33:24,408 Epoch[15] Batch [300]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.123256,	
2017-07-31 15:33:28,661 Epoch[15] Batch [310]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.123375,	
2017-07-31 15:33:32,734 Epoch[15] Batch [320]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.123260,	
2017-07-31 15:33:36,583 Epoch[15] Batch [330]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.122896,	
2017-07-31 15:33:40,559 Epoch[15] Batch [340]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.122381,	
2017-07-31 15:33:44,391 Epoch[15] Batch [350]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.122410,	
2017-07-31 15:33:48,326 Epoch[15] Batch [360]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.121934,	
2017-07-31 15:33:52,297 Epoch[15] Batch [370]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.122032,	
2017-07-31 15:33:56,572 Epoch[15] Batch [380]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.122363,	
2017-07-31 15:34:00,466 Epoch[15] Batch [390]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.122437,	
2017-07-31 15:34:04,209 Epoch[15] Batch [400]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.122098,	
2017-07-31 15:34:07,960 Epoch[15] Batch [410]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.122531,	
2017-07-31 15:34:11,755 Epoch[15] Batch [420]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.122905,	
2017-07-31 15:34:15,888 Epoch[15] Batch [430]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.123024,	
2017-07-31 15:34:19,771 Epoch[15] Batch [440]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.123274,	
2017-07-31 15:34:23,857 Epoch[15] Batch [450]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.123142,	
2017-07-31 15:34:28,050 Epoch[15] Batch [460]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.123211,	
2017-07-31 15:34:31,979 Epoch[15] Batch [470]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.122910,	
2017-07-31 15:34:36,229 Epoch[15] Batch [480]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.122726,	
2017-07-31 15:34:40,021 Epoch[15] Batch [490]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.123025,	
2017-07-31 15:34:43,985 Epoch[15] Batch [500]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.123246,	
2017-07-31 15:34:47,808 Epoch[15] Batch [510]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.123436,	
2017-07-31 15:34:51,712 Epoch[15] Batch [520]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.123342,	
2017-07-31 15:34:55,436 Epoch[15] Batch [530]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.123162,	
2017-07-31 15:34:59,180 Epoch[15] Batch [540]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.123270,	
2017-07-31 15:35:03,155 Epoch[15] Batch [550]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.123290,	
2017-07-31 15:35:06,953 Epoch[15] Batch [560]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.123240,	
2017-07-31 15:35:10,775 Epoch[15] Batch [570]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.123216,	
2017-07-31 15:35:14,660 Epoch[15] Batch [580]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.123179,	
2017-07-31 15:35:18,895 Epoch[15] Batch [590]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.124308,	
2017-07-31 15:35:22,783 Epoch[15] Batch [600]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.125827,	
2017-07-31 15:35:26,630 Epoch[15] Batch [610]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.126158,	
2017-07-31 15:35:30,748 Epoch[15] Batch [620]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.126825,	
2017-07-31 15:35:34,868 Epoch[15] Batch [630]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.127685,	
2017-07-31 15:35:38,667 Epoch[15] Batch [640]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.127990,	
2017-07-31 15:35:42,596 Epoch[15] Batch [650]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.128619,	
2017-07-31 15:35:46,341 Epoch[15] Batch [660]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.128858,	
2017-07-31 15:35:50,813 Epoch[15] Batch [670]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.128830,	
2017-07-31 15:35:54,773 Epoch[15] Batch [680]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.128886,	
2017-07-31 15:35:58,985 Epoch[15] Batch [690]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.128975,	
2017-07-31 15:36:03,254 Epoch[15] Batch [700]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.128944,	
2017-07-31 15:36:07,155 Epoch[15] Batch [710]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.129162,	
2017-07-31 15:36:10,967 Epoch[15] Batch [720]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.129326,	
2017-07-31 15:36:14,802 Epoch[15] Batch [730]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.129259,	
2017-07-31 15:36:18,539 Epoch[15] Batch [740]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.129608,	
2017-07-31 15:36:22,832 Epoch[15] Batch [750]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.129765,	
2017-07-31 15:36:26,582 Epoch[15] Batch [760]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.129857,	
2017-07-31 15:36:30,611 Epoch[15] Batch [770]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.129886,	
2017-07-31 15:36:34,467 Epoch[15] Batch [780]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.129786,	
2017-07-31 15:36:38,746 Epoch[15] Batch [790]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.129833,	
2017-07-31 15:36:42,720 Epoch[15] Batch [800]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.129948,	
2017-07-31 15:36:46,546 Epoch[15] Batch [810]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.130093,	
2017-07-31 15:36:50,302 Epoch[15] Batch [820]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.130152,	
2017-07-31 15:36:54,190 Epoch[15] Batch [830]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.130146,	
2017-07-31 15:36:57,863 Epoch[15] Batch [840]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.130008,	
2017-07-31 15:37:01,823 Epoch[15] Batch [850]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129966,	
2017-07-31 15:37:05,898 Epoch[15] Batch [860]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.129881,	
2017-07-31 15:37:09,616 Epoch[15] Batch [870]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.129843,	
2017-07-31 15:37:13,724 Epoch[15] Batch [880]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.129809,	
2017-07-31 15:37:17,537 Epoch[15] Batch [890]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.129857,	
2017-07-31 15:37:21,374 Epoch[15] Batch [900]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.129937,	
2017-07-31 15:37:25,365 Epoch[15] Batch [910]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.129800,	
2017-07-31 15:37:29,334 Epoch[15] Batch [920]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.129878,	
2017-07-31 15:37:33,148 Epoch[15] Batch [930]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.129835,	
2017-07-31 15:37:37,151 Epoch[15] Batch [940]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.129867,	
2017-07-31 15:37:41,008 Epoch[15] Batch [950]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.129844,	
2017-07-31 15:37:44,716 Epoch[15] Batch [960]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.129803,	
2017-07-31 15:37:48,686 Epoch[15] Batch [970]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.129660,	
2017-07-31 15:37:52,670 Epoch[15] Batch [980]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.129820,	
2017-07-31 15:37:56,771 Epoch[15] Batch [990]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.129969,	
2017-07-31 15:38:00,913 Epoch[15] Batch [1000]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.130117,	
2017-07-31 15:38:04,680 Epoch[15] Batch [1010]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.129959,	
2017-07-31 15:38:09,152 Epoch[15] Batch [1020]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.129920,	
2017-07-31 15:38:13,067 Epoch[15] Batch [1030]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.129913,	
2017-07-31 15:38:17,041 Epoch[15] Batch [1040]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.129826,	
2017-07-31 15:38:20,945 Epoch[15] Batch [1050]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.129738,	
2017-07-31 15:38:24,810 Epoch[15] Batch [1060]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.129667,	
2017-07-31 15:38:28,722 Epoch[15] Batch [1070]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.129685,	
2017-07-31 15:38:32,825 Epoch[15] Batch [1080]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.129698,	
2017-07-31 15:38:36,701 Epoch[15] Batch [1090]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.129644,	
2017-07-31 15:38:40,510 Epoch[15] Batch [1100]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.129587,	
2017-07-31 15:38:44,581 Epoch[15] Batch [1110]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.129470,	
2017-07-31 15:38:48,577 Epoch[15] Batch [1120]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.129319,	
2017-07-31 15:38:52,287 Epoch[15] Batch [1130]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.129078,	
2017-07-31 15:38:56,039 Epoch[15] Batch [1140]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.128916,	
2017-07-31 15:39:00,244 Epoch[15] Batch [1150]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.128842,	
2017-07-31 15:39:04,211 Epoch[15] Batch [1160]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.128645,	
2017-07-31 15:39:08,061 Epoch[15] Batch [1170]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.128552,	
2017-07-31 15:39:11,923 Epoch[15] Batch [1180]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.128825,	
2017-07-31 15:39:15,644 Epoch[15] Batch [1190]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.128694,	
2017-07-31 15:39:19,477 Epoch[15] Batch [1200]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.128772,	
2017-07-31 15:39:23,483 Epoch[15] Batch [1210]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.128783,	
2017-07-31 15:39:27,333 Epoch[15] Batch [1220]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.128765,	
2017-07-31 15:39:31,126 Epoch[15] Batch [1230]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.128723,	
2017-07-31 15:39:35,050 Epoch[15] Batch [1240]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.128682,	
2017-07-31 15:39:38,920 Epoch[15] Batch [1250]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.128639,	
2017-07-31 15:39:42,699 Epoch[15] Batch [1260]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.128625,	
2017-07-31 15:39:46,369 Epoch[15] Batch [1270]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.128599,	
2017-07-31 15:39:50,128 Epoch[15] Batch [1280]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.128665,	
2017-07-31 15:39:53,871 Epoch[15] Batch [1290]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.128580,	
2017-07-31 15:39:57,556 Epoch[15] Batch [1300]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.128531,	
2017-07-31 15:40:01,488 Epoch[15] Batch [1310]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.128644,	
2017-07-31 15:40:05,423 Epoch[15] Batch [1320]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.128528,	
2017-07-31 15:40:09,087 Epoch[15] Batch [1330]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.128464,	
2017-07-31 15:40:13,006 Epoch[15] Batch [1340]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.128332,	
2017-07-31 15:40:16,763 Epoch[15] Batch [1350]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.128446,	
2017-07-31 15:40:20,531 Epoch[15] Batch [1360]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.128507,	
2017-07-31 15:40:24,320 Epoch[15] Batch [1370]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.128414,	
2017-07-31 15:40:28,279 Epoch[15] Batch [1380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.128340,	
2017-07-31 15:40:32,115 Epoch[15] Batch [1390]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.128289,	
2017-07-31 15:40:35,917 Epoch[15] Batch [1400]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.128236,	
2017-07-31 15:40:39,772 Epoch[15] Batch [1410]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.128198,	
2017-07-31 15:40:43,563 Epoch[15] Batch [1420]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.128345,	
2017-07-31 15:40:47,424 Epoch[15] Batch [1430]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.128282,	
2017-07-31 15:40:51,130 Epoch[15] Batch [1440]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.128285,	
2017-07-31 15:40:54,878 Epoch[15] Batch [1450]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.128276,	
2017-07-31 15:40:58,800 Epoch[15] Batch [1460]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.128306,	
2017-07-31 15:41:02,713 Epoch[15] Batch [1470]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.128298,	
2017-07-31 15:41:06,465 Epoch[15] Batch [1480]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.128192,	
2017-07-31 15:41:08,724 Epoch[15] Train-FCNLogLoss=0.128153
2017-07-31 15:41:08,724 Epoch[15] Time cost=583.261
2017-07-31 15:41:09,534 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.params"
2017-07-31 15:41:11,814 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.states"
2017-07-31 15:41:16,303 Epoch[16] Batch [10]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.104589,	
2017-07-31 15:41:20,068 Epoch[16] Batch [20]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.119271,	
2017-07-31 15:41:23,799 Epoch[16] Batch [30]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.116401,	
2017-07-31 15:41:27,613 Epoch[16] Batch [40]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.117392,	
2017-07-31 15:41:31,389 Epoch[16] Batch [50]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.120811,	
2017-07-31 15:41:35,351 Epoch[16] Batch [60]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.119836,	
2017-07-31 15:41:39,339 Epoch[16] Batch [70]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.120677,	
2017-07-31 15:41:43,171 Epoch[16] Batch [80]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.121769,	
2017-07-31 15:41:46,908 Epoch[16] Batch [90]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.120506,	
2017-07-31 15:41:50,546 Epoch[16] Batch [100]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.119679,	
2017-07-31 15:41:54,337 Epoch[16] Batch [110]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.119060,	
2017-07-31 15:41:58,301 Epoch[16] Batch [120]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.118713,	
2017-07-31 15:42:02,101 Epoch[16] Batch [130]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.120148,	
2017-07-31 15:42:05,965 Epoch[16] Batch [140]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.120213,	
2017-07-31 15:42:09,856 Epoch[16] Batch [150]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.120972,	
2017-07-31 15:42:13,619 Epoch[16] Batch [160]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.120515,	
2017-07-31 15:42:17,379 Epoch[16] Batch [170]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.120295,	
2017-07-31 15:42:21,052 Epoch[16] Batch [180]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.119423,	
2017-07-31 15:42:24,819 Epoch[16] Batch [190]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.119753,	
2017-07-31 15:42:28,614 Epoch[16] Batch [200]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.119483,	
2017-07-31 15:42:32,417 Epoch[16] Batch [210]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.119444,	
2017-07-31 15:42:36,442 Epoch[16] Batch [220]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.120080,	
2017-07-31 15:42:40,245 Epoch[16] Batch [230]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.121136,	
2017-07-31 15:42:44,100 Epoch[16] Batch [240]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.121589,	
2017-07-31 15:42:48,277 Epoch[16] Batch [250]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.122482,	
2017-07-31 15:42:51,949 Epoch[16] Batch [260]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.123412,	
2017-07-31 15:42:55,862 Epoch[16] Batch [270]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.123070,	
2017-07-31 15:42:59,726 Epoch[16] Batch [280]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.123556,	
2017-07-31 15:43:03,487 Epoch[16] Batch [290]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.123278,	
2017-07-31 15:43:07,188 Epoch[16] Batch [300]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.123354,	
2017-07-31 15:43:10,992 Epoch[16] Batch [310]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.123234,	
2017-07-31 15:43:14,730 Epoch[16] Batch [320]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.122919,	
2017-07-31 15:43:18,700 Epoch[16] Batch [330]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.122962,	
2017-07-31 15:43:22,496 Epoch[16] Batch [340]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123183,	
2017-07-31 15:43:26,177 Epoch[16] Batch [350]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.123584,	
2017-07-31 15:43:29,947 Epoch[16] Batch [360]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123795,	
2017-07-31 15:43:33,726 Epoch[16] Batch [370]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.123499,	
2017-07-31 15:43:37,509 Epoch[16] Batch [380]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.123969,	
2017-07-31 15:43:41,267 Epoch[16] Batch [390]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.124370,	
2017-07-31 15:43:44,992 Epoch[16] Batch [400]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.124177,	
2017-07-31 15:43:48,650 Epoch[16] Batch [410]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.123903,	
2017-07-31 15:43:52,420 Epoch[16] Batch [420]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123700,	
2017-07-31 15:43:56,186 Epoch[16] Batch [430]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.123669,	
2017-07-31 15:43:59,966 Epoch[16] Batch [440]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.123805,	
2017-07-31 15:44:03,720 Epoch[16] Batch [450]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.124063,	
2017-07-31 15:44:07,486 Epoch[16] Batch [460]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.124140,	
2017-07-31 15:44:11,261 Epoch[16] Batch [470]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.124039,	
2017-07-31 15:44:15,088 Epoch[16] Batch [480]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.123831,	
2017-07-31 15:44:18,843 Epoch[16] Batch [490]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.123908,	
2017-07-31 15:44:22,704 Epoch[16] Batch [500]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.123600,	
2017-07-31 15:44:26,474 Epoch[16] Batch [510]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123605,	
2017-07-31 15:44:30,227 Epoch[16] Batch [520]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.123367,	
2017-07-31 15:44:33,960 Epoch[16] Batch [530]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.123197,	
2017-07-31 15:44:37,703 Epoch[16] Batch [540]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.123134,	
2017-07-31 15:44:41,499 Epoch[16] Batch [550]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.122877,	
2017-07-31 15:44:45,168 Epoch[16] Batch [560]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.122747,	
2017-07-31 15:44:48,878 Epoch[16] Batch [570]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.122786,	
2017-07-31 15:44:52,627 Epoch[16] Batch [580]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.122792,	
2017-07-31 15:44:56,367 Epoch[16] Batch [590]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.122755,	
2017-07-31 15:45:00,180 Epoch[16] Batch [600]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.122754,	
2017-07-31 15:45:03,854 Epoch[16] Batch [610]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.122541,	
2017-07-31 15:45:07,621 Epoch[16] Batch [620]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.122639,	
2017-07-31 15:45:11,424 Epoch[16] Batch [630]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.122600,	
2017-07-31 15:45:15,154 Epoch[16] Batch [640]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.122637,	
2017-07-31 15:45:18,960 Epoch[16] Batch [650]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.122825,	
2017-07-31 15:45:22,726 Epoch[16] Batch [660]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.122812,	
2017-07-31 15:45:26,458 Epoch[16] Batch [670]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.122723,	
2017-07-31 15:45:30,214 Epoch[16] Batch [680]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.122809,	
2017-07-31 15:45:33,897 Epoch[16] Batch [690]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.122785,	
2017-07-31 15:45:37,723 Epoch[16] Batch [700]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.122838,	
2017-07-31 15:45:41,547 Epoch[16] Batch [710]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.123070,	
2017-07-31 15:45:45,307 Epoch[16] Batch [720]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.123152,	
2017-07-31 15:45:49,124 Epoch[16] Batch [730]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.123196,	
2017-07-31 15:45:52,981 Epoch[16] Batch [740]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.123083,	
2017-07-31 15:45:56,914 Epoch[16] Batch [750]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.122993,	
2017-07-31 15:46:00,781 Epoch[16] Batch [760]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.122838,	
2017-07-31 15:46:04,501 Epoch[16] Batch [770]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.122881,	
2017-07-31 15:46:08,155 Epoch[16] Batch [780]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.122873,	
2017-07-31 15:46:11,975 Epoch[16] Batch [790]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.122708,	
2017-07-31 15:46:15,744 Epoch[16] Batch [800]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.122667,	
2017-07-31 15:46:19,491 Epoch[16] Batch [810]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.122494,	
2017-07-31 15:46:23,450 Epoch[16] Batch [820]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.122355,	
2017-07-31 15:46:27,150 Epoch[16] Batch [830]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.122504,	
2017-07-31 15:46:30,897 Epoch[16] Batch [840]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.122481,	
2017-07-31 15:46:34,747 Epoch[16] Batch [850]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.122437,	
2017-07-31 15:46:38,434 Epoch[16] Batch [860]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.122325,	
2017-07-31 15:46:42,120 Epoch[16] Batch [870]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.122453,	
2017-07-31 15:46:46,080 Epoch[16] Batch [880]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.122657,	
2017-07-31 15:46:50,135 Epoch[16] Batch [890]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.122789,	
2017-07-31 15:46:53,775 Epoch[16] Batch [900]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.122939,	
2017-07-31 15:46:57,445 Epoch[16] Batch [910]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.123062,	
2017-07-31 15:47:01,156 Epoch[16] Batch [920]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.123009,	
2017-07-31 15:47:04,925 Epoch[16] Batch [930]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.122942,	
2017-07-31 15:47:08,669 Epoch[16] Batch [940]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.122860,	
2017-07-31 15:47:12,391 Epoch[16] Batch [950]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.122900,	
2017-07-31 15:47:16,042 Epoch[16] Batch [960]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.123078,	
2017-07-31 15:47:20,024 Epoch[16] Batch [970]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.122998,	
2017-07-31 15:47:23,752 Epoch[16] Batch [980]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.123108,	
2017-07-31 15:47:27,476 Epoch[16] Batch [990]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.123177,	
2017-07-31 15:47:31,193 Epoch[16] Batch [1000]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.123299,	
2017-07-31 15:47:34,918 Epoch[16] Batch [1010]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.123283,	
2017-07-31 15:47:38,713 Epoch[16] Batch [1020]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123336,	
2017-07-31 15:47:42,413 Epoch[16] Batch [1030]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.123454,	
2017-07-31 15:47:46,352 Epoch[16] Batch [1040]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.123484,	
2017-07-31 15:47:50,113 Epoch[16] Batch [1050]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.123493,	
2017-07-31 15:47:53,823 Epoch[16] Batch [1060]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.123359,	
2017-07-31 15:47:57,762 Epoch[16] Batch [1070]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.123296,	
2017-07-31 15:48:01,505 Epoch[16] Batch [1080]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.123317,	
2017-07-31 15:48:05,255 Epoch[16] Batch [1090]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.123280,	
2017-07-31 15:48:08,951 Epoch[16] Batch [1100]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.123255,	
2017-07-31 15:48:12,799 Epoch[16] Batch [1110]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.123102,	
2017-07-31 15:48:16,615 Epoch[16] Batch [1120]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.123162,	
2017-07-31 15:48:20,467 Epoch[16] Batch [1130]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.123318,	
2017-07-31 15:48:24,346 Epoch[16] Batch [1140]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.123347,	
2017-07-31 15:48:27,947 Epoch[16] Batch [1150]	Speed: 11.11 samples/sec	Train-FCNLogLoss=0.123300,	
2017-07-31 15:48:31,904 Epoch[16] Batch [1160]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.123293,	
2017-07-31 15:48:35,600 Epoch[16] Batch [1170]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.123196,	
2017-07-31 15:48:39,387 Epoch[16] Batch [1180]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.123113,	
2017-07-31 15:48:43,125 Epoch[16] Batch [1190]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.123167,	
2017-07-31 15:48:47,068 Epoch[16] Batch [1200]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.123141,	
2017-07-31 15:48:50,770 Epoch[16] Batch [1210]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.123292,	
2017-07-31 15:48:54,601 Epoch[16] Batch [1220]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.123305,	
2017-07-31 15:48:58,359 Epoch[16] Batch [1230]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.123445,	
2017-07-31 15:49:02,188 Epoch[16] Batch [1240]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.123556,	
2017-07-31 15:49:06,117 Epoch[16] Batch [1250]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.123671,	
2017-07-31 15:49:11,239 Epoch[16] Batch [1260]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.123723,	
2017-07-31 15:49:14,958 Epoch[16] Batch [1270]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.123656,	
2017-07-31 15:49:19,204 Epoch[16] Batch [1280]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.123633,	
2017-07-31 15:49:22,841 Epoch[16] Batch [1290]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.123601,	
2017-07-31 15:49:27,061 Epoch[16] Batch [1300]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.123594,	
2017-07-31 15:49:31,087 Epoch[16] Batch [1310]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.123627,	
2017-07-31 15:49:34,812 Epoch[16] Batch [1320]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.123624,	
2017-07-31 15:49:38,515 Epoch[16] Batch [1330]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.123717,	
2017-07-31 15:49:42,861 Epoch[16] Batch [1340]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.123789,	
2017-07-31 15:49:46,572 Epoch[16] Batch [1350]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.123899,	
2017-07-31 15:49:50,255 Epoch[16] Batch [1360]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.123889,	
2017-07-31 15:49:54,041 Epoch[16] Batch [1370]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.123887,	
2017-07-31 15:49:58,001 Epoch[16] Batch [1380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.123835,	
2017-07-31 15:50:01,720 Epoch[16] Batch [1390]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.123910,	
2017-07-31 15:50:05,422 Epoch[16] Batch [1400]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.124074,	
2017-07-31 15:50:09,898 Epoch[16] Batch [1410]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.124345,	
2017-07-31 15:50:13,649 Epoch[16] Batch [1420]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.124468,	
2017-07-31 15:50:17,847 Epoch[16] Batch [1430]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.124501,	
2017-07-31 15:50:21,853 Epoch[16] Batch [1440]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.124517,	
2017-07-31 15:50:27,199 Epoch[16] Batch [1450]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124457,	
2017-07-31 15:50:30,972 Epoch[16] Batch [1460]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.124454,	
2017-07-31 15:50:35,949 Epoch[16] Batch [1470]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.124478,	
2017-07-31 15:50:40,874 Epoch[16] Batch [1480]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.124408,	
2017-07-31 15:50:43,434 Epoch[16] Train-FCNLogLoss=0.124400
2017-07-31 15:50:43,434 Epoch[16] Time cost=571.620
2017-07-31 15:50:44,217 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.params"
2017-07-31 15:50:46,384 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.states"
2017-07-31 15:50:51,044 Epoch[17] Batch [10]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.121781,	
2017-07-31 15:50:54,755 Epoch[17] Batch [20]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.119180,	
2017-07-31 15:50:58,925 Epoch[17] Batch [30]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.116165,	
2017-07-31 15:51:03,478 Epoch[17] Batch [40]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.116516,	
2017-07-31 15:51:07,375 Epoch[17] Batch [50]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.116128,	
2017-07-31 15:51:11,641 Epoch[17] Batch [60]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.115904,	
2017-07-31 15:51:15,386 Epoch[17] Batch [70]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.115728,	
2017-07-31 15:51:19,450 Epoch[17] Batch [80]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116499,	
2017-07-31 15:51:23,445 Epoch[17] Batch [90]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.116295,	
2017-07-31 15:51:27,395 Epoch[17] Batch [100]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.116316,	
2017-07-31 15:51:31,681 Epoch[17] Batch [110]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.117960,	
2017-07-31 15:51:36,054 Epoch[17] Batch [120]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.119223,	
2017-07-31 15:51:40,102 Epoch[17] Batch [130]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.119511,	
2017-07-31 15:51:45,716 Epoch[17] Batch [140]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.119799,	
2017-07-31 15:51:50,223 Epoch[17] Batch [150]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.120163,	
2017-07-31 15:51:55,191 Epoch[17] Batch [160]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.120701,	
2017-07-31 15:51:59,276 Epoch[17] Batch [170]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.120692,	
2017-07-31 15:52:02,875 Epoch[17] Batch [180]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.120099,	
2017-07-31 15:52:06,632 Epoch[17] Batch [190]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.120766,	
2017-07-31 15:52:10,703 Epoch[17] Batch [200]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.120462,	
2017-07-31 15:52:14,745 Epoch[17] Batch [210]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.120021,	
2017-07-31 15:52:20,017 Epoch[17] Batch [220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.121074,	
2017-07-31 15:52:23,741 Epoch[17] Batch [230]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.122445,	
2017-07-31 15:52:27,910 Epoch[17] Batch [240]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.122922,	
2017-07-31 15:52:31,628 Epoch[17] Batch [250]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.122960,	
2017-07-31 15:52:35,389 Epoch[17] Batch [260]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.123410,	
2017-07-31 15:52:39,593 Epoch[17] Batch [270]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.123718,	
2017-07-31 15:52:44,830 Epoch[17] Batch [280]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.123693,	
2017-07-31 15:52:49,134 Epoch[17] Batch [290]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.123737,	
2017-07-31 15:52:52,854 Epoch[17] Batch [300]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.123712,	
2017-07-31 15:52:56,554 Epoch[17] Batch [310]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.124036,	
2017-07-31 15:53:00,526 Epoch[17] Batch [320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.124029,	
2017-07-31 15:53:05,149 Epoch[17] Batch [330]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.123996,	
2017-07-31 15:53:09,315 Epoch[17] Batch [340]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.123947,	
2017-07-31 15:53:13,084 Epoch[17] Batch [350]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.123849,	
2017-07-31 15:53:17,128 Epoch[17] Batch [360]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.123537,	
2017-07-31 15:53:20,868 Epoch[17] Batch [370]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.123514,	
2017-07-31 15:53:25,161 Epoch[17] Batch [380]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.123236,	
2017-07-31 15:53:28,987 Epoch[17] Batch [390]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.122929,	
2017-07-31 15:53:33,084 Epoch[17] Batch [400]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.123254,	
2017-07-31 15:53:37,499 Epoch[17] Batch [410]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.123546,	
2017-07-31 15:53:41,859 Epoch[17] Batch [420]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.123507,	
2017-07-31 15:53:45,667 Epoch[17] Batch [430]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.123433,	
2017-07-31 15:53:49,401 Epoch[17] Batch [440]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.123735,	
2017-07-31 15:53:53,124 Epoch[17] Batch [450]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.123793,	
2017-07-31 15:53:56,998 Epoch[17] Batch [460]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.123959,	
2017-07-31 15:54:00,781 Epoch[17] Batch [470]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.124301,	
2017-07-31 15:54:04,759 Epoch[17] Batch [480]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.124063,	
2017-07-31 15:54:08,518 Epoch[17] Batch [490]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.124027,	
2017-07-31 15:54:12,528 Epoch[17] Batch [500]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.123983,	
2017-07-31 15:54:16,499 Epoch[17] Batch [510]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.124055,	
2017-07-31 15:54:20,237 Epoch[17] Batch [520]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.123965,	
2017-07-31 15:54:24,077 Epoch[17] Batch [530]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.123689,	
2017-07-31 15:54:27,792 Epoch[17] Batch [540]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.123680,	
2017-07-31 15:54:31,801 Epoch[17] Batch [550]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.123920,	
2017-07-31 15:54:35,636 Epoch[17] Batch [560]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.124022,	
2017-07-31 15:54:39,467 Epoch[17] Batch [570]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.123768,	
2017-07-31 15:54:43,265 Epoch[17] Batch [580]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.124071,	
2017-07-31 15:54:47,158 Epoch[17] Batch [590]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.123967,	
2017-07-31 15:54:50,931 Epoch[17] Batch [600]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.123756,	
2017-07-31 15:54:54,693 Epoch[17] Batch [610]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.123671,	
2017-07-31 15:54:58,407 Epoch[17] Batch [620]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.123781,	
2017-07-31 15:55:02,345 Epoch[17] Batch [630]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.123792,	
2017-07-31 15:55:06,266 Epoch[17] Batch [640]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.123750,	
2017-07-31 15:55:09,999 Epoch[17] Batch [650]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.123719,	
2017-07-31 15:55:13,707 Epoch[17] Batch [660]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.123665,	
2017-07-31 15:55:17,445 Epoch[17] Batch [670]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.123470,	
2017-07-31 15:55:21,177 Epoch[17] Batch [680]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.123359,	
2017-07-31 15:55:25,133 Epoch[17] Batch [690]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.123330,	
2017-07-31 15:55:28,943 Epoch[17] Batch [700]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.123311,	
2017-07-31 15:55:32,687 Epoch[17] Batch [710]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.123299,	
2017-07-31 15:55:36,506 Epoch[17] Batch [720]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.123227,	
2017-07-31 15:55:40,333 Epoch[17] Batch [730]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.123259,	
2017-07-31 15:55:44,090 Epoch[17] Batch [740]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.123223,	
2017-07-31 15:55:47,915 Epoch[17] Batch [750]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.123029,	
2017-07-31 15:55:51,785 Epoch[17] Batch [760]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.122964,	
2017-07-31 15:55:55,584 Epoch[17] Batch [770]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.123091,	
2017-07-31 15:55:59,332 Epoch[17] Batch [780]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.122894,	
2017-07-31 15:56:03,108 Epoch[17] Batch [790]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.122791,	
2017-07-31 15:56:06,838 Epoch[17] Batch [800]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.122801,	
2017-07-31 15:56:10,584 Epoch[17] Batch [810]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.122848,	
2017-07-31 15:56:14,357 Epoch[17] Batch [820]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.122990,	
2017-07-31 15:56:18,629 Epoch[17] Batch [830]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.122992,	
2017-07-31 15:56:22,824 Epoch[17] Batch [840]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.123017,	
2017-07-31 15:56:26,469 Epoch[17] Batch [850]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.123003,	
2017-07-31 15:56:30,173 Epoch[17] Batch [860]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.122989,	
2017-07-31 15:56:34,083 Epoch[17] Batch [870]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.122984,	
2017-07-31 15:56:37,888 Epoch[17] Batch [880]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123039,	
2017-07-31 15:56:41,935 Epoch[17] Batch [890]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.123225,	
2017-07-31 15:56:45,894 Epoch[17] Batch [900]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.123121,	
2017-07-31 15:56:49,798 Epoch[17] Batch [910]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.123025,	
2017-07-31 15:56:53,468 Epoch[17] Batch [920]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.122858,	
2017-07-31 15:56:57,392 Epoch[17] Batch [930]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.122794,	
2017-07-31 15:57:01,078 Epoch[17] Batch [940]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.123133,	
2017-07-31 15:57:04,993 Epoch[17] Batch [950]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.123178,	
2017-07-31 15:57:08,867 Epoch[17] Batch [960]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.123079,	
2017-07-31 15:57:12,652 Epoch[17] Batch [970]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.123170,	
2017-07-31 15:57:16,573 Epoch[17] Batch [980]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.123188,	
2017-07-31 15:57:20,420 Epoch[17] Batch [990]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.123484,	
2017-07-31 15:57:24,624 Epoch[17] Batch [1000]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.123552,	
2017-07-31 15:57:28,390 Epoch[17] Batch [1010]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.123432,	
2017-07-31 15:57:32,533 Epoch[17] Batch [1020]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.123440,	
2017-07-31 15:57:36,333 Epoch[17] Batch [1030]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.123341,	
2017-07-31 15:57:40,189 Epoch[17] Batch [1040]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.123169,	
2017-07-31 15:57:43,984 Epoch[17] Batch [1050]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123068,	
2017-07-31 15:57:47,942 Epoch[17] Batch [1060]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.123024,	
2017-07-31 15:57:51,744 Epoch[17] Batch [1070]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.123020,	
2017-07-31 15:57:55,412 Epoch[17] Batch [1080]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.123128,	
2017-07-31 15:57:59,350 Epoch[17] Batch [1090]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.123200,	
2017-07-31 15:58:03,256 Epoch[17] Batch [1100]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.123250,	
2017-07-31 15:58:07,102 Epoch[17] Batch [1110]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.123215,	
2017-07-31 15:58:10,852 Epoch[17] Batch [1120]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.123137,	
2017-07-31 15:58:14,638 Epoch[17] Batch [1130]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.123147,	
2017-07-31 15:58:18,433 Epoch[17] Batch [1140]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123154,	
2017-07-31 15:58:22,171 Epoch[17] Batch [1150]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.123128,	
2017-07-31 15:58:26,035 Epoch[17] Batch [1160]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.123147,	
2017-07-31 15:58:29,931 Epoch[17] Batch [1170]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.123279,	
2017-07-31 15:58:33,647 Epoch[17] Batch [1180]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.123237,	
2017-07-31 15:58:37,457 Epoch[17] Batch [1190]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.123399,	
2017-07-31 15:58:41,215 Epoch[17] Batch [1200]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.123624,	
2017-07-31 15:58:45,032 Epoch[17] Batch [1210]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.123694,	
2017-07-31 15:58:49,015 Epoch[17] Batch [1220]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.123843,	
2017-07-31 15:58:52,784 Epoch[17] Batch [1230]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123779,	
2017-07-31 15:58:56,592 Epoch[17] Batch [1240]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123724,	
2017-07-31 15:59:00,391 Epoch[17] Batch [1250]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.123682,	
2017-07-31 15:59:04,146 Epoch[17] Batch [1260]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.123698,	
2017-07-31 15:59:07,940 Epoch[17] Batch [1270]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.123795,	
2017-07-31 15:59:11,770 Epoch[17] Batch [1280]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.123733,	
2017-07-31 15:59:15,471 Epoch[17] Batch [1290]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.123770,	
2017-07-31 15:59:19,289 Epoch[17] Batch [1300]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.123863,	
2017-07-31 15:59:23,139 Epoch[17] Batch [1310]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.123737,	
2017-07-31 15:59:26,869 Epoch[17] Batch [1320]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.123650,	
2017-07-31 15:59:30,733 Epoch[17] Batch [1330]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.123588,	
2017-07-31 15:59:34,488 Epoch[17] Batch [1340]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.123573,	
2017-07-31 15:59:38,202 Epoch[17] Batch [1350]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.123566,	
2017-07-31 15:59:41,925 Epoch[17] Batch [1360]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.123510,	
2017-07-31 15:59:45,697 Epoch[17] Batch [1370]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.123528,	
2017-07-31 15:59:49,713 Epoch[17] Batch [1380]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.123441,	
2017-07-31 15:59:53,511 Epoch[17] Batch [1390]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.123528,	
2017-07-31 15:59:57,330 Epoch[17] Batch [1400]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.123477,	
2017-07-31 16:00:01,224 Epoch[17] Batch [1410]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.123432,	
2017-07-31 16:00:04,960 Epoch[17] Batch [1420]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.123463,	
2017-07-31 16:00:08,766 Epoch[17] Batch [1430]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123514,	
2017-07-31 16:00:12,520 Epoch[17] Batch [1440]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.123504,	
2017-07-31 16:00:16,316 Epoch[17] Batch [1450]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123533,	
2017-07-31 16:00:20,059 Epoch[17] Batch [1460]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.123502,	
2017-07-31 16:00:24,024 Epoch[17] Batch [1470]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.123562,	
2017-07-31 16:00:27,710 Epoch[17] Batch [1480]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.123613,	
2017-07-31 16:00:29,946 Epoch[17] Train-FCNLogLoss=0.123613
2017-07-31 16:00:29,946 Epoch[17] Time cost=583.562
2017-07-31 16:00:30,756 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.params"
2017-07-31 16:00:33,582 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.states"
2017-07-31 16:00:37,954 Epoch[18] Batch [10]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.120414,	
2017-07-31 16:00:41,753 Epoch[18] Batch [20]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.125984,	
2017-07-31 16:00:45,581 Epoch[18] Batch [30]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.122667,	
2017-07-31 16:00:49,361 Epoch[18] Batch [40]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.123219,	
2017-07-31 16:00:53,156 Epoch[18] Batch [50]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123930,	
2017-07-31 16:00:56,969 Epoch[18] Batch [60]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.126980,	
2017-07-31 16:01:00,759 Epoch[18] Batch [70]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.128849,	
2017-07-31 16:01:04,537 Epoch[18] Batch [80]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.127905,	
2017-07-31 16:01:08,291 Epoch[18] Batch [90]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.127369,	
2017-07-31 16:01:12,131 Epoch[18] Batch [100]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.125503,	
2017-07-31 16:01:15,977 Epoch[18] Batch [110]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.125639,	
2017-07-31 16:01:19,851 Epoch[18] Batch [120]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.124249,	
2017-07-31 16:01:23,538 Epoch[18] Batch [130]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.124479,	
2017-07-31 16:01:27,449 Epoch[18] Batch [140]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.124697,	
2017-07-31 16:01:31,255 Epoch[18] Batch [150]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.124723,	
2017-07-31 16:01:35,072 Epoch[18] Batch [160]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.124525,	
2017-07-31 16:01:38,939 Epoch[18] Batch [170]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.124273,	
2017-07-31 16:01:42,800 Epoch[18] Batch [180]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.124026,	
2017-07-31 16:01:46,710 Epoch[18] Batch [190]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.124333,	
2017-07-31 16:01:50,506 Epoch[18] Batch [200]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.124174,	
2017-07-31 16:01:54,264 Epoch[18] Batch [210]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.123758,	
2017-07-31 16:01:57,936 Epoch[18] Batch [220]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.123200,	
2017-07-31 16:02:01,947 Epoch[18] Batch [230]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.123303,	
2017-07-31 16:02:05,803 Epoch[18] Batch [240]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.123361,	
2017-07-31 16:02:09,528 Epoch[18] Batch [250]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.122869,	
2017-07-31 16:02:13,297 Epoch[18] Batch [260]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123036,	
2017-07-31 16:02:17,073 Epoch[18] Batch [270]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.122655,	
2017-07-31 16:02:20,896 Epoch[18] Batch [280]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.122788,	
2017-07-31 16:02:24,687 Epoch[18] Batch [290]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.122642,	
2017-07-31 16:02:28,434 Epoch[18] Batch [300]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.122495,	
2017-07-31 16:02:32,312 Epoch[18] Batch [310]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.122325,	
2017-07-31 16:02:35,960 Epoch[18] Batch [320]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.122278,	
2017-07-31 16:02:39,904 Epoch[18] Batch [330]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.121999,	
2017-07-31 16:02:43,720 Epoch[18] Batch [340]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.122108,	
2017-07-31 16:02:47,755 Epoch[18] Batch [350]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.121780,	
2017-07-31 16:02:51,425 Epoch[18] Batch [360]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.121563,	
2017-07-31 16:02:55,155 Epoch[18] Batch [370]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.121600,	
2017-07-31 16:02:59,187 Epoch[18] Batch [380]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.121554,	
2017-07-31 16:03:02,987 Epoch[18] Batch [390]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.121328,	
2017-07-31 16:03:06,870 Epoch[18] Batch [400]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.121117,	
2017-07-31 16:03:10,638 Epoch[18] Batch [410]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.121009,	
2017-07-31 16:03:14,520 Epoch[18] Batch [420]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.121313,	
2017-07-31 16:03:18,303 Epoch[18] Batch [430]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.121089,	
2017-07-31 16:03:22,408 Epoch[18] Batch [440]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.120958,	
2017-07-31 16:03:26,278 Epoch[18] Batch [450]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.120646,	
2017-07-31 16:03:30,212 Epoch[18] Batch [460]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.120841,	
2017-07-31 16:03:34,096 Epoch[18] Batch [470]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.120800,	
2017-07-31 16:03:38,063 Epoch[18] Batch [480]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.120716,	
2017-07-31 16:03:42,033 Epoch[18] Batch [490]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.120642,	
2017-07-31 16:03:45,987 Epoch[18] Batch [500]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.120605,	
2017-07-31 16:03:49,822 Epoch[18] Batch [510]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.120847,	
2017-07-31 16:03:53,804 Epoch[18] Batch [520]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.120962,	
2017-07-31 16:03:57,777 Epoch[18] Batch [530]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.120581,	
2017-07-31 16:04:01,710 Epoch[18] Batch [540]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.120328,	
2017-07-31 16:04:05,642 Epoch[18] Batch [550]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.120316,	
2017-07-31 16:04:09,625 Epoch[18] Batch [560]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.120192,	
2017-07-31 16:04:13,479 Epoch[18] Batch [570]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.120155,	
2017-07-31 16:04:17,524 Epoch[18] Batch [580]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.120392,	
2017-07-31 16:04:21,358 Epoch[18] Batch [590]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.120267,	
2017-07-31 16:04:25,273 Epoch[18] Batch [600]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.120178,	
2017-07-31 16:04:29,267 Epoch[18] Batch [610]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.120035,	
2017-07-31 16:04:33,136 Epoch[18] Batch [620]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.119970,	
2017-07-31 16:04:36,961 Epoch[18] Batch [630]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.119958,	
2017-07-31 16:04:40,918 Epoch[18] Batch [640]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.119913,	
2017-07-31 16:04:44,854 Epoch[18] Batch [650]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.120263,	
2017-07-31 16:04:48,843 Epoch[18] Batch [660]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.120620,	
2017-07-31 16:04:52,795 Epoch[18] Batch [670]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.120811,	
2017-07-31 16:04:56,798 Epoch[18] Batch [680]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.120940,	
2017-07-31 16:05:00,724 Epoch[18] Batch [690]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.121236,	
2017-07-31 16:05:04,799 Epoch[18] Batch [700]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.121336,	
2017-07-31 16:05:08,759 Epoch[18] Batch [710]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.121354,	
2017-07-31 16:05:12,838 Epoch[18] Batch [720]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.121507,	
2017-07-31 16:05:16,816 Epoch[18] Batch [730]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.121656,	
2017-07-31 16:05:20,805 Epoch[18] Batch [740]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.121585,	
2017-07-31 16:05:24,970 Epoch[18] Batch [750]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.121523,	
2017-07-31 16:05:29,055 Epoch[18] Batch [760]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.121595,	
2017-07-31 16:05:33,221 Epoch[18] Batch [770]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.121819,	
2017-07-31 16:05:37,381 Epoch[18] Batch [780]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.121774,	
2017-07-31 16:05:41,505 Epoch[18] Batch [790]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.121949,	
2017-07-31 16:05:45,677 Epoch[18] Batch [800]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.121977,	
2017-07-31 16:05:49,803 Epoch[18] Batch [810]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.122192,	
2017-07-31 16:05:53,876 Epoch[18] Batch [820]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.122181,	
2017-07-31 16:05:57,900 Epoch[18] Batch [830]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.122208,	
2017-07-31 16:06:02,179 Epoch[18] Batch [840]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.122060,	
2017-07-31 16:06:06,515 Epoch[18] Batch [850]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.122129,	
2017-07-31 16:06:10,743 Epoch[18] Batch [860]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.121862,	
2017-07-31 16:06:15,107 Epoch[18] Batch [870]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.121814,	
2017-07-31 16:06:19,529 Epoch[18] Batch [880]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.121858,	
2017-07-31 16:06:23,512 Epoch[18] Batch [890]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.121771,	
2017-07-31 16:06:27,713 Epoch[18] Batch [900]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.121717,	
2017-07-31 16:06:31,930 Epoch[18] Batch [910]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.121704,	
2017-07-31 16:06:36,100 Epoch[18] Batch [920]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.121689,	
2017-07-31 16:06:40,238 Epoch[18] Batch [930]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.121652,	
2017-07-31 16:06:44,407 Epoch[18] Batch [940]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.121682,	
2017-07-31 16:06:48,725 Epoch[18] Batch [950]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.121743,	
2017-07-31 16:06:52,822 Epoch[18] Batch [960]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.121642,	
2017-07-31 16:06:57,185 Epoch[18] Batch [970]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.121596,	
2017-07-31 16:07:01,599 Epoch[18] Batch [980]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.121530,	
2017-07-31 16:07:05,808 Epoch[18] Batch [990]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.121584,	
2017-07-31 16:07:10,520 Epoch[18] Batch [1000]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.121580,	
2017-07-31 16:07:15,204 Epoch[18] Batch [1010]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121476,	
2017-07-31 16:07:19,365 Epoch[18] Batch [1020]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.121373,	
2017-07-31 16:07:23,591 Epoch[18] Batch [1030]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.121339,	
2017-07-31 16:07:27,613 Epoch[18] Batch [1040]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.121310,	
2017-07-31 16:07:32,162 Epoch[18] Batch [1050]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121344,	
2017-07-31 16:07:36,495 Epoch[18] Batch [1060]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.121366,	
2017-07-31 16:07:40,865 Epoch[18] Batch [1070]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.121377,	
2017-07-31 16:07:45,457 Epoch[18] Batch [1080]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.121325,	
2017-07-31 16:07:49,874 Epoch[18] Batch [1090]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.121254,	
2017-07-31 16:07:54,214 Epoch[18] Batch [1100]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.121229,	
2017-07-31 16:07:58,670 Epoch[18] Batch [1110]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.121312,	
2017-07-31 16:08:02,963 Epoch[18] Batch [1120]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.121238,	
2017-07-31 16:08:07,508 Epoch[18] Batch [1130]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.121232,	
2017-07-31 16:08:11,836 Epoch[18] Batch [1140]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.121190,	
2017-07-31 16:08:16,354 Epoch[18] Batch [1150]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.121184,	
2017-07-31 16:08:21,153 Epoch[18] Batch [1160]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.121153,	
2017-07-31 16:08:25,650 Epoch[18] Batch [1170]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.121089,	
2017-07-31 16:08:30,551 Epoch[18] Batch [1180]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.121198,	
2017-07-31 16:08:34,919 Epoch[18] Batch [1190]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.121195,	
2017-07-31 16:08:39,258 Epoch[18] Batch [1200]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.121180,	
2017-07-31 16:08:43,796 Epoch[18] Batch [1210]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.121126,	
2017-07-31 16:08:48,441 Epoch[18] Batch [1220]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.121039,	
2017-07-31 16:08:53,112 Epoch[18] Batch [1230]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121076,	
2017-07-31 16:08:57,496 Epoch[18] Batch [1240]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.121102,	
2017-07-31 16:09:02,158 Epoch[18] Batch [1250]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.121039,	
2017-07-31 16:09:07,072 Epoch[18] Batch [1260]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.121020,	
2017-07-31 16:09:11,499 Epoch[18] Batch [1270]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.120940,	
2017-07-31 16:09:16,001 Epoch[18] Batch [1280]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.120898,	
2017-07-31 16:09:20,428 Epoch[18] Batch [1290]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.120901,	
2017-07-31 16:09:24,650 Epoch[18] Batch [1300]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.120959,	
2017-07-31 16:09:29,390 Epoch[18] Batch [1310]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.121027,	
2017-07-31 16:09:33,897 Epoch[18] Batch [1320]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.121034,	
2017-07-31 16:09:38,521 Epoch[18] Batch [1330]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.121011,	
2017-07-31 16:09:42,991 Epoch[18] Batch [1340]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121112,	
2017-07-31 16:09:47,614 Epoch[18] Batch [1350]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.121178,	
2017-07-31 16:09:52,005 Epoch[18] Batch [1360]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.121250,	
2017-07-31 16:09:56,833 Epoch[18] Batch [1370]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.121228,	
2017-07-31 16:10:02,273 Epoch[18] Batch [1380]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.121264,	
2017-07-31 16:10:06,742 Epoch[18] Batch [1390]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121181,	
2017-07-31 16:10:11,935 Epoch[18] Batch [1400]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.121234,	
2017-07-31 16:10:17,424 Epoch[18] Batch [1410]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.121234,	
2017-07-31 16:10:22,646 Epoch[18] Batch [1420]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.121222,	
2017-07-31 16:10:27,749 Epoch[18] Batch [1430]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.121297,	
2017-07-31 16:10:32,640 Epoch[18] Batch [1440]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.121161,	
2017-07-31 16:10:37,281 Epoch[18] Batch [1450]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.121123,	
2017-07-31 16:10:42,078 Epoch[18] Batch [1460]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.121090,	
2017-07-31 16:10:47,007 Epoch[18] Batch [1470]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.121052,	
2017-07-31 16:10:52,412 Epoch[18] Batch [1480]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.121105,	
2017-07-31 16:10:55,401 Epoch[18] Train-FCNLogLoss=0.121008
2017-07-31 16:10:55,401 Epoch[18] Time cost=621.818
2017-07-31 16:10:56,363 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.params"
2017-07-31 16:10:59,713 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.states"
2017-07-31 16:11:04,913 Epoch[19] Batch [10]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.119226,	
2017-07-31 16:11:09,533 Epoch[19] Batch [20]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.121354,	
2017-07-31 16:11:14,606 Epoch[19] Batch [30]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.118222,	
2017-07-31 16:11:19,499 Epoch[19] Batch [40]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.117907,	
2017-07-31 16:11:24,329 Epoch[19] Batch [50]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.116133,	
2017-07-31 16:11:29,299 Epoch[19] Batch [60]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.114227,	
2017-07-31 16:11:34,556 Epoch[19] Batch [70]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112881,	
2017-07-31 16:11:39,938 Epoch[19] Batch [80]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.116308,	
2017-07-31 16:11:45,485 Epoch[19] Batch [90]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.117565,	
2017-07-31 16:11:50,663 Epoch[19] Batch [100]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.119447,	
2017-07-31 16:11:55,069 Epoch[19] Batch [110]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.120441,	
2017-07-31 16:11:59,561 Epoch[19] Batch [120]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.121975,	
2017-07-31 16:12:04,369 Epoch[19] Batch [130]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.121380,	
2017-07-31 16:12:09,918 Epoch[19] Batch [140]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.121222,	
2017-07-31 16:12:15,456 Epoch[19] Batch [150]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.121009,	
2017-07-31 16:12:20,442 Epoch[19] Batch [160]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.119765,	
2017-07-31 16:12:25,212 Epoch[19] Batch [170]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.119128,	
2017-07-31 16:12:30,093 Epoch[19] Batch [180]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.119152,	
2017-07-31 16:12:34,889 Epoch[19] Batch [190]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.118665,	
2017-07-31 16:12:39,684 Epoch[19] Batch [200]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.118540,	
2017-07-31 16:12:44,639 Epoch[19] Batch [210]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.118474,	
2017-07-31 16:12:49,598 Epoch[19] Batch [220]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.118317,	
2017-07-31 16:12:54,824 Epoch[19] Batch [230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.118394,	
2017-07-31 16:13:00,300 Epoch[19] Batch [240]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.118458,	
2017-07-31 16:13:05,443 Epoch[19] Batch [250]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.118506,	
2017-07-31 16:13:10,431 Epoch[19] Batch [260]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.118028,	
2017-07-31 16:13:15,453 Epoch[19] Batch [270]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.118375,	
2017-07-31 16:13:20,995 Epoch[19] Batch [280]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.118358,	
2017-07-31 16:13:26,343 Epoch[19] Batch [290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117999,	
2017-07-31 16:13:31,636 Epoch[19] Batch [300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.117614,	
2017-07-31 16:13:36,898 Epoch[19] Batch [310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.117314,	
2017-07-31 16:13:41,651 Epoch[19] Batch [320]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.117337,	
2017-07-31 16:13:46,628 Epoch[19] Batch [330]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.117439,	
2017-07-31 16:13:52,037 Epoch[19] Batch [340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.117723,	
2017-07-31 16:13:57,181 Epoch[19] Batch [350]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.117565,	
2017-07-31 16:14:02,523 Epoch[19] Batch [360]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117367,	
2017-07-31 16:14:07,929 Epoch[19] Batch [370]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.117581,	
2017-07-31 16:14:13,430 Epoch[19] Batch [380]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.117342,	
2017-07-31 16:14:19,254 Epoch[19] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.117286,	
2017-07-31 16:14:25,243 Epoch[19] Batch [400]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.117668,	
2017-07-31 16:14:31,448 Epoch[19] Batch [410]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.118134,	
2017-07-31 16:14:37,912 Epoch[19] Batch [420]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.118211,	
2017-07-31 16:14:44,485 Epoch[19] Batch [430]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.118188,	
2017-07-31 16:14:51,366 Epoch[19] Batch [440]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.117921,	
2017-07-31 16:14:58,235 Epoch[19] Batch [450]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.117818,	
2017-07-31 16:15:04,764 Epoch[19] Batch [460]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.117780,	
2017-07-31 16:15:11,392 Epoch[19] Batch [470]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.117651,	
2017-07-31 16:15:17,982 Epoch[19] Batch [480]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.117441,	
2017-07-31 16:15:24,066 Epoch[19] Batch [490]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.117768,	
2017-07-31 16:15:27,976 Epoch[19] Batch [500]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.118148,	
2017-07-31 16:15:31,813 Epoch[19] Batch [510]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.118267,	
2017-07-31 16:15:35,759 Epoch[19] Batch [520]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.118232,	
2017-07-31 16:15:39,841 Epoch[19] Batch [530]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118117,	
2017-07-31 16:15:44,042 Epoch[19] Batch [540]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.118093,	
2017-07-31 16:15:48,482 Epoch[19] Batch [550]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.117966,	
2017-07-31 16:15:52,779 Epoch[19] Batch [560]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.117809,	
2017-07-31 16:15:56,607 Epoch[19] Batch [570]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.117631,	
2017-07-31 16:16:00,379 Epoch[19] Batch [580]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.117480,	
2017-07-31 16:16:04,176 Epoch[19] Batch [590]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.117598,	
2017-07-31 16:16:07,981 Epoch[19] Batch [600]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.117560,	
2017-07-31 16:16:11,585 Epoch[19] Batch [610]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.117398,	
2017-07-31 16:16:15,372 Epoch[19] Batch [620]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.117215,	
2017-07-31 16:16:19,618 Epoch[19] Batch [630]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.117101,	
2017-07-31 16:16:23,579 Epoch[19] Batch [640]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.117040,	
2017-07-31 16:16:27,592 Epoch[19] Batch [650]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.117135,	
2017-07-31 16:16:31,528 Epoch[19] Batch [660]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.117240,	
2017-07-31 16:16:35,395 Epoch[19] Batch [670]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.117210,	
2017-07-31 16:16:39,270 Epoch[19] Batch [680]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.117419,	
2017-07-31 16:16:43,019 Epoch[19] Batch [690]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.117680,	
2017-07-31 16:16:46,830 Epoch[19] Batch [700]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.117806,	
2017-07-31 16:16:50,748 Epoch[19] Batch [710]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.117929,	
2017-07-31 16:16:54,610 Epoch[19] Batch [720]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.117912,	
2017-07-31 16:16:58,352 Epoch[19] Batch [730]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.118229,	
2017-07-31 16:17:02,203 Epoch[19] Batch [740]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.118353,	
2017-07-31 16:17:06,197 Epoch[19] Batch [750]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.118347,	
2017-07-31 16:17:10,180 Epoch[19] Batch [760]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118370,	
2017-07-31 16:17:14,242 Epoch[19] Batch [770]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.118553,	
2017-07-31 16:17:18,128 Epoch[19] Batch [780]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.118493,	
2017-07-31 16:17:22,122 Epoch[19] Batch [790]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.118681,	
2017-07-31 16:17:26,269 Epoch[19] Batch [800]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.118699,	
2017-07-31 16:17:30,330 Epoch[19] Batch [810]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.118808,	
2017-07-31 16:17:34,423 Epoch[19] Batch [820]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.118938,	
2017-07-31 16:17:38,403 Epoch[19] Batch [830]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.118995,	
2017-07-31 16:17:43,482 Epoch[19] Batch [840]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.118861,	
2017-07-31 16:17:47,316 Epoch[19] Batch [850]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.118863,	
2017-07-31 16:17:51,222 Epoch[19] Batch [860]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.118975,	
2017-07-31 16:17:55,157 Epoch[19] Batch [870]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.118879,	
2017-07-31 16:17:59,141 Epoch[19] Batch [880]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118939,	
2017-07-31 16:18:03,299 Epoch[19] Batch [890]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.119081,	
2017-07-31 16:18:08,046 Epoch[19] Batch [900]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.119036,	
2017-07-31 16:18:12,392 Epoch[19] Batch [910]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.118918,	
2017-07-31 16:18:16,780 Epoch[19] Batch [920]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.118971,	
2017-07-31 16:18:20,999 Epoch[19] Batch [930]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.119283,	
2017-07-31 16:18:25,424 Epoch[19] Batch [940]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.119313,	
2017-07-31 16:18:29,916 Epoch[19] Batch [950]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.119164,	
2017-07-31 16:18:34,849 Epoch[19] Batch [960]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.119278,	
2017-07-31 16:18:39,962 Epoch[19] Batch [970]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.119276,	
2017-07-31 16:18:44,395 Epoch[19] Batch [980]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.119420,	
2017-07-31 16:18:48,889 Epoch[19] Batch [990]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.119405,	
2017-07-31 16:18:53,413 Epoch[19] Batch [1000]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.119572,	
2017-07-31 16:18:57,729 Epoch[19] Batch [1010]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.119481,	
2017-07-31 16:19:01,937 Epoch[19] Batch [1020]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.119331,	
2017-07-31 16:19:06,411 Epoch[19] Batch [1030]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.119229,	
2017-07-31 16:19:10,670 Epoch[19] Batch [1040]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.119171,	
2017-07-31 16:19:15,473 Epoch[19] Batch [1050]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.119142,	
2017-07-31 16:19:20,298 Epoch[19] Batch [1060]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.118969,	
2017-07-31 16:19:24,604 Epoch[19] Batch [1070]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.118961,	
2017-07-31 16:19:28,847 Epoch[19] Batch [1080]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.118938,	
2017-07-31 16:19:32,984 Epoch[19] Batch [1090]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.118858,	
2017-07-31 16:19:37,138 Epoch[19] Batch [1100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.118720,	
2017-07-31 16:19:41,297 Epoch[19] Batch [1110]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.118632,	
2017-07-31 16:19:45,502 Epoch[19] Batch [1120]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.118707,	
2017-07-31 16:19:49,624 Epoch[19] Batch [1130]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.118711,	
2017-07-31 16:19:53,708 Epoch[19] Batch [1140]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.118688,	
2017-07-31 16:19:57,946 Epoch[19] Batch [1150]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.118630,	
2017-07-31 16:20:02,256 Epoch[19] Batch [1160]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.118679,	
2017-07-31 16:20:06,442 Epoch[19] Batch [1170]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.118595,	
2017-07-31 16:20:11,421 Epoch[19] Batch [1180]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.118537,	
2017-07-31 16:20:15,619 Epoch[19] Batch [1190]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.118514,	
2017-07-31 16:20:19,894 Epoch[19] Batch [1200]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.118467,	
2017-07-31 16:20:23,987 Epoch[19] Batch [1210]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.118337,	
2017-07-31 16:20:28,038 Epoch[19] Batch [1220]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.118336,	
2017-07-31 16:20:32,276 Epoch[19] Batch [1230]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.118383,	
2017-07-31 16:20:36,304 Epoch[19] Batch [1240]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.118366,	
2017-07-31 16:20:40,387 Epoch[19] Batch [1250]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118304,	
2017-07-31 16:20:44,630 Epoch[19] Batch [1260]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.118366,	
2017-07-31 16:20:48,850 Epoch[19] Batch [1270]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.118449,	
2017-07-31 16:20:52,990 Epoch[19] Batch [1280]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.118294,	
2017-07-31 16:20:57,434 Epoch[19] Batch [1290]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.118212,	
2017-07-31 16:21:01,651 Epoch[19] Batch [1300]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.118350,	
2017-07-31 16:21:06,046 Epoch[19] Batch [1310]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.118380,	
2017-07-31 16:21:10,464 Epoch[19] Batch [1320]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.118450,	
2017-07-31 16:21:15,164 Epoch[19] Batch [1330]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.118628,	
2017-07-31 16:21:19,645 Epoch[19] Batch [1340]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.119192,	
2017-07-31 16:21:24,216 Epoch[19] Batch [1350]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.120007,	
2017-07-31 16:21:28,581 Epoch[19] Batch [1360]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.121066,	
2017-07-31 16:21:33,452 Epoch[19] Batch [1370]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.121348,	
2017-07-31 16:21:37,986 Epoch[19] Batch [1380]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.121753,	
2017-07-31 16:21:42,920 Epoch[19] Batch [1390]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.122011,	
2017-07-31 16:21:47,593 Epoch[19] Batch [1400]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.122224,	
2017-07-31 16:21:51,999 Epoch[19] Batch [1410]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.122378,	
2017-07-31 16:21:56,446 Epoch[19] Batch [1420]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.122414,	
2017-07-31 16:22:01,451 Epoch[19] Batch [1430]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.122476,	
2017-07-31 16:22:05,775 Epoch[19] Batch [1440]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.122645,	
2017-07-31 16:22:10,100 Epoch[19] Batch [1450]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.122831,	
2017-07-31 16:22:14,603 Epoch[19] Batch [1460]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.122929,	
2017-07-31 16:22:19,038 Epoch[19] Batch [1470]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.123099,	
2017-07-31 16:22:23,420 Epoch[19] Batch [1480]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.123163,	
2017-07-31 16:22:26,253 Epoch[19] Train-FCNLogLoss=0.123266
2017-07-31 16:22:26,254 Epoch[19] Time cost=686.540
2017-07-31 16:22:27,040 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.params"
2017-07-31 16:22:30,184 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.states"
2017-07-31 16:22:35,624 Epoch[20] Batch [10]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.163188,	
2017-07-31 16:22:39,995 Epoch[20] Batch [20]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.153620,	
2017-07-31 16:22:44,596 Epoch[20] Batch [30]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.159398,	
2017-07-31 16:22:49,138 Epoch[20] Batch [40]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.155342,	
2017-07-31 16:22:54,286 Epoch[20] Batch [50]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.151742,	
2017-07-31 16:22:59,787 Epoch[20] Batch [60]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.151122,	
2017-07-31 16:23:04,477 Epoch[20] Batch [70]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.146990,	
2017-07-31 16:23:08,993 Epoch[20] Batch [80]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.144211,	
2017-07-31 16:23:13,582 Epoch[20] Batch [90]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.140974,	
2017-07-31 16:23:18,564 Epoch[20] Batch [100]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.136993,	
2017-07-31 16:23:23,375 Epoch[20] Batch [110]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.135079,	
2017-07-31 16:23:28,066 Epoch[20] Batch [120]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.134903,	
2017-07-31 16:23:33,686 Epoch[20] Batch [130]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.133126,	
2017-07-31 16:23:38,895 Epoch[20] Batch [140]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.131541,	
2017-07-31 16:23:43,228 Epoch[20] Batch [150]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.130243,	
2017-07-31 16:23:47,961 Epoch[20] Batch [160]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.130068,	
2017-07-31 16:23:52,505 Epoch[20] Batch [170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.130044,	
2017-07-31 16:23:57,444 Epoch[20] Batch [180]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.129590,	
2017-07-31 16:24:02,085 Epoch[20] Batch [190]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.129423,	
2017-07-31 16:24:06,769 Epoch[20] Batch [200]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.129248,	
2017-07-31 16:24:11,803 Epoch[20] Batch [210]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.128233,	
2017-07-31 16:24:16,922 Epoch[20] Batch [220]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.128464,	
2017-07-31 16:24:21,983 Epoch[20] Batch [230]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.128306,	
2017-07-31 16:24:26,889 Epoch[20] Batch [240]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.128157,	
2017-07-31 16:24:32,350 Epoch[20] Batch [250]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.128487,	
2017-07-31 16:24:37,876 Epoch[20] Batch [260]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.128383,	
2017-07-31 16:24:43,467 Epoch[20] Batch [270]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.128010,	
2017-07-31 16:24:49,090 Epoch[20] Batch [280]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.128034,	
2017-07-31 16:24:54,615 Epoch[20] Batch [290]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.128151,	
2017-07-31 16:24:59,852 Epoch[20] Batch [300]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.128184,	
2017-07-31 16:25:05,446 Epoch[20] Batch [310]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.128732,	
2017-07-31 16:25:11,112 Epoch[20] Batch [320]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.128892,	
2017-07-31 16:25:16,894 Epoch[20] Batch [330]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.128942,	
2017-07-31 16:25:22,829 Epoch[20] Batch [340]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.129057,	
2017-07-31 16:25:28,852 Epoch[20] Batch [350]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.128525,	
2017-07-31 16:25:35,165 Epoch[20] Batch [360]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.128294,	
2017-07-31 16:25:41,704 Epoch[20] Batch [370]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.127797,	
2017-07-31 16:25:48,184 Epoch[20] Batch [380]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.127820,	
2017-07-31 16:25:55,223 Epoch[20] Batch [390]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.127798,	
2017-07-31 16:26:01,620 Epoch[20] Batch [400]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.127539,	
2017-07-31 16:26:07,847 Epoch[20] Batch [410]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.127170,	
2017-07-31 16:26:14,124 Epoch[20] Batch [420]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.126833,	
2017-07-31 16:26:20,067 Epoch[20] Batch [430]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.126594,	
2017-07-31 16:26:26,113 Epoch[20] Batch [440]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.126444,	
2017-07-31 16:26:32,261 Epoch[20] Batch [450]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.126737,	
2017-07-31 16:26:38,425 Epoch[20] Batch [460]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.126784,	
2017-07-31 16:26:44,523 Epoch[20] Batch [470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.126689,	
2017-07-31 16:26:50,398 Epoch[20] Batch [480]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.126085,	
2017-07-31 16:26:56,230 Epoch[20] Batch [490]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.126076,	
2017-07-31 16:27:02,782 Epoch[20] Batch [500]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.125819,	
2017-07-31 16:27:08,949 Epoch[20] Batch [510]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.125638,	
2017-07-31 16:27:16,030 Epoch[20] Batch [520]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.125287,	
2017-07-31 16:27:23,151 Epoch[20] Batch [530]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.125111,	
2017-07-31 16:27:30,218 Epoch[20] Batch [540]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.125105,	
2017-07-31 16:27:37,253 Epoch[20] Batch [550]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.124935,	
2017-07-31 16:27:44,331 Epoch[20] Batch [560]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.125038,	
2017-07-31 16:27:51,365 Epoch[20] Batch [570]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.124706,	
2017-07-31 16:27:58,386 Epoch[20] Batch [580]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.124522,	
2017-07-31 16:28:05,497 Epoch[20] Batch [590]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.124416,	
2017-07-31 16:28:12,281 Epoch[20] Batch [600]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.124334,	
2017-07-31 16:28:19,118 Epoch[20] Batch [610]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.124439,	
2017-07-31 16:28:26,008 Epoch[20] Batch [620]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.124257,	
2017-07-31 16:28:32,852 Epoch[20] Batch [630]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.124006,	
2017-07-31 16:28:39,862 Epoch[20] Batch [640]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.123789,	
2017-07-31 16:28:46,986 Epoch[20] Batch [650]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.123743,	
2017-07-31 16:28:54,103 Epoch[20] Batch [660]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.123927,	
2017-07-31 16:29:01,186 Epoch[20] Batch [670]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.123898,	
2017-07-31 16:29:08,194 Epoch[20] Batch [680]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.123808,	
2017-07-31 16:29:15,123 Epoch[20] Batch [690]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.123878,	
2017-07-31 16:29:22,008 Epoch[20] Batch [700]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.123764,	
2017-07-31 16:29:29,132 Epoch[20] Batch [710]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.123944,	
2017-07-31 16:29:36,205 Epoch[20] Batch [720]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.124086,	
2017-07-31 16:29:43,333 Epoch[20] Batch [730]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.124065,	
2017-07-31 16:29:50,209 Epoch[20] Batch [740]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.124102,	
2017-07-31 16:29:57,020 Epoch[20] Batch [750]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.124069,	
2017-07-31 16:30:04,055 Epoch[20] Batch [760]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.123966,	
2017-07-31 16:30:11,041 Epoch[20] Batch [770]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.123857,	
2017-07-31 16:30:17,897 Epoch[20] Batch [780]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.123825,	
2017-07-31 16:30:24,898 Epoch[20] Batch [790]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.123853,	
2017-07-31 16:30:31,932 Epoch[20] Batch [800]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.123793,	
2017-07-31 16:30:38,977 Epoch[20] Batch [810]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.124121,	
2017-07-31 16:30:46,004 Epoch[20] Batch [820]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.124166,	
2017-07-31 16:30:53,040 Epoch[20] Batch [830]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.124330,	
2017-07-31 16:30:59,986 Epoch[20] Batch [840]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.124368,	
2017-07-31 16:31:07,094 Epoch[20] Batch [850]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.124419,	
2017-07-31 16:31:14,131 Epoch[20] Batch [860]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.124281,	
2017-07-31 16:31:21,210 Epoch[20] Batch [870]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.124265,	
2017-07-31 16:31:28,378 Epoch[20] Batch [880]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.124224,	
2017-07-31 16:31:35,530 Epoch[20] Batch [890]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.124202,	
2017-07-31 16:31:42,425 Epoch[20] Batch [900]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.124199,	
2017-07-31 16:31:49,327 Epoch[20] Batch [910]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.124245,	
2017-07-31 16:31:56,291 Epoch[20] Batch [920]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.124125,	
2017-07-31 16:32:03,260 Epoch[20] Batch [930]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.124006,	
2017-07-31 16:32:10,259 Epoch[20] Batch [940]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.123958,	
2017-07-31 16:32:16,933 Epoch[20] Batch [950]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.123972,	
2017-07-31 16:32:23,583 Epoch[20] Batch [960]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.124075,	
2017-07-31 16:32:30,198 Epoch[20] Batch [970]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.124083,	
2017-07-31 16:32:37,007 Epoch[20] Batch [980]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.124057,	
2017-07-31 16:32:43,818 Epoch[20] Batch [990]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.124198,	
2017-07-31 16:32:50,620 Epoch[20] Batch [1000]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.124250,	
2017-07-31 16:32:57,370 Epoch[20] Batch [1010]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.124296,	
2017-07-31 16:33:04,211 Epoch[20] Batch [1020]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.124279,	
2017-07-31 16:33:11,103 Epoch[20] Batch [1030]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.124224,	
2017-07-31 16:33:17,916 Epoch[20] Batch [1040]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.124428,	
2017-07-31 16:33:24,826 Epoch[20] Batch [1050]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.124350,	
2017-07-31 16:33:31,773 Epoch[20] Batch [1060]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.124303,	
2017-07-31 16:33:38,612 Epoch[20] Batch [1070]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.124330,	
2017-07-31 16:33:45,583 Epoch[20] Batch [1080]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.124333,	
2017-07-31 16:33:52,595 Epoch[20] Batch [1090]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.124221,	
2017-07-31 16:33:59,584 Epoch[20] Batch [1100]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.124220,	
2017-07-31 16:34:06,559 Epoch[20] Batch [1110]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.124155,	
2017-07-31 16:34:13,603 Epoch[20] Batch [1120]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.124017,	
2017-07-31 16:34:20,551 Epoch[20] Batch [1130]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.124146,	
2017-07-31 16:34:27,493 Epoch[20] Batch [1140]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.124152,	
2017-07-31 16:34:34,570 Epoch[20] Batch [1150]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.124125,	
2017-07-31 16:34:41,556 Epoch[20] Batch [1160]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.124062,	
2017-07-31 16:34:48,507 Epoch[20] Batch [1170]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.124043,	
2017-07-31 16:34:55,561 Epoch[20] Batch [1180]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.123898,	
2017-07-31 16:35:02,579 Epoch[20] Batch [1190]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.123822,	
2017-07-31 16:35:09,384 Epoch[20] Batch [1200]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.123701,	
2017-07-31 16:35:16,020 Epoch[20] Batch [1210]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.123729,	
2017-07-31 16:35:22,763 Epoch[20] Batch [1220]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.124869,	
2017-07-31 16:35:29,545 Epoch[20] Batch [1230]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.126728,	
2017-07-31 16:35:36,371 Epoch[20] Batch [1240]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.127900,	
2017-07-31 16:35:43,175 Epoch[20] Batch [1250]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.128972,	
2017-07-31 16:35:50,082 Epoch[20] Batch [1260]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.130127,	
2017-07-31 16:35:57,078 Epoch[20] Batch [1270]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.130506,	
2017-07-31 16:36:04,000 Epoch[20] Batch [1280]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.130683,	
2017-07-31 16:36:10,986 Epoch[20] Batch [1290]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.131046,	
2017-07-31 16:36:17,769 Epoch[20] Batch [1300]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.131283,	
2017-07-31 16:36:24,303 Epoch[20] Batch [1310]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.131595,	
2017-07-31 16:36:31,008 Epoch[20] Batch [1320]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.131752,	
2017-07-31 16:36:37,670 Epoch[20] Batch [1330]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.132178,	
2017-07-31 16:36:44,446 Epoch[20] Batch [1340]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.132532,	
2017-07-31 16:36:51,210 Epoch[20] Batch [1350]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.132622,	
2017-07-31 16:36:58,256 Epoch[20] Batch [1360]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.133106,	
2017-07-31 16:37:05,201 Epoch[20] Batch [1370]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.133148,	
2017-07-31 16:37:12,010 Epoch[20] Batch [1380]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.133185,	
2017-07-31 16:37:18,693 Epoch[20] Batch [1390]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.133649,	
2017-07-31 16:37:25,243 Epoch[20] Batch [1400]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.133853,	
2017-07-31 16:37:32,171 Epoch[20] Batch [1410]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.134305,	
2017-07-31 16:37:39,000 Epoch[20] Batch [1420]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.134493,	
2017-07-31 16:37:45,752 Epoch[20] Batch [1430]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.134642,	
2017-07-31 16:37:52,533 Epoch[20] Batch [1440]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.134666,	
2017-07-31 16:37:59,382 Epoch[20] Batch [1450]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.134633,	
2017-07-31 16:38:06,249 Epoch[20] Batch [1460]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.134604,	
2017-07-31 16:38:13,133 Epoch[20] Batch [1470]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.134576,	
2017-07-31 16:38:19,976 Epoch[20] Batch [1480]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.134482,	
2017-07-31 16:38:24,197 Epoch[20] Train-FCNLogLoss=0.134440
2017-07-31 16:38:24,197 Epoch[20] Time cost=954.013
2017-07-31 16:38:25,165 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.params"
2017-07-31 16:38:28,608 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.states"
2017-07-31 16:38:35,458 Epoch[21] Batch [10]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.131494,	
2017-07-31 16:38:41,506 Epoch[21] Batch [20]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.137849,	
2017-07-31 16:38:47,725 Epoch[21] Batch [30]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.136387,	
2017-07-31 16:38:54,431 Epoch[21] Batch [40]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.135700,	
2017-07-31 16:39:01,470 Epoch[21] Batch [50]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.134917,	
2017-07-31 16:39:08,442 Epoch[21] Batch [60]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.134608,	
2017-07-31 16:39:15,416 Epoch[21] Batch [70]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.133301,	
2017-07-31 16:39:22,451 Epoch[21] Batch [80]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.135634,	
2017-07-31 16:39:29,193 Epoch[21] Batch [90]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.135116,	
2017-07-31 16:39:35,852 Epoch[21] Batch [100]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.133519,	
2017-07-31 16:39:42,787 Epoch[21] Batch [110]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.131784,	
2017-07-31 16:39:49,720 Epoch[21] Batch [120]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.132306,	
2017-07-31 16:39:56,647 Epoch[21] Batch [130]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.130212,	
2017-07-31 16:40:03,647 Epoch[21] Batch [140]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.129218,	
2017-07-31 16:40:10,700 Epoch[21] Batch [150]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.128525,	
2017-07-31 16:40:17,701 Epoch[21] Batch [160]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.128173,	
2017-07-31 16:40:24,546 Epoch[21] Batch [170]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.127925,	
2017-07-31 16:40:31,539 Epoch[21] Batch [180]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.128036,	
2017-07-31 16:40:38,404 Epoch[21] Batch [190]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.128709,	
2017-07-31 16:40:45,508 Epoch[21] Batch [200]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.128830,	
2017-07-31 16:40:52,431 Epoch[21] Batch [210]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.128647,	
2017-07-31 16:40:59,462 Epoch[21] Batch [220]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.128036,	
2017-07-31 16:41:06,361 Epoch[21] Batch [230]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.128190,	
2017-07-31 16:41:13,233 Epoch[21] Batch [240]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.127686,	
2017-07-31 16:41:20,216 Epoch[21] Batch [250]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.126978,	
2017-07-31 16:41:27,250 Epoch[21] Batch [260]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.127335,	
2017-07-31 16:41:33,895 Epoch[21] Batch [270]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.127302,	
2017-07-31 16:41:40,463 Epoch[21] Batch [280]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.127187,	
2017-07-31 16:41:47,050 Epoch[21] Batch [290]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.127379,	
2017-07-31 16:41:53,602 Epoch[21] Batch [300]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.127596,	
2017-07-31 16:42:00,076 Epoch[21] Batch [310]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.127700,	
2017-07-31 16:42:06,277 Epoch[21] Batch [320]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.127624,	
2017-07-31 16:42:11,913 Epoch[21] Batch [330]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.127511,	
2017-07-31 16:42:17,466 Epoch[21] Batch [340]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.127081,	
2017-07-31 16:42:23,200 Epoch[21] Batch [350]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.126769,	
2017-07-31 16:42:28,827 Epoch[21] Batch [360]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.126934,	
2017-07-31 16:42:34,475 Epoch[21] Batch [370]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.126788,	
2017-07-31 16:42:40,250 Epoch[21] Batch [380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.126776,	
2017-07-31 16:42:46,748 Epoch[21] Batch [390]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.126926,	
2017-07-31 16:42:53,141 Epoch[21] Batch [400]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.126692,	
2017-07-31 16:42:59,487 Epoch[21] Batch [410]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.126756,	
2017-07-31 16:43:05,997 Epoch[21] Batch [420]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.126508,	
2017-07-31 16:43:12,112 Epoch[21] Batch [430]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.126918,	
2017-07-31 16:43:18,008 Epoch[21] Batch [440]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.127284,	
2017-07-31 16:43:23,796 Epoch[21] Batch [450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.127080,	
2017-07-31 16:43:29,781 Epoch[21] Batch [460]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.127085,	
2017-07-31 16:43:36,661 Epoch[21] Batch [470]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.126717,	
2017-07-31 16:43:43,578 Epoch[21] Batch [480]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.126976,	
2017-07-31 16:43:50,532 Epoch[21] Batch [490]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.126717,	
2017-07-31 16:43:57,571 Epoch[21] Batch [500]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.126636,	
2017-07-31 16:44:04,678 Epoch[21] Batch [510]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.126252,	
2017-07-31 16:44:11,648 Epoch[21] Batch [520]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.125966,	
2017-07-31 16:44:18,763 Epoch[21] Batch [530]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.125662,	
2017-07-31 16:44:25,493 Epoch[21] Batch [540]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.125550,	
2017-07-31 16:44:32,072 Epoch[21] Batch [550]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.125352,	
2017-07-31 16:44:38,723 Epoch[21] Batch [560]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.125223,	
2017-07-31 16:44:45,326 Epoch[21] Batch [570]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.124979,	
2017-07-31 16:44:52,334 Epoch[21] Batch [580]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.125088,	
2017-07-31 16:44:59,296 Epoch[21] Batch [590]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.124761,	
2017-07-31 16:45:06,288 Epoch[21] Batch [600]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.124770,	
2017-07-31 16:45:13,312 Epoch[21] Batch [610]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.124859,	
2017-07-31 16:45:20,319 Epoch[21] Batch [620]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.124754,	
2017-07-31 16:45:27,411 Epoch[21] Batch [630]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.124691,	
2017-07-31 16:45:34,421 Epoch[21] Batch [640]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.124549,	
2017-07-31 16:45:41,471 Epoch[21] Batch [650]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.124360,	
2017-07-31 16:45:48,604 Epoch[21] Batch [660]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.124520,	
2017-07-31 16:45:55,773 Epoch[21] Batch [670]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.124459,	
2017-07-31 16:46:02,711 Epoch[21] Batch [680]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.124484,	
2017-07-31 16:46:09,685 Epoch[21] Batch [690]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.124464,	
2017-07-31 16:46:16,534 Epoch[21] Batch [700]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.124414,	
2017-07-31 16:46:23,183 Epoch[21] Batch [710]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.124169,	
2017-07-31 16:46:29,655 Epoch[21] Batch [720]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.123792,	
2017-07-31 16:46:36,040 Epoch[21] Batch [730]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.123577,	
2017-07-31 16:46:42,885 Epoch[21] Batch [740]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.123462,	
2017-07-31 16:46:49,909 Epoch[21] Batch [750]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.123396,	
2017-07-31 16:46:56,719 Epoch[21] Batch [760]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.123328,	
2017-07-31 16:47:03,743 Epoch[21] Batch [770]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.123172,	
2017-07-31 16:47:10,491 Epoch[21] Batch [780]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.123378,	
2017-07-31 16:47:17,413 Epoch[21] Batch [790]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.123197,	
2017-07-31 16:47:24,354 Epoch[21] Batch [800]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.123211,	
2017-07-31 16:47:31,190 Epoch[21] Batch [810]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.123113,	
2017-07-31 16:47:38,172 Epoch[21] Batch [820]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.123017,	
2017-07-31 16:47:45,358 Epoch[21] Batch [830]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.123123,	
2017-07-31 16:47:52,010 Epoch[21] Batch [840]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.123085,	
2017-07-31 16:47:58,732 Epoch[21] Batch [850]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.122959,	
2017-07-31 16:48:05,589 Epoch[21] Batch [860]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.122929,	
2017-07-31 16:48:12,378 Epoch[21] Batch [870]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.122847,	
2017-07-31 16:48:19,351 Epoch[21] Batch [880]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.122688,	
2017-07-31 16:48:26,136 Epoch[21] Batch [890]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.122747,	
2017-07-31 16:48:32,760 Epoch[21] Batch [900]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.122783,	
2017-07-31 16:48:39,384 Epoch[21] Batch [910]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.122663,	
2017-07-31 16:48:46,401 Epoch[21] Batch [920]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.122668,	
2017-07-31 16:48:53,307 Epoch[21] Batch [930]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.122532,	
2017-07-31 16:49:00,331 Epoch[21] Batch [940]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.122715,	
2017-07-31 16:49:07,522 Epoch[21] Batch [950]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.122637,	
2017-07-31 16:49:14,329 Epoch[21] Batch [960]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.122652,	
2017-07-31 16:49:21,191 Epoch[21] Batch [970]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.122643,	
2017-07-31 16:49:27,827 Epoch[21] Batch [980]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.122700,	
2017-07-31 16:49:34,725 Epoch[21] Batch [990]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.122591,	
2017-07-31 16:49:41,739 Epoch[21] Batch [1000]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.122552,	
2017-07-31 16:49:48,681 Epoch[21] Batch [1010]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.122410,	
2017-07-31 16:49:55,577 Epoch[21] Batch [1020]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.122428,	
2017-07-31 16:50:02,626 Epoch[21] Batch [1030]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.122351,	
2017-07-31 16:50:09,529 Epoch[21] Batch [1040]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.122247,	
2017-07-31 16:50:16,484 Epoch[21] Batch [1050]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.122186,	
2017-07-31 16:50:23,429 Epoch[21] Batch [1060]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.122418,	
2017-07-31 16:50:30,461 Epoch[21] Batch [1070]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.122371,	
2017-07-31 16:50:37,325 Epoch[21] Batch [1080]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.122442,	
2017-07-31 16:50:44,316 Epoch[21] Batch [1090]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.122450,	
2017-07-31 16:50:51,417 Epoch[21] Batch [1100]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.122492,	
2017-07-31 16:50:58,234 Epoch[21] Batch [1110]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.122448,	
2017-07-31 16:51:05,344 Epoch[21] Batch [1120]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.122528,	
2017-07-31 16:51:12,192 Epoch[21] Batch [1130]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.122468,	
2017-07-31 16:51:19,085 Epoch[21] Batch [1140]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.122407,	
2017-07-31 16:51:25,921 Epoch[21] Batch [1150]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.122450,	
2017-07-31 16:51:32,950 Epoch[21] Batch [1160]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.122379,	
2017-07-31 16:51:39,788 Epoch[21] Batch [1170]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.122382,	
2017-07-31 16:51:46,722 Epoch[21] Batch [1180]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.122328,	
2017-07-31 16:51:53,554 Epoch[21] Batch [1190]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.122340,	
2017-07-31 16:52:00,448 Epoch[21] Batch [1200]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.122397,	
2017-07-31 16:52:07,331 Epoch[21] Batch [1210]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.122670,	
2017-07-31 16:52:14,215 Epoch[21] Batch [1220]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.122794,	
2017-07-31 16:52:21,113 Epoch[21] Batch [1230]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.122850,	
2017-07-31 16:52:28,111 Epoch[21] Batch [1240]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.122836,	
2017-07-31 16:52:34,871 Epoch[21] Batch [1250]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.122782,	
2017-07-31 16:52:41,818 Epoch[21] Batch [1260]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.122762,	
2017-07-31 16:52:48,816 Epoch[21] Batch [1270]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.122737,	
2017-07-31 16:52:55,798 Epoch[21] Batch [1280]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.122696,	
2017-07-31 16:53:02,846 Epoch[21] Batch [1290]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.122758,	
2017-07-31 16:53:09,904 Epoch[21] Batch [1300]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.122710,	
2017-07-31 16:53:17,035 Epoch[21] Batch [1310]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.122678,	
2017-07-31 16:53:24,037 Epoch[21] Batch [1320]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.122738,	
2017-07-31 16:53:31,134 Epoch[21] Batch [1330]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.122762,	
2017-07-31 16:53:38,042 Epoch[21] Batch [1340]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.122736,	
2017-07-31 16:53:44,996 Epoch[21] Batch [1350]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.122765,	
2017-07-31 16:53:52,100 Epoch[21] Batch [1360]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.122762,	
2017-07-31 16:53:56,927 Epoch[21] Batch [1370]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.122765,	
2017-07-31 16:54:01,644 Epoch[21] Batch [1380]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.122888,	
2017-07-31 16:54:06,424 Epoch[21] Batch [1390]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.122818,	
2017-07-31 16:54:10,934 Epoch[21] Batch [1400]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.122792,	
2017-07-31 16:54:15,327 Epoch[21] Batch [1410]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.122724,	
2017-07-31 16:54:19,609 Epoch[21] Batch [1420]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.122631,	
2017-07-31 16:54:23,779 Epoch[21] Batch [1430]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.122573,	
2017-07-31 16:54:28,261 Epoch[21] Batch [1440]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.122536,	
2017-07-31 16:54:32,599 Epoch[21] Batch [1450]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.122493,	
2017-07-31 16:54:37,111 Epoch[21] Batch [1460]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.122426,	
2017-07-31 16:54:40,942 Epoch[21] Batch [1470]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.122360,	
2017-07-31 16:54:45,321 Epoch[21] Batch [1480]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.122311,	
2017-07-31 16:54:47,749 Epoch[21] Train-FCNLogLoss=0.122255
2017-07-31 16:54:47,749 Epoch[21] Time cost=979.141
2017-07-31 16:54:48,502 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.params"
2017-07-31 16:54:51,912 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.states"
2017-07-31 16:54:56,967 Epoch[22] Batch [10]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.113000,	
2017-07-31 16:55:01,219 Epoch[22] Batch [20]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.118210,	
2017-07-31 16:55:05,510 Epoch[22] Batch [30]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.115758,	
2017-07-31 16:55:09,754 Epoch[22] Batch [40]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.119958,	
2017-07-31 16:55:13,868 Epoch[22] Batch [50]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117954,	
2017-07-31 16:55:17,994 Epoch[22] Batch [60]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.123920,	
2017-07-31 16:55:22,284 Epoch[22] Batch [70]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.125927,	
2017-07-31 16:55:27,114 Epoch[22] Batch [80]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.125555,	
2017-07-31 16:55:31,521 Epoch[22] Batch [90]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.125048,	
2017-07-31 16:55:36,245 Epoch[22] Batch [100]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.123096,	
2017-07-31 16:55:40,956 Epoch[22] Batch [110]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.122780,	
2017-07-31 16:55:45,534 Epoch[22] Batch [120]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.122826,	
2017-07-31 16:55:49,962 Epoch[22] Batch [130]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.122895,	
2017-07-31 16:55:54,647 Epoch[22] Batch [140]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121675,	
2017-07-31 16:55:59,058 Epoch[22] Batch [150]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.120777,	
2017-07-31 16:56:03,578 Epoch[22] Batch [160]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.120681,	
2017-07-31 16:56:08,427 Epoch[22] Batch [170]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.121354,	
2017-07-31 16:56:13,298 Epoch[22] Batch [180]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.120649,	
2017-07-31 16:56:17,775 Epoch[22] Batch [190]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.119633,	
2017-07-31 16:56:22,226 Epoch[22] Batch [200]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.119707,	
2017-07-31 16:56:27,435 Epoch[22] Batch [210]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.119803,	
2017-07-31 16:56:32,305 Epoch[22] Batch [220]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.119606,	
2017-07-31 16:56:37,333 Epoch[22] Batch [230]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.119645,	
2017-07-31 16:56:42,146 Epoch[22] Batch [240]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.119450,	
2017-07-31 16:56:46,760 Epoch[22] Batch [250]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.119091,	
2017-07-31 16:56:51,448 Epoch[22] Batch [260]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.118408,	
2017-07-31 16:56:56,439 Epoch[22] Batch [270]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.118406,	
2017-07-31 16:57:01,429 Epoch[22] Batch [280]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.118672,	
2017-07-31 16:57:05,851 Epoch[22] Batch [290]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.119170,	
2017-07-31 16:57:10,530 Epoch[22] Batch [300]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.120219,	
2017-07-31 16:57:15,578 Epoch[22] Batch [310]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.120917,	
2017-07-31 16:57:20,163 Epoch[22] Batch [320]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.121482,	
2017-07-31 16:57:24,799 Epoch[22] Batch [330]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.121878,	
2017-07-31 16:57:29,675 Epoch[22] Batch [340]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.121907,	
2017-07-31 16:57:34,904 Epoch[22] Batch [350]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121825,	
2017-07-31 16:57:40,138 Epoch[22] Batch [360]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.121891,	
2017-07-31 16:57:45,424 Epoch[22] Batch [370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121740,	
2017-07-31 16:57:50,561 Epoch[22] Batch [380]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.121838,	
2017-07-31 16:57:55,391 Epoch[22] Batch [390]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.121822,	
2017-07-31 16:58:00,630 Epoch[22] Batch [400]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.122222,	
2017-07-31 16:58:06,011 Epoch[22] Batch [410]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.122152,	
2017-07-31 16:58:11,857 Epoch[22] Batch [420]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.121919,	
2017-07-31 16:58:17,905 Epoch[22] Batch [430]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.122150,	
2017-07-31 16:58:23,695 Epoch[22] Batch [440]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.121913,	
2017-07-31 16:58:29,421 Epoch[22] Batch [450]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.122071,	
2017-07-31 16:58:34,633 Epoch[22] Batch [460]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.122045,	
2017-07-31 16:58:40,098 Epoch[22] Batch [470]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.122069,	
2017-07-31 16:58:45,359 Epoch[22] Batch [480]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121810,	
2017-07-31 16:58:50,307 Epoch[22] Batch [490]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.121532,	
2017-07-31 16:58:55,572 Epoch[22] Batch [500]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121488,	
2017-07-31 16:59:00,891 Epoch[22] Batch [510]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121754,	
2017-07-31 16:59:06,617 Epoch[22] Batch [520]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.121519,	
2017-07-31 16:59:11,598 Epoch[22] Batch [530]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.121629,	
2017-07-31 16:59:16,283 Epoch[22] Batch [540]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121416,	
2017-07-31 16:59:20,918 Epoch[22] Batch [550]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.121288,	
2017-07-31 16:59:25,630 Epoch[22] Batch [560]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.121126,	
2017-07-31 16:59:30,780 Epoch[22] Batch [570]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.121373,	
2017-07-31 16:59:35,711 Epoch[22] Batch [580]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.121254,	
2017-07-31 16:59:40,363 Epoch[22] Batch [590]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.121144,	
2017-07-31 16:59:45,543 Epoch[22] Batch [600]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120912,	
2017-07-31 16:59:50,270 Epoch[22] Batch [610]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.120753,	
2017-07-31 16:59:54,858 Epoch[22] Batch [620]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.120649,	
2017-07-31 16:59:59,321 Epoch[22] Batch [630]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.120382,	
2017-07-31 17:00:03,750 Epoch[22] Batch [640]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.120274,	
2017-07-31 17:00:08,421 Epoch[22] Batch [650]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.120279,	
2017-07-31 17:00:12,920 Epoch[22] Batch [660]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.120274,	
2017-07-31 17:00:17,287 Epoch[22] Batch [670]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.120325,	
2017-07-31 17:00:22,157 Epoch[22] Batch [680]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.120324,	
2017-07-31 17:00:26,902 Epoch[22] Batch [690]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.120255,	
2017-07-31 17:00:31,697 Epoch[22] Batch [700]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.120025,	
2017-07-31 17:00:36,348 Epoch[22] Batch [710]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.120004,	
2017-07-31 17:00:40,597 Epoch[22] Batch [720]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.120020,	
2017-07-31 17:00:45,237 Epoch[22] Batch [730]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.120103,	
2017-07-31 17:00:49,395 Epoch[22] Batch [740]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.120095,	
2017-07-31 17:00:54,376 Epoch[22] Batch [750]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.120081,	
2017-07-31 17:00:59,773 Epoch[22] Batch [760]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.119885,	
2017-07-31 17:01:04,662 Epoch[22] Batch [770]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.119727,	
2017-07-31 17:01:09,306 Epoch[22] Batch [780]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.119551,	
2017-07-31 17:01:14,310 Epoch[22] Batch [790]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.119475,	
2017-07-31 17:01:19,069 Epoch[22] Batch [800]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.119557,	
2017-07-31 17:01:23,720 Epoch[22] Batch [810]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.119638,	
2017-07-31 17:01:28,220 Epoch[22] Batch [820]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.119495,	
2017-07-31 17:01:32,812 Epoch[22] Batch [830]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.119777,	
2017-07-31 17:01:37,340 Epoch[22] Batch [840]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.119843,	
2017-07-31 17:01:41,622 Epoch[22] Batch [850]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.119959,	
2017-07-31 17:01:45,992 Epoch[22] Batch [860]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.119978,	
2017-07-31 17:01:50,510 Epoch[22] Batch [870]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.120039,	
2017-07-31 17:01:55,208 Epoch[22] Batch [880]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.120035,	
2017-07-31 17:02:00,057 Epoch[22] Batch [890]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.119917,	
2017-07-31 17:02:05,011 Epoch[22] Batch [900]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.119845,	
2017-07-31 17:02:09,549 Epoch[22] Batch [910]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.119863,	
2017-07-31 17:02:14,214 Epoch[22] Batch [920]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.119804,	
2017-07-31 17:02:18,921 Epoch[22] Batch [930]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.119710,	
2017-07-31 17:02:23,741 Epoch[22] Batch [940]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.119782,	
2017-07-31 17:02:28,172 Epoch[22] Batch [950]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.119721,	
2017-07-31 17:02:33,052 Epoch[22] Batch [960]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.119626,	
2017-07-31 17:02:37,687 Epoch[22] Batch [970]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.119676,	
2017-07-31 17:02:42,261 Epoch[22] Batch [980]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.119557,	
2017-07-31 17:02:47,006 Epoch[22] Batch [990]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.119492,	
2017-07-31 17:02:51,487 Epoch[22] Batch [1000]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.119648,	
2017-07-31 17:02:56,212 Epoch[22] Batch [1010]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.119617,	
2017-07-31 17:03:00,496 Epoch[22] Batch [1020]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.119643,	
2017-07-31 17:03:05,075 Epoch[22] Batch [1030]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.119722,	
2017-07-31 17:03:10,016 Epoch[22] Batch [1040]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.119852,	
2017-07-31 17:03:14,063 Epoch[22] Batch [1050]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.119812,	
2017-07-31 17:03:18,801 Epoch[22] Batch [1060]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.119573,	
2017-07-31 17:03:23,702 Epoch[22] Batch [1070]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.119385,	
2017-07-31 17:03:28,773 Epoch[22] Batch [1080]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.119317,	
2017-07-31 17:03:33,592 Epoch[22] Batch [1090]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.119332,	
2017-07-31 17:03:38,823 Epoch[22] Batch [1100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.119464,	
2017-07-31 17:03:45,386 Epoch[22] Batch [1110]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.119460,	
2017-07-31 17:03:52,904 Epoch[22] Batch [1120]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.119410,	
2017-07-31 17:03:59,790 Epoch[22] Batch [1130]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.119548,	
2017-07-31 17:04:05,995 Epoch[22] Batch [1140]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.119779,	
2017-07-31 17:04:13,067 Epoch[22] Batch [1150]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.119858,	
2017-07-31 17:04:19,886 Epoch[22] Batch [1160]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.119852,	
2017-07-31 17:04:25,959 Epoch[22] Batch [1170]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.119863,	
2017-07-31 17:04:33,489 Epoch[22] Batch [1180]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.119963,	
2017-07-31 17:04:40,638 Epoch[22] Batch [1190]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.119998,	
2017-07-31 17:04:47,892 Epoch[22] Batch [1200]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.120066,	
2017-07-31 17:04:54,458 Epoch[22] Batch [1210]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.120019,	
2017-07-31 17:05:00,692 Epoch[22] Batch [1220]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.120145,	
2017-07-31 17:05:07,311 Epoch[22] Batch [1230]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.120289,	
2017-07-31 17:05:13,842 Epoch[22] Batch [1240]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.120243,	
2017-07-31 17:05:20,725 Epoch[22] Batch [1250]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.120203,	
2017-07-31 17:05:27,393 Epoch[22] Batch [1260]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.120155,	
2017-07-31 17:05:34,309 Epoch[22] Batch [1270]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.120120,	
2017-07-31 17:05:40,347 Epoch[22] Batch [1280]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.120236,	
2017-07-31 17:05:46,987 Epoch[22] Batch [1290]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.120245,	
2017-07-31 17:05:53,586 Epoch[22] Batch [1300]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.120244,	
2017-07-31 17:06:00,582 Epoch[22] Batch [1310]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.120233,	
2017-07-31 17:06:06,184 Epoch[22] Batch [1320]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.120124,	
2017-07-31 17:06:12,370 Epoch[22] Batch [1330]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.120095,	
2017-07-31 17:06:19,038 Epoch[22] Batch [1340]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.119973,	
2017-07-31 17:06:26,011 Epoch[22] Batch [1350]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.119917,	
2017-07-31 17:06:32,783 Epoch[22] Batch [1360]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.120002,	
2017-07-31 17:06:39,346 Epoch[22] Batch [1370]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.119975,	
2017-07-31 17:06:46,648 Epoch[22] Batch [1380]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.119964,	
2017-07-31 17:06:53,876 Epoch[22] Batch [1390]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.119995,	
2017-07-31 17:07:00,755 Epoch[22] Batch [1400]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.119982,	
2017-07-31 17:07:07,737 Epoch[22] Batch [1410]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.119870,	
2017-07-31 17:07:14,578 Epoch[22] Batch [1420]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.119843,	
2017-07-31 17:07:21,876 Epoch[22] Batch [1430]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.119896,	
2017-07-31 17:07:28,109 Epoch[22] Batch [1440]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.119938,	
2017-07-31 17:07:34,602 Epoch[22] Batch [1450]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.119838,	
2017-07-31 17:07:41,414 Epoch[22] Batch [1460]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.119754,	
2017-07-31 17:07:48,489 Epoch[22] Batch [1470]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.119677,	
2017-07-31 17:07:54,863 Epoch[22] Batch [1480]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.119613,	
2017-07-31 17:07:58,340 Epoch[22] Train-FCNLogLoss=0.119622
2017-07-31 17:07:58,340 Epoch[22] Time cost=786.428
2017-07-31 17:07:59,632 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.params"
2017-07-31 17:08:03,100 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.states"
2017-07-31 17:08:10,877 Epoch[23] Batch [10]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.118366,	
2017-07-31 17:08:17,438 Epoch[23] Batch [20]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.114808,	
2017-07-31 17:08:23,762 Epoch[23] Batch [30]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.114358,	
2017-07-31 17:08:30,724 Epoch[23] Batch [40]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.116395,	
2017-07-31 17:08:37,738 Epoch[23] Batch [50]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.117314,	
2017-07-31 17:08:43,282 Epoch[23] Batch [60]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.114269,	
2017-07-31 17:08:50,311 Epoch[23] Batch [70]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.115305,	
2017-07-31 17:08:56,959 Epoch[23] Batch [80]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.113657,	
2017-07-31 17:09:03,360 Epoch[23] Batch [90]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.115708,	
2017-07-31 17:09:10,344 Epoch[23] Batch [100]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.113477,	
2017-07-31 17:09:17,492 Epoch[23] Batch [110]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.113663,	
2017-07-31 17:09:23,821 Epoch[23] Batch [120]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.114351,	
2017-07-31 17:09:30,005 Epoch[23] Batch [130]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.113034,	
2017-07-31 17:09:36,951 Epoch[23] Batch [140]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.113412,	
2017-07-31 17:09:43,686 Epoch[23] Batch [150]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.113841,	
2017-07-31 17:09:50,669 Epoch[23] Batch [160]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.113587,	
2017-07-31 17:09:57,453 Epoch[23] Batch [170]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.114113,	
2017-07-31 17:10:04,614 Epoch[23] Batch [180]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.113990,	
2017-07-31 17:10:11,854 Epoch[23] Batch [190]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.114202,	
2017-07-31 17:10:19,046 Epoch[23] Batch [200]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.113735,	
2017-07-31 17:10:26,131 Epoch[23] Batch [210]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.113619,	
2017-07-31 17:10:33,214 Epoch[23] Batch [220]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.113040,	
2017-07-31 17:10:40,277 Epoch[23] Batch [230]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.112738,	
2017-07-31 17:10:47,247 Epoch[23] Batch [240]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.113421,	
2017-07-31 17:10:54,006 Epoch[23] Batch [250]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.113862,	
2017-07-31 17:11:00,975 Epoch[23] Batch [260]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.114154,	
2017-07-31 17:11:08,093 Epoch[23] Batch [270]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.113755,	
2017-07-31 17:11:14,977 Epoch[23] Batch [280]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.113574,	
2017-07-31 17:11:21,399 Epoch[23] Batch [290]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.113745,	
2017-07-31 17:11:28,505 Epoch[23] Batch [300]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.113690,	
2017-07-31 17:11:35,385 Epoch[23] Batch [310]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.114047,	
2017-07-31 17:11:42,124 Epoch[23] Batch [320]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.113972,	
2017-07-31 17:11:48,850 Epoch[23] Batch [330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.113814,	
2017-07-31 17:11:56,116 Epoch[23] Batch [340]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.113824,	
2017-07-31 17:12:02,782 Epoch[23] Batch [350]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.113703,	
2017-07-31 17:12:09,889 Epoch[23] Batch [360]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.113524,	
2017-07-31 17:12:16,842 Epoch[23] Batch [370]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.113507,	
2017-07-31 17:12:24,199 Epoch[23] Batch [380]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.113354,	
2017-07-31 17:12:31,074 Epoch[23] Batch [390]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.113372,	
2017-07-31 17:12:38,036 Epoch[23] Batch [400]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.113162,	
2017-07-31 17:12:44,388 Epoch[23] Batch [410]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.113178,	
2017-07-31 17:12:51,356 Epoch[23] Batch [420]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.112967,	
2017-07-31 17:12:57,874 Epoch[23] Batch [430]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.113043,	
2017-07-31 17:13:04,584 Epoch[23] Batch [440]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.113049,	
2017-07-31 17:13:11,097 Epoch[23] Batch [450]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.112932,	
2017-07-31 17:13:17,892 Epoch[23] Batch [460]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.112545,	
2017-07-31 17:13:24,886 Epoch[23] Batch [470]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.112313,	
2017-07-31 17:13:31,857 Epoch[23] Batch [480]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.112095,	
2017-07-31 17:13:38,792 Epoch[23] Batch [490]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.112023,	
2017-07-31 17:13:45,792 Epoch[23] Batch [500]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.112123,	
2017-07-31 17:13:52,473 Epoch[23] Batch [510]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.112004,	
2017-07-31 17:13:59,267 Epoch[23] Batch [520]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.112468,	
2017-07-31 17:14:06,253 Epoch[23] Batch [530]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.112691,	
2017-07-31 17:14:13,118 Epoch[23] Batch [540]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.112629,	
2017-07-31 17:14:19,967 Epoch[23] Batch [550]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.112629,	
2017-07-31 17:14:27,157 Epoch[23] Batch [560]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.112599,	
2017-07-31 17:14:34,237 Epoch[23] Batch [570]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.112725,	
2017-07-31 17:14:41,166 Epoch[23] Batch [580]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.112783,	
2017-07-31 17:14:48,143 Epoch[23] Batch [590]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.112876,	
2017-07-31 17:14:55,263 Epoch[23] Batch [600]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.112959,	
2017-07-31 17:15:02,448 Epoch[23] Batch [610]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.112870,	
2017-07-31 17:15:09,235 Epoch[23] Batch [620]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.112862,	
2017-07-31 17:15:15,372 Epoch[23] Batch [630]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.112726,	
2017-07-31 17:15:21,838 Epoch[23] Batch [640]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.112692,	
2017-07-31 17:15:29,149 Epoch[23] Batch [650]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.112860,	
2017-07-31 17:15:36,009 Epoch[23] Batch [660]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.112991,	
2017-07-31 17:15:43,150 Epoch[23] Batch [670]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.113083,	
2017-07-31 17:15:49,860 Epoch[23] Batch [680]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.113135,	
2017-07-31 17:15:56,264 Epoch[23] Batch [690]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.113089,	
2017-07-31 17:16:02,963 Epoch[23] Batch [700]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.113190,	
2017-07-31 17:16:09,564 Epoch[23] Batch [710]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.113213,	
2017-07-31 17:16:16,349 Epoch[23] Batch [720]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.113058,	
2017-07-31 17:16:23,136 Epoch[23] Batch [730]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.113219,	
2017-07-31 17:16:30,151 Epoch[23] Batch [740]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.113214,	
2017-07-31 17:16:36,631 Epoch[23] Batch [750]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.113063,	
2017-07-31 17:16:43,449 Epoch[23] Batch [760]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.113107,	
2017-07-31 17:16:50,713 Epoch[23] Batch [770]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.113045,	
2017-07-31 17:16:57,021 Epoch[23] Batch [780]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.113118,	
2017-07-31 17:17:03,781 Epoch[23] Batch [790]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.113068,	
2017-07-31 17:17:10,299 Epoch[23] Batch [800]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.113204,	
2017-07-31 17:17:16,787 Epoch[23] Batch [810]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.113393,	
2017-07-31 17:17:23,788 Epoch[23] Batch [820]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.113358,	
2017-07-31 17:17:30,574 Epoch[23] Batch [830]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.113271,	
2017-07-31 17:17:36,740 Epoch[23] Batch [840]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.113216,	
2017-07-31 17:17:42,670 Epoch[23] Batch [850]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.113247,	
2017-07-31 17:17:49,094 Epoch[23] Batch [860]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.113194,	
2017-07-31 17:17:55,884 Epoch[23] Batch [870]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.113310,	
2017-07-31 17:18:02,479 Epoch[23] Batch [880]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.113493,	
2017-07-31 17:18:09,489 Epoch[23] Batch [890]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.113462,	
2017-07-31 17:18:15,800 Epoch[23] Batch [900]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.113448,	
2017-07-31 17:18:22,251 Epoch[23] Batch [910]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.113438,	
2017-07-31 17:18:28,635 Epoch[23] Batch [920]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.113401,	
2017-07-31 17:18:35,476 Epoch[23] Batch [930]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.113324,	
2017-07-31 17:18:42,030 Epoch[23] Batch [940]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.113370,	
2017-07-31 17:18:48,834 Epoch[23] Batch [950]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.113278,	
2017-07-31 17:18:55,505 Epoch[23] Batch [960]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.113299,	
2017-07-31 17:19:02,283 Epoch[23] Batch [970]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.113259,	
2017-07-31 17:19:08,937 Epoch[23] Batch [980]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.113237,	
2017-07-31 17:19:15,776 Epoch[23] Batch [990]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.113238,	
2017-07-31 17:19:22,226 Epoch[23] Batch [1000]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.113310,	
2017-07-31 17:19:28,978 Epoch[23] Batch [1010]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.113192,	
2017-07-31 17:19:35,041 Epoch[23] Batch [1020]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.113089,	
2017-07-31 17:19:41,387 Epoch[23] Batch [1030]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.113016,	
2017-07-31 17:19:48,283 Epoch[23] Batch [1040]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.112956,	
2017-07-31 17:19:55,343 Epoch[23] Batch [1050]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.112929,	
2017-07-31 17:20:02,239 Epoch[23] Batch [1060]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.112883,	
2017-07-31 17:20:09,003 Epoch[23] Batch [1070]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.112983,	
2017-07-31 17:20:15,672 Epoch[23] Batch [1080]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.113233,	
2017-07-31 17:20:22,373 Epoch[23] Batch [1090]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.113383,	
2017-07-31 17:20:29,240 Epoch[23] Batch [1100]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.113528,	
2017-07-31 17:20:36,295 Epoch[23] Batch [1110]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.113625,	
2017-07-31 17:20:43,170 Epoch[23] Batch [1120]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.113579,	
2017-07-31 17:20:49,993 Epoch[23] Batch [1130]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.113688,	
2017-07-31 17:20:56,881 Epoch[23] Batch [1140]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.113685,	
2017-07-31 17:21:03,645 Epoch[23] Batch [1150]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.113665,	
2017-07-31 17:21:10,006 Epoch[23] Batch [1160]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.113689,	
2017-07-31 17:21:16,547 Epoch[23] Batch [1170]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.113641,	
2017-07-31 17:21:23,602 Epoch[23] Batch [1180]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.113679,	
2017-07-31 17:21:30,115 Epoch[23] Batch [1190]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.113653,	
2017-07-31 17:21:36,915 Epoch[23] Batch [1200]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.113724,	
2017-07-31 17:21:43,224 Epoch[23] Batch [1210]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.113694,	
2017-07-31 17:21:50,025 Epoch[23] Batch [1220]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.113607,	
2017-07-31 17:21:56,925 Epoch[23] Batch [1230]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.113546,	
2017-07-31 17:22:03,703 Epoch[23] Batch [1240]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.113520,	
2017-07-31 17:22:09,924 Epoch[23] Batch [1250]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.113489,	
2017-07-31 17:22:16,443 Epoch[23] Batch [1260]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.113578,	
2017-07-31 17:22:23,021 Epoch[23] Batch [1270]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.113565,	
2017-07-31 17:22:29,736 Epoch[23] Batch [1280]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.113453,	
2017-07-31 17:22:36,240 Epoch[23] Batch [1290]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.113443,	
2017-07-31 17:22:42,923 Epoch[23] Batch [1300]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.113469,	
2017-07-31 17:22:49,942 Epoch[23] Batch [1310]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.113837,	
2017-07-31 17:22:56,847 Epoch[23] Batch [1320]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.114018,	
2017-07-31 17:23:03,538 Epoch[23] Batch [1330]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.114146,	
2017-07-31 17:23:09,508 Epoch[23] Batch [1340]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.114286,	
2017-07-31 17:23:15,482 Epoch[23] Batch [1350]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.114443,	
2017-07-31 17:23:21,722 Epoch[23] Batch [1360]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.114440,	
2017-07-31 17:23:28,314 Epoch[23] Batch [1370]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.114429,	
2017-07-31 17:23:34,932 Epoch[23] Batch [1380]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.114393,	
2017-07-31 17:23:41,714 Epoch[23] Batch [1390]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.114227,	
2017-07-31 17:23:49,239 Epoch[23] Batch [1400]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.114298,	
2017-07-31 17:23:55,338 Epoch[23] Batch [1410]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.114500,	
2017-07-31 17:24:02,084 Epoch[23] Batch [1420]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.114699,	
2017-07-31 17:24:08,845 Epoch[23] Batch [1430]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.114735,	
2017-07-31 17:24:15,929 Epoch[23] Batch [1440]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.114815,	
2017-07-31 17:24:21,817 Epoch[23] Batch [1450]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.114974,	
2017-07-31 17:24:26,915 Epoch[23] Batch [1460]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.114987,	
2017-07-31 17:24:32,994 Epoch[23] Batch [1470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.115008,	
2017-07-31 17:24:39,410 Epoch[23] Batch [1480]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.115087,	
2017-07-31 17:24:43,524 Epoch[23] Train-FCNLogLoss=0.115177
2017-07-31 17:24:43,525 Epoch[23] Time cost=1000.424
2017-07-31 17:24:44,678 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.params"
2017-07-31 17:24:47,997 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.states"
2017-07-31 17:24:55,233 Epoch[24] Batch [10]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.108836,	
2017-07-31 17:25:00,542 Epoch[24] Batch [20]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.115949,	
2017-07-31 17:25:07,073 Epoch[24] Batch [30]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.116517,	
2017-07-31 17:25:13,497 Epoch[24] Batch [40]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.114245,	
2017-07-31 17:25:20,055 Epoch[24] Batch [50]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.116250,	
2017-07-31 17:25:26,544 Epoch[24] Batch [60]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.114898,	
2017-07-31 17:25:32,423 Epoch[24] Batch [70]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.114774,	
2017-07-31 17:25:38,404 Epoch[24] Batch [80]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.115185,	
2017-07-31 17:25:44,333 Epoch[24] Batch [90]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.114736,	
2017-07-31 17:25:50,022 Epoch[24] Batch [100]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.115110,	
2017-07-31 17:25:56,083 Epoch[24] Batch [110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.114238,	
2017-07-31 17:26:02,031 Epoch[24] Batch [120]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.113811,	
2017-07-31 17:26:08,549 Epoch[24] Batch [130]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.113261,	
2017-07-31 17:26:14,954 Epoch[24] Batch [140]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.113106,	
2017-07-31 17:26:21,722 Epoch[24] Batch [150]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.112906,	
2017-07-31 17:26:27,744 Epoch[24] Batch [160]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.112796,	
2017-07-31 17:26:34,081 Epoch[24] Batch [170]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.112466,	
2017-07-31 17:26:41,110 Epoch[24] Batch [180]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.112166,	
2017-07-31 17:26:47,210 Epoch[24] Batch [190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.111414,	
2017-07-31 17:26:53,665 Epoch[24] Batch [200]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.112111,	
2017-07-31 17:27:00,324 Epoch[24] Batch [210]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.112839,	
2017-07-31 17:27:07,070 Epoch[24] Batch [220]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.112371,	
2017-07-31 17:27:13,625 Epoch[24] Batch [230]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.112295,	
2017-07-31 17:27:20,280 Epoch[24] Batch [240]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.112156,	
2017-07-31 17:27:26,348 Epoch[24] Batch [250]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.112515,	
2017-07-31 17:27:32,716 Epoch[24] Batch [260]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.112724,	
2017-07-31 17:27:39,178 Epoch[24] Batch [270]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.112407,	
2017-07-31 17:27:45,386 Epoch[24] Batch [280]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.112315,	
2017-07-31 17:27:51,761 Epoch[24] Batch [290]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.112064,	
2017-07-31 17:27:56,902 Epoch[24] Batch [300]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.112015,	
2017-07-31 17:28:02,571 Epoch[24] Batch [310]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.112115,	
2017-07-31 17:28:08,716 Epoch[24] Batch [320]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.112142,	
2017-07-31 17:28:15,947 Epoch[24] Batch [330]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.112470,	
2017-07-31 17:28:22,025 Epoch[24] Batch [340]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.112514,	
2017-07-31 17:28:27,980 Epoch[24] Batch [350]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.112485,	
2017-07-31 17:28:33,254 Epoch[24] Batch [360]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.112402,	
2017-07-31 17:28:38,889 Epoch[24] Batch [370]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.111978,	
2017-07-31 17:28:44,965 Epoch[24] Batch [380]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.111734,	
2017-07-31 17:28:51,033 Epoch[24] Batch [390]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.111666,	
2017-07-31 17:28:57,905 Epoch[24] Batch [400]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.111733,	
2017-07-31 17:29:04,879 Epoch[24] Batch [410]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.111874,	
2017-07-31 17:29:11,372 Epoch[24] Batch [420]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.111839,	
2017-07-31 17:29:16,888 Epoch[24] Batch [430]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.111950,	
2017-07-31 17:29:23,664 Epoch[24] Batch [440]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.112099,	
2017-07-31 17:29:30,275 Epoch[24] Batch [450]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.112126,	
2017-07-31 17:29:37,379 Epoch[24] Batch [460]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.112349,	
2017-07-31 17:29:44,171 Epoch[24] Batch [470]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.112282,	
2017-07-31 17:29:49,811 Epoch[24] Batch [480]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.112185,	
2017-07-31 17:29:55,939 Epoch[24] Batch [490]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.112242,	
2017-07-31 17:30:02,371 Epoch[24] Batch [500]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.112140,	
2017-07-31 17:30:08,852 Epoch[24] Batch [510]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.112410,	
2017-07-31 17:30:15,722 Epoch[24] Batch [520]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.112459,	
2017-07-31 17:30:22,797 Epoch[24] Batch [530]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.112460,	
2017-07-31 17:30:29,491 Epoch[24] Batch [540]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.112835,	
2017-07-31 17:30:35,876 Epoch[24] Batch [550]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.112543,	
2017-07-31 17:30:42,034 Epoch[24] Batch [560]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.112457,	
2017-07-31 17:30:48,367 Epoch[24] Batch [570]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.112371,	
2017-07-31 17:30:55,704 Epoch[24] Batch [580]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.112458,	
2017-07-31 17:31:02,684 Epoch[24] Batch [590]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.112594,	
2017-07-31 17:31:09,800 Epoch[24] Batch [600]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.112481,	
2017-07-31 17:31:15,933 Epoch[24] Batch [610]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.112568,	
2017-07-31 17:31:22,331 Epoch[24] Batch [620]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.112629,	
2017-07-31 17:31:28,734 Epoch[24] Batch [630]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.112665,	
2017-07-31 17:31:35,438 Epoch[24] Batch [640]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.112747,	
2017-07-31 17:31:41,688 Epoch[24] Batch [650]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.113240,	
2017-07-31 17:31:48,535 Epoch[24] Batch [660]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.114215,	
2017-07-31 17:31:55,209 Epoch[24] Batch [670]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.115361,	
2017-07-31 17:32:01,917 Epoch[24] Batch [680]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.115840,	
2017-07-31 17:32:08,639 Epoch[24] Batch [690]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.116208,	
2017-07-31 17:32:15,381 Epoch[24] Batch [700]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.116816,	
2017-07-31 17:32:22,132 Epoch[24] Batch [710]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.116946,	
2017-07-31 17:32:28,524 Epoch[24] Batch [720]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.116951,	
2017-07-31 17:32:34,991 Epoch[24] Batch [730]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.117065,	
2017-07-31 17:32:41,674 Epoch[24] Batch [740]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.116938,	
2017-07-31 17:32:48,702 Epoch[24] Batch [750]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.117056,	
2017-07-31 17:32:55,226 Epoch[24] Batch [760]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.117032,	
2017-07-31 17:33:01,179 Epoch[24] Batch [770]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.117169,	
2017-07-31 17:33:07,914 Epoch[24] Batch [780]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.117441,	
2017-07-31 17:33:14,392 Epoch[24] Batch [790]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.117623,	
2017-07-31 17:33:21,026 Epoch[24] Batch [800]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.117689,	
2017-07-31 17:33:27,380 Epoch[24] Batch [810]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.117744,	
2017-07-31 17:33:34,765 Epoch[24] Batch [820]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.117496,	
2017-07-31 17:33:41,428 Epoch[24] Batch [830]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.117387,	
2017-07-31 17:33:47,589 Epoch[24] Batch [840]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.117477,	
2017-07-31 17:33:54,032 Epoch[24] Batch [850]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.117400,	
2017-07-31 17:34:00,688 Epoch[24] Batch [860]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.117382,	
2017-07-31 17:34:05,224 Epoch[24] Batch [870]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.117283,	
2017-07-31 17:34:09,556 Epoch[24] Batch [880]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.117297,	
2017-07-31 17:34:13,812 Epoch[24] Batch [890]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.117415,	
2017-07-31 17:34:17,976 Epoch[24] Batch [900]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.117344,	
2017-07-31 17:34:22,021 Epoch[24] Batch [910]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117256,	
2017-07-31 17:34:26,254 Epoch[24] Batch [920]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.117207,	
2017-07-31 17:34:30,446 Epoch[24] Batch [930]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.117102,	
2017-07-31 17:34:34,330 Epoch[24] Batch [940]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.117099,	
2017-07-31 17:34:38,529 Epoch[24] Batch [950]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.117028,	
2017-07-31 17:34:42,579 Epoch[24] Batch [960]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117032,	
2017-07-31 17:34:46,603 Epoch[24] Batch [970]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117013,	
2017-07-31 17:34:50,668 Epoch[24] Batch [980]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116935,	
2017-07-31 17:34:54,630 Epoch[24] Batch [990]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.116812,	
2017-07-31 17:34:58,751 Epoch[24] Batch [1000]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.116827,	
2017-07-31 17:35:02,927 Epoch[24] Batch [1010]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.116695,	
2017-07-31 17:35:06,885 Epoch[24] Batch [1020]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.116685,	
2017-07-31 17:35:11,033 Epoch[24] Batch [1030]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.116572,	
2017-07-31 17:35:15,118 Epoch[24] Batch [1040]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116456,	
2017-07-31 17:35:19,340 Epoch[24] Batch [1050]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.116372,	
2017-07-31 17:35:23,627 Epoch[24] Batch [1060]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.116415,	
2017-07-31 17:35:27,562 Epoch[24] Batch [1070]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.116447,	
2017-07-31 17:35:31,502 Epoch[24] Batch [1080]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.116475,	
2017-07-31 17:35:35,580 Epoch[24] Batch [1090]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116503,	
2017-07-31 17:35:39,615 Epoch[24] Batch [1100]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.116596,	
2017-07-31 17:35:43,795 Epoch[24] Batch [1110]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.116542,	
2017-07-31 17:35:47,921 Epoch[24] Batch [1120]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.116538,	
2017-07-31 17:35:51,938 Epoch[24] Batch [1130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116570,	
2017-07-31 17:35:55,948 Epoch[24] Batch [1140]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.116468,	
2017-07-31 17:36:00,060 Epoch[24] Batch [1150]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116525,	
2017-07-31 17:36:03,943 Epoch[24] Batch [1160]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.116511,	
2017-07-31 17:36:08,010 Epoch[24] Batch [1170]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116445,	
2017-07-31 17:36:12,103 Epoch[24] Batch [1180]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116428,	
2017-07-31 17:36:16,198 Epoch[24] Batch [1190]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116474,	
2017-07-31 17:36:20,367 Epoch[24] Batch [1200]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.116400,	
2017-07-31 17:36:24,334 Epoch[24] Batch [1210]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.116431,	
2017-07-31 17:36:28,368 Epoch[24] Batch [1220]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116517,	
2017-07-31 17:36:32,703 Epoch[24] Batch [1230]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.116525,	
2017-07-31 17:36:37,003 Epoch[24] Batch [1240]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.116548,	
2017-07-31 17:36:41,236 Epoch[24] Batch [1250]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.116547,	
2017-07-31 17:36:45,490 Epoch[24] Batch [1260]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.116462,	
2017-07-31 17:36:49,600 Epoch[24] Batch [1270]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116371,	
2017-07-31 17:36:53,573 Epoch[24] Batch [1280]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.116285,	
2017-07-31 17:36:57,626 Epoch[24] Batch [1290]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.116230,	
2017-07-31 17:37:01,797 Epoch[24] Batch [1300]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.116140,	
2017-07-31 17:37:05,831 Epoch[24] Batch [1310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116082,	
2017-07-31 17:37:10,060 Epoch[24] Batch [1320]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.116119,	
2017-07-31 17:37:14,322 Epoch[24] Batch [1330]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.115982,	
2017-07-31 17:37:18,438 Epoch[24] Batch [1340]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.115982,	
2017-07-31 17:37:22,512 Epoch[24] Batch [1350]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115950,	
2017-07-31 17:37:26,346 Epoch[24] Batch [1360]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.115891,	
2017-07-31 17:37:30,564 Epoch[24] Batch [1370]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.115969,	
2017-07-31 17:37:34,661 Epoch[24] Batch [1380]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.115989,	
2017-07-31 17:37:38,615 Epoch[24] Batch [1390]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.116067,	
2017-07-31 17:37:42,759 Epoch[24] Batch [1400]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.116045,	
2017-07-31 17:37:46,949 Epoch[24] Batch [1410]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.116032,	
2017-07-31 17:37:51,190 Epoch[24] Batch [1420]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.116077,	
2017-07-31 17:37:55,747 Epoch[24] Batch [1430]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.116162,	
2017-07-31 17:38:00,468 Epoch[24] Batch [1440]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.116215,	
2017-07-31 17:38:04,872 Epoch[24] Batch [1450]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.116140,	
2017-07-31 17:38:09,340 Epoch[24] Batch [1460]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.116077,	
2017-07-31 17:38:13,647 Epoch[24] Batch [1470]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.116060,	
2017-07-31 17:38:18,230 Epoch[24] Batch [1480]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.115941,	
2017-07-31 17:38:20,723 Epoch[24] Train-FCNLogLoss=0.115863
2017-07-31 17:38:20,724 Epoch[24] Time cost=812.726
2017-07-31 17:38:21,531 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.params"
2017-07-31 17:38:23,484 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.states"
2017-07-31 17:38:28,580 Epoch[25] Batch [10]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.107017,	
2017-07-31 17:38:32,955 Epoch[25] Batch [20]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.107093,	
2017-07-31 17:38:37,315 Epoch[25] Batch [30]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.107218,	
2017-07-31 17:38:41,736 Epoch[25] Batch [40]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.107333,	
2017-07-31 17:38:45,813 Epoch[25] Batch [50]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.106289,	
2017-07-31 17:38:50,208 Epoch[25] Batch [60]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.107523,	
2017-07-31 17:38:54,772 Epoch[25] Batch [70]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108238,	
2017-07-31 17:38:59,109 Epoch[25] Batch [80]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.107473,	
2017-07-31 17:39:03,410 Epoch[25] Batch [90]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.109236,	
2017-07-31 17:39:07,673 Epoch[25] Batch [100]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.108021,	
2017-07-31 17:39:12,134 Epoch[25] Batch [110]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.109244,	
2017-07-31 17:39:16,262 Epoch[25] Batch [120]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.109043,	
2017-07-31 17:39:20,545 Epoch[25] Batch [130]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.108526,	
2017-07-31 17:39:24,946 Epoch[25] Batch [140]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108926,	
2017-07-31 17:39:29,086 Epoch[25] Batch [150]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.108950,	
2017-07-31 17:39:33,304 Epoch[25] Batch [160]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.109608,	
2017-07-31 17:39:37,664 Epoch[25] Batch [170]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.109283,	
2017-07-31 17:39:42,204 Epoch[25] Batch [180]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.109330,	
2017-07-31 17:39:46,351 Epoch[25] Batch [190]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.108802,	
2017-07-31 17:39:50,791 Epoch[25] Batch [200]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108544,	
2017-07-31 17:39:55,157 Epoch[25] Batch [210]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.109124,	
2017-07-31 17:39:59,482 Epoch[25] Batch [220]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109064,	
2017-07-31 17:40:04,373 Epoch[25] Batch [230]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.108820,	
2017-07-31 17:40:08,546 Epoch[25] Batch [240]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.108270,	
2017-07-31 17:40:12,850 Epoch[25] Batch [250]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.108508,	
2017-07-31 17:40:17,334 Epoch[25] Batch [260]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.108770,	
2017-07-31 17:40:21,856 Epoch[25] Batch [270]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.109140,	
2017-07-31 17:40:26,670 Epoch[25] Batch [280]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.108674,	
2017-07-31 17:40:31,112 Epoch[25] Batch [290]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.109024,	
2017-07-31 17:40:35,330 Epoch[25] Batch [300]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.108880,	
2017-07-31 17:40:39,635 Epoch[25] Batch [310]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.109304,	
2017-07-31 17:40:44,050 Epoch[25] Batch [320]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.109440,	
2017-07-31 17:40:48,748 Epoch[25] Batch [330]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.109411,	
2017-07-31 17:40:53,198 Epoch[25] Batch [340]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.109201,	
2017-07-31 17:40:57,525 Epoch[25] Batch [350]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109484,	
2017-07-31 17:41:01,860 Epoch[25] Batch [360]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.109819,	
2017-07-31 17:41:06,544 Epoch[25] Batch [370]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109888,	
2017-07-31 17:41:10,829 Epoch[25] Batch [380]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.109909,	
2017-07-31 17:41:14,961 Epoch[25] Batch [390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.109765,	
2017-07-31 17:41:19,137 Epoch[25] Batch [400]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109895,	
2017-07-31 17:41:23,660 Epoch[25] Batch [410]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.110089,	
2017-07-31 17:41:27,993 Epoch[25] Batch [420]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.110084,	
2017-07-31 17:41:32,430 Epoch[25] Batch [430]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.110357,	
2017-07-31 17:41:36,792 Epoch[25] Batch [440]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.110467,	
2017-07-31 17:41:41,262 Epoch[25] Batch [450]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.110447,	
2017-07-31 17:41:45,707 Epoch[25] Batch [460]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.110511,	
2017-07-31 17:41:50,165 Epoch[25] Batch [470]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.110443,	
2017-07-31 17:41:54,883 Epoch[25] Batch [480]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.110577,	
2017-07-31 17:41:59,696 Epoch[25] Batch [490]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.110692,	
2017-07-31 17:42:03,966 Epoch[25] Batch [500]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.110821,	
2017-07-31 17:42:08,220 Epoch[25] Batch [510]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.111102,	
2017-07-31 17:42:12,825 Epoch[25] Batch [520]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.110995,	
2017-07-31 17:42:17,424 Epoch[25] Batch [530]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.111038,	
2017-07-31 17:42:21,832 Epoch[25] Batch [540]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.111293,	
2017-07-31 17:42:26,219 Epoch[25] Batch [550]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.111928,	
2017-07-31 17:42:30,879 Epoch[25] Batch [560]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.112074,	
2017-07-31 17:42:35,124 Epoch[25] Batch [570]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.112186,	
2017-07-31 17:42:39,473 Epoch[25] Batch [580]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.112136,	
2017-07-31 17:42:44,014 Epoch[25] Batch [590]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112330,	
2017-07-31 17:42:48,710 Epoch[25] Batch [600]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.112457,	
2017-07-31 17:42:52,859 Epoch[25] Batch [610]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112371,	
2017-07-31 17:42:57,110 Epoch[25] Batch [620]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.112495,	
2017-07-31 17:43:01,377 Epoch[25] Batch [630]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.112383,	
2017-07-31 17:43:05,638 Epoch[25] Batch [640]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.112331,	
2017-07-31 17:43:10,233 Epoch[25] Batch [650]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.112287,	
2017-07-31 17:43:14,759 Epoch[25] Batch [660]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.112272,	
2017-07-31 17:43:19,197 Epoch[25] Batch [670]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.112282,	
2017-07-31 17:43:23,718 Epoch[25] Batch [680]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.112657,	
2017-07-31 17:43:28,398 Epoch[25] Batch [690]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.112872,	
2017-07-31 17:43:33,032 Epoch[25] Batch [700]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.112807,	
2017-07-31 17:43:37,633 Epoch[25] Batch [710]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.112670,	
2017-07-31 17:43:42,183 Epoch[25] Batch [720]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.112691,	
2017-07-31 17:43:46,519 Epoch[25] Batch [730]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.112704,	
2017-07-31 17:43:50,927 Epoch[25] Batch [740]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.112551,	
2017-07-31 17:43:55,716 Epoch[25] Batch [750]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.112404,	
2017-07-31 17:44:00,186 Epoch[25] Batch [760]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.112400,	
2017-07-31 17:44:04,684 Epoch[25] Batch [770]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.112413,	
2017-07-31 17:44:09,009 Epoch[25] Batch [780]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.112355,	
2017-07-31 17:44:13,320 Epoch[25] Batch [790]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.112377,	
2017-07-31 17:44:17,999 Epoch[25] Batch [800]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.112388,	
2017-07-31 17:44:22,439 Epoch[25] Batch [810]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.112352,	
2017-07-31 17:44:27,094 Epoch[25] Batch [820]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.112189,	
2017-07-31 17:44:31,758 Epoch[25] Batch [830]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.112208,	
2017-07-31 17:44:36,033 Epoch[25] Batch [840]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.112594,	
2017-07-31 17:44:40,284 Epoch[25] Batch [850]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.112538,	
2017-07-31 17:44:44,591 Epoch[25] Batch [860]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112636,	
2017-07-31 17:44:48,853 Epoch[25] Batch [870]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.112610,	
2017-07-31 17:44:53,441 Epoch[25] Batch [880]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.112486,	
2017-07-31 17:44:58,120 Epoch[25] Batch [890]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.112390,	
2017-07-31 17:45:02,663 Epoch[25] Batch [900]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.112421,	
2017-07-31 17:45:07,068 Epoch[25] Batch [910]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.112478,	
2017-07-31 17:45:11,501 Epoch[25] Batch [920]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.112717,	
2017-07-31 17:45:15,864 Epoch[25] Batch [930]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.112686,	
2017-07-31 17:45:20,547 Epoch[25] Batch [940]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.112601,	
2017-07-31 17:45:25,036 Epoch[25] Batch [950]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.112595,	
2017-07-31 17:45:29,860 Epoch[25] Batch [960]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.112579,	
2017-07-31 17:45:34,452 Epoch[25] Batch [970]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.112796,	
2017-07-31 17:45:38,921 Epoch[25] Batch [980]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.112716,	
2017-07-31 17:45:43,435 Epoch[25] Batch [990]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.112580,	
2017-07-31 17:45:48,257 Epoch[25] Batch [1000]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.112675,	
2017-07-31 17:45:52,965 Epoch[25] Batch [1010]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.112696,	
2017-07-31 17:45:57,636 Epoch[25] Batch [1020]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.112691,	
2017-07-31 17:46:02,286 Epoch[25] Batch [1030]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.112563,	
2017-07-31 17:46:06,787 Epoch[25] Batch [1040]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.112436,	
2017-07-31 17:46:11,440 Epoch[25] Batch [1050]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.112363,	
2017-07-31 17:46:15,891 Epoch[25] Batch [1060]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.112334,	
2017-07-31 17:46:20,343 Epoch[25] Batch [1070]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.112313,	
2017-07-31 17:46:24,853 Epoch[25] Batch [1080]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.112418,	
2017-07-31 17:46:29,416 Epoch[25] Batch [1090]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112376,	
2017-07-31 17:46:34,256 Epoch[25] Batch [1100]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.112375,	
2017-07-31 17:46:39,101 Epoch[25] Batch [1110]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.112363,	
2017-07-31 17:46:43,766 Epoch[25] Batch [1120]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.112349,	
2017-07-31 17:46:48,341 Epoch[25] Batch [1130]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.112309,	
2017-07-31 17:46:52,844 Epoch[25] Batch [1140]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.112265,	
2017-07-31 17:46:57,235 Epoch[25] Batch [1150]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.112269,	
2017-07-31 17:47:01,801 Epoch[25] Batch [1160]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.112236,	
2017-07-31 17:47:06,314 Epoch[25] Batch [1170]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.112234,	
2017-07-31 17:47:10,819 Epoch[25] Batch [1180]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.112285,	
2017-07-31 17:47:15,390 Epoch[25] Batch [1190]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.112243,	
2017-07-31 17:47:20,266 Epoch[25] Batch [1200]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.112271,	
2017-07-31 17:47:24,830 Epoch[25] Batch [1210]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.112237,	
2017-07-31 17:47:29,054 Epoch[25] Batch [1220]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.112193,	
2017-07-31 17:47:33,343 Epoch[25] Batch [1230]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.112048,	
2017-07-31 17:47:37,892 Epoch[25] Batch [1240]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.112031,	
2017-07-31 17:47:42,265 Epoch[25] Batch [1250]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.112114,	
2017-07-31 17:47:46,614 Epoch[25] Batch [1260]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.112022,	
2017-07-31 17:47:51,098 Epoch[25] Batch [1270]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.111964,	
2017-07-31 17:47:55,560 Epoch[25] Batch [1280]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111945,	
2017-07-31 17:47:59,889 Epoch[25] Batch [1290]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111827,	
2017-07-31 17:48:04,464 Epoch[25] Batch [1300]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.111860,	
2017-07-31 17:48:09,327 Epoch[25] Batch [1310]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.111910,	
2017-07-31 17:48:13,764 Epoch[25] Batch [1320]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111907,	
2017-07-31 17:48:18,306 Epoch[25] Batch [1330]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.111935,	
2017-07-31 17:48:22,995 Epoch[25] Batch [1340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.111842,	
2017-07-31 17:48:27,334 Epoch[25] Batch [1350]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.111759,	
2017-07-31 17:48:31,974 Epoch[25] Batch [1360]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.111729,	
2017-07-31 17:48:36,628 Epoch[25] Batch [1370]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.111684,	
2017-07-31 17:48:41,003 Epoch[25] Batch [1380]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.111661,	
2017-07-31 17:48:45,371 Epoch[25] Batch [1390]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.111684,	
2017-07-31 17:48:49,901 Epoch[25] Batch [1400]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.111652,	
2017-07-31 17:48:54,397 Epoch[25] Batch [1410]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.111661,	
2017-07-31 17:48:58,863 Epoch[25] Batch [1420]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.111681,	
2017-07-31 17:49:03,320 Epoch[25] Batch [1430]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111539,	
2017-07-31 17:49:07,837 Epoch[25] Batch [1440]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.111548,	
2017-07-31 17:49:12,414 Epoch[25] Batch [1450]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.111559,	
2017-07-31 17:49:16,981 Epoch[25] Batch [1460]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.111577,	
2017-07-31 17:49:21,748 Epoch[25] Batch [1470]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.111545,	
2017-07-31 17:49:26,433 Epoch[25] Batch [1480]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.111609,	
2017-07-31 17:49:29,094 Epoch[25] Train-FCNLogLoss=0.111593
2017-07-31 17:49:29,095 Epoch[25] Time cost=665.611
2017-07-31 17:49:29,828 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.params"
2017-07-31 17:49:31,763 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.states"
2017-07-31 17:49:37,228 Epoch[26] Batch [10]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.115207,	
2017-07-31 17:49:41,775 Epoch[26] Batch [20]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.119730,	
2017-07-31 17:49:46,279 Epoch[26] Batch [30]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.121280,	
2017-07-31 17:49:50,778 Epoch[26] Batch [40]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.119241,	
2017-07-31 17:49:55,311 Epoch[26] Batch [50]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.117135,	
2017-07-31 17:49:59,882 Epoch[26] Batch [60]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.116369,	
2017-07-31 17:50:04,402 Epoch[26] Batch [70]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.114885,	
2017-07-31 17:50:08,899 Epoch[26] Batch [80]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.113281,	
2017-07-31 17:50:13,797 Epoch[26] Batch [90]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.111843,	
2017-07-31 17:50:18,193 Epoch[26] Batch [100]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.111361,	
2017-07-31 17:50:22,722 Epoch[26] Batch [110]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.110898,	
2017-07-31 17:50:27,087 Epoch[26] Batch [120]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.110129,	
2017-07-31 17:50:31,440 Epoch[26] Batch [130]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.109909,	
2017-07-31 17:50:35,920 Epoch[26] Batch [140]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.109506,	
2017-07-31 17:50:40,185 Epoch[26] Batch [150]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.109133,	
2017-07-31 17:50:44,485 Epoch[26] Batch [160]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.108899,	
2017-07-31 17:50:48,718 Epoch[26] Batch [170]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.108131,	
2017-07-31 17:50:53,059 Epoch[26] Batch [180]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.107276,	
2017-07-31 17:50:57,391 Epoch[26] Batch [190]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.107312,	
2017-07-31 17:51:01,839 Epoch[26] Batch [200]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.107614,	
2017-07-31 17:51:06,308 Epoch[26] Batch [210]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.107222,	
2017-07-31 17:51:10,922 Epoch[26] Batch [220]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.106663,	
2017-07-31 17:51:15,221 Epoch[26] Batch [230]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106712,	
2017-07-31 17:51:19,634 Epoch[26] Batch [240]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.107012,	
2017-07-31 17:51:23,973 Epoch[26] Batch [250]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.106435,	
2017-07-31 17:51:28,271 Epoch[26] Batch [260]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.106112,	
2017-07-31 17:51:32,634 Epoch[26] Batch [270]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.106792,	
2017-07-31 17:51:37,181 Epoch[26] Batch [280]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107054,	
2017-07-31 17:51:41,588 Epoch[26] Batch [290]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.107831,	
2017-07-31 17:51:45,983 Epoch[26] Batch [300]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.107712,	
2017-07-31 17:51:50,259 Epoch[26] Batch [310]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.107939,	
2017-07-31 17:51:54,719 Epoch[26] Batch [320]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108068,	
2017-07-31 17:51:59,028 Epoch[26] Batch [330]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.108504,	
2017-07-31 17:52:03,257 Epoch[26] Batch [340]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.110374,	
2017-07-31 17:52:07,466 Epoch[26] Batch [350]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.110769,	
2017-07-31 17:52:11,771 Epoch[26] Batch [360]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.111248,	
2017-07-31 17:52:16,209 Epoch[26] Batch [370]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111639,	
2017-07-31 17:52:20,366 Epoch[26] Batch [380]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.111515,	
2017-07-31 17:52:24,682 Epoch[26] Batch [390]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.111748,	
2017-07-31 17:52:28,976 Epoch[26] Batch [400]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.111854,	
2017-07-31 17:52:33,367 Epoch[26] Batch [410]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.111965,	
2017-07-31 17:52:37,535 Epoch[26] Batch [420]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.111618,	
2017-07-31 17:52:41,851 Epoch[26] Batch [430]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.111993,	
2017-07-31 17:52:46,230 Epoch[26] Batch [440]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.111674,	
2017-07-31 17:52:50,769 Epoch[26] Batch [450]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.111748,	
2017-07-31 17:52:55,344 Epoch[26] Batch [460]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.111750,	
2017-07-31 17:52:59,703 Epoch[26] Batch [470]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.111574,	
2017-07-31 17:53:04,199 Epoch[26] Batch [480]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.111497,	
2017-07-31 17:53:08,367 Epoch[26] Batch [490]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.111604,	
2017-07-31 17:53:12,877 Epoch[26] Batch [500]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.111656,	
2017-07-31 17:53:17,209 Epoch[26] Batch [510]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111538,	
2017-07-31 17:53:21,594 Epoch[26] Batch [520]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.111564,	
2017-07-31 17:53:25,897 Epoch[26] Batch [530]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.111371,	
2017-07-31 17:53:30,427 Epoch[26] Batch [540]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.111061,	
2017-07-31 17:53:34,593 Epoch[26] Batch [550]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.111194,	
2017-07-31 17:53:38,920 Epoch[26] Batch [560]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.111056,	
2017-07-31 17:53:43,346 Epoch[26] Batch [570]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.111080,	
2017-07-31 17:53:47,632 Epoch[26] Batch [580]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.111030,	
2017-07-31 17:53:51,792 Epoch[26] Batch [590]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.110961,	
2017-07-31 17:53:56,183 Epoch[26] Batch [600]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.111003,	
2017-07-31 17:54:00,412 Epoch[26] Batch [610]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.110948,	
2017-07-31 17:54:04,723 Epoch[26] Batch [620]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.110970,	
2017-07-31 17:54:08,850 Epoch[26] Batch [630]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.111048,	
2017-07-31 17:54:13,002 Epoch[26] Batch [640]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.111065,	
2017-07-31 17:54:17,283 Epoch[26] Batch [650]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.111091,	
2017-07-31 17:54:21,494 Epoch[26] Batch [660]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.111337,	
2017-07-31 17:54:25,606 Epoch[26] Batch [670]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.111390,	
2017-07-31 17:54:29,949 Epoch[26] Batch [680]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.111380,	
2017-07-31 17:54:34,359 Epoch[26] Batch [690]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.111240,	
2017-07-31 17:54:38,768 Epoch[26] Batch [700]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.111307,	
2017-07-31 17:54:43,055 Epoch[26] Batch [710]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.111182,	
2017-07-31 17:54:47,363 Epoch[26] Batch [720]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.110993,	
2017-07-31 17:54:51,683 Epoch[26] Batch [730]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110935,	
2017-07-31 17:54:56,158 Epoch[26] Batch [740]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.110833,	
2017-07-31 17:55:00,620 Epoch[26] Batch [750]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.110724,	
2017-07-31 17:55:04,901 Epoch[26] Batch [760]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.110596,	
2017-07-31 17:55:09,213 Epoch[26] Batch [770]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.110574,	
2017-07-31 17:55:13,327 Epoch[26] Batch [780]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110546,	
2017-07-31 17:55:17,633 Epoch[26] Batch [790]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.110482,	
2017-07-31 17:55:21,692 Epoch[26] Batch [800]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110432,	
2017-07-31 17:55:26,028 Epoch[26] Batch [810]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.110652,	
2017-07-31 17:55:30,279 Epoch[26] Batch [820]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.110621,	
2017-07-31 17:55:34,607 Epoch[26] Batch [830]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.110867,	
2017-07-31 17:55:39,013 Epoch[26] Batch [840]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.111016,	
2017-07-31 17:55:43,394 Epoch[26] Batch [850]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.111189,	
2017-07-31 17:55:47,732 Epoch[26] Batch [860]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.111180,	
2017-07-31 17:55:51,866 Epoch[26] Batch [870]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111199,	
2017-07-31 17:55:56,119 Epoch[26] Batch [880]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.111319,	
2017-07-31 17:56:00,519 Epoch[26] Batch [890]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.111377,	
2017-07-31 17:56:05,010 Epoch[26] Batch [900]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.111399,	
2017-07-31 17:56:09,435 Epoch[26] Batch [910]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.111507,	
2017-07-31 17:56:13,815 Epoch[26] Batch [920]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.111507,	
2017-07-31 17:56:18,146 Epoch[26] Batch [930]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111484,	
2017-07-31 17:56:22,620 Epoch[26] Batch [940]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.111583,	
2017-07-31 17:56:26,916 Epoch[26] Batch [950]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.111756,	
2017-07-31 17:56:31,113 Epoch[26] Batch [960]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.111815,	
2017-07-31 17:56:35,383 Epoch[26] Batch [970]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.111788,	
2017-07-31 17:56:39,619 Epoch[26] Batch [980]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.111746,	
2017-07-31 17:56:43,987 Epoch[26] Batch [990]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.111641,	
2017-07-31 17:56:48,159 Epoch[26] Batch [1000]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.111509,	
2017-07-31 17:56:52,554 Epoch[26] Batch [1010]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.111544,	
2017-07-31 17:56:56,895 Epoch[26] Batch [1020]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.111543,	
2017-07-31 17:57:01,237 Epoch[26] Batch [1030]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.111494,	
2017-07-31 17:57:05,670 Epoch[26] Batch [1040]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111632,	
2017-07-31 17:57:10,262 Epoch[26] Batch [1050]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.111660,	
2017-07-31 17:57:14,847 Epoch[26] Batch [1060]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.111566,	
2017-07-31 17:57:19,136 Epoch[26] Batch [1070]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.111493,	
2017-07-31 17:57:23,531 Epoch[26] Batch [1080]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.111449,	
2017-07-31 17:57:27,986 Epoch[26] Batch [1090]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.111233,	
2017-07-31 17:57:32,371 Epoch[26] Batch [1100]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.111256,	
2017-07-31 17:57:36,674 Epoch[26] Batch [1110]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.111208,	
2017-07-31 17:57:41,081 Epoch[26] Batch [1120]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.111169,	
2017-07-31 17:57:45,233 Epoch[26] Batch [1130]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.111227,	
2017-07-31 17:57:49,454 Epoch[26] Batch [1140]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.111227,	
2017-07-31 17:57:53,767 Epoch[26] Batch [1150]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.111228,	
2017-07-31 17:57:58,130 Epoch[26] Batch [1160]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.111263,	
2017-07-31 17:58:02,450 Epoch[26] Batch [1170]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.111142,	
2017-07-31 17:58:06,625 Epoch[26] Batch [1180]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.111194,	
2017-07-31 17:58:10,811 Epoch[26] Batch [1190]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.111180,	
2017-07-31 17:58:15,100 Epoch[26] Batch [1200]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.111192,	
2017-07-31 17:58:19,600 Epoch[26] Batch [1210]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.111042,	
2017-07-31 17:58:23,955 Epoch[26] Batch [1220]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.111039,	
2017-07-31 17:58:28,382 Epoch[26] Batch [1230]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.111147,	
2017-07-31 17:58:32,891 Epoch[26] Batch [1240]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.111193,	
2017-07-31 17:58:37,373 Epoch[26] Batch [1250]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.111139,	
2017-07-31 17:58:41,577 Epoch[26] Batch [1260]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.111278,	
2017-07-31 17:58:45,930 Epoch[26] Batch [1270]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.111311,	
2017-07-31 17:58:50,300 Epoch[26] Batch [1280]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.111350,	
2017-07-31 17:58:54,421 Epoch[26] Batch [1290]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.111360,	
2017-07-31 17:58:58,714 Epoch[26] Batch [1300]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.111318,	
2017-07-31 17:59:02,870 Epoch[26] Batch [1310]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.111263,	
2017-07-31 17:59:07,270 Epoch[26] Batch [1320]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.111315,	
2017-07-31 17:59:11,558 Epoch[26] Batch [1330]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.111277,	
2017-07-31 17:59:15,926 Epoch[26] Batch [1340]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.111270,	
2017-07-31 17:59:20,289 Epoch[26] Batch [1350]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.111234,	
2017-07-31 17:59:24,581 Epoch[26] Batch [1360]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.111299,	
2017-07-31 17:59:29,087 Epoch[26] Batch [1370]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.111315,	
2017-07-31 17:59:33,417 Epoch[26] Batch [1380]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111324,	
2017-07-31 17:59:37,701 Epoch[26] Batch [1390]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.111294,	
2017-07-31 17:59:42,059 Epoch[26] Batch [1400]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.111241,	
2017-07-31 17:59:46,378 Epoch[26] Batch [1410]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.111244,	
2017-07-31 17:59:50,651 Epoch[26] Batch [1420]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.111164,	
2017-07-31 17:59:54,865 Epoch[26] Batch [1430]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.111167,	
2017-07-31 17:59:59,129 Epoch[26] Batch [1440]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.111052,	
2017-07-31 18:00:03,399 Epoch[26] Batch [1450]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.111075,	
2017-07-31 18:00:07,653 Epoch[26] Batch [1460]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.111097,	
2017-07-31 18:00:11,881 Epoch[26] Batch [1470]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.111124,	
2017-07-31 18:00:16,305 Epoch[26] Batch [1480]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.111103,	
2017-07-31 18:00:18,971 Epoch[26] Train-FCNLogLoss=0.111094
2017-07-31 18:00:18,971 Epoch[26] Time cost=647.207
2017-07-31 18:00:19,695 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.params"
2017-07-31 18:00:21,193 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.states"
2017-07-31 18:00:26,183 Epoch[27] Batch [10]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.109366,	
2017-07-31 18:00:30,697 Epoch[27] Batch [20]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.103110,	
2017-07-31 18:00:35,058 Epoch[27] Batch [30]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.108307,	
2017-07-31 18:00:39,273 Epoch[27] Batch [40]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.104942,	
2017-07-31 18:00:43,577 Epoch[27] Batch [50]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.108266,	
2017-07-31 18:00:47,839 Epoch[27] Batch [60]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.109272,	
2017-07-31 18:00:51,991 Epoch[27] Batch [70]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107762,	
2017-07-31 18:00:56,278 Epoch[27] Batch [80]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.107958,	
2017-07-31 18:01:00,813 Epoch[27] Batch [90]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108101,	
2017-07-31 18:01:05,029 Epoch[27] Batch [100]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.107847,	
2017-07-31 18:01:09,395 Epoch[27] Batch [110]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.107821,	
2017-07-31 18:01:13,547 Epoch[27] Batch [120]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.107282,	
2017-07-31 18:01:17,951 Epoch[27] Batch [130]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.106471,	
2017-07-31 18:01:22,576 Epoch[27] Batch [140]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.107042,	
2017-07-31 18:01:27,064 Epoch[27] Batch [150]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.107448,	
2017-07-31 18:01:31,476 Epoch[27] Batch [160]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.107218,	
2017-07-31 18:01:35,685 Epoch[27] Batch [170]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.107599,	
2017-07-31 18:01:39,993 Epoch[27] Batch [180]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.107197,	
2017-07-31 18:01:44,522 Epoch[27] Batch [190]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.107505,	
2017-07-31 18:01:48,804 Epoch[27] Batch [200]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.107097,	
2017-07-31 18:01:53,172 Epoch[27] Batch [210]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.107090,	
2017-07-31 18:01:57,435 Epoch[27] Batch [220]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.107270,	
2017-07-31 18:02:01,806 Epoch[27] Batch [230]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.107089,	
2017-07-31 18:02:06,101 Epoch[27] Batch [240]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.107480,	
2017-07-31 18:02:10,386 Epoch[27] Batch [250]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.107690,	
2017-07-31 18:02:14,659 Epoch[27] Batch [260]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.108215,	
2017-07-31 18:02:18,959 Epoch[27] Batch [270]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.108047,	
2017-07-31 18:02:23,252 Epoch[27] Batch [280]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.107853,	
2017-07-31 18:02:27,495 Epoch[27] Batch [290]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.107668,	
2017-07-31 18:02:31,779 Epoch[27] Batch [300]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.107557,	
2017-07-31 18:02:36,117 Epoch[27] Batch [310]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.107156,	
2017-07-31 18:02:40,349 Epoch[27] Batch [320]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.107109,	
2017-07-31 18:02:44,738 Epoch[27] Batch [330]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.107309,	
2017-07-31 18:02:48,990 Epoch[27] Batch [340]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.106890,	
2017-07-31 18:02:53,223 Epoch[27] Batch [350]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.107117,	
2017-07-31 18:02:57,561 Epoch[27] Batch [360]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.107057,	
2017-07-31 18:03:01,832 Epoch[27] Batch [370]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.106908,	
2017-07-31 18:03:06,114 Epoch[27] Batch [380]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.106998,	
2017-07-31 18:03:10,356 Epoch[27] Batch [390]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.107246,	
2017-07-31 18:03:14,659 Epoch[27] Batch [400]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.107037,	
2017-07-31 18:03:19,076 Epoch[27] Batch [410]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.106981,	
2017-07-31 18:03:23,462 Epoch[27] Batch [420]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106788,	
2017-07-31 18:03:27,778 Epoch[27] Batch [430]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.107141,	
2017-07-31 18:03:32,126 Epoch[27] Batch [440]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.106999,	
2017-07-31 18:03:36,686 Epoch[27] Batch [450]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.107164,	
2017-07-31 18:03:41,181 Epoch[27] Batch [460]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.107023,	
2017-07-31 18:03:45,947 Epoch[27] Batch [470]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.107071,	
2017-07-31 18:03:50,419 Epoch[27] Batch [480]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.107214,	
2017-07-31 18:03:55,118 Epoch[27] Batch [490]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.107263,	
2017-07-31 18:03:59,823 Epoch[27] Batch [500]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.107145,	
2017-07-31 18:04:04,355 Epoch[27] Batch [510]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106975,	
2017-07-31 18:04:09,277 Epoch[27] Batch [520]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.106631,	
2017-07-31 18:04:14,061 Epoch[27] Batch [530]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.106582,	
2017-07-31 18:04:18,273 Epoch[27] Batch [540]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.106423,	
2017-07-31 18:04:22,956 Epoch[27] Batch [550]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.106799,	
2017-07-31 18:04:27,497 Epoch[27] Batch [560]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.106672,	
2017-07-31 18:04:32,320 Epoch[27] Batch [570]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.106715,	
2017-07-31 18:04:37,244 Epoch[27] Batch [580]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.106740,	
2017-07-31 18:04:41,623 Epoch[27] Batch [590]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.106791,	
2017-07-31 18:04:46,105 Epoch[27] Batch [600]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.107034,	
2017-07-31 18:04:50,514 Epoch[27] Batch [610]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.106934,	
2017-07-31 18:04:55,032 Epoch[27] Batch [620]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.106877,	
2017-07-31 18:04:59,548 Epoch[27] Batch [630]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106998,	
2017-07-31 18:05:04,057 Epoch[27] Batch [640]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.106969,	
2017-07-31 18:05:08,448 Epoch[27] Batch [650]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.106955,	
2017-07-31 18:05:12,962 Epoch[27] Batch [660]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.107130,	
2017-07-31 18:05:17,609 Epoch[27] Batch [670]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.107027,	
2017-07-31 18:05:21,919 Epoch[27] Batch [680]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.106834,	
2017-07-31 18:05:26,428 Epoch[27] Batch [690]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.106879,	
2017-07-31 18:05:30,968 Epoch[27] Batch [700]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.107156,	
2017-07-31 18:05:35,352 Epoch[27] Batch [710]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.107073,	
2017-07-31 18:05:40,068 Epoch[27] Batch [720]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.107296,	
2017-07-31 18:05:44,752 Epoch[27] Batch [730]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.107399,	
2017-07-31 18:05:49,079 Epoch[27] Batch [740]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.107444,	
2017-07-31 18:05:53,377 Epoch[27] Batch [750]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.107376,	
2017-07-31 18:05:57,654 Epoch[27] Batch [760]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.107583,	
2017-07-31 18:06:02,080 Epoch[27] Batch [770]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.107593,	
2017-07-31 18:06:06,487 Epoch[27] Batch [780]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.107583,	
2017-07-31 18:06:10,847 Epoch[27] Batch [790]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.107659,	
2017-07-31 18:06:15,437 Epoch[27] Batch [800]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.107772,	
2017-07-31 18:06:20,264 Epoch[27] Batch [810]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.107684,	
2017-07-31 18:06:24,748 Epoch[27] Batch [820]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.107669,	
2017-07-31 18:06:29,191 Epoch[27] Batch [830]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.107662,	
2017-07-31 18:06:33,653 Epoch[27] Batch [840]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.107741,	
2017-07-31 18:06:38,213 Epoch[27] Batch [850]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.107646,	
2017-07-31 18:06:42,636 Epoch[27] Batch [860]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.107687,	
2017-07-31 18:06:47,288 Epoch[27] Batch [870]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.108003,	
2017-07-31 18:06:51,975 Epoch[27] Batch [880]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.107938,	
2017-07-31 18:06:56,607 Epoch[27] Batch [890]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.107861,	
2017-07-31 18:07:00,987 Epoch[27] Batch [900]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.108008,	
2017-07-31 18:07:05,682 Epoch[27] Batch [910]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.107998,	
2017-07-31 18:07:10,336 Epoch[27] Batch [920]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.108042,	
2017-07-31 18:07:14,782 Epoch[27] Batch [930]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.107938,	
2017-07-31 18:07:19,086 Epoch[27] Batch [940]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.108257,	
2017-07-31 18:07:23,618 Epoch[27] Batch [950]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.108228,	
2017-07-31 18:07:28,250 Epoch[27] Batch [960]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.108126,	
2017-07-31 18:07:32,625 Epoch[27] Batch [970]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.108036,	
2017-07-31 18:07:37,295 Epoch[27] Batch [980]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.107949,	
2017-07-31 18:07:41,689 Epoch[27] Batch [990]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.108045,	
2017-07-31 18:07:46,162 Epoch[27] Batch [1000]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.107945,	
2017-07-31 18:07:50,588 Epoch[27] Batch [1010]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.107943,	
2017-07-31 18:07:55,192 Epoch[27] Batch [1020]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107966,	
2017-07-31 18:07:59,872 Epoch[27] Batch [1030]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.108065,	
2017-07-31 18:08:04,628 Epoch[27] Batch [1040]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.108045,	
2017-07-31 18:08:09,228 Epoch[27] Batch [1050]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107984,	
2017-07-31 18:08:13,831 Epoch[27] Batch [1060]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108245,	
2017-07-31 18:08:18,616 Epoch[27] Batch [1070]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.108274,	
2017-07-31 18:08:23,289 Epoch[27] Batch [1080]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.108197,	
2017-07-31 18:08:27,970 Epoch[27] Batch [1090]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.108241,	
2017-07-31 18:08:32,467 Epoch[27] Batch [1100]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.108277,	
2017-07-31 18:08:37,208 Epoch[27] Batch [1110]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.108151,	
2017-07-31 18:08:41,649 Epoch[27] Batch [1120]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108146,	
2017-07-31 18:08:46,094 Epoch[27] Batch [1130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.108058,	
2017-07-31 18:08:50,707 Epoch[27] Batch [1140]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108035,	
2017-07-31 18:08:54,886 Epoch[27] Batch [1150]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.107983,	
2017-07-31 18:08:59,636 Epoch[27] Batch [1160]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.107963,	
2017-07-31 18:09:04,079 Epoch[27] Batch [1170]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.107870,	
2017-07-31 18:09:08,450 Epoch[27] Batch [1180]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.107909,	
2017-07-31 18:09:13,123 Epoch[27] Batch [1190]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.107893,	
2017-07-31 18:09:17,339 Epoch[27] Batch [1200]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.107881,	
2017-07-31 18:09:21,690 Epoch[27] Batch [1210]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.107889,	
2017-07-31 18:09:26,172 Epoch[27] Batch [1220]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.107823,	
2017-07-31 18:09:30,519 Epoch[27] Batch [1230]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.107769,	
2017-07-31 18:09:34,961 Epoch[27] Batch [1240]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.107665,	
2017-07-31 18:09:39,411 Epoch[27] Batch [1250]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.107618,	
2017-07-31 18:09:44,114 Epoch[27] Batch [1260]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.107490,	
2017-07-31 18:09:48,800 Epoch[27] Batch [1270]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.107446,	
2017-07-31 18:09:53,400 Epoch[27] Batch [1280]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107444,	
2017-07-31 18:09:57,836 Epoch[27] Batch [1290]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.107550,	
2017-07-31 18:10:02,250 Epoch[27] Batch [1300]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.107599,	
2017-07-31 18:10:06,805 Epoch[27] Batch [1310]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107573,	
2017-07-31 18:10:11,360 Epoch[27] Batch [1320]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.107539,	
2017-07-31 18:10:16,017 Epoch[27] Batch [1330]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.107579,	
2017-07-31 18:10:20,483 Epoch[27] Batch [1340]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.107662,	
2017-07-31 18:10:24,955 Epoch[27] Batch [1350]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.107713,	
2017-07-31 18:10:29,179 Epoch[27] Batch [1360]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.107683,	
2017-07-31 18:10:33,790 Epoch[27] Batch [1370]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.107746,	
2017-07-31 18:10:38,427 Epoch[27] Batch [1380]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107779,	
2017-07-31 18:10:42,976 Epoch[27] Batch [1390]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.107816,	
2017-07-31 18:10:47,535 Epoch[27] Batch [1400]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.107931,	
2017-07-31 18:10:51,909 Epoch[27] Batch [1410]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.107882,	
2017-07-31 18:10:56,326 Epoch[27] Batch [1420]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.107921,	
2017-07-31 18:11:00,691 Epoch[27] Batch [1430]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.107897,	
2017-07-31 18:11:04,907 Epoch[27] Batch [1440]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.108151,	
2017-07-31 18:11:09,441 Epoch[27] Batch [1450]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108186,	
2017-07-31 18:11:13,948 Epoch[27] Batch [1460]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108198,	
2017-07-31 18:11:18,389 Epoch[27] Batch [1470]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108120,	
2017-07-31 18:11:22,751 Epoch[27] Batch [1480]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.108102,	
2017-07-31 18:11:25,535 Epoch[27] Train-FCNLogLoss=0.108072
2017-07-31 18:11:25,535 Epoch[27] Time cost=664.342
2017-07-31 18:11:26,301 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.params"
2017-07-31 18:11:28,510 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.states"
2017-07-31 18:11:34,081 Epoch[28] Batch [10]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.103961,	
2017-07-31 18:11:38,565 Epoch[28] Batch [20]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.101482,	
2017-07-31 18:11:42,811 Epoch[28] Batch [30]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.099432,	
2017-07-31 18:11:47,215 Epoch[28] Batch [40]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.100548,	
2017-07-31 18:11:51,620 Epoch[28] Batch [50]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.104264,	
2017-07-31 18:11:56,108 Epoch[28] Batch [60]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.107463,	
2017-07-31 18:12:00,653 Epoch[28] Batch [70]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107865,	
2017-07-31 18:12:05,009 Epoch[28] Batch [80]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.109364,	
2017-07-31 18:12:09,587 Epoch[28] Batch [90]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.108594,	
2017-07-31 18:12:14,337 Epoch[28] Batch [100]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.107380,	
2017-07-31 18:12:19,035 Epoch[28] Batch [110]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.107471,	
2017-07-31 18:12:23,824 Epoch[28] Batch [120]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.107412,	
2017-07-31 18:12:28,239 Epoch[28] Batch [130]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.106775,	
2017-07-31 18:12:32,792 Epoch[28] Batch [140]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.107206,	
2017-07-31 18:12:37,369 Epoch[28] Batch [150]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.106167,	
2017-07-31 18:12:42,040 Epoch[28] Batch [160]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.106438,	
2017-07-31 18:12:46,624 Epoch[28] Batch [170]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.106924,	
2017-07-31 18:12:51,324 Epoch[28] Batch [180]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.107446,	
2017-07-31 18:12:55,771 Epoch[28] Batch [190]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.106973,	
2017-07-31 18:13:00,386 Epoch[28] Batch [200]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.106767,	
2017-07-31 18:13:05,121 Epoch[28] Batch [210]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.107093,	
2017-07-31 18:13:09,576 Epoch[28] Batch [220]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.107169,	
2017-07-31 18:13:13,983 Epoch[28] Batch [230]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.106682,	
2017-07-31 18:13:18,517 Epoch[28] Batch [240]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.106638,	
2017-07-31 18:13:22,664 Epoch[28] Batch [250]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.106608,	
2017-07-31 18:13:26,996 Epoch[28] Batch [260]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.106588,	
2017-07-31 18:13:31,607 Epoch[28] Batch [270]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.106310,	
2017-07-31 18:13:36,085 Epoch[28] Batch [280]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.106572,	
2017-07-31 18:13:40,497 Epoch[28] Batch [290]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.106371,	
2017-07-31 18:13:45,217 Epoch[28] Batch [300]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.106335,	
2017-07-31 18:13:50,043 Epoch[28] Batch [310]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.106187,	
2017-07-31 18:13:54,458 Epoch[28] Batch [320]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.106140,	
2017-07-31 18:13:58,899 Epoch[28] Batch [330]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.106232,	
2017-07-31 18:14:03,258 Epoch[28] Batch [340]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.106335,	
2017-07-31 18:14:07,561 Epoch[28] Batch [350]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106080,	
2017-07-31 18:14:12,125 Epoch[28] Batch [360]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.106119,	
2017-07-31 18:14:16,762 Epoch[28] Batch [370]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.106199,	
2017-07-31 18:14:21,683 Epoch[28] Batch [380]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.105923,	
2017-07-31 18:14:26,200 Epoch[28] Batch [390]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.105996,	
2017-07-31 18:14:30,783 Epoch[28] Batch [400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.106160,	
2017-07-31 18:14:35,401 Epoch[28] Batch [410]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.106179,	
2017-07-31 18:14:40,313 Epoch[28] Batch [420]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.106147,	
2017-07-31 18:14:44,789 Epoch[28] Batch [430]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.106013,	
2017-07-31 18:14:49,423 Epoch[28] Batch [440]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.105973,	
2017-07-31 18:14:53,893 Epoch[28] Batch [450]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.105899,	
2017-07-31 18:14:58,453 Epoch[28] Batch [460]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.106109,	
2017-07-31 18:15:02,808 Epoch[28] Batch [470]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.106006,	
2017-07-31 18:15:07,301 Epoch[28] Batch [480]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.106052,	
2017-07-31 18:15:11,626 Epoch[28] Batch [490]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.106166,	
2017-07-31 18:15:15,996 Epoch[28] Batch [500]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.106259,	
2017-07-31 18:15:20,383 Epoch[28] Batch [510]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106086,	
2017-07-31 18:15:24,828 Epoch[28] Batch [520]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.105986,	
2017-07-31 18:15:29,512 Epoch[28] Batch [530]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.106086,	
2017-07-31 18:15:34,236 Epoch[28] Batch [540]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.106153,	
2017-07-31 18:15:38,644 Epoch[28] Batch [550]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.106404,	
2017-07-31 18:15:43,317 Epoch[28] Batch [560]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.106382,	
2017-07-31 18:15:47,890 Epoch[28] Batch [570]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.106399,	
2017-07-31 18:15:52,530 Epoch[28] Batch [580]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.107850,	
2017-07-31 18:15:57,063 Epoch[28] Batch [590]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108096,	
2017-07-31 18:16:01,636 Epoch[28] Batch [600]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.108271,	
2017-07-31 18:16:06,049 Epoch[28] Batch [610]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.108754,	
2017-07-31 18:16:10,391 Epoch[28] Batch [620]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108937,	
2017-07-31 18:16:14,948 Epoch[28] Batch [630]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109012,	
2017-07-31 18:16:19,350 Epoch[28] Batch [640]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.108760,	
2017-07-31 18:16:23,794 Epoch[28] Batch [650]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.108832,	
2017-07-31 18:16:28,280 Epoch[28] Batch [660]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.108831,	
2017-07-31 18:16:32,622 Epoch[28] Batch [670]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108657,	
2017-07-31 18:16:37,167 Epoch[28] Batch [680]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.108667,	
2017-07-31 18:16:41,608 Epoch[28] Batch [690]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108540,	
2017-07-31 18:16:45,982 Epoch[28] Batch [700]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.108499,	
2017-07-31 18:16:50,304 Epoch[28] Batch [710]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.108726,	
2017-07-31 18:16:54,767 Epoch[28] Batch [720]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.108768,	
2017-07-31 18:16:59,139 Epoch[28] Batch [730]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.108886,	
2017-07-31 18:17:03,444 Epoch[28] Batch [740]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.109003,	
2017-07-31 18:17:07,912 Epoch[28] Batch [750]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.109052,	
2017-07-31 18:17:12,454 Epoch[28] Batch [760]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.109019,	
2017-07-31 18:17:17,005 Epoch[28] Batch [770]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.109129,	
2017-07-31 18:17:21,799 Epoch[28] Batch [780]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.109259,	
2017-07-31 18:17:26,323 Epoch[28] Batch [790]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.109191,	
2017-07-31 18:17:31,120 Epoch[28] Batch [800]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.109205,	
2017-07-31 18:17:35,768 Epoch[28] Batch [810]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.109336,	
2017-07-31 18:17:40,398 Epoch[28] Batch [820]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.109284,	
2017-07-31 18:17:44,960 Epoch[28] Batch [830]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109345,	
2017-07-31 18:17:49,489 Epoch[28] Batch [840]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.109396,	
2017-07-31 18:17:53,990 Epoch[28] Batch [850]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.109298,	
2017-07-31 18:17:58,555 Epoch[28] Batch [860]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109338,	
2017-07-31 18:18:03,148 Epoch[28] Batch [870]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.109414,	
2017-07-31 18:18:07,810 Epoch[28] Batch [880]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.109379,	
2017-07-31 18:18:12,543 Epoch[28] Batch [890]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109211,	
2017-07-31 18:18:17,107 Epoch[28] Batch [900]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109137,	
2017-07-31 18:18:21,773 Epoch[28] Batch [910]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.109089,	
2017-07-31 18:18:26,451 Epoch[28] Batch [920]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.109127,	
2017-07-31 18:18:31,127 Epoch[28] Batch [930]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.109126,	
2017-07-31 18:18:35,707 Epoch[28] Batch [940]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.109075,	
2017-07-31 18:18:40,015 Epoch[28] Batch [950]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.109058,	
2017-07-31 18:18:44,503 Epoch[28] Batch [960]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.108959,	
2017-07-31 18:18:49,031 Epoch[28] Batch [970]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.108871,	
2017-07-31 18:18:53,644 Epoch[28] Batch [980]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108781,	
2017-07-31 18:18:58,155 Epoch[28] Batch [990]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.108812,	
2017-07-31 18:19:02,755 Epoch[28] Batch [1000]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108926,	
2017-07-31 18:19:07,237 Epoch[28] Batch [1010]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.109001,	
2017-07-31 18:19:11,857 Epoch[28] Batch [1020]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.109001,	
2017-07-31 18:19:16,510 Epoch[28] Batch [1030]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.108918,	
2017-07-31 18:19:21,064 Epoch[28] Batch [1040]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.108834,	
2017-07-31 18:19:25,546 Epoch[28] Batch [1050]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.108714,	
2017-07-31 18:19:29,986 Epoch[28] Batch [1060]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.108695,	
2017-07-31 18:19:34,448 Epoch[28] Batch [1070]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108671,	
2017-07-31 18:19:38,902 Epoch[28] Batch [1080]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.108674,	
2017-07-31 18:19:43,583 Epoch[28] Batch [1090]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.108631,	
2017-07-31 18:19:47,957 Epoch[28] Batch [1100]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.108648,	
2017-07-31 18:19:52,700 Epoch[28] Batch [1110]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.108891,	
2017-07-31 18:19:57,366 Epoch[28] Batch [1120]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.109256,	
2017-07-31 18:20:01,969 Epoch[28] Batch [1130]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.109400,	
2017-07-31 18:20:06,595 Epoch[28] Batch [1140]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.109643,	
2017-07-31 18:20:11,081 Epoch[28] Batch [1150]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.109784,	
2017-07-31 18:20:15,484 Epoch[28] Batch [1160]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.110066,	
2017-07-31 18:20:20,152 Epoch[28] Batch [1170]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.110176,	
2017-07-31 18:20:24,804 Epoch[28] Batch [1180]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.110191,	
2017-07-31 18:20:29,512 Epoch[28] Batch [1190]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.110275,	
2017-07-31 18:20:33,947 Epoch[28] Batch [1200]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.110294,	
2017-07-31 18:20:38,554 Epoch[28] Batch [1210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110330,	
2017-07-31 18:20:43,109 Epoch[28] Batch [1220]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.110395,	
2017-07-31 18:20:47,692 Epoch[28] Batch [1230]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.110446,	
2017-07-31 18:20:52,381 Epoch[28] Batch [1240]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.110470,	
2017-07-31 18:20:57,274 Epoch[28] Batch [1250]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.110627,	
2017-07-31 18:21:01,808 Epoch[28] Batch [1260]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.110584,	
2017-07-31 18:21:06,224 Epoch[28] Batch [1270]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.110566,	
2017-07-31 18:21:10,850 Epoch[28] Batch [1280]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.110651,	
2017-07-31 18:21:15,392 Epoch[28] Batch [1290]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.110597,	
2017-07-31 18:21:19,970 Epoch[28] Batch [1300]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.110814,	
2017-07-31 18:21:24,303 Epoch[28] Batch [1310]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.111203,	
2017-07-31 18:21:28,962 Epoch[28] Batch [1320]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.111672,	
2017-07-31 18:21:33,168 Epoch[28] Batch [1330]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.111842,	
2017-07-31 18:21:37,724 Epoch[28] Batch [1340]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.112007,	
2017-07-31 18:21:42,198 Epoch[28] Batch [1350]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.112025,	
2017-07-31 18:21:46,505 Epoch[28] Batch [1360]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.112005,	
2017-07-31 18:21:51,028 Epoch[28] Batch [1370]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.112050,	
2017-07-31 18:21:55,861 Epoch[28] Batch [1380]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.112135,	
2017-07-31 18:22:00,177 Epoch[28] Batch [1390]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.112203,	
2017-07-31 18:22:04,946 Epoch[28] Batch [1400]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.112263,	
2017-07-31 18:22:09,642 Epoch[28] Batch [1410]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.112196,	
2017-07-31 18:22:14,375 Epoch[28] Batch [1420]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.112200,	
2017-07-31 18:22:18,847 Epoch[28] Batch [1430]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.112230,	
2017-07-31 18:22:23,509 Epoch[28] Batch [1440]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.112520,	
2017-07-31 18:22:28,263 Epoch[28] Batch [1450]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.112701,	
2017-07-31 18:22:32,957 Epoch[28] Batch [1460]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.112866,	
2017-07-31 18:22:37,488 Epoch[28] Batch [1470]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.112985,	
2017-07-31 18:22:42,089 Epoch[28] Batch [1480]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.113033,	
2017-07-31 18:22:45,030 Epoch[28] Train-FCNLogLoss=0.113035
2017-07-31 18:22:45,031 Epoch[28] Time cost=676.520
2017-07-31 18:22:45,810 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.params"
2017-07-31 18:22:47,558 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.states"
2017-07-31 18:22:52,947 Epoch[29] Batch [10]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.115041,	
2017-07-31 18:22:57,444 Epoch[29] Batch [20]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.112542,	
2017-07-31 18:23:01,614 Epoch[29] Batch [30]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.109863,	
2017-07-31 18:23:06,085 Epoch[29] Batch [40]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.108995,	
2017-07-31 18:23:10,723 Epoch[29] Batch [50]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107505,	
2017-07-31 18:23:15,415 Epoch[29] Batch [60]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.106732,	
2017-07-31 18:23:20,041 Epoch[29] Batch [70]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.108365,	
2017-07-31 18:23:24,604 Epoch[29] Batch [80]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109127,	
2017-07-31 18:23:29,207 Epoch[29] Batch [90]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.110238,	
2017-07-31 18:23:33,901 Epoch[29] Batch [100]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.109706,	
2017-07-31 18:23:38,588 Epoch[29] Batch [110]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109648,	
2017-07-31 18:23:43,101 Epoch[29] Batch [120]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.109122,	
2017-07-31 18:23:47,921 Epoch[29] Batch [130]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.110239,	
2017-07-31 18:23:52,314 Epoch[29] Batch [140]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.110463,	
2017-07-31 18:23:56,742 Epoch[29] Batch [150]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.111465,	
2017-07-31 18:24:01,570 Epoch[29] Batch [160]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.112160,	
2017-07-31 18:24:06,071 Epoch[29] Batch [170]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.112583,	
2017-07-31 18:24:10,600 Epoch[29] Batch [180]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.112097,	
2017-07-31 18:24:15,122 Epoch[29] Batch [190]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.113035,	
2017-07-31 18:24:19,594 Epoch[29] Batch [200]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.112704,	
2017-07-31 18:24:23,960 Epoch[29] Batch [210]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.112529,	
2017-07-31 18:24:28,508 Epoch[29] Batch [220]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.112493,	
2017-07-31 18:24:33,066 Epoch[29] Batch [230]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.112585,	
2017-07-31 18:24:37,765 Epoch[29] Batch [240]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.112435,	
2017-07-31 18:24:42,441 Epoch[29] Batch [250]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.111985,	
2017-07-31 18:24:46,940 Epoch[29] Batch [260]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.111811,	
2017-07-31 18:24:51,427 Epoch[29] Batch [270]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.112062,	
2017-07-31 18:24:56,053 Epoch[29] Batch [280]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.112250,	
2017-07-31 18:25:00,512 Epoch[29] Batch [290]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.112141,	
2017-07-31 18:25:05,150 Epoch[29] Batch [300]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.111792,	
2017-07-31 18:25:09,615 Epoch[29] Batch [310]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.111743,	
2017-07-31 18:25:14,316 Epoch[29] Batch [320]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.111560,	
2017-07-31 18:25:18,963 Epoch[29] Batch [330]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.111284,	
2017-07-31 18:25:23,641 Epoch[29] Batch [340]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.110922,	
2017-07-31 18:25:28,171 Epoch[29] Batch [350]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.110977,	
2017-07-31 18:25:32,707 Epoch[29] Batch [360]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.110758,	
2017-07-31 18:25:37,379 Epoch[29] Batch [370]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.110624,	
2017-07-31 18:25:41,743 Epoch[29] Batch [380]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.110342,	
2017-07-31 18:25:46,123 Epoch[29] Batch [390]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.110219,	
2017-07-31 18:25:50,633 Epoch[29] Batch [400]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.109970,	
2017-07-31 18:25:55,279 Epoch[29] Batch [410]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.109975,	
2017-07-31 18:25:59,927 Epoch[29] Batch [420]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.109866,	
2017-07-31 18:26:04,296 Epoch[29] Batch [430]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.109656,	
2017-07-31 18:26:08,842 Epoch[29] Batch [440]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109819,	
2017-07-31 18:26:13,387 Epoch[29] Batch [450]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109929,	
2017-07-31 18:26:17,902 Epoch[29] Batch [460]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110365,	
2017-07-31 18:26:22,475 Epoch[29] Batch [470]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.110448,	
2017-07-31 18:26:26,881 Epoch[29] Batch [480]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.110354,	
2017-07-31 18:26:31,308 Epoch[29] Batch [490]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.110222,	
2017-07-31 18:26:35,647 Epoch[29] Batch [500]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.110165,	
2017-07-31 18:26:40,245 Epoch[29] Batch [510]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.110006,	
2017-07-31 18:26:44,561 Epoch[29] Batch [520]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.110041,	
2017-07-31 18:26:49,047 Epoch[29] Batch [530]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.109667,	
2017-07-31 18:26:53,530 Epoch[29] Batch [540]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.109535,	
2017-07-31 18:26:58,072 Epoch[29] Batch [550]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.109437,	
2017-07-31 18:27:02,525 Epoch[29] Batch [560]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.109519,	
2017-07-31 18:27:06,805 Epoch[29] Batch [570]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.109504,	
2017-07-31 18:27:11,242 Epoch[29] Batch [580]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.112483,	
2017-07-31 18:27:15,582 Epoch[29] Batch [590]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.113449,	
2017-07-31 18:27:19,895 Epoch[29] Batch [600]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.114375,	
2017-07-31 18:27:24,172 Epoch[29] Batch [610]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.114757,	
2017-07-31 18:27:28,832 Epoch[29] Batch [620]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.115010,	
2017-07-31 18:27:33,376 Epoch[29] Batch [630]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.115205,	
2017-07-31 18:27:38,181 Epoch[29] Batch [640]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.115586,	
2017-07-31 18:27:42,567 Epoch[29] Batch [650]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.116210,	
2017-07-31 18:27:47,230 Epoch[29] Batch [660]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.118107,	
2017-07-31 18:27:52,012 Epoch[29] Batch [670]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.118513,	
2017-07-31 18:27:56,552 Epoch[29] Batch [680]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.118790,	
2017-07-31 18:28:01,229 Epoch[29] Batch [690]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.118898,	
2017-07-31 18:28:05,658 Epoch[29] Batch [700]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.119166,	
2017-07-31 18:28:10,388 Epoch[29] Batch [710]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.119358,	
2017-07-31 18:28:14,945 Epoch[29] Batch [720]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.119654,	
2017-07-31 18:28:19,378 Epoch[29] Batch [730]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.119952,	
2017-07-31 18:28:23,885 Epoch[29] Batch [740]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.119883,	
2017-07-31 18:28:28,364 Epoch[29] Batch [750]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.120049,	
2017-07-31 18:28:32,611 Epoch[29] Batch [760]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.120297,	
2017-07-31 18:28:37,191 Epoch[29] Batch [770]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.120326,	
2017-07-31 18:28:41,729 Epoch[29] Batch [780]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.120556,	
2017-07-31 18:28:46,113 Epoch[29] Batch [790]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.120528,	
2017-07-31 18:28:50,660 Epoch[29] Batch [800]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120465,	
2017-07-31 18:28:55,254 Epoch[29] Batch [810]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.120484,	
2017-07-31 18:28:59,864 Epoch[29] Batch [820]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.120469,	
2017-07-31 18:29:04,303 Epoch[29] Batch [830]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.120355,	
2017-07-31 18:29:09,319 Epoch[29] Batch [840]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.120224,	
2017-07-31 18:29:14,153 Epoch[29] Batch [850]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.120108,	
2017-07-31 18:29:18,731 Epoch[29] Batch [860]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.119951,	
2017-07-31 18:29:23,516 Epoch[29] Batch [870]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.119784,	
2017-07-31 18:29:28,359 Epoch[29] Batch [880]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.119624,	
2017-07-31 18:29:33,131 Epoch[29] Batch [890]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.119564,	
2017-07-31 18:29:37,523 Epoch[29] Batch [900]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.119583,	
2017-07-31 18:29:41,975 Epoch[29] Batch [910]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.119340,	
2017-07-31 18:29:46,385 Epoch[29] Batch [920]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.119273,	
2017-07-31 18:29:50,898 Epoch[29] Batch [930]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.119454,	
2017-07-31 18:29:55,554 Epoch[29] Batch [940]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.119515,	
2017-07-31 18:30:00,098 Epoch[29] Batch [950]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.119298,	
2017-07-31 18:30:04,668 Epoch[29] Batch [960]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.119218,	
2017-07-31 18:30:09,217 Epoch[29] Batch [970]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.119117,	
2017-07-31 18:30:13,647 Epoch[29] Batch [980]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.118976,	
2017-07-31 18:30:18,119 Epoch[29] Batch [990]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.118845,	
2017-07-31 18:30:22,548 Epoch[29] Batch [1000]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.118708,	
2017-07-31 18:30:27,094 Epoch[29] Batch [1010]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.118706,	
2017-07-31 18:30:31,876 Epoch[29] Batch [1020]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.118814,	
2017-07-31 18:30:36,935 Epoch[29] Batch [1030]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.118745,	
2017-07-31 18:30:41,672 Epoch[29] Batch [1040]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.118700,	
2017-07-31 18:30:46,083 Epoch[29] Batch [1050]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.118674,	
2017-07-31 18:30:50,624 Epoch[29] Batch [1060]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.118526,	
2017-07-31 18:30:55,232 Epoch[29] Batch [1070]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.118480,	
2017-07-31 18:30:59,681 Epoch[29] Batch [1080]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.118975,	
2017-07-31 18:31:04,239 Epoch[29] Batch [1090]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.119836,	
2017-07-31 18:31:08,827 Epoch[29] Batch [1100]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.120728,	
2017-07-31 18:31:13,076 Epoch[29] Batch [1110]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.121203,	
2017-07-31 18:31:17,783 Epoch[29] Batch [1120]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.121497,	
2017-07-31 18:31:22,218 Epoch[29] Batch [1130]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.121669,	
2017-07-31 18:31:26,685 Epoch[29] Batch [1140]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.121843,	
2017-07-31 18:31:31,237 Epoch[29] Batch [1150]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.121897,	
2017-07-31 18:31:35,527 Epoch[29] Batch [1160]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.121942,	
2017-07-31 18:31:39,999 Epoch[29] Batch [1170]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.122010,	
2017-07-31 18:31:44,449 Epoch[29] Batch [1180]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.121947,	
2017-07-31 18:31:48,904 Epoch[29] Batch [1190]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.121956,	
2017-07-31 18:31:53,443 Epoch[29] Batch [1200]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.121959,	
2017-07-31 18:31:58,268 Epoch[29] Batch [1210]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.121908,	
2017-07-31 18:32:02,741 Epoch[29] Batch [1220]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.121912,	
2017-07-31 18:32:07,147 Epoch[29] Batch [1230]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.121861,	
2017-07-31 18:32:11,832 Epoch[29] Batch [1240]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121895,	
2017-07-31 18:32:16,524 Epoch[29] Batch [1250]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.121846,	
2017-07-31 18:32:21,208 Epoch[29] Batch [1260]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121683,	
2017-07-31 18:32:25,546 Epoch[29] Batch [1270]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.121564,	
2017-07-31 18:32:30,126 Epoch[29] Batch [1280]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.121395,	
2017-07-31 18:32:34,541 Epoch[29] Batch [1290]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.121498,	
2017-07-31 18:32:39,070 Epoch[29] Batch [1300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.121464,	
2017-07-31 18:32:43,514 Epoch[29] Batch [1310]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.121475,	
2017-07-31 18:32:48,049 Epoch[29] Batch [1320]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.121489,	
2017-07-31 18:32:52,811 Epoch[29] Batch [1330]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.121482,	
2017-07-31 18:32:57,624 Epoch[29] Batch [1340]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.121463,	
2017-07-31 18:33:02,397 Epoch[29] Batch [1350]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.121334,	
2017-07-31 18:33:07,072 Epoch[29] Batch [1360]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121312,	
2017-07-31 18:33:11,758 Epoch[29] Batch [1370]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.121235,	
2017-07-31 18:33:16,279 Epoch[29] Batch [1380]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.121168,	
2017-07-31 18:33:20,748 Epoch[29] Batch [1390]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121087,	
2017-07-31 18:33:25,237 Epoch[29] Batch [1400]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.120985,	
2017-07-31 18:33:29,857 Epoch[29] Batch [1410]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.120810,	
2017-07-31 18:33:34,281 Epoch[29] Batch [1420]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.120701,	
2017-07-31 18:33:38,853 Epoch[29] Batch [1430]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.120591,	
2017-07-31 18:33:43,283 Epoch[29] Batch [1440]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.120569,	
2017-07-31 18:33:47,717 Epoch[29] Batch [1450]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.120529,	
2017-07-31 18:33:52,263 Epoch[29] Batch [1460]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.120444,	
2017-07-31 18:33:56,705 Epoch[29] Batch [1470]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.120326,	
2017-07-31 18:34:01,109 Epoch[29] Batch [1480]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.120244,	
2017-07-31 18:34:03,832 Epoch[29] Train-FCNLogLoss=0.120168
2017-07-31 18:34:03,832 Epoch[29] Time cost=676.274
2017-07-31 18:34:04,711 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.params"
2017-07-31 18:34:07,038 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.states"
2017-07-31 18:34:12,268 Epoch[30] Batch [10]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.106858,	
2017-07-31 18:34:16,824 Epoch[30] Batch [20]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109979,	
2017-07-31 18:34:21,465 Epoch[30] Batch [30]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.110120,	
2017-07-31 18:34:26,149 Epoch[30] Batch [40]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109144,	
2017-07-31 18:34:30,621 Epoch[30] Batch [50]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.112021,	
2017-07-31 18:34:35,355 Epoch[30] Batch [60]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.113983,	
2017-07-31 18:34:40,201 Epoch[30] Batch [70]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.115315,	
2017-07-31 18:34:44,618 Epoch[30] Batch [80]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.114287,	
2017-07-31 18:34:49,184 Epoch[30] Batch [90]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.115051,	
2017-07-31 18:34:53,546 Epoch[30] Batch [100]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.114900,	
2017-07-31 18:34:58,123 Epoch[30] Batch [110]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.114038,	
2017-07-31 18:35:02,686 Epoch[30] Batch [120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.116733,	
2017-07-31 18:35:07,407 Epoch[30] Batch [130]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.117348,	
2017-07-31 18:35:11,713 Epoch[30] Batch [140]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.117800,	
2017-07-31 18:35:16,060 Epoch[30] Batch [150]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.117477,	
2017-07-31 18:35:20,668 Epoch[30] Batch [160]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.117243,	
2017-07-31 18:35:25,180 Epoch[30] Batch [170]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.117068,	
2017-07-31 18:35:29,545 Epoch[30] Batch [180]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.117321,	
2017-07-31 18:35:34,117 Epoch[30] Batch [190]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.116564,	
2017-07-31 18:35:38,727 Epoch[30] Batch [200]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.116300,	
2017-07-31 18:35:43,213 Epoch[30] Batch [210]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.116125,	
2017-07-31 18:35:47,743 Epoch[30] Batch [220]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.115730,	
2017-07-31 18:35:52,312 Epoch[30] Batch [230]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.115390,	
2017-07-31 18:35:56,799 Epoch[30] Batch [240]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.114994,	
2017-07-31 18:36:01,389 Epoch[30] Batch [250]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.114596,	
2017-07-31 18:36:05,888 Epoch[30] Batch [260]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.114327,	
2017-07-31 18:36:10,367 Epoch[30] Batch [270]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.113881,	
2017-07-31 18:36:14,681 Epoch[30] Batch [280]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.113728,	
2017-07-31 18:36:19,165 Epoch[30] Batch [290]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.113633,	
2017-07-31 18:36:23,735 Epoch[30] Batch [300]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.113326,	
2017-07-31 18:36:28,251 Epoch[30] Batch [310]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.113262,	
2017-07-31 18:36:32,959 Epoch[30] Batch [320]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.113263,	
2017-07-31 18:36:37,589 Epoch[30] Batch [330]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.112924,	
2017-07-31 18:36:42,019 Epoch[30] Batch [340]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.112847,	
2017-07-31 18:36:46,298 Epoch[30] Batch [350]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112617,	
2017-07-31 18:36:50,954 Epoch[30] Batch [360]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.112246,	
2017-07-31 18:36:55,527 Epoch[30] Batch [370]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.112219,	
2017-07-31 18:37:00,265 Epoch[30] Batch [380]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.112354,	
2017-07-31 18:37:04,711 Epoch[30] Batch [390]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.112893,	
2017-07-31 18:37:09,269 Epoch[30] Batch [400]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.112684,	
2017-07-31 18:37:13,706 Epoch[30] Batch [410]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.112718,	
2017-07-31 18:37:18,233 Epoch[30] Batch [420]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.112573,	
2017-07-31 18:37:22,881 Epoch[30] Batch [430]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.112729,	
2017-07-31 18:37:27,435 Epoch[30] Batch [440]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.112519,	
2017-07-31 18:37:31,966 Epoch[30] Batch [450]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.112575,	
2017-07-31 18:37:36,374 Epoch[30] Batch [460]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.112210,	
2017-07-31 18:37:40,856 Epoch[30] Batch [470]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.111999,	
2017-07-31 18:37:45,243 Epoch[30] Batch [480]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.111944,	
2017-07-31 18:37:49,780 Epoch[30] Batch [490]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.111887,	
2017-07-31 18:37:54,406 Epoch[30] Batch [500]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.111722,	
2017-07-31 18:37:58,923 Epoch[30] Batch [510]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.111630,	
2017-07-31 18:38:03,360 Epoch[30] Batch [520]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111414,	
2017-07-31 18:38:07,865 Epoch[30] Batch [530]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.111322,	
2017-07-31 18:38:12,436 Epoch[30] Batch [540]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.111736,	
2017-07-31 18:38:17,276 Epoch[30] Batch [550]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.111908,	
2017-07-31 18:38:22,015 Epoch[30] Batch [560]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.112052,	
2017-07-31 18:38:26,696 Epoch[30] Batch [570]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.112193,	
2017-07-31 18:38:31,200 Epoch[30] Batch [580]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.112078,	
2017-07-31 18:38:35,680 Epoch[30] Batch [590]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.111952,	
2017-07-31 18:38:40,133 Epoch[30] Batch [600]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.112040,	
2017-07-31 18:38:44,594 Epoch[30] Batch [610]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111862,	
2017-07-31 18:38:48,917 Epoch[30] Batch [620]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.111805,	
2017-07-31 18:38:53,445 Epoch[30] Batch [630]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.111687,	
2017-07-31 18:38:57,841 Epoch[30] Batch [640]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.111626,	
2017-07-31 18:39:02,403 Epoch[30] Batch [650]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.111513,	
2017-07-31 18:39:06,823 Epoch[30] Batch [660]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.111323,	
2017-07-31 18:39:11,454 Epoch[30] Batch [670]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.111504,	
2017-07-31 18:39:15,957 Epoch[30] Batch [680]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.111478,	
2017-07-31 18:39:20,245 Epoch[30] Batch [690]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.111321,	
2017-07-31 18:39:24,649 Epoch[30] Batch [700]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.111226,	
2017-07-31 18:39:29,043 Epoch[30] Batch [710]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.111176,	
2017-07-31 18:39:33,653 Epoch[30] Batch [720]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110946,	
2017-07-31 18:39:38,153 Epoch[30] Batch [730]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.110955,	
2017-07-31 18:39:42,578 Epoch[30] Batch [740]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.110835,	
2017-07-31 18:39:47,115 Epoch[30] Batch [750]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.110755,	
2017-07-31 18:39:51,833 Epoch[30] Batch [760]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.110661,	
2017-07-31 18:39:56,669 Epoch[30] Batch [770]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.110543,	
2017-07-31 18:40:01,276 Epoch[30] Batch [780]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110468,	
2017-07-31 18:40:05,717 Epoch[30] Batch [790]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.110545,	
2017-07-31 18:40:10,246 Epoch[30] Batch [800]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.110474,	
2017-07-31 18:40:14,628 Epoch[30] Batch [810]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.110492,	
2017-07-31 18:40:19,129 Epoch[30] Batch [820]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.110416,	
2017-07-31 18:40:23,600 Epoch[30] Batch [830]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.110364,	
2017-07-31 18:40:28,202 Epoch[30] Batch [840]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.110480,	
2017-07-31 18:40:32,718 Epoch[30] Batch [850]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110357,	
2017-07-31 18:40:37,501 Epoch[30] Batch [860]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.110216,	
2017-07-31 18:40:42,087 Epoch[30] Batch [870]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.110074,	
2017-07-31 18:40:46,749 Epoch[30] Batch [880]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.110066,	
2017-07-31 18:40:51,358 Epoch[30] Batch [890]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.110123,	
2017-07-31 18:40:56,076 Epoch[30] Batch [900]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.110055,	
2017-07-31 18:41:00,628 Epoch[30] Batch [910]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.109880,	
2017-07-31 18:41:05,225 Epoch[30] Batch [920]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.109908,	
2017-07-31 18:41:09,769 Epoch[30] Batch [930]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109813,	
2017-07-31 18:41:14,190 Epoch[30] Batch [940]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.109755,	
2017-07-31 18:41:18,662 Epoch[30] Batch [950]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.109710,	
2017-07-31 18:41:23,141 Epoch[30] Batch [960]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.109550,	
2017-07-31 18:41:27,357 Epoch[30] Batch [970]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.109509,	
2017-07-31 18:41:32,042 Epoch[30] Batch [980]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109623,	
2017-07-31 18:41:36,628 Epoch[30] Batch [990]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.109570,	
2017-07-31 18:41:41,131 Epoch[30] Batch [1000]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.109447,	
2017-07-31 18:41:45,605 Epoch[30] Batch [1010]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.109443,	
2017-07-31 18:41:49,889 Epoch[30] Batch [1020]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.109428,	
2017-07-31 18:41:54,282 Epoch[30] Batch [1030]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.109393,	
2017-07-31 18:41:58,629 Epoch[30] Batch [1040]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.109369,	
2017-07-31 18:42:03,263 Epoch[30] Batch [1050]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.109431,	
2017-07-31 18:42:07,724 Epoch[30] Batch [1060]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.109368,	
2017-07-31 18:42:12,359 Epoch[30] Batch [1070]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.109283,	
2017-07-31 18:42:17,042 Epoch[30] Batch [1080]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.109251,	
2017-07-31 18:42:21,412 Epoch[30] Batch [1090]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.109162,	
2017-07-31 18:42:26,001 Epoch[30] Batch [1100]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.109251,	
2017-07-31 18:42:30,509 Epoch[30] Batch [1110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.109306,	
2017-07-31 18:42:35,078 Epoch[30] Batch [1120]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109316,	
2017-07-31 18:42:39,598 Epoch[30] Batch [1130]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.109326,	
2017-07-31 18:42:44,113 Epoch[30] Batch [1140]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.109355,	
2017-07-31 18:42:48,818 Epoch[30] Batch [1150]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.109331,	
2017-07-31 18:42:53,425 Epoch[30] Batch [1160]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109245,	
2017-07-31 18:42:57,983 Epoch[30] Batch [1170]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109114,	
2017-07-31 18:43:02,504 Epoch[30] Batch [1180]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.109232,	
2017-07-31 18:43:07,176 Epoch[30] Batch [1190]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.109179,	
2017-07-31 18:43:11,547 Epoch[30] Batch [1200]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.109227,	
2017-07-31 18:43:16,179 Epoch[30] Batch [1210]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.109203,	
2017-07-31 18:43:20,747 Epoch[30] Batch [1220]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.109103,	
2017-07-31 18:43:25,355 Epoch[30] Batch [1230]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109104,	
2017-07-31 18:43:29,890 Epoch[30] Batch [1240]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.109011,	
2017-07-31 18:43:34,528 Epoch[30] Batch [1250]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.108960,	
2017-07-31 18:43:39,091 Epoch[30] Batch [1260]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109057,	
2017-07-31 18:43:43,631 Epoch[30] Batch [1270]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.109228,	
2017-07-31 18:43:48,024 Epoch[30] Batch [1280]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.109186,	
2017-07-31 18:43:52,442 Epoch[30] Batch [1290]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.109212,	
2017-07-31 18:43:56,885 Epoch[30] Batch [1300]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.109274,	
2017-07-31 18:44:01,288 Epoch[30] Batch [1310]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.109260,	
2017-07-31 18:44:05,775 Epoch[30] Batch [1320]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.109263,	
2017-07-31 18:44:10,189 Epoch[30] Batch [1330]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.109223,	
2017-07-31 18:44:14,654 Epoch[30] Batch [1340]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.109219,	
2017-07-31 18:44:19,207 Epoch[30] Batch [1350]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.109180,	
2017-07-31 18:44:23,739 Epoch[30] Batch [1360]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.109233,	
2017-07-31 18:44:28,327 Epoch[30] Batch [1370]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.109211,	
2017-07-31 18:44:32,815 Epoch[30] Batch [1380]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.109108,	
2017-07-31 18:44:37,362 Epoch[30] Batch [1390]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109041,	
2017-07-31 18:44:41,846 Epoch[30] Batch [1400]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.109017,	
2017-07-31 18:44:46,462 Epoch[30] Batch [1410]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.108943,	
2017-07-31 18:44:51,086 Epoch[30] Batch [1420]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.108884,	
2017-07-31 18:44:55,548 Epoch[30] Batch [1430]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.108828,	
2017-07-31 18:45:00,176 Epoch[30] Batch [1440]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.108820,	
2017-07-31 18:45:04,675 Epoch[30] Batch [1450]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.108783,	
2017-07-31 18:45:09,280 Epoch[30] Batch [1460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108636,	
2017-07-31 18:45:13,805 Epoch[30] Batch [1470]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.108605,	
2017-07-31 18:45:18,332 Epoch[30] Batch [1480]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.108584,	
2017-07-31 18:45:21,029 Epoch[30] Train-FCNLogLoss=0.108519
2017-07-31 18:45:21,029 Epoch[30] Time cost=673.990
2017-07-31 18:45:21,836 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.params"
2017-07-31 18:45:23,458 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.states"
2017-07-31 18:45:28,688 Epoch[31] Batch [10]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.114368,	
2017-07-31 18:45:33,100 Epoch[31] Batch [20]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.107153,	
2017-07-31 18:45:37,537 Epoch[31] Batch [30]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.103729,	
2017-07-31 18:45:42,079 Epoch[31] Batch [40]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.105087,	
2017-07-31 18:45:46,733 Epoch[31] Batch [50]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.108429,	
2017-07-31 18:45:51,362 Epoch[31] Batch [60]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.109555,	
2017-07-31 18:45:56,165 Epoch[31] Batch [70]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.109970,	
2017-07-31 18:46:00,899 Epoch[31] Batch [80]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109158,	
2017-07-31 18:46:05,793 Epoch[31] Batch [90]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.109184,	
2017-07-31 18:46:10,402 Epoch[31] Batch [100]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.107909,	
2017-07-31 18:46:14,961 Epoch[31] Batch [110]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.106746,	
2017-07-31 18:46:19,794 Epoch[31] Batch [120]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.106897,	
2017-07-31 18:46:24,518 Epoch[31] Batch [130]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.106951,	
2017-07-31 18:46:28,837 Epoch[31] Batch [140]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.106757,	
2017-07-31 18:46:33,547 Epoch[31] Batch [150]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.107007,	
2017-07-31 18:46:38,173 Epoch[31] Batch [160]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.107050,	
2017-07-31 18:46:42,774 Epoch[31] Batch [170]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107082,	
2017-07-31 18:46:47,287 Epoch[31] Batch [180]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.107279,	
2017-07-31 18:46:51,696 Epoch[31] Batch [190]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.107519,	
2017-07-31 18:46:56,194 Epoch[31] Batch [200]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.107276,	
2017-07-31 18:47:00,785 Epoch[31] Batch [210]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.107329,	
2017-07-31 18:47:05,137 Epoch[31] Batch [220]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.107650,	
2017-07-31 18:47:09,576 Epoch[31] Batch [230]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.107817,	
2017-07-31 18:47:14,126 Epoch[31] Batch [240]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.108092,	
2017-07-31 18:47:18,585 Epoch[31] Batch [250]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.107465,	
2017-07-31 18:47:23,127 Epoch[31] Batch [260]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.107282,	
2017-07-31 18:47:27,491 Epoch[31] Batch [270]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.107174,	
2017-07-31 18:47:32,127 Epoch[31] Batch [280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107269,	
2017-07-31 18:47:36,735 Epoch[31] Batch [290]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.106983,	
2017-07-31 18:47:41,437 Epoch[31] Batch [300]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.106719,	
2017-07-31 18:47:45,947 Epoch[31] Batch [310]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.106519,	
2017-07-31 18:47:50,528 Epoch[31] Batch [320]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.106744,	
2017-07-31 18:47:54,998 Epoch[31] Batch [330]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.106644,	
2017-07-31 18:47:59,709 Epoch[31] Batch [340]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.106769,	
2017-07-31 18:48:04,320 Epoch[31] Batch [350]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.106916,	
2017-07-31 18:48:08,643 Epoch[31] Batch [360]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.107044,	
2017-07-31 18:48:13,228 Epoch[31] Batch [370]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.106730,	
2017-07-31 18:48:17,684 Epoch[31] Batch [380]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.106837,	
2017-07-31 18:48:22,166 Epoch[31] Batch [390]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106822,	
2017-07-31 18:48:26,627 Epoch[31] Batch [400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.106514,	
2017-07-31 18:48:31,075 Epoch[31] Batch [410]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.106310,	
2017-07-31 18:48:35,536 Epoch[31] Batch [420]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.106118,	
2017-07-31 18:48:40,086 Epoch[31] Batch [430]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.106161,	
2017-07-31 18:48:44,668 Epoch[31] Batch [440]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.105805,	
2017-07-31 18:48:48,987 Epoch[31] Batch [450]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.105749,	
2017-07-31 18:48:53,499 Epoch[31] Batch [460]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.105560,	
2017-07-31 18:48:57,950 Epoch[31] Batch [470]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.105463,	
2017-07-31 18:49:02,324 Epoch[31] Batch [480]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.105398,	
2017-07-31 18:49:06,750 Epoch[31] Batch [490]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.105384,	
2017-07-31 18:49:11,212 Epoch[31] Batch [500]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.105204,	
2017-07-31 18:49:15,578 Epoch[31] Batch [510]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.105209,	
2017-07-31 18:49:19,741 Epoch[31] Batch [520]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.105368,	
2017-07-31 18:49:24,177 Epoch[31] Batch [530]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.105419,	
2017-07-31 18:49:28,752 Epoch[31] Batch [540]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.105652,	
2017-07-31 18:49:33,153 Epoch[31] Batch [550]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.105652,	
2017-07-31 18:49:37,510 Epoch[31] Batch [560]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.105550,	
2017-07-31 18:49:41,807 Epoch[31] Batch [570]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105490,	
2017-07-31 18:49:46,154 Epoch[31] Batch [580]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.105361,	
2017-07-31 18:49:50,558 Epoch[31] Batch [590]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.105435,	
2017-07-31 18:49:55,046 Epoch[31] Batch [600]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.105369,	
2017-07-31 18:49:59,408 Epoch[31] Batch [610]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.105836,	
2017-07-31 18:50:03,949 Epoch[31] Batch [620]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.105878,	
2017-07-31 18:50:08,312 Epoch[31] Batch [630]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.106081,	
2017-07-31 18:50:12,938 Epoch[31] Batch [640]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.106474,	
2017-07-31 18:50:17,387 Epoch[31] Batch [650]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.106619,	
2017-07-31 18:50:21,672 Epoch[31] Batch [660]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.106545,	
2017-07-31 18:50:26,135 Epoch[31] Batch [670]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.106699,	
2017-07-31 18:50:30,777 Epoch[31] Batch [680]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.106822,	
2017-07-31 18:50:35,187 Epoch[31] Batch [690]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.106883,	
2017-07-31 18:50:39,877 Epoch[31] Batch [700]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.107189,	
2017-07-31 18:50:44,416 Epoch[31] Batch [710]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.107280,	
2017-07-31 18:50:48,874 Epoch[31] Batch [720]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.107325,	
2017-07-31 18:50:53,320 Epoch[31] Batch [730]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.107426,	
2017-07-31 18:50:57,674 Epoch[31] Batch [740]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.107466,	
2017-07-31 18:51:02,134 Epoch[31] Batch [750]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.107404,	
2017-07-31 18:51:06,726 Epoch[31] Batch [760]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.107392,	
2017-07-31 18:51:11,318 Epoch[31] Batch [770]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.107458,	
2017-07-31 18:51:15,739 Epoch[31] Batch [780]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.107386,	
2017-07-31 18:51:20,504 Epoch[31] Batch [790]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.107314,	
2017-07-31 18:51:25,320 Epoch[31] Batch [800]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.107116,	
2017-07-31 18:51:30,079 Epoch[31] Batch [810]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.106960,	
2017-07-31 18:51:34,636 Epoch[31] Batch [820]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.106993,	
2017-07-31 18:51:39,114 Epoch[31] Batch [830]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.106972,	
2017-07-31 18:51:43,699 Epoch[31] Batch [840]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.106974,	
2017-07-31 18:51:48,380 Epoch[31] Batch [850]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.106891,	
2017-07-31 18:51:52,867 Epoch[31] Batch [860]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106933,	
2017-07-31 18:51:57,457 Epoch[31] Batch [870]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.106967,	
2017-07-31 18:52:02,038 Epoch[31] Batch [880]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.107077,	
2017-07-31 18:52:06,773 Epoch[31] Batch [890]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.106962,	
2017-07-31 18:52:11,260 Epoch[31] Batch [900]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106948,	
2017-07-31 18:52:16,114 Epoch[31] Batch [910]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.106867,	
2017-07-31 18:52:20,729 Epoch[31] Batch [920]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.106773,	
2017-07-31 18:52:25,210 Epoch[31] Batch [930]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.106767,	
2017-07-31 18:52:29,713 Epoch[31] Batch [940]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.106838,	
2017-07-31 18:52:34,195 Epoch[31] Batch [950]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.107061,	
2017-07-31 18:52:38,513 Epoch[31] Batch [960]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.107002,	
2017-07-31 18:52:42,825 Epoch[31] Batch [970]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.106993,	
2017-07-31 18:52:47,316 Epoch[31] Batch [980]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.106991,	
2017-07-31 18:52:51,761 Epoch[31] Batch [990]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.107050,	
2017-07-31 18:52:56,272 Epoch[31] Batch [1000]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.107021,	
2017-07-31 18:53:00,627 Epoch[31] Batch [1010]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.106913,	
2017-07-31 18:53:05,294 Epoch[31] Batch [1020]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.106849,	
2017-07-31 18:53:09,965 Epoch[31] Batch [1030]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.106834,	
2017-07-31 18:53:14,461 Epoch[31] Batch [1040]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.106861,	
2017-07-31 18:53:19,134 Epoch[31] Batch [1050]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.106959,	
2017-07-31 18:53:23,770 Epoch[31] Batch [1060]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.106942,	
2017-07-31 18:53:28,501 Epoch[31] Batch [1070]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.106935,	
2017-07-31 18:53:32,880 Epoch[31] Batch [1080]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.106835,	
2017-07-31 18:53:37,368 Epoch[31] Batch [1090]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.106909,	
2017-07-31 18:53:42,027 Epoch[31] Batch [1100]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.106889,	
2017-07-31 18:53:46,620 Epoch[31] Batch [1110]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.106785,	
2017-07-31 18:53:51,483 Epoch[31] Batch [1120]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.106711,	
2017-07-31 18:53:55,979 Epoch[31] Batch [1130]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.106598,	
2017-07-31 18:54:00,270 Epoch[31] Batch [1140]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.106539,	
2017-07-31 18:54:04,691 Epoch[31] Batch [1150]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.106486,	
2017-07-31 18:54:09,111 Epoch[31] Batch [1160]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.106462,	
2017-07-31 18:54:13,637 Epoch[31] Batch [1170]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.106440,	
2017-07-31 18:54:18,244 Epoch[31] Batch [1180]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.106334,	
2017-07-31 18:54:22,782 Epoch[31] Batch [1190]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.106328,	
2017-07-31 18:54:27,409 Epoch[31] Batch [1200]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.106284,	
2017-07-31 18:54:31,997 Epoch[31] Batch [1210]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.106231,	
2017-07-31 18:54:36,878 Epoch[31] Batch [1220]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.106270,	
2017-07-31 18:54:41,403 Epoch[31] Batch [1230]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.106291,	
2017-07-31 18:54:46,027 Epoch[31] Batch [1240]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.106304,	
2017-07-31 18:54:50,666 Epoch[31] Batch [1250]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.106264,	
2017-07-31 18:54:55,287 Epoch[31] Batch [1260]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.106267,	
2017-07-31 18:54:59,761 Epoch[31] Batch [1270]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.106295,	
2017-07-31 18:55:04,272 Epoch[31] Batch [1280]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.106264,	
2017-07-31 18:55:08,962 Epoch[31] Batch [1290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.106183,	
2017-07-31 18:55:13,706 Epoch[31] Batch [1300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.106097,	
2017-07-31 18:55:18,184 Epoch[31] Batch [1310]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.106104,	
2017-07-31 18:55:22,680 Epoch[31] Batch [1320]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.106115,	
2017-07-31 18:55:27,067 Epoch[31] Batch [1330]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106083,	
2017-07-31 18:55:31,354 Epoch[31] Batch [1340]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.106102,	
2017-07-31 18:55:35,789 Epoch[31] Batch [1350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.106075,	
2017-07-31 18:55:40,000 Epoch[31] Batch [1360]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.106024,	
2017-07-31 18:55:44,772 Epoch[31] Batch [1370]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.106026,	
2017-07-31 18:55:49,250 Epoch[31] Batch [1380]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.106052,	
2017-07-31 18:55:53,813 Epoch[31] Batch [1390]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.105998,	
2017-07-31 18:55:58,478 Epoch[31] Batch [1400]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.106055,	
2017-07-31 18:56:03,235 Epoch[31] Batch [1410]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.106038,	
2017-07-31 18:56:07,878 Epoch[31] Batch [1420]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.105986,	
2017-07-31 18:56:12,541 Epoch[31] Batch [1430]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.105971,	
2017-07-31 18:56:17,025 Epoch[31] Batch [1440]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106036,	
2017-07-31 18:56:21,621 Epoch[31] Batch [1450]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.106030,	
2017-07-31 18:56:25,991 Epoch[31] Batch [1460]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.106050,	
2017-07-31 18:56:30,616 Epoch[31] Batch [1470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.106027,	
2017-07-31 18:56:35,221 Epoch[31] Batch [1480]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.106033,	
2017-07-31 18:56:37,976 Epoch[31] Train-FCNLogLoss=0.106037
2017-07-31 18:56:37,977 Epoch[31] Time cost=674.519
2017-07-31 18:56:38,711 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.params"
2017-07-31 18:56:40,395 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.states"
2017-07-31 18:56:45,713 Epoch[32] Batch [10]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.105240,	
2017-07-31 18:56:50,251 Epoch[32] Batch [20]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.105590,	
2017-07-31 18:56:55,148 Epoch[32] Batch [30]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.099535,	
2017-07-31 18:56:59,819 Epoch[32] Batch [40]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.099088,	
2017-07-31 18:57:04,449 Epoch[32] Batch [50]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.099468,	
2017-07-31 18:57:09,020 Epoch[32] Batch [60]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.103703,	
2017-07-31 18:57:13,424 Epoch[32] Batch [70]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.103569,	
2017-07-31 18:57:17,864 Epoch[32] Batch [80]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.104130,	
2017-07-31 18:57:22,508 Epoch[32] Batch [90]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.103932,	
2017-07-31 18:57:26,942 Epoch[32] Batch [100]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.103742,	
2017-07-31 18:57:31,208 Epoch[32] Batch [110]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.104531,	
2017-07-31 18:57:35,763 Epoch[32] Batch [120]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.103375,	
2017-07-31 18:57:40,210 Epoch[32] Batch [130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.104198,	
2017-07-31 18:57:44,686 Epoch[32] Batch [140]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.104303,	
2017-07-31 18:57:49,119 Epoch[32] Batch [150]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104331,	
2017-07-31 18:57:53,418 Epoch[32] Batch [160]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.104503,	
2017-07-31 18:57:57,906 Epoch[32] Batch [170]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104211,	
2017-07-31 18:58:02,372 Epoch[32] Batch [180]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.104524,	
2017-07-31 18:58:06,894 Epoch[32] Batch [190]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.104579,	
2017-07-31 18:58:11,635 Epoch[32] Batch [200]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.104635,	
2017-07-31 18:58:16,104 Epoch[32] Batch [210]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.104197,	
2017-07-31 18:58:20,845 Epoch[32] Batch [220]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.103940,	
2017-07-31 18:58:25,571 Epoch[32] Batch [230]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.103674,	
2017-07-31 18:58:29,962 Epoch[32] Batch [240]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.103524,	
2017-07-31 18:58:34,598 Epoch[32] Batch [250]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.104029,	
2017-07-31 18:58:38,777 Epoch[32] Batch [260]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103694,	
2017-07-31 18:58:43,158 Epoch[32] Batch [270]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.104028,	
2017-07-31 18:58:47,594 Epoch[32] Batch [280]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104291,	
2017-07-31 18:58:52,083 Epoch[32] Batch [290]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104285,	
2017-07-31 18:58:56,494 Epoch[32] Batch [300]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.104370,	
2017-07-31 18:59:01,115 Epoch[32] Batch [310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.104022,	
2017-07-31 18:59:05,707 Epoch[32] Batch [320]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.103996,	
2017-07-31 18:59:10,204 Epoch[32] Batch [330]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.103649,	
2017-07-31 18:59:15,099 Epoch[32] Batch [340]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.103935,	
2017-07-31 18:59:19,656 Epoch[32] Batch [350]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.104230,	
2017-07-31 18:59:24,175 Epoch[32] Batch [360]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.104653,	
2017-07-31 18:59:28,740 Epoch[32] Batch [370]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.104707,	
2017-07-31 18:59:33,220 Epoch[32] Batch [380]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.104323,	
2017-07-31 18:59:37,750 Epoch[32] Batch [390]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.104645,	
2017-07-31 18:59:42,186 Epoch[32] Batch [400]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104691,	
2017-07-31 18:59:46,447 Epoch[32] Batch [410]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.104668,	
2017-07-31 18:59:50,751 Epoch[32] Batch [420]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.104697,	
2017-07-31 18:59:55,110 Epoch[32] Batch [430]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104373,	
2017-07-31 18:59:59,627 Epoch[32] Batch [440]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.104625,	
2017-07-31 19:00:04,158 Epoch[32] Batch [450]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.104528,	
2017-07-31 19:00:08,613 Epoch[32] Batch [460]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.104730,	
2017-07-31 19:00:13,099 Epoch[32] Batch [470]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.104704,	
2017-07-31 19:00:17,676 Epoch[32] Batch [480]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.104759,	
2017-07-31 19:00:22,111 Epoch[32] Batch [490]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104672,	
2017-07-31 19:00:26,531 Epoch[32] Batch [500]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.104641,	
2017-07-31 19:00:31,022 Epoch[32] Batch [510]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104503,	
2017-07-31 19:00:35,616 Epoch[32] Batch [520]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.104181,	
2017-07-31 19:00:40,326 Epoch[32] Batch [530]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.104044,	
2017-07-31 19:00:45,070 Epoch[32] Batch [540]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.103947,	
2017-07-31 19:00:49,726 Epoch[32] Batch [550]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.103898,	
2017-07-31 19:00:54,261 Epoch[32] Batch [560]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.103934,	
2017-07-31 19:00:58,618 Epoch[32] Batch [570]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104073,	
2017-07-31 19:01:03,089 Epoch[32] Batch [580]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.103945,	
2017-07-31 19:01:07,579 Epoch[32] Batch [590]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.103968,	
2017-07-31 19:01:12,307 Epoch[32] Batch [600]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.103999,	
2017-07-31 19:01:17,037 Epoch[32] Batch [610]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.103800,	
2017-07-31 19:01:21,830 Epoch[32] Batch [620]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.103736,	
2017-07-31 19:01:26,612 Epoch[32] Batch [630]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.103852,	
2017-07-31 19:01:31,304 Epoch[32] Batch [640]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.103847,	
2017-07-31 19:01:36,174 Epoch[32] Batch [650]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.103784,	
2017-07-31 19:01:40,395 Epoch[32] Batch [660]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.103712,	
2017-07-31 19:01:44,860 Epoch[32] Batch [670]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.103730,	
2017-07-31 19:01:49,577 Epoch[32] Batch [680]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.103615,	
2017-07-31 19:01:53,946 Epoch[32] Batch [690]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.103529,	
2017-07-31 19:01:58,351 Epoch[32] Batch [700]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.103543,	
2017-07-31 19:02:02,828 Epoch[32] Batch [710]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.103362,	
2017-07-31 19:02:07,231 Epoch[32] Batch [720]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.103294,	
2017-07-31 19:02:11,722 Epoch[32] Batch [730]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.103304,	
2017-07-31 19:02:16,081 Epoch[32] Batch [740]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.103260,	
2017-07-31 19:02:20,510 Epoch[32] Batch [750]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.103249,	
2017-07-31 19:02:24,839 Epoch[32] Batch [760]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.103473,	
2017-07-31 19:02:29,329 Epoch[32] Batch [770]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.103566,	
2017-07-31 19:02:34,149 Epoch[32] Batch [780]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.103575,	
2017-07-31 19:02:38,862 Epoch[32] Batch [790]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.103726,	
2017-07-31 19:02:43,215 Epoch[32] Batch [800]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.103793,	
2017-07-31 19:02:47,867 Epoch[32] Batch [810]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.103748,	
2017-07-31 19:02:52,485 Epoch[32] Batch [820]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.103711,	
2017-07-31 19:02:57,277 Epoch[32] Batch [830]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.103527,	
2017-07-31 19:03:01,563 Epoch[32] Batch [840]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.103586,	
2017-07-31 19:03:06,154 Epoch[32] Batch [850]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.103536,	
2017-07-31 19:03:10,442 Epoch[32] Batch [860]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.103718,	
2017-07-31 19:03:14,916 Epoch[32] Batch [870]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.103765,	
2017-07-31 19:03:19,724 Epoch[32] Batch [880]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.103634,	
2017-07-31 19:03:24,267 Epoch[32] Batch [890]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.103619,	
2017-07-31 19:03:28,963 Epoch[32] Batch [900]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.103827,	
2017-07-31 19:03:33,601 Epoch[32] Batch [910]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.103657,	
2017-07-31 19:03:38,380 Epoch[32] Batch [920]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.103507,	
2017-07-31 19:03:42,847 Epoch[32] Batch [930]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.103645,	
2017-07-31 19:03:47,145 Epoch[32] Batch [940]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.103749,	
2017-07-31 19:03:51,672 Epoch[32] Batch [950]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.103754,	
2017-07-31 19:03:56,148 Epoch[32] Batch [960]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.103763,	
2017-07-31 19:04:00,771 Epoch[32] Batch [970]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.103781,	
2017-07-31 19:04:05,292 Epoch[32] Batch [980]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.103829,	
2017-07-31 19:04:09,598 Epoch[32] Batch [990]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.103866,	
2017-07-31 19:04:14,039 Epoch[32] Batch [1000]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.103923,	
2017-07-31 19:04:18,400 Epoch[32] Batch [1010]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.103926,	
2017-07-31 19:04:22,849 Epoch[32] Batch [1020]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.103952,	
2017-07-31 19:04:27,401 Epoch[32] Batch [1030]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.103957,	
2017-07-31 19:04:31,752 Epoch[32] Batch [1040]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.104043,	
2017-07-31 19:04:36,306 Epoch[32] Batch [1050]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104017,	
2017-07-31 19:04:41,094 Epoch[32] Batch [1060]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.104053,	
2017-07-31 19:04:45,430 Epoch[32] Batch [1070]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.104001,	
2017-07-31 19:04:50,121 Epoch[32] Batch [1080]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.103970,	
2017-07-31 19:04:54,613 Epoch[32] Batch [1090]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104073,	
2017-07-31 19:04:58,948 Epoch[32] Batch [1100]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.104211,	
2017-07-31 19:05:03,583 Epoch[32] Batch [1110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.104416,	
2017-07-31 19:05:08,078 Epoch[32] Batch [1120]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.104567,	
2017-07-31 19:05:12,607 Epoch[32] Batch [1130]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.104600,	
2017-07-31 19:05:17,080 Epoch[32] Batch [1140]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.104642,	
2017-07-31 19:05:21,599 Epoch[32] Batch [1150]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.104624,	
2017-07-31 19:05:26,042 Epoch[32] Batch [1160]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.104588,	
2017-07-31 19:05:30,356 Epoch[32] Batch [1170]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.104660,	
2017-07-31 19:05:34,727 Epoch[32] Batch [1180]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.104696,	
2017-07-31 19:05:39,328 Epoch[32] Batch [1190]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.104689,	
2017-07-31 19:05:44,237 Epoch[32] Batch [1200]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.104696,	
2017-07-31 19:05:48,784 Epoch[32] Batch [1210]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.104649,	
2017-07-31 19:05:53,223 Epoch[32] Batch [1220]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.104626,	
2017-07-31 19:05:57,848 Epoch[32] Batch [1230]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.104582,	
2017-07-31 19:06:02,311 Epoch[32] Batch [1240]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.104532,	
2017-07-31 19:06:06,872 Epoch[32] Batch [1250]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.104500,	
2017-07-31 19:06:11,239 Epoch[32] Batch [1260]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.104481,	
2017-07-31 19:06:15,633 Epoch[32] Batch [1270]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.104430,	
2017-07-31 19:06:20,091 Epoch[32] Batch [1280]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.104384,	
2017-07-31 19:06:24,437 Epoch[32] Batch [1290]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.104413,	
2017-07-31 19:06:28,826 Epoch[32] Batch [1300]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.104332,	
2017-07-31 19:06:33,228 Epoch[32] Batch [1310]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.104355,	
2017-07-31 19:06:37,739 Epoch[32] Batch [1320]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.104327,	
2017-07-31 19:06:42,047 Epoch[32] Batch [1330]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.104412,	
2017-07-31 19:06:46,694 Epoch[32] Batch [1340]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.104370,	
2017-07-31 19:06:51,181 Epoch[32] Batch [1350]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104437,	
2017-07-31 19:06:55,570 Epoch[32] Batch [1360]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.104427,	
2017-07-31 19:07:00,159 Epoch[32] Batch [1370]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.104384,	
2017-07-31 19:07:04,598 Epoch[32] Batch [1380]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.104307,	
2017-07-31 19:07:09,149 Epoch[32] Batch [1390]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104406,	
2017-07-31 19:07:13,745 Epoch[32] Batch [1400]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.104470,	
2017-07-31 19:07:18,132 Epoch[32] Batch [1410]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.104374,	
2017-07-31 19:07:22,757 Epoch[32] Batch [1420]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.104313,	
2017-07-31 19:07:27,273 Epoch[32] Batch [1430]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.104351,	
2017-07-31 19:07:31,940 Epoch[32] Batch [1440]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.104296,	
2017-07-31 19:07:36,216 Epoch[32] Batch [1450]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.104389,	
2017-07-31 19:07:40,737 Epoch[32] Batch [1460]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.104487,	
2017-07-31 19:07:45,098 Epoch[32] Batch [1470]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.104603,	
2017-07-31 19:07:49,487 Epoch[32] Batch [1480]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.104568,	
2017-07-31 19:07:52,188 Epoch[32] Train-FCNLogLoss=0.104642
2017-07-31 19:07:52,188 Epoch[32] Time cost=671.793
2017-07-31 19:07:53,000 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.params"
2017-07-31 19:07:55,458 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.states"
2017-07-31 19:08:00,604 Epoch[33] Batch [10]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.101063,	
2017-07-31 19:08:05,268 Epoch[33] Batch [20]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.100350,	
2017-07-31 19:08:09,797 Epoch[33] Batch [30]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.095976,	
2017-07-31 19:08:14,209 Epoch[33] Batch [40]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.100976,	
2017-07-31 19:08:18,685 Epoch[33] Batch [50]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102370,	
2017-07-31 19:08:23,072 Epoch[33] Batch [60]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.103124,	
2017-07-31 19:08:27,695 Epoch[33] Batch [70]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.103293,	
2017-07-31 19:08:32,290 Epoch[33] Batch [80]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.102487,	
2017-07-31 19:08:36,768 Epoch[33] Batch [90]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.103147,	
2017-07-31 19:08:41,259 Epoch[33] Batch [100]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.105069,	
2017-07-31 19:08:45,834 Epoch[33] Batch [110]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.107004,	
2017-07-31 19:08:50,612 Epoch[33] Batch [120]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.106364,	
2017-07-31 19:08:55,098 Epoch[33] Batch [130]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.107161,	
2017-07-31 19:08:59,346 Epoch[33] Batch [140]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.107035,	
2017-07-31 19:09:03,780 Epoch[33] Batch [150]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.107691,	
2017-07-31 19:09:08,248 Epoch[33] Batch [160]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.108401,	
2017-07-31 19:09:12,736 Epoch[33] Batch [170]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.108177,	
2017-07-31 19:09:17,335 Epoch[33] Batch [180]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107404,	
2017-07-31 19:09:22,008 Epoch[33] Batch [190]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.106884,	
2017-07-31 19:09:26,395 Epoch[33] Batch [200]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106747,	
2017-07-31 19:09:30,977 Epoch[33] Batch [210]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.106805,	
2017-07-31 19:09:35,571 Epoch[33] Batch [220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.107047,	
2017-07-31 19:09:40,303 Epoch[33] Batch [230]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.106992,	
2017-07-31 19:09:44,883 Epoch[33] Batch [240]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.106524,	
2017-07-31 19:09:49,504 Epoch[33] Batch [250]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.106463,	
2017-07-31 19:09:54,229 Epoch[33] Batch [260]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.106501,	
2017-07-31 19:09:58,942 Epoch[33] Batch [270]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.105922,	
2017-07-31 19:10:03,635 Epoch[33] Batch [280]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.105955,	
2017-07-31 19:10:08,065 Epoch[33] Batch [290]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.105996,	
2017-07-31 19:10:12,651 Epoch[33] Batch [300]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.106051,	
2017-07-31 19:10:17,327 Epoch[33] Batch [310]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.105960,	
2017-07-31 19:10:21,943 Epoch[33] Batch [320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.105847,	
2017-07-31 19:10:26,552 Epoch[33] Batch [330]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.105556,	
2017-07-31 19:10:30,929 Epoch[33] Batch [340]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.105669,	
2017-07-31 19:10:35,398 Epoch[33] Batch [350]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.106499,	
2017-07-31 19:10:39,921 Epoch[33] Batch [360]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107097,	
2017-07-31 19:10:44,377 Epoch[33] Batch [370]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.107142,	
2017-07-31 19:10:48,770 Epoch[33] Batch [380]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.106989,	
2017-07-31 19:10:53,440 Epoch[33] Batch [390]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.107083,	
2017-07-31 19:10:57,586 Epoch[33] Batch [400]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.107015,	
2017-07-31 19:11:02,125 Epoch[33] Batch [410]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.106945,	
2017-07-31 19:11:06,614 Epoch[33] Batch [420]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.106785,	
2017-07-31 19:11:11,110 Epoch[33] Batch [430]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.106902,	
2017-07-31 19:11:15,656 Epoch[33] Batch [440]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.106848,	
2017-07-31 19:11:20,249 Epoch[33] Batch [450]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.106683,	
2017-07-31 19:11:24,763 Epoch[33] Batch [460]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106966,	
2017-07-31 19:11:29,380 Epoch[33] Batch [470]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.106827,	
2017-07-31 19:11:34,061 Epoch[33] Batch [480]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.106606,	
2017-07-31 19:11:38,498 Epoch[33] Batch [490]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.106618,	
2017-07-31 19:11:43,158 Epoch[33] Batch [500]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.106400,	
2017-07-31 19:11:47,769 Epoch[33] Batch [510]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.106200,	
2017-07-31 19:11:52,321 Epoch[33] Batch [520]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.106085,	
2017-07-31 19:11:56,899 Epoch[33] Batch [530]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.105838,	
2017-07-31 19:12:01,720 Epoch[33] Batch [540]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.105531,	
2017-07-31 19:12:06,197 Epoch[33] Batch [550]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.105585,	
2017-07-31 19:12:10,951 Epoch[33] Batch [560]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.105478,	
2017-07-31 19:12:15,435 Epoch[33] Batch [570]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.105444,	
2017-07-31 19:12:19,941 Epoch[33] Batch [580]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.105561,	
2017-07-31 19:12:24,411 Epoch[33] Batch [590]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.105512,	
2017-07-31 19:12:28,963 Epoch[33] Batch [600]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.105380,	
2017-07-31 19:12:33,483 Epoch[33] Batch [610]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.105280,	
2017-07-31 19:12:37,859 Epoch[33] Batch [620]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.105096,	
2017-07-31 19:12:42,638 Epoch[33] Batch [630]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.104940,	
2017-07-31 19:12:47,167 Epoch[33] Batch [640]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.104937,	
2017-07-31 19:12:51,855 Epoch[33] Batch [650]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.104747,	
2017-07-31 19:12:56,730 Epoch[33] Batch [660]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.104683,	
2017-07-31 19:13:01,495 Epoch[33] Batch [670]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.104732,	
2017-07-31 19:13:06,114 Epoch[33] Batch [680]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.104794,	
2017-07-31 19:13:10,451 Epoch[33] Batch [690]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.104790,	
2017-07-31 19:13:14,926 Epoch[33] Batch [700]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.104818,	
2017-07-31 19:13:19,482 Epoch[33] Batch [710]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.104693,	
2017-07-31 19:13:24,083 Epoch[33] Batch [720]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.104681,	
2017-07-31 19:13:28,446 Epoch[33] Batch [730]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.104541,	
2017-07-31 19:13:32,804 Epoch[33] Batch [740]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104535,	
2017-07-31 19:13:37,240 Epoch[33] Batch [750]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104527,	
2017-07-31 19:13:41,805 Epoch[33] Batch [760]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.104670,	
2017-07-31 19:13:46,167 Epoch[33] Batch [770]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.104749,	
2017-07-31 19:13:50,742 Epoch[33] Batch [780]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.104673,	
2017-07-31 19:13:55,277 Epoch[33] Batch [790]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.104825,	
2017-07-31 19:13:59,743 Epoch[33] Batch [800]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.104802,	
2017-07-31 19:14:04,314 Epoch[33] Batch [810]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.104888,	
2017-07-31 19:14:08,918 Epoch[33] Batch [820]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.104888,	
2017-07-31 19:14:13,515 Epoch[33] Batch [830]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.104827,	
2017-07-31 19:14:18,062 Epoch[33] Batch [840]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.104776,	
2017-07-31 19:14:22,763 Epoch[33] Batch [850]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.104764,	
2017-07-31 19:14:27,355 Epoch[33] Batch [860]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.104681,	
2017-07-31 19:14:31,924 Epoch[33] Batch [870]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.104675,	
2017-07-31 19:14:36,304 Epoch[33] Batch [880]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.104519,	
2017-07-31 19:14:40,952 Epoch[33] Batch [890]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.104532,	
2017-07-31 19:14:45,440 Epoch[33] Batch [900]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104463,	
2017-07-31 19:14:50,175 Epoch[33] Batch [910]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.104332,	
2017-07-31 19:14:54,617 Epoch[33] Batch [920]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.104375,	
2017-07-31 19:14:59,168 Epoch[33] Batch [930]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104299,	
2017-07-31 19:15:03,627 Epoch[33] Batch [940]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.104228,	
2017-07-31 19:15:08,534 Epoch[33] Batch [950]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.104164,	
2017-07-31 19:15:12,962 Epoch[33] Batch [960]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.104151,	
2017-07-31 19:15:17,618 Epoch[33] Batch [970]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.104107,	
2017-07-31 19:15:22,026 Epoch[33] Batch [980]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.104065,	
2017-07-31 19:15:26,578 Epoch[33] Batch [990]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104030,	
2017-07-31 19:15:31,127 Epoch[33] Batch [1000]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.103809,	
2017-07-31 19:15:35,527 Epoch[33] Batch [1010]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.103903,	
2017-07-31 19:15:39,872 Epoch[33] Batch [1020]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.103897,	
2017-07-31 19:15:44,659 Epoch[33] Batch [1030]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.103946,	
2017-07-31 19:15:48,874 Epoch[33] Batch [1040]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.104054,	
2017-07-31 19:15:53,362 Epoch[33] Batch [1050]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.104094,	
2017-07-31 19:15:57,775 Epoch[33] Batch [1060]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.104087,	
2017-07-31 19:16:02,271 Epoch[33] Batch [1070]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.103924,	
2017-07-31 19:16:06,708 Epoch[33] Batch [1080]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104047,	
2017-07-31 19:16:11,010 Epoch[33] Batch [1090]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.104177,	
2017-07-31 19:16:15,439 Epoch[33] Batch [1100]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.104181,	
2017-07-31 19:16:19,847 Epoch[33] Batch [1110]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.104164,	
2017-07-31 19:16:24,366 Epoch[33] Batch [1120]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.104167,	
2017-07-31 19:16:28,770 Epoch[33] Batch [1130]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.104316,	
2017-07-31 19:16:33,274 Epoch[33] Batch [1140]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.104355,	
2017-07-31 19:16:37,855 Epoch[33] Batch [1150]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.104330,	
2017-07-31 19:16:42,748 Epoch[33] Batch [1160]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.104357,	
2017-07-31 19:16:47,288 Epoch[33] Batch [1170]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.104381,	
2017-07-31 19:16:51,647 Epoch[33] Batch [1180]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104409,	
2017-07-31 19:16:56,133 Epoch[33] Batch [1190]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.104306,	
2017-07-31 19:17:00,400 Epoch[33] Batch [1200]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.104251,	
2017-07-31 19:17:04,935 Epoch[33] Batch [1210]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.104278,	
2017-07-31 19:17:09,314 Epoch[33] Batch [1220]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.104251,	
2017-07-31 19:17:13,756 Epoch[33] Batch [1230]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.104285,	
2017-07-31 19:17:18,216 Epoch[33] Batch [1240]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.104255,	
2017-07-31 19:17:22,697 Epoch[33] Batch [1250]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.104250,	
2017-07-31 19:17:27,134 Epoch[33] Batch [1260]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.104315,	
2017-07-31 19:17:31,680 Epoch[33] Batch [1270]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.104255,	
2017-07-31 19:17:35,936 Epoch[33] Batch [1280]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.104307,	
2017-07-31 19:17:40,548 Epoch[33] Batch [1290]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.104271,	
2017-07-31 19:17:45,334 Epoch[33] Batch [1300]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.104293,	
2017-07-31 19:17:49,955 Epoch[33] Batch [1310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.104261,	
2017-07-31 19:17:54,325 Epoch[33] Batch [1320]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.104277,	
2017-07-31 19:17:58,891 Epoch[33] Batch [1330]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.104250,	
2017-07-31 19:18:03,405 Epoch[33] Batch [1340]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.104244,	
2017-07-31 19:18:08,275 Epoch[33] Batch [1350]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.104207,	
2017-07-31 19:18:12,682 Epoch[33] Batch [1360]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.104353,	
2017-07-31 19:18:17,363 Epoch[33] Batch [1370]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.104264,	
2017-07-31 19:18:21,828 Epoch[33] Batch [1380]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.104315,	
2017-07-31 19:18:26,437 Epoch[33] Batch [1390]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.104287,	
2017-07-31 19:18:30,886 Epoch[33] Batch [1400]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.104285,	
2017-07-31 19:18:35,472 Epoch[33] Batch [1410]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.104316,	
2017-07-31 19:18:40,081 Epoch[33] Batch [1420]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.104303,	
2017-07-31 19:18:44,583 Epoch[33] Batch [1430]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.104207,	
2017-07-31 19:18:48,831 Epoch[33] Batch [1440]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.104168,	
2017-07-31 19:18:53,254 Epoch[33] Batch [1450]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.104166,	
2017-07-31 19:18:57,722 Epoch[33] Batch [1460]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.104126,	
2017-07-31 19:19:02,209 Epoch[33] Batch [1470]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.104157,	
2017-07-31 19:19:06,583 Epoch[33] Batch [1480]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.104188,	
2017-07-31 19:19:09,324 Epoch[33] Train-FCNLogLoss=0.104190
2017-07-31 19:19:09,324 Epoch[33] Time cost=673.865
2017-07-31 19:19:10,162 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.params"
2017-07-31 19:19:11,914 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.states"
2017-07-31 19:19:17,395 Epoch[34] Batch [10]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.104135,	
2017-07-31 19:19:21,987 Epoch[34] Batch [20]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.111776,	
2017-07-31 19:19:26,639 Epoch[34] Batch [30]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.110666,	
2017-07-31 19:19:31,230 Epoch[34] Batch [40]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.104856,	
2017-07-31 19:19:35,912 Epoch[34] Batch [50]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.106456,	
2017-07-31 19:19:40,250 Epoch[34] Batch [60]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.106943,	
2017-07-31 19:19:44,611 Epoch[34] Batch [70]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.104393,	
2017-07-31 19:19:49,021 Epoch[34] Batch [80]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.104168,	
2017-07-31 19:19:53,548 Epoch[34] Batch [90]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.103746,	
2017-07-31 19:19:58,186 Epoch[34] Batch [100]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.103161,	
2017-07-31 19:20:02,658 Epoch[34] Batch [110]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.103559,	
2017-07-31 19:20:07,072 Epoch[34] Batch [120]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.102597,	
2017-07-31 19:20:11,665 Epoch[34] Batch [130]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.102035,	
2017-07-31 19:20:16,228 Epoch[34] Batch [140]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.102187,	
2017-07-31 19:20:20,607 Epoch[34] Batch [150]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.101936,	
2017-07-31 19:20:25,045 Epoch[34] Batch [160]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.102300,	
2017-07-31 19:20:29,386 Epoch[34] Batch [170]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.102430,	
2017-07-31 19:20:34,257 Epoch[34] Batch [180]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.102412,	
2017-07-31 19:20:38,697 Epoch[34] Batch [190]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.102235,	
2017-07-31 19:20:43,076 Epoch[34] Batch [200]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.102511,	
2017-07-31 19:20:47,476 Epoch[34] Batch [210]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.102579,	
2017-07-31 19:20:51,789 Epoch[34] Batch [220]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.102545,	
2017-07-31 19:20:56,459 Epoch[34] Batch [230]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.102096,	
2017-07-31 19:21:00,865 Epoch[34] Batch [240]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.102003,	
2017-07-31 19:21:05,265 Epoch[34] Batch [250]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.101897,	
2017-07-31 19:21:09,529 Epoch[34] Batch [260]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.102000,	
2017-07-31 19:21:13,994 Epoch[34] Batch [270]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.101739,	
2017-07-31 19:21:18,411 Epoch[34] Batch [280]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.102085,	
2017-07-31 19:21:23,016 Epoch[34] Batch [290]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.102441,	
2017-07-31 19:21:27,185 Epoch[34] Batch [300]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.102552,	
2017-07-31 19:21:31,723 Epoch[34] Batch [310]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.102108,	
2017-07-31 19:21:36,107 Epoch[34] Batch [320]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.101948,	
2017-07-31 19:21:40,341 Epoch[34] Batch [330]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.102392,	
2017-07-31 19:21:44,720 Epoch[34] Batch [340]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.102628,	
2017-07-31 19:21:49,174 Epoch[34] Batch [350]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.102834,	
2017-07-31 19:21:53,634 Epoch[34] Batch [360]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.102952,	
2017-07-31 19:21:58,357 Epoch[34] Batch [370]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.103108,	
2017-07-31 19:22:02,950 Epoch[34] Batch [380]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.103008,	
2017-07-31 19:22:07,386 Epoch[34] Batch [390]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.103452,	
2017-07-31 19:22:11,821 Epoch[34] Batch [400]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.103512,	
2017-07-31 19:22:16,372 Epoch[34] Batch [410]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.103688,	
2017-07-31 19:22:20,852 Epoch[34] Batch [420]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.103986,	
2017-07-31 19:22:25,315 Epoch[34] Batch [430]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.103978,	
2017-07-31 19:22:29,781 Epoch[34] Batch [440]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.103923,	
2017-07-31 19:22:34,372 Epoch[34] Batch [450]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.104267,	
2017-07-31 19:22:38,923 Epoch[34] Batch [460]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.104407,	
2017-07-31 19:22:43,346 Epoch[34] Batch [470]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.104623,	
2017-07-31 19:22:47,866 Epoch[34] Batch [480]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.104695,	
2017-07-31 19:22:52,584 Epoch[34] Batch [490]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.104505,	
2017-07-31 19:22:56,971 Epoch[34] Batch [500]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.104490,	
2017-07-31 19:23:01,400 Epoch[34] Batch [510]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.104421,	
2017-07-31 19:23:05,712 Epoch[34] Batch [520]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.104860,	
2017-07-31 19:23:10,080 Epoch[34] Batch [530]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.105880,	
2017-07-31 19:23:14,745 Epoch[34] Batch [540]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.106306,	
2017-07-31 19:23:19,644 Epoch[34] Batch [550]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.106715,	
2017-07-31 19:23:24,327 Epoch[34] Batch [560]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.107178,	
2017-07-31 19:23:29,130 Epoch[34] Batch [570]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.107278,	
2017-07-31 19:23:33,522 Epoch[34] Batch [580]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.107635,	
2017-07-31 19:23:38,183 Epoch[34] Batch [590]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.108376,	
2017-07-31 19:23:43,163 Epoch[34] Batch [600]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.108912,	
2017-07-31 19:23:47,711 Epoch[34] Batch [610]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109139,	
2017-07-31 19:23:52,181 Epoch[34] Batch [620]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.109228,	
2017-07-31 19:23:56,837 Epoch[34] Batch [630]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.109229,	
2017-07-31 19:24:01,366 Epoch[34] Batch [640]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.109293,	
2017-07-31 19:24:06,201 Epoch[34] Batch [650]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.109398,	
2017-07-31 19:24:10,493 Epoch[34] Batch [660]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.109301,	
2017-07-31 19:24:15,194 Epoch[34] Batch [670]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.109274,	
2017-07-31 19:24:19,729 Epoch[34] Batch [680]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.109243,	
2017-07-31 19:24:24,339 Epoch[34] Batch [690]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109355,	
2017-07-31 19:24:28,823 Epoch[34] Batch [700]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.109337,	
2017-07-31 19:24:33,596 Epoch[34] Batch [710]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.109390,	
2017-07-31 19:24:38,156 Epoch[34] Batch [720]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.109312,	
2017-07-31 19:24:42,670 Epoch[34] Batch [730]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.109161,	
2017-07-31 19:24:47,220 Epoch[34] Batch [740]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.109115,	
2017-07-31 19:24:51,703 Epoch[34] Batch [750]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.109096,	
2017-07-31 19:24:56,043 Epoch[34] Batch [760]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.109005,	
2017-07-31 19:25:00,566 Epoch[34] Batch [770]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.109064,	
2017-07-31 19:25:05,302 Epoch[34] Batch [780]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.109059,	
2017-07-31 19:25:09,704 Epoch[34] Batch [790]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.109041,	
2017-07-31 19:25:14,118 Epoch[34] Batch [800]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.108975,	
2017-07-31 19:25:18,640 Epoch[34] Batch [810]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.108945,	
2017-07-31 19:25:22,970 Epoch[34] Batch [820]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.108825,	
2017-07-31 19:25:27,579 Epoch[34] Batch [830]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.108887,	
2017-07-31 19:25:32,243 Epoch[34] Batch [840]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.108887,	
2017-07-31 19:25:36,657 Epoch[34] Batch [850]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.109121,	
2017-07-31 19:25:41,083 Epoch[34] Batch [860]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.109025,	
2017-07-31 19:25:45,339 Epoch[34] Batch [870]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.108912,	
2017-07-31 19:25:49,926 Epoch[34] Batch [880]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.108703,	
2017-07-31 19:25:54,194 Epoch[34] Batch [890]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.108581,	
2017-07-31 19:25:58,530 Epoch[34] Batch [900]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.108663,	
2017-07-31 19:26:02,838 Epoch[34] Batch [910]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.108633,	
2017-07-31 19:26:07,204 Epoch[34] Batch [920]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.108627,	
2017-07-31 19:26:11,794 Epoch[34] Batch [930]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.108586,	
2017-07-31 19:26:16,502 Epoch[34] Batch [940]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.108684,	
2017-07-31 19:26:21,077 Epoch[34] Batch [950]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.108754,	
2017-07-31 19:26:25,551 Epoch[34] Batch [960]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.108766,	
2017-07-31 19:26:30,102 Epoch[34] Batch [970]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.108737,	
2017-07-31 19:26:34,492 Epoch[34] Batch [980]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.108786,	
2017-07-31 19:26:39,096 Epoch[34] Batch [990]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.108703,	
2017-07-31 19:26:43,620 Epoch[34] Batch [1000]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.108656,	
2017-07-31 19:26:48,079 Epoch[34] Batch [1010]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108673,	
2017-07-31 19:26:52,440 Epoch[34] Batch [1020]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.108701,	
2017-07-31 19:26:56,934 Epoch[34] Batch [1030]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.108788,	
2017-07-31 19:27:01,276 Epoch[34] Batch [1040]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108797,	
2017-07-31 19:27:05,813 Epoch[34] Batch [1050]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.108821,	
2017-07-31 19:27:10,134 Epoch[34] Batch [1060]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.108763,	
2017-07-31 19:27:14,709 Epoch[34] Batch [1070]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.108691,	
2017-07-31 19:27:19,224 Epoch[34] Batch [1080]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.108681,	
2017-07-31 19:27:23,562 Epoch[34] Batch [1090]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.108676,	
2017-07-31 19:27:28,118 Epoch[34] Batch [1100]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.108573,	
2017-07-31 19:27:32,609 Epoch[34] Batch [1110]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.108471,	
2017-07-31 19:27:37,117 Epoch[34] Batch [1120]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.108394,	
2017-07-31 19:27:41,400 Epoch[34] Batch [1130]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.108327,	
2017-07-31 19:27:45,859 Epoch[34] Batch [1140]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.108390,	
2017-07-31 19:27:50,642 Epoch[34] Batch [1150]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.108225,	
2017-07-31 19:27:55,033 Epoch[34] Batch [1160]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.108174,	
2017-07-31 19:27:59,771 Epoch[34] Batch [1170]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.108105,	
2017-07-31 19:28:04,190 Epoch[34] Batch [1180]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.107960,	
2017-07-31 19:28:08,717 Epoch[34] Batch [1190]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107846,	
2017-07-31 19:28:13,010 Epoch[34] Batch [1200]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.107864,	
2017-07-31 19:28:17,604 Epoch[34] Batch [1210]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.107802,	
2017-07-31 19:28:21,939 Epoch[34] Batch [1220]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.107769,	
2017-07-31 19:28:26,278 Epoch[34] Batch [1230]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.107773,	
2017-07-31 19:28:30,902 Epoch[34] Batch [1240]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.107778,	
2017-07-31 19:28:35,125 Epoch[34] Batch [1250]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.107728,	
2017-07-31 19:28:39,492 Epoch[34] Batch [1260]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.107666,	
2017-07-31 19:28:44,017 Epoch[34] Batch [1270]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107637,	
2017-07-31 19:28:48,461 Epoch[34] Batch [1280]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.107644,	
2017-07-31 19:28:53,150 Epoch[34] Batch [1290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.107681,	
2017-07-31 19:28:57,513 Epoch[34] Batch [1300]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.107669,	
2017-07-31 19:29:02,100 Epoch[34] Batch [1310]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.107625,	
2017-07-31 19:29:06,642 Epoch[34] Batch [1320]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.107561,	
2017-07-31 19:29:11,156 Epoch[34] Batch [1330]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.107557,	
2017-07-31 19:29:15,780 Epoch[34] Batch [1340]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.107473,	
2017-07-31 19:29:20,418 Epoch[34] Batch [1350]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107404,	
2017-07-31 19:29:24,896 Epoch[34] Batch [1360]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.107388,	
2017-07-31 19:29:29,364 Epoch[34] Batch [1370]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.107403,	
2017-07-31 19:29:33,810 Epoch[34] Batch [1380]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.107474,	
2017-07-31 19:29:38,476 Epoch[34] Batch [1390]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.107527,	
2017-07-31 19:29:43,176 Epoch[34] Batch [1400]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.107517,	
2017-07-31 19:29:47,781 Epoch[34] Batch [1410]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107455,	
2017-07-31 19:29:52,835 Epoch[34] Batch [1420]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.107421,	
2017-07-31 19:29:57,440 Epoch[34] Batch [1430]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107455,	
2017-07-31 19:30:01,984 Epoch[34] Batch [1440]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107441,	
2017-07-31 19:30:06,858 Epoch[34] Batch [1450]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.107396,	
2017-07-31 19:30:11,497 Epoch[34] Batch [1460]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.107348,	
2017-07-31 19:30:15,756 Epoch[34] Batch [1470]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.107275,	
2017-07-31 19:30:20,281 Epoch[34] Batch [1480]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107119,	
2017-07-31 19:30:22,951 Epoch[34] Train-FCNLogLoss=0.107124
2017-07-31 19:30:22,951 Epoch[34] Time cost=671.037
2017-07-31 19:30:23,740 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.params"
2017-07-31 19:30:25,335 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.states"
2017-07-31 19:30:30,436 Epoch[35] Batch [10]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.091267,	
2017-07-31 19:30:34,895 Epoch[35] Batch [20]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.126971,	
2017-07-31 19:30:39,293 Epoch[35] Batch [30]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.124773,	
2017-07-31 19:30:43,847 Epoch[35] Batch [40]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.121886,	
2017-07-31 19:30:48,278 Epoch[35] Batch [50]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.118654,	
2017-07-31 19:30:52,733 Epoch[35] Batch [60]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.116173,	
2017-07-31 19:30:57,161 Epoch[35] Batch [70]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.114685,	
2017-07-31 19:31:01,676 Epoch[35] Batch [80]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.113782,	
2017-07-31 19:31:06,327 Epoch[35] Batch [90]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.111845,	
2017-07-31 19:31:10,824 Epoch[35] Batch [100]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.110005,	
2017-07-31 19:31:15,361 Epoch[35] Batch [110]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.109377,	
2017-07-31 19:31:20,067 Epoch[35] Batch [120]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.109646,	
2017-07-31 19:31:24,529 Epoch[35] Batch [130]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.109205,	
2017-07-31 19:31:29,215 Epoch[35] Batch [140]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.108722,	
2017-07-31 19:31:33,898 Epoch[35] Batch [150]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.108766,	
2017-07-31 19:31:38,457 Epoch[35] Batch [160]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.107893,	
2017-07-31 19:31:42,939 Epoch[35] Batch [170]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.107872,	
2017-07-31 19:31:47,484 Epoch[35] Batch [180]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.108076,	
2017-07-31 19:31:52,039 Epoch[35] Batch [190]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.107582,	
2017-07-31 19:31:56,651 Epoch[35] Batch [200]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.107460,	
2017-07-31 19:32:01,126 Epoch[35] Batch [210]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.107207,	
2017-07-31 19:32:05,609 Epoch[35] Batch [220]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.106339,	
2017-07-31 19:32:10,331 Epoch[35] Batch [230]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.106261,	
2017-07-31 19:32:14,736 Epoch[35] Batch [240]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.106084,	
2017-07-31 19:32:19,123 Epoch[35] Batch [250]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106183,	
2017-07-31 19:32:23,690 Epoch[35] Batch [260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.106281,	
2017-07-31 19:32:28,212 Epoch[35] Batch [270]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.106134,	
2017-07-31 19:32:32,728 Epoch[35] Batch [280]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.105918,	
2017-07-31 19:32:37,412 Epoch[35] Batch [290]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.105784,	
2017-07-31 19:32:41,899 Epoch[35] Batch [300]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.105568,	
2017-07-31 19:32:46,407 Epoch[35] Batch [310]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.105308,	
2017-07-31 19:32:51,041 Epoch[35] Batch [320]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.105137,	
2017-07-31 19:32:55,703 Epoch[35] Batch [330]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.105144,	
2017-07-31 19:33:00,192 Epoch[35] Batch [340]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.105028,	
2017-07-31 19:33:04,914 Epoch[35] Batch [350]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.105018,	
2017-07-31 19:33:09,374 Epoch[35] Batch [360]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.105507,	
2017-07-31 19:33:13,801 Epoch[35] Batch [370]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.105297,	
2017-07-31 19:33:18,077 Epoch[35] Batch [380]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.105499,	
2017-07-31 19:33:22,577 Epoch[35] Batch [390]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.105327,	
2017-07-31 19:33:27,001 Epoch[35] Batch [400]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.105433,	
2017-07-31 19:33:31,229 Epoch[35] Batch [410]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.105381,	
2017-07-31 19:33:35,832 Epoch[35] Batch [420]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.105137,	
2017-07-31 19:33:40,530 Epoch[35] Batch [430]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.104846,	
2017-07-31 19:33:45,357 Epoch[35] Batch [440]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.104761,	
2017-07-31 19:33:50,123 Epoch[35] Batch [450]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.104589,	
2017-07-31 19:33:54,668 Epoch[35] Batch [460]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.104198,	
2017-07-31 19:33:59,198 Epoch[35] Batch [470]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.104403,	
2017-07-31 19:34:03,685 Epoch[35] Batch [480]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.104547,	
2017-07-31 19:34:07,843 Epoch[35] Batch [490]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104373,	
2017-07-31 19:34:12,205 Epoch[35] Batch [500]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.104434,	
2017-07-31 19:34:16,530 Epoch[35] Batch [510]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.104269,	
2017-07-31 19:34:21,078 Epoch[35] Batch [520]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.104194,	
2017-07-31 19:34:25,562 Epoch[35] Batch [530]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.104396,	
2017-07-31 19:34:30,024 Epoch[35] Batch [540]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.104139,	
2017-07-31 19:34:34,495 Epoch[35] Batch [550]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.103918,	
2017-07-31 19:34:39,260 Epoch[35] Batch [560]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.103848,	
2017-07-31 19:34:43,761 Epoch[35] Batch [570]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.103866,	
2017-07-31 19:34:48,221 Epoch[35] Batch [580]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.103565,	
2017-07-31 19:34:52,656 Epoch[35] Batch [590]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.103562,	
2017-07-31 19:34:57,172 Epoch[35] Batch [600]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.103510,	
2017-07-31 19:35:01,859 Epoch[35] Batch [610]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.103605,	
2017-07-31 19:35:06,249 Epoch[35] Batch [620]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.103568,	
2017-07-31 19:35:10,797 Epoch[35] Batch [630]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.103584,	
2017-07-31 19:35:15,500 Epoch[35] Batch [640]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.103430,	
2017-07-31 19:35:19,949 Epoch[35] Batch [650]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.103211,	
2017-07-31 19:35:24,431 Epoch[35] Batch [660]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.102984,	
2017-07-31 19:35:28,980 Epoch[35] Batch [670]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.102995,	
2017-07-31 19:35:33,541 Epoch[35] Batch [680]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.102986,	
2017-07-31 19:35:38,248 Epoch[35] Batch [690]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.102935,	
2017-07-31 19:35:42,834 Epoch[35] Batch [700]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.102864,	
2017-07-31 19:35:47,384 Epoch[35] Batch [710]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.102840,	
2017-07-31 19:35:52,080 Epoch[35] Batch [720]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.102889,	
2017-07-31 19:35:56,778 Epoch[35] Batch [730]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.102949,	
2017-07-31 19:36:01,319 Epoch[35] Batch [740]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.102854,	
2017-07-31 19:36:05,758 Epoch[35] Batch [750]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.102723,	
2017-07-31 19:36:10,592 Epoch[35] Batch [760]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.102712,	
2017-07-31 19:36:15,000 Epoch[35] Batch [770]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.102690,	
2017-07-31 19:36:19,238 Epoch[35] Batch [780]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.102702,	
2017-07-31 19:36:23,730 Epoch[35] Batch [790]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.102590,	
2017-07-31 19:36:28,195 Epoch[35] Batch [800]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.102558,	
2017-07-31 19:36:32,696 Epoch[35] Batch [810]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.102523,	
2017-07-31 19:36:37,124 Epoch[35] Batch [820]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.102424,	
2017-07-31 19:36:41,331 Epoch[35] Batch [830]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.102322,	
2017-07-31 19:36:45,956 Epoch[35] Batch [840]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.102272,	
2017-07-31 19:36:50,624 Epoch[35] Batch [850]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.102166,	
2017-07-31 19:36:55,353 Epoch[35] Batch [860]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.102138,	
2017-07-31 19:36:59,803 Epoch[35] Batch [870]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.102099,	
2017-07-31 19:37:04,405 Epoch[35] Batch [880]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.102138,	
2017-07-31 19:37:09,054 Epoch[35] Batch [890]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.102059,	
2017-07-31 19:37:13,488 Epoch[35] Batch [900]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.102052,	
2017-07-31 19:37:17,862 Epoch[35] Batch [910]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.102147,	
2017-07-31 19:37:22,411 Epoch[35] Batch [920]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.102220,	
2017-07-31 19:37:27,000 Epoch[35] Batch [930]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.102139,	
2017-07-31 19:37:31,454 Epoch[35] Batch [940]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.101999,	
2017-07-31 19:37:35,926 Epoch[35] Batch [950]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102039,	
2017-07-31 19:37:40,293 Epoch[35] Batch [960]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101905,	
2017-07-31 19:37:44,806 Epoch[35] Batch [970]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.102057,	
2017-07-31 19:37:49,266 Epoch[35] Batch [980]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.102179,	
2017-07-31 19:37:53,836 Epoch[35] Batch [990]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.102152,	
2017-07-31 19:37:58,324 Epoch[35] Batch [1000]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.102050,	
2017-07-31 19:38:02,886 Epoch[35] Batch [1010]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.101951,	
2017-07-31 19:38:07,663 Epoch[35] Batch [1020]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.101841,	
2017-07-31 19:38:12,118 Epoch[35] Batch [1030]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.101862,	
2017-07-31 19:38:16,683 Epoch[35] Batch [1040]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.101841,	
2017-07-31 19:38:21,310 Epoch[35] Batch [1050]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.101803,	
2017-07-31 19:38:25,785 Epoch[35] Batch [1060]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.101690,	
2017-07-31 19:38:30,153 Epoch[35] Batch [1070]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101693,	
2017-07-31 19:38:34,493 Epoch[35] Batch [1080]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.101649,	
2017-07-31 19:38:38,812 Epoch[35] Batch [1090]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.101637,	
2017-07-31 19:38:43,388 Epoch[35] Batch [1100]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.101597,	
2017-07-31 19:38:47,983 Epoch[35] Batch [1110]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.101624,	
2017-07-31 19:38:52,449 Epoch[35] Batch [1120]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.101633,	
2017-07-31 19:38:57,207 Epoch[35] Batch [1130]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.101626,	
2017-07-31 19:39:01,731 Epoch[35] Batch [1140]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.101743,	
2017-07-31 19:39:06,354 Epoch[35] Batch [1150]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.101730,	
2017-07-31 19:39:10,618 Epoch[35] Batch [1160]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.101702,	
2017-07-31 19:39:15,267 Epoch[35] Batch [1170]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.101650,	
2017-07-31 19:39:19,761 Epoch[35] Batch [1180]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.101636,	
2017-07-31 19:39:24,455 Epoch[35] Batch [1190]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.101489,	
2017-07-31 19:39:29,013 Epoch[35] Batch [1200]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.101379,	
2017-07-31 19:39:33,446 Epoch[35] Batch [1210]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.101396,	
2017-07-31 19:39:38,186 Epoch[35] Batch [1220]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.101345,	
2017-07-31 19:39:42,439 Epoch[35] Batch [1230]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.101510,	
2017-07-31 19:39:46,912 Epoch[35] Batch [1240]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.101392,	
2017-07-31 19:39:51,465 Epoch[35] Batch [1250]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.101343,	
2017-07-31 19:39:55,905 Epoch[35] Batch [1260]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.101330,	
2017-07-31 19:40:00,307 Epoch[35] Batch [1270]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.101290,	
2017-07-31 19:40:04,829 Epoch[35] Batch [1280]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.101405,	
2017-07-31 19:40:09,354 Epoch[35] Batch [1290]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.101388,	
2017-07-31 19:40:13,824 Epoch[35] Batch [1300]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.101382,	
2017-07-31 19:40:18,197 Epoch[35] Batch [1310]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.101368,	
2017-07-31 19:40:22,668 Epoch[35] Batch [1320]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.101483,	
2017-07-31 19:40:27,258 Epoch[35] Batch [1330]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.101421,	
2017-07-31 19:40:31,752 Epoch[35] Batch [1340]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.101472,	
2017-07-31 19:40:36,273 Epoch[35] Batch [1350]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.101411,	
2017-07-31 19:40:40,758 Epoch[35] Batch [1360]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.101438,	
2017-07-31 19:40:45,109 Epoch[35] Batch [1370]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.101421,	
2017-07-31 19:40:49,431 Epoch[35] Batch [1380]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.101394,	
2017-07-31 19:40:54,042 Epoch[35] Batch [1390]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.101359,	
2017-07-31 19:40:58,467 Epoch[35] Batch [1400]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.101272,	
2017-07-31 19:41:02,860 Epoch[35] Batch [1410]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.101350,	
2017-07-31 19:41:07,395 Epoch[35] Batch [1420]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.101384,	
2017-07-31 19:41:12,065 Epoch[35] Batch [1430]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.101311,	
2017-07-31 19:41:16,587 Epoch[35] Batch [1440]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.101414,	
2017-07-31 19:41:21,146 Epoch[35] Batch [1450]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.101390,	
2017-07-31 19:41:25,835 Epoch[35] Batch [1460]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.101335,	
2017-07-31 19:41:30,465 Epoch[35] Batch [1470]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.101341,	
2017-07-31 19:41:34,913 Epoch[35] Batch [1480]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.101431,	
2017-07-31 19:41:37,636 Epoch[35] Train-FCNLogLoss=0.101368
2017-07-31 19:41:37,636 Epoch[35] Time cost=672.301
2017-07-31 19:41:38,347 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.params"
2017-07-31 19:41:40,437 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.states"
2017-07-31 19:41:46,053 Epoch[36] Batch [10]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.100189,	
2017-07-31 19:41:50,571 Epoch[36] Batch [20]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.098867,	
2017-07-31 19:41:54,984 Epoch[36] Batch [30]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.098941,	
2017-07-31 19:41:59,300 Epoch[36] Batch [40]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.098317,	
2017-07-31 19:42:03,819 Epoch[36] Batch [50]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.097552,	
2017-07-31 19:42:08,164 Epoch[36] Batch [60]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.098937,	
2017-07-31 19:42:12,453 Epoch[36] Batch [70]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.099746,	
2017-07-31 19:42:17,077 Epoch[36] Batch [80]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.099515,	
2017-07-31 19:42:21,511 Epoch[36] Batch [90]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.099885,	
2017-07-31 19:42:25,865 Epoch[36] Batch [100]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.100687,	
2017-07-31 19:42:30,342 Epoch[36] Batch [110]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.101243,	
2017-07-31 19:42:34,738 Epoch[36] Batch [120]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.100848,	
2017-07-31 19:42:39,296 Epoch[36] Batch [130]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.100760,	
2017-07-31 19:42:43,882 Epoch[36] Batch [140]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.101790,	
2017-07-31 19:42:48,388 Epoch[36] Batch [150]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.102167,	
2017-07-31 19:42:52,927 Epoch[36] Batch [160]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.102099,	
2017-07-31 19:42:57,466 Epoch[36] Batch [170]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.101555,	
2017-07-31 19:43:02,231 Epoch[36] Batch [180]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.101092,	
2017-07-31 19:43:06,825 Epoch[36] Batch [190]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.101701,	
2017-07-31 19:43:11,749 Epoch[36] Batch [200]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.102294,	
2017-07-31 19:43:16,449 Epoch[36] Batch [210]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.102071,	
2017-07-31 19:43:21,017 Epoch[36] Batch [220]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.102288,	
2017-07-31 19:43:25,666 Epoch[36] Batch [230]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.101550,	
2017-07-31 19:43:30,232 Epoch[36] Batch [240]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.101287,	
2017-07-31 19:43:34,593 Epoch[36] Batch [250]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.101490,	
2017-07-31 19:43:39,022 Epoch[36] Batch [260]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.101834,	
2017-07-31 19:43:43,283 Epoch[36] Batch [270]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.101794,	
2017-07-31 19:43:47,577 Epoch[36] Batch [280]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.101494,	
2017-07-31 19:43:51,928 Epoch[36] Batch [290]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.101307,	
2017-07-31 19:43:56,560 Epoch[36] Batch [300]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.101257,	
2017-07-31 19:44:01,070 Epoch[36] Batch [310]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.101179,	
2017-07-31 19:44:05,488 Epoch[36] Batch [320]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.100901,	
2017-07-31 19:44:10,046 Epoch[36] Batch [330]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.100907,	
2017-07-31 19:44:14,316 Epoch[36] Batch [340]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.101148,	
2017-07-31 19:44:19,078 Epoch[36] Batch [350]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.101179,	
2017-07-31 19:44:23,843 Epoch[36] Batch [360]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.101077,	
2017-07-31 19:44:28,196 Epoch[36] Batch [370]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.101024,	
2017-07-31 19:44:32,595 Epoch[36] Batch [380]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.101450,	
2017-07-31 19:44:36,990 Epoch[36] Batch [390]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.101362,	
2017-07-31 19:44:41,626 Epoch[36] Batch [400]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.101595,	
2017-07-31 19:44:46,149 Epoch[36] Batch [410]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.101769,	
2017-07-31 19:44:50,517 Epoch[36] Batch [420]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.102128,	
2017-07-31 19:44:55,132 Epoch[36] Batch [430]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.102315,	
2017-07-31 19:44:59,569 Epoch[36] Batch [440]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.102390,	
2017-07-31 19:45:04,046 Epoch[36] Batch [450]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.102399,	
2017-07-31 19:45:08,635 Epoch[36] Batch [460]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.102325,	
2017-07-31 19:45:12,895 Epoch[36] Batch [470]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.102158,	
2017-07-31 19:45:17,553 Epoch[36] Batch [480]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.101991,	
2017-07-31 19:45:22,050 Epoch[36] Batch [490]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.101888,	
2017-07-31 19:45:26,771 Epoch[36] Batch [500]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.101972,	
2017-07-31 19:45:31,233 Epoch[36] Batch [510]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.102130,	
2017-07-31 19:45:35,576 Epoch[36] Batch [520]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.102394,	
2017-07-31 19:45:40,245 Epoch[36] Batch [530]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.102558,	
2017-07-31 19:45:44,824 Epoch[36] Batch [540]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.102701,	
2017-07-31 19:45:49,418 Epoch[36] Batch [550]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.102623,	
2017-07-31 19:45:54,130 Epoch[36] Batch [560]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.102755,	
2017-07-31 19:45:58,717 Epoch[36] Batch [570]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.102642,	
2017-07-31 19:46:03,086 Epoch[36] Batch [580]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.102889,	
2017-07-31 19:46:07,484 Epoch[36] Batch [590]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.103219,	
2017-07-31 19:46:12,026 Epoch[36] Batch [600]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.103798,	
2017-07-31 19:46:16,593 Epoch[36] Batch [610]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.104325,	
2017-07-31 19:46:21,106 Epoch[36] Batch [620]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.105513,	
2017-07-31 19:46:25,407 Epoch[36] Batch [630]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106366,	
2017-07-31 19:46:29,923 Epoch[36] Batch [640]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106896,	
2017-07-31 19:46:34,375 Epoch[36] Batch [650]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.106953,	
2017-07-31 19:46:38,987 Epoch[36] Batch [660]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.107139,	
2017-07-31 19:46:43,484 Epoch[36] Batch [670]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.107201,	
2017-07-31 19:46:47,995 Epoch[36] Batch [680]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.107257,	
2017-07-31 19:46:52,632 Epoch[36] Batch [690]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.107309,	
2017-07-31 19:46:57,251 Epoch[36] Batch [700]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.107325,	
2017-07-31 19:47:01,847 Epoch[36] Batch [710]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107219,	
2017-07-31 19:47:06,353 Epoch[36] Batch [720]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.107171,	
2017-07-31 19:47:10,790 Epoch[36] Batch [730]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.107099,	
2017-07-31 19:47:15,560 Epoch[36] Batch [740]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.107128,	
2017-07-31 19:47:19,794 Epoch[36] Batch [750]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.107014,	
2017-07-31 19:47:24,243 Epoch[36] Batch [760]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.106948,	
2017-07-31 19:47:28,800 Epoch[36] Batch [770]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.107012,	
2017-07-31 19:47:33,354 Epoch[36] Batch [780]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.107094,	
2017-07-31 19:47:38,268 Epoch[36] Batch [790]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.107077,	
2017-07-31 19:47:42,816 Epoch[36] Batch [800]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.107042,	
2017-07-31 19:47:47,481 Epoch[36] Batch [810]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.107005,	
2017-07-31 19:47:52,139 Epoch[36] Batch [820]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.106999,	
2017-07-31 19:47:56,655 Epoch[36] Batch [830]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106948,	
2017-07-31 19:48:01,210 Epoch[36] Batch [840]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.106870,	
2017-07-31 19:48:05,727 Epoch[36] Batch [850]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106864,	
2017-07-31 19:48:10,194 Epoch[36] Batch [860]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.107066,	
2017-07-31 19:48:14,701 Epoch[36] Batch [870]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.107140,	
2017-07-31 19:48:19,126 Epoch[36] Batch [880]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.107223,	
2017-07-31 19:48:23,586 Epoch[36] Batch [890]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.107338,	
2017-07-31 19:48:28,352 Epoch[36] Batch [900]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.107259,	
2017-07-31 19:48:32,683 Epoch[36] Batch [910]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.107466,	
2017-07-31 19:48:36,998 Epoch[36] Batch [920]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.107460,	
2017-07-31 19:48:41,744 Epoch[36] Batch [930]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.107580,	
2017-07-31 19:48:46,347 Epoch[36] Batch [940]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107484,	
2017-07-31 19:48:50,678 Epoch[36] Batch [950]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.107419,	
2017-07-31 19:48:55,196 Epoch[36] Batch [960]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.107420,	
2017-07-31 19:48:59,633 Epoch[36] Batch [970]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.107289,	
2017-07-31 19:49:04,106 Epoch[36] Batch [980]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.107307,	
2017-07-31 19:49:08,572 Epoch[36] Batch [990]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.107174,	
2017-07-31 19:49:12,995 Epoch[36] Batch [1000]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.107037,	
2017-07-31 19:49:17,456 Epoch[36] Batch [1010]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.106876,	
2017-07-31 19:49:22,135 Epoch[36] Batch [1020]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.106797,	
2017-07-31 19:49:26,650 Epoch[36] Batch [1030]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.106714,	
2017-07-31 19:49:31,154 Epoch[36] Batch [1040]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.106692,	
2017-07-31 19:49:35,721 Epoch[36] Batch [1050]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.106651,	
2017-07-31 19:49:40,466 Epoch[36] Batch [1060]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.106592,	
2017-07-31 19:49:45,170 Epoch[36] Batch [1070]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.106574,	
2017-07-31 19:49:49,500 Epoch[36] Batch [1080]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.106594,	
2017-07-31 19:49:53,962 Epoch[36] Batch [1090]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.106457,	
2017-07-31 19:49:58,356 Epoch[36] Batch [1100]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.107514,	
2017-07-31 19:50:02,892 Epoch[36] Batch [1110]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.107939,	
2017-07-31 19:50:07,348 Epoch[36] Batch [1120]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.108364,	
2017-07-31 19:50:11,781 Epoch[36] Batch [1130]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.108671,	
2017-07-31 19:50:16,278 Epoch[36] Batch [1140]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.108850,	
2017-07-31 19:50:20,548 Epoch[36] Batch [1150]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.108997,	
2017-07-31 19:50:25,228 Epoch[36] Batch [1160]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.108986,	
2017-07-31 19:50:29,772 Epoch[36] Batch [1170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109022,	
2017-07-31 19:50:34,294 Epoch[36] Batch [1180]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.109187,	
2017-07-31 19:50:38,953 Epoch[36] Batch [1190]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.109296,	
2017-07-31 19:50:43,450 Epoch[36] Batch [1200]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.109338,	
2017-07-31 19:50:48,342 Epoch[36] Batch [1210]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.109343,	
2017-07-31 19:50:52,791 Epoch[36] Batch [1220]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.109286,	
2017-07-31 19:50:57,456 Epoch[36] Batch [1230]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.109306,	
2017-07-31 19:51:01,636 Epoch[36] Batch [1240]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.109265,	
2017-07-31 19:51:06,006 Epoch[36] Batch [1250]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.109207,	
2017-07-31 19:51:10,553 Epoch[36] Batch [1260]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109175,	
2017-07-31 19:51:14,962 Epoch[36] Batch [1270]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.109139,	
2017-07-31 19:51:19,470 Epoch[36] Batch [1280]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.109168,	
2017-07-31 19:51:23,722 Epoch[36] Batch [1290]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109246,	
2017-07-31 19:51:28,120 Epoch[36] Batch [1300]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.109250,	
2017-07-31 19:51:32,528 Epoch[36] Batch [1310]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.109228,	
2017-07-31 19:51:36,832 Epoch[36] Batch [1320]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.109132,	
2017-07-31 19:51:41,371 Epoch[36] Batch [1330]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.109054,	
2017-07-31 19:51:45,545 Epoch[36] Batch [1340]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109011,	
2017-07-31 19:51:49,855 Epoch[36] Batch [1350]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.109006,	
2017-07-31 19:51:54,177 Epoch[36] Batch [1360]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.109009,	
2017-07-31 19:51:58,430 Epoch[36] Batch [1370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.109061,	
2017-07-31 19:52:02,777 Epoch[36] Batch [1380]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.108998,	
2017-07-31 19:52:07,247 Epoch[36] Batch [1390]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.109008,	
2017-07-31 19:52:11,843 Epoch[36] Batch [1400]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.108992,	
2017-07-31 19:52:16,156 Epoch[36] Batch [1410]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.108896,	
2017-07-31 19:52:20,718 Epoch[36] Batch [1420]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.108745,	
2017-07-31 19:52:25,012 Epoch[36] Batch [1430]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.108747,	
2017-07-31 19:52:29,444 Epoch[36] Batch [1440]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.108767,	
2017-07-31 19:52:33,759 Epoch[36] Batch [1450]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.108745,	
2017-07-31 19:52:38,252 Epoch[36] Batch [1460]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.108696,	
2017-07-31 19:52:43,196 Epoch[36] Batch [1470]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.108723,	
2017-07-31 19:52:47,890 Epoch[36] Batch [1480]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.108723,	
2017-07-31 19:52:50,565 Epoch[36] Train-FCNLogLoss=0.108668
2017-07-31 19:52:50,565 Epoch[36] Time cost=670.127
2017-07-31 19:52:51,235 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.params"
2017-07-31 19:52:52,987 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.states"
2017-07-31 19:52:58,437 Epoch[37] Batch [10]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.090408,	
2017-07-31 19:53:02,915 Epoch[37] Batch [20]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.097804,	
2017-07-31 19:53:07,323 Epoch[37] Batch [30]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.101063,	
2017-07-31 19:53:11,827 Epoch[37] Batch [40]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.102254,	
2017-07-31 19:53:16,250 Epoch[37] Batch [50]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.100403,	
2017-07-31 19:53:20,889 Epoch[37] Batch [60]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.103781,	
2017-07-31 19:53:25,411 Epoch[37] Batch [70]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.102598,	
2017-07-31 19:53:29,844 Epoch[37] Batch [80]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.101386,	
2017-07-31 19:53:34,337 Epoch[37] Batch [90]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.100235,	
2017-07-31 19:53:38,548 Epoch[37] Batch [100]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.100091,	
2017-07-31 19:53:42,763 Epoch[37] Batch [110]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.101089,	
2017-07-31 19:53:47,125 Epoch[37] Batch [120]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.100881,	
2017-07-31 19:53:51,537 Epoch[37] Batch [130]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.101034,	
2017-07-31 19:53:56,246 Epoch[37] Batch [140]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.100320,	
2017-07-31 19:54:01,240 Epoch[37] Batch [150]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.100238,	
2017-07-31 19:54:05,630 Epoch[37] Batch [160]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.101478,	
2017-07-31 19:54:09,934 Epoch[37] Batch [170]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.101090,	
2017-07-31 19:54:14,390 Epoch[37] Batch [180]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.100738,	
2017-07-31 19:54:18,778 Epoch[37] Batch [190]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.100806,	
2017-07-31 19:54:23,228 Epoch[37] Batch [200]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.100719,	
2017-07-31 19:54:27,738 Epoch[37] Batch [210]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.100795,	
2017-07-31 19:54:32,370 Epoch[37] Batch [220]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.101458,	
2017-07-31 19:54:36,754 Epoch[37] Batch [230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.101159,	
2017-07-31 19:54:41,395 Epoch[37] Batch [240]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.100713,	
2017-07-31 19:54:45,838 Epoch[37] Batch [250]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.100716,	
2017-07-31 19:54:50,171 Epoch[37] Batch [260]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.101169,	
2017-07-31 19:54:54,609 Epoch[37] Batch [270]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.101839,	
2017-07-31 19:54:59,171 Epoch[37] Batch [280]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.102308,	
2017-07-31 19:55:03,505 Epoch[37] Batch [290]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.102501,	
2017-07-31 19:55:08,331 Epoch[37] Batch [300]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.102852,	
2017-07-31 19:55:12,551 Epoch[37] Batch [310]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.102779,	
2017-07-31 19:55:17,163 Epoch[37] Batch [320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.103327,	
2017-07-31 19:55:21,516 Epoch[37] Batch [330]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.103116,	
2017-07-31 19:55:26,028 Epoch[37] Batch [340]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.103107,	
2017-07-31 19:55:30,286 Epoch[37] Batch [350]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.103184,	
2017-07-31 19:55:34,585 Epoch[37] Batch [360]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.103585,	
2017-07-31 19:55:38,911 Epoch[37] Batch [370]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.103602,	
2017-07-31 19:55:43,167 Epoch[37] Batch [380]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.103724,	
2017-07-31 19:55:47,541 Epoch[37] Batch [390]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.103792,	
2017-07-31 19:55:51,957 Epoch[37] Batch [400]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103567,	
2017-07-31 19:55:56,289 Epoch[37] Batch [410]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.103654,	
2017-07-31 19:56:00,720 Epoch[37] Batch [420]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.103638,	
2017-07-31 19:56:04,998 Epoch[37] Batch [430]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103565,	
2017-07-31 19:56:09,361 Epoch[37] Batch [440]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.103525,	
2017-07-31 19:56:13,738 Epoch[37] Batch [450]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.103628,	
2017-07-31 19:56:18,070 Epoch[37] Batch [460]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.103535,	
2017-07-31 19:56:22,417 Epoch[37] Batch [470]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.103619,	
2017-07-31 19:56:26,773 Epoch[37] Batch [480]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.103696,	
2017-07-31 19:56:31,157 Epoch[37] Batch [490]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.103671,	
2017-07-31 19:56:35,348 Epoch[37] Batch [500]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.103562,	
2017-07-31 19:56:39,736 Epoch[37] Batch [510]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.103761,	
2017-07-31 19:56:44,048 Epoch[37] Batch [520]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.103670,	
2017-07-31 19:56:48,401 Epoch[37] Batch [530]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.103548,	
2017-07-31 19:56:52,737 Epoch[37] Batch [540]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.103542,	
2017-07-31 19:56:57,140 Epoch[37] Batch [550]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.103490,	
2017-07-31 19:57:01,426 Epoch[37] Batch [560]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.103434,	
2017-07-31 19:57:05,917 Epoch[37] Batch [570]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.103360,	
2017-07-31 19:57:10,228 Epoch[37] Batch [580]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.103434,	
2017-07-31 19:57:14,590 Epoch[37] Batch [590]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.103445,	
2017-07-31 19:57:18,971 Epoch[37] Batch [600]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.103454,	
2017-07-31 19:57:23,289 Epoch[37] Batch [610]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.103540,	
2017-07-31 19:57:27,626 Epoch[37] Batch [620]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.103498,	
2017-07-31 19:57:31,998 Epoch[37] Batch [630]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.103309,	
2017-07-31 19:57:36,340 Epoch[37] Batch [640]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.103248,	
2017-07-31 19:57:40,733 Epoch[37] Batch [650]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.103103,	
2017-07-31 19:57:45,010 Epoch[37] Batch [660]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103170,	
2017-07-31 19:57:49,366 Epoch[37] Batch [670]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.103098,	
2017-07-31 19:57:53,727 Epoch[37] Batch [680]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.103231,	
2017-07-31 19:57:58,006 Epoch[37] Batch [690]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103366,	
2017-07-31 19:58:02,431 Epoch[37] Batch [700]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.103362,	
2017-07-31 19:58:06,803 Epoch[37] Batch [710]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.103334,	
2017-07-31 19:58:11,147 Epoch[37] Batch [720]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.103331,	
2017-07-31 19:58:15,469 Epoch[37] Batch [730]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.103362,	
2017-07-31 19:58:19,787 Epoch[37] Batch [740]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.103217,	
2017-07-31 19:58:24,213 Epoch[37] Batch [750]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.103336,	
2017-07-31 19:58:28,668 Epoch[37] Batch [760]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.103235,	
2017-07-31 19:58:32,855 Epoch[37] Batch [770]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.103101,	
2017-07-31 19:58:37,083 Epoch[37] Batch [780]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.103152,	
2017-07-31 19:58:41,448 Epoch[37] Batch [790]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.103002,	
2017-07-31 19:58:45,829 Epoch[37] Batch [800]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.103062,	
2017-07-31 19:58:50,171 Epoch[37] Batch [810]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.102999,	
2017-07-31 19:58:54,571 Epoch[37] Batch [820]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.102866,	
2017-07-31 19:58:58,929 Epoch[37] Batch [830]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.102778,	
2017-07-31 19:59:03,314 Epoch[37] Batch [840]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.102913,	
2017-07-31 19:59:07,674 Epoch[37] Batch [850]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.102962,	
2017-07-31 19:59:12,045 Epoch[37] Batch [860]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.102932,	
2017-07-31 19:59:16,269 Epoch[37] Batch [870]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.102952,	
2017-07-31 19:59:20,714 Epoch[37] Batch [880]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.102962,	
2017-07-31 19:59:25,184 Epoch[37] Batch [890]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.102948,	
2017-07-31 19:59:29,453 Epoch[37] Batch [900]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.102944,	
2017-07-31 19:59:33,827 Epoch[37] Batch [910]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.102957,	
2017-07-31 19:59:38,166 Epoch[37] Batch [920]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.102879,	
2017-07-31 19:59:42,731 Epoch[37] Batch [930]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.102853,	
2017-07-31 19:59:47,061 Epoch[37] Batch [940]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.102952,	
2017-07-31 19:59:51,394 Epoch[37] Batch [950]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.103047,	
2017-07-31 19:59:55,788 Epoch[37] Batch [960]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.103203,	
2017-07-31 20:00:00,092 Epoch[37] Batch [970]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.103201,	
2017-07-31 20:00:04,435 Epoch[37] Batch [980]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.103088,	
2017-07-31 20:00:08,830 Epoch[37] Batch [990]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.103179,	
2017-07-31 20:00:13,118 Epoch[37] Batch [1000]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.103082,	
2017-07-31 20:00:17,540 Epoch[37] Batch [1010]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.103215,	
2017-07-31 20:00:22,068 Epoch[37] Batch [1020]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.103500,	
2017-07-31 20:00:26,412 Epoch[37] Batch [1030]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.103575,	
2017-07-31 20:00:30,856 Epoch[37] Batch [1040]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.103736,	
2017-07-31 20:00:35,333 Epoch[37] Batch [1050]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.103713,	
2017-07-31 20:00:39,592 Epoch[37] Batch [1060]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.103644,	
2017-07-31 20:00:44,034 Epoch[37] Batch [1070]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.103617,	
2017-07-31 20:00:48,386 Epoch[37] Batch [1080]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.103576,	
2017-07-31 20:00:52,882 Epoch[37] Batch [1090]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.103629,	
2017-07-31 20:00:57,159 Epoch[37] Batch [1100]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103648,	
2017-07-31 20:01:01,343 Epoch[37] Batch [1110]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.103677,	
2017-07-31 20:01:05,767 Epoch[37] Batch [1120]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.103593,	
2017-07-31 20:01:10,073 Epoch[37] Batch [1130]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.103593,	
2017-07-31 20:01:14,328 Epoch[37] Batch [1140]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.103573,	
2017-07-31 20:01:18,661 Epoch[37] Batch [1150]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.103528,	
2017-07-31 20:01:22,939 Epoch[37] Batch [1160]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103517,	
2017-07-31 20:01:27,253 Epoch[37] Batch [1170]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.103409,	
2017-07-31 20:01:31,686 Epoch[37] Batch [1180]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.103408,	
2017-07-31 20:01:35,986 Epoch[37] Batch [1190]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.103347,	
2017-07-31 20:01:40,397 Epoch[37] Batch [1200]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.103373,	
2017-07-31 20:01:44,753 Epoch[37] Batch [1210]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.103340,	
2017-07-31 20:01:49,048 Epoch[37] Batch [1220]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.103416,	
2017-07-31 20:01:53,366 Epoch[37] Batch [1230]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.103312,	
2017-07-31 20:01:57,674 Epoch[37] Batch [1240]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.103260,	
2017-07-31 20:02:02,089 Epoch[37] Batch [1250]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103284,	
2017-07-31 20:02:06,430 Epoch[37] Batch [1260]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.103286,	
2017-07-31 20:02:10,824 Epoch[37] Batch [1270]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.103248,	
2017-07-31 20:02:15,318 Epoch[37] Batch [1280]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.103292,	
2017-07-31 20:02:19,664 Epoch[37] Batch [1290]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.103313,	
2017-07-31 20:02:24,040 Epoch[37] Batch [1300]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.103240,	
2017-07-31 20:02:28,458 Epoch[37] Batch [1310]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103200,	
2017-07-31 20:02:32,821 Epoch[37] Batch [1320]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.103135,	
2017-07-31 20:02:37,266 Epoch[37] Batch [1330]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.103165,	
2017-07-31 20:02:41,674 Epoch[37] Batch [1340]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.103224,	
2017-07-31 20:02:46,043 Epoch[37] Batch [1350]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.103233,	
2017-07-31 20:02:50,457 Epoch[37] Batch [1360]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103355,	
2017-07-31 20:02:54,882 Epoch[37] Batch [1370]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.103337,	
2017-07-31 20:02:59,119 Epoch[37] Batch [1380]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.103260,	
2017-07-31 20:03:03,536 Epoch[37] Batch [1390]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103193,	
2017-07-31 20:03:07,809 Epoch[37] Batch [1400]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.103218,	
2017-07-31 20:03:12,160 Epoch[37] Batch [1410]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.103187,	
2017-07-31 20:03:16,643 Epoch[37] Batch [1420]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.103211,	
2017-07-31 20:03:21,087 Epoch[37] Batch [1430]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.103148,	
2017-07-31 20:03:25,386 Epoch[37] Batch [1440]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.103183,	
2017-07-31 20:03:29,776 Epoch[37] Batch [1450]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.103108,	
2017-07-31 20:03:34,255 Epoch[37] Batch [1460]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.103063,	
2017-07-31 20:03:38,673 Epoch[37] Batch [1470]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103047,	
2017-07-31 20:03:43,049 Epoch[37] Batch [1480]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.103032,	
2017-07-31 20:03:45,615 Epoch[37] Train-FCNLogLoss=0.103053
2017-07-31 20:03:45,615 Epoch[37] Time cost=652.627
2017-07-31 20:03:46,317 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.params"
2017-07-31 20:03:47,882 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.states"
2017-07-31 20:03:52,938 Epoch[38] Batch [10]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.100425,	
2017-07-31 20:03:57,182 Epoch[38] Batch [20]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100261,	
2017-07-31 20:04:01,473 Epoch[38] Batch [30]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.099406,	
2017-07-31 20:04:05,894 Epoch[38] Batch [40]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.102979,	
2017-07-31 20:04:10,108 Epoch[38] Batch [50]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.103284,	
2017-07-31 20:04:14,468 Epoch[38] Batch [60]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.102148,	
2017-07-31 20:04:18,767 Epoch[38] Batch [70]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.100999,	
2017-07-31 20:04:23,086 Epoch[38] Batch [80]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.102121,	
2017-07-31 20:04:27,451 Epoch[38] Batch [90]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101284,	
2017-07-31 20:04:31,840 Epoch[38] Batch [100]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.101665,	
2017-07-31 20:04:36,166 Epoch[38] Batch [110]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.100877,	
2017-07-31 20:04:40,511 Epoch[38] Batch [120]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.101060,	
2017-07-31 20:04:44,810 Epoch[38] Batch [130]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.101485,	
2017-07-31 20:04:49,130 Epoch[38] Batch [140]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.102193,	
2017-07-31 20:04:53,445 Epoch[38] Batch [150]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.102318,	
2017-07-31 20:04:57,842 Epoch[38] Batch [160]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.102800,	
2017-07-31 20:05:02,256 Epoch[38] Batch [170]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.102989,	
2017-07-31 20:05:06,645 Epoch[38] Batch [180]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.102835,	
2017-07-31 20:05:10,974 Epoch[38] Batch [190]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.102005,	
2017-07-31 20:05:15,413 Epoch[38] Batch [200]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.101953,	
2017-07-31 20:05:19,847 Epoch[38] Batch [210]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.101679,	
2017-07-31 20:05:24,175 Epoch[38] Batch [220]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.100967,	
2017-07-31 20:05:28,527 Epoch[38] Batch [230]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.100690,	
2017-07-31 20:05:32,926 Epoch[38] Batch [240]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.100988,	
2017-07-31 20:05:37,331 Epoch[38] Batch [250]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.100621,	
2017-07-31 20:05:41,742 Epoch[38] Batch [260]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.100759,	
2017-07-31 20:05:46,093 Epoch[38] Batch [270]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.100736,	
2017-07-31 20:05:50,397 Epoch[38] Batch [280]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.100673,	
2017-07-31 20:05:54,723 Epoch[38] Batch [290]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.100925,	
2017-07-31 20:05:58,962 Epoch[38] Batch [300]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100769,	
2017-07-31 20:06:03,294 Epoch[38] Batch [310]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.100922,	
2017-07-31 20:06:07,637 Epoch[38] Batch [320]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.100899,	
2017-07-31 20:06:11,943 Epoch[38] Batch [330]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.100582,	
2017-07-31 20:06:16,174 Epoch[38] Batch [340]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100247,	
2017-07-31 20:06:20,563 Epoch[38] Batch [350]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.099910,	
2017-07-31 20:06:24,927 Epoch[38] Batch [360]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.099626,	
2017-07-31 20:06:29,323 Epoch[38] Batch [370]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.099941,	
2017-07-31 20:06:33,668 Epoch[38] Batch [380]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.100023,	
2017-07-31 20:06:37,995 Epoch[38] Batch [390]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.099829,	
2017-07-31 20:06:42,409 Epoch[38] Batch [400]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.099956,	
2017-07-31 20:06:46,779 Epoch[38] Batch [410]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.100104,	
2017-07-31 20:06:51,224 Epoch[38] Batch [420]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.099737,	
2017-07-31 20:06:55,701 Epoch[38] Batch [430]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.099603,	
2017-07-31 20:06:59,974 Epoch[38] Batch [440]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.099367,	
2017-07-31 20:07:04,322 Epoch[38] Batch [450]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.099292,	
2017-07-31 20:07:08,734 Epoch[38] Batch [460]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.099505,	
2017-07-31 20:07:13,155 Epoch[38] Batch [470]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.099810,	
2017-07-31 20:07:17,486 Epoch[38] Batch [480]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.099977,	
2017-07-31 20:07:21,871 Epoch[38] Batch [490]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.099954,	
2017-07-31 20:07:26,257 Epoch[38] Batch [500]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.100092,	
2017-07-31 20:07:30,603 Epoch[38] Batch [510]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.099924,	
2017-07-31 20:07:34,951 Epoch[38] Batch [520]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.099878,	
2017-07-31 20:07:39,317 Epoch[38] Batch [530]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.099642,	
2017-07-31 20:07:43,711 Epoch[38] Batch [540]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.099709,	
2017-07-31 20:07:48,301 Epoch[38] Batch [550]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.099637,	
2017-07-31 20:07:52,695 Epoch[38] Batch [560]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.099485,	
2017-07-31 20:07:57,036 Epoch[38] Batch [570]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.099485,	
2017-07-31 20:08:01,354 Epoch[38] Batch [580]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.099417,	
2017-07-31 20:08:05,633 Epoch[38] Batch [590]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.099292,	
2017-07-31 20:08:09,990 Epoch[38] Batch [600]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.099173,	
2017-07-31 20:08:14,173 Epoch[38] Batch [610]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.099211,	
2017-07-31 20:08:18,575 Epoch[38] Batch [620]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.099118,	
2017-07-31 20:08:22,921 Epoch[38] Batch [630]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.099137,	
2017-07-31 20:08:27,258 Epoch[38] Batch [640]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.099237,	
2017-07-31 20:08:31,636 Epoch[38] Batch [650]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.099379,	
2017-07-31 20:08:35,932 Epoch[38] Batch [660]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.099391,	
2017-07-31 20:08:40,339 Epoch[38] Batch [670]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099397,	
2017-07-31 20:08:44,615 Epoch[38] Batch [680]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.099454,	
2017-07-31 20:08:48,902 Epoch[38] Batch [690]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.099396,	
2017-07-31 20:08:53,149 Epoch[38] Batch [700]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.099472,	
2017-07-31 20:08:57,477 Epoch[38] Batch [710]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.099679,	
2017-07-31 20:09:01,787 Epoch[38] Batch [720]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.099675,	
2017-07-31 20:09:06,204 Epoch[38] Batch [730]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.099787,	
2017-07-31 20:09:10,616 Epoch[38] Batch [740]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.099922,	
2017-07-31 20:09:15,060 Epoch[38] Batch [750]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.099868,	
2017-07-31 20:09:19,465 Epoch[38] Batch [760]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099800,	
2017-07-31 20:09:23,942 Epoch[38] Batch [770]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.099992,	
2017-07-31 20:09:28,237 Epoch[38] Batch [780]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.100134,	
2017-07-31 20:09:32,601 Epoch[38] Batch [790]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.100057,	
2017-07-31 20:09:36,915 Epoch[38] Batch [800]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.100010,	
2017-07-31 20:09:41,312 Epoch[38] Batch [810]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.100047,	
2017-07-31 20:09:45,760 Epoch[38] Batch [820]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.100056,	
2017-07-31 20:09:50,150 Epoch[38] Batch [830]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.100099,	
2017-07-31 20:09:54,616 Epoch[38] Batch [840]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.099976,	
2017-07-31 20:09:59,015 Epoch[38] Batch [850]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.100022,	
2017-07-31 20:10:03,366 Epoch[38] Batch [860]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.099941,	
2017-07-31 20:10:07,765 Epoch[38] Batch [870]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.099980,	
2017-07-31 20:10:12,157 Epoch[38] Batch [880]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.099813,	
2017-07-31 20:10:16,435 Epoch[38] Batch [890]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.100073,	
2017-07-31 20:10:20,889 Epoch[38] Batch [900]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.100085,	
2017-07-31 20:10:25,225 Epoch[38] Batch [910]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.100116,	
2017-07-31 20:10:29,546 Epoch[38] Batch [920]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.100112,	
2017-07-31 20:10:33,778 Epoch[38] Batch [930]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.100151,	
2017-07-31 20:10:38,194 Epoch[38] Batch [940]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.100137,	
2017-07-31 20:10:42,446 Epoch[38] Batch [950]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.100122,	
2017-07-31 20:10:46,841 Epoch[38] Batch [960]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.100153,	
2017-07-31 20:10:51,251 Epoch[38] Batch [970]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.100211,	
2017-07-31 20:10:55,597 Epoch[38] Batch [980]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.100142,	
2017-07-31 20:10:59,922 Epoch[38] Batch [990]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.100096,	
2017-07-31 20:11:04,262 Epoch[38] Batch [1000]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.100164,	
2017-07-31 20:11:08,625 Epoch[38] Batch [1010]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.100247,	
2017-07-31 20:11:12,948 Epoch[38] Batch [1020]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.100305,	
2017-07-31 20:11:17,363 Epoch[38] Batch [1030]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.100312,	
2017-07-31 20:11:21,607 Epoch[38] Batch [1040]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100250,	
2017-07-31 20:11:25,981 Epoch[38] Batch [1050]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.100220,	
2017-07-31 20:11:30,418 Epoch[38] Batch [1060]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.100155,	
2017-07-31 20:11:34,713 Epoch[38] Batch [1070]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.100125,	
2017-07-31 20:11:39,179 Epoch[38] Batch [1080]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.100097,	
2017-07-31 20:11:43,497 Epoch[38] Batch [1090]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.100145,	
2017-07-31 20:11:47,897 Epoch[38] Batch [1100]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.100263,	
2017-07-31 20:11:52,176 Epoch[38] Batch [1110]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.100254,	
2017-07-31 20:11:56,414 Epoch[38] Batch [1120]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100291,	
2017-07-31 20:12:00,981 Epoch[38] Batch [1130]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.100301,	
2017-07-31 20:12:05,267 Epoch[38] Batch [1140]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.100362,	
2017-07-31 20:12:09,585 Epoch[38] Batch [1150]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.100286,	
2017-07-31 20:12:13,980 Epoch[38] Batch [1160]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.100249,	
2017-07-31 20:12:18,273 Epoch[38] Batch [1170]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.100248,	
2017-07-31 20:12:22,576 Epoch[38] Batch [1180]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.100156,	
2017-07-31 20:12:26,917 Epoch[38] Batch [1190]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.100157,	
2017-07-31 20:12:31,221 Epoch[38] Batch [1200]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.100193,	
2017-07-31 20:12:35,516 Epoch[38] Batch [1210]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.100268,	
2017-07-31 20:12:39,917 Epoch[38] Batch [1220]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.100314,	
2017-07-31 20:12:44,224 Epoch[38] Batch [1230]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.100312,	
2017-07-31 20:12:48,654 Epoch[38] Batch [1240]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.100363,	
2017-07-31 20:12:52,968 Epoch[38] Batch [1250]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.100427,	
2017-07-31 20:12:57,350 Epoch[38] Batch [1260]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.100419,	
2017-07-31 20:13:01,751 Epoch[38] Batch [1270]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.100530,	
2017-07-31 20:13:06,007 Epoch[38] Batch [1280]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.100490,	
2017-07-31 20:13:10,502 Epoch[38] Batch [1290]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.100543,	
2017-07-31 20:13:14,995 Epoch[38] Batch [1300]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.100551,	
2017-07-31 20:13:19,211 Epoch[38] Batch [1310]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.100586,	
2017-07-31 20:13:23,644 Epoch[38] Batch [1320]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.100591,	
2017-07-31 20:13:28,023 Epoch[38] Batch [1330]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.100687,	
2017-07-31 20:13:32,224 Epoch[38] Batch [1340]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.100737,	
2017-07-31 20:13:36,451 Epoch[38] Batch [1350]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.100715,	
2017-07-31 20:13:40,870 Epoch[38] Batch [1360]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.100721,	
2017-07-31 20:13:45,290 Epoch[38] Batch [1370]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.100758,	
2017-07-31 20:13:49,667 Epoch[38] Batch [1380]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.100755,	
2017-07-31 20:13:54,066 Epoch[38] Batch [1390]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.100705,	
2017-07-31 20:13:58,600 Epoch[38] Batch [1400]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.100676,	
2017-07-31 20:14:02,920 Epoch[38] Batch [1410]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.100650,	
2017-07-31 20:14:07,297 Epoch[38] Batch [1420]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.100621,	
2017-07-31 20:14:11,622 Epoch[38] Batch [1430]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.100555,	
2017-07-31 20:14:15,916 Epoch[38] Batch [1440]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.100514,	
2017-07-31 20:14:20,211 Epoch[38] Batch [1450]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.100401,	
2017-07-31 20:14:24,516 Epoch[38] Batch [1460]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.100406,	
2017-07-31 20:14:28,893 Epoch[38] Batch [1470]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.100322,	
2017-07-31 20:14:33,093 Epoch[38] Batch [1480]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.100238,	
2017-07-31 20:14:35,767 Epoch[38] Train-FCNLogLoss=0.100194
2017-07-31 20:14:35,768 Epoch[38] Time cost=647.885
2017-07-31 20:14:36,435 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.params"
2017-07-31 20:14:37,955 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.states"
2017-07-31 20:14:42,820 Epoch[39] Batch [10]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.098278,	
2017-07-31 20:14:47,171 Epoch[39] Batch [20]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.091529,	
2017-07-31 20:14:51,508 Epoch[39] Batch [30]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.092209,	
2017-07-31 20:14:55,704 Epoch[39] Batch [40]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.093919,	
2017-07-31 20:15:00,129 Epoch[39] Batch [50]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.093450,	
2017-07-31 20:15:04,453 Epoch[39] Batch [60]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.093064,	
2017-07-31 20:15:08,841 Epoch[39] Batch [70]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.093970,	
2017-07-31 20:15:13,215 Epoch[39] Batch [80]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.093347,	
2017-07-31 20:15:17,550 Epoch[39] Batch [90]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.094071,	
2017-07-31 20:15:21,851 Epoch[39] Batch [100]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.093543,	
2017-07-31 20:15:26,191 Epoch[39] Batch [110]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.094210,	
2017-07-31 20:15:30,589 Epoch[39] Batch [120]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.093364,	
2017-07-31 20:15:35,014 Epoch[39] Batch [130]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.093591,	
2017-07-31 20:15:39,311 Epoch[39] Batch [140]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.093536,	
2017-07-31 20:15:43,678 Epoch[39] Batch [150]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.094151,	
2017-07-31 20:15:48,113 Epoch[39] Batch [160]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.095227,	
2017-07-31 20:15:52,458 Epoch[39] Batch [170]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.094783,	
2017-07-31 20:15:56,736 Epoch[39] Batch [180]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095030,	
2017-07-31 20:16:00,964 Epoch[39] Batch [190]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.095630,	
2017-07-31 20:16:05,285 Epoch[39] Batch [200]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096155,	
2017-07-31 20:16:09,692 Epoch[39] Batch [210]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.096323,	
2017-07-31 20:16:14,192 Epoch[39] Batch [220]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.096147,	
2017-07-31 20:16:18,581 Epoch[39] Batch [230]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.096179,	
2017-07-31 20:16:22,881 Epoch[39] Batch [240]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.096459,	
2017-07-31 20:16:27,271 Epoch[39] Batch [250]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.096801,	
2017-07-31 20:16:31,521 Epoch[39] Batch [260]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.097143,	
2017-07-31 20:16:35,888 Epoch[39] Batch [270]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.097675,	
2017-07-31 20:16:40,288 Epoch[39] Batch [280]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098393,	
2017-07-31 20:16:44,681 Epoch[39] Batch [290]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097977,	
2017-07-31 20:16:48,957 Epoch[39] Batch [300]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097846,	
2017-07-31 20:16:53,336 Epoch[39] Batch [310]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.097892,	
2017-07-31 20:16:57,601 Epoch[39] Batch [320]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.097743,	
2017-07-31 20:17:01,950 Epoch[39] Batch [330]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.097768,	
2017-07-31 20:17:06,209 Epoch[39] Batch [340]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.098060,	
2017-07-31 20:17:10,533 Epoch[39] Batch [350]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.097985,	
2017-07-31 20:17:14,855 Epoch[39] Batch [360]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097940,	
2017-07-31 20:17:19,125 Epoch[39] Batch [370]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.097889,	
2017-07-31 20:17:23,263 Epoch[39] Batch [380]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097674,	
2017-07-31 20:17:27,599 Epoch[39] Batch [390]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097639,	
2017-07-31 20:17:31,923 Epoch[39] Batch [400]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.097623,	
2017-07-31 20:17:36,213 Epoch[39] Batch [410]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.097463,	
2017-07-31 20:17:40,609 Epoch[39] Batch [420]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.097383,	
2017-07-31 20:17:44,911 Epoch[39] Batch [430]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.097507,	
2017-07-31 20:17:49,126 Epoch[39] Batch [440]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.097521,	
2017-07-31 20:17:53,476 Epoch[39] Batch [450]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.097564,	
2017-07-31 20:17:57,759 Epoch[39] Batch [460]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.098028,	
2017-07-31 20:18:01,829 Epoch[39] Batch [470]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.098443,	
2017-07-31 20:18:05,801 Epoch[39] Batch [480]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.098691,	
2017-07-31 20:18:10,061 Epoch[39] Batch [490]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.098504,	
2017-07-31 20:18:14,196 Epoch[39] Batch [500]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.098599,	
2017-07-31 20:18:18,449 Epoch[39] Batch [510]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.098694,	
2017-07-31 20:18:23,067 Epoch[39] Batch [520]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.098929,	
2017-07-31 20:18:27,220 Epoch[39] Batch [530]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.098839,	
2017-07-31 20:18:31,433 Epoch[39] Batch [540]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.098654,	
2017-07-31 20:18:35,469 Epoch[39] Batch [550]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.098600,	
2017-07-31 20:18:39,641 Epoch[39] Batch [560]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.098485,	
2017-07-31 20:18:43,825 Epoch[39] Batch [570]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.098352,	
2017-07-31 20:18:48,032 Epoch[39] Batch [580]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.098451,	
2017-07-31 20:18:52,325 Epoch[39] Batch [590]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.098298,	
2017-07-31 20:18:56,575 Epoch[39] Batch [600]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.098164,	
2017-07-31 20:19:00,764 Epoch[39] Batch [610]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098288,	
2017-07-31 20:19:04,981 Epoch[39] Batch [620]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.098329,	
2017-07-31 20:19:09,280 Epoch[39] Batch [630]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.098221,	
2017-07-31 20:19:13,628 Epoch[39] Batch [640]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.098453,	
2017-07-31 20:19:17,833 Epoch[39] Batch [650]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.098517,	
2017-07-31 20:19:21,997 Epoch[39] Batch [660]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.098468,	
2017-07-31 20:19:26,198 Epoch[39] Batch [670]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.098281,	
2017-07-31 20:19:30,575 Epoch[39] Batch [680]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.098253,	
2017-07-31 20:19:34,656 Epoch[39] Batch [690]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.098166,	
2017-07-31 20:19:38,767 Epoch[39] Batch [700]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.098197,	
2017-07-31 20:19:42,958 Epoch[39] Batch [710]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.098209,	
2017-07-31 20:19:47,101 Epoch[39] Batch [720]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.098036,	
2017-07-31 20:19:51,255 Epoch[39] Batch [730]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.098110,	
2017-07-31 20:19:55,427 Epoch[39] Batch [740]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.098114,	
2017-07-31 20:19:59,628 Epoch[39] Batch [750]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.098263,	
2017-07-31 20:20:03,831 Epoch[39] Batch [760]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.098209,	
2017-07-31 20:20:07,869 Epoch[39] Batch [770]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.098190,	
2017-07-31 20:20:11,957 Epoch[39] Batch [780]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.098286,	
2017-07-31 20:20:16,016 Epoch[39] Batch [790]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098328,	
2017-07-31 20:20:20,135 Epoch[39] Batch [800]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.098268,	
2017-07-31 20:20:24,385 Epoch[39] Batch [810]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.098234,	
2017-07-31 20:20:28,566 Epoch[39] Batch [820]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.098224,	
2017-07-31 20:20:32,754 Epoch[39] Batch [830]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098113,	
2017-07-31 20:20:37,001 Epoch[39] Batch [840]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.098057,	
2017-07-31 20:20:41,421 Epoch[39] Batch [850]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.098041,	
2017-07-31 20:20:45,611 Epoch[39] Batch [860]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098026,	
2017-07-31 20:20:49,705 Epoch[39] Batch [870]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097979,	
2017-07-31 20:20:53,819 Epoch[39] Batch [880]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097895,	
2017-07-31 20:20:57,906 Epoch[39] Batch [890]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.097813,	
2017-07-31 20:21:02,067 Epoch[39] Batch [900]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.097775,	
2017-07-31 20:21:06,187 Epoch[39] Batch [910]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097671,	
2017-07-31 20:21:10,254 Epoch[39] Batch [920]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.097619,	
2017-07-31 20:21:14,435 Epoch[39] Batch [930]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097467,	
2017-07-31 20:21:18,468 Epoch[39] Batch [940]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.097554,	
2017-07-31 20:21:22,517 Epoch[39] Batch [950]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097642,	
2017-07-31 20:21:26,669 Epoch[39] Batch [960]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.097650,	
2017-07-31 20:21:30,713 Epoch[39] Batch [970]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.097661,	
2017-07-31 20:21:34,784 Epoch[39] Batch [980]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.097700,	
2017-07-31 20:21:38,913 Epoch[39] Batch [990]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097651,	
2017-07-31 20:21:42,963 Epoch[39] Batch [1000]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097684,	
2017-07-31 20:21:47,023 Epoch[39] Batch [1010]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097687,	
2017-07-31 20:21:51,104 Epoch[39] Batch [1020]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.097645,	
2017-07-31 20:21:55,137 Epoch[39] Batch [1030]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.097615,	
2017-07-31 20:21:59,123 Epoch[39] Batch [1040]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.097631,	
2017-07-31 20:22:03,259 Epoch[39] Batch [1050]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097591,	
2017-07-31 20:22:07,334 Epoch[39] Batch [1060]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.097545,	
2017-07-31 20:22:11,332 Epoch[39] Batch [1070]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.097664,	
2017-07-31 20:22:15,380 Epoch[39] Batch [1080]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097746,	
2017-07-31 20:22:19,550 Epoch[39] Batch [1090]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097689,	
2017-07-31 20:22:23,581 Epoch[39] Batch [1100]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.097670,	
2017-07-31 20:22:27,693 Epoch[39] Batch [1110]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.097559,	
2017-07-31 20:22:31,811 Epoch[39] Batch [1120]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.097619,	
2017-07-31 20:22:35,791 Epoch[39] Batch [1130]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.097664,	
2017-07-31 20:22:39,852 Epoch[39] Batch [1140]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097764,	
2017-07-31 20:22:43,942 Epoch[39] Batch [1150]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.097714,	
2017-07-31 20:22:47,949 Epoch[39] Batch [1160]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.097605,	
2017-07-31 20:22:52,008 Epoch[39] Batch [1170]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.097587,	
2017-07-31 20:22:56,017 Epoch[39] Batch [1180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.097634,	
2017-07-31 20:23:00,078 Epoch[39] Batch [1190]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097603,	
2017-07-31 20:23:04,083 Epoch[39] Batch [1200]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097552,	
2017-07-31 20:23:08,007 Epoch[39] Batch [1210]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.097593,	
2017-07-31 20:23:12,089 Epoch[39] Batch [1220]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.097599,	
2017-07-31 20:23:16,082 Epoch[39] Batch [1230]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.097585,	
2017-07-31 20:23:20,162 Epoch[39] Batch [1240]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.097537,	
2017-07-31 20:23:24,166 Epoch[39] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097568,	
2017-07-31 20:23:28,175 Epoch[39] Batch [1260]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.097571,	
2017-07-31 20:23:32,225 Epoch[39] Batch [1270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097606,	
2017-07-31 20:23:36,226 Epoch[39] Batch [1280]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.097611,	
2017-07-31 20:23:40,212 Epoch[39] Batch [1290]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.097615,	
2017-07-31 20:23:44,341 Epoch[39] Batch [1300]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097575,	
2017-07-31 20:23:48,371 Epoch[39] Batch [1310]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.097519,	
2017-07-31 20:23:52,305 Epoch[39] Batch [1320]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.097519,	
2017-07-31 20:23:56,357 Epoch[39] Batch [1330]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.097674,	
2017-07-31 20:24:00,484 Epoch[39] Batch [1340]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097657,	
2017-07-31 20:24:04,616 Epoch[39] Batch [1350]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097742,	
2017-07-31 20:24:08,671 Epoch[39] Batch [1360]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.097689,	
2017-07-31 20:24:12,721 Epoch[39] Batch [1370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097743,	
2017-07-31 20:24:16,846 Epoch[39] Batch [1380]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.097795,	
2017-07-31 20:24:20,945 Epoch[39] Batch [1390]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097720,	
2017-07-31 20:24:24,935 Epoch[39] Batch [1400]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.097737,	
2017-07-31 20:24:28,973 Epoch[39] Batch [1410]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097688,	
2017-07-31 20:24:33,044 Epoch[39] Batch [1420]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.097697,	
2017-07-31 20:24:37,153 Epoch[39] Batch [1430]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.097701,	
2017-07-31 20:24:41,212 Epoch[39] Batch [1440]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.097702,	
2017-07-31 20:24:45,173 Epoch[39] Batch [1450]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.097729,	
2017-07-31 20:24:49,244 Epoch[39] Batch [1460]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.097770,	
2017-07-31 20:24:53,319 Epoch[39] Batch [1470]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.097705,	
2017-07-31 20:24:57,452 Epoch[39] Batch [1480]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097739,	
2017-07-31 20:24:59,881 Epoch[39] Train-FCNLogLoss=0.097738
2017-07-31 20:24:59,881 Epoch[39] Time cost=621.926
2017-07-31 20:25:00,558 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.params"
2017-07-31 20:25:02,140 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.states"
2017-07-31 20:25:06,835 Epoch[40] Batch [10]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111514,	
2017-07-31 20:25:11,044 Epoch[40] Batch [20]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.108352,	
2017-07-31 20:25:15,083 Epoch[40] Batch [30]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105809,	
2017-07-31 20:25:19,025 Epoch[40] Batch [40]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.101178,	
2017-07-31 20:25:23,060 Epoch[40] Batch [50]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103080,	
2017-07-31 20:25:27,059 Epoch[40] Batch [60]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.102185,	
2017-07-31 20:25:31,066 Epoch[40] Batch [70]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.101193,	
2017-07-31 20:25:35,113 Epoch[40] Batch [80]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101518,	
2017-07-31 20:25:39,256 Epoch[40] Batch [90]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.101513,	
2017-07-31 20:25:43,281 Epoch[40] Batch [100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.101642,	
2017-07-31 20:25:47,313 Epoch[40] Batch [110]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100312,	
2017-07-31 20:25:51,330 Epoch[40] Batch [120]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.100263,	
2017-07-31 20:25:55,338 Epoch[40] Batch [130]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.100466,	
2017-07-31 20:25:59,265 Epoch[40] Batch [140]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.101163,	
2017-07-31 20:26:03,226 Epoch[40] Batch [150]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.100989,	
2017-07-31 20:26:07,322 Epoch[40] Batch [160]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101506,	
2017-07-31 20:26:11,312 Epoch[40] Batch [170]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.101404,	
2017-07-31 20:26:15,332 Epoch[40] Batch [180]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.101004,	
2017-07-31 20:26:19,386 Epoch[40] Batch [190]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.100558,	
2017-07-31 20:26:23,375 Epoch[40] Batch [200]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.100671,	
2017-07-31 20:26:27,323 Epoch[40] Batch [210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.100766,	
2017-07-31 20:26:31,335 Epoch[40] Batch [220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.100482,	
2017-07-31 20:26:35,300 Epoch[40] Batch [230]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.100764,	
2017-07-31 20:26:39,293 Epoch[40] Batch [240]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.100743,	
2017-07-31 20:26:43,155 Epoch[40] Batch [250]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.100703,	
2017-07-31 20:26:47,110 Epoch[40] Batch [260]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.100315,	
2017-07-31 20:26:51,102 Epoch[40] Batch [270]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.100034,	
2017-07-31 20:26:55,063 Epoch[40] Batch [280]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.100030,	
2017-07-31 20:26:59,034 Epoch[40] Batch [290]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.100126,	
2017-07-31 20:27:02,971 Epoch[40] Batch [300]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.099989,	
2017-07-31 20:27:06,898 Epoch[40] Batch [310]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.099999,	
2017-07-31 20:27:10,815 Epoch[40] Batch [320]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.099703,	
2017-07-31 20:27:14,755 Epoch[40] Batch [330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.099684,	
2017-07-31 20:27:18,679 Epoch[40] Batch [340]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.099673,	
2017-07-31 20:27:22,703 Epoch[40] Batch [350]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.099440,	
2017-07-31 20:27:26,708 Epoch[40] Batch [360]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.099618,	
2017-07-31 20:27:30,650 Epoch[40] Batch [370]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.099433,	
2017-07-31 20:27:34,528 Epoch[40] Batch [380]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.099453,	
2017-07-31 20:27:38,564 Epoch[40] Batch [390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.099284,	
2017-07-31 20:27:42,638 Epoch[40] Batch [400]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.099242,	
2017-07-31 20:27:46,624 Epoch[40] Batch [410]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.099053,	
2017-07-31 20:27:50,712 Epoch[40] Batch [420]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.099126,	
2017-07-31 20:27:54,620 Epoch[40] Batch [430]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.099158,	
2017-07-31 20:27:58,649 Epoch[40] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.099326,	
2017-07-31 20:28:02,640 Epoch[40] Batch [450]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.099462,	
2017-07-31 20:28:06,583 Epoch[40] Batch [460]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.099434,	
2017-07-31 20:28:10,504 Epoch[40] Batch [470]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.099384,	
2017-07-31 20:28:14,438 Epoch[40] Batch [480]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.099214,	
2017-07-31 20:28:18,350 Epoch[40] Batch [490]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.099118,	
2017-07-31 20:28:22,229 Epoch[40] Batch [500]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.098867,	
2017-07-31 20:28:26,002 Epoch[40] Batch [510]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.098831,	
2017-07-31 20:28:29,237 Update[60000]: Change learning rate to 5.00000e-05
2017-07-31 20:28:29,882 Epoch[40] Batch [520]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.098497,	
2017-07-31 20:28:33,757 Epoch[40] Batch [530]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.098251,	
2017-07-31 20:28:37,606 Epoch[40] Batch [540]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.098151,	
2017-07-31 20:28:41,421 Epoch[40] Batch [550]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.098188,	
2017-07-31 20:28:45,254 Epoch[40] Batch [560]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.098150,	
2017-07-31 20:28:49,131 Epoch[40] Batch [570]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.098016,	
2017-07-31 20:28:53,171 Epoch[40] Batch [580]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.097961,	
2017-07-31 20:28:57,078 Epoch[40] Batch [590]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.098065,	
2017-07-31 20:29:01,032 Epoch[40] Batch [600]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.098000,	
2017-07-31 20:29:04,895 Epoch[40] Batch [610]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.098113,	
2017-07-31 20:29:08,818 Epoch[40] Batch [620]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.098157,	
2017-07-31 20:29:12,667 Epoch[40] Batch [630]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.097951,	
2017-07-31 20:29:16,610 Epoch[40] Batch [640]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.098036,	
2017-07-31 20:29:20,481 Epoch[40] Batch [650]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.097703,	
2017-07-31 20:29:24,319 Epoch[40] Batch [660]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.097522,	
2017-07-31 20:29:28,182 Epoch[40] Batch [670]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.097406,	
2017-07-31 20:29:32,059 Epoch[40] Batch [680]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.097405,	
2017-07-31 20:29:35,981 Epoch[40] Batch [690]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.097259,	
2017-07-31 20:29:39,840 Epoch[40] Batch [700]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.097032,	
2017-07-31 20:29:43,765 Epoch[40] Batch [710]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.097127,	
2017-07-31 20:29:47,688 Epoch[40] Batch [720]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.097056,	
2017-07-31 20:29:51,617 Epoch[40] Batch [730]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096951,	
2017-07-31 20:29:55,529 Epoch[40] Batch [740]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.096940,	
2017-07-31 20:29:59,418 Epoch[40] Batch [750]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.096868,	
2017-07-31 20:30:03,282 Epoch[40] Batch [760]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.096898,	
2017-07-31 20:30:07,182 Epoch[40] Batch [770]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.096855,	
2017-07-31 20:30:11,027 Epoch[40] Batch [780]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.096917,	
2017-07-31 20:30:14,939 Epoch[40] Batch [790]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.096839,	
2017-07-31 20:30:18,856 Epoch[40] Batch [800]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.096811,	
2017-07-31 20:30:22,763 Epoch[40] Batch [810]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.096751,	
2017-07-31 20:30:26,634 Epoch[40] Batch [820]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.096745,	
2017-07-31 20:30:30,486 Epoch[40] Batch [830]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.096613,	
2017-07-31 20:30:34,383 Epoch[40] Batch [840]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.096609,	
2017-07-31 20:30:38,254 Epoch[40] Batch [850]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.096752,	
2017-07-31 20:30:42,096 Epoch[40] Batch [860]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.096725,	
2017-07-31 20:30:45,901 Epoch[40] Batch [870]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.096749,	
2017-07-31 20:30:49,715 Epoch[40] Batch [880]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.096644,	
2017-07-31 20:30:53,677 Epoch[40] Batch [890]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096560,	
2017-07-31 20:30:57,575 Epoch[40] Batch [900]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.096622,	
2017-07-31 20:31:01,402 Epoch[40] Batch [910]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.096666,	
2017-07-31 20:31:05,388 Epoch[40] Batch [920]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.096677,	
2017-07-31 20:31:09,301 Epoch[40] Batch [930]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.096685,	
2017-07-31 20:31:13,211 Epoch[40] Batch [940]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.096580,	
2017-07-31 20:31:17,120 Epoch[40] Batch [950]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.096487,	
2017-07-31 20:31:21,031 Epoch[40] Batch [960]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.096534,	
2017-07-31 20:31:24,931 Epoch[40] Batch [970]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.096575,	
2017-07-31 20:31:28,786 Epoch[40] Batch [980]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.096512,	
2017-07-31 20:31:32,622 Epoch[40] Batch [990]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.096494,	
2017-07-31 20:31:36,521 Epoch[40] Batch [1000]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.096543,	
2017-07-31 20:31:40,394 Epoch[40] Batch [1010]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.096448,	
2017-07-31 20:31:44,278 Epoch[40] Batch [1020]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.096417,	
2017-07-31 20:31:48,147 Epoch[40] Batch [1030]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.096390,	
2017-07-31 20:31:52,013 Epoch[40] Batch [1040]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.096366,	
2017-07-31 20:31:55,887 Epoch[40] Batch [1050]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.096306,	
2017-07-31 20:31:59,845 Epoch[40] Batch [1060]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096286,	
2017-07-31 20:32:03,845 Epoch[40] Batch [1070]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.096253,	
2017-07-31 20:32:07,735 Epoch[40] Batch [1080]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.096255,	
2017-07-31 20:32:11,660 Epoch[40] Batch [1090]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.096325,	
2017-07-31 20:32:15,627 Epoch[40] Batch [1100]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.096192,	
2017-07-31 20:32:19,532 Epoch[40] Batch [1110]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.096154,	
2017-07-31 20:32:23,466 Epoch[40] Batch [1120]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096155,	
2017-07-31 20:32:27,266 Epoch[40] Batch [1130]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.096227,	
2017-07-31 20:32:31,171 Epoch[40] Batch [1140]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.096195,	
2017-07-31 20:32:35,076 Epoch[40] Batch [1150]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.096269,	
2017-07-31 20:32:39,006 Epoch[40] Batch [1160]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096273,	
2017-07-31 20:32:42,777 Epoch[40] Batch [1170]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.096271,	
2017-07-31 20:32:46,636 Epoch[40] Batch [1180]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.096303,	
2017-07-31 20:32:50,569 Epoch[40] Batch [1190]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096186,	
2017-07-31 20:32:54,443 Epoch[40] Batch [1200]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.096289,	
2017-07-31 20:32:58,350 Epoch[40] Batch [1210]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.096212,	
2017-07-31 20:33:02,254 Epoch[40] Batch [1220]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.096215,	
2017-07-31 20:33:06,143 Epoch[40] Batch [1230]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.096261,	
2017-07-31 20:33:10,038 Epoch[40] Batch [1240]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.096320,	
2017-07-31 20:33:13,902 Epoch[40] Batch [1250]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.096310,	
2017-07-31 20:33:17,816 Epoch[40] Batch [1260]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.096294,	
2017-07-31 20:33:21,715 Epoch[40] Batch [1270]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.096312,	
2017-07-31 20:33:25,687 Epoch[40] Batch [1280]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.096350,	
2017-07-31 20:33:29,567 Epoch[40] Batch [1290]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.096255,	
2017-07-31 20:33:33,486 Epoch[40] Batch [1300]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.096279,	
2017-07-31 20:33:37,341 Epoch[40] Batch [1310]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.096234,	
2017-07-31 20:33:41,260 Epoch[40] Batch [1320]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.096213,	
2017-07-31 20:33:45,145 Epoch[40] Batch [1330]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.096174,	
2017-07-31 20:33:49,074 Epoch[40] Batch [1340]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096222,	
2017-07-31 20:33:53,061 Epoch[40] Batch [1350]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.096161,	
2017-07-31 20:33:57,020 Epoch[40] Batch [1360]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096161,	
2017-07-31 20:34:00,876 Epoch[40] Batch [1370]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.096110,	
2017-07-31 20:34:04,831 Epoch[40] Batch [1380]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.096124,	
2017-07-31 20:34:08,716 Epoch[40] Batch [1390]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.096108,	
2017-07-31 20:34:12,579 Epoch[40] Batch [1400]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.096203,	
2017-07-31 20:34:16,559 Epoch[40] Batch [1410]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.096389,	
2017-07-31 20:34:20,489 Epoch[40] Batch [1420]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096539,	
2017-07-31 20:34:24,384 Epoch[40] Batch [1430]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.096507,	
2017-07-31 20:34:28,315 Epoch[40] Batch [1440]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096425,	
2017-07-31 20:34:32,176 Epoch[40] Batch [1450]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.096491,	
2017-07-31 20:34:36,072 Epoch[40] Batch [1460]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.096526,	
2017-07-31 20:34:40,021 Epoch[40] Batch [1470]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.096518,	
2017-07-31 20:34:43,943 Epoch[40] Batch [1480]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.096568,	
2017-07-31 20:34:46,229 Epoch[40] Train-FCNLogLoss=0.096613
2017-07-31 20:34:46,229 Epoch[40] Time cost=584.089
2017-07-31 20:34:46,912 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.params"
2017-07-31 20:34:48,470 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.states"
2017-07-31 20:34:53,105 Epoch[41] Batch [10]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.098572,	
2017-07-31 20:34:56,953 Epoch[41] Batch [20]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.098904,	
2017-07-31 20:35:00,837 Epoch[41] Batch [30]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.098742,	
2017-07-31 20:35:04,721 Epoch[41] Batch [40]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.095233,	
2017-07-31 20:35:08,615 Epoch[41] Batch [50]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094647,	
2017-07-31 20:35:12,447 Epoch[41] Batch [60]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.095813,	
2017-07-31 20:35:16,352 Epoch[41] Batch [70]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093453,	
2017-07-31 20:35:20,336 Epoch[41] Batch [80]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.092121,	
2017-07-31 20:35:24,253 Epoch[41] Batch [90]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.092214,	
2017-07-31 20:35:28,189 Epoch[41] Batch [100]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.091359,	
2017-07-31 20:35:32,159 Epoch[41] Batch [110]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.092837,	
2017-07-31 20:35:36,091 Epoch[41] Batch [120]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.092527,	
2017-07-31 20:35:39,979 Epoch[41] Batch [130]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092505,	
2017-07-31 20:35:43,929 Epoch[41] Batch [140]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.092221,	
2017-07-31 20:35:47,854 Epoch[41] Batch [150]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.092179,	
2017-07-31 20:35:51,718 Epoch[41] Batch [160]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093278,	
2017-07-31 20:35:55,547 Epoch[41] Batch [170]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.093041,	
2017-07-31 20:35:59,368 Epoch[41] Batch [180]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.093220,	
2017-07-31 20:36:03,362 Epoch[41] Batch [190]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.093692,	
2017-07-31 20:36:07,152 Epoch[41] Batch [200]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.094020,	
2017-07-31 20:36:11,012 Epoch[41] Batch [210]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093409,	
2017-07-31 20:36:14,933 Epoch[41] Batch [220]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093652,	
2017-07-31 20:36:18,745 Epoch[41] Batch [230]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.093552,	
2017-07-31 20:36:22,770 Epoch[41] Batch [240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.093638,	
2017-07-31 20:36:26,717 Epoch[41] Batch [250]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.093695,	
2017-07-31 20:36:30,593 Epoch[41] Batch [260]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093703,	
2017-07-31 20:36:34,463 Epoch[41] Batch [270]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093972,	
2017-07-31 20:36:38,313 Epoch[41] Batch [280]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.094462,	
2017-07-31 20:36:42,210 Epoch[41] Batch [290]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094087,	
2017-07-31 20:36:46,138 Epoch[41] Batch [300]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094154,	
2017-07-31 20:36:50,088 Epoch[41] Batch [310]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094114,	
2017-07-31 20:36:54,044 Epoch[41] Batch [320]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.093891,	
2017-07-31 20:36:58,010 Epoch[41] Batch [330]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094014,	
2017-07-31 20:37:01,873 Epoch[41] Batch [340]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093903,	
2017-07-31 20:37:05,758 Epoch[41] Batch [350]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094220,	
2017-07-31 20:37:09,715 Epoch[41] Batch [360]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094086,	
2017-07-31 20:37:13,598 Epoch[41] Batch [370]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094026,	
2017-07-31 20:37:17,548 Epoch[41] Batch [380]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094128,	
2017-07-31 20:37:21,466 Epoch[41] Batch [390]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094578,	
2017-07-31 20:37:25,387 Epoch[41] Batch [400]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094391,	
2017-07-31 20:37:29,302 Epoch[41] Batch [410]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.094374,	
2017-07-31 20:37:33,144 Epoch[41] Batch [420]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.094194,	
2017-07-31 20:37:37,120 Epoch[41] Batch [430]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094032,	
2017-07-31 20:37:40,930 Epoch[41] Batch [440]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.094004,	
2017-07-31 20:37:44,877 Epoch[41] Batch [450]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094326,	
2017-07-31 20:37:48,805 Epoch[41] Batch [460]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094293,	
2017-07-31 20:37:52,735 Epoch[41] Batch [470]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094392,	
2017-07-31 20:37:56,669 Epoch[41] Batch [480]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094508,	
2017-07-31 20:38:00,596 Epoch[41] Batch [490]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.094383,	
2017-07-31 20:38:04,476 Epoch[41] Batch [500]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094517,	
2017-07-31 20:38:08,369 Epoch[41] Batch [510]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094486,	
2017-07-31 20:38:12,365 Epoch[41] Batch [520]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094667,	
2017-07-31 20:38:16,349 Epoch[41] Batch [530]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094437,	
2017-07-31 20:38:20,264 Epoch[41] Batch [540]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.094408,	
2017-07-31 20:38:24,130 Epoch[41] Batch [550]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.094319,	
2017-07-31 20:38:28,063 Epoch[41] Batch [560]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094204,	
2017-07-31 20:38:32,003 Epoch[41] Batch [570]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094174,	
2017-07-31 20:38:35,910 Epoch[41] Batch [580]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094037,	
2017-07-31 20:38:39,795 Epoch[41] Batch [590]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094055,	
2017-07-31 20:38:43,725 Epoch[41] Batch [600]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094149,	
2017-07-31 20:38:47,651 Epoch[41] Batch [610]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.094042,	
2017-07-31 20:38:51,513 Epoch[41] Batch [620]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094032,	
2017-07-31 20:38:55,453 Epoch[41] Batch [630]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093885,	
2017-07-31 20:38:59,515 Epoch[41] Batch [640]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.093892,	
2017-07-31 20:39:03,479 Epoch[41] Batch [650]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.093925,	
2017-07-31 20:39:07,398 Epoch[41] Batch [660]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093916,	
2017-07-31 20:39:11,313 Epoch[41] Batch [670]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093949,	
2017-07-31 20:39:15,272 Epoch[41] Batch [680]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.093972,	
2017-07-31 20:39:19,161 Epoch[41] Batch [690]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093989,	
2017-07-31 20:39:23,098 Epoch[41] Batch [700]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093933,	
2017-07-31 20:39:27,015 Epoch[41] Batch [710]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093948,	
2017-07-31 20:39:30,954 Epoch[41] Batch [720]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093910,	
2017-07-31 20:39:34,856 Epoch[41] Batch [730]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093916,	
2017-07-31 20:39:38,720 Epoch[41] Batch [740]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093846,	
2017-07-31 20:39:42,697 Epoch[41] Batch [750]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.093789,	
2017-07-31 20:39:46,500 Epoch[41] Batch [760]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.093668,	
2017-07-31 20:39:50,366 Epoch[41] Batch [770]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093681,	
2017-07-31 20:39:54,260 Epoch[41] Batch [780]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093706,	
2017-07-31 20:39:58,105 Epoch[41] Batch [790]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.093579,	
2017-07-31 20:40:02,008 Epoch[41] Batch [800]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093729,	
2017-07-31 20:40:05,956 Epoch[41] Batch [810]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.093703,	
2017-07-31 20:40:09,855 Epoch[41] Batch [820]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.093620,	
2017-07-31 20:40:13,719 Epoch[41] Batch [830]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093490,	
2017-07-31 20:40:17,649 Epoch[41] Batch [840]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093428,	
2017-07-31 20:40:21,598 Epoch[41] Batch [850]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.093376,	
2017-07-31 20:40:25,545 Epoch[41] Batch [860]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.093304,	
2017-07-31 20:40:29,537 Epoch[41] Batch [870]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.093277,	
2017-07-31 20:40:33,492 Epoch[41] Batch [880]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.093163,	
2017-07-31 20:40:37,373 Epoch[41] Batch [890]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093185,	
2017-07-31 20:40:41,297 Epoch[41] Batch [900]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.093164,	
2017-07-31 20:40:45,255 Epoch[41] Batch [910]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.093246,	
2017-07-31 20:40:49,179 Epoch[41] Batch [920]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093221,	
2017-07-31 20:40:53,003 Epoch[41] Batch [930]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.093244,	
2017-07-31 20:40:56,928 Epoch[41] Batch [940]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.093295,	
2017-07-31 20:41:00,831 Epoch[41] Batch [950]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093207,	
2017-07-31 20:41:04,789 Epoch[41] Batch [960]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.093165,	
2017-07-31 20:41:08,704 Epoch[41] Batch [970]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093294,	
2017-07-31 20:41:12,599 Epoch[41] Batch [980]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093376,	
2017-07-31 20:41:16,460 Epoch[41] Batch [990]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093450,	
2017-07-31 20:41:20,329 Epoch[41] Batch [1000]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093388,	
2017-07-31 20:41:24,189 Epoch[41] Batch [1010]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093378,	
2017-07-31 20:41:28,159 Epoch[41] Batch [1020]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.093305,	
2017-07-31 20:41:32,107 Epoch[41] Batch [1030]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.093261,	
2017-07-31 20:41:36,007 Epoch[41] Batch [1040]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.093281,	
2017-07-31 20:41:39,868 Epoch[41] Batch [1050]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093231,	
2017-07-31 20:41:43,800 Epoch[41] Batch [1060]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093249,	
2017-07-31 20:41:47,660 Epoch[41] Batch [1070]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093276,	
2017-07-31 20:41:51,597 Epoch[41] Batch [1080]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093307,	
2017-07-31 20:41:55,439 Epoch[41] Batch [1090]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.093254,	
2017-07-31 20:41:59,376 Epoch[41] Batch [1100]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093270,	
2017-07-31 20:42:03,359 Epoch[41] Batch [1110]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.093191,	
2017-07-31 20:42:07,170 Epoch[41] Batch [1120]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.093238,	
2017-07-31 20:42:10,962 Epoch[41] Batch [1130]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.093408,	
2017-07-31 20:42:14,885 Epoch[41] Batch [1140]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093391,	
2017-07-31 20:42:18,852 Epoch[41] Batch [1150]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.093394,	
2017-07-31 20:42:22,724 Epoch[41] Batch [1160]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093425,	
2017-07-31 20:42:26,718 Epoch[41] Batch [1170]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.093451,	
2017-07-31 20:42:30,548 Epoch[41] Batch [1180]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.093466,	
2017-07-31 20:42:34,468 Epoch[41] Batch [1190]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093620,	
2017-07-31 20:42:38,318 Epoch[41] Batch [1200]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.093608,	
2017-07-31 20:42:42,233 Epoch[41] Batch [1210]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093558,	
2017-07-31 20:42:46,163 Epoch[41] Batch [1220]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093577,	
2017-07-31 20:42:50,091 Epoch[41] Batch [1230]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.093603,	
2017-07-31 20:42:54,050 Epoch[41] Batch [1240]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.093555,	
2017-07-31 20:42:57,895 Epoch[41] Batch [1250]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.093558,	
2017-07-31 20:43:01,837 Epoch[41] Batch [1260]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093624,	
2017-07-31 20:43:05,658 Epoch[41] Batch [1270]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.093536,	
2017-07-31 20:43:09,588 Epoch[41] Batch [1280]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093550,	
2017-07-31 20:43:13,541 Epoch[41] Batch [1290]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.093517,	
2017-07-31 20:43:17,383 Epoch[41] Batch [1300]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.093514,	
2017-07-31 20:43:21,245 Epoch[41] Batch [1310]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093572,	
2017-07-31 20:43:25,150 Epoch[41] Batch [1320]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093611,	
2017-07-31 20:43:29,057 Epoch[41] Batch [1330]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093684,	
2017-07-31 20:43:32,916 Epoch[41] Batch [1340]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093794,	
2017-07-31 20:43:36,832 Epoch[41] Batch [1350]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093821,	
2017-07-31 20:43:40,911 Epoch[41] Batch [1360]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.093784,	
2017-07-31 20:43:44,851 Epoch[41] Batch [1370]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093823,	
2017-07-31 20:43:48,767 Epoch[41] Batch [1380]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093799,	
2017-07-31 20:43:52,659 Epoch[41] Batch [1390]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093824,	
2017-07-31 20:43:56,582 Epoch[41] Batch [1400]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093793,	
2017-07-31 20:44:00,465 Epoch[41] Batch [1410]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093710,	
2017-07-31 20:44:04,513 Epoch[41] Batch [1420]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.093733,	
2017-07-31 20:44:08,375 Epoch[41] Batch [1430]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093716,	
2017-07-31 20:44:12,296 Epoch[41] Batch [1440]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093684,	
2017-07-31 20:44:16,228 Epoch[41] Batch [1450]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093734,	
2017-07-31 20:44:20,053 Epoch[41] Batch [1460]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.093719,	
2017-07-31 20:44:23,964 Epoch[41] Batch [1470]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.093821,	
2017-07-31 20:44:27,818 Epoch[41] Batch [1480]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093777,	
2017-07-31 20:44:30,063 Epoch[41] Train-FCNLogLoss=0.093803
2017-07-31 20:44:30,063 Epoch[41] Time cost=581.593
2017-07-31 20:44:30,762 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.params"
2017-07-31 20:44:32,287 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.states"
2017-07-31 20:44:36,838 Epoch[42] Batch [10]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.096622,	
2017-07-31 20:44:40,699 Epoch[42] Batch [20]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.091858,	
2017-07-31 20:44:44,636 Epoch[42] Batch [30]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.091490,	
2017-07-31 20:44:48,549 Epoch[42] Batch [40]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.092760,	
2017-07-31 20:44:52,436 Epoch[42] Batch [50]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.094130,	
2017-07-31 20:44:56,303 Epoch[42] Batch [60]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.095502,	
2017-07-31 20:45:00,095 Epoch[42] Batch [70]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.094855,	
2017-07-31 20:45:04,143 Epoch[42] Batch [80]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.096307,	
2017-07-31 20:45:08,013 Epoch[42] Batch [90]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.095963,	
2017-07-31 20:45:11,972 Epoch[42] Batch [100]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.095149,	
2017-07-31 20:45:15,905 Epoch[42] Batch [110]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.095286,	
2017-07-31 20:45:19,860 Epoch[42] Batch [120]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095174,	
2017-07-31 20:45:23,699 Epoch[42] Batch [130]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.095370,	
2017-07-31 20:45:27,703 Epoch[42] Batch [140]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.095145,	
2017-07-31 20:45:31,607 Epoch[42] Batch [150]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094517,	
2017-07-31 20:45:35,440 Epoch[42] Batch [160]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.094956,	
2017-07-31 20:45:39,276 Epoch[42] Batch [170]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.094643,	
2017-07-31 20:45:43,110 Epoch[42] Batch [180]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.094594,	
2017-07-31 20:45:47,029 Epoch[42] Batch [190]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094603,	
2017-07-31 20:45:50,924 Epoch[42] Batch [200]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094775,	
2017-07-31 20:45:54,826 Epoch[42] Batch [210]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.095484,	
2017-07-31 20:45:58,759 Epoch[42] Batch [220]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094961,	
2017-07-31 20:46:02,661 Epoch[42] Batch [230]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.095516,	
2017-07-31 20:46:06,566 Epoch[42] Batch [240]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094963,	
2017-07-31 20:46:10,460 Epoch[42] Batch [250]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094997,	
2017-07-31 20:46:14,290 Epoch[42] Batch [260]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.095070,	
2017-07-31 20:46:18,134 Epoch[42] Batch [270]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.095053,	
2017-07-31 20:46:22,046 Epoch[42] Batch [280]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094787,	
2017-07-31 20:46:25,820 Epoch[42] Batch [290]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.094736,	
2017-07-31 20:46:29,832 Epoch[42] Batch [300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094685,	
2017-07-31 20:46:33,772 Epoch[42] Batch [310]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094340,	
2017-07-31 20:46:37,694 Epoch[42] Batch [320]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094363,	
2017-07-31 20:46:41,587 Epoch[42] Batch [330]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.094426,	
2017-07-31 20:46:45,542 Epoch[42] Batch [340]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094530,	
2017-07-31 20:46:49,363 Epoch[42] Batch [350]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.094333,	
2017-07-31 20:46:53,259 Epoch[42] Batch [360]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094443,	
2017-07-31 20:46:57,176 Epoch[42] Batch [370]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094409,	
2017-07-31 20:47:01,071 Epoch[42] Batch [380]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094347,	
2017-07-31 20:47:04,944 Epoch[42] Batch [390]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.094332,	
2017-07-31 20:47:08,847 Epoch[42] Batch [400]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094309,	
2017-07-31 20:47:12,704 Epoch[42] Batch [410]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093897,	
2017-07-31 20:47:16,646 Epoch[42] Batch [420]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093924,	
2017-07-31 20:47:20,518 Epoch[42] Batch [430]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093864,	
2017-07-31 20:47:24,454 Epoch[42] Batch [440]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093665,	
2017-07-31 20:47:28,335 Epoch[42] Batch [450]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093559,	
2017-07-31 20:47:32,144 Epoch[42] Batch [460]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.093453,	
2017-07-31 20:47:36,045 Epoch[42] Batch [470]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.093521,	
2017-07-31 20:47:39,899 Epoch[42] Batch [480]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093640,	
2017-07-31 20:47:43,733 Epoch[42] Batch [490]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.093435,	
2017-07-31 20:47:47,602 Epoch[42] Batch [500]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093536,	
2017-07-31 20:47:51,451 Epoch[42] Batch [510]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.093468,	
2017-07-31 20:47:55,341 Epoch[42] Batch [520]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093298,	
2017-07-31 20:47:59,167 Epoch[42] Batch [530]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.093380,	
2017-07-31 20:48:03,111 Epoch[42] Batch [540]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.093313,	
2017-07-31 20:48:07,039 Epoch[42] Batch [550]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093401,	
2017-07-31 20:48:10,931 Epoch[42] Batch [560]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093339,	
2017-07-31 20:48:14,854 Epoch[42] Batch [570]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093425,	
2017-07-31 20:48:18,834 Epoch[42] Batch [580]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.093436,	
2017-07-31 20:48:22,743 Epoch[42] Batch [590]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.093317,	
2017-07-31 20:48:26,637 Epoch[42] Batch [600]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093458,	
2017-07-31 20:48:30,554 Epoch[42] Batch [610]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093283,	
2017-07-31 20:48:34,478 Epoch[42] Batch [620]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093278,	
2017-07-31 20:48:38,395 Epoch[42] Batch [630]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093181,	
2017-07-31 20:48:42,254 Epoch[42] Batch [640]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093274,	
2017-07-31 20:48:46,071 Epoch[42] Batch [650]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.093288,	
2017-07-31 20:48:49,936 Epoch[42] Batch [660]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093143,	
2017-07-31 20:48:53,891 Epoch[42] Batch [670]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.093252,	
2017-07-31 20:48:57,810 Epoch[42] Batch [680]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093167,	
2017-07-31 20:49:01,746 Epoch[42] Batch [690]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093122,	
2017-07-31 20:49:05,582 Epoch[42] Batch [700]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.093116,	
2017-07-31 20:49:09,465 Epoch[42] Batch [710]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093093,	
2017-07-31 20:49:13,332 Epoch[42] Batch [720]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093110,	
2017-07-31 20:49:17,276 Epoch[42] Batch [730]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.093398,	
2017-07-31 20:49:21,155 Epoch[42] Batch [740]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093413,	
2017-07-31 20:49:24,996 Epoch[42] Batch [750]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.093394,	
2017-07-31 20:49:28,939 Epoch[42] Batch [760]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093593,	
2017-07-31 20:49:32,812 Epoch[42] Batch [770]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093554,	
2017-07-31 20:49:36,713 Epoch[42] Batch [780]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093537,	
2017-07-31 20:49:40,633 Epoch[42] Batch [790]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093418,	
2017-07-31 20:49:44,510 Epoch[42] Batch [800]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093434,	
2017-07-31 20:49:48,397 Epoch[42] Batch [810]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093380,	
2017-07-31 20:49:52,299 Epoch[42] Batch [820]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093475,	
2017-07-31 20:49:56,230 Epoch[42] Batch [830]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093428,	
2017-07-31 20:50:00,098 Epoch[42] Batch [840]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093337,	
2017-07-31 20:50:03,997 Epoch[42] Batch [850]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.093345,	
2017-07-31 20:50:07,937 Epoch[42] Batch [860]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093395,	
2017-07-31 20:50:11,868 Epoch[42] Batch [870]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093408,	
2017-07-31 20:50:15,745 Epoch[42] Batch [880]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093373,	
2017-07-31 20:50:19,665 Epoch[42] Batch [890]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093271,	
2017-07-31 20:50:23,528 Epoch[42] Batch [900]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093281,	
2017-07-31 20:50:27,489 Epoch[42] Batch [910]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.093269,	
2017-07-31 20:50:31,404 Epoch[42] Batch [920]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093230,	
2017-07-31 20:50:35,326 Epoch[42] Batch [930]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093237,	
2017-07-31 20:50:39,242 Epoch[42] Batch [940]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093211,	
2017-07-31 20:50:43,186 Epoch[42] Batch [950]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.093120,	
2017-07-31 20:50:47,003 Epoch[42] Batch [960]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.093177,	
2017-07-31 20:50:50,871 Epoch[42] Batch [970]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093239,	
2017-07-31 20:50:54,809 Epoch[42] Batch [980]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093239,	
2017-07-31 20:50:58,647 Epoch[42] Batch [990]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.093296,	
2017-07-31 20:51:02,590 Epoch[42] Batch [1000]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093352,	
2017-07-31 20:51:06,513 Epoch[42] Batch [1010]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093506,	
2017-07-31 20:51:10,529 Epoch[42] Batch [1020]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.093639,	
2017-07-31 20:51:14,469 Epoch[42] Batch [1030]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093655,	
2017-07-31 20:51:18,433 Epoch[42] Batch [1040]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.093593,	
2017-07-31 20:51:22,348 Epoch[42] Batch [1050]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093600,	
2017-07-31 20:51:26,182 Epoch[42] Batch [1060]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.093538,	
2017-07-31 20:51:30,071 Epoch[42] Batch [1070]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093524,	
2017-07-31 20:51:33,941 Epoch[42] Batch [1080]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093581,	
2017-07-31 20:51:37,859 Epoch[42] Batch [1090]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093570,	
2017-07-31 20:51:41,792 Epoch[42] Batch [1100]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.093576,	
2017-07-31 20:51:45,593 Epoch[42] Batch [1110]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.093597,	
2017-07-31 20:51:49,576 Epoch[42] Batch [1120]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.093539,	
2017-07-31 20:51:53,376 Epoch[42] Batch [1130]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.093499,	
2017-07-31 20:51:57,284 Epoch[42] Batch [1140]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093495,	
2017-07-31 20:52:01,150 Epoch[42] Batch [1150]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093429,	
2017-07-31 20:52:04,956 Epoch[42] Batch [1160]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.093445,	
2017-07-31 20:52:08,853 Epoch[42] Batch [1170]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093335,	
2017-07-31 20:52:12,744 Epoch[42] Batch [1180]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093288,	
2017-07-31 20:52:16,663 Epoch[42] Batch [1190]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093295,	
2017-07-31 20:52:20,457 Epoch[42] Batch [1200]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.093290,	
2017-07-31 20:52:24,279 Epoch[42] Batch [1210]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.093326,	
2017-07-31 20:52:28,199 Epoch[42] Batch [1220]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093322,	
2017-07-31 20:52:32,077 Epoch[42] Batch [1230]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093367,	
2017-07-31 20:52:35,959 Epoch[42] Batch [1240]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093397,	
2017-07-31 20:52:39,805 Epoch[42] Batch [1250]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.093349,	
2017-07-31 20:52:43,696 Epoch[42] Batch [1260]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093407,	
2017-07-31 20:52:47,542 Epoch[42] Batch [1270]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.093380,	
2017-07-31 20:52:51,359 Epoch[42] Batch [1280]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.093332,	
2017-07-31 20:52:55,281 Epoch[42] Batch [1290]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093306,	
2017-07-31 20:52:59,175 Epoch[42] Batch [1300]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093347,	
2017-07-31 20:53:03,137 Epoch[42] Batch [1310]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.093382,	
2017-07-31 20:53:07,080 Epoch[42] Batch [1320]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093436,	
2017-07-31 20:53:10,947 Epoch[42] Batch [1330]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093470,	
2017-07-31 20:53:14,845 Epoch[42] Batch [1340]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.093467,	
2017-07-31 20:53:18,708 Epoch[42] Batch [1350]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093472,	
2017-07-31 20:53:22,552 Epoch[42] Batch [1360]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.093442,	
2017-07-31 20:53:26,464 Epoch[42] Batch [1370]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.093418,	
2017-07-31 20:53:30,370 Epoch[42] Batch [1380]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093372,	
2017-07-31 20:53:34,341 Epoch[42] Batch [1390]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093368,	
2017-07-31 20:53:38,341 Epoch[42] Batch [1400]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.093347,	
2017-07-31 20:53:42,216 Epoch[42] Batch [1410]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093287,	
2017-07-31 20:53:46,222 Epoch[42] Batch [1420]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.093370,	
2017-07-31 20:53:50,112 Epoch[42] Batch [1430]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093363,	
2017-07-31 20:53:53,968 Epoch[42] Batch [1440]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093338,	
2017-07-31 20:53:57,866 Epoch[42] Batch [1450]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.093344,	
2017-07-31 20:54:01,883 Epoch[42] Batch [1460]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.093423,	
2017-07-31 20:54:05,848 Epoch[42] Batch [1470]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.093416,	
2017-07-31 20:54:09,615 Epoch[42] Batch [1480]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.093353,	
2017-07-31 20:54:11,962 Epoch[42] Train-FCNLogLoss=0.093328
2017-07-31 20:54:11,962 Epoch[42] Time cost=579.675
2017-07-31 20:54:12,632 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.params"
2017-07-31 20:54:14,156 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.states"
2017-07-31 20:54:18,751 Epoch[43] Batch [10]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096204,	
2017-07-31 20:54:22,680 Epoch[43] Batch [20]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.095184,	
2017-07-31 20:54:26,552 Epoch[43] Batch [30]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.097007,	
2017-07-31 20:54:30,463 Epoch[43] Batch [40]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095431,	
2017-07-31 20:54:34,464 Epoch[43] Batch [50]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095740,	
2017-07-31 20:54:38,399 Epoch[43] Batch [60]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.095591,	
2017-07-31 20:54:42,259 Epoch[43] Batch [70]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.097431,	
2017-07-31 20:54:46,231 Epoch[43] Batch [80]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.097287,	
2017-07-31 20:54:50,191 Epoch[43] Batch [90]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096744,	
2017-07-31 20:54:54,105 Epoch[43] Batch [100]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.097356,	
2017-07-31 20:54:58,065 Epoch[43] Batch [110]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.097232,	
2017-07-31 20:55:02,037 Epoch[43] Batch [120]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.095873,	
2017-07-31 20:55:05,944 Epoch[43] Batch [130]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.095051,	
2017-07-31 20:55:09,900 Epoch[43] Batch [140]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095166,	
2017-07-31 20:55:13,905 Epoch[43] Batch [150]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.095532,	
2017-07-31 20:55:17,831 Epoch[43] Batch [160]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095203,	
2017-07-31 20:55:21,796 Epoch[43] Batch [170]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094889,	
2017-07-31 20:55:25,702 Epoch[43] Batch [180]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094772,	
2017-07-31 20:55:29,628 Epoch[43] Batch [190]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095288,	
2017-07-31 20:55:33,651 Epoch[43] Batch [200]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095826,	
2017-07-31 20:55:37,579 Epoch[43] Batch [210]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.095845,	
2017-07-31 20:55:41,505 Epoch[43] Batch [220]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095751,	
2017-07-31 20:55:45,395 Epoch[43] Batch [230]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.095191,	
2017-07-31 20:55:49,244 Epoch[43] Batch [240]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.095064,	
2017-07-31 20:55:53,217 Epoch[43] Batch [250]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.095547,	
2017-07-31 20:55:57,065 Epoch[43] Batch [260]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.095275,	
2017-07-31 20:56:00,975 Epoch[43] Batch [270]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095490,	
2017-07-31 20:56:04,902 Epoch[43] Batch [280]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095638,	
2017-07-31 20:56:08,820 Epoch[43] Batch [290]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.095724,	
2017-07-31 20:56:12,721 Epoch[43] Batch [300]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095470,	
2017-07-31 20:56:16,609 Epoch[43] Batch [310]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.095570,	
2017-07-31 20:56:20,465 Epoch[43] Batch [320]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.095460,	
2017-07-31 20:56:24,358 Epoch[43] Batch [330]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.094918,	
2017-07-31 20:56:28,268 Epoch[43] Batch [340]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094881,	
2017-07-31 20:56:32,177 Epoch[43] Batch [350]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094857,	
2017-07-31 20:56:36,054 Epoch[43] Batch [360]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.094658,	
2017-07-31 20:56:39,939 Epoch[43] Batch [370]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094761,	
2017-07-31 20:56:43,845 Epoch[43] Batch [380]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094349,	
2017-07-31 20:56:47,768 Epoch[43] Batch [390]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094357,	
2017-07-31 20:56:51,602 Epoch[43] Batch [400]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.094397,	
2017-07-31 20:56:55,564 Epoch[43] Batch [410]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094355,	
2017-07-31 20:56:59,396 Epoch[43] Batch [420]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.094523,	
2017-07-31 20:57:03,399 Epoch[43] Batch [430]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094451,	
2017-07-31 20:57:07,269 Epoch[43] Batch [440]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.094624,	
2017-07-31 20:57:11,202 Epoch[43] Batch [450]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094797,	
2017-07-31 20:57:15,107 Epoch[43] Batch [460]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094787,	
2017-07-31 20:57:19,004 Epoch[43] Batch [470]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094713,	
2017-07-31 20:57:22,869 Epoch[43] Batch [480]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.094604,	
2017-07-31 20:57:26,730 Epoch[43] Batch [490]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094524,	
2017-07-31 20:57:30,684 Epoch[43] Batch [500]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094213,	
2017-07-31 20:57:34,533 Epoch[43] Batch [510]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.094175,	
2017-07-31 20:57:38,352 Epoch[43] Batch [520]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.094217,	
2017-07-31 20:57:42,173 Epoch[43] Batch [530]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.094284,	
2017-07-31 20:57:46,097 Epoch[43] Batch [540]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094244,	
2017-07-31 20:57:50,115 Epoch[43] Batch [550]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094054,	
2017-07-31 20:57:53,997 Epoch[43] Batch [560]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093997,	
2017-07-31 20:57:57,881 Epoch[43] Batch [570]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094130,	
2017-07-31 20:58:01,815 Epoch[43] Batch [580]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094155,	
2017-07-31 20:58:05,855 Epoch[43] Batch [590]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094014,	
2017-07-31 20:58:09,828 Epoch[43] Batch [600]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093932,	
2017-07-31 20:58:13,638 Epoch[43] Batch [610]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.093982,	
2017-07-31 20:58:17,484 Epoch[43] Batch [620]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.094209,	
2017-07-31 20:58:21,316 Epoch[43] Batch [630]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.094042,	
2017-07-31 20:58:25,296 Epoch[43] Batch [640]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094028,	
2017-07-31 20:58:29,191 Epoch[43] Batch [650]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093899,	
2017-07-31 20:58:33,077 Epoch[43] Batch [660]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093826,	
2017-07-31 20:58:36,957 Epoch[43] Batch [670]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093879,	
2017-07-31 20:58:40,828 Epoch[43] Batch [680]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093915,	
2017-07-31 20:58:44,729 Epoch[43] Batch [690]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094119,	
2017-07-31 20:58:48,634 Epoch[43] Batch [700]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093977,	
2017-07-31 20:58:52,513 Epoch[43] Batch [710]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093913,	
2017-07-31 20:58:56,367 Epoch[43] Batch [720]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093823,	
2017-07-31 20:59:00,208 Epoch[43] Batch [730]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.093762,	
2017-07-31 20:59:04,061 Epoch[43] Batch [740]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093754,	
2017-07-31 20:59:07,972 Epoch[43] Batch [750]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.093789,	
2017-07-31 20:59:11,808 Epoch[43] Batch [760]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.093618,	
2017-07-31 20:59:15,709 Epoch[43] Batch [770]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093641,	
2017-07-31 20:59:19,597 Epoch[43] Batch [780]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093630,	
2017-07-31 20:59:23,467 Epoch[43] Batch [790]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.093641,	
2017-07-31 20:59:27,354 Epoch[43] Batch [800]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093648,	
2017-07-31 20:59:31,153 Epoch[43] Batch [810]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.093680,	
2017-07-31 20:59:35,005 Epoch[43] Batch [820]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093733,	
2017-07-31 20:59:38,894 Epoch[43] Batch [830]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093784,	
2017-07-31 20:59:42,785 Epoch[43] Batch [840]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093737,	
2017-07-31 20:59:46,709 Epoch[43] Batch [850]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.093685,	
2017-07-31 20:59:50,640 Epoch[43] Batch [860]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093598,	
2017-07-31 20:59:54,558 Epoch[43] Batch [870]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093589,	
2017-07-31 20:59:58,506 Epoch[43] Batch [880]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.093603,	
2017-07-31 21:00:02,460 Epoch[43] Batch [890]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.093582,	
2017-07-31 21:00:06,298 Epoch[43] Batch [900]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.093641,	
2017-07-31 21:00:10,240 Epoch[43] Batch [910]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093684,	
2017-07-31 21:00:14,052 Epoch[43] Batch [920]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.093675,	
2017-07-31 21:00:17,905 Epoch[43] Batch [930]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093728,	
2017-07-31 21:00:21,736 Epoch[43] Batch [940]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.093658,	
2017-07-31 21:00:25,570 Epoch[43] Batch [950]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.093654,	
2017-07-31 21:00:29,460 Epoch[43] Batch [960]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093994,	
2017-07-31 21:00:33,308 Epoch[43] Batch [970]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.094076,	
2017-07-31 21:00:37,246 Epoch[43] Batch [980]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094179,	
2017-07-31 21:00:41,136 Epoch[43] Batch [990]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.094121,	
2017-07-31 21:00:45,033 Epoch[43] Batch [1000]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.094174,	
2017-07-31 21:00:48,857 Epoch[43] Batch [1010]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.094122,	
2017-07-31 21:00:52,785 Epoch[43] Batch [1020]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094077,	
2017-07-31 21:00:56,673 Epoch[43] Batch [1030]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.094088,	
2017-07-31 21:01:00,602 Epoch[43] Batch [1040]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094063,	
2017-07-31 21:01:04,476 Epoch[43] Batch [1050]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093975,	
2017-07-31 21:01:08,306 Epoch[43] Batch [1060]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.094006,	
2017-07-31 21:01:12,231 Epoch[43] Batch [1070]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.093954,	
2017-07-31 21:01:16,106 Epoch[43] Batch [1080]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093928,	
2017-07-31 21:01:19,986 Epoch[43] Batch [1090]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093946,	
2017-07-31 21:01:23,828 Epoch[43] Batch [1100]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.093934,	
2017-07-31 21:01:27,766 Epoch[43] Batch [1110]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093917,	
2017-07-31 21:01:31,679 Epoch[43] Batch [1120]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093948,	
2017-07-31 21:01:35,651 Epoch[43] Batch [1130]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093928,	
2017-07-31 21:01:39,481 Epoch[43] Batch [1140]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.093856,	
2017-07-31 21:01:43,352 Epoch[43] Batch [1150]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093865,	
2017-07-31 21:01:47,232 Epoch[43] Batch [1160]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093724,	
2017-07-31 21:01:51,240 Epoch[43] Batch [1170]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.093708,	
2017-07-31 21:01:55,145 Epoch[43] Batch [1180]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093642,	
2017-07-31 21:01:59,081 Epoch[43] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093668,	
2017-07-31 21:02:03,057 Epoch[43] Batch [1200]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.093623,	
2017-07-31 21:02:07,006 Epoch[43] Batch [1210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.093664,	
2017-07-31 21:02:10,877 Epoch[43] Batch [1220]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093691,	
2017-07-31 21:02:14,752 Epoch[43] Batch [1230]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093614,	
2017-07-31 21:02:18,628 Epoch[43] Batch [1240]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093567,	
2017-07-31 21:02:22,494 Epoch[43] Batch [1250]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093590,	
2017-07-31 21:02:26,416 Epoch[43] Batch [1260]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093473,	
2017-07-31 21:02:30,279 Epoch[43] Batch [1270]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093482,	
2017-07-31 21:02:34,195 Epoch[43] Batch [1280]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093444,	
2017-07-31 21:02:38,055 Epoch[43] Batch [1290]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093450,	
2017-07-31 21:02:41,986 Epoch[43] Batch [1300]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093365,	
2017-07-31 21:02:45,903 Epoch[43] Batch [1310]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093420,	
2017-07-31 21:02:49,815 Epoch[43] Batch [1320]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.093359,	
2017-07-31 21:02:53,701 Epoch[43] Batch [1330]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093315,	
2017-07-31 21:02:57,577 Epoch[43] Batch [1340]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093324,	
2017-07-31 21:03:01,420 Epoch[43] Batch [1350]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.093338,	
2017-07-31 21:03:05,287 Epoch[43] Batch [1360]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093360,	
2017-07-31 21:03:09,189 Epoch[43] Batch [1370]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093358,	
2017-07-31 21:03:13,116 Epoch[43] Batch [1380]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.093277,	
2017-07-31 21:03:17,001 Epoch[43] Batch [1390]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093258,	
2017-07-31 21:03:21,016 Epoch[43] Batch [1400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.093227,	
2017-07-31 21:03:24,870 Epoch[43] Batch [1410]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093248,	
2017-07-31 21:03:28,808 Epoch[43] Batch [1420]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093332,	
2017-07-31 21:03:32,743 Epoch[43] Batch [1430]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093338,	
2017-07-31 21:03:36,625 Epoch[43] Batch [1440]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093290,	
2017-07-31 21:03:40,520 Epoch[43] Batch [1450]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093299,	
2017-07-31 21:03:44,511 Epoch[43] Batch [1460]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.093341,	
2017-07-31 21:03:48,460 Epoch[43] Batch [1470]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.093308,	
2017-07-31 21:03:52,441 Epoch[43] Batch [1480]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.093324,	
2017-07-31 21:03:54,874 Epoch[43] Train-FCNLogLoss=0.093342
2017-07-31 21:03:54,875 Epoch[43] Time cost=580.718
2017-07-31 21:03:55,530 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.params"
2017-07-31 21:03:57,091 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.states"
2017-07-31 21:04:01,552 Epoch[44] Batch [10]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.096402,	
2017-07-31 21:04:05,533 Epoch[44] Batch [20]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094139,	
2017-07-31 21:04:09,465 Epoch[44] Batch [30]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094036,	
2017-07-31 21:04:13,447 Epoch[44] Batch [40]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.092516,	
2017-07-31 21:04:17,349 Epoch[44] Batch [50]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093857,	
2017-07-31 21:04:21,319 Epoch[44] Batch [60]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.093158,	
2017-07-31 21:04:25,260 Epoch[44] Batch [70]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092674,	
2017-07-31 21:04:29,190 Epoch[44] Batch [80]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092955,	
2017-07-31 21:04:33,138 Epoch[44] Batch [90]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.091888,	
2017-07-31 21:04:37,032 Epoch[44] Batch [100]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.091557,	
2017-07-31 21:04:40,888 Epoch[44] Batch [110]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.090160,	
2017-07-31 21:04:44,861 Epoch[44] Batch [120]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.090117,	
2017-07-31 21:04:48,838 Epoch[44] Batch [130]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.090011,	
2017-07-31 21:04:52,716 Epoch[44] Batch [140]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.090182,	
2017-07-31 21:04:56,613 Epoch[44] Batch [150]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.090148,	
2017-07-31 21:05:00,566 Epoch[44] Batch [160]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.090044,	
2017-07-31 21:05:04,555 Epoch[44] Batch [170]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.090400,	
2017-07-31 21:05:08,515 Epoch[44] Batch [180]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.090458,	
2017-07-31 21:05:12,418 Epoch[44] Batch [190]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.090925,	
2017-07-31 21:05:16,200 Epoch[44] Batch [200]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.090990,	
2017-07-31 21:05:20,081 Epoch[44] Batch [210]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.091344,	
2017-07-31 21:05:23,888 Epoch[44] Batch [220]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.091431,	
2017-07-31 21:05:27,824 Epoch[44] Batch [230]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.091646,	
2017-07-31 21:05:31,745 Epoch[44] Batch [240]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092701,	
2017-07-31 21:05:35,767 Epoch[44] Batch [250]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.093042,	
2017-07-31 21:05:39,632 Epoch[44] Batch [260]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.092859,	
2017-07-31 21:05:43,556 Epoch[44] Batch [270]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093302,	
2017-07-31 21:05:47,433 Epoch[44] Batch [280]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093303,	
2017-07-31 21:05:51,319 Epoch[44] Batch [290]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093663,	
2017-07-31 21:05:55,201 Epoch[44] Batch [300]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093627,	
2017-07-31 21:05:59,075 Epoch[44] Batch [310]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093669,	
2017-07-31 21:06:02,983 Epoch[44] Batch [320]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093211,	
2017-07-31 21:06:06,833 Epoch[44] Batch [330]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.093266,	
2017-07-31 21:06:10,692 Epoch[44] Batch [340]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093170,	
2017-07-31 21:06:14,559 Epoch[44] Batch [350]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093049,	
2017-07-31 21:06:18,557 Epoch[44] Batch [360]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.092978,	
2017-07-31 21:06:22,452 Epoch[44] Batch [370]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092694,	
2017-07-31 21:06:26,413 Epoch[44] Batch [380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.092526,	
2017-07-31 21:06:30,354 Epoch[44] Batch [390]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092417,	
2017-07-31 21:06:34,217 Epoch[44] Batch [400]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.092253,	
2017-07-31 21:06:38,189 Epoch[44] Batch [410]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.092073,	
2017-07-31 21:06:42,118 Epoch[44] Batch [420]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092104,	
2017-07-31 21:06:46,007 Epoch[44] Batch [430]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.091899,	
2017-07-31 21:06:49,941 Epoch[44] Batch [440]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.091875,	
2017-07-31 21:06:53,787 Epoch[44] Batch [450]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.091908,	
2017-07-31 21:06:57,680 Epoch[44] Batch [460]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092078,	
2017-07-31 21:07:01,510 Epoch[44] Batch [470]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.092253,	
2017-07-31 21:07:05,404 Epoch[44] Batch [480]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092145,	
2017-07-31 21:07:09,279 Epoch[44] Batch [490]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092212,	
2017-07-31 21:07:13,117 Epoch[44] Batch [500]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.092151,	
2017-07-31 21:07:17,010 Epoch[44] Batch [510]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092274,	
2017-07-31 21:07:20,922 Epoch[44] Batch [520]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.092320,	
2017-07-31 21:07:24,745 Epoch[44] Batch [530]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.092328,	
2017-07-31 21:07:28,635 Epoch[44] Batch [540]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092420,	
2017-07-31 21:07:32,516 Epoch[44] Batch [550]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092366,	
2017-07-31 21:07:36,412 Epoch[44] Batch [560]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092251,	
2017-07-31 21:07:40,315 Epoch[44] Batch [570]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092405,	
2017-07-31 21:07:44,225 Epoch[44] Batch [580]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.092298,	
2017-07-31 21:07:48,124 Epoch[44] Batch [590]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092357,	
2017-07-31 21:07:52,040 Epoch[44] Batch [600]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.092307,	
2017-07-31 21:07:55,910 Epoch[44] Batch [610]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.092313,	
2017-07-31 21:07:59,855 Epoch[44] Batch [620]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.092284,	
2017-07-31 21:08:03,867 Epoch[44] Batch [630]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.092310,	
2017-07-31 21:08:07,793 Epoch[44] Batch [640]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.092324,	
2017-07-31 21:08:11,697 Epoch[44] Batch [650]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092260,	
2017-07-31 21:08:15,533 Epoch[44] Batch [660]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.092280,	
2017-07-31 21:08:19,380 Epoch[44] Batch [670]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.092213,	
2017-07-31 21:08:23,290 Epoch[44] Batch [680]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.092143,	
2017-07-31 21:08:27,225 Epoch[44] Batch [690]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.092031,	
2017-07-31 21:08:31,124 Epoch[44] Batch [700]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092078,	
2017-07-31 21:08:35,013 Epoch[44] Batch [710]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.091925,	
2017-07-31 21:08:38,893 Epoch[44] Batch [720]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.091961,	
2017-07-31 21:08:42,788 Epoch[44] Batch [730]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.091934,	
2017-07-31 21:08:46,629 Epoch[44] Batch [740]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.092069,	
2017-07-31 21:08:50,559 Epoch[44] Batch [750]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092086,	
2017-07-31 21:08:54,439 Epoch[44] Batch [760]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092101,	
2017-07-31 21:08:58,389 Epoch[44] Batch [770]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.092196,	
2017-07-31 21:09:02,316 Epoch[44] Batch [780]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.092221,	
2017-07-31 21:09:06,174 Epoch[44] Batch [790]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.092215,	
2017-07-31 21:09:10,097 Epoch[44] Batch [800]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092067,	
2017-07-31 21:09:14,008 Epoch[44] Batch [810]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.092110,	
2017-07-31 21:09:17,957 Epoch[44] Batch [820]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.092000,	
2017-07-31 21:09:21,963 Epoch[44] Batch [830]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.092002,	
2017-07-31 21:09:25,845 Epoch[44] Batch [840]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.091967,	
2017-07-31 21:09:29,732 Epoch[44] Batch [850]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.091957,	
2017-07-31 21:09:33,686 Epoch[44] Batch [860]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.091991,	
2017-07-31 21:09:37,504 Epoch[44] Batch [870]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.092025,	
2017-07-31 21:09:41,344 Epoch[44] Batch [880]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.092061,	
2017-07-31 21:09:45,613 Epoch[44] Batch [890]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.092271,	
2017-07-31 21:09:49,971 Epoch[44] Batch [900]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.092271,	
2017-07-31 21:09:54,051 Epoch[44] Batch [910]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.092370,	
2017-07-31 21:09:58,095 Epoch[44] Batch [920]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.092461,	
2017-07-31 21:10:02,270 Epoch[44] Batch [930]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.092335,	
2017-07-31 21:10:06,675 Epoch[44] Batch [940]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.092366,	
2017-07-31 21:10:10,562 Epoch[44] Batch [950]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092317,	
2017-07-31 21:10:14,614 Epoch[44] Batch [960]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.092272,	
2017-07-31 21:10:18,513 Epoch[44] Batch [970]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092197,	
2017-07-31 21:10:22,435 Epoch[44] Batch [980]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092155,	
2017-07-31 21:10:26,281 Epoch[44] Batch [990]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.092161,	
2017-07-31 21:10:30,135 Epoch[44] Batch [1000]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.092165,	
2017-07-31 21:10:34,015 Epoch[44] Batch [1010]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092136,	
2017-07-31 21:10:37,933 Epoch[44] Batch [1020]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.092079,	
2017-07-31 21:10:41,715 Epoch[44] Batch [1030]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.092123,	
2017-07-31 21:10:45,572 Epoch[44] Batch [1040]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.092134,	
2017-07-31 21:10:49,503 Epoch[44] Batch [1050]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092065,	
2017-07-31 21:10:53,345 Epoch[44] Batch [1060]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.092056,	
2017-07-31 21:10:57,233 Epoch[44] Batch [1070]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092076,	
2017-07-31 21:11:01,039 Epoch[44] Batch [1080]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.092086,	
2017-07-31 21:11:04,912 Epoch[44] Batch [1090]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092077,	
2017-07-31 21:11:08,803 Epoch[44] Batch [1100]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092025,	
2017-07-31 21:11:12,720 Epoch[44] Batch [1110]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.091984,	
2017-07-31 21:11:16,552 Epoch[44] Batch [1120]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.091980,	
2017-07-31 21:11:20,436 Epoch[44] Batch [1130]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.092021,	
2017-07-31 21:11:24,334 Epoch[44] Batch [1140]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092038,	
2017-07-31 21:11:28,338 Epoch[44] Batch [1150]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.092087,	
2017-07-31 21:11:32,260 Epoch[44] Batch [1160]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092118,	
2017-07-31 21:11:36,219 Epoch[44] Batch [1170]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.092178,	
2017-07-31 21:11:40,158 Epoch[44] Batch [1180]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.092178,	
2017-07-31 21:11:44,128 Epoch[44] Batch [1190]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.092271,	
2017-07-31 21:11:48,126 Epoch[44] Batch [1200]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.092255,	
2017-07-31 21:11:52,084 Epoch[44] Batch [1210]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.092265,	
2017-07-31 21:11:56,005 Epoch[44] Batch [1220]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092259,	
2017-07-31 21:11:59,894 Epoch[44] Batch [1230]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092361,	
2017-07-31 21:12:03,835 Epoch[44] Batch [1240]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092354,	
2017-07-31 21:12:07,767 Epoch[44] Batch [1250]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.092373,	
2017-07-31 21:12:11,654 Epoch[44] Batch [1260]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092375,	
2017-07-31 21:12:15,612 Epoch[44] Batch [1270]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.092381,	
2017-07-31 21:12:19,568 Epoch[44] Batch [1280]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.092328,	
2017-07-31 21:12:23,460 Epoch[44] Batch [1290]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092360,	
2017-07-31 21:12:27,372 Epoch[44] Batch [1300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.092385,	
2017-07-31 21:12:31,265 Epoch[44] Batch [1310]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092405,	
2017-07-31 21:12:35,226 Epoch[44] Batch [1320]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.092374,	
2017-07-31 21:12:39,127 Epoch[44] Batch [1330]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092351,	
2017-07-31 21:12:43,056 Epoch[44] Batch [1340]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092386,	
2017-07-31 21:12:46,988 Epoch[44] Batch [1350]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.092424,	
2017-07-31 21:12:50,908 Epoch[44] Batch [1360]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092364,	
2017-07-31 21:12:54,856 Epoch[44] Batch [1370]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.092437,	
2017-07-31 21:12:58,689 Epoch[44] Batch [1380]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.092484,	
2017-07-31 21:13:02,533 Epoch[44] Batch [1390]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.092473,	
2017-07-31 21:13:06,475 Epoch[44] Batch [1400]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092474,	
2017-07-31 21:13:10,394 Epoch[44] Batch [1410]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.092443,	
2017-07-31 21:13:14,315 Epoch[44] Batch [1420]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092434,	
2017-07-31 21:13:18,261 Epoch[44] Batch [1430]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.092530,	
2017-07-31 21:13:22,154 Epoch[44] Batch [1440]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092600,	
2017-07-31 21:13:26,030 Epoch[44] Batch [1450]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092557,	
2017-07-31 21:13:29,858 Epoch[44] Batch [1460]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.092540,	
2017-07-31 21:13:33,815 Epoch[44] Batch [1470]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.092576,	
2017-07-31 21:13:37,786 Epoch[44] Batch [1480]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.092595,	
2017-07-31 21:13:40,207 Epoch[44] Train-FCNLogLoss=0.092629
2017-07-31 21:13:40,207 Epoch[44] Time cost=583.115
2017-07-31 21:13:40,853 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0045.params"
2017-07-31 21:13:42,376 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0045.states"
2017-07-31 21:13:46,953 Epoch[45] Batch [10]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.085460,	
2017-07-31 21:13:50,895 Epoch[45] Batch [20]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.089333,	
2017-07-31 21:13:54,771 Epoch[45] Batch [30]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.090851,	
2017-07-31 21:13:58,627 Epoch[45] Batch [40]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093244,	
2017-07-31 21:14:02,449 Epoch[45] Batch [50]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.094928,	
2017-07-31 21:14:06,349 Epoch[45] Batch [60]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.094145,	
2017-07-31 21:14:10,222 Epoch[45] Batch [70]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.093887,	
2017-07-31 21:14:14,116 Epoch[45] Batch [80]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092890,	
2017-07-31 21:14:17,937 Epoch[45] Batch [90]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.092307,	
2017-07-31 21:14:21,784 Epoch[45] Batch [100]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.091288,	
2017-07-31 21:14:25,726 Epoch[45] Batch [110]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092207,	
2017-07-31 21:14:29,647 Epoch[45] Batch [120]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092141,	
2017-07-31 21:14:33,518 Epoch[45] Batch [130]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.092488,	
2017-07-31 21:14:37,402 Epoch[45] Batch [140]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.092202,	
2017-07-31 21:14:41,303 Epoch[45] Batch [150]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092651,	
2017-07-31 21:14:45,092 Epoch[45] Batch [160]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.092501,	
2017-07-31 21:14:48,969 Epoch[45] Batch [170]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092402,	
2017-07-31 21:14:52,864 Epoch[45] Batch [180]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093031,	
2017-07-31 21:14:56,737 Epoch[45] Batch [190]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092724,	
2017-07-31 21:15:00,572 Epoch[45] Batch [200]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.092293,	
2017-07-31 21:15:04,460 Epoch[45] Batch [210]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092872,	
2017-07-31 21:15:08,385 Epoch[45] Batch [220]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.092870,	
2017-07-31 21:15:12,265 Epoch[45] Batch [230]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092920,	
2017-07-31 21:15:16,206 Epoch[45] Batch [240]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092570,	
2017-07-31 21:15:20,103 Epoch[45] Batch [250]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092547,	
2017-07-31 21:15:23,981 Epoch[45] Batch [260]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092646,	
2017-07-31 21:15:27,882 Epoch[45] Batch [270]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092613,	
2017-07-31 21:15:31,807 Epoch[45] Batch [280]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.093356,	
2017-07-31 21:15:35,745 Epoch[45] Batch [290]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093052,	
2017-07-31 21:15:39,654 Epoch[45] Batch [300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.092726,	
2017-07-31 21:15:43,547 Epoch[45] Batch [310]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092745,	
2017-07-31 21:15:47,474 Epoch[45] Batch [320]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.092884,	
2017-07-31 21:15:51,429 Epoch[45] Batch [330]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.093185,	
2017-07-31 21:15:55,242 Epoch[45] Batch [340]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.093520,	
2017-07-31 21:15:59,131 Epoch[45] Batch [350]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093778,	
2017-07-31 21:16:02,990 Epoch[45] Batch [360]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093566,	
2017-07-31 21:16:06,823 Epoch[45] Batch [370]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.093427,	
2017-07-31 21:16:10,765 Epoch[45] Batch [380]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093541,	
2017-07-31 21:16:14,574 Epoch[45] Batch [390]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.093561,	
2017-07-31 21:16:18,476 Epoch[45] Batch [400]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093493,	
2017-07-31 21:16:22,334 Epoch[45] Batch [410]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093404,	
2017-07-31 21:16:26,169 Epoch[45] Batch [420]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.093358,	
2017-07-31 21:16:30,086 Epoch[45] Batch [430]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093270,	
2017-07-31 21:16:33,990 Epoch[45] Batch [440]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093341,	
2017-07-31 21:16:37,818 Epoch[45] Batch [450]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.093210,	
2017-07-31 21:16:41,711 Epoch[45] Batch [460]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093207,	
2017-07-31 21:16:45,693 Epoch[45] Batch [470]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.093172,	
2017-07-31 21:16:49,593 Epoch[45] Batch [480]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.093119,	
2017-07-31 21:16:53,457 Epoch[45] Batch [490]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093091,	
2017-07-31 21:16:57,306 Epoch[45] Batch [500]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.093085,	
2017-07-31 21:17:01,146 Epoch[45] Batch [510]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.093084,	
2017-07-31 21:17:04,942 Epoch[45] Batch [520]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.093073,	
2017-07-31 21:17:08,780 Epoch[45] Batch [530]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.092778,	
2017-07-31 21:17:12,699 Epoch[45] Batch [540]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.092522,	
2017-07-31 21:17:16,586 Epoch[45] Batch [550]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092510,	
2017-07-31 21:17:20,521 Epoch[45] Batch [560]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.092353,	
2017-07-31 21:17:24,428 Epoch[45] Batch [570]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.092216,	
2017-07-31 21:17:28,375 Epoch[45] Batch [580]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.092207,	
2017-07-31 21:17:32,173 Epoch[45] Batch [590]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.092362,	
2017-07-31 21:17:35,996 Epoch[45] Batch [600]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.092327,	
2017-07-31 21:17:39,827 Epoch[45] Batch [610]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.092161,	
2017-07-31 21:17:43,712 Epoch[45] Batch [620]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.092305,	
2017-07-31 21:17:47,512 Epoch[45] Batch [630]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.092326,	
2017-07-31 21:17:51,343 Epoch[45] Batch [640]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.092361,	
2017-07-31 21:17:55,202 Epoch[45] Batch [650]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.092358,	
2017-07-31 21:17:59,091 Epoch[45] Batch [660]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092218,	
2017-07-31 21:18:02,940 Epoch[45] Batch [670]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.092305,	
2017-07-31 21:18:06,811 Epoch[45] Batch [680]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092282,	
2017-07-31 21:18:10,679 Epoch[45] Batch [690]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.092406,	
2017-07-31 21:18:14,623 Epoch[45] Batch [700]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.092439,	
2017-07-31 21:18:18,547 Epoch[45] Batch [710]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.092522,	
2017-07-31 21:18:22,333 Epoch[45] Batch [720]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.092651,	
2017-07-31 21:18:26,225 Epoch[45] Batch [730]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092537,	
2017-07-31 21:18:30,146 Epoch[45] Batch [740]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092446,	
2017-07-31 21:18:34,050 Epoch[45] Batch [750]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092411,	
2017-07-31 21:18:37,877 Epoch[45] Batch [760]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.092442,	
2017-07-31 21:18:41,648 Epoch[45] Batch [770]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.092404,	
2017-07-31 21:18:45,520 Epoch[45] Batch [780]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092396,	
2017-07-31 21:18:49,311 Epoch[45] Batch [790]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.092375,	
2017-07-31 21:18:53,156 Epoch[45] Batch [800]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.092241,	
2017-07-31 21:18:56,994 Epoch[45] Batch [810]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.092348,	
2017-07-31 21:19:00,883 Epoch[45] Batch [820]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092296,	
2017-07-31 21:19:04,751 Epoch[45] Batch [830]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.092252,	
2017-07-31 21:19:08,717 Epoch[45] Batch [840]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.092179,	
2017-07-31 21:19:12,523 Epoch[45] Batch [850]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.092258,	
2017-07-31 21:19:16,376 Epoch[45] Batch [860]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.092291,	
2017-07-31 21:19:20,256 Epoch[45] Batch [870]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092184,	
2017-07-31 21:19:24,097 Epoch[45] Batch [880]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.092195,	
2017-07-31 21:19:27,993 Epoch[45] Batch [890]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092135,	
2017-07-31 21:19:31,936 Epoch[45] Batch [900]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092181,	
2017-07-31 21:19:35,751 Epoch[45] Batch [910]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.092252,	
2017-07-31 21:19:39,529 Epoch[45] Batch [920]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.092242,	
2017-07-31 21:19:43,333 Epoch[45] Batch [930]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.092300,	
2017-07-31 21:19:47,220 Epoch[45] Batch [940]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092308,	
2017-07-31 21:19:51,096 Epoch[45] Batch [950]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092414,	
2017-07-31 21:19:54,998 Epoch[45] Batch [960]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092458,	
2017-07-31 21:19:58,859 Epoch[45] Batch [970]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.092457,	
2017-07-31 21:20:02,731 Epoch[45] Batch [980]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092415,	
2017-07-31 21:20:06,634 Epoch[45] Batch [990]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092510,	
2017-07-31 21:20:10,427 Epoch[45] Batch [1000]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.092489,	
2017-07-31 21:20:14,261 Epoch[45] Batch [1010]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.092546,	
2017-07-31 21:20:18,079 Epoch[45] Batch [1020]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.092555,	
2017-07-31 21:20:22,024 Epoch[45] Batch [1030]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.092528,	
2017-07-31 21:20:25,928 Epoch[45] Batch [1040]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092483,	
2017-07-31 21:20:29,884 Epoch[45] Batch [1050]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.092476,	
2017-07-31 21:20:33,718 Epoch[45] Batch [1060]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.092417,	
2017-07-31 21:20:37,486 Epoch[45] Batch [1070]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.092500,	
2017-07-31 21:20:41,393 Epoch[45] Batch [1080]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.092404,	
2017-07-31 21:20:45,268 Epoch[45] Batch [1090]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092479,	
2017-07-31 21:20:49,168 Epoch[45] Batch [1100]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092491,	
2017-07-31 21:20:53,112 Epoch[45] Batch [1110]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.092415,	
2017-07-31 21:20:56,967 Epoch[45] Batch [1120]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.092410,	
2017-07-31 21:21:00,874 Epoch[45] Batch [1130]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.092312,	
2017-07-31 21:21:04,776 Epoch[45] Batch [1140]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092336,	
2017-07-31 21:21:08,691 Epoch[45] Batch [1150]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.092343,	
2017-07-31 21:21:12,596 Epoch[45] Batch [1160]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.092284,	
2017-07-31 21:21:16,486 Epoch[45] Batch [1170]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092240,	
2017-07-31 21:21:20,378 Epoch[45] Batch [1180]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092254,	
2017-07-31 21:21:24,203 Epoch[45] Batch [1190]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.092354,	
2017-07-31 21:21:28,068 Epoch[45] Batch [1200]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.092339,	
2017-07-31 21:21:31,998 Epoch[45] Batch [1210]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092409,	
2017-07-31 21:21:35,840 Epoch[45] Batch [1220]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.092333,	
2017-07-31 21:21:39,648 Epoch[45] Batch [1230]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.092305,	
2017-07-31 21:21:43,540 Epoch[45] Batch [1240]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092323,	
2017-07-31 21:21:47,392 Epoch[45] Batch [1250]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.092304,	
2017-07-31 21:21:51,268 Epoch[45] Batch [1260]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092295,	
2017-07-31 21:21:55,107 Epoch[45] Batch [1270]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.092397,	
2017-07-31 21:21:59,042 Epoch[45] Batch [1280]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.092454,	
2017-07-31 21:22:02,940 Epoch[45] Batch [1290]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092537,	
2017-07-31 21:22:06,788 Epoch[45] Batch [1300]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.092514,	
2017-07-31 21:22:10,623 Epoch[45] Batch [1310]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.092566,	
2017-07-31 21:22:14,466 Epoch[45] Batch [1320]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.092567,	
2017-07-31 21:22:18,363 Epoch[45] Batch [1330]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092605,	
2017-07-31 21:22:22,222 Epoch[45] Batch [1340]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.092665,	
2017-07-31 21:22:26,184 Epoch[45] Batch [1350]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.092691,	
2017-07-31 21:22:30,152 Epoch[45] Batch [1360]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.092706,	
2017-07-31 21:22:34,098 Epoch[45] Batch [1370]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.092703,	
2017-07-31 21:22:37,898 Epoch[45] Batch [1380]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.092750,	
2017-07-31 21:22:41,791 Epoch[45] Batch [1390]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092728,	
2017-07-31 21:22:45,713 Epoch[45] Batch [1400]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092674,	
2017-07-31 21:22:49,584 Epoch[45] Batch [1410]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092631,	
2017-07-31 21:22:53,445 Epoch[45] Batch [1420]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.092670,	
2017-07-31 21:22:57,342 Epoch[45] Batch [1430]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092693,	
2017-07-31 21:23:01,155 Epoch[45] Batch [1440]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.092709,	
2017-07-31 21:23:05,000 Epoch[45] Batch [1450]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.092649,	
2017-07-31 21:23:08,893 Epoch[45] Batch [1460]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092587,	
2017-07-31 21:23:12,723 Epoch[45] Batch [1470]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.092631,	
2017-07-31 21:23:16,587 Epoch[45] Batch [1480]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.092635,	
2017-07-31 21:23:18,876 Epoch[45] Train-FCNLogLoss=0.092617
2017-07-31 21:23:18,876 Epoch[45] Time cost=576.499
2017-07-31 21:23:19,552 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0046.params"
2017-07-31 21:23:21,073 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0046.states"
2017-07-31 21:23:25,623 Epoch[46] Batch [10]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.102109,	
2017-07-31 21:23:29,522 Epoch[46] Batch [20]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.102970,	
2017-07-31 21:23:33,407 Epoch[46] Batch [30]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.100353,	
2017-07-31 21:23:37,316 Epoch[46] Batch [40]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.098782,	
2017-07-31 21:23:41,198 Epoch[46] Batch [50]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.096593,	
2017-07-31 21:23:45,039 Epoch[46] Batch [60]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.095528,	
2017-07-31 21:23:48,918 Epoch[46] Batch [70]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.096074,	
2017-07-31 21:23:52,889 Epoch[46] Batch [80]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094685,	
2017-07-31 21:23:56,789 Epoch[46] Batch [90]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.094215,	
2017-07-31 21:24:00,579 Epoch[46] Batch [100]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.094723,	
2017-07-31 21:24:04,487 Epoch[46] Batch [110]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093812,	
2017-07-31 21:24:08,456 Epoch[46] Batch [120]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.093958,	
2017-07-31 21:24:12,344 Epoch[46] Batch [130]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.095327,	
2017-07-31 21:24:16,256 Epoch[46] Batch [140]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094645,	
2017-07-31 21:24:20,108 Epoch[46] Batch [150]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.095127,	
2017-07-31 21:24:24,010 Epoch[46] Batch [160]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.095334,	
2017-07-31 21:24:27,829 Epoch[46] Batch [170]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.095327,	
2017-07-31 21:24:31,731 Epoch[46] Batch [180]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094754,	
2017-07-31 21:24:35,601 Epoch[46] Batch [190]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.094391,	
2017-07-31 21:24:39,429 Epoch[46] Batch [200]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.094360,	
2017-07-31 21:24:43,315 Epoch[46] Batch [210]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093741,	
2017-07-31 21:24:47,208 Epoch[46] Batch [220]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094115,	
2017-07-31 21:24:51,126 Epoch[46] Batch [230]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094133,	
2017-07-31 21:24:55,001 Epoch[46] Batch [240]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093802,	
2017-07-31 21:24:58,866 Epoch[46] Batch [250]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093872,	
2017-07-31 21:25:02,806 Epoch[46] Batch [260]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093698,	
2017-07-31 21:25:06,667 Epoch[46] Batch [270]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093478,	
2017-07-31 21:25:10,482 Epoch[46] Batch [280]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.093481,	
2017-07-31 21:25:14,364 Epoch[46] Batch [290]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093313,	
2017-07-31 21:25:18,244 Epoch[46] Batch [300]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093386,	
2017-07-31 21:25:22,136 Epoch[46] Batch [310]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093134,	
2017-07-31 21:25:25,921 Epoch[46] Batch [320]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.092745,	
2017-07-31 21:25:29,802 Epoch[46] Batch [330]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092679,	
2017-07-31 21:25:33,661 Epoch[46] Batch [340]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.092685,	
2017-07-31 21:25:37,459 Epoch[46] Batch [350]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.092701,	
2017-07-31 21:25:41,492 Epoch[46] Batch [360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.092366,	
2017-07-31 21:25:45,350 Epoch[46] Batch [370]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.092389,	
2017-07-31 21:25:49,262 Epoch[46] Batch [380]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.092439,	
2017-07-31 21:25:53,119 Epoch[46] Batch [390]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.092765,	
2017-07-31 21:25:57,087 Epoch[46] Batch [400]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.092847,	
2017-07-31 21:26:01,008 Epoch[46] Batch [410]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092740,	
2017-07-31 21:26:04,899 Epoch[46] Batch [420]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092537,	
2017-07-31 21:26:08,801 Epoch[46] Batch [430]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092435,	
2017-07-31 21:26:12,643 Epoch[46] Batch [440]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.092449,	
2017-07-31 21:26:16,608 Epoch[46] Batch [450]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.092316,	
2017-07-31 21:26:20,415 Epoch[46] Batch [460]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.092312,	
2017-07-31 21:26:24,300 Epoch[46] Batch [470]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.092228,	
2017-07-31 21:26:28,175 Epoch[46] Batch [480]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092289,	
2017-07-31 21:26:32,115 Epoch[46] Batch [490]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092130,	
2017-07-31 21:26:36,067 Epoch[46] Batch [500]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.091934,	
2017-07-31 21:26:40,024 Epoch[46] Batch [510]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.091942,	
2017-07-31 21:26:44,053 Epoch[46] Batch [520]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.091933,	
2017-07-31 21:26:47,901 Epoch[46] Batch [530]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.091861,	
2017-07-31 21:26:51,920 Epoch[46] Batch [540]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.091871,	
2017-07-31 21:26:55,840 Epoch[46] Batch [550]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.091821,	
2017-07-31 21:26:59,708 Epoch[46] Batch [560]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.091816,	
2017-07-31 21:27:03,607 Epoch[46] Batch [570]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.092110,	
2017-07-31 21:27:07,511 Epoch[46] Batch [580]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092072,	
2017-07-31 21:27:11,379 Epoch[46] Batch [590]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.092025,	
2017-07-31 21:27:15,270 Epoch[46] Batch [600]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092154,	
2017-07-31 21:27:19,158 Epoch[46] Batch [610]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092256,	
2017-07-31 21:27:22,993 Epoch[46] Batch [620]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.092208,	
2017-07-31 21:27:26,870 Epoch[46] Batch [630]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092251,	
2017-07-31 21:27:30,800 Epoch[46] Batch [640]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092181,	
2017-07-31 21:27:34,640 Epoch[46] Batch [650]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.092028,	
2017-07-31 21:27:38,570 Epoch[46] Batch [660]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092125,	
2017-07-31 21:27:42,455 Epoch[46] Batch [670]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.092074,	
2017-07-31 21:27:46,325 Epoch[46] Batch [680]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092015,	
2017-07-31 21:27:50,233 Epoch[46] Batch [690]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.091922,	
2017-07-31 21:27:54,130 Epoch[46] Batch [700]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.091868,	
2017-07-31 21:27:57,958 Epoch[46] Batch [710]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.091898,	
2017-07-31 21:28:01,892 Epoch[46] Batch [720]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.091965,	
2017-07-31 21:28:05,741 Epoch[46] Batch [730]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.091904,	
2017-07-31 21:28:09,587 Epoch[46] Batch [740]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.091838,	
2017-07-31 21:28:13,572 Epoch[46] Batch [750]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.091859,	
2017-07-31 21:28:17,542 Epoch[46] Batch [760]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.091916,	
2017-07-31 21:28:21,400 Epoch[46] Batch [770]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.091801,	
2017-07-31 21:28:25,392 Epoch[46] Batch [780]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.091822,	
2017-07-31 21:28:29,254 Epoch[46] Batch [790]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.091896,	
2017-07-31 21:28:33,262 Epoch[46] Batch [800]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091848,	
2017-07-31 21:28:37,160 Epoch[46] Batch [810]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.091674,	
2017-07-31 21:28:41,026 Epoch[46] Batch [820]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.091611,	
2017-07-31 21:28:44,904 Epoch[46] Batch [830]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.091561,	
2017-07-31 21:28:48,851 Epoch[46] Batch [840]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.091537,	
2017-07-31 21:28:52,728 Epoch[46] Batch [850]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.091356,	
2017-07-31 21:28:56,679 Epoch[46] Batch [860]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.091465,	
2017-07-31 21:29:00,616 Epoch[46] Batch [870]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.091498,	
2017-07-31 21:29:04,591 Epoch[46] Batch [880]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.091514,	
2017-07-31 21:29:08,474 Epoch[46] Batch [890]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.091562,	
2017-07-31 21:29:12,370 Epoch[46] Batch [900]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.091520,	
2017-07-31 21:29:16,221 Epoch[46] Batch [910]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.091449,	
2017-07-31 21:29:20,049 Epoch[46] Batch [920]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.091594,	
2017-07-31 21:29:23,962 Epoch[46] Batch [930]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.091562,	
2017-07-31 21:29:27,753 Epoch[46] Batch [940]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.091570,	
2017-07-31 21:29:31,629 Epoch[46] Batch [950]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.091616,	
2017-07-31 21:29:35,476 Epoch[46] Batch [960]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.091721,	
2017-07-31 21:29:39,313 Epoch[46] Batch [970]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.091800,	
2017-07-31 21:29:43,155 Epoch[46] Batch [980]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.091869,	
2017-07-31 21:29:47,037 Epoch[46] Batch [990]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.091831,	
2017-07-31 21:29:50,877 Epoch[46] Batch [1000]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.091813,	
2017-07-31 21:29:54,745 Epoch[46] Batch [1010]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.091825,	
2017-07-31 21:29:58,604 Epoch[46] Batch [1020]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.091909,	
2017-07-31 21:30:02,467 Epoch[46] Batch [1030]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.091868,	
2017-07-31 21:30:06,500 Epoch[46] Batch [1040]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.091928,	
2017-07-31 21:30:10,437 Epoch[46] Batch [1050]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.091975,	
2017-07-31 21:30:14,246 Epoch[46] Batch [1060]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.092024,	
2017-07-31 21:30:18,054 Epoch[46] Batch [1070]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.092097,	
2017-07-31 21:30:21,973 Epoch[46] Batch [1080]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.092063,	
2017-07-31 21:30:25,819 Epoch[46] Batch [1090]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.091978,	
2017-07-31 21:30:29,713 Epoch[46] Batch [1100]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.091959,	
2017-07-31 21:30:33,581 Epoch[46] Batch [1110]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.091917,	
2017-07-31 21:30:37,377 Epoch[46] Batch [1120]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.091884,	
2017-07-31 21:30:41,234 Epoch[46] Batch [1130]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.091837,	
2017-07-31 21:30:45,151 Epoch[46] Batch [1140]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.091844,	
2017-07-31 21:30:49,150 Epoch[46] Batch [1150]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.091836,	
2017-07-31 21:30:53,099 Epoch[46] Batch [1160]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.091928,	
2017-07-31 21:30:56,923 Epoch[46] Batch [1170]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.091859,	
2017-07-31 21:31:00,775 Epoch[46] Batch [1180]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.091865,	
2017-07-31 21:31:04,651 Epoch[46] Batch [1190]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.091914,	
2017-07-31 21:31:08,505 Epoch[46] Batch [1200]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.091984,	
2017-07-31 21:31:12,377 Epoch[46] Batch [1210]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.091981,	
2017-07-31 21:31:16,270 Epoch[46] Batch [1220]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.091929,	
2017-07-31 21:31:20,173 Epoch[46] Batch [1230]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.091979,	
2017-07-31 21:31:23,990 Epoch[46] Batch [1240]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.091937,	
2017-07-31 21:31:27,847 Epoch[46] Batch [1250]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.091952,	
2017-07-31 21:31:31,675 Epoch[46] Batch [1260]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.091954,	
2017-07-31 21:31:35,624 Epoch[46] Batch [1270]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.091994,	
2017-07-31 21:31:39,595 Epoch[46] Batch [1280]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.092007,	
2017-07-31 21:31:43,358 Epoch[46] Batch [1290]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.092129,	
2017-07-31 21:31:47,254 Epoch[46] Batch [1300]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092118,	
2017-07-31 21:31:51,144 Epoch[46] Batch [1310]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092131,	
2017-07-31 21:31:55,102 Epoch[46] Batch [1320]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.092056,	
2017-07-31 21:31:59,027 Epoch[46] Batch [1330]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.092035,	
2017-07-31 21:32:02,924 Epoch[46] Batch [1340]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092077,	
2017-07-31 21:32:06,768 Epoch[46] Batch [1350]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.092058,	
2017-07-31 21:32:10,708 Epoch[46] Batch [1360]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.091985,	
2017-07-31 21:32:14,581 Epoch[46] Batch [1370]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092030,	
2017-07-31 21:32:18,468 Epoch[46] Batch [1380]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092004,	
2017-07-31 21:32:22,319 Epoch[46] Batch [1390]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.092003,	
2017-07-31 21:32:26,165 Epoch[46] Batch [1400]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.091972,	
2017-07-31 21:32:30,022 Epoch[46] Batch [1410]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.091939,	
2017-07-31 21:32:33,896 Epoch[46] Batch [1420]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.091991,	
2017-07-31 21:32:37,796 Epoch[46] Batch [1430]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.091979,	
2017-07-31 21:32:41,690 Epoch[46] Batch [1440]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.092057,	
2017-07-31 21:32:45,685 Epoch[46] Batch [1450]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.092133,	
2017-07-31 21:32:49,565 Epoch[46] Batch [1460]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092065,	
2017-07-31 21:32:53,445 Epoch[46] Batch [1470]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092154,	
2017-07-31 21:32:57,290 Epoch[46] Batch [1480]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.092082,	
2017-07-31 21:32:59,609 Epoch[46] Train-FCNLogLoss=0.092068
2017-07-31 21:32:59,609 Epoch[46] Time cost=578.536
2017-07-31 21:33:00,231 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0047.params"
2017-07-31 21:33:01,751 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0047.states"
2017-07-31 21:33:06,231 Epoch[47] Batch [10]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.086090,	
2017-07-31 21:33:10,046 Epoch[47] Batch [20]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.091748,	
2017-07-31 21:33:13,951 Epoch[47] Batch [30]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.091389,	
2017-07-31 21:33:17,826 Epoch[47] Batch [40]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.092234,	
2017-07-31 21:33:21,739 Epoch[47] Batch [50]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.092978,	
2017-07-31 21:33:25,605 Epoch[47] Batch [60]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093601,	
2017-07-31 21:33:29,484 Epoch[47] Batch [70]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.093590,	
2017-07-31 21:33:33,443 Epoch[47] Batch [80]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.092535,	
2017-07-31 21:33:37,278 Epoch[47] Batch [90]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.093163,	
2017-07-31 21:33:41,137 Epoch[47] Batch [100]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093462,	
2017-07-31 21:33:45,082 Epoch[47] Batch [110]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.093918,	
2017-07-31 21:33:48,934 Epoch[47] Batch [120]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.094313,	
2017-07-31 21:33:52,719 Epoch[47] Batch [130]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.094327,	
2017-07-31 21:33:56,574 Epoch[47] Batch [140]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.094266,	
2017-07-31 21:34:00,430 Epoch[47] Batch [150]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093876,	
2017-07-31 21:34:04,212 Epoch[47] Batch [160]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.093861,	
2017-07-31 21:34:08,102 Epoch[47] Batch [170]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093971,	
2017-07-31 21:34:11,901 Epoch[47] Batch [180]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.094422,	
2017-07-31 21:34:15,774 Epoch[47] Batch [190]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.094520,	
2017-07-31 21:34:19,609 Epoch[47] Batch [200]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.094924,	
2017-07-31 21:34:23,501 Epoch[47] Batch [210]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.095030,	
2017-07-31 21:34:27,390 Epoch[47] Batch [220]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.095100,	
2017-07-31 21:34:31,284 Epoch[47] Batch [230]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094914,	
2017-07-31 21:34:35,104 Epoch[47] Batch [240]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.095130,	
2017-07-31 21:34:39,003 Epoch[47] Batch [250]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095153,	
2017-07-31 21:34:42,888 Epoch[47] Batch [260]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094961,	
2017-07-31 21:34:46,843 Epoch[47] Batch [270]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094855,	
2017-07-31 21:34:50,722 Epoch[47] Batch [280]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094840,	
2017-07-31 21:34:54,660 Epoch[47] Batch [290]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094460,	
2017-07-31 21:34:58,535 Epoch[47] Batch [300]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.094541,	
2017-07-31 21:35:02,589 Epoch[47] Batch [310]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094240,	
2017-07-31 21:35:06,469 Epoch[47] Batch [320]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094343,	
2017-07-31 21:35:10,325 Epoch[47] Batch [330]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.094313,	
2017-07-31 21:35:14,266 Epoch[47] Batch [340]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094099,	
2017-07-31 21:35:18,147 Epoch[47] Batch [350]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094032,	
2017-07-31 21:35:22,039 Epoch[47] Batch [360]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.094008,	
2017-07-31 21:35:25,947 Epoch[47] Batch [370]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.093789,	
2017-07-31 21:35:29,785 Epoch[47] Batch [380]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.093816,	
2017-07-31 21:35:33,788 Epoch[47] Batch [390]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.093594,	
2017-07-31 21:35:37,685 Epoch[47] Batch [400]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.093442,	
2017-07-31 21:35:41,598 Epoch[47] Batch [410]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093501,	
2017-07-31 21:35:45,452 Epoch[47] Batch [420]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.093449,	
2017-07-31 21:35:49,374 Epoch[47] Batch [430]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093464,	
2017-07-31 21:35:53,189 Epoch[47] Batch [440]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.093412,	
2017-07-31 21:35:57,050 Epoch[47] Batch [450]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093500,	
2017-07-31 21:36:00,889 Epoch[47] Batch [460]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.093273,	
2017-07-31 21:36:04,792 Epoch[47] Batch [470]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093329,	
2017-07-31 21:36:08,593 Epoch[47] Batch [480]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.093273,	
2017-07-31 21:36:12,423 Epoch[47] Batch [490]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.093220,	
2017-07-31 21:36:16,243 Epoch[47] Batch [500]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.093309,	
2017-07-31 21:36:20,074 Epoch[47] Batch [510]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.093209,	
2017-07-31 21:36:24,004 Epoch[47] Batch [520]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093205,	
2017-07-31 21:36:27,852 Epoch[47] Batch [530]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.093082,	
2017-07-31 21:36:31,727 Epoch[47] Batch [540]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093044,	
2017-07-31 21:36:35,605 Epoch[47] Batch [550]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093014,	
2017-07-31 21:36:39,485 Epoch[47] Batch [560]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.092898,	
2017-07-31 21:36:43,368 Epoch[47] Batch [570]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.092913,	
2017-07-31 21:36:47,284 Epoch[47] Batch [580]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.092919,	
2017-07-31 21:36:51,132 Epoch[47] Batch [590]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.092764,	
2017-07-31 21:36:55,034 Epoch[47] Batch [600]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092786,	
2017-07-31 21:36:58,904 Epoch[47] Batch [610]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.092722,	
2017-07-31 21:37:02,834 Epoch[47] Batch [620]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092847,	
2017-07-31 21:37:06,727 Epoch[47] Batch [630]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.092803,	
2017-07-31 21:37:10,643 Epoch[47] Batch [640]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.092758,	
2017-07-31 21:37:14,602 Epoch[47] Batch [650]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.092779,	
2017-07-31 21:37:18,474 Epoch[47] Batch [660]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.092796,	
2017-07-31 21:37:22,381 Epoch[47] Batch [670]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.092852,	
2017-07-31 21:37:26,251 Epoch[47] Batch [680]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.092789,	
2017-07-31 21:37:30,172 Epoch[47] Batch [690]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.092965,	
2017-07-31 21:37:34,140 Epoch[47] Batch [700]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.093009,	
2017-07-31 21:37:37,938 Epoch[47] Batch [710]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.093101,	
2017-07-31 21:37:41,829 Epoch[47] Batch [720]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093094,	
2017-07-31 21:37:45,833 Epoch[47] Batch [730]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.093110,	
2017-07-31 21:37:49,819 Epoch[47] Batch [740]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.092947,	
2017-07-31 21:37:54,177 Epoch[47] Batch [750]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.092899,	
2017-07-31 21:37:58,282 Epoch[47] Batch [760]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092845,	
2017-07-31 21:38:02,497 Epoch[47] Batch [770]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.092834,	
2017-07-31 21:38:07,006 Epoch[47] Batch [780]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.092795,	
2017-07-31 21:38:11,789 Epoch[47] Batch [790]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092836,	
2017-07-31 21:38:16,714 Epoch[47] Batch [800]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.092962,	
2017-07-31 21:38:20,964 Epoch[47] Batch [810]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.092902,	
2017-07-31 21:38:25,588 Epoch[47] Batch [820]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.092963,	
2017-07-31 21:38:29,705 Epoch[47] Batch [830]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.092972,	
2017-07-31 21:38:33,940 Epoch[47] Batch [840]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.092999,	
2017-07-31 21:38:38,530 Epoch[47] Batch [850]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.093034,	
2017-07-31 21:38:42,857 Epoch[47] Batch [860]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.093003,	
2017-07-31 21:38:47,175 Epoch[47] Batch [870]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.092936,	
2017-07-31 21:38:51,321 Epoch[47] Batch [880]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.092948,	
2017-07-31 21:38:55,644 Epoch[47] Batch [890]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.093102,	
2017-07-31 21:39:00,299 Epoch[47] Batch [900]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.093075,	
2017-07-31 21:39:04,806 Epoch[47] Batch [910]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.093107,	
2017-07-31 21:39:09,178 Epoch[47] Batch [920]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.093203,	
2017-07-31 21:39:13,392 Epoch[47] Batch [930]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.093112,	
2017-07-31 21:39:18,080 Epoch[47] Batch [940]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.093085,	
2017-07-31 21:39:22,220 Epoch[47] Batch [950]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.093123,	
2017-07-31 21:39:26,469 Epoch[47] Batch [960]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.093139,	
2017-07-31 21:39:30,739 Epoch[47] Batch [970]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.093121,	
2017-07-31 21:39:35,862 Epoch[47] Batch [980]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.093134,	
2017-07-31 21:39:40,704 Epoch[47] Batch [990]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.093135,	
2017-07-31 21:39:45,247 Epoch[47] Batch [1000]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.093118,	
2017-07-31 21:39:49,995 Epoch[47] Batch [1010]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.093046,	
2017-07-31 21:39:54,305 Epoch[47] Batch [1020]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.093052,	
2017-07-31 21:39:58,419 Epoch[47] Batch [1030]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.092979,	
2017-07-31 21:40:03,084 Epoch[47] Batch [1040]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.092996,	
2017-07-31 21:40:07,326 Epoch[47] Batch [1050]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.093062,	
2017-07-31 21:40:11,908 Epoch[47] Batch [1060]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.093068,	
2017-07-31 21:40:16,385 Epoch[47] Batch [1070]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.093019,	
2017-07-31 21:40:21,203 Epoch[47] Batch [1080]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092997,	
2017-07-31 21:40:26,096 Epoch[47] Batch [1090]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092948,	
2017-07-31 21:40:31,002 Epoch[47] Batch [1100]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.093017,	
2017-07-31 21:40:35,595 Epoch[47] Batch [1110]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092983,	
2017-07-31 21:40:40,018 Epoch[47] Batch [1120]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.092944,	
2017-07-31 21:40:44,104 Epoch[47] Batch [1130]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.092911,	
2017-07-31 21:40:48,705 Epoch[47] Batch [1140]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092959,	
2017-07-31 21:40:52,829 Epoch[47] Batch [1150]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092919,	
2017-07-31 21:40:57,459 Epoch[47] Batch [1160]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.092938,	
2017-07-31 21:41:01,791 Epoch[47] Batch [1170]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.093035,	
2017-07-31 21:41:06,247 Epoch[47] Batch [1180]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.093024,	
2017-07-31 21:41:10,774 Epoch[47] Batch [1190]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092953,	
2017-07-31 21:41:15,408 Epoch[47] Batch [1200]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.092912,	
2017-07-31 21:41:19,640 Epoch[47] Batch [1210]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.092974,	
2017-07-31 21:41:24,132 Epoch[47] Batch [1220]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.092946,	
2017-07-31 21:41:28,672 Epoch[47] Batch [1230]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092964,	
2017-07-31 21:41:32,982 Epoch[47] Batch [1240]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.092969,	
2017-07-31 21:41:37,349 Epoch[47] Batch [1250]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.093012,	
2017-07-31 21:41:41,524 Epoch[47] Batch [1260]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.092952,	
2017-07-31 21:41:46,419 Epoch[47] Batch [1270]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.092833,	
2017-07-31 21:41:51,017 Epoch[47] Batch [1280]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092790,	
2017-07-31 21:41:55,701 Epoch[47] Batch [1290]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092775,	
2017-07-31 21:42:00,236 Epoch[47] Batch [1300]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.092790,	
2017-07-31 21:42:04,443 Epoch[47] Batch [1310]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.092803,	
2017-07-31 21:42:08,688 Epoch[47] Batch [1320]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.092811,	
2017-07-31 21:42:12,904 Epoch[47] Batch [1330]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.092828,	
2017-07-31 21:42:17,044 Epoch[47] Batch [1340]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.092864,	
2017-07-31 21:42:21,265 Epoch[47] Batch [1350]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.092933,	
2017-07-31 21:42:25,891 Epoch[47] Batch [1360]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.092947,	
2017-07-31 21:42:30,859 Epoch[47] Batch [1370]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.092886,	
2017-07-31 21:42:35,716 Epoch[47] Batch [1380]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.092944,	
2017-07-31 21:42:40,169 Epoch[47] Batch [1390]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.092957,	
2017-07-31 21:42:44,833 Epoch[47] Batch [1400]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.092972,	
2017-07-31 21:42:49,756 Epoch[47] Batch [1410]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.092971,	
2017-07-31 21:42:54,420 Epoch[47] Batch [1420]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.093079,	
2017-07-31 21:42:59,173 Epoch[47] Batch [1430]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.093041,	
2017-07-31 21:43:03,665 Epoch[47] Batch [1440]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.093044,	
2017-07-31 21:43:08,402 Epoch[47] Batch [1450]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.093015,	
2017-07-31 21:43:13,009 Epoch[47] Batch [1460]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.093008,	
2017-07-31 21:43:17,661 Epoch[47] Batch [1470]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.092992,	
2017-07-31 21:43:22,293 Epoch[47] Batch [1480]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.092973,	
2017-07-31 21:43:25,083 Epoch[47] Train-FCNLogLoss=0.092976
2017-07-31 21:43:25,083 Epoch[47] Time cost=623.332
2017-07-31 21:43:25,951 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0048.params"
2017-07-31 21:43:28,206 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0048.states"
2017-07-31 21:43:33,305 Epoch[48] Batch [10]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.090683,	
2017-07-31 21:43:37,559 Epoch[48] Batch [20]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.095323,	
2017-07-31 21:43:41,836 Epoch[48] Batch [30]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095445,	
2017-07-31 21:43:45,974 Epoch[48] Batch [40]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094847,	
2017-07-31 21:43:50,276 Epoch[48] Batch [50]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.092422,	
2017-07-31 21:43:54,721 Epoch[48] Batch [60]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.091018,	
2017-07-31 21:43:59,120 Epoch[48] Batch [70]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.090919,	
2017-07-31 21:44:03,390 Epoch[48] Batch [80]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.091715,	
2017-07-31 21:44:07,889 Epoch[48] Batch [90]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091774,	
2017-07-31 21:44:12,544 Epoch[48] Batch [100]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091698,	
2017-07-31 21:44:17,179 Epoch[48] Batch [110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.091430,	
2017-07-31 21:44:21,313 Epoch[48] Batch [120]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.091246,	
2017-07-31 21:44:25,910 Epoch[48] Batch [130]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091429,	
2017-07-31 21:44:30,323 Epoch[48] Batch [140]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091983,	
2017-07-31 21:44:34,824 Epoch[48] Batch [150]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091413,	
2017-07-31 21:44:38,968 Epoch[48] Batch [160]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.092510,	
2017-07-31 21:44:43,271 Epoch[48] Batch [170]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.092565,	
2017-07-31 21:44:47,514 Epoch[48] Batch [180]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.092099,	
2017-07-31 21:44:51,777 Epoch[48] Batch [190]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.091636,	
2017-07-31 21:44:55,954 Epoch[48] Batch [200]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091865,	
2017-07-31 21:45:00,246 Epoch[48] Batch [210]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.091499,	
2017-07-31 21:45:04,713 Epoch[48] Batch [220]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.091687,	
2017-07-31 21:45:09,163 Epoch[48] Batch [230]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091865,	
2017-07-31 21:45:13,497 Epoch[48] Batch [240]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.091892,	
2017-07-31 21:45:17,870 Epoch[48] Batch [250]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.091753,	
2017-07-31 21:45:22,108 Epoch[48] Batch [260]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091668,	
2017-07-31 21:45:26,456 Epoch[48] Batch [270]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.091733,	
2017-07-31 21:45:31,189 Epoch[48] Batch [280]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.091801,	
2017-07-31 21:45:35,680 Epoch[48] Batch [290]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091858,	
2017-07-31 21:45:40,154 Epoch[48] Batch [300]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091811,	
2017-07-31 21:45:44,318 Epoch[48] Batch [310]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091924,	
2017-07-31 21:45:48,433 Epoch[48] Batch [320]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091931,	
2017-07-31 21:45:52,821 Epoch[48] Batch [330]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.091593,	
2017-07-31 21:45:56,850 Epoch[48] Batch [340]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.091380,	
2017-07-31 21:46:01,034 Epoch[48] Batch [350]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.091606,	
2017-07-31 21:46:05,599 Epoch[48] Batch [360]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091675,	
2017-07-31 21:46:10,090 Epoch[48] Batch [370]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091837,	
2017-07-31 21:46:14,490 Epoch[48] Batch [380]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.091942,	
2017-07-31 21:46:19,165 Epoch[48] Batch [390]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092026,	
2017-07-31 21:46:23,491 Epoch[48] Batch [400]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.092154,	
2017-07-31 21:46:27,972 Epoch[48] Batch [410]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.092442,	
2017-07-31 21:46:32,415 Epoch[48] Batch [420]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.092481,	
2017-07-31 21:46:36,576 Epoch[48] Batch [430]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.092511,	
2017-07-31 21:46:40,632 Epoch[48] Batch [440]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.092290,	
2017-07-31 21:46:44,980 Epoch[48] Batch [450]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.092263,	
2017-07-31 21:46:49,596 Epoch[48] Batch [460]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092521,	
2017-07-31 21:46:53,774 Epoch[48] Batch [470]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.092379,	
2017-07-31 21:46:58,412 Epoch[48] Batch [480]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092173,	
2017-07-31 21:47:02,643 Epoch[48] Batch [490]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.092483,	
2017-07-31 21:47:06,971 Epoch[48] Batch [500]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.092574,	
2017-07-31 21:47:11,324 Epoch[48] Batch [510]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.092740,	
2017-07-31 21:47:15,660 Epoch[48] Batch [520]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.092666,	
2017-07-31 21:47:20,197 Epoch[48] Batch [530]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.092512,	
2017-07-31 21:47:24,575 Epoch[48] Batch [540]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.092472,	
2017-07-31 21:47:28,773 Epoch[48] Batch [550]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.092311,	
2017-07-31 21:47:33,227 Epoch[48] Batch [560]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.092203,	
2017-07-31 21:47:37,811 Epoch[48] Batch [570]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092002,	
2017-07-31 21:47:42,385 Epoch[48] Batch [580]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091951,	
2017-07-31 21:47:46,638 Epoch[48] Batch [590]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.092073,	
2017-07-31 21:47:50,810 Epoch[48] Batch [600]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.092046,	
2017-07-31 21:47:55,131 Epoch[48] Batch [610]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.092067,	
2017-07-31 21:47:59,696 Epoch[48] Batch [620]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092015,	
2017-07-31 21:48:03,843 Epoch[48] Batch [630]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.091950,	
2017-07-31 21:48:08,620 Epoch[48] Batch [640]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.092056,	
2017-07-31 21:48:12,994 Epoch[48] Batch [650]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.091948,	
2017-07-31 21:48:17,273 Epoch[48] Batch [660]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.092039,	
2017-07-31 21:48:21,786 Epoch[48] Batch [670]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091989,	
2017-07-31 21:48:26,816 Epoch[48] Batch [680]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.091849,	
2017-07-31 21:48:31,372 Epoch[48] Batch [690]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092097,	
2017-07-31 21:48:36,165 Epoch[48] Batch [700]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092153,	
2017-07-31 21:48:40,725 Epoch[48] Batch [710]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092184,	
2017-07-31 21:48:45,303 Epoch[48] Batch [720]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092067,	
2017-07-31 21:48:49,755 Epoch[48] Batch [730]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.092109,	
2017-07-31 21:48:54,300 Epoch[48] Batch [740]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092124,	
2017-07-31 21:48:58,913 Epoch[48] Batch [750]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092129,	
2017-07-31 21:49:03,478 Epoch[48] Batch [760]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092181,	
2017-07-31 21:49:07,933 Epoch[48] Batch [770]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.092265,	
2017-07-31 21:49:12,942 Epoch[48] Batch [780]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.092334,	
2017-07-31 21:49:17,339 Epoch[48] Batch [790]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.092261,	
2017-07-31 21:49:21,672 Epoch[48] Batch [800]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.092307,	
2017-07-31 21:49:26,442 Epoch[48] Batch [810]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092284,	
2017-07-31 21:49:30,770 Epoch[48] Batch [820]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.092251,	
2017-07-31 21:49:35,190 Epoch[48] Batch [830]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.092142,	
2017-07-31 21:49:39,753 Epoch[48] Batch [840]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092170,	
2017-07-31 21:49:43,787 Epoch[48] Batch [850]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.092180,	
2017-07-31 21:49:48,334 Epoch[48] Batch [860]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092084,	
2017-07-31 21:49:52,900 Epoch[48] Batch [870]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091930,	
2017-07-31 21:49:57,014 Epoch[48] Batch [880]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091892,	
2017-07-31 21:50:01,437 Epoch[48] Batch [890]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.091949,	
2017-07-31 21:50:05,803 Epoch[48] Batch [900]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.091926,	
2017-07-31 21:50:10,155 Epoch[48] Batch [910]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.091966,	
2017-07-31 21:50:14,329 Epoch[48] Batch [920]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091928,	
2017-07-31 21:50:18,573 Epoch[48] Batch [930]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.091922,	
2017-07-31 21:50:22,577 Epoch[48] Batch [940]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.091961,	
2017-07-31 21:50:26,711 Epoch[48] Batch [950]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.092026,	
2017-07-31 21:50:30,866 Epoch[48] Batch [960]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.092042,	
2017-07-31 21:50:35,241 Epoch[48] Batch [970]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.091983,	
2017-07-31 21:50:39,785 Epoch[48] Batch [980]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091998,	
2017-07-31 21:50:44,266 Epoch[48] Batch [990]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.091967,	
2017-07-31 21:50:48,383 Epoch[48] Batch [1000]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091945,	
2017-07-31 21:50:53,021 Epoch[48] Batch [1010]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092001,	
2017-07-31 21:50:57,520 Epoch[48] Batch [1020]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091959,	
2017-07-31 21:51:01,498 Epoch[48] Batch [1030]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.091918,	
2017-07-31 21:51:05,784 Epoch[48] Batch [1040]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.092005,	
2017-07-31 21:51:09,936 Epoch[48] Batch [1050]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.092179,	
2017-07-31 21:51:14,030 Epoch[48] Batch [1060]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.092159,	
2017-07-31 21:51:18,465 Epoch[48] Batch [1070]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.092166,	
2017-07-31 21:51:22,817 Epoch[48] Batch [1080]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.092187,	
2017-07-31 21:51:26,921 Epoch[48] Batch [1090]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.092231,	
2017-07-31 21:51:31,426 Epoch[48] Batch [1100]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.092121,	
2017-07-31 21:51:36,298 Epoch[48] Batch [1110]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.092030,	
2017-07-31 21:51:40,685 Epoch[48] Batch [1120]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.092079,	
2017-07-31 21:51:45,190 Epoch[48] Batch [1130]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.092100,	
2017-07-31 21:51:49,565 Epoch[48] Batch [1140]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.092075,	
2017-07-31 21:51:53,660 Epoch[48] Batch [1150]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.092120,	
2017-07-31 21:51:57,742 Epoch[48] Batch [1160]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.092127,	
2017-07-31 21:52:01,963 Epoch[48] Batch [1170]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.092132,	
2017-07-31 21:52:06,247 Epoch[48] Batch [1180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.092208,	
2017-07-31 21:52:10,652 Epoch[48] Batch [1190]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.092201,	
2017-07-31 21:52:15,066 Epoch[48] Batch [1200]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.092250,	
2017-07-31 21:52:19,668 Epoch[48] Batch [1210]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092145,	
2017-07-31 21:52:24,235 Epoch[48] Batch [1220]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092126,	
2017-07-31 21:52:28,596 Epoch[48] Batch [1230]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.092161,	
2017-07-31 21:52:33,321 Epoch[48] Batch [1240]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092219,	
2017-07-31 21:52:37,761 Epoch[48] Batch [1250]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.092202,	
2017-07-31 21:52:42,106 Epoch[48] Batch [1260]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.092200,	
2017-07-31 21:52:46,911 Epoch[48] Batch [1270]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.092160,	
2017-07-31 21:52:51,662 Epoch[48] Batch [1280]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092061,	
2017-07-31 21:52:56,456 Epoch[48] Batch [1290]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092093,	
2017-07-31 21:53:00,788 Epoch[48] Batch [1300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.092083,	
2017-07-31 21:53:04,942 Epoch[48] Batch [1310]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.092171,	
2017-07-31 21:53:09,737 Epoch[48] Batch [1320]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092193,	
2017-07-31 21:53:14,171 Epoch[48] Batch [1330]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.092218,	
2017-07-31 21:53:18,854 Epoch[48] Batch [1340]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092279,	
2017-07-31 21:53:23,248 Epoch[48] Batch [1350]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.092273,	
2017-07-31 21:53:27,485 Epoch[48] Batch [1360]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.092274,	
2017-07-31 21:53:32,269 Epoch[48] Batch [1370]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092298,	
2017-07-31 21:53:37,183 Epoch[48] Batch [1380]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.092367,	
2017-07-31 21:53:41,810 Epoch[48] Batch [1390]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.092366,	
2017-07-31 21:53:46,468 Epoch[48] Batch [1400]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092396,	
2017-07-31 21:53:50,930 Epoch[48] Batch [1410]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.092397,	
2017-07-31 21:53:55,592 Epoch[48] Batch [1420]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.092364,	
2017-07-31 21:54:00,191 Epoch[48] Batch [1430]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092325,	
2017-07-31 21:54:04,578 Epoch[48] Batch [1440]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.092299,	
2017-07-31 21:54:09,286 Epoch[48] Batch [1450]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.092336,	
2017-07-31 21:54:14,082 Epoch[48] Batch [1460]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092302,	
2017-07-31 21:54:18,520 Epoch[48] Batch [1470]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.092237,	
2017-07-31 21:54:23,242 Epoch[48] Batch [1480]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092246,	
2017-07-31 21:54:26,072 Epoch[48] Train-FCNLogLoss=0.092250
2017-07-31 21:54:26,073 Epoch[48] Time cost=657.866
2017-07-31 21:54:26,875 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0049.params"
2017-07-31 21:54:28,688 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0049.states"
2017-07-31 21:54:33,888 Epoch[49] Batch [10]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089549,	
2017-07-31 21:54:38,258 Epoch[49] Batch [20]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.088493,	
2017-07-31 21:54:42,772 Epoch[49] Batch [30]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.086761,	
2017-07-31 21:54:47,137 Epoch[49] Batch [40]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.088562,	
2017-07-31 21:54:51,202 Epoch[49] Batch [50]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.089066,	
2017-07-31 21:54:55,974 Epoch[49] Batch [60]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089245,	
2017-07-31 21:55:00,332 Epoch[49] Batch [70]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.088513,	
2017-07-31 21:55:04,601 Epoch[49] Batch [80]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.088916,	
2017-07-31 21:55:09,360 Epoch[49] Batch [90]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.088805,	
2017-07-31 21:55:14,001 Epoch[49] Batch [100]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088038,	
2017-07-31 21:55:18,726 Epoch[49] Batch [110]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088261,	
2017-07-31 21:55:23,017 Epoch[49] Batch [120]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.088626,	
2017-07-31 21:55:27,312 Epoch[49] Batch [130]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.088984,	
2017-07-31 21:55:31,660 Epoch[49] Batch [140]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.089116,	
2017-07-31 21:55:36,089 Epoch[49] Batch [150]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.089721,	
2017-07-31 21:55:40,130 Epoch[49] Batch [160]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.089459,	
2017-07-31 21:55:44,585 Epoch[49] Batch [170]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.089720,	
2017-07-31 21:55:49,411 Epoch[49] Batch [180]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089815,	
2017-07-31 21:55:54,261 Epoch[49] Batch [190]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090092,	
2017-07-31 21:55:58,727 Epoch[49] Batch [200]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.090132,	
2017-07-31 21:56:03,195 Epoch[49] Batch [210]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.090366,	
2017-07-31 21:56:07,665 Epoch[49] Batch [220]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.090667,	
2017-07-31 21:56:12,030 Epoch[49] Batch [230]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.090971,	
2017-07-31 21:56:16,480 Epoch[49] Batch [240]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.090914,	
2017-07-31 21:56:21,290 Epoch[49] Batch [250]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.091210,	
2017-07-31 21:56:25,866 Epoch[49] Batch [260]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091235,	
2017-07-31 21:56:29,998 Epoch[49] Batch [270]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.090631,	
2017-07-31 21:56:34,353 Epoch[49] Batch [280]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.090833,	
2017-07-31 21:56:38,634 Epoch[49] Batch [290]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.090805,	
2017-07-31 21:56:43,260 Epoch[49] Batch [300]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091257,	
2017-07-31 21:56:47,837 Epoch[49] Batch [310]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091137,	
2017-07-31 21:56:52,919 Epoch[49] Batch [320]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.091157,	
2017-07-31 21:56:57,207 Epoch[49] Batch [330]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.091055,	
2017-07-31 21:57:01,283 Epoch[49] Batch [340]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.090741,	
2017-07-31 21:57:05,770 Epoch[49] Batch [350]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.090645,	
2017-07-31 21:57:10,157 Epoch[49] Batch [360]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090890,	
2017-07-31 21:57:14,397 Epoch[49] Batch [370]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091024,	
2017-07-31 21:57:18,637 Epoch[49] Batch [380]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.091002,	
2017-07-31 21:57:22,991 Epoch[49] Batch [390]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.090968,	
2017-07-31 21:57:27,588 Epoch[49] Batch [400]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090891,	
2017-07-31 21:57:32,010 Epoch[49] Batch [410]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.091008,	
2017-07-31 21:57:36,342 Epoch[49] Batch [420]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.091352,	
2017-07-31 21:57:41,178 Epoch[49] Batch [430]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.091570,	
2017-07-31 21:57:45,217 Epoch[49] Batch [440]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.091580,	
2017-07-31 21:57:50,060 Epoch[49] Batch [450]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091777,	
2017-07-31 21:57:54,182 Epoch[49] Batch [460]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091599,	
2017-07-31 21:57:58,738 Epoch[49] Batch [470]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091669,	
2017-07-31 21:58:03,029 Epoch[49] Batch [480]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.091733,	
2017-07-31 21:58:07,325 Epoch[49] Batch [490]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.091668,	
2017-07-31 21:58:12,139 Epoch[49] Batch [500]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.091787,	
2017-07-31 21:58:16,872 Epoch[49] Batch [510]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.091686,	
2017-07-31 21:58:21,178 Epoch[49] Batch [520]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.091810,	
2017-07-31 21:58:25,437 Epoch[49] Batch [530]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.091963,	
2017-07-31 21:58:29,525 Epoch[49] Batch [540]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.091877,	
2017-07-31 21:58:33,884 Epoch[49] Batch [550]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.091787,	
2017-07-31 21:58:38,716 Epoch[49] Batch [560]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.091765,	
2017-07-31 21:58:43,209 Epoch[49] Batch [570]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091724,	
2017-07-31 21:58:47,499 Epoch[49] Batch [580]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.091717,	
2017-07-31 21:58:52,117 Epoch[49] Batch [590]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091770,	
2017-07-31 21:58:56,195 Epoch[49] Batch [600]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.091874,	
2017-07-31 21:59:00,811 Epoch[49] Batch [610]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091831,	
2017-07-31 21:59:04,900 Epoch[49] Batch [620]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.091976,	
2017-07-31 21:59:09,493 Epoch[49] Batch [630]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092072,	
2017-07-31 21:59:14,261 Epoch[49] Batch [640]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092011,	
2017-07-31 21:59:18,852 Epoch[49] Batch [650]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092070,	
2017-07-31 21:59:23,470 Epoch[49] Batch [660]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092068,	
2017-07-31 21:59:28,144 Epoch[49] Batch [670]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092059,	
2017-07-31 21:59:32,474 Epoch[49] Batch [680]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.092149,	
2017-07-31 21:59:36,943 Epoch[49] Batch [690]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091981,	
2017-07-31 21:59:41,854 Epoch[49] Batch [700]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.092152,	
2017-07-31 21:59:46,675 Epoch[49] Batch [710]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092149,	
2017-07-31 21:59:50,849 Epoch[49] Batch [720]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.092114,	
2017-07-31 21:59:55,070 Epoch[49] Batch [730]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.092121,	
2017-07-31 21:59:59,844 Epoch[49] Batch [740]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092161,	
2017-07-31 22:00:04,666 Epoch[49] Batch [750]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092164,	
2017-07-31 22:00:09,279 Epoch[49] Batch [760]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092225,	
2017-07-31 22:00:13,870 Epoch[49] Batch [770]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092137,	
2017-07-31 22:00:18,286 Epoch[49] Batch [780]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.092140,	
2017-07-31 22:00:22,581 Epoch[49] Batch [790]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.092153,	
2017-07-31 22:00:26,576 Epoch[49] Batch [800]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.092199,	
2017-07-31 22:00:31,036 Epoch[49] Batch [810]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.092089,	
2017-07-31 22:00:35,619 Epoch[49] Batch [820]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092165,	
2017-07-31 22:00:39,874 Epoch[49] Batch [830]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.092117,	
2017-07-31 22:00:44,093 Epoch[49] Batch [840]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.092140,	
2017-07-31 22:00:48,519 Epoch[49] Batch [850]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.092175,	
2017-07-31 22:00:52,615 Epoch[49] Batch [860]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.092228,	
2017-07-31 22:00:57,069 Epoch[49] Batch [870]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.092160,	
2017-07-31 22:01:01,431 Epoch[49] Batch [880]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.092213,	
2017-07-31 22:01:05,915 Epoch[49] Batch [890]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.092282,	
2017-07-31 22:01:10,713 Epoch[49] Batch [900]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092275,	
2017-07-31 22:01:15,235 Epoch[49] Batch [910]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.092249,	
2017-07-31 22:01:20,075 Epoch[49] Batch [920]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.092205,	
2017-07-31 22:01:24,663 Epoch[49] Batch [930]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092157,	
2017-07-31 22:01:29,204 Epoch[49] Batch [940]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092145,	
2017-07-31 22:01:33,441 Epoch[49] Batch [950]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.092077,	
2017-07-31 22:01:37,700 Epoch[49] Batch [960]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.092118,	
2017-07-31 22:01:42,745 Epoch[49] Batch [970]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.092123,	
2017-07-31 22:01:47,117 Epoch[49] Batch [980]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.092101,	
2017-07-31 22:01:51,461 Epoch[49] Batch [990]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.092090,	
2017-07-31 22:01:55,788 Epoch[49] Batch [1000]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.092045,	
2017-07-31 22:02:00,419 Epoch[49] Batch [1010]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.092036,	
2017-07-31 22:02:04,711 Epoch[49] Batch [1020]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.091960,	
2017-07-31 22:02:09,187 Epoch[49] Batch [1030]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092022,	
2017-07-31 22:02:13,437 Epoch[49] Batch [1040]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.092036,	
2017-07-31 22:02:17,716 Epoch[49] Batch [1050]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.092066,	
2017-07-31 22:02:22,221 Epoch[49] Batch [1060]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.092061,	
2017-07-31 22:02:26,638 Epoch[49] Batch [1070]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.092020,	
2017-07-31 22:02:31,465 Epoch[49] Batch [1080]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091950,	
2017-07-31 22:02:36,127 Epoch[49] Batch [1090]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091989,	
2017-07-31 22:02:40,358 Epoch[49] Batch [1100]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.091933,	
2017-07-31 22:02:44,867 Epoch[49] Batch [1110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091976,	
2017-07-31 22:02:49,335 Epoch[49] Batch [1120]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091931,	
2017-07-31 22:02:53,751 Epoch[49] Batch [1130]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091931,	
2017-07-31 22:02:58,353 Epoch[49] Batch [1140]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.091896,	
2017-07-31 22:03:03,037 Epoch[49] Batch [1150]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.091875,	
2017-07-31 22:03:07,186 Epoch[49] Batch [1160]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091866,	
2017-07-31 22:03:11,427 Epoch[49] Batch [1170]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.091940,	
2017-07-31 22:03:15,892 Epoch[49] Batch [1180]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.092011,	
2017-07-31 22:03:20,681 Epoch[49] Batch [1190]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.092106,	
2017-07-31 22:03:25,216 Epoch[49] Batch [1200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.092086,	
2017-07-31 22:03:29,748 Epoch[49] Batch [1210]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.091969,	
2017-07-31 22:03:33,696 Epoch[49] Batch [1220]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.091905,	
2017-07-31 22:03:37,804 Epoch[49] Batch [1230]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.091961,	
2017-07-31 22:03:41,821 Epoch[49] Batch [1240]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.092001,	
2017-07-31 22:03:46,379 Epoch[49] Batch [1250]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092003,	
2017-07-31 22:03:50,749 Epoch[49] Batch [1260]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.091987,	
2017-07-31 22:03:55,233 Epoch[49] Batch [1270]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.091960,	
2017-07-31 22:03:59,578 Epoch[49] Batch [1280]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.091966,	
2017-07-31 22:04:04,123 Epoch[49] Batch [1290]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092013,	
2017-07-31 22:04:08,706 Epoch[49] Batch [1300]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092105,	
2017-07-31 22:04:13,567 Epoch[49] Batch [1310]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.092004,	
2017-07-31 22:04:17,946 Epoch[49] Batch [1320]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.092074,	
2017-07-31 22:04:22,893 Epoch[49] Batch [1330]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.092067,	
2017-07-31 22:04:27,433 Epoch[49] Batch [1340]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092071,	
2017-07-31 22:04:32,161 Epoch[49] Batch [1350]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.092052,	
2017-07-31 22:04:36,998 Epoch[49] Batch [1360]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092136,	
2017-07-31 22:04:41,852 Epoch[49] Batch [1370]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.092127,	
2017-07-31 22:04:46,657 Epoch[49] Batch [1380]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092099,	
2017-07-31 22:04:51,019 Epoch[49] Batch [1390]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.092088,	
2017-07-31 22:04:55,356 Epoch[49] Batch [1400]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.092023,	
2017-07-31 22:04:59,818 Epoch[49] Batch [1410]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.092089,	
2017-07-31 22:05:04,417 Epoch[49] Batch [1420]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092044,	
2017-07-31 22:05:09,226 Epoch[49] Batch [1430]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092034,	
2017-07-31 22:05:13,422 Epoch[49] Batch [1440]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.091990,	
2017-07-31 22:05:17,780 Epoch[49] Batch [1450]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.091969,	
2017-07-31 22:05:22,238 Epoch[49] Batch [1460]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091995,	
2017-07-31 22:05:26,646 Epoch[49] Batch [1470]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.092027,	
2017-07-31 22:05:31,304 Epoch[49] Batch [1480]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091991,	
2017-07-31 22:05:34,034 Epoch[49] Train-FCNLogLoss=0.092009
2017-07-31 22:05:34,034 Epoch[49] Time cost=665.345
2017-07-31 22:05:34,779 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0050.params"
2017-07-31 22:05:36,354 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0050.states"
2017-07-31 22:05:41,495 Epoch[50] Batch [10]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.088462,	
2017-07-31 22:05:45,723 Epoch[50] Batch [20]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.088894,	
2017-07-31 22:05:50,242 Epoch[50] Batch [30]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.091495,	
2017-07-31 22:05:55,141 Epoch[50] Batch [40]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.092082,	
2017-07-31 22:05:59,508 Epoch[50] Batch [50]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.093917,	
2017-07-31 22:06:03,622 Epoch[50] Batch [60]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.093649,	
2017-07-31 22:06:07,762 Epoch[50] Batch [70]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.092264,	
2017-07-31 22:06:12,274 Epoch[50] Batch [80]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091545,	
2017-07-31 22:06:16,836 Epoch[50] Batch [90]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092206,	
2017-07-31 22:06:21,388 Epoch[50] Batch [100]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.092394,	
2017-07-31 22:06:25,646 Epoch[50] Batch [110]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.092902,	
2017-07-31 22:06:29,710 Epoch[50] Batch [120]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.093412,	
2017-07-31 22:06:34,166 Epoch[50] Batch [130]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.092529,	
2017-07-31 22:06:38,751 Epoch[50] Batch [140]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092124,	
2017-07-31 22:06:43,453 Epoch[50] Batch [150]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092261,	
2017-07-31 22:06:47,973 Epoch[50] Batch [160]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.092016,	
2017-07-31 22:06:52,560 Epoch[50] Batch [170]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092561,	
2017-07-31 22:06:57,249 Epoch[50] Batch [180]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092803,	
2017-07-31 22:07:01,724 Epoch[50] Batch [190]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092756,	
2017-07-31 22:07:05,672 Epoch[50] Batch [200]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.092346,	
2017-07-31 22:07:09,979 Epoch[50] Batch [210]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.092215,	
2017-07-31 22:07:14,125 Epoch[50] Batch [220]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.091657,	
2017-07-31 22:07:18,422 Epoch[50] Batch [230]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.092503,	
2017-07-31 22:07:22,483 Epoch[50] Batch [240]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.092600,	
2017-07-31 22:07:26,643 Epoch[50] Batch [250]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.092442,	
2017-07-31 22:07:30,755 Epoch[50] Batch [260]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.092256,	
2017-07-31 22:07:35,171 Epoch[50] Batch [270]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.092331,	
2017-07-31 22:07:39,416 Epoch[50] Batch [280]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.092478,	
2017-07-31 22:07:43,625 Epoch[50] Batch [290]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.092555,	
2017-07-31 22:07:47,741 Epoch[50] Batch [300]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.092185,	
2017-07-31 22:07:52,003 Epoch[50] Batch [310]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.092122,	
2017-07-31 22:07:56,497 Epoch[50] Batch [320]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091976,	
2017-07-31 22:08:00,729 Epoch[50] Batch [330]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.091835,	
2017-07-31 22:08:05,112 Epoch[50] Batch [340]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.092015,	
2017-07-31 22:08:09,455 Epoch[50] Batch [350]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.092094,	
2017-07-31 22:08:14,445 Epoch[50] Batch [360]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.092217,	
2017-07-31 22:08:18,438 Epoch[50] Batch [370]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.091999,	
2017-07-31 22:08:22,422 Epoch[50] Batch [380]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.092182,	
2017-07-31 22:08:26,804 Epoch[50] Batch [390]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.092171,	
2017-07-31 22:08:31,510 Epoch[50] Batch [400]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.092169,	
2017-07-31 22:08:36,059 Epoch[50] Batch [410]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.092339,	
2017-07-31 22:08:40,578 Epoch[50] Batch [420]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.092354,	
2017-07-31 22:08:45,207 Epoch[50] Batch [430]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.092392,	
2017-07-31 22:08:49,811 Epoch[50] Batch [440]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092455,	
2017-07-31 22:08:54,283 Epoch[50] Batch [450]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092449,	
2017-07-31 22:08:58,767 Epoch[50] Batch [460]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.092348,	
2017-07-31 22:09:03,351 Epoch[50] Batch [470]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092361,	
2017-07-31 22:09:07,805 Epoch[50] Batch [480]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.092212,	
2017-07-31 22:09:11,984 Epoch[50] Batch [490]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092417,	
2017-07-31 22:09:16,196 Epoch[50] Batch [500]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.092320,	
2017-07-31 22:09:21,062 Epoch[50] Batch [510]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092377,	
2017-07-31 22:09:25,809 Epoch[50] Batch [520]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.092424,	
2017-07-31 22:09:30,339 Epoch[50] Batch [530]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.092390,	
2017-07-31 22:09:34,533 Epoch[50] Batch [540]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.092336,	
2017-07-31 22:09:38,548 Epoch[50] Batch [550]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.092395,	
2017-07-31 22:09:42,894 Epoch[50] Batch [560]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.092305,	
2017-07-31 22:09:47,410 Epoch[50] Batch [570]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092174,	
2017-07-31 22:09:51,996 Epoch[50] Batch [580]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092289,	
2017-07-31 22:09:56,876 Epoch[50] Batch [590]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.092247,	
2017-07-31 22:10:01,557 Epoch[50] Batch [600]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.092193,	
2017-07-31 22:10:05,705 Epoch[50] Batch [610]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.092175,	
2017-07-31 22:10:09,922 Epoch[50] Batch [620]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.092140,	
2017-07-31 22:10:14,317 Epoch[50] Batch [630]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.092023,	
2017-07-31 22:10:18,466 Epoch[50] Batch [640]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.092007,	
2017-07-31 22:10:23,087 Epoch[50] Batch [650]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092096,	
2017-07-31 22:10:27,750 Epoch[50] Batch [660]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091999,	
2017-07-31 22:10:32,117 Epoch[50] Batch [670]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.092076,	
2017-07-31 22:10:36,422 Epoch[50] Batch [680]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.092147,	
2017-07-31 22:10:40,602 Epoch[50] Batch [690]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.092101,	
2017-07-31 22:10:44,722 Epoch[50] Batch [700]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.092101,	
2017-07-31 22:10:49,029 Epoch[50] Batch [710]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.092034,	
2017-07-31 22:10:53,435 Epoch[50] Batch [720]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.092168,	
2017-07-31 22:10:58,052 Epoch[50] Batch [730]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092146,	
2017-07-31 22:11:02,651 Epoch[50] Batch [740]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092010,	
2017-07-31 22:11:07,109 Epoch[50] Batch [750]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091880,	
2017-07-31 22:11:11,449 Epoch[50] Batch [760]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.091879,	
2017-07-31 22:11:15,732 Epoch[50] Batch [770]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.091866,	
2017-07-31 22:11:20,278 Epoch[50] Batch [780]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091905,	
2017-07-31 22:11:24,850 Epoch[50] Batch [790]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091814,	
2017-07-31 22:11:29,461 Epoch[50] Batch [800]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091814,	
2017-07-31 22:11:33,750 Epoch[50] Batch [810]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.091735,	
2017-07-31 22:11:38,157 Epoch[50] Batch [820]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.091749,	
2017-07-31 22:11:42,295 Epoch[50] Batch [830]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.091582,	
2017-07-31 22:11:46,751 Epoch[50] Batch [840]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091537,	
2017-07-31 22:11:51,144 Epoch[50] Batch [850]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.091522,	
2017-07-31 22:11:55,506 Epoch[50] Batch [860]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.091491,	
2017-07-31 22:11:59,762 Epoch[50] Batch [870]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.091565,	
2017-07-31 22:12:03,925 Epoch[50] Batch [880]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091658,	
2017-07-31 22:12:08,215 Epoch[50] Batch [890]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.091549,	
2017-07-31 22:12:12,340 Epoch[50] Batch [900]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091508,	
2017-07-31 22:12:16,696 Epoch[50] Batch [910]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.091417,	
2017-07-31 22:12:21,041 Epoch[50] Batch [920]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.091379,	
2017-07-31 22:12:25,618 Epoch[50] Batch [930]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091415,	
2017-07-31 22:12:30,184 Epoch[50] Batch [940]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091334,	
2017-07-31 22:12:34,454 Epoch[50] Batch [950]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.091324,	
2017-07-31 22:12:38,603 Epoch[50] Batch [960]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091465,	
2017-07-31 22:12:42,908 Epoch[50] Batch [970]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.091415,	
2017-07-31 22:12:47,400 Epoch[50] Batch [980]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091362,	
2017-07-31 22:12:51,847 Epoch[50] Batch [990]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091386,	
2017-07-31 22:12:56,397 Epoch[50] Batch [1000]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091394,	
2017-07-31 22:13:00,933 Epoch[50] Batch [1010]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.091336,	
2017-07-31 22:13:05,325 Epoch[50] Batch [1020]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.091349,	
2017-07-31 22:13:09,817 Epoch[50] Batch [1030]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091302,	
2017-07-31 22:13:14,239 Epoch[50] Batch [1040]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.091273,	
2017-07-31 22:13:19,045 Epoch[50] Batch [1050]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.091301,	
2017-07-31 22:13:23,119 Epoch[50] Batch [1060]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.091301,	
2017-07-31 22:13:27,793 Epoch[50] Batch [1070]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.091332,	
2017-07-31 22:13:32,498 Epoch[50] Batch [1080]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091310,	
2017-07-31 22:13:37,365 Epoch[50] Batch [1090]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.091323,	
2017-07-31 22:13:41,868 Epoch[50] Batch [1100]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.091383,	
2017-07-31 22:13:46,152 Epoch[50] Batch [1110]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.091410,	
2017-07-31 22:13:50,503 Epoch[50] Batch [1120]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.091492,	
2017-07-31 22:13:55,230 Epoch[50] Batch [1130]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091477,	
2017-07-31 22:13:59,731 Epoch[50] Batch [1140]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091446,	
2017-07-31 22:14:04,200 Epoch[50] Batch [1150]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091481,	
2017-07-31 22:14:08,694 Epoch[50] Batch [1160]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091472,	
2017-07-31 22:14:13,191 Epoch[50] Batch [1170]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091450,	
2017-07-31 22:14:17,826 Epoch[50] Batch [1180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.091563,	
2017-07-31 22:14:22,212 Epoch[50] Batch [1190]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.091525,	
2017-07-31 22:14:26,896 Epoch[50] Batch [1200]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.091544,	
2017-07-31 22:14:31,134 Epoch[50] Batch [1210]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091565,	
2017-07-31 22:14:35,322 Epoch[50] Batch [1220]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.091565,	
2017-07-31 22:14:39,981 Epoch[50] Batch [1230]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091548,	
2017-07-31 22:14:44,458 Epoch[50] Batch [1240]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091621,	
2017-07-31 22:14:49,369 Epoch[50] Batch [1250]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.091621,	
2017-07-31 22:14:53,877 Epoch[50] Batch [1260]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091626,	
2017-07-31 22:14:58,647 Epoch[50] Batch [1270]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091702,	
2017-07-31 22:15:03,059 Epoch[50] Batch [1280]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.091714,	
2017-07-31 22:15:07,398 Epoch[50] Batch [1290]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.091765,	
2017-07-31 22:15:11,863 Epoch[50] Batch [1300]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.091745,	
2017-07-31 22:15:16,061 Epoch[50] Batch [1310]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.091840,	
2017-07-31 22:15:20,445 Epoch[50] Batch [1320]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.091833,	
2017-07-31 22:15:24,891 Epoch[50] Batch [1330]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.091901,	
2017-07-31 22:15:29,816 Epoch[50] Batch [1340]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.091964,	
2017-07-31 22:15:34,314 Epoch[50] Batch [1350]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091969,	
2017-07-31 22:15:38,766 Epoch[50] Batch [1360]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091980,	
2017-07-31 22:15:43,181 Epoch[50] Batch [1370]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091942,	
2017-07-31 22:15:47,849 Epoch[50] Batch [1380]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.091925,	
2017-07-31 22:15:52,233 Epoch[50] Batch [1390]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.091905,	
2017-07-31 22:15:56,750 Epoch[50] Batch [1400]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091885,	
2017-07-31 22:16:01,454 Epoch[50] Batch [1410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091973,	
2017-07-31 22:16:06,146 Epoch[50] Batch [1420]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.091989,	
2017-07-31 22:16:10,404 Epoch[50] Batch [1430]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.092004,	
2017-07-31 22:16:14,726 Epoch[50] Batch [1440]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.092050,	
2017-07-31 22:16:19,116 Epoch[50] Batch [1450]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.092049,	
2017-07-31 22:16:23,672 Epoch[50] Batch [1460]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092081,	
2017-07-31 22:16:28,249 Epoch[50] Batch [1470]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092110,	
2017-07-31 22:16:32,293 Epoch[50] Batch [1480]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.092081,	
2017-07-31 22:16:34,764 Epoch[50] Train-FCNLogLoss=0.092063
2017-07-31 22:16:34,764 Epoch[50] Time cost=658.410
2017-07-31 22:16:35,377 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0051.params"
2017-07-31 22:16:36,968 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0051.states"
2017-07-31 22:16:42,257 Epoch[51] Batch [10]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.084381,	
2017-07-31 22:16:46,571 Epoch[51] Batch [20]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.086593,	
2017-07-31 22:16:50,831 Epoch[51] Batch [30]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086445,	
2017-07-31 22:16:55,229 Epoch[51] Batch [40]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.086796,	
2017-07-31 22:16:59,728 Epoch[51] Batch [50]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088757,	
2017-07-31 22:17:03,979 Epoch[51] Batch [60]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.090345,	
2017-07-31 22:17:08,609 Epoch[51] Batch [70]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090547,	
2017-07-31 22:17:13,329 Epoch[51] Batch [80]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091228,	
2017-07-31 22:17:17,424 Epoch[51] Batch [90]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091223,	
2017-07-31 22:17:21,862 Epoch[51] Batch [100]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.091291,	
2017-07-31 22:17:26,419 Epoch[51] Batch [110]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.090172,	
2017-07-31 22:17:31,418 Epoch[51] Batch [120]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.090614,	
2017-07-31 22:17:36,160 Epoch[51] Batch [130]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090848,	
2017-07-31 22:17:40,774 Epoch[51] Batch [140]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.090902,	
2017-07-31 22:17:45,359 Epoch[51] Batch [150]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090591,	
2017-07-31 22:17:50,142 Epoch[51] Batch [160]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090711,	
2017-07-31 22:17:54,593 Epoch[51] Batch [170]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.090872,	
2017-07-31 22:17:59,247 Epoch[51] Batch [180]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090751,	
2017-07-31 22:18:04,043 Epoch[51] Batch [190]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.091085,	
2017-07-31 22:18:08,713 Epoch[51] Batch [200]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090943,	
2017-07-31 22:18:13,365 Epoch[51] Batch [210]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091092,	
2017-07-31 22:18:17,802 Epoch[51] Batch [220]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090987,	
2017-07-31 22:18:21,811 Epoch[51] Batch [230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.091234,	
2017-07-31 22:18:25,824 Epoch[51] Batch [240]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.090963,	
2017-07-31 22:18:29,891 Epoch[51] Batch [250]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.091011,	
2017-07-31 22:18:34,249 Epoch[51] Batch [260]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.090845,	
2017-07-31 22:18:39,351 Epoch[51] Batch [270]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.090880,	
2017-07-31 22:18:44,233 Epoch[51] Batch [280]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.091076,	
2017-07-31 22:18:48,907 Epoch[51] Batch [290]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.091070,	
2017-07-31 22:18:53,352 Epoch[51] Batch [300]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.091293,	
2017-07-31 22:18:57,788 Epoch[51] Batch [310]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.091303,	
2017-07-31 22:19:02,071 Epoch[51] Batch [320]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.091232,	
2017-07-31 22:19:06,731 Epoch[51] Batch [330]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091369,	
2017-07-31 22:19:11,288 Epoch[51] Batch [340]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091556,	
2017-07-31 22:19:15,888 Epoch[51] Batch [350]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091277,	
2017-07-31 22:19:20,190 Epoch[51] Batch [360]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.091167,	
2017-07-31 22:19:24,967 Epoch[51] Batch [370]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.091150,	
2017-07-31 22:19:29,393 Epoch[51] Batch [380]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.091291,	
2017-07-31 22:19:33,540 Epoch[51] Batch [390]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.091275,	
2017-07-31 22:19:38,576 Epoch[51] Batch [400]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.091051,	
2017-07-31 22:19:43,244 Epoch[51] Batch [410]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090942,	
2017-07-31 22:19:47,679 Epoch[51] Batch [420]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.091129,	
2017-07-31 22:19:52,300 Epoch[51] Batch [430]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091212,	
2017-07-31 22:19:56,914 Epoch[51] Batch [440]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091121,	
2017-07-31 22:20:01,382 Epoch[51] Batch [450]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091051,	
2017-07-31 22:20:05,911 Epoch[51] Batch [460]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.090984,	
2017-07-31 22:20:10,684 Epoch[51] Batch [470]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.091125,	
2017-07-31 22:20:14,949 Epoch[51] Batch [480]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.091170,	
2017-07-31 22:20:19,440 Epoch[51] Batch [490]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091207,	
2017-07-31 22:20:23,622 Epoch[51] Batch [500]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.091166,	
2017-07-31 22:20:27,729 Epoch[51] Batch [510]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.091211,	
2017-07-31 22:20:32,345 Epoch[51] Batch [520]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091636,	
2017-07-31 22:20:36,839 Epoch[51] Batch [530]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091569,	
2017-07-31 22:20:41,320 Epoch[51] Batch [540]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.091550,	
2017-07-31 22:20:45,484 Epoch[51] Batch [550]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.091384,	
2017-07-31 22:20:50,029 Epoch[51] Batch [560]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091571,	
2017-07-31 22:20:54,482 Epoch[51] Batch [570]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091669,	
2017-07-31 22:20:58,904 Epoch[51] Batch [580]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.091630,	
2017-07-31 22:21:03,213 Epoch[51] Batch [590]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.091518,	
2017-07-31 22:21:07,330 Epoch[51] Batch [600]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091348,	
2017-07-31 22:21:11,997 Epoch[51] Batch [610]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.091453,	
2017-07-31 22:21:16,487 Epoch[51] Batch [620]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091380,	
2017-07-31 22:21:21,085 Epoch[51] Batch [630]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091353,	
2017-07-31 22:21:25,727 Epoch[51] Batch [640]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091261,	
2017-07-31 22:21:30,576 Epoch[51] Batch [650]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091277,	
2017-07-31 22:21:35,242 Epoch[51] Batch [660]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.091309,	
2017-07-31 22:21:39,765 Epoch[51] Batch [670]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091197,	
2017-07-31 22:21:44,509 Epoch[51] Batch [680]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.091342,	
2017-07-31 22:21:48,833 Epoch[51] Batch [690]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.091320,	
2017-07-31 22:21:53,183 Epoch[51] Batch [700]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.091246,	
2017-07-31 22:21:57,465 Epoch[51] Batch [710]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.091410,	
2017-07-31 22:22:01,932 Epoch[51] Batch [720]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.091280,	
2017-07-31 22:22:05,949 Epoch[51] Batch [730]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.091464,	
2017-07-31 22:22:10,109 Epoch[51] Batch [740]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091592,	
2017-07-31 22:22:14,823 Epoch[51] Batch [750]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.091603,	
2017-07-31 22:22:19,521 Epoch[51] Batch [760]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091683,	
2017-07-31 22:22:24,420 Epoch[51] Batch [770]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.091708,	
2017-07-31 22:22:28,874 Epoch[51] Batch [780]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091798,	
2017-07-31 22:22:33,858 Epoch[51] Batch [790]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.091807,	
2017-07-31 22:22:38,180 Epoch[51] Batch [800]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.091712,	
2017-07-31 22:22:42,666 Epoch[51] Batch [810]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.091788,	
2017-07-31 22:22:47,204 Epoch[51] Batch [820]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.091791,	
2017-07-31 22:22:51,863 Epoch[51] Batch [830]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091927,	
2017-07-31 22:22:56,237 Epoch[51] Batch [840]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.091827,	
2017-07-31 22:23:01,076 Epoch[51] Batch [850]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.091814,	
2017-07-31 22:23:05,690 Epoch[51] Batch [860]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091926,	
2017-07-31 22:23:10,232 Epoch[51] Batch [870]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092005,	
2017-07-31 22:23:14,946 Epoch[51] Batch [880]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.092042,	
2017-07-31 22:23:19,491 Epoch[51] Batch [890]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091878,	
2017-07-31 22:23:24,323 Epoch[51] Batch [900]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.091845,	
2017-07-31 22:23:28,467 Epoch[51] Batch [910]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.091774,	
2017-07-31 22:23:32,967 Epoch[51] Batch [920]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091652,	
2017-07-31 22:23:37,126 Epoch[51] Batch [930]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091721,	
2017-07-31 22:23:41,314 Epoch[51] Batch [940]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.091701,	
2017-07-31 22:23:45,455 Epoch[51] Batch [950]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.091666,	
2017-07-31 22:23:50,005 Epoch[51] Batch [960]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091652,	
2017-07-31 22:23:54,416 Epoch[51] Batch [970]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.091648,	
2017-07-31 22:23:58,852 Epoch[51] Batch [980]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.091613,	
2017-07-31 22:24:03,086 Epoch[51] Batch [990]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.091508,	
2017-07-31 22:24:07,308 Epoch[51] Batch [1000]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091529,	
2017-07-31 22:24:11,866 Epoch[51] Batch [1010]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091602,	
2017-07-31 22:24:16,229 Epoch[51] Batch [1020]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.091585,	
2017-07-31 22:24:20,813 Epoch[51] Batch [1030]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091577,	
2017-07-31 22:24:25,205 Epoch[51] Batch [1040]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.091671,	
2017-07-31 22:24:29,697 Epoch[51] Batch [1050]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091746,	
2017-07-31 22:24:33,799 Epoch[51] Batch [1060]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.091816,	
2017-07-31 22:24:38,161 Epoch[51] Batch [1070]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.091686,	
2017-07-31 22:24:42,590 Epoch[51] Batch [1080]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.091697,	
2017-07-31 22:24:47,039 Epoch[51] Batch [1090]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091649,	
2017-07-31 22:24:51,815 Epoch[51] Batch [1100]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.091672,	
2017-07-31 22:24:56,460 Epoch[51] Batch [1110]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091602,	
2017-07-31 22:25:00,741 Epoch[51] Batch [1120]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.091632,	
2017-07-31 22:25:04,816 Epoch[51] Batch [1130]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.091704,	
2017-07-31 22:25:08,944 Epoch[51] Batch [1140]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.091603,	
2017-07-31 22:25:13,317 Epoch[51] Batch [1150]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.091669,	
2017-07-31 22:25:17,700 Epoch[51] Batch [1160]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.091700,	
2017-07-31 22:25:22,270 Epoch[51] Batch [1170]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091673,	
2017-07-31 22:25:26,815 Epoch[51] Batch [1180]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091715,	
2017-07-31 22:25:31,606 Epoch[51] Batch [1190]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.091756,	
2017-07-31 22:25:35,999 Epoch[51] Batch [1200]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.091817,	
2017-07-31 22:25:40,645 Epoch[51] Batch [1210]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091773,	
2017-07-31 22:25:45,402 Epoch[51] Batch [1220]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.091731,	
2017-07-31 22:25:50,097 Epoch[51] Batch [1230]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091763,	
2017-07-31 22:25:54,717 Epoch[51] Batch [1240]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091725,	
2017-07-31 22:25:59,175 Epoch[51] Batch [1250]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091766,	
2017-07-31 22:26:03,334 Epoch[51] Batch [1260]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091811,	
2017-07-31 22:26:07,830 Epoch[51] Batch [1270]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091906,	
2017-07-31 22:26:12,286 Epoch[51] Batch [1280]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091849,	
2017-07-31 22:26:16,835 Epoch[51] Batch [1290]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091830,	
2017-07-31 22:26:21,436 Epoch[51] Batch [1300]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.091794,	
2017-07-31 22:26:25,593 Epoch[51] Batch [1310]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.091747,	
2017-07-31 22:26:30,248 Epoch[51] Batch [1320]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091788,	
2017-07-31 22:26:34,687 Epoch[51] Batch [1330]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.091789,	
2017-07-31 22:26:39,211 Epoch[51] Batch [1340]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091805,	
2017-07-31 22:26:43,430 Epoch[51] Batch [1350]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.091810,	
2017-07-31 22:26:47,843 Epoch[51] Batch [1360]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091857,	
2017-07-31 22:26:52,463 Epoch[51] Batch [1370]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091870,	
2017-07-31 22:26:57,330 Epoch[51] Batch [1380]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.091885,	
2017-07-31 22:27:01,908 Epoch[51] Batch [1390]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091943,	
2017-07-31 22:27:06,374 Epoch[51] Batch [1400]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.091936,	
2017-07-31 22:27:11,025 Epoch[51] Batch [1410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091846,	
2017-07-31 22:27:15,519 Epoch[51] Batch [1420]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091880,	
2017-07-31 22:27:19,746 Epoch[51] Batch [1430]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091865,	
2017-07-31 22:27:24,301 Epoch[51] Batch [1440]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091926,	
2017-07-31 22:27:28,386 Epoch[51] Batch [1450]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.091987,	
2017-07-31 22:27:32,898 Epoch[51] Batch [1460]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.092048,	
2017-07-31 22:27:37,432 Epoch[51] Batch [1470]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.092100,	
2017-07-31 22:27:41,906 Epoch[51] Batch [1480]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092042,	
2017-07-31 22:27:44,551 Epoch[51] Train-FCNLogLoss=0.092042
2017-07-31 22:27:44,551 Epoch[51] Time cost=667.583
2017-07-31 22:27:45,302 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0052.params"
2017-07-31 22:27:46,973 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0052.states"
2017-07-31 22:27:52,562 Epoch[52] Batch [10]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.090101,	
2017-07-31 22:27:56,889 Epoch[52] Batch [20]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.093538,	
2017-07-31 22:28:01,278 Epoch[52] Batch [30]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.093819,	
2017-07-31 22:28:05,459 Epoch[52] Batch [40]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.093247,	
2017-07-31 22:28:10,067 Epoch[52] Batch [50]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091961,	
2017-07-31 22:28:14,425 Epoch[52] Batch [60]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.093501,	
2017-07-31 22:28:18,985 Epoch[52] Batch [70]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.095502,	
2017-07-31 22:28:23,037 Epoch[52] Batch [80]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094100,	
2017-07-31 22:28:27,204 Epoch[52] Batch [90]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094059,	
2017-07-31 22:28:31,503 Epoch[52] Batch [100]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.093675,	
2017-07-31 22:28:36,120 Epoch[52] Batch [110]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.094139,	
2017-07-31 22:28:40,661 Epoch[52] Batch [120]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.093308,	
2017-07-31 22:28:45,347 Epoch[52] Batch [130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.093609,	
2017-07-31 22:28:49,890 Epoch[52] Batch [140]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.093380,	
2017-07-31 22:28:54,203 Epoch[52] Batch [150]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.093203,	
2017-07-31 22:28:58,381 Epoch[52] Batch [160]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.092782,	
2017-07-31 22:29:02,422 Epoch[52] Batch [170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.092345,	
2017-07-31 22:29:06,596 Epoch[52] Batch [180]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091990,	
2017-07-31 22:29:10,659 Epoch[52] Batch [190]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.091819,	
2017-07-31 22:29:14,789 Epoch[52] Batch [200]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.091727,	
2017-07-31 22:29:18,957 Epoch[52] Batch [210]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.091715,	
2017-07-31 22:29:23,337 Epoch[52] Batch [220]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.091863,	
2017-07-31 22:29:28,008 Epoch[52] Batch [230]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092108,	
2017-07-31 22:29:32,551 Epoch[52] Batch [240]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092496,	
2017-07-31 22:29:36,673 Epoch[52] Batch [250]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.092480,	
2017-07-31 22:29:41,040 Epoch[52] Batch [260]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.092597,	
2017-07-31 22:29:45,296 Epoch[52] Batch [270]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.092458,	
2017-07-31 22:29:49,604 Epoch[52] Batch [280]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.092443,	
2017-07-31 22:29:54,205 Epoch[52] Batch [290]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092521,	
2017-07-31 22:29:59,099 Epoch[52] Batch [300]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.092327,	
2017-07-31 22:30:04,019 Epoch[52] Batch [310]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092353,	
2017-07-31 22:30:08,375 Epoch[52] Batch [320]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.092296,	
2017-07-31 22:30:12,642 Epoch[52] Batch [330]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.092241,	
2017-07-31 22:30:16,903 Epoch[52] Batch [340]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.092112,	
2017-07-31 22:30:21,239 Epoch[52] Batch [350]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.092168,	
2017-07-31 22:30:25,766 Epoch[52] Batch [360]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092215,	
2017-07-31 22:30:30,553 Epoch[52] Batch [370]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092216,	
2017-07-31 22:30:35,208 Epoch[52] Batch [380]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092361,	
2017-07-31 22:30:39,785 Epoch[52] Batch [390]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092380,	
2017-07-31 22:30:43,975 Epoch[52] Batch [400]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.092331,	
2017-07-31 22:30:48,551 Epoch[52] Batch [410]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092226,	
2017-07-31 22:30:52,857 Epoch[52] Batch [420]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.092182,	
2017-07-31 22:30:57,335 Epoch[52] Batch [430]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.091912,	
2017-07-31 22:31:01,458 Epoch[52] Batch [440]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.091978,	
2017-07-31 22:31:05,659 Epoch[52] Batch [450]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.091829,	
2017-07-31 22:31:09,778 Epoch[52] Batch [460]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.091614,	
2017-07-31 22:31:14,377 Epoch[52] Batch [470]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091819,	
2017-07-31 22:31:19,007 Epoch[52] Batch [480]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091627,	
2017-07-31 22:31:23,886 Epoch[52] Batch [490]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.091549,	
2017-07-31 22:31:28,226 Epoch[52] Batch [500]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.091550,	
2017-07-31 22:31:33,013 Epoch[52] Batch [510]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.091379,	
2017-07-31 22:31:37,541 Epoch[52] Batch [520]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.091187,	
2017-07-31 22:31:42,002 Epoch[52] Batch [530]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091077,	
2017-07-31 22:31:46,619 Epoch[52] Batch [540]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091023,	
2017-07-31 22:31:51,277 Epoch[52] Batch [550]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091218,	
2017-07-31 22:31:56,003 Epoch[52] Batch [560]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.091147,	
2017-07-31 22:32:00,439 Epoch[52] Batch [570]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.091271,	
2017-07-31 22:32:05,007 Epoch[52] Batch [580]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091619,	
2017-07-31 22:32:09,124 Epoch[52] Batch [590]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.091510,	
2017-07-31 22:32:13,648 Epoch[52] Batch [600]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091407,	
2017-07-31 22:32:18,325 Epoch[52] Batch [610]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091391,	
2017-07-31 22:32:22,797 Epoch[52] Batch [620]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091422,	
2017-07-31 22:32:27,267 Epoch[52] Batch [630]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091340,	
2017-07-31 22:32:31,853 Epoch[52] Batch [640]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091298,	
2017-07-31 22:32:36,713 Epoch[52] Batch [650]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.091249,	
2017-07-31 22:32:41,314 Epoch[52] Batch [660]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091227,	
2017-07-31 22:32:45,983 Epoch[52] Batch [670]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.091170,	
2017-07-31 22:32:50,299 Epoch[52] Batch [680]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.091225,	
2017-07-31 22:32:54,812 Epoch[52] Batch [690]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091221,	
2017-07-31 22:32:59,455 Epoch[52] Batch [700]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091275,	
2017-07-31 22:33:04,052 Epoch[52] Batch [710]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091297,	
2017-07-31 22:33:08,457 Epoch[52] Batch [720]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.091389,	
2017-07-31 22:33:12,975 Epoch[52] Batch [730]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091421,	
2017-07-31 22:33:17,358 Epoch[52] Batch [740]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.091429,	
2017-07-31 22:33:21,919 Epoch[52] Batch [750]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091454,	
2017-07-31 22:33:26,434 Epoch[52] Batch [760]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091391,	
2017-07-31 22:33:30,712 Epoch[52] Batch [770]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.091420,	
2017-07-31 22:33:35,240 Epoch[52] Batch [780]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.091396,	
2017-07-31 22:33:39,434 Epoch[52] Batch [790]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.091470,	
2017-07-31 22:33:43,706 Epoch[52] Batch [800]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.091394,	
2017-07-31 22:33:47,883 Epoch[52] Batch [810]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091419,	
2017-07-31 22:33:52,093 Epoch[52] Batch [820]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.091328,	
2017-07-31 22:33:56,436 Epoch[52] Batch [830]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.091409,	
2017-07-31 22:34:00,826 Epoch[52] Batch [840]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.091307,	
2017-07-31 22:34:05,046 Epoch[52] Batch [850]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.091300,	
2017-07-31 22:34:09,775 Epoch[52] Batch [860]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091281,	
2017-07-31 22:34:14,506 Epoch[52] Batch [870]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091165,	
2017-07-31 22:34:19,022 Epoch[52] Batch [880]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091119,	
2017-07-31 22:34:23,360 Epoch[52] Batch [890]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.091135,	
2017-07-31 22:34:27,879 Epoch[52] Batch [900]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.091113,	
2017-07-31 22:34:32,053 Epoch[52] Batch [910]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.091096,	
2017-07-31 22:34:36,863 Epoch[52] Batch [920]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.091154,	
2017-07-31 22:34:41,333 Epoch[52] Batch [930]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091199,	
2017-07-31 22:34:45,731 Epoch[52] Batch [940]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.091290,	
2017-07-31 22:34:50,251 Epoch[52] Batch [950]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.091347,	
2017-07-31 22:34:55,020 Epoch[52] Batch [960]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091316,	
2017-07-31 22:34:59,698 Epoch[52] Batch [970]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091343,	
2017-07-31 22:35:04,174 Epoch[52] Batch [980]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091328,	
2017-07-31 22:35:08,799 Epoch[52] Batch [990]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091309,	
2017-07-31 22:35:13,688 Epoch[52] Batch [1000]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.091375,	
2017-07-31 22:35:18,086 Epoch[52] Batch [1010]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.091372,	
2017-07-31 22:35:22,819 Epoch[52] Batch [1020]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.091346,	
2017-07-31 22:35:27,854 Epoch[52] Batch [1030]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.091382,	
2017-07-31 22:35:32,688 Epoch[52] Batch [1040]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.091378,	
2017-07-31 22:35:36,965 Epoch[52] Batch [1050]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.091406,	
2017-07-31 22:35:41,485 Epoch[52] Batch [1060]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.091435,	
2017-07-31 22:35:45,635 Epoch[52] Batch [1070]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.091472,	
2017-07-31 22:35:50,034 Epoch[52] Batch [1080]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.091453,	
2017-07-31 22:35:54,325 Epoch[52] Batch [1090]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.091434,	
2017-07-31 22:35:58,789 Epoch[52] Batch [1100]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.091380,	
2017-07-31 22:36:03,492 Epoch[52] Batch [1110]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091423,	
2017-07-31 22:36:07,938 Epoch[52] Batch [1120]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.091430,	
2017-07-31 22:36:11,970 Epoch[52] Batch [1130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.091445,	
2017-07-31 22:36:16,279 Epoch[52] Batch [1140]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.091501,	
2017-07-31 22:36:21,155 Epoch[52] Batch [1150]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.091488,	
2017-07-31 22:36:26,074 Epoch[52] Batch [1160]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.091521,	
2017-07-31 22:36:30,729 Epoch[52] Batch [1170]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091527,	
2017-07-31 22:36:34,937 Epoch[52] Batch [1180]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091702,	
2017-07-31 22:36:39,693 Epoch[52] Batch [1190]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.091677,	
2017-07-31 22:36:44,155 Epoch[52] Batch [1200]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091703,	
2017-07-31 22:36:48,360 Epoch[52] Batch [1210]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091730,	
2017-07-31 22:36:52,334 Epoch[52] Batch [1220]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.091726,	
2017-07-31 22:36:56,931 Epoch[52] Batch [1230]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091741,	
2017-07-31 22:37:01,686 Epoch[52] Batch [1240]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.091726,	
2017-07-31 22:37:06,288 Epoch[52] Batch [1250]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.091693,	
2017-07-31 22:37:10,692 Epoch[52] Batch [1260]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.091720,	
2017-07-31 22:37:15,286 Epoch[52] Batch [1270]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.091679,	
2017-07-31 22:37:19,546 Epoch[52] Batch [1280]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.091678,	
2017-07-31 22:37:23,961 Epoch[52] Batch [1290]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091694,	
2017-07-31 22:37:28,583 Epoch[52] Batch [1300]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091649,	
2017-07-31 22:37:32,642 Epoch[52] Batch [1310]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.091651,	
2017-07-31 22:37:37,003 Epoch[52] Batch [1320]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.091715,	
2017-07-31 22:37:41,358 Epoch[52] Batch [1330]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.091705,	
2017-07-31 22:37:45,645 Epoch[52] Batch [1340]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.091743,	
2017-07-31 22:37:50,172 Epoch[52] Batch [1350]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091719,	
2017-07-31 22:37:54,523 Epoch[52] Batch [1360]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.091734,	
2017-07-31 22:37:59,088 Epoch[52] Batch [1370]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091672,	
2017-07-31 22:38:03,493 Epoch[52] Batch [1380]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.091676,	
2017-07-31 22:38:08,149 Epoch[52] Batch [1390]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091649,	
2017-07-31 22:38:12,681 Epoch[52] Batch [1400]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.091528,	
2017-07-31 22:38:17,168 Epoch[52] Batch [1410]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.091547,	
2017-07-31 22:38:21,935 Epoch[52] Batch [1420]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091543,	
2017-07-31 22:38:26,295 Epoch[52] Batch [1430]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.091599,	
2017-07-31 22:38:30,622 Epoch[52] Batch [1440]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.091596,	
2017-07-31 22:38:34,943 Epoch[52] Batch [1450]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.091608,	
2017-07-31 22:38:39,122 Epoch[52] Batch [1460]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.091584,	
2017-07-31 22:38:43,379 Epoch[52] Batch [1470]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.091607,	
2017-07-31 22:38:47,763 Epoch[52] Batch [1480]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.091580,	
2017-07-31 22:38:50,499 Epoch[52] Train-FCNLogLoss=0.091600
2017-07-31 22:38:50,499 Epoch[52] Time cost=663.526
2017-07-31 22:38:51,304 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0053.params"
2017-07-31 22:38:53,019 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0053.states"
2017-07-31 22:38:53,052 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-31 22:39:03,594 testing 4/500 data 0.7204s net 0.3104s post 0.0115s
2017-07-31 22:39:04,346 testing 8/500 data 0.6034s net 0.2834s post 0.0103s
2017-07-31 22:39:05,075 testing 12/500 data 0.5562s net 0.2745s post 0.0106s
2017-07-31 22:39:05,882 testing 16/500 data 0.5516s net 0.2702s post 0.0109s
2017-07-31 22:39:06,648 testing 20/500 data 0.5398s net 0.2681s post 0.0113s
2017-07-31 22:39:07,298 testing 24/500 data 0.5131s net 0.2666s post 0.0114s
2017-07-31 22:39:08,097 testing 28/500 data 0.5145s net 0.2661s post 0.0115s
2017-07-31 22:39:08,791 testing 32/500 data 0.5030s net 0.2653s post 0.0116s
2017-07-31 22:39:09,443 testing 36/500 data 0.4896s net 0.2643s post 0.0119s
2017-07-31 22:39:10,130 testing 40/500 data 0.4823s net 0.2636s post 0.0120s
2017-07-31 22:39:10,838 testing 44/500 data 0.4780s net 0.2634s post 0.0120s
2017-07-31 22:39:11,699 testing 48/500 data 0.4872s net 0.2633s post 0.0118s
2017-07-31 22:39:12,486 testing 52/500 data 0.4895s net 0.2631s post 0.0115s
2017-07-31 22:39:13,300 testing 56/500 data 0.4930s net 0.2631s post 0.0116s
2017-07-31 22:39:14,025 testing 60/500 data 0.4901s net 0.2631s post 0.0117s
2017-07-31 22:39:14,823 testing 64/500 data 0.4926s net 0.2627s post 0.0117s
2017-07-31 22:39:15,593 testing 68/500 data 0.4932s net 0.2623s post 0.0117s
2017-07-31 22:39:16,277 testing 72/500 data 0.4889s net 0.2619s post 0.0117s
2017-07-31 22:39:16,870 testing 76/500 data 0.4803s net 0.2617s post 0.0116s
2017-07-31 22:39:17,660 testing 80/500 data 0.4822s net 0.2616s post 0.0116s
2017-07-31 22:39:18,431 testing 84/500 data 0.4833s net 0.2613s post 0.0116s
2017-07-31 22:39:19,217 testing 88/500 data 0.4847s net 0.2612s post 0.0116s
2017-07-31 22:39:19,993 testing 92/500 data 0.4859s net 0.2610s post 0.0114s
2017-07-31 22:39:20,752 testing 96/500 data 0.4862s net 0.2607s post 0.0114s
2017-07-31 22:39:21,534 testing 100/500 data 0.4873s net 0.2606s post 0.0114s
2017-07-31 22:39:22,179 testing 104/500 data 0.4829s net 0.2605s post 0.0115s
2017-07-31 22:39:24,587 testing 108/500 data 0.5443s net 0.2603s post 0.0115s
2017-07-31 22:39:25,241 testing 112/500 data 0.5387s net 0.2602s post 0.0115s
2017-07-31 22:39:26,016 testing 116/500 data 0.5376s net 0.2601s post 0.0115s
2017-07-31 22:39:26,638 testing 120/500 data 0.5315s net 0.2600s post 0.0114s
2017-07-31 22:39:27,244 testing 124/500 data 0.5252s net 0.2599s post 0.0114s
2017-07-31 22:39:27,893 testing 128/500 data 0.5207s net 0.2598s post 0.0114s
2017-07-31 22:39:30,271 testing 132/500 data 0.5689s net 0.2597s post 0.0114s
2017-07-31 22:39:30,911 testing 136/500 data 0.5631s net 0.2596s post 0.0114s
2017-07-31 22:39:31,522 testing 140/500 data 0.5569s net 0.2595s post 0.0114s
2017-07-31 22:39:32,125 testing 144/500 data 0.5508s net 0.2594s post 0.0113s
2017-07-31 22:39:32,757 testing 148/500 data 0.5458s net 0.2594s post 0.0112s
2017-07-31 22:39:33,392 testing 152/500 data 0.5412s net 0.2593s post 0.0111s
2017-07-31 22:39:34,174 testing 156/500 data 0.5407s net 0.2592s post 0.0110s
2017-07-31 22:39:34,857 testing 160/500 data 0.5377s net 0.2591s post 0.0109s
2017-07-31 22:39:35,479 testing 164/500 data 0.5333s net 0.2590s post 0.0109s
2017-07-31 22:39:36,098 testing 168/500 data 0.5289s net 0.2590s post 0.0109s
2017-07-31 22:39:36,726 testing 172/500 data 0.5250s net 0.2589s post 0.0108s
2017-07-31 22:39:37,341 testing 176/500 data 0.5212s net 0.2588s post 0.0107s
2017-07-31 22:39:37,974 testing 180/500 data 0.5177s net 0.2587s post 0.0108s
2017-07-31 22:39:38,592 testing 184/500 data 0.5140s net 0.2587s post 0.0108s
2017-07-31 22:39:39,218 testing 188/500 data 0.5107s net 0.2586s post 0.0108s
2017-07-31 22:39:39,836 testing 192/500 data 0.5075s net 0.2586s post 0.0107s
2017-07-31 22:39:40,658 testing 196/500 data 0.5085s net 0.2585s post 0.0107s
2017-07-31 22:39:41,404 testing 200/500 data 0.5078s net 0.2585s post 0.0107s
2017-07-31 22:39:42,020 testing 204/500 data 0.5047s net 0.2584s post 0.0107s
2017-07-31 22:39:42,598 testing 208/500 data 0.5010s net 0.2584s post 0.0108s
2017-07-31 22:39:43,252 testing 212/500 data 0.4989s net 0.2583s post 0.0107s
2017-07-31 22:39:44,026 testing 216/500 data 0.4990s net 0.2583s post 0.0107s
2017-07-31 22:39:44,882 testing 220/500 data 0.5006s net 0.2582s post 0.0108s
2017-07-31 22:39:45,700 testing 224/500 data 0.5015s net 0.2582s post 0.0108s
2017-07-31 22:39:46,539 testing 228/500 data 0.5027s net 0.2582s post 0.0108s
2017-07-31 22:39:47,323 testing 232/500 data 0.5029s net 0.2582s post 0.0108s
2017-07-31 22:39:48,100 testing 236/500 data 0.5031s net 0.2582s post 0.0107s
2017-07-31 22:39:48,750 testing 240/500 data 0.5011s net 0.2581s post 0.0107s
2017-07-31 22:39:49,589 testing 244/500 data 0.5023s net 0.2581s post 0.0108s
2017-07-31 22:39:50,362 testing 248/500 data 0.5023s net 0.2580s post 0.0108s
2017-07-31 22:39:51,148 testing 252/500 data 0.5026s net 0.2580s post 0.0108s
2017-07-31 22:39:52,016 testing 256/500 data 0.5041s net 0.2580s post 0.0108s
2017-07-31 22:39:52,783 testing 260/500 data 0.5041s net 0.2579s post 0.0107s
2017-07-31 22:39:53,630 testing 264/500 data 0.5053s net 0.2579s post 0.0108s
2017-07-31 22:39:54,473 testing 268/500 data 0.5063s net 0.2579s post 0.0107s
2017-07-31 22:39:55,254 testing 272/500 data 0.5064s net 0.2578s post 0.0108s
2017-07-31 22:39:56,058 testing 276/500 data 0.5069s net 0.2578s post 0.0107s
2017-07-31 22:39:56,803 testing 280/500 data 0.5065s net 0.2578s post 0.0108s
2017-07-31 22:39:57,592 testing 284/500 data 0.5067s net 0.2577s post 0.0108s
2017-07-31 22:39:58,258 testing 288/500 data 0.5052s net 0.2577s post 0.0108s
2017-07-31 22:39:58,974 testing 292/500 data 0.5044s net 0.2577s post 0.0108s
2017-07-31 22:39:59,759 testing 296/500 data 0.5046s net 0.2577s post 0.0108s
2017-07-31 22:40:00,368 testing 300/500 data 0.5024s net 0.2576s post 0.0108s
2017-07-31 22:40:01,104 testing 304/500 data 0.5020s net 0.2576s post 0.0108s
2017-07-31 22:40:01,835 testing 308/500 data 0.5015s net 0.2576s post 0.0108s
2017-07-31 22:40:02,466 testing 312/500 data 0.4998s net 0.2576s post 0.0108s
2017-07-31 22:40:03,070 testing 316/500 data 0.4977s net 0.2576s post 0.0108s
2017-07-31 22:40:03,665 testing 320/500 data 0.4956s net 0.2576s post 0.0107s
2017-07-31 22:40:04,265 testing 324/500 data 0.4937s net 0.2575s post 0.0107s
2017-07-31 22:40:04,876 testing 328/500 data 0.4919s net 0.2575s post 0.0106s
2017-07-31 22:40:05,495 testing 332/500 data 0.4902s net 0.2575s post 0.0106s
2017-07-31 22:40:06,114 testing 336/500 data 0.4886s net 0.2575s post 0.0106s
2017-07-31 22:40:06,720 testing 340/500 data 0.4869s net 0.2575s post 0.0106s
2017-07-31 22:40:07,362 testing 344/500 data 0.4856s net 0.2574s post 0.0106s
2017-07-31 22:40:08,009 testing 348/500 data 0.4844s net 0.2574s post 0.0105s
2017-07-31 22:40:08,758 testing 352/500 data 0.4844s net 0.2574s post 0.0105s
2017-07-31 22:40:09,468 testing 356/500 data 0.4839s net 0.2574s post 0.0105s
2017-07-31 22:40:10,261 testing 360/500 data 0.4844s net 0.2575s post 0.0105s
2017-07-31 22:40:10,997 testing 364/500 data 0.4841s net 0.2575s post 0.0105s
2017-07-31 22:40:11,729 testing 368/500 data 0.4839s net 0.2575s post 0.0105s
2017-07-31 22:40:12,483 testing 372/500 data 0.4839s net 0.2575s post 0.0105s
2017-07-31 22:40:13,249 testing 376/500 data 0.4840s net 0.2575s post 0.0105s
2017-07-31 22:40:14,022 testing 380/500 data 0.4843s net 0.2575s post 0.0105s
2017-07-31 22:40:14,822 testing 384/500 data 0.4848s net 0.2575s post 0.0105s
2017-07-31 22:40:15,540 testing 388/500 data 0.4845s net 0.2575s post 0.0105s
2017-07-31 22:40:16,300 testing 392/500 data 0.4846s net 0.2574s post 0.0105s
2017-07-31 22:40:16,979 testing 396/500 data 0.4839s net 0.2575s post 0.0105s
2017-07-31 22:40:17,754 testing 400/500 data 0.4841s net 0.2575s post 0.0105s
2017-07-31 22:40:18,561 testing 404/500 data 0.4846s net 0.2575s post 0.0105s
2017-07-31 22:40:19,311 testing 408/500 data 0.4847s net 0.2574s post 0.0105s
2017-07-31 22:40:20,026 testing 412/500 data 0.4843s net 0.2574s post 0.0105s
2017-07-31 22:40:20,618 testing 416/500 data 0.4828s net 0.2574s post 0.0105s
2017-07-31 22:40:21,231 testing 420/500 data 0.4815s net 0.2573s post 0.0105s
2017-07-31 22:40:21,850 testing 424/500 data 0.4802s net 0.2573s post 0.0105s
2017-07-31 22:40:22,626 testing 428/500 data 0.4805s net 0.2573s post 0.0105s
2017-07-31 22:40:23,290 testing 432/500 data 0.4797s net 0.2573s post 0.0105s
2017-07-31 22:40:24,025 testing 436/500 data 0.4797s net 0.2573s post 0.0105s
2017-07-31 22:40:24,696 testing 440/500 data 0.4790s net 0.2573s post 0.0105s
2017-07-31 22:40:25,465 testing 444/500 data 0.4793s net 0.2573s post 0.0104s
2017-07-31 22:40:26,226 testing 448/500 data 0.4794s net 0.2573s post 0.0104s
2017-07-31 22:40:26,975 testing 452/500 data 0.4795s net 0.2573s post 0.0104s
2017-07-31 22:40:27,704 testing 456/500 data 0.4793s net 0.2572s post 0.0104s
2017-07-31 22:40:28,442 testing 460/500 data 0.4793s net 0.2572s post 0.0104s
2017-07-31 22:40:29,112 testing 464/500 data 0.4786s net 0.2572s post 0.0103s
2017-07-31 22:40:29,709 testing 468/500 data 0.4774s net 0.2572s post 0.0103s
2017-07-31 22:40:30,444 testing 472/500 data 0.4774s net 0.2572s post 0.0103s
2017-07-31 22:40:31,244 testing 476/500 data 0.4779s net 0.2572s post 0.0103s
2017-07-31 22:40:31,998 testing 480/500 data 0.4779s net 0.2572s post 0.0103s
2017-07-31 22:40:32,689 testing 484/500 data 0.4775s net 0.2572s post 0.0103s
2017-07-31 22:40:33,323 testing 488/500 data 0.4766s net 0.2572s post 0.0103s
2017-07-31 22:40:34,095 testing 492/500 data 0.4768s net 0.2571s post 0.0103s
2017-07-31 22:40:34,927 testing 496/500 data 0.4775s net 0.2571s post 0.0103s
2017-07-31 22:40:35,693 testing 500/500 data 0.4776s net 0.2572s post 0.0103s
2017-07-31 22:42:16,994 evaluate segmentation: 

2017-07-31 22:42:16,994 IU_array:

2017-07-31 22:42:16,994 0.97963
2017-07-31 22:42:16,994 0.83169
2017-07-31 22:42:16,994 0.91393
2017-07-31 22:42:16,994 0.51994
2017-07-31 22:42:16,995 0.56691
2017-07-31 22:42:16,995 0.53758
2017-07-31 22:42:16,995 0.63882
2017-07-31 22:42:16,995 0.73495
2017-07-31 22:42:16,995 0.91456
2017-07-31 22:42:16,995 0.61568
2017-07-31 22:42:16,995 0.93544
2017-07-31 22:42:16,995 0.78225
2017-07-31 22:42:16,995 0.58283
2017-07-31 22:42:16,995 0.93909
2017-07-31 22:42:16,995 0.67994
2017-07-31 22:42:16,995 0.80877
2017-07-31 22:42:16,995 0.64430
2017-07-31 22:42:16,995 0.58745
2017-07-31 22:42:16,995 0.73935
2017-07-31 22:42:16,995 meanIU:0.73437

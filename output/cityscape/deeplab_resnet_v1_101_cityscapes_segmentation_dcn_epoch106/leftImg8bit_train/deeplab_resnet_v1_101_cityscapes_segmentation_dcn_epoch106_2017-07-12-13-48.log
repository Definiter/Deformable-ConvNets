2017-07-12 13:48:33,732 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 106,
           'lr': 0.0005,
           'lr_step': '80.672',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn'}

2017-07-12 13:49:27,750 Epoch[0] Batch [10]	Speed: 3.90 samples/sec	Train-FCNLogLoss=2.888704,	
2017-07-12 13:49:35,418 Epoch[0] Batch [20]	Speed: 5.22 samples/sec	Train-FCNLogLoss=2.747168,	
2017-07-12 13:49:41,893 Epoch[0] Batch [30]	Speed: 6.18 samples/sec	Train-FCNLogLoss=2.494472,	
2017-07-12 13:49:48,665 Epoch[0] Batch [40]	Speed: 5.91 samples/sec	Train-FCNLogLoss=2.254824,	
2017-07-12 13:49:54,985 Epoch[0] Batch [50]	Speed: 6.33 samples/sec	Train-FCNLogLoss=2.070695,	
2017-07-12 13:50:01,759 Epoch[0] Batch [60]	Speed: 5.91 samples/sec	Train-FCNLogLoss=1.916955,	
2017-07-12 13:50:08,643 Epoch[0] Batch [70]	Speed: 5.81 samples/sec	Train-FCNLogLoss=1.791306,	
2017-07-12 13:50:15,294 Epoch[0] Batch [80]	Speed: 6.02 samples/sec	Train-FCNLogLoss=1.688437,	
2017-07-12 13:50:22,375 Epoch[0] Batch [90]	Speed: 5.65 samples/sec	Train-FCNLogLoss=1.588291,	
2017-07-12 13:50:29,398 Epoch[0] Batch [100]	Speed: 5.70 samples/sec	Train-FCNLogLoss=1.500542,	
2017-07-12 13:50:36,398 Epoch[0] Batch [110]	Speed: 5.71 samples/sec	Train-FCNLogLoss=1.427010,	
2017-07-12 13:50:43,244 Epoch[0] Batch [120]	Speed: 5.84 samples/sec	Train-FCNLogLoss=1.365415,	
2017-07-12 13:50:51,999 Epoch[0] Batch [130]	Speed: 4.57 samples/sec	Train-FCNLogLoss=1.304097,	
2017-07-12 13:51:00,762 Epoch[0] Batch [140]	Speed: 4.56 samples/sec	Train-FCNLogLoss=1.257047,	
2017-07-12 13:51:09,843 Epoch[0] Batch [150]	Speed: 4.41 samples/sec	Train-FCNLogLoss=1.212800,	
2017-07-12 13:51:19,082 Epoch[0] Batch [160]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.175665,	
2017-07-12 13:51:28,305 Epoch[0] Batch [170]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.141872,	
2017-07-12 13:51:37,410 Epoch[0] Batch [180]	Speed: 4.39 samples/sec	Train-FCNLogLoss=1.101506,	
2017-07-12 13:51:46,380 Epoch[0] Batch [190]	Speed: 4.46 samples/sec	Train-FCNLogLoss=1.070440,	
2017-07-12 13:51:55,591 Epoch[0] Batch [200]	Speed: 4.34 samples/sec	Train-FCNLogLoss=1.043355,	
2017-07-12 13:52:02,854 Epoch[0] Batch [210]	Speed: 5.51 samples/sec	Train-FCNLogLoss=1.018783,	
2017-07-12 13:52:10,168 Epoch[0] Batch [220]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.991610,	
2017-07-12 13:52:17,370 Epoch[0] Batch [230]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.967384,	
2017-07-12 13:52:24,439 Epoch[0] Batch [240]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.947918,	
2017-07-12 13:52:31,558 Epoch[0] Batch [250]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.928064,	
2017-07-12 13:52:38,787 Epoch[0] Batch [260]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.910536,	
2017-07-12 13:52:46,087 Epoch[0] Batch [270]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.891927,	
2017-07-12 13:52:53,973 Epoch[0] Batch [280]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.877234,	
2017-07-12 13:53:01,723 Epoch[0] Batch [290]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.863186,	
2017-07-12 13:53:09,069 Epoch[0] Batch [300]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.848879,	
2017-07-12 13:53:17,482 Epoch[0] Batch [310]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.835810,	
2017-07-12 13:53:25,317 Epoch[0] Batch [320]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.822227,	
2017-07-12 13:53:33,478 Epoch[0] Batch [330]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.808950,	
2017-07-12 13:53:41,909 Epoch[0] Batch [340]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.796884,	
2017-07-12 13:53:50,543 Epoch[0] Batch [350]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.785855,	
2017-07-12 13:53:59,242 Epoch[0] Batch [360]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.777835,	
2017-07-12 13:54:07,889 Epoch[0] Batch [370]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.770440,	
2017-07-12 13:54:16,332 Epoch[0] Batch [380]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.760596,	
2017-07-12 13:54:24,482 Epoch[0] Batch [390]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.751343,	
2017-07-12 13:54:31,685 Epoch[0] Batch [400]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.743019,	
2017-07-12 13:54:39,170 Epoch[0] Batch [410]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.734790,	
2017-07-12 13:54:46,714 Epoch[0] Batch [420]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.724989,	
2017-07-12 13:54:54,052 Epoch[0] Batch [430]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.717400,	
2017-07-12 13:55:01,508 Epoch[0] Batch [440]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.711032,	
2017-07-12 13:55:08,766 Epoch[0] Batch [450]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.704825,	
2017-07-12 13:55:16,268 Epoch[0] Batch [460]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.699910,	
2017-07-12 13:55:23,261 Epoch[0] Batch [470]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.693909,	
2017-07-12 13:55:31,591 Epoch[0] Batch [480]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.687874,	
2017-07-12 13:55:40,852 Epoch[0] Batch [490]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.681530,	
2017-07-12 13:55:49,954 Epoch[0] Batch [500]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.675683,	
2017-07-12 13:55:59,017 Epoch[0] Batch [510]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.669574,	
2017-07-12 13:56:08,034 Epoch[0] Batch [520]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.663729,	
2017-07-12 13:56:16,673 Epoch[0] Batch [530]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.658858,	
2017-07-12 13:56:25,388 Epoch[0] Batch [540]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.654608,	
2017-07-12 13:56:33,936 Epoch[0] Batch [550]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.649165,	
2017-07-12 13:56:42,353 Epoch[0] Batch [560]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.644105,	
2017-07-12 13:56:49,626 Epoch[0] Batch [570]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.639204,	
2017-07-12 13:56:57,047 Epoch[0] Batch [580]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.633782,	
2017-07-12 13:57:04,543 Epoch[0] Batch [590]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.628468,	
2017-07-12 13:57:12,830 Epoch[0] Batch [600]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.623760,	
2017-07-12 13:57:20,905 Epoch[0] Batch [610]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.620009,	
2017-07-12 13:57:28,799 Epoch[0] Batch [620]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.615630,	
2017-07-12 13:57:36,191 Epoch[0] Batch [630]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.612514,	
2017-07-12 13:57:43,435 Epoch[0] Batch [640]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.608404,	
2017-07-12 13:57:50,566 Epoch[0] Batch [650]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.603576,	
2017-07-12 13:57:58,674 Epoch[0] Batch [660]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.600199,	
2017-07-12 13:58:06,531 Epoch[0] Batch [670]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.597730,	
2017-07-12 13:58:14,060 Epoch[0] Batch [680]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.594249,	
2017-07-12 13:58:21,556 Epoch[0] Batch [690]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.590969,	
2017-07-12 13:58:29,302 Epoch[0] Batch [700]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.586814,	
2017-07-12 13:58:37,598 Epoch[0] Batch [710]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.582565,	
2017-07-12 13:58:45,647 Epoch[0] Batch [720]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.579439,	
2017-07-12 13:58:53,294 Epoch[0] Batch [730]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.576578,	
2017-07-12 13:59:01,387 Epoch[0] Batch [740]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.573320,	
2017-07-12 13:59:09,426 Epoch[0] Batch [750]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.570120,	
2017-07-12 13:59:17,195 Epoch[0] Batch [760]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.566482,	
2017-07-12 13:59:25,192 Epoch[0] Batch [770]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.563767,	
2017-07-12 13:59:32,766 Epoch[0] Batch [780]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.560933,	
2017-07-12 13:59:40,438 Epoch[0] Batch [790]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.557891,	
2017-07-12 13:59:48,287 Epoch[0] Batch [800]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.555743,	
2017-07-12 13:59:55,725 Epoch[0] Batch [810]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.552788,	
2017-07-12 14:00:04,036 Epoch[0] Batch [820]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.549828,	
2017-07-12 14:00:11,985 Epoch[0] Batch [830]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.547870,	
2017-07-12 14:00:20,053 Epoch[0] Batch [840]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.544968,	
2017-07-12 14:00:27,899 Epoch[0] Batch [850]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.543045,	
2017-07-12 14:00:36,042 Epoch[0] Batch [860]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.540470,	
2017-07-12 14:00:44,197 Epoch[0] Batch [870]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.538187,	
2017-07-12 14:00:52,462 Epoch[0] Batch [880]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.535515,	
2017-07-12 14:01:00,535 Epoch[0] Batch [890]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.533787,	
2017-07-12 14:01:08,430 Epoch[0] Batch [900]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.532248,	
2017-07-12 14:01:16,324 Epoch[0] Batch [910]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.529913,	
2017-07-12 14:01:24,374 Epoch[0] Batch [920]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.528791,	
2017-07-12 14:01:32,467 Epoch[0] Batch [930]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.526016,	
2017-07-12 14:01:40,675 Epoch[0] Batch [940]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.523576,	
2017-07-12 14:01:48,586 Epoch[0] Batch [950]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.521855,	
2017-07-12 14:01:56,317 Epoch[0] Batch [960]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.519418,	
2017-07-12 14:02:03,792 Epoch[0] Batch [970]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.517501,	
2017-07-12 14:02:11,682 Epoch[0] Batch [980]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.515150,	
2017-07-12 14:02:20,824 Epoch[0] Batch [990]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.512947,	
2017-07-12 14:02:29,706 Epoch[0] Batch [1000]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.511423,	
2017-07-12 14:02:37,888 Epoch[0] Batch [1010]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.509176,	
2017-07-12 14:02:53,482 Epoch[0] Batch [1020]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.508684,	
2017-07-12 14:03:07,684 Epoch[0] Batch [1030]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.507648,	
2017-07-12 14:03:21,853 Epoch[0] Batch [1040]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.507024,	
2017-07-12 14:03:33,300 Epoch[0] Batch [1050]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.506320,	
2017-07-12 14:03:45,465 Epoch[0] Batch [1060]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.508164,	
2017-07-12 14:03:57,060 Epoch[0] Batch [1070]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.508734,	
2017-07-12 14:04:07,878 Epoch[0] Batch [1080]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.507733,	
2017-07-12 14:04:21,438 Epoch[0] Batch [1090]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.507562,	
2017-07-12 14:04:35,701 Epoch[0] Batch [1100]	Speed: 2.80 samples/sec	Train-FCNLogLoss=0.507937,	
2017-07-12 14:04:48,341 Epoch[0] Batch [1110]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.507446,	
2017-07-12 14:05:01,254 Epoch[0] Batch [1120]	Speed: 3.10 samples/sec	Train-FCNLogLoss=0.506371,	
2017-07-12 14:05:13,992 Epoch[0] Batch [1130]	Speed: 3.14 samples/sec	Train-FCNLogLoss=0.505192,	
2017-07-12 14:05:27,652 Epoch[0] Batch [1140]	Speed: 2.93 samples/sec	Train-FCNLogLoss=0.506422,	
2017-07-12 14:05:38,965 Epoch[0] Batch [1150]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.506415,	
2017-07-12 14:05:46,952 Epoch[0] Batch [1160]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.505832,	
2017-07-12 14:05:54,061 Epoch[0] Batch [1170]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.504565,	
2017-07-12 14:06:00,404 Epoch[0] Batch [1180]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.503194,	
2017-07-12 14:06:06,947 Epoch[0] Batch [1190]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.501730,	
2017-07-12 14:06:13,588 Epoch[0] Batch [1200]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.500297,	
2017-07-12 14:06:20,228 Epoch[0] Batch [1210]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.498680,	
2017-07-12 14:06:27,521 Epoch[0] Batch [1220]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.497054,	
2017-07-12 14:06:34,632 Epoch[0] Batch [1230]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.495402,	
2017-07-12 14:06:43,260 Epoch[0] Batch [1240]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.493779,	
2017-07-12 14:06:50,622 Epoch[0] Batch [1250]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.491972,	
2017-07-12 14:06:58,899 Epoch[0] Batch [1260]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.490769,	
2017-07-12 14:07:04,638 Epoch[0] Batch [1270]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.489402,	
2017-07-12 14:07:09,578 Epoch[0] Batch [1280]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.487615,	
2017-07-12 14:07:15,212 Epoch[0] Batch [1290]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.486068,	
2017-07-12 14:07:21,438 Epoch[0] Batch [1300]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.485099,	
2017-07-12 14:07:27,292 Epoch[0] Batch [1310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.484426,	
2017-07-12 14:07:33,818 Epoch[0] Batch [1320]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.483634,	
2017-07-12 14:07:39,614 Epoch[0] Batch [1330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.483711,	
2017-07-12 14:07:44,905 Epoch[0] Batch [1340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.482948,	
2017-07-12 14:07:50,757 Epoch[0] Batch [1350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.481848,	
2017-07-12 14:07:56,471 Epoch[0] Batch [1360]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.480411,	
2017-07-12 14:08:02,304 Epoch[0] Batch [1370]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.479348,	
2017-07-12 14:08:08,118 Epoch[0] Batch [1380]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.477990,	
2017-07-12 14:08:14,108 Epoch[0] Batch [1390]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.477365,	
2017-07-12 14:08:19,272 Epoch[0] Batch [1400]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.476205,	
2017-07-12 14:08:25,303 Epoch[0] Batch [1410]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.474907,	
2017-07-12 14:08:31,047 Epoch[0] Batch [1420]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.473396,	
2017-07-12 14:08:36,635 Epoch[0] Batch [1430]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.472014,	
2017-07-12 14:08:42,168 Epoch[0] Batch [1440]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.470617,	
2017-07-12 14:08:48,065 Epoch[0] Batch [1450]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.470407,	
2017-07-12 14:08:54,126 Epoch[0] Batch [1460]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.469953,	
2017-07-12 14:08:59,434 Epoch[0] Batch [1470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.468938,	
2017-07-12 14:09:05,009 Epoch[0] Batch [1480]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.468016,	
2017-07-12 14:09:08,367 Epoch[0] Train-FCNLogLoss=0.467421
2017-07-12 14:09:08,367 Epoch[0] Time cost=1200.795
2017-07-12 14:09:09,455 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0001.params"
2017-07-12 14:09:13,738 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0001.states"
2017-07-12 14:09:19,663 Epoch[1] Batch [10]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.292376,	
2017-07-12 14:09:24,741 Epoch[1] Batch [20]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.283201,	
2017-07-12 14:09:29,869 Epoch[1] Batch [30]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.288606,	
2017-07-12 14:09:34,984 Epoch[1] Batch [40]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.287425,	
2017-07-12 14:09:40,626 Epoch[1] Batch [50]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.293057,	
2017-07-12 14:09:46,288 Epoch[1] Batch [60]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.291677,	
2017-07-12 14:09:52,220 Epoch[1] Batch [70]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.283739,	
2017-07-12 14:09:57,949 Epoch[1] Batch [80]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.278492,	
2017-07-12 14:10:03,625 Epoch[1] Batch [90]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.280291,	
2017-07-12 14:10:09,516 Epoch[1] Batch [100]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.277890,	
2017-07-12 14:10:14,774 Epoch[1] Batch [110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.274422,	
2017-07-12 14:10:20,701 Epoch[1] Batch [120]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.274715,	
2017-07-12 14:10:26,106 Epoch[1] Batch [130]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.277033,	
2017-07-12 14:10:31,750 Epoch[1] Batch [140]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.275770,	
2017-07-12 14:10:37,423 Epoch[1] Batch [150]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.274523,	
2017-07-12 14:10:42,831 Epoch[1] Batch [160]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.273288,	
2017-07-12 14:10:48,669 Epoch[1] Batch [170]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.273245,	
2017-07-12 14:10:54,123 Epoch[1] Batch [180]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.275843,	
2017-07-12 14:10:59,228 Epoch[1] Batch [190]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.274977,	
2017-07-12 14:11:04,693 Epoch[1] Batch [200]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.272648,	
2017-07-12 14:11:09,944 Epoch[1] Batch [210]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.270263,	
2017-07-12 14:11:15,428 Epoch[1] Batch [220]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.268889,	
2017-07-12 14:11:21,227 Epoch[1] Batch [230]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.269882,	
2017-07-12 14:11:26,708 Epoch[1] Batch [240]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.269460,	
2017-07-12 14:11:31,867 Epoch[1] Batch [250]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.269862,	
2017-07-12 14:11:38,622 Epoch[1] Batch [260]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.270685,	
2017-07-12 14:11:46,854 Epoch[1] Batch [270]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.271682,	
2017-07-12 14:11:51,786 Epoch[1] Batch [280]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.271886,	
2017-07-12 14:11:56,445 Epoch[1] Batch [290]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.272951,	
2017-07-12 14:12:01,357 Epoch[1] Batch [300]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.273233,	
2017-07-12 14:12:06,396 Epoch[1] Batch [310]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.274446,	
2017-07-12 14:12:11,957 Epoch[1] Batch [320]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.274077,	
2017-07-12 14:12:17,497 Epoch[1] Batch [330]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.272720,	
2017-07-12 14:12:23,023 Epoch[1] Batch [340]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.273316,	
2017-07-12 14:12:28,330 Epoch[1] Batch [350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.272514,	
2017-07-12 14:12:33,531 Epoch[1] Batch [360]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.272965,	
2017-07-12 14:12:38,672 Epoch[1] Batch [370]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.271500,	
2017-07-12 14:12:43,910 Epoch[1] Batch [380]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.270037,	
2017-07-12 14:12:49,293 Epoch[1] Batch [390]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.270725,	
2017-07-12 14:12:54,452 Epoch[1] Batch [400]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.271436,	
2017-07-12 14:12:59,741 Epoch[1] Batch [410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.272791,	
2017-07-12 14:13:05,361 Epoch[1] Batch [420]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.275782,	
2017-07-12 14:13:10,687 Epoch[1] Batch [430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.277545,	
2017-07-12 14:13:16,148 Epoch[1] Batch [440]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.277089,	
2017-07-12 14:13:21,267 Epoch[1] Batch [450]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.277889,	
2017-07-12 14:13:26,178 Epoch[1] Batch [460]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.277826,	
2017-07-12 14:13:31,418 Epoch[1] Batch [470]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.276889,	
2017-07-12 14:13:36,150 Epoch[1] Batch [480]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.275803,	
2017-07-12 14:13:41,267 Epoch[1] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.275719,	
2017-07-12 14:13:46,168 Epoch[1] Batch [500]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.275023,	
2017-07-12 14:13:51,142 Epoch[1] Batch [510]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.274558,	
2017-07-12 14:13:56,161 Epoch[1] Batch [520]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.274546,	
2017-07-12 14:14:00,984 Epoch[1] Batch [530]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.273827,	
2017-07-12 14:14:05,633 Epoch[1] Batch [540]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.273770,	
2017-07-12 14:14:10,483 Epoch[1] Batch [550]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.272580,	
2017-07-12 14:14:15,549 Epoch[1] Batch [560]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.271631,	
2017-07-12 14:14:20,482 Epoch[1] Batch [570]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.270676,	
2017-07-12 14:14:25,193 Epoch[1] Batch [580]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.269740,	
2017-07-12 14:14:29,965 Epoch[1] Batch [590]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.268927,	
2017-07-12 14:14:34,648 Epoch[1] Batch [600]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.267945,	
2017-07-12 14:14:39,423 Epoch[1] Batch [610]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.267573,	
2017-07-12 14:14:44,284 Epoch[1] Batch [620]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.266416,	
2017-07-12 14:14:48,970 Epoch[1] Batch [630]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.266481,	
2017-07-12 14:14:53,685 Epoch[1] Batch [640]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.266331,	
2017-07-12 14:14:58,638 Epoch[1] Batch [650]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.265859,	
2017-07-12 14:15:03,398 Epoch[1] Batch [660]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.265579,	
2017-07-12 14:15:08,260 Epoch[1] Batch [670]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.265524,	
2017-07-12 14:15:12,829 Epoch[1] Batch [680]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.265502,	
2017-07-12 14:15:17,574 Epoch[1] Batch [690]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.265221,	
2017-07-12 14:15:22,492 Epoch[1] Batch [700]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.264541,	
2017-07-12 14:15:27,323 Epoch[1] Batch [710]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.263874,	
2017-07-12 14:15:32,517 Epoch[1] Batch [720]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.263272,	
2017-07-12 14:15:37,277 Epoch[1] Batch [730]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.263283,	
2017-07-12 14:15:41,952 Epoch[1] Batch [740]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.262435,	
2017-07-12 14:15:46,644 Epoch[1] Batch [750]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.261638,	
2017-07-12 14:15:51,603 Epoch[1] Batch [760]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.261770,	
2017-07-12 14:15:56,433 Epoch[1] Batch [770]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.261126,	
2017-07-12 14:16:00,832 Epoch[1] Batch [780]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.261240,	
2017-07-12 14:16:05,380 Epoch[1] Batch [790]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.260743,	
2017-07-12 14:16:09,910 Epoch[1] Batch [800]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.260277,	
2017-07-12 14:16:14,529 Epoch[1] Batch [810]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.260034,	
2017-07-12 14:16:19,366 Epoch[1] Batch [820]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.259931,	
2017-07-12 14:16:24,071 Epoch[1] Batch [830]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.259443,	
2017-07-12 14:16:28,823 Epoch[1] Batch [840]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.258648,	
2017-07-12 14:16:33,743 Epoch[1] Batch [850]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.258392,	
2017-07-12 14:16:38,832 Epoch[1] Batch [860]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.257725,	
2017-07-12 14:16:44,437 Epoch[1] Batch [870]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.257229,	
2017-07-12 14:16:49,367 Epoch[1] Batch [880]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.256933,	
2017-07-12 14:16:54,324 Epoch[1] Batch [890]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.256582,	
2017-07-12 14:16:59,352 Epoch[1] Batch [900]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.256063,	
2017-07-12 14:17:04,413 Epoch[1] Batch [910]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.255895,	
2017-07-12 14:17:09,444 Epoch[1] Batch [920]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.255616,	
2017-07-12 14:17:14,625 Epoch[1] Batch [930]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.255462,	
2017-07-12 14:17:19,925 Epoch[1] Batch [940]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.256044,	
2017-07-12 14:17:25,124 Epoch[1] Batch [950]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.256132,	
2017-07-12 14:17:30,547 Epoch[1] Batch [960]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.255940,	
2017-07-12 14:17:35,759 Epoch[1] Batch [970]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.255691,	
2017-07-12 14:17:41,167 Epoch[1] Batch [980]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.256126,	
2017-07-12 14:17:45,995 Epoch[1] Batch [990]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.256113,	
2017-07-12 14:17:51,674 Epoch[1] Batch [1000]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.255589,	
2017-07-12 14:17:56,697 Epoch[1] Batch [1010]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.255021,	
2017-07-12 14:18:01,866 Epoch[1] Batch [1020]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.254382,	
2017-07-12 14:18:07,676 Epoch[1] Batch [1030]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.254209,	
2017-07-12 14:18:13,509 Epoch[1] Batch [1040]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.253800,	
2017-07-12 14:18:19,313 Epoch[1] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.253294,	
2017-07-12 14:18:25,187 Epoch[1] Batch [1060]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.253179,	
2017-07-12 14:18:31,188 Epoch[1] Batch [1070]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.253114,	
2017-07-12 14:18:37,998 Epoch[1] Batch [1080]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.253097,	
2017-07-12 14:18:44,213 Epoch[1] Batch [1090]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.252930,	
2017-07-12 14:18:50,436 Epoch[1] Batch [1100]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.252485,	
2017-07-12 14:18:57,332 Epoch[1] Batch [1110]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.252057,	
2017-07-12 14:19:05,425 Epoch[1] Batch [1120]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.252144,	
2017-07-12 14:19:13,060 Epoch[1] Batch [1130]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.252193,	
2017-07-12 14:19:21,756 Epoch[1] Batch [1140]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.252067,	
2017-07-12 14:19:29,216 Epoch[1] Batch [1150]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.251559,	
2017-07-12 14:19:36,689 Epoch[1] Batch [1160]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.251579,	
2017-07-12 14:19:44,205 Epoch[1] Batch [1170]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.251186,	
2017-07-12 14:19:52,187 Epoch[1] Batch [1180]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.251144,	
2017-07-12 14:19:59,823 Epoch[1] Batch [1190]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.251283,	
2017-07-12 14:20:07,091 Epoch[1] Batch [1200]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.251024,	
2017-07-12 14:20:12,482 Epoch[1] Batch [1210]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.250651,	
2017-07-12 14:20:17,736 Epoch[1] Batch [1220]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.250372,	
2017-07-12 14:20:22,843 Epoch[1] Batch [1230]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.250405,	
2017-07-12 14:20:27,676 Epoch[1] Batch [1240]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.249975,	
2017-07-12 14:20:32,778 Epoch[1] Batch [1250]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.249636,	
2017-07-12 14:20:37,681 Epoch[1] Batch [1260]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.249268,	
2017-07-12 14:20:42,453 Epoch[1] Batch [1270]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.248868,	
2017-07-12 14:20:47,340 Epoch[1] Batch [1280]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.248860,	
2017-07-12 14:20:52,563 Epoch[1] Batch [1290]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.248725,	
2017-07-12 14:20:57,526 Epoch[1] Batch [1300]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.248421,	
2017-07-12 14:21:02,696 Epoch[1] Batch [1310]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.248306,	
2017-07-12 14:21:07,338 Epoch[1] Batch [1320]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.248175,	
2017-07-12 14:21:12,333 Epoch[1] Batch [1330]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.247709,	
2017-07-12 14:21:17,409 Epoch[1] Batch [1340]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.247467,	
2017-07-12 14:21:22,643 Epoch[1] Batch [1350]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.247279,	
2017-07-12 14:21:28,128 Epoch[1] Batch [1360]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.247059,	
2017-07-12 14:21:33,195 Epoch[1] Batch [1370]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.247252,	
2017-07-12 14:21:38,369 Epoch[1] Batch [1380]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.247043,	
2017-07-12 14:21:44,154 Epoch[1] Batch [1390]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.246738,	
2017-07-12 14:21:49,449 Epoch[1] Batch [1400]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.246542,	
2017-07-12 14:21:54,737 Epoch[1] Batch [1410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.246140,	
2017-07-12 14:21:59,772 Epoch[1] Batch [1420]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.245647,	
2017-07-12 14:22:05,114 Epoch[1] Batch [1430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.245272,	
2017-07-12 14:22:10,312 Epoch[1] Batch [1440]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.244994,	
2017-07-12 14:22:15,365 Epoch[1] Batch [1450]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.244940,	
2017-07-12 14:22:20,102 Epoch[1] Batch [1460]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.244752,	
2017-07-12 14:22:25,181 Epoch[1] Batch [1470]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.244500,	
2017-07-12 14:22:30,365 Epoch[1] Batch [1480]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.244478,	
2017-07-12 14:22:33,445 Epoch[1] Train-FCNLogLoss=0.244400
2017-07-12 14:22:33,446 Epoch[1] Time cost=799.707
2017-07-12 14:22:34,379 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0002.params"
2017-07-12 14:22:36,628 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0002.states"
2017-07-12 14:22:42,312 Epoch[2] Batch [10]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.220382,	
2017-07-12 14:22:47,406 Epoch[2] Batch [20]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.206042,	
2017-07-12 14:22:52,637 Epoch[2] Batch [30]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.199353,	
2017-07-12 14:22:57,819 Epoch[2] Batch [40]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.189232,	
2017-07-12 14:23:02,907 Epoch[2] Batch [50]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.188952,	
2017-07-12 14:23:07,945 Epoch[2] Batch [60]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.191561,	
2017-07-12 14:23:12,895 Epoch[2] Batch [70]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.190435,	
2017-07-12 14:23:18,068 Epoch[2] Batch [80]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.191755,	
2017-07-12 14:23:23,126 Epoch[2] Batch [90]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.194634,	
2017-07-12 14:23:28,174 Epoch[2] Batch [100]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.192802,	
2017-07-12 14:23:33,515 Epoch[2] Batch [110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.191856,	
2017-07-12 14:23:38,670 Epoch[2] Batch [120]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.195421,	
2017-07-12 14:23:44,035 Epoch[2] Batch [130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.196665,	
2017-07-12 14:23:49,407 Epoch[2] Batch [140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.198762,	
2017-07-12 14:23:54,429 Epoch[2] Batch [150]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.198300,	
2017-07-12 14:23:59,570 Epoch[2] Batch [160]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.197621,	
2017-07-12 14:24:04,723 Epoch[2] Batch [170]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.196919,	
2017-07-12 14:24:09,916 Epoch[2] Batch [180]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.197389,	
2017-07-12 14:24:14,875 Epoch[2] Batch [190]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.197234,	
2017-07-12 14:24:20,175 Epoch[2] Batch [200]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.197316,	
2017-07-12 14:24:25,365 Epoch[2] Batch [210]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.200394,	
2017-07-12 14:24:30,703 Epoch[2] Batch [220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.200656,	
2017-07-12 14:24:35,223 Epoch[2] Batch [230]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.201981,	
2017-07-12 14:24:39,668 Epoch[2] Batch [240]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.202796,	
2017-07-12 14:24:44,865 Epoch[2] Batch [250]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.202664,	
2017-07-12 14:24:49,850 Epoch[2] Batch [260]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.202565,	
2017-07-12 14:24:54,908 Epoch[2] Batch [270]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.202796,	
2017-07-12 14:25:00,685 Epoch[2] Batch [280]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.202805,	
2017-07-12 14:25:05,927 Epoch[2] Batch [290]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.203613,	
2017-07-12 14:25:11,001 Epoch[2] Batch [300]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.203560,	
2017-07-12 14:25:16,472 Epoch[2] Batch [310]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.204546,	
2017-07-12 14:25:21,558 Epoch[2] Batch [320]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.205538,	
2017-07-12 14:25:27,011 Epoch[2] Batch [330]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.207525,	
2017-07-12 14:25:32,424 Epoch[2] Batch [340]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.207917,	
2017-07-12 14:25:37,767 Epoch[2] Batch [350]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.208102,	
2017-07-12 14:25:42,720 Epoch[2] Batch [360]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.208202,	
2017-07-12 14:25:47,789 Epoch[2] Batch [370]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.208394,	
2017-07-12 14:25:52,886 Epoch[2] Batch [380]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.207847,	
2017-07-12 14:25:58,088 Epoch[2] Batch [390]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.208466,	
2017-07-12 14:26:02,950 Epoch[2] Batch [400]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.207556,	
2017-07-12 14:26:07,889 Epoch[2] Batch [410]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.206842,	
2017-07-12 14:26:12,999 Epoch[2] Batch [420]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.206697,	
2017-07-12 14:26:18,034 Epoch[2] Batch [430]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.208558,	
2017-07-12 14:26:22,821 Epoch[2] Batch [440]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.208326,	
2017-07-12 14:26:27,724 Epoch[2] Batch [450]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.208040,	
2017-07-12 14:26:32,806 Epoch[2] Batch [460]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.208069,	
2017-07-12 14:26:38,030 Epoch[2] Batch [470]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.207607,	
2017-07-12 14:26:43,242 Epoch[2] Batch [480]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.207490,	
2017-07-12 14:26:48,266 Epoch[2] Batch [490]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.207671,	
2017-07-12 14:26:53,072 Epoch[2] Batch [500]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.207450,	
2017-07-12 14:26:58,078 Epoch[2] Batch [510]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.208994,	
2017-07-12 14:27:02,915 Epoch[2] Batch [520]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.208235,	
2017-07-12 14:27:08,288 Epoch[2] Batch [530]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.208065,	
2017-07-12 14:27:13,338 Epoch[2] Batch [540]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.207528,	
2017-07-12 14:27:18,574 Epoch[2] Batch [550]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.207591,	
2017-07-12 14:27:23,727 Epoch[2] Batch [560]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.207328,	
2017-07-12 14:27:29,005 Epoch[2] Batch [570]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.208048,	
2017-07-12 14:27:34,359 Epoch[2] Batch [580]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.208065,	
2017-07-12 14:27:39,526 Epoch[2] Batch [590]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.207613,	
2017-07-12 14:27:44,734 Epoch[2] Batch [600]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.207682,	
2017-07-12 14:27:49,755 Epoch[2] Batch [610]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.206920,	
2017-07-12 14:27:54,954 Epoch[2] Batch [620]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.208392,	
2017-07-12 14:27:59,924 Epoch[2] Batch [630]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.208900,	
2017-07-12 14:28:05,226 Epoch[2] Batch [640]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.209422,	
2017-07-12 14:28:10,267 Epoch[2] Batch [650]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.209681,	
2017-07-12 14:28:15,099 Epoch[2] Batch [660]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.209194,	
2017-07-12 14:28:20,054 Epoch[2] Batch [670]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.208946,	
2017-07-12 14:28:24,979 Epoch[2] Batch [680]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.208464,	
2017-07-12 14:28:30,020 Epoch[2] Batch [690]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.208236,	
2017-07-12 14:28:35,102 Epoch[2] Batch [700]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.208464,	
2017-07-12 14:28:40,176 Epoch[2] Batch [710]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.208421,	
2017-07-12 14:28:45,255 Epoch[2] Batch [720]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.208528,	
2017-07-12 14:28:50,364 Epoch[2] Batch [730]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.208205,	
2017-07-12 14:28:55,703 Epoch[2] Batch [740]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.208530,	
2017-07-12 14:29:00,826 Epoch[2] Batch [750]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.208543,	
2017-07-12 14:29:05,952 Epoch[2] Batch [760]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.208475,	
2017-07-12 14:29:11,192 Epoch[2] Batch [770]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.208292,	
2017-07-12 14:29:16,415 Epoch[2] Batch [780]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.208471,	
2017-07-12 14:29:21,609 Epoch[2] Batch [790]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.208008,	
2017-07-12 14:29:26,709 Epoch[2] Batch [800]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.208191,	
2017-07-12 14:29:31,957 Epoch[2] Batch [810]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.208072,	
2017-07-12 14:29:36,895 Epoch[2] Batch [820]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.207954,	
2017-07-12 14:29:42,012 Epoch[2] Batch [830]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.207742,	
2017-07-12 14:29:47,075 Epoch[2] Batch [840]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.207484,	
2017-07-12 14:29:52,194 Epoch[2] Batch [850]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.207411,	
2017-07-12 14:29:57,256 Epoch[2] Batch [860]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.207440,	
2017-07-12 14:30:02,431 Epoch[2] Batch [870]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.207488,	
2017-07-12 14:30:07,251 Epoch[2] Batch [880]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.207456,	
2017-07-12 14:30:12,222 Epoch[2] Batch [890]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.207571,	
2017-07-12 14:30:17,110 Epoch[2] Batch [900]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.207253,	
2017-07-12 14:30:21,731 Epoch[2] Batch [910]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.207016,	
2017-07-12 14:30:26,724 Epoch[2] Batch [920]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.207066,	
2017-07-12 14:30:31,799 Epoch[2] Batch [930]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.207226,	
2017-07-12 14:30:36,736 Epoch[2] Batch [940]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.206968,	
2017-07-12 14:30:41,769 Epoch[2] Batch [950]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.206945,	
2017-07-12 14:30:46,875 Epoch[2] Batch [960]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.206811,	
2017-07-12 14:30:52,228 Epoch[2] Batch [970]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.206817,	
2017-07-12 14:30:57,094 Epoch[2] Batch [980]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.206497,	
2017-07-12 14:31:02,464 Epoch[2] Batch [990]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.206341,	
2017-07-12 14:31:07,259 Epoch[2] Batch [1000]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.206169,	
2017-07-12 14:31:12,417 Epoch[2] Batch [1010]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.206229,	
2017-07-12 14:31:17,771 Epoch[2] Batch [1020]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.206158,	
2017-07-12 14:31:22,886 Epoch[2] Batch [1030]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.206330,	
2017-07-12 14:31:28,183 Epoch[2] Batch [1040]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.206632,	
2017-07-12 14:31:32,982 Epoch[2] Batch [1050]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.206784,	
2017-07-12 14:31:38,090 Epoch[2] Batch [1060]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.206804,	
2017-07-12 14:31:43,043 Epoch[2] Batch [1070]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.206667,	
2017-07-12 14:31:47,978 Epoch[2] Batch [1080]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.206705,	
2017-07-12 14:31:53,103 Epoch[2] Batch [1090]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.206520,	
2017-07-12 14:31:58,073 Epoch[2] Batch [1100]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.206439,	
2017-07-12 14:32:02,959 Epoch[2] Batch [1110]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.206538,	
2017-07-12 14:32:08,099 Epoch[2] Batch [1120]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.206358,	
2017-07-12 14:32:13,237 Epoch[2] Batch [1130]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.206293,	
2017-07-12 14:32:18,854 Epoch[2] Batch [1140]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.206110,	
2017-07-12 14:32:24,278 Epoch[2] Batch [1150]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.205945,	
2017-07-12 14:32:29,323 Epoch[2] Batch [1160]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.206808,	
2017-07-12 14:32:34,437 Epoch[2] Batch [1170]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.207332,	
2017-07-12 14:32:39,727 Epoch[2] Batch [1180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.207784,	
2017-07-12 14:32:44,728 Epoch[2] Batch [1190]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.207787,	
2017-07-12 14:32:49,859 Epoch[2] Batch [1200]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.207693,	
2017-07-12 14:32:55,027 Epoch[2] Batch [1210]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.207716,	
2017-07-12 14:33:00,397 Epoch[2] Batch [1220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.207911,	
2017-07-12 14:33:05,423 Epoch[2] Batch [1230]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.207667,	
2017-07-12 14:33:10,725 Epoch[2] Batch [1240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.207405,	
2017-07-12 14:33:15,914 Epoch[2] Batch [1250]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.207269,	
2017-07-12 14:33:21,172 Epoch[2] Batch [1260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.206985,	
2017-07-12 14:33:26,559 Epoch[2] Batch [1270]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.206729,	
2017-07-12 14:33:31,571 Epoch[2] Batch [1280]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.206829,	
2017-07-12 14:33:36,577 Epoch[2] Batch [1290]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.206600,	
2017-07-12 14:33:41,402 Epoch[2] Batch [1300]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.206349,	
2017-07-12 14:33:46,866 Epoch[2] Batch [1310]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.206314,	
2017-07-12 14:33:52,025 Epoch[2] Batch [1320]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.206134,	
2017-07-12 14:33:57,084 Epoch[2] Batch [1330]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.206056,	
2017-07-12 14:34:01,868 Epoch[2] Batch [1340]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.206100,	
2017-07-12 14:34:06,505 Epoch[2] Batch [1350]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.206150,	
2017-07-12 14:34:11,772 Epoch[2] Batch [1360]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.206357,	
2017-07-12 14:34:17,095 Epoch[2] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.206697,	
2017-07-12 14:34:22,118 Epoch[2] Batch [1380]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.206580,	
2017-07-12 14:34:27,179 Epoch[2] Batch [1390]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.206431,	
2017-07-12 14:34:32,296 Epoch[2] Batch [1400]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.206221,	
2017-07-12 14:34:37,045 Epoch[2] Batch [1410]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.206368,	
2017-07-12 14:34:42,159 Epoch[2] Batch [1420]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.206569,	
2017-07-12 14:34:47,312 Epoch[2] Batch [1430]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.206840,	
2017-07-12 14:34:52,961 Epoch[2] Batch [1440]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.206639,	
2017-07-12 14:34:58,028 Epoch[2] Batch [1450]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.206899,	
2017-07-12 14:35:02,842 Epoch[2] Batch [1460]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.206767,	
2017-07-12 14:35:07,770 Epoch[2] Batch [1470]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.206965,	
2017-07-12 14:35:12,334 Epoch[2] Batch [1480]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.206785,	
2017-07-12 14:35:15,408 Epoch[2] Train-FCNLogLoss=0.206902
2017-07-12 14:35:15,408 Epoch[2] Time cost=758.779
2017-07-12 14:35:16,343 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0003.params"
2017-07-12 14:35:18,544 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0003.states"
2017-07-12 14:35:24,752 Epoch[3] Batch [10]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.194100,	
2017-07-12 14:35:29,924 Epoch[3] Batch [20]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.192592,	
2017-07-12 14:35:35,079 Epoch[3] Batch [30]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.184778,	
2017-07-12 14:35:39,923 Epoch[3] Batch [40]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.183585,	
2017-07-12 14:35:45,073 Epoch[3] Batch [50]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.190519,	
2017-07-12 14:35:50,143 Epoch[3] Batch [60]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.186286,	
2017-07-12 14:35:55,457 Epoch[3] Batch [70]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.185416,	
2017-07-12 14:36:00,564 Epoch[3] Batch [80]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.181842,	
2017-07-12 14:36:05,907 Epoch[3] Batch [90]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.180008,	
2017-07-12 14:36:11,208 Epoch[3] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.178504,	
2017-07-12 14:36:16,453 Epoch[3] Batch [110]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.177230,	
2017-07-12 14:36:21,431 Epoch[3] Batch [120]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.175855,	
2017-07-12 14:36:26,384 Epoch[3] Batch [130]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.176554,	
2017-07-12 14:36:31,784 Epoch[3] Batch [140]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.177067,	
2017-07-12 14:36:37,832 Epoch[3] Batch [150]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.178314,	
2017-07-12 14:36:43,059 Epoch[3] Batch [160]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.178304,	
2017-07-12 14:36:48,142 Epoch[3] Batch [170]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.178961,	
2017-07-12 14:36:53,489 Epoch[3] Batch [180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.181108,	
2017-07-12 14:36:58,607 Epoch[3] Batch [190]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.181396,	
2017-07-12 14:37:03,727 Epoch[3] Batch [200]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.182621,	
2017-07-12 14:37:08,525 Epoch[3] Batch [210]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.185266,	
2017-07-12 14:37:13,791 Epoch[3] Batch [220]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.186038,	
2017-07-12 14:37:19,218 Epoch[3] Batch [230]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.186379,	
2017-07-12 14:37:24,305 Epoch[3] Batch [240]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.186097,	
2017-07-12 14:37:29,419 Epoch[3] Batch [250]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.186345,	
2017-07-12 14:37:34,528 Epoch[3] Batch [260]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.186666,	
2017-07-12 14:37:39,453 Epoch[3] Batch [270]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.186374,	
2017-07-12 14:37:44,680 Epoch[3] Batch [280]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.185956,	
2017-07-12 14:37:49,848 Epoch[3] Batch [290]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.185196,	
2017-07-12 14:37:54,615 Epoch[3] Batch [300]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.185857,	
2017-07-12 14:37:59,737 Epoch[3] Batch [310]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.186400,	
2017-07-12 14:38:04,784 Epoch[3] Batch [320]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.185638,	
2017-07-12 14:38:09,866 Epoch[3] Batch [330]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.185524,	
2017-07-12 14:38:14,897 Epoch[3] Batch [340]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.185339,	
2017-07-12 14:38:20,049 Epoch[3] Batch [350]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.184798,	
2017-07-12 14:38:24,981 Epoch[3] Batch [360]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.184598,	
2017-07-12 14:38:29,842 Epoch[3] Batch [370]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.185339,	
2017-07-12 14:38:34,819 Epoch[3] Batch [380]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.184870,	
2017-07-12 14:38:39,867 Epoch[3] Batch [390]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.184232,	
2017-07-12 14:38:44,704 Epoch[3] Batch [400]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.183822,	
2017-07-12 14:38:49,963 Epoch[3] Batch [410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.184139,	
2017-07-12 14:38:55,218 Epoch[3] Batch [420]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.184074,	
2017-07-12 14:39:00,372 Epoch[3] Batch [430]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.184446,	
2017-07-12 14:39:05,471 Epoch[3] Batch [440]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.183554,	
2017-07-12 14:39:10,499 Epoch[3] Batch [450]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.183528,	
2017-07-12 14:39:15,570 Epoch[3] Batch [460]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.183738,	
2017-07-12 14:39:20,691 Epoch[3] Batch [470]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.184538,	
2017-07-12 14:39:25,739 Epoch[3] Batch [480]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.184490,	
2017-07-12 14:39:30,735 Epoch[3] Batch [490]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.184923,	
2017-07-12 14:39:35,642 Epoch[3] Batch [500]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.184677,	
2017-07-12 14:39:41,030 Epoch[3] Batch [510]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.184467,	
2017-07-12 14:39:46,152 Epoch[3] Batch [520]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.184428,	
2017-07-12 14:39:51,205 Epoch[3] Batch [530]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.183741,	
2017-07-12 14:39:56,356 Epoch[3] Batch [540]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.183690,	
2017-07-12 14:40:01,657 Epoch[3] Batch [550]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.183679,	
2017-07-12 14:40:06,520 Epoch[3] Batch [560]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.183580,	
2017-07-12 14:40:11,748 Epoch[3] Batch [570]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.183243,	
2017-07-12 14:40:17,028 Epoch[3] Batch [580]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.183041,	
2017-07-12 14:40:22,076 Epoch[3] Batch [590]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.182860,	
2017-07-12 14:40:27,437 Epoch[3] Batch [600]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.182508,	
2017-07-12 14:40:32,460 Epoch[3] Batch [610]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.182478,	
2017-07-12 14:40:37,569 Epoch[3] Batch [620]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.182659,	
2017-07-12 14:40:42,847 Epoch[3] Batch [630]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.182827,	
2017-07-12 14:40:48,342 Epoch[3] Batch [640]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.183111,	
2017-07-12 14:40:53,565 Epoch[3] Batch [650]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.183309,	
2017-07-12 14:40:59,195 Epoch[3] Batch [660]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.183274,	
2017-07-12 14:41:04,404 Epoch[3] Batch [670]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.183119,	
2017-07-12 14:41:09,454 Epoch[3] Batch [680]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.182735,	
2017-07-12 14:41:14,487 Epoch[3] Batch [690]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.182580,	
2017-07-12 14:41:19,530 Epoch[3] Batch [700]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.182384,	
2017-07-12 14:41:24,587 Epoch[3] Batch [710]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.182205,	
2017-07-12 14:41:29,645 Epoch[3] Batch [720]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.182129,	
2017-07-12 14:41:34,820 Epoch[3] Batch [730]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.181695,	
2017-07-12 14:41:40,020 Epoch[3] Batch [740]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.181422,	
2017-07-12 14:41:45,315 Epoch[3] Batch [750]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.181456,	
2017-07-12 14:41:50,255 Epoch[3] Batch [760]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.181219,	
2017-07-12 14:41:55,721 Epoch[3] Batch [770]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.181430,	
2017-07-12 14:42:00,734 Epoch[3] Batch [780]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.181645,	
2017-07-12 14:42:05,968 Epoch[3] Batch [790]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.181708,	
2017-07-12 14:42:10,976 Epoch[3] Batch [800]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.181327,	
2017-07-12 14:42:16,370 Epoch[3] Batch [810]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.181273,	
2017-07-12 14:42:21,820 Epoch[3] Batch [820]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.181106,	
2017-07-12 14:42:27,009 Epoch[3] Batch [830]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.181715,	
2017-07-12 14:42:32,228 Epoch[3] Batch [840]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.181709,	
2017-07-12 14:42:37,347 Epoch[3] Batch [850]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.181657,	
2017-07-12 14:42:42,447 Epoch[3] Batch [860]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.181490,	
2017-07-12 14:42:47,388 Epoch[3] Batch [870]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.181460,	
2017-07-12 14:42:53,140 Epoch[3] Batch [880]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.181833,	
2017-07-12 14:42:58,038 Epoch[3] Batch [890]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.181862,	
2017-07-12 14:43:03,129 Epoch[3] Batch [900]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.181750,	
2017-07-12 14:43:08,392 Epoch[3] Batch [910]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.181564,	
2017-07-12 14:43:13,438 Epoch[3] Batch [920]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.181839,	
2017-07-12 14:43:18,416 Epoch[3] Batch [930]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.181965,	
2017-07-12 14:43:23,527 Epoch[3] Batch [940]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.181691,	
2017-07-12 14:43:28,562 Epoch[3] Batch [950]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.181702,	
2017-07-12 14:43:33,492 Epoch[3] Batch [960]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.181749,	
2017-07-12 14:43:38,985 Epoch[3] Batch [970]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.181500,	
2017-07-12 14:43:44,012 Epoch[3] Batch [980]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.181276,	
2017-07-12 14:43:49,678 Epoch[3] Batch [990]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.181251,	
2017-07-12 14:43:54,911 Epoch[3] Batch [1000]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.180985,	
2017-07-12 14:44:00,202 Epoch[3] Batch [1010]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.181153,	
2017-07-12 14:44:05,374 Epoch[3] Batch [1020]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.180845,	
2017-07-12 14:44:10,489 Epoch[3] Batch [1030]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.180692,	
2017-07-12 14:44:15,837 Epoch[3] Batch [1040]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.180496,	
2017-07-12 14:44:21,142 Epoch[3] Batch [1050]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.180448,	
2017-07-12 14:44:26,248 Epoch[3] Batch [1060]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.180493,	
2017-07-12 14:44:31,251 Epoch[3] Batch [1070]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.180424,	
2017-07-12 14:44:36,348 Epoch[3] Batch [1080]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.180220,	
2017-07-12 14:44:41,399 Epoch[3] Batch [1090]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.180233,	
2017-07-12 14:44:46,590 Epoch[3] Batch [1100]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.179969,	
2017-07-12 14:44:51,337 Epoch[3] Batch [1110]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.179650,	
2017-07-12 14:44:56,441 Epoch[3] Batch [1120]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.179401,	
2017-07-12 14:45:01,170 Epoch[3] Batch [1130]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.179499,	
2017-07-12 14:45:05,516 Epoch[3] Batch [1140]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.179531,	
2017-07-12 14:45:09,945 Epoch[3] Batch [1150]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.179661,	
2017-07-12 14:45:15,027 Epoch[3] Batch [1160]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.179455,	
2017-07-12 14:45:19,958 Epoch[3] Batch [1170]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.179122,	
2017-07-12 14:45:25,090 Epoch[3] Batch [1180]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.178977,	
2017-07-12 14:45:30,584 Epoch[3] Batch [1190]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.178787,	
2017-07-12 14:45:35,441 Epoch[3] Batch [1200]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.178571,	
2017-07-12 14:45:40,531 Epoch[3] Batch [1210]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.178457,	
2017-07-12 14:45:45,601 Epoch[3] Batch [1220]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.178410,	
2017-07-12 14:45:50,517 Epoch[3] Batch [1230]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.178418,	
2017-07-12 14:45:55,568 Epoch[3] Batch [1240]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.178145,	
2017-07-12 14:46:00,678 Epoch[3] Batch [1250]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.177984,	
2017-07-12 14:46:05,878 Epoch[3] Batch [1260]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.177972,	
2017-07-12 14:46:10,862 Epoch[3] Batch [1270]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.177933,	
2017-07-12 14:46:16,221 Epoch[3] Batch [1280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.177701,	
2017-07-12 14:46:21,519 Epoch[3] Batch [1290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.177787,	
2017-07-12 14:46:26,612 Epoch[3] Batch [1300]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.177823,	
2017-07-12 14:46:31,833 Epoch[3] Batch [1310]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.177787,	
2017-07-12 14:46:37,006 Epoch[3] Batch [1320]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.177827,	
2017-07-12 14:46:42,010 Epoch[3] Batch [1330]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.177634,	
2017-07-12 14:46:47,197 Epoch[3] Batch [1340]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.177382,	
2017-07-12 14:46:52,067 Epoch[3] Batch [1350]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.177183,	
2017-07-12 14:46:57,028 Epoch[3] Batch [1360]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.177112,	
2017-07-12 14:47:02,259 Epoch[3] Batch [1370]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.176886,	
2017-07-12 14:47:07,598 Epoch[3] Batch [1380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.176989,	
2017-07-12 14:47:12,451 Epoch[3] Batch [1390]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.176920,	
2017-07-12 14:47:17,426 Epoch[3] Batch [1400]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.176805,	
2017-07-12 14:47:22,430 Epoch[3] Batch [1410]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.176743,	
2017-07-12 14:47:27,835 Epoch[3] Batch [1420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.176641,	
2017-07-12 14:47:33,250 Epoch[3] Batch [1430]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.176796,	
2017-07-12 14:47:38,473 Epoch[3] Batch [1440]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.176844,	
2017-07-12 14:47:43,616 Epoch[3] Batch [1450]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.176787,	
2017-07-12 14:47:48,787 Epoch[3] Batch [1460]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.176627,	
2017-07-12 14:47:54,342 Epoch[3] Batch [1470]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.176479,	
2017-07-12 14:47:59,380 Epoch[3] Batch [1480]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.176399,	
2017-07-12 14:48:02,240 Epoch[3] Train-FCNLogLoss=0.176408
2017-07-12 14:48:02,241 Epoch[3] Time cost=763.697
2017-07-12 14:48:03,229 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0004.params"
2017-07-12 14:48:05,515 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0004.states"
2017-07-12 14:48:11,770 Epoch[4] Batch [10]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.171224,	
2017-07-12 14:48:16,824 Epoch[4] Batch [20]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.174816,	
2017-07-12 14:48:21,940 Epoch[4] Batch [30]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.170161,	
2017-07-12 14:48:27,324 Epoch[4] Batch [40]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.174429,	
2017-07-12 14:48:32,366 Epoch[4] Batch [50]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.172580,	
2017-07-12 14:48:37,475 Epoch[4] Batch [60]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.170925,	
2017-07-12 14:48:42,613 Epoch[4] Batch [70]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.171284,	
2017-07-12 14:48:47,507 Epoch[4] Batch [80]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.168092,	
2017-07-12 14:48:52,448 Epoch[4] Batch [90]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.167278,	
2017-07-12 14:48:57,590 Epoch[4] Batch [100]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.167292,	
2017-07-12 14:49:02,361 Epoch[4] Batch [110]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.166905,	
2017-07-12 14:49:07,770 Epoch[4] Batch [120]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.165647,	
2017-07-12 14:49:12,723 Epoch[4] Batch [130]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.165769,	
2017-07-12 14:49:17,902 Epoch[4] Batch [140]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.165617,	
2017-07-12 14:49:23,115 Epoch[4] Batch [150]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.165225,	
2017-07-12 14:49:28,201 Epoch[4] Batch [160]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.164450,	
2017-07-12 14:49:33,155 Epoch[4] Batch [170]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.166355,	
2017-07-12 14:49:38,499 Epoch[4] Batch [180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.165735,	
2017-07-12 14:49:43,521 Epoch[4] Batch [190]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.164216,	
2017-07-12 14:49:49,162 Epoch[4] Batch [200]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.163556,	
2017-07-12 14:49:54,188 Epoch[4] Batch [210]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.163811,	
2017-07-12 14:49:59,638 Epoch[4] Batch [220]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.162950,	
2017-07-12 14:50:04,706 Epoch[4] Batch [230]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.164896,	
2017-07-12 14:50:09,474 Epoch[4] Batch [240]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.165326,	
2017-07-12 14:50:14,603 Epoch[4] Batch [250]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.165158,	
2017-07-12 14:50:19,329 Epoch[4] Batch [260]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.164939,	
2017-07-12 14:50:24,627 Epoch[4] Batch [270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.165148,	
2017-07-12 14:50:29,520 Epoch[4] Batch [280]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.164738,	
2017-07-12 14:50:34,360 Epoch[4] Batch [290]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.164687,	
2017-07-12 14:50:39,646 Epoch[4] Batch [300]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.165219,	
2017-07-12 14:50:44,641 Epoch[4] Batch [310]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.165290,	
2017-07-12 14:50:49,302 Epoch[4] Batch [320]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.165271,	
2017-07-12 14:50:54,297 Epoch[4] Batch [330]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.165447,	
2017-07-12 14:50:59,017 Epoch[4] Batch [340]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.164922,	
2017-07-12 14:51:03,807 Epoch[4] Batch [350]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.165101,	
2017-07-12 14:51:08,863 Epoch[4] Batch [360]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.164790,	
2017-07-12 14:51:14,182 Epoch[4] Batch [370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.164483,	
2017-07-12 14:51:19,394 Epoch[4] Batch [380]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.163759,	
2017-07-12 14:51:24,660 Epoch[4] Batch [390]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.163269,	
2017-07-12 14:51:29,881 Epoch[4] Batch [400]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.163399,	
2017-07-12 14:51:34,996 Epoch[4] Batch [410]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.163123,	
2017-07-12 14:51:39,845 Epoch[4] Batch [420]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.162945,	
2017-07-12 14:51:45,223 Epoch[4] Batch [430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.162302,	
2017-07-12 14:51:50,401 Epoch[4] Batch [440]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.162086,	
2017-07-12 14:51:55,299 Epoch[4] Batch [450]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.162101,	
2017-07-12 14:52:00,286 Epoch[4] Batch [460]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.162027,	
2017-07-12 14:52:05,440 Epoch[4] Batch [470]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.161855,	
2017-07-12 14:52:10,303 Epoch[4] Batch [480]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.162199,	
2017-07-12 14:52:15,126 Epoch[4] Batch [490]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.162125,	
2017-07-12 14:52:19,992 Epoch[4] Batch [500]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.162016,	
2017-07-12 14:52:24,821 Epoch[4] Batch [510]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.162319,	
2017-07-12 14:52:29,903 Epoch[4] Batch [520]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.162252,	
2017-07-12 14:52:34,804 Epoch[4] Batch [530]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.161887,	
2017-07-12 14:52:39,865 Epoch[4] Batch [540]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.161804,	
2017-07-12 14:52:44,869 Epoch[4] Batch [550]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.161804,	
2017-07-12 14:52:49,961 Epoch[4] Batch [560]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.161559,	
2017-07-12 14:52:54,903 Epoch[4] Batch [570]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.162154,	
2017-07-12 14:53:00,144 Epoch[4] Batch [580]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.161999,	
2017-07-12 14:53:05,398 Epoch[4] Batch [590]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.162277,	
2017-07-12 14:53:10,145 Epoch[4] Batch [600]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.161775,	
2017-07-12 14:53:15,418 Epoch[4] Batch [610]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.161694,	
2017-07-12 14:53:20,674 Epoch[4] Batch [620]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.161596,	
2017-07-12 14:53:25,732 Epoch[4] Batch [630]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.161359,	
2017-07-12 14:53:30,809 Epoch[4] Batch [640]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.161120,	
2017-07-12 14:53:35,974 Epoch[4] Batch [650]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.160904,	
2017-07-12 14:53:41,099 Epoch[4] Batch [660]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.160589,	
2017-07-12 14:53:46,137 Epoch[4] Batch [670]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.160563,	
2017-07-12 14:53:51,106 Epoch[4] Batch [680]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.160250,	
2017-07-12 14:53:56,363 Epoch[4] Batch [690]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.160365,	
2017-07-12 14:54:01,325 Epoch[4] Batch [700]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.160876,	
2017-07-12 14:54:06,615 Epoch[4] Batch [710]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.161090,	
2017-07-12 14:54:11,538 Epoch[4] Batch [720]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.161112,	
2017-07-12 14:54:16,432 Epoch[4] Batch [730]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.161122,	
2017-07-12 14:54:21,516 Epoch[4] Batch [740]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.161262,	
2017-07-12 14:54:26,646 Epoch[4] Batch [750]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.161328,	
2017-07-12 14:54:31,674 Epoch[4] Batch [760]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.161271,	
2017-07-12 14:54:36,766 Epoch[4] Batch [770]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.161178,	
2017-07-12 14:54:41,731 Epoch[4] Batch [780]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.161193,	
2017-07-12 14:54:46,810 Epoch[4] Batch [790]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.161483,	
2017-07-12 14:54:51,632 Epoch[4] Batch [800]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.161286,	
2017-07-12 14:54:56,652 Epoch[4] Batch [810]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.161218,	
2017-07-12 14:55:01,808 Epoch[4] Batch [820]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.161345,	
2017-07-12 14:55:07,209 Epoch[4] Batch [830]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.161563,	
2017-07-12 14:55:12,600 Epoch[4] Batch [840]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.162034,	
2017-07-12 14:55:17,752 Epoch[4] Batch [850]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.162402,	
2017-07-12 14:55:22,705 Epoch[4] Batch [860]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.162643,	
2017-07-12 14:55:28,066 Epoch[4] Batch [870]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.162530,	
2017-07-12 14:55:33,302 Epoch[4] Batch [880]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.162548,	
2017-07-12 14:55:38,351 Epoch[4] Batch [890]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.162408,	
2017-07-12 14:55:43,698 Epoch[4] Batch [900]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.162247,	
2017-07-12 14:55:48,842 Epoch[4] Batch [910]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.162267,	
2017-07-12 14:55:54,207 Epoch[4] Batch [920]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.162002,	
2017-07-12 14:55:59,076 Epoch[4] Batch [930]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.162037,	
2017-07-12 14:56:04,204 Epoch[4] Batch [940]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.161855,	
2017-07-12 14:56:09,269 Epoch[4] Batch [950]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.161821,	
2017-07-12 14:56:14,146 Epoch[4] Batch [960]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.161794,	
2017-07-12 14:56:19,226 Epoch[4] Batch [970]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.161559,	
2017-07-12 14:56:24,662 Epoch[4] Batch [980]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.161689,	
2017-07-12 14:56:29,921 Epoch[4] Batch [990]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.161758,	
2017-07-12 14:56:35,260 Epoch[4] Batch [1000]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.161835,	
2017-07-12 14:56:40,201 Epoch[4] Batch [1010]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.161737,	
2017-07-12 14:56:45,512 Epoch[4] Batch [1020]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.161709,	
2017-07-12 14:56:50,719 Epoch[4] Batch [1030]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.161667,	
2017-07-12 14:56:55,642 Epoch[4] Batch [1040]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.161700,	
2017-07-12 14:57:00,531 Epoch[4] Batch [1050]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.161920,	
2017-07-12 14:57:05,552 Epoch[4] Batch [1060]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.161875,	
2017-07-12 14:57:10,502 Epoch[4] Batch [1070]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.161823,	
2017-07-12 14:57:15,779 Epoch[4] Batch [1080]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.161669,	
2017-07-12 14:57:21,205 Epoch[4] Batch [1090]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.161619,	
2017-07-12 14:57:26,285 Epoch[4] Batch [1100]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.161611,	
2017-07-12 14:57:31,398 Epoch[4] Batch [1110]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.161723,	
2017-07-12 14:57:36,503 Epoch[4] Batch [1120]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.161599,	
2017-07-12 14:57:41,834 Epoch[4] Batch [1130]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.161629,	
2017-07-12 14:57:46,768 Epoch[4] Batch [1140]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.161634,	
2017-07-12 14:57:51,765 Epoch[4] Batch [1150]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.161650,	
2017-07-12 14:57:56,954 Epoch[4] Batch [1160]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.161490,	
2017-07-12 14:58:01,983 Epoch[4] Batch [1170]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.161509,	
2017-07-12 14:58:07,197 Epoch[4] Batch [1180]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.161423,	
2017-07-12 14:58:12,852 Epoch[4] Batch [1190]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.161310,	
2017-07-12 14:58:18,385 Epoch[4] Batch [1200]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.161296,	
2017-07-12 14:58:23,860 Epoch[4] Batch [1210]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.161333,	
2017-07-12 14:58:29,104 Epoch[4] Batch [1220]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.161369,	
2017-07-12 14:58:34,452 Epoch[4] Batch [1230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.161375,	
2017-07-12 14:58:39,862 Epoch[4] Batch [1240]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.161260,	
2017-07-12 14:58:45,541 Epoch[4] Batch [1250]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.161155,	
2017-07-12 14:58:50,984 Epoch[4] Batch [1260]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.161076,	
2017-07-12 14:58:56,420 Epoch[4] Batch [1270]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.161004,	
2017-07-12 14:59:01,639 Epoch[4] Batch [1280]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.161244,	
2017-07-12 14:59:07,032 Epoch[4] Batch [1290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.161339,	
2017-07-12 14:59:12,257 Epoch[4] Batch [1300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.161303,	
2017-07-12 14:59:17,949 Epoch[4] Batch [1310]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.161401,	
2017-07-12 14:59:23,335 Epoch[4] Batch [1320]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.161561,	
2017-07-12 14:59:28,620 Epoch[4] Batch [1330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.161598,	
2017-07-12 14:59:33,876 Epoch[4] Batch [1340]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.161407,	
2017-07-12 14:59:39,124 Epoch[4] Batch [1350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.161617,	
2017-07-12 14:59:44,547 Epoch[4] Batch [1360]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.161524,	
2017-07-12 14:59:49,514 Epoch[4] Batch [1370]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.161347,	
2017-07-12 14:59:54,531 Epoch[4] Batch [1380]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.161319,	
2017-07-12 14:59:59,452 Epoch[4] Batch [1390]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.161178,	
2017-07-12 15:00:04,787 Epoch[4] Batch [1400]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.161089,	
2017-07-12 15:00:09,667 Epoch[4] Batch [1410]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.160860,	
2017-07-12 15:00:15,127 Epoch[4] Batch [1420]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.160687,	
2017-07-12 15:00:20,309 Epoch[4] Batch [1430]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.160602,	
2017-07-12 15:00:25,711 Epoch[4] Batch [1440]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.160539,	
2017-07-12 15:00:30,901 Epoch[4] Batch [1450]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.160411,	
2017-07-12 15:00:36,204 Epoch[4] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.160370,	
2017-07-12 15:00:41,908 Epoch[4] Batch [1470]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.160327,	
2017-07-12 15:00:47,176 Epoch[4] Batch [1480]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.160237,	
2017-07-12 15:00:50,216 Epoch[4] Train-FCNLogLoss=0.160245
2017-07-12 15:00:50,216 Epoch[4] Time cost=764.700
2017-07-12 15:00:51,100 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0005.params"
2017-07-12 15:00:53,412 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0005.states"
2017-07-12 15:00:59,186 Epoch[5] Batch [10]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.176461,	
2017-07-12 15:01:04,413 Epoch[5] Batch [20]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.174468,	
2017-07-12 15:01:09,911 Epoch[5] Batch [30]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.167724,	
2017-07-12 15:01:15,061 Epoch[5] Batch [40]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.167679,	
2017-07-12 15:01:20,434 Epoch[5] Batch [50]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.169701,	
2017-07-12 15:01:25,840 Epoch[5] Batch [60]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.166926,	
2017-07-12 15:01:30,964 Epoch[5] Batch [70]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.162393,	
2017-07-12 15:01:36,523 Epoch[5] Batch [80]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.161201,	
2017-07-12 15:01:41,893 Epoch[5] Batch [90]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.161082,	
2017-07-12 15:01:47,282 Epoch[5] Batch [100]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.159819,	
2017-07-12 15:01:52,178 Epoch[5] Batch [110]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.158748,	
2017-07-12 15:01:57,229 Epoch[5] Batch [120]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.156240,	
2017-07-12 15:02:02,418 Epoch[5] Batch [130]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.155461,	
2017-07-12 15:02:07,420 Epoch[5] Batch [140]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.153901,	
2017-07-12 15:02:12,261 Epoch[5] Batch [150]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.153056,	
2017-07-12 15:02:17,364 Epoch[5] Batch [160]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.151591,	
2017-07-12 15:02:22,500 Epoch[5] Batch [170]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.154621,	
2017-07-12 15:02:27,727 Epoch[5] Batch [180]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.153537,	
2017-07-12 15:02:32,820 Epoch[5] Batch [190]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.154597,	
2017-07-12 15:02:38,019 Epoch[5] Batch [200]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.154642,	
2017-07-12 15:02:43,112 Epoch[5] Batch [210]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.154117,	
2017-07-12 15:02:48,481 Epoch[5] Batch [220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.153296,	
2017-07-12 15:02:53,783 Epoch[5] Batch [230]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.154020,	
2017-07-12 15:02:59,179 Epoch[5] Batch [240]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.155401,	
2017-07-12 15:03:04,558 Epoch[5] Batch [250]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.155302,	
2017-07-12 15:03:09,846 Epoch[5] Batch [260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.155182,	
2017-07-12 15:03:15,076 Epoch[5] Batch [270]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.155154,	
2017-07-12 15:03:20,251 Epoch[5] Batch [280]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.155483,	
2017-07-12 15:03:25,494 Epoch[5] Batch [290]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.155879,	
2017-07-12 15:03:30,900 Epoch[5] Batch [300]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.155420,	
2017-07-12 15:03:35,924 Epoch[5] Batch [310]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.155617,	
2017-07-12 15:03:40,769 Epoch[5] Batch [320]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.155352,	
2017-07-12 15:03:45,985 Epoch[5] Batch [330]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.154905,	
2017-07-12 15:03:51,325 Epoch[5] Batch [340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.155194,	
2017-07-12 15:03:56,313 Epoch[5] Batch [350]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.154979,	
2017-07-12 15:04:01,514 Epoch[5] Batch [360]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.155486,	
2017-07-12 15:04:06,935 Epoch[5] Batch [370]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.155251,	
2017-07-12 15:04:12,482 Epoch[5] Batch [380]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.155347,	
2017-07-12 15:04:17,814 Epoch[5] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.155980,	
2017-07-12 15:04:22,637 Epoch[5] Batch [400]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.156121,	
2017-07-12 15:04:28,367 Epoch[5] Batch [410]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.155800,	
2017-07-12 15:04:33,704 Epoch[5] Batch [420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.155779,	
2017-07-12 15:04:39,118 Epoch[5] Batch [430]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.156236,	
2017-07-12 15:04:44,425 Epoch[5] Batch [440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.156710,	
2017-07-12 15:04:49,709 Epoch[5] Batch [450]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.156548,	
2017-07-12 15:04:54,971 Epoch[5] Batch [460]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.156840,	
2017-07-12 15:05:00,611 Epoch[5] Batch [470]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.157165,	
2017-07-12 15:05:05,974 Epoch[5] Batch [480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.157139,	
2017-07-12 15:05:11,477 Epoch[5] Batch [490]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.156805,	
2017-07-12 15:05:16,486 Epoch[5] Batch [500]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.156443,	
2017-07-12 15:05:21,484 Epoch[5] Batch [510]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.156456,	
2017-07-12 15:05:26,446 Epoch[5] Batch [520]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.156356,	
2017-07-12 15:05:31,006 Epoch[5] Batch [530]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.155992,	
2017-07-12 15:05:35,682 Epoch[5] Batch [540]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.155868,	
2017-07-12 15:05:41,031 Epoch[5] Batch [550]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.155956,	
2017-07-12 15:05:46,745 Epoch[5] Batch [560]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.155453,	
2017-07-12 15:05:51,970 Epoch[5] Batch [570]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.155203,	
2017-07-12 15:05:57,102 Epoch[5] Batch [580]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.155019,	
2017-07-12 15:06:02,340 Epoch[5] Batch [590]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.154986,	
2017-07-12 15:06:07,550 Epoch[5] Batch [600]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.155038,	
2017-07-12 15:06:13,251 Epoch[5] Batch [610]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.155075,	
2017-07-12 15:06:18,887 Epoch[5] Batch [620]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.154847,	
2017-07-12 15:06:24,477 Epoch[5] Batch [630]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.154647,	
2017-07-12 15:06:29,518 Epoch[5] Batch [640]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.154446,	
2017-07-12 15:06:34,911 Epoch[5] Batch [650]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.154113,	
2017-07-12 15:06:40,164 Epoch[5] Batch [660]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.153847,	
2017-07-12 15:06:45,912 Epoch[5] Batch [670]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.153965,	
2017-07-12 15:06:50,898 Epoch[5] Batch [680]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.153947,	
2017-07-12 15:06:56,901 Epoch[5] Batch [690]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.153937,	
2017-07-12 15:07:02,361 Epoch[5] Batch [700]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.153852,	
2017-07-12 15:07:08,026 Epoch[5] Batch [710]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.153690,	
2017-07-12 15:07:12,890 Epoch[5] Batch [720]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.153500,	
2017-07-12 15:07:18,155 Epoch[5] Batch [730]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.153304,	
2017-07-12 15:07:23,109 Epoch[5] Batch [740]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.153447,	
2017-07-12 15:07:28,357 Epoch[5] Batch [750]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.153542,	
2017-07-12 15:07:33,316 Epoch[5] Batch [760]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.153473,	
2017-07-12 15:07:38,758 Epoch[5] Batch [770]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.153585,	
2017-07-12 15:07:43,827 Epoch[5] Batch [780]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.153312,	
2017-07-12 15:07:48,873 Epoch[5] Batch [790]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.153565,	
2017-07-12 15:07:54,093 Epoch[5] Batch [800]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.153671,	
2017-07-12 15:07:59,556 Epoch[5] Batch [810]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.153543,	
2017-07-12 15:08:04,992 Epoch[5] Batch [820]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.153493,	
2017-07-12 15:08:10,257 Epoch[5] Batch [830]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.153559,	
2017-07-12 15:08:15,778 Epoch[5] Batch [840]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.153644,	
2017-07-12 15:08:20,788 Epoch[5] Batch [850]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.153697,	
2017-07-12 15:08:25,763 Epoch[5] Batch [860]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.153483,	
2017-07-12 15:08:30,930 Epoch[5] Batch [870]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.153459,	
2017-07-12 15:08:36,078 Epoch[5] Batch [880]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.153249,	
2017-07-12 15:08:41,091 Epoch[5] Batch [890]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.153031,	
2017-07-12 15:08:46,232 Epoch[5] Batch [900]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.152904,	
2017-07-12 15:08:51,632 Epoch[5] Batch [910]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.152920,	
2017-07-12 15:08:56,766 Epoch[5] Batch [920]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.153287,	
2017-07-12 15:09:01,773 Epoch[5] Batch [930]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.153245,	
2017-07-12 15:09:06,751 Epoch[5] Batch [940]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.153236,	
2017-07-12 15:09:22,729 Epoch[5] Batch [950]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.153456,	
2017-07-12 15:09:38,545 Epoch[5] Batch [960]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.153698,	
2017-07-12 15:09:56,381 Epoch[5] Batch [970]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.153878,	
2017-07-12 15:10:14,295 Epoch[5] Batch [980]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.154122,	
2017-07-12 15:10:31,177 Epoch[5] Batch [990]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.154239,	
2017-07-12 15:10:47,736 Epoch[5] Batch [1000]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.154128,	
2017-07-12 15:10:53,953 Epoch[5] Batch [1010]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.154054,	
2017-07-12 15:10:59,017 Epoch[5] Batch [1020]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.154052,	
2017-07-12 15:11:04,695 Epoch[5] Batch [1030]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.153942,	
2017-07-12 15:11:10,112 Epoch[5] Batch [1040]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.153841,	
2017-07-12 15:11:15,396 Epoch[5] Batch [1050]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.153989,	
2017-07-12 15:11:20,643 Epoch[5] Batch [1060]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.153754,	
2017-07-12 15:11:25,789 Epoch[5] Batch [1070]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.153553,	
2017-07-12 15:11:31,149 Epoch[5] Batch [1080]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.153510,	
2017-07-12 15:11:36,650 Epoch[5] Batch [1090]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.153402,	
2017-07-12 15:11:41,964 Epoch[5] Batch [1100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.153305,	
2017-07-12 15:11:47,120 Epoch[5] Batch [1110]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.153272,	
2017-07-12 15:11:52,213 Epoch[5] Batch [1120]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.153233,	
2017-07-12 15:11:57,576 Epoch[5] Batch [1130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.153277,	
2017-07-12 15:12:03,179 Epoch[5] Batch [1140]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.153225,	
2017-07-12 15:12:08,703 Epoch[5] Batch [1150]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.152940,	
2017-07-12 15:12:13,822 Epoch[5] Batch [1160]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.153021,	
2017-07-12 15:12:19,093 Epoch[5] Batch [1170]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.153068,	
2017-07-12 15:12:24,170 Epoch[5] Batch [1180]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.152956,	
2017-07-12 15:12:29,509 Epoch[5] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.152896,	
2017-07-12 15:12:34,887 Epoch[5] Batch [1200]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.152740,	
2017-07-12 15:12:40,208 Epoch[5] Batch [1210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.152628,	
2017-07-12 15:12:45,932 Epoch[5] Batch [1220]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.152543,	
2017-07-12 15:12:50,894 Epoch[5] Batch [1230]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.152672,	
2017-07-12 15:12:56,361 Epoch[5] Batch [1240]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.152648,	
2017-07-12 15:13:01,563 Epoch[5] Batch [1250]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.152476,	
2017-07-12 15:13:06,666 Epoch[5] Batch [1260]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.152422,	
2017-07-12 15:13:12,242 Epoch[5] Batch [1270]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.152353,	
2017-07-12 15:13:17,779 Epoch[5] Batch [1280]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.152219,	
2017-07-12 15:13:22,988 Epoch[5] Batch [1290]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.152234,	
2017-07-12 15:13:28,506 Epoch[5] Batch [1300]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.152147,	
2017-07-12 15:13:33,461 Epoch[5] Batch [1310]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.152401,	
2017-07-12 15:13:38,489 Epoch[5] Batch [1320]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.152440,	
2017-07-12 15:13:43,514 Epoch[5] Batch [1330]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.152403,	
2017-07-12 15:13:48,553 Epoch[5] Batch [1340]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.152823,	
2017-07-12 15:13:53,589 Epoch[5] Batch [1350]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.152893,	
2017-07-12 15:13:58,350 Epoch[5] Batch [1360]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.152924,	
2017-07-12 15:14:03,637 Epoch[5] Batch [1370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.153007,	
2017-07-12 15:14:09,018 Epoch[5] Batch [1380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.153203,	
2017-07-12 15:14:14,129 Epoch[5] Batch [1390]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.153243,	
2017-07-12 15:14:19,135 Epoch[5] Batch [1400]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.153222,	
2017-07-12 15:14:24,218 Epoch[5] Batch [1410]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.153299,	
2017-07-12 15:14:29,419 Epoch[5] Batch [1420]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.153255,	
2017-07-12 15:14:34,665 Epoch[5] Batch [1430]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.153152,	
2017-07-12 15:14:39,764 Epoch[5] Batch [1440]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.153207,	
2017-07-12 15:14:45,138 Epoch[5] Batch [1450]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.153038,	
2017-07-12 15:14:50,092 Epoch[5] Batch [1460]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.153134,	
2017-07-12 15:14:55,151 Epoch[5] Batch [1470]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.153020,	
2017-07-12 15:15:00,272 Epoch[5] Batch [1480]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.152880,	
2017-07-12 15:15:03,196 Epoch[5] Train-FCNLogLoss=0.152788
2017-07-12 15:15:03,197 Epoch[5] Time cost=849.785
2017-07-12 15:15:04,104 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0006.params"
2017-07-12 15:15:06,433 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0006.states"
2017-07-12 15:15:12,143 Epoch[6] Batch [10]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.136210,	
2017-07-12 15:15:17,152 Epoch[6] Batch [20]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.143996,	
2017-07-12 15:15:22,387 Epoch[6] Batch [30]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.144542,	
2017-07-12 15:15:27,529 Epoch[6] Batch [40]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.143806,	
2017-07-12 15:15:32,369 Epoch[6] Batch [50]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.143956,	
2017-07-12 15:15:37,474 Epoch[6] Batch [60]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.144139,	
2017-07-12 15:15:42,835 Epoch[6] Batch [70]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.145552,	
2017-07-12 15:15:47,856 Epoch[6] Batch [80]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.144047,	
2017-07-12 15:15:52,983 Epoch[6] Batch [90]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.144126,	
2017-07-12 15:15:58,211 Epoch[6] Batch [100]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.142669,	
2017-07-12 15:16:03,583 Epoch[6] Batch [110]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.143550,	
2017-07-12 15:16:08,524 Epoch[6] Batch [120]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.144930,	
2017-07-12 15:16:13,567 Epoch[6] Batch [130]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.144383,	
2017-07-12 15:16:18,425 Epoch[6] Batch [140]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.143856,	
2017-07-12 15:16:23,467 Epoch[6] Batch [150]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.143569,	
2017-07-12 15:16:28,379 Epoch[6] Batch [160]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.143612,	
2017-07-12 15:16:33,399 Epoch[6] Batch [170]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.142673,	
2017-07-12 15:16:38,445 Epoch[6] Batch [180]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.142657,	
2017-07-12 15:16:43,360 Epoch[6] Batch [190]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.142330,	
2017-07-12 15:16:48,561 Epoch[6] Batch [200]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.143337,	
2017-07-12 15:16:53,614 Epoch[6] Batch [210]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.143746,	
2017-07-12 15:16:58,502 Epoch[6] Batch [220]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.143146,	
2017-07-12 15:17:03,529 Epoch[6] Batch [230]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.143217,	
2017-07-12 15:17:08,472 Epoch[6] Batch [240]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.143089,	
2017-07-12 15:17:13,883 Epoch[6] Batch [250]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.143089,	
2017-07-12 15:17:19,066 Epoch[6] Batch [260]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.142573,	
2017-07-12 15:17:24,510 Epoch[6] Batch [270]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.142667,	
2017-07-12 15:17:30,003 Epoch[6] Batch [280]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.142806,	
2017-07-12 15:17:35,361 Epoch[6] Batch [290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.143229,	
2017-07-12 15:17:41,450 Epoch[6] Batch [300]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.143306,	
2017-07-12 15:17:47,005 Epoch[6] Batch [310]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.143971,	
2017-07-12 15:17:52,325 Epoch[6] Batch [320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.143584,	
2017-07-12 15:17:57,898 Epoch[6] Batch [330]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.144263,	
2017-07-12 15:18:03,541 Epoch[6] Batch [340]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.144220,	
2017-07-12 15:18:08,868 Epoch[6] Batch [350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.144380,	
2017-07-12 15:18:14,348 Epoch[6] Batch [360]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.144376,	
2017-07-12 15:18:19,684 Epoch[6] Batch [370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.144397,	
2017-07-12 15:18:25,883 Epoch[6] Batch [380]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.144897,	
2017-07-12 15:18:31,610 Epoch[6] Batch [390]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.145256,	
2017-07-12 15:18:37,011 Epoch[6] Batch [400]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.145086,	
2017-07-12 15:18:42,497 Epoch[6] Batch [410]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.145150,	
2017-07-12 15:18:47,741 Epoch[6] Batch [420]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.144856,	
2017-07-12 15:18:53,144 Epoch[6] Batch [430]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.144237,	
2017-07-12 15:18:58,649 Epoch[6] Batch [440]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.144270,	
2017-07-12 15:19:04,409 Epoch[6] Batch [450]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.144625,	
2017-07-12 15:19:09,950 Epoch[6] Batch [460]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.144986,	
2017-07-12 15:19:15,328 Epoch[6] Batch [470]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.145169,	
2017-07-12 15:19:21,031 Epoch[6] Batch [480]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.144864,	
2017-07-12 15:19:26,392 Epoch[6] Batch [490]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.144611,	
2017-07-12 15:19:32,067 Epoch[6] Batch [500]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.144635,	
2017-07-12 15:19:37,869 Epoch[6] Batch [510]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.144567,	
2017-07-12 15:19:43,476 Epoch[6] Batch [520]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.143978,	
2017-07-12 15:19:48,562 Epoch[6] Batch [530]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.143764,	
2017-07-12 15:19:53,744 Epoch[6] Batch [540]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.143906,	
2017-07-12 15:19:58,552 Epoch[6] Batch [550]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.144816,	
2017-07-12 15:20:03,584 Epoch[6] Batch [560]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.144892,	
2017-07-12 15:20:08,692 Epoch[6] Batch [570]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.145028,	
2017-07-12 15:20:13,841 Epoch[6] Batch [580]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.145070,	
2017-07-12 15:20:19,340 Epoch[6] Batch [590]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.144946,	
2017-07-12 15:20:24,407 Epoch[6] Batch [600]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.144933,	
2017-07-12 15:20:29,372 Epoch[6] Batch [610]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.144920,	
2017-07-12 15:20:34,653 Epoch[6] Batch [620]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.145040,	
2017-07-12 15:20:39,935 Epoch[6] Batch [630]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.145008,	
2017-07-12 15:20:45,377 Epoch[6] Batch [640]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.145108,	
2017-07-12 15:20:50,637 Epoch[6] Batch [650]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.144965,	
2017-07-12 15:20:55,727 Epoch[6] Batch [660]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.144972,	
2017-07-12 15:21:01,129 Epoch[6] Batch [670]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.145305,	
2017-07-12 15:21:06,810 Epoch[6] Batch [680]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.145199,	
2017-07-12 15:21:12,320 Epoch[6] Batch [690]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.145267,	
2017-07-12 15:21:17,387 Epoch[6] Batch [700]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.145129,	
2017-07-12 15:21:22,869 Epoch[6] Batch [710]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.145034,	
2017-07-12 15:21:28,878 Epoch[6] Batch [720]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.145048,	
2017-07-12 15:21:34,310 Epoch[6] Batch [730]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.144940,	
2017-07-12 15:21:39,365 Epoch[6] Batch [740]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.144976,	
2017-07-12 15:21:44,410 Epoch[6] Batch [750]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.144974,	
2017-07-12 15:21:50,174 Epoch[6] Batch [760]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.144887,	
2017-07-12 15:21:55,867 Epoch[6] Batch [770]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.144748,	
2017-07-12 15:22:01,540 Epoch[6] Batch [780]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.144555,	
2017-07-12 15:22:07,232 Epoch[6] Batch [790]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.144646,	
2017-07-12 15:22:12,611 Epoch[6] Batch [800]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.144596,	
2017-07-12 15:22:17,691 Epoch[6] Batch [810]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.144474,	
2017-07-12 15:22:23,256 Epoch[6] Batch [820]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.144483,	
2017-07-12 15:22:28,281 Epoch[6] Batch [830]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.144418,	
2017-07-12 15:22:33,603 Epoch[6] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.144146,	
2017-07-12 15:22:39,104 Epoch[6] Batch [850]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.143990,	
2017-07-12 15:22:44,801 Epoch[6] Batch [860]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.143820,	
2017-07-12 15:22:50,214 Epoch[6] Batch [870]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.143765,	
2017-07-12 15:22:55,517 Epoch[6] Batch [880]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.143539,	
2017-07-12 15:23:00,404 Epoch[6] Batch [890]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.143602,	
2017-07-12 15:23:05,760 Epoch[6] Batch [900]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.143604,	
2017-07-12 15:23:12,588 Epoch[6] Batch [910]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.143490,	
2017-07-12 15:23:24,618 Epoch[6] Batch [920]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.143538,	
2017-07-12 15:23:35,315 Epoch[6] Batch [930]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.143468,	
2017-07-12 15:23:46,837 Epoch[6] Batch [940]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.143489,	
2017-07-12 15:23:56,938 Epoch[6] Batch [950]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.143434,	
2017-07-12 15:24:05,801 Epoch[6] Batch [960]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.143555,	
2017-07-12 15:24:14,781 Epoch[6] Batch [970]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.143424,	
2017-07-12 15:24:24,068 Epoch[6] Batch [980]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.143290,	
2017-07-12 15:24:34,143 Epoch[6] Batch [990]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.143269,	
2017-07-12 15:24:42,879 Epoch[6] Batch [1000]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.143448,	
2017-07-12 15:24:51,973 Epoch[6] Batch [1010]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.143399,	
2017-07-12 15:25:01,383 Epoch[6] Batch [1020]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.143222,	
2017-07-12 15:25:10,815 Epoch[6] Batch [1030]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.143053,	
2017-07-12 15:25:20,275 Epoch[6] Batch [1040]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.143078,	
2017-07-12 15:25:29,681 Epoch[6] Batch [1050]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.143026,	
2017-07-12 15:25:39,809 Epoch[6] Batch [1060]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.142951,	
2017-07-12 15:25:48,873 Epoch[6] Batch [1070]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.142700,	
2017-07-12 15:25:57,105 Epoch[6] Batch [1080]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.142670,	
2017-07-12 15:26:04,113 Epoch[6] Batch [1090]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.142682,	
2017-07-12 15:26:10,909 Epoch[6] Batch [1100]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.142736,	
2017-07-12 15:26:16,640 Epoch[6] Batch [1110]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.142711,	
2017-07-12 15:26:22,392 Epoch[6] Batch [1120]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.142889,	
2017-07-12 15:26:28,019 Epoch[6] Batch [1130]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.143055,	
2017-07-12 15:26:33,581 Epoch[6] Batch [1140]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.142965,	
2017-07-12 15:26:39,212 Epoch[6] Batch [1150]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.142934,	
2017-07-12 15:26:44,435 Epoch[6] Batch [1160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142800,	
2017-07-12 15:26:49,722 Epoch[6] Batch [1170]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.142879,	
2017-07-12 15:26:54,907 Epoch[6] Batch [1180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.142773,	
2017-07-12 15:27:00,129 Epoch[6] Batch [1190]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.142677,	
2017-07-12 15:27:05,573 Epoch[6] Batch [1200]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.142585,	
2017-07-12 15:27:11,011 Epoch[6] Batch [1210]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.142772,	
2017-07-12 15:27:16,135 Epoch[6] Batch [1220]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.142795,	
2017-07-12 15:27:21,677 Epoch[6] Batch [1230]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.142716,	
2017-07-12 15:27:26,749 Epoch[6] Batch [1240]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.142660,	
2017-07-12 15:27:32,077 Epoch[6] Batch [1250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.142611,	
2017-07-12 15:27:37,087 Epoch[6] Batch [1260]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.142600,	
2017-07-12 15:27:42,290 Epoch[6] Batch [1270]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.142559,	
2017-07-12 15:27:47,475 Epoch[6] Batch [1280]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.142573,	
2017-07-12 15:27:52,468 Epoch[6] Batch [1290]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.142543,	
2017-07-12 15:27:57,509 Epoch[6] Batch [1300]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.142560,	
2017-07-12 15:28:02,602 Epoch[6] Batch [1310]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.142422,	
2017-07-12 15:28:07,555 Epoch[6] Batch [1320]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.142656,	
2017-07-12 15:28:12,656 Epoch[6] Batch [1330]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.142637,	
2017-07-12 15:28:17,875 Epoch[6] Batch [1340]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.142717,	
2017-07-12 15:28:23,131 Epoch[6] Batch [1350]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.142796,	
2017-07-12 15:28:28,443 Epoch[6] Batch [1360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.142750,	
2017-07-12 15:28:33,694 Epoch[6] Batch [1370]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.142737,	
2017-07-12 15:28:39,080 Epoch[6] Batch [1380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.142635,	
2017-07-12 15:28:44,053 Epoch[6] Batch [1390]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.142767,	
2017-07-12 15:28:49,603 Epoch[6] Batch [1400]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.143072,	
2017-07-12 15:28:54,967 Epoch[6] Batch [1410]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.142991,	
2017-07-12 15:29:00,093 Epoch[6] Batch [1420]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.142904,	
2017-07-12 15:29:05,847 Epoch[6] Batch [1430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.143081,	
2017-07-12 15:29:11,188 Epoch[6] Batch [1440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.143004,	
2017-07-12 15:29:16,429 Epoch[6] Batch [1450]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.142953,	
2017-07-12 15:29:21,826 Epoch[6] Batch [1460]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.142943,	
2017-07-12 15:29:27,001 Epoch[6] Batch [1470]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.142973,	
2017-07-12 15:29:32,199 Epoch[6] Batch [1480]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.142887,	
2017-07-12 15:29:35,754 Epoch[6] Train-FCNLogLoss=0.142905
2017-07-12 15:29:35,754 Epoch[6] Time cost=869.321
2017-07-12 15:29:36,668 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0007.params"
2017-07-12 15:29:39,373 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0007.states"
2017-07-12 15:29:45,581 Epoch[7] Batch [10]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.141721,	
2017-07-12 15:29:50,981 Epoch[7] Batch [20]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.137387,	
2017-07-12 15:29:56,291 Epoch[7] Batch [30]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.137222,	
2017-07-12 15:30:01,788 Epoch[7] Batch [40]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.142038,	
2017-07-12 15:30:06,817 Epoch[7] Batch [50]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.140622,	
2017-07-12 15:30:11,645 Epoch[7] Batch [60]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.139481,	
2017-07-12 15:30:16,670 Epoch[7] Batch [70]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.138216,	
2017-07-12 15:30:21,713 Epoch[7] Batch [80]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.138376,	
2017-07-12 15:30:26,754 Epoch[7] Batch [90]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.137862,	
2017-07-12 15:30:32,161 Epoch[7] Batch [100]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.138282,	
2017-07-12 15:30:37,312 Epoch[7] Batch [110]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.139253,	
2017-07-12 15:30:42,237 Epoch[7] Batch [120]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.139200,	
2017-07-12 15:30:47,412 Epoch[7] Batch [130]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.137884,	
2017-07-12 15:30:52,671 Epoch[7] Batch [140]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.137947,	
2017-07-12 15:30:57,955 Epoch[7] Batch [150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.136676,	
2017-07-12 15:31:03,103 Epoch[7] Batch [160]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.137447,	
2017-07-12 15:31:08,253 Epoch[7] Batch [170]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.136612,	
2017-07-12 15:31:13,439 Epoch[7] Batch [180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.136446,	
2017-07-12 15:31:18,669 Epoch[7] Batch [190]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.136578,	
2017-07-12 15:31:23,868 Epoch[7] Batch [200]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.136112,	
2017-07-12 15:31:28,869 Epoch[7] Batch [210]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.136365,	
2017-07-12 15:31:33,796 Epoch[7] Batch [220]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.136782,	
2017-07-12 15:31:38,697 Epoch[7] Batch [230]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.136781,	
2017-07-12 15:31:43,471 Epoch[7] Batch [240]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.137071,	
2017-07-12 15:31:48,504 Epoch[7] Batch [250]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.136750,	
2017-07-12 15:31:53,746 Epoch[7] Batch [260]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.137022,	
2017-07-12 15:31:59,123 Epoch[7] Batch [270]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.136190,	
2017-07-12 15:32:04,430 Epoch[7] Batch [280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.136188,	
2017-07-12 15:32:09,470 Epoch[7] Batch [290]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.136497,	
2017-07-12 15:32:14,561 Epoch[7] Batch [300]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.136015,	
2017-07-12 15:32:19,569 Epoch[7] Batch [310]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.136085,	
2017-07-12 15:32:24,567 Epoch[7] Batch [320]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.135767,	
2017-07-12 15:32:29,799 Epoch[7] Batch [330]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.136215,	
2017-07-12 15:32:35,468 Epoch[7] Batch [340]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.136773,	
2017-07-12 15:32:40,713 Epoch[7] Batch [350]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.136158,	
2017-07-12 15:32:45,805 Epoch[7] Batch [360]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.135888,	
2017-07-12 15:32:50,924 Epoch[7] Batch [370]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.136211,	
2017-07-12 15:32:56,010 Epoch[7] Batch [380]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.135947,	
2017-07-12 15:33:01,090 Epoch[7] Batch [390]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.136103,	
2017-07-12 15:33:06,266 Epoch[7] Batch [400]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.136585,	
2017-07-12 15:33:11,590 Epoch[7] Batch [410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.137137,	
2017-07-12 15:33:16,563 Epoch[7] Batch [420]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.137181,	
2017-07-12 15:33:21,690 Epoch[7] Batch [430]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.138212,	
2017-07-12 15:33:26,733 Epoch[7] Batch [440]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.138399,	
2017-07-12 15:33:31,794 Epoch[7] Batch [450]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.138333,	
2017-07-12 15:33:37,294 Epoch[7] Batch [460]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.138386,	
2017-07-12 15:33:42,846 Epoch[7] Batch [470]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.138351,	
2017-07-12 15:33:48,124 Epoch[7] Batch [480]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.138216,	
2017-07-12 15:33:53,076 Epoch[7] Batch [490]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.138117,	
2017-07-12 15:33:58,269 Epoch[7] Batch [500]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.138151,	
2017-07-12 15:34:03,722 Epoch[7] Batch [510]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.138238,	
2017-07-12 15:34:08,784 Epoch[7] Batch [520]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.138183,	
2017-07-12 15:34:13,923 Epoch[7] Batch [530]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.139205,	
2017-07-12 15:34:18,821 Epoch[7] Batch [540]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.139391,	
2017-07-12 15:34:24,140 Epoch[7] Batch [550]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.139774,	
2017-07-12 15:34:29,401 Epoch[7] Batch [560]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.139805,	
2017-07-12 15:34:34,470 Epoch[7] Batch [570]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.139612,	
2017-07-12 15:34:39,747 Epoch[7] Batch [580]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.139842,	
2017-07-12 15:34:45,415 Epoch[7] Batch [590]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.139911,	
2017-07-12 15:34:50,459 Epoch[7] Batch [600]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.140119,	
2017-07-12 15:34:55,663 Epoch[7] Batch [610]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.140377,	
2017-07-12 15:35:01,010 Epoch[7] Batch [620]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.140263,	
2017-07-12 15:35:06,152 Epoch[7] Batch [630]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.139922,	
2017-07-12 15:35:11,131 Epoch[7] Batch [640]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.140091,	
2017-07-12 15:35:16,298 Epoch[7] Batch [650]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.140466,	
2017-07-12 15:35:21,376 Epoch[7] Batch [660]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.140615,	
2017-07-12 15:35:26,335 Epoch[7] Batch [670]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.140967,	
2017-07-12 15:35:31,267 Epoch[7] Batch [680]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.141132,	
2017-07-12 15:35:36,287 Epoch[7] Batch [690]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.141245,	
2017-07-12 15:35:41,333 Epoch[7] Batch [700]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.141137,	
2017-07-12 15:35:46,273 Epoch[7] Batch [710]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.140853,	
2017-07-12 15:35:51,406 Epoch[7] Batch [720]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.140835,	
2017-07-12 15:35:56,795 Epoch[7] Batch [730]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.141003,	
2017-07-12 15:36:01,994 Epoch[7] Batch [740]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.141018,	
2017-07-12 15:36:07,173 Epoch[7] Batch [750]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.140790,	
2017-07-12 15:36:12,356 Epoch[7] Batch [760]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.140781,	
2017-07-12 15:36:17,243 Epoch[7] Batch [770]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.140986,	
2017-07-12 15:36:22,554 Epoch[7] Batch [780]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.140992,	
2017-07-12 15:36:27,960 Epoch[7] Batch [790]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.140826,	
2017-07-12 15:36:33,082 Epoch[7] Batch [800]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.140804,	
2017-07-12 15:36:38,406 Epoch[7] Batch [810]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.140716,	
2017-07-12 15:36:43,882 Epoch[7] Batch [820]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.140541,	
2017-07-12 15:36:49,335 Epoch[7] Batch [830]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.140407,	
2017-07-12 15:36:54,199 Epoch[7] Batch [840]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.140234,	
2017-07-12 15:36:59,124 Epoch[7] Batch [850]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.140022,	
2017-07-12 15:37:04,748 Epoch[7] Batch [860]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.139815,	
2017-07-12 15:37:10,209 Epoch[7] Batch [870]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.139718,	
2017-07-12 15:37:15,548 Epoch[7] Batch [880]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.139679,	
2017-07-12 15:37:20,836 Epoch[7] Batch [890]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.139577,	
2017-07-12 15:37:26,325 Epoch[7] Batch [900]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.139480,	
2017-07-12 15:37:31,356 Epoch[7] Batch [910]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.139349,	
2017-07-12 15:37:36,624 Epoch[7] Batch [920]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.139509,	
2017-07-12 15:37:42,147 Epoch[7] Batch [930]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.139514,	
2017-07-12 15:37:47,285 Epoch[7] Batch [940]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.139337,	
2017-07-12 15:37:52,501 Epoch[7] Batch [950]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.139788,	
2017-07-12 15:37:57,713 Epoch[7] Batch [960]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.139777,	
2017-07-12 15:38:02,993 Epoch[7] Batch [970]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.139668,	
2017-07-12 15:38:08,349 Epoch[7] Batch [980]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.139634,	
2017-07-12 15:38:13,692 Epoch[7] Batch [990]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.139701,	
2017-07-12 15:38:18,667 Epoch[7] Batch [1000]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.139860,	
2017-07-12 15:38:23,624 Epoch[7] Batch [1010]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.139837,	
2017-07-12 15:38:28,563 Epoch[7] Batch [1020]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.139791,	
2017-07-12 15:38:33,925 Epoch[7] Batch [1030]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.139728,	
2017-07-12 15:38:39,194 Epoch[7] Batch [1040]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.139633,	
2017-07-12 15:38:44,372 Epoch[7] Batch [1050]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.141859,	
2017-07-12 15:38:49,613 Epoch[7] Batch [1060]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.143576,	
2017-07-12 15:38:54,789 Epoch[7] Batch [1070]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.144344,	
2017-07-12 15:39:00,109 Epoch[7] Batch [1080]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.144974,	
2017-07-12 15:39:05,105 Epoch[7] Batch [1090]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.145257,	
2017-07-12 15:39:10,137 Epoch[7] Batch [1100]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.145375,	
2017-07-12 15:39:15,534 Epoch[7] Batch [1110]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.145907,	
2017-07-12 15:39:20,808 Epoch[7] Batch [1120]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.146457,	
2017-07-12 15:39:26,392 Epoch[7] Batch [1130]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.146558,	
2017-07-12 15:39:31,607 Epoch[7] Batch [1140]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.146835,	
2017-07-12 15:39:36,425 Epoch[7] Batch [1150]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.147002,	
2017-07-12 15:39:41,397 Epoch[7] Batch [1160]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.147176,	
2017-07-12 15:39:47,139 Epoch[7] Batch [1170]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.147321,	
2017-07-12 15:39:52,872 Epoch[7] Batch [1180]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.147602,	
2017-07-12 15:39:58,033 Epoch[7] Batch [1190]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.147999,	
2017-07-12 15:40:02,814 Epoch[7] Batch [1200]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.148191,	
2017-07-12 15:40:07,853 Epoch[7] Batch [1210]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.148254,	
2017-07-12 15:40:12,768 Epoch[7] Batch [1220]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.148309,	
2017-07-12 15:40:17,694 Epoch[7] Batch [1230]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.148401,	
2017-07-12 15:40:23,292 Epoch[7] Batch [1240]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.148566,	
2017-07-12 15:40:28,801 Epoch[7] Batch [1250]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.148513,	
2017-07-12 15:40:33,959 Epoch[7] Batch [1260]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.148431,	
2017-07-12 15:40:39,271 Epoch[7] Batch [1270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.148259,	
2017-07-12 15:40:44,309 Epoch[7] Batch [1280]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.148236,	
2017-07-12 15:40:49,256 Epoch[7] Batch [1290]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.148162,	
2017-07-12 15:40:54,400 Epoch[7] Batch [1300]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.148136,	
2017-07-12 15:40:59,581 Epoch[7] Batch [1310]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.148270,	
2017-07-12 15:41:04,714 Epoch[7] Batch [1320]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.148328,	
2017-07-12 15:41:10,060 Epoch[7] Batch [1330]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.148210,	
2017-07-12 15:41:14,802 Epoch[7] Batch [1340]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.148140,	
2017-07-12 15:41:20,195 Epoch[7] Batch [1350]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.148320,	
2017-07-12 15:41:25,339 Epoch[7] Batch [1360]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.148337,	
2017-07-12 15:41:30,452 Epoch[7] Batch [1370]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.148236,	
2017-07-12 15:41:36,067 Epoch[7] Batch [1380]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.148141,	
2017-07-12 15:41:41,345 Epoch[7] Batch [1390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.148069,	
2017-07-12 15:41:46,632 Epoch[7] Batch [1400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.147972,	
2017-07-12 15:41:51,945 Epoch[7] Batch [1410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.148091,	
2017-07-12 15:41:57,037 Epoch[7] Batch [1420]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.148161,	
2017-07-12 15:42:02,695 Epoch[7] Batch [1430]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.148042,	
2017-07-12 15:42:08,643 Epoch[7] Batch [1440]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.147864,	
2017-07-12 15:42:13,670 Epoch[7] Batch [1450]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.147825,	
2017-07-12 15:42:18,757 Epoch[7] Batch [1460]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.147976,	
2017-07-12 15:42:24,152 Epoch[7] Batch [1470]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.147965,	
2017-07-12 15:42:28,966 Epoch[7] Batch [1480]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.147994,	
2017-07-12 15:42:32,151 Epoch[7] Train-FCNLogLoss=0.147877
2017-07-12 15:42:32,151 Epoch[7] Time cost=772.777
2017-07-12 15:42:33,043 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0008.params"
2017-07-12 15:42:35,948 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0008.states"
2017-07-12 15:42:42,206 Epoch[8] Batch [10]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.123129,	
2017-07-12 15:42:47,842 Epoch[8] Batch [20]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.121072,	
2017-07-12 15:42:53,133 Epoch[8] Batch [30]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122206,	
2017-07-12 15:42:58,344 Epoch[8] Batch [40]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.120092,	
2017-07-12 15:43:03,598 Epoch[8] Batch [50]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121633,	
2017-07-12 15:43:09,024 Epoch[8] Batch [60]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.122538,	
2017-07-12 15:43:14,538 Epoch[8] Batch [70]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.121845,	
2017-07-12 15:43:20,172 Epoch[8] Batch [80]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.120977,	
2017-07-12 15:43:25,962 Epoch[8] Batch [90]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.124800,	
2017-07-12 15:43:31,259 Epoch[8] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125761,	
2017-07-12 15:43:37,404 Epoch[8] Batch [110]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.125586,	
2017-07-12 15:43:42,519 Epoch[8] Batch [120]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.125352,	
2017-07-12 15:43:47,805 Epoch[8] Batch [130]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.127133,	
2017-07-12 15:43:53,076 Epoch[8] Batch [140]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.127872,	
2017-07-12 15:43:57,964 Epoch[8] Batch [150]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.127763,	
2017-07-12 15:44:03,467 Epoch[8] Batch [160]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.127777,	
2017-07-12 15:44:08,882 Epoch[8] Batch [170]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.127089,	
2017-07-12 15:44:14,193 Epoch[8] Batch [180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.128692,	
2017-07-12 15:44:19,721 Epoch[8] Batch [190]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.129480,	
2017-07-12 15:44:25,442 Epoch[8] Batch [200]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.133010,	
2017-07-12 15:44:30,565 Epoch[8] Batch [210]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.134846,	
2017-07-12 15:44:36,067 Epoch[8] Batch [220]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.135751,	
2017-07-12 15:44:41,158 Epoch[8] Batch [230]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.135953,	
2017-07-12 15:44:46,454 Epoch[8] Batch [240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.136139,	
2017-07-12 15:44:51,824 Epoch[8] Batch [250]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.136939,	
2017-07-12 15:44:57,164 Epoch[8] Batch [260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.137209,	
2017-07-12 15:45:02,535 Epoch[8] Batch [270]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.137697,	
2017-07-12 15:45:08,066 Epoch[8] Batch [280]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.137512,	
2017-07-12 15:45:13,947 Epoch[8] Batch [290]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.137587,	
2017-07-12 15:45:19,042 Epoch[8] Batch [300]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.137516,	
2017-07-12 15:45:24,718 Epoch[8] Batch [310]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.137242,	
2017-07-12 15:45:29,947 Epoch[8] Batch [320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.136498,	
2017-07-12 15:45:35,188 Epoch[8] Batch [330]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.137178,	
2017-07-12 15:45:40,842 Epoch[8] Batch [340]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.137469,	
2017-07-12 15:45:47,012 Epoch[8] Batch [350]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.137433,	
2017-07-12 15:45:53,281 Epoch[8] Batch [360]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.138018,	
2017-07-12 15:45:59,542 Epoch[8] Batch [370]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.138361,	
2017-07-12 15:46:05,806 Epoch[8] Batch [380]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.138299,	
2017-07-12 15:46:12,049 Epoch[8] Batch [390]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.138494,	
2017-07-12 15:46:18,317 Epoch[8] Batch [400]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.138146,	
2017-07-12 15:46:24,768 Epoch[8] Batch [410]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.137972,	
2017-07-12 15:46:31,082 Epoch[8] Batch [420]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.138787,	
2017-07-12 15:46:37,338 Epoch[8] Batch [430]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.139515,	
2017-07-12 15:46:43,597 Epoch[8] Batch [440]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.139714,	
2017-07-12 15:46:49,875 Epoch[8] Batch [450]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.139746,	
2017-07-12 15:46:56,138 Epoch[8] Batch [460]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.139700,	
2017-07-12 15:47:02,362 Epoch[8] Batch [470]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.139886,	
2017-07-12 15:47:08,631 Epoch[8] Batch [480]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.139834,	
2017-07-12 15:47:14,857 Epoch[8] Batch [490]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.139875,	
2017-07-12 15:47:21,117 Epoch[8] Batch [500]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.140182,	
2017-07-12 15:47:27,377 Epoch[8] Batch [510]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.139756,	
2017-07-12 15:47:33,599 Epoch[8] Batch [520]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.139408,	
2017-07-12 15:47:39,851 Epoch[8] Batch [530]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.139530,	
2017-07-12 15:47:46,096 Epoch[8] Batch [540]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.139378,	
2017-07-12 15:47:52,375 Epoch[8] Batch [550]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.139008,	
2017-07-12 15:47:58,648 Epoch[8] Batch [560]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.138845,	
2017-07-12 15:48:04,835 Epoch[8] Batch [570]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.138720,	
2017-07-12 15:48:11,094 Epoch[8] Batch [580]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.138399,	
2017-07-12 15:48:17,348 Epoch[8] Batch [590]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.138349,	
2017-07-12 15:48:23,629 Epoch[8] Batch [600]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.138123,	
2017-07-12 15:48:29,915 Epoch[8] Batch [610]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.138510,	
2017-07-12 15:48:36,164 Epoch[8] Batch [620]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.138380,	
2017-07-12 15:48:42,413 Epoch[8] Batch [630]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.138387,	
2017-07-12 15:48:48,673 Epoch[8] Batch [640]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.138584,	
2017-07-12 15:48:54,890 Epoch[8] Batch [650]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.138549,	
2017-07-12 15:49:01,155 Epoch[8] Batch [660]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.138348,	
2017-07-12 15:49:07,424 Epoch[8] Batch [670]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.138349,	
2017-07-12 15:49:13,695 Epoch[8] Batch [680]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.138156,	
2017-07-12 15:49:19,977 Epoch[8] Batch [690]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.137921,	
2017-07-12 15:49:26,208 Epoch[8] Batch [700]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.138029,	
2017-07-12 15:49:32,484 Epoch[8] Batch [710]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.138176,	
2017-07-12 15:49:37,574 Epoch[8] Batch [720]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.137989,	
2017-07-12 15:49:42,828 Epoch[8] Batch [730]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.137754,	
2017-07-12 15:49:47,736 Epoch[8] Batch [740]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.137746,	
2017-07-12 15:49:52,687 Epoch[8] Batch [750]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.137752,	
2017-07-12 15:49:58,069 Epoch[8] Batch [760]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.138050,	
2017-07-12 15:50:04,037 Epoch[8] Batch [770]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.137927,	
2017-07-12 15:50:09,388 Epoch[8] Batch [780]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.137890,	
2017-07-12 15:50:15,039 Epoch[8] Batch [790]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.137776,	
2017-07-12 15:50:20,046 Epoch[8] Batch [800]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.137691,	
2017-07-12 15:50:25,088 Epoch[8] Batch [810]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.137662,	
2017-07-12 15:50:30,703 Epoch[8] Batch [820]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.137581,	
2017-07-12 15:50:36,435 Epoch[8] Batch [830]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.137545,	
2017-07-12 15:50:41,740 Epoch[8] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.137458,	
2017-07-12 15:50:46,763 Epoch[8] Batch [850]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.137541,	
2017-07-12 15:50:51,801 Epoch[8] Batch [860]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.137440,	
2017-07-12 15:50:57,231 Epoch[8] Batch [870]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.137399,	
2017-07-12 15:51:02,862 Epoch[8] Batch [880]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.137439,	
2017-07-12 15:51:07,649 Epoch[8] Batch [890]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.137477,	
2017-07-12 15:51:13,006 Epoch[8] Batch [900]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.137338,	
2017-07-12 15:51:17,832 Epoch[8] Batch [910]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.137384,	
2017-07-12 15:51:23,051 Epoch[8] Batch [920]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.137416,	
2017-07-12 15:51:28,103 Epoch[8] Batch [930]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.137384,	
2017-07-12 15:51:33,192 Epoch[8] Batch [940]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.137295,	
2017-07-12 15:51:38,318 Epoch[8] Batch [950]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.137349,	
2017-07-12 15:51:43,473 Epoch[8] Batch [960]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.137180,	
2017-07-12 15:51:49,094 Epoch[8] Batch [970]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.137237,	
2017-07-12 15:51:54,861 Epoch[8] Batch [980]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.137078,	
2017-07-12 15:52:00,110 Epoch[8] Batch [990]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.137077,	
2017-07-12 15:52:05,387 Epoch[8] Batch [1000]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.136992,	
2017-07-12 15:52:10,619 Epoch[8] Batch [1010]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.136918,	
2017-07-12 15:52:15,608 Epoch[8] Batch [1020]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.137032,	
2017-07-12 15:52:21,046 Epoch[8] Batch [1030]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.137012,	
2017-07-12 15:52:26,265 Epoch[8] Batch [1040]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.136848,	
2017-07-12 15:52:31,733 Epoch[8] Batch [1050]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.136761,	
2017-07-12 15:52:36,796 Epoch[8] Batch [1060]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.136812,	
2017-07-12 15:52:42,230 Epoch[8] Batch [1070]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.136716,	
2017-07-12 15:52:47,467 Epoch[8] Batch [1080]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.136784,	
2017-07-12 15:52:53,075 Epoch[8] Batch [1090]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.136717,	
2017-07-12 15:52:58,900 Epoch[8] Batch [1100]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.136659,	
2017-07-12 15:53:04,182 Epoch[8] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.136608,	
2017-07-12 15:53:09,613 Epoch[8] Batch [1120]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.136548,	
2017-07-12 15:53:15,081 Epoch[8] Batch [1130]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.136497,	
2017-07-12 15:53:20,233 Epoch[8] Batch [1140]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.136442,	
2017-07-12 15:53:25,164 Epoch[8] Batch [1150]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.136264,	
2017-07-12 15:53:30,169 Epoch[8] Batch [1160]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.136219,	
2017-07-12 15:53:35,404 Epoch[8] Batch [1170]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.136274,	
2017-07-12 15:53:40,434 Epoch[8] Batch [1180]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.136119,	
2017-07-12 15:53:45,683 Epoch[8] Batch [1190]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.136316,	
2017-07-12 15:53:50,870 Epoch[8] Batch [1200]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.136430,	
2017-07-12 15:53:55,933 Epoch[8] Batch [1210]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.136650,	
2017-07-12 15:54:00,998 Epoch[8] Batch [1220]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.136811,	
2017-07-12 15:54:06,376 Epoch[8] Batch [1230]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.137983,	
2017-07-12 15:54:11,410 Epoch[8] Batch [1240]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.138977,	
2017-07-12 15:54:16,902 Epoch[8] Batch [1250]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.139268,	
2017-07-12 15:54:22,024 Epoch[8] Batch [1260]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.139758,	
2017-07-12 15:54:27,063 Epoch[8] Batch [1270]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.140213,	
2017-07-12 15:54:32,477 Epoch[8] Batch [1280]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.140560,	
2017-07-12 15:54:37,533 Epoch[8] Batch [1290]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.140562,	
2017-07-12 15:54:42,594 Epoch[8] Batch [1300]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.140706,	
2017-07-12 15:54:47,868 Epoch[8] Batch [1310]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.140823,	
2017-07-12 15:54:53,127 Epoch[8] Batch [1320]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.140881,	
2017-07-12 15:54:58,541 Epoch[8] Batch [1330]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.140965,	
2017-07-12 15:55:04,092 Epoch[8] Batch [1340]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.140922,	
2017-07-12 15:55:09,306 Epoch[8] Batch [1350]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.140986,	
2017-07-12 15:55:14,669 Epoch[8] Batch [1360]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.140972,	
2017-07-12 15:55:20,293 Epoch[8] Batch [1370]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.140779,	
2017-07-12 15:55:26,013 Epoch[8] Batch [1380]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.140800,	
2017-07-12 15:55:31,034 Epoch[8] Batch [1390]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.140774,	
2017-07-12 15:55:36,427 Epoch[8] Batch [1400]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.140839,	
2017-07-12 15:55:41,733 Epoch[8] Batch [1410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.140819,	
2017-07-12 15:55:47,271 Epoch[8] Batch [1420]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.140877,	
2017-07-12 15:55:52,732 Epoch[8] Batch [1430]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.140832,	
2017-07-12 15:55:57,956 Epoch[8] Batch [1440]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.140710,	
2017-07-12 15:56:02,864 Epoch[8] Batch [1450]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.140755,	
2017-07-12 15:56:07,739 Epoch[8] Batch [1460]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.140769,	
2017-07-12 15:56:12,394 Epoch[8] Batch [1470]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.140667,	
2017-07-12 15:56:17,448 Epoch[8] Batch [1480]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.140618,	
2017-07-12 15:56:20,740 Epoch[8] Train-FCNLogLoss=0.140612
2017-07-12 15:56:20,740 Epoch[8] Time cost=824.792
2017-07-12 15:56:21,646 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0009.params"
2017-07-12 15:56:24,656 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0009.states"
2017-07-12 15:56:30,735 Epoch[9] Batch [10]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.149504,	
2017-07-12 15:56:35,635 Epoch[9] Batch [20]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.147614,	
2017-07-12 15:56:40,886 Epoch[9] Batch [30]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.137388,	
2017-07-12 15:56:45,822 Epoch[9] Batch [40]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.133980,	
2017-07-12 15:56:51,031 Epoch[9] Batch [50]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.134531,	
2017-07-12 15:56:56,437 Epoch[9] Batch [60]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.134283,	
2017-07-12 15:57:01,621 Epoch[9] Batch [70]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.135300,	
2017-07-12 15:57:07,206 Epoch[9] Batch [80]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.136748,	
2017-07-12 15:57:12,773 Epoch[9] Batch [90]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.136292,	
2017-07-12 15:57:17,870 Epoch[9] Batch [100]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.135274,	
2017-07-12 15:57:22,813 Epoch[9] Batch [110]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.133489,	
2017-07-12 15:57:28,084 Epoch[9] Batch [120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.132524,	
2017-07-12 15:57:33,185 Epoch[9] Batch [130]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.131679,	
2017-07-12 15:57:38,541 Epoch[9] Batch [140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131076,	
2017-07-12 15:57:44,182 Epoch[9] Batch [150]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.131646,	
2017-07-12 15:57:49,516 Epoch[9] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130944,	
2017-07-12 15:57:55,456 Epoch[9] Batch [170]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.130493,	
2017-07-12 15:58:00,595 Epoch[9] Batch [180]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.130176,	
2017-07-12 15:58:06,145 Epoch[9] Batch [190]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.129802,	
2017-07-12 15:58:10,957 Epoch[9] Batch [200]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.129501,	
2017-07-12 15:58:16,579 Epoch[9] Batch [210]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.129251,	
2017-07-12 15:58:22,182 Epoch[9] Batch [220]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.129203,	
2017-07-12 15:58:27,780 Epoch[9] Batch [230]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.129414,	
2017-07-12 15:58:33,284 Epoch[9] Batch [240]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.129129,	
2017-07-12 15:58:39,073 Epoch[9] Batch [250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.129044,	
2017-07-12 15:58:44,815 Epoch[9] Batch [260]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.130558,	
2017-07-12 15:58:50,448 Epoch[9] Batch [270]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.131108,	
2017-07-12 15:58:56,775 Epoch[9] Batch [280]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.131063,	
2017-07-12 15:59:02,340 Epoch[9] Batch [290]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.130586,	
2017-07-12 15:59:07,785 Epoch[9] Batch [300]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.130381,	
2017-07-12 15:59:12,734 Epoch[9] Batch [310]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.130334,	
2017-07-12 15:59:17,540 Epoch[9] Batch [320]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.130495,	
2017-07-12 15:59:22,524 Epoch[9] Batch [330]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.130586,	
2017-07-12 15:59:27,450 Epoch[9] Batch [340]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.130700,	
2017-07-12 15:59:33,269 Epoch[9] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.130830,	
2017-07-12 15:59:38,771 Epoch[9] Batch [360]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.131258,	
2017-07-12 15:59:43,583 Epoch[9] Batch [370]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.131260,	
2017-07-12 15:59:48,718 Epoch[9] Batch [380]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.130755,	
2017-07-12 15:59:53,832 Epoch[9] Batch [390]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.130833,	
2017-07-12 15:59:58,843 Epoch[9] Batch [400]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.131120,	
2017-07-12 16:00:04,366 Epoch[9] Batch [410]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.131131,	
2017-07-12 16:00:09,813 Epoch[9] Batch [420]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.130866,	
2017-07-12 16:00:15,502 Epoch[9] Batch [430]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.130657,	
2017-07-12 16:00:20,803 Epoch[9] Batch [440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.130342,	
2017-07-12 16:00:25,963 Epoch[9] Batch [450]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.130653,	
2017-07-12 16:00:30,880 Epoch[9] Batch [460]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.130698,	
2017-07-12 16:00:36,646 Epoch[9] Batch [470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.130753,	
2017-07-12 16:00:41,966 Epoch[9] Batch [480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130785,	
2017-07-12 16:00:47,447 Epoch[9] Batch [490]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.130817,	
2017-07-12 16:00:52,447 Epoch[9] Batch [500]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.130751,	
2017-07-12 16:00:57,716 Epoch[9] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.131001,	
2017-07-12 16:01:02,791 Epoch[9] Batch [520]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.130924,	
2017-07-12 16:01:08,469 Epoch[9] Batch [530]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.130811,	
2017-07-12 16:01:13,555 Epoch[9] Batch [540]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.131000,	
2017-07-12 16:01:18,685 Epoch[9] Batch [550]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.130838,	
2017-07-12 16:01:23,942 Epoch[9] Batch [560]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.130626,	
2017-07-12 16:01:29,635 Epoch[9] Batch [570]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.130278,	
2017-07-12 16:01:35,192 Epoch[9] Batch [580]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.130177,	
2017-07-12 16:01:40,492 Epoch[9] Batch [590]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.130181,	
2017-07-12 16:01:46,054 Epoch[9] Batch [600]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.130073,	
2017-07-12 16:01:51,168 Epoch[9] Batch [610]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.130122,	
2017-07-12 16:01:56,527 Epoch[9] Batch [620]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130030,	
2017-07-12 16:02:01,569 Epoch[9] Batch [630]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.130121,	
2017-07-12 16:02:06,152 Epoch[9] Batch [640]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.130253,	
2017-07-12 16:02:10,953 Epoch[9] Batch [650]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.130369,	
2017-07-12 16:02:16,521 Epoch[9] Batch [660]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.130504,	
2017-07-12 16:02:21,860 Epoch[9] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130572,	
2017-07-12 16:02:27,334 Epoch[9] Batch [680]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.130593,	
2017-07-12 16:02:32,639 Epoch[9] Batch [690]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130705,	
2017-07-12 16:02:37,920 Epoch[9] Batch [700]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130769,	
2017-07-12 16:02:43,565 Epoch[9] Batch [710]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.130873,	
2017-07-12 16:02:49,318 Epoch[9] Batch [720]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.130829,	
2017-07-12 16:02:54,629 Epoch[9] Batch [730]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130700,	
2017-07-12 16:02:59,700 Epoch[9] Batch [740]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.130479,	
2017-07-12 16:03:04,989 Epoch[9] Batch [750]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.130542,	
2017-07-12 16:03:10,346 Epoch[9] Batch [760]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130467,	
2017-07-12 16:03:15,739 Epoch[9] Batch [770]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.130375,	
2017-07-12 16:03:21,155 Epoch[9] Batch [780]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.130353,	
2017-07-12 16:03:26,579 Epoch[9] Batch [790]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.130344,	
2017-07-12 16:03:31,557 Epoch[9] Batch [800]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.130370,	
2017-07-12 16:03:36,911 Epoch[9] Batch [810]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130413,	
2017-07-12 16:03:42,334 Epoch[9] Batch [820]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.130134,	
2017-07-12 16:03:47,813 Epoch[9] Batch [830]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.130004,	
2017-07-12 16:03:52,845 Epoch[9] Batch [840]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.130166,	
2017-07-12 16:03:57,780 Epoch[9] Batch [850]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.130233,	
2017-07-12 16:04:03,126 Epoch[9] Batch [860]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130133,	
2017-07-12 16:04:07,993 Epoch[9] Batch [870]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.130145,	
2017-07-12 16:04:13,033 Epoch[9] Batch [880]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.130140,	
2017-07-12 16:04:17,852 Epoch[9] Batch [890]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.129965,	
2017-07-12 16:04:23,140 Epoch[9] Batch [900]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130007,	
2017-07-12 16:04:28,521 Epoch[9] Batch [910]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.130052,	
2017-07-12 16:04:34,397 Epoch[9] Batch [920]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.130052,	
2017-07-12 16:04:39,594 Epoch[9] Batch [930]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.130083,	
2017-07-12 16:04:44,431 Epoch[9] Batch [940]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.130005,	
2017-07-12 16:04:49,460 Epoch[9] Batch [950]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.130142,	
2017-07-12 16:04:54,810 Epoch[9] Batch [960]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130615,	
2017-07-12 16:05:00,305 Epoch[9] Batch [970]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.130718,	
2017-07-12 16:05:05,393 Epoch[9] Batch [980]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.130776,	
2017-07-12 16:05:10,498 Epoch[9] Batch [990]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.130714,	
2017-07-12 16:05:15,628 Epoch[9] Batch [1000]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.130895,	
2017-07-12 16:05:21,073 Epoch[9] Batch [1010]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.130879,	
2017-07-12 16:05:26,310 Epoch[9] Batch [1020]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.130912,	
2017-07-12 16:05:31,827 Epoch[9] Batch [1030]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.131138,	
2017-07-12 16:05:36,974 Epoch[9] Batch [1040]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.131115,	
2017-07-12 16:05:42,440 Epoch[9] Batch [1050]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.131119,	
2017-07-12 16:05:47,829 Epoch[9] Batch [1060]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.131229,	
2017-07-12 16:05:53,428 Epoch[9] Batch [1070]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.131058,	
2017-07-12 16:05:58,425 Epoch[9] Batch [1080]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.130994,	
2017-07-12 16:06:04,219 Epoch[9] Batch [1090]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.130964,	
2017-07-12 16:06:09,584 Epoch[9] Batch [1100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130816,	
2017-07-12 16:06:14,918 Epoch[9] Batch [1110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130772,	
2017-07-12 16:06:19,984 Epoch[9] Batch [1120]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.130858,	
2017-07-12 16:06:25,250 Epoch[9] Batch [1130]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.130960,	
2017-07-12 16:06:30,445 Epoch[9] Batch [1140]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.131039,	
2017-07-12 16:06:35,838 Epoch[9] Batch [1150]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.130969,	
2017-07-12 16:06:41,114 Epoch[9] Batch [1160]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.131010,	
2017-07-12 16:06:46,287 Epoch[9] Batch [1170]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.131070,	
2017-07-12 16:06:51,616 Epoch[9] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131098,	
2017-07-12 16:06:56,936 Epoch[9] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130972,	
2017-07-12 16:07:01,936 Epoch[9] Batch [1200]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.130908,	
2017-07-12 16:07:06,787 Epoch[9] Batch [1210]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.131019,	
2017-07-12 16:07:11,927 Epoch[9] Batch [1220]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.131084,	
2017-07-12 16:07:17,505 Epoch[9] Batch [1230]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.131058,	
2017-07-12 16:07:22,921 Epoch[9] Batch [1240]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.131013,	
2017-07-12 16:07:28,612 Epoch[9] Batch [1250]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.130864,	
2017-07-12 16:07:33,680 Epoch[9] Batch [1260]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.130797,	
2017-07-12 16:07:38,760 Epoch[9] Batch [1270]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.130860,	
2017-07-12 16:07:44,251 Epoch[9] Batch [1280]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.130796,	
2017-07-12 16:07:49,972 Epoch[9] Batch [1290]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.130650,	
2017-07-12 16:07:55,527 Epoch[9] Batch [1300]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.130481,	
2017-07-12 16:08:00,891 Epoch[9] Batch [1310]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130418,	
2017-07-12 16:08:05,941 Epoch[9] Batch [1320]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.130384,	
2017-07-12 16:08:11,125 Epoch[9] Batch [1330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.130437,	
2017-07-12 16:08:16,007 Epoch[9] Batch [1340]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.130962,	
2017-07-12 16:08:20,833 Epoch[9] Batch [1350]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.131481,	
2017-07-12 16:08:25,377 Epoch[9] Batch [1360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.131618,	
2017-07-12 16:08:29,981 Epoch[9] Batch [1370]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.131629,	
2017-07-12 16:08:34,976 Epoch[9] Batch [1380]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.131638,	
2017-07-12 16:08:40,012 Epoch[9] Batch [1390]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.131655,	
2017-07-12 16:08:44,839 Epoch[9] Batch [1400]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.131770,	
2017-07-12 16:08:49,752 Epoch[9] Batch [1410]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.131959,	
2017-07-12 16:08:55,141 Epoch[9] Batch [1420]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.132077,	
2017-07-12 16:09:00,328 Epoch[9] Batch [1430]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.132168,	
2017-07-12 16:09:05,705 Epoch[9] Batch [1440]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.132380,	
2017-07-12 16:09:11,574 Epoch[9] Batch [1450]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.132486,	
2017-07-12 16:09:16,867 Epoch[9] Batch [1460]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.132483,	
2017-07-12 16:09:22,352 Epoch[9] Batch [1470]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.132666,	
2017-07-12 16:09:27,264 Epoch[9] Batch [1480]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.132799,	
2017-07-12 16:09:30,346 Epoch[9] Train-FCNLogLoss=0.132969
2017-07-12 16:09:30,346 Epoch[9] Time cost=785.690
2017-07-12 16:09:31,326 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0010.params"
2017-07-12 16:09:34,324 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0010.states"
2017-07-12 16:09:40,678 Epoch[10] Batch [10]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.137437,	
2017-07-12 16:09:45,720 Epoch[10] Batch [20]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.160840,	
2017-07-12 16:09:50,985 Epoch[10] Batch [30]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.159738,	
2017-07-12 16:09:56,607 Epoch[10] Batch [40]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.151406,	
2017-07-12 16:10:02,014 Epoch[10] Batch [50]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.147479,	
2017-07-12 16:10:07,090 Epoch[10] Batch [60]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.145679,	
2017-07-12 16:10:12,338 Epoch[10] Batch [70]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.144786,	
2017-07-12 16:10:17,585 Epoch[10] Batch [80]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.142321,	
2017-07-12 16:10:22,365 Epoch[10] Batch [90]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.141717,	
2017-07-12 16:10:27,466 Epoch[10] Batch [100]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.141396,	
2017-07-12 16:10:33,122 Epoch[10] Batch [110]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.139354,	
2017-07-12 16:10:38,457 Epoch[10] Batch [120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.138619,	
2017-07-12 16:10:43,688 Epoch[10] Batch [130]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.140163,	
2017-07-12 16:10:49,119 Epoch[10] Batch [140]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.138067,	
2017-07-12 16:10:54,352 Epoch[10] Batch [150]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.138610,	
2017-07-12 16:10:59,694 Epoch[10] Batch [160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.137867,	
2017-07-12 16:11:04,583 Epoch[10] Batch [170]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.136689,	
2017-07-12 16:11:09,604 Epoch[10] Batch [180]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.136318,	
2017-07-12 16:11:15,025 Epoch[10] Batch [190]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.136133,	
2017-07-12 16:11:20,286 Epoch[10] Batch [200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.134984,	
2017-07-12 16:11:25,436 Epoch[10] Batch [210]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.134884,	
2017-07-12 16:11:30,701 Epoch[10] Batch [220]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.134668,	
2017-07-12 16:11:35,670 Epoch[10] Batch [230]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.133833,	
2017-07-12 16:11:40,848 Epoch[10] Batch [240]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.134083,	
2017-07-12 16:11:46,322 Epoch[10] Batch [250]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.133517,	
2017-07-12 16:11:51,704 Epoch[10] Batch [260]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.133409,	
2017-07-12 16:11:57,174 Epoch[10] Batch [270]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.133231,	
2017-07-12 16:12:02,536 Epoch[10] Batch [280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.132898,	
2017-07-12 16:12:07,555 Epoch[10] Batch [290]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.133159,	
2017-07-12 16:12:12,619 Epoch[10] Batch [300]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.133347,	
2017-07-12 16:12:17,760 Epoch[10] Batch [310]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.133412,	
2017-07-12 16:12:22,914 Epoch[10] Batch [320]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.133467,	
2017-07-12 16:12:28,023 Epoch[10] Batch [330]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.133293,	
2017-07-12 16:12:32,932 Epoch[10] Batch [340]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.133012,	
2017-07-12 16:12:38,048 Epoch[10] Batch [350]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.132418,	
2017-07-12 16:12:42,994 Epoch[10] Batch [360]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.132274,	
2017-07-12 16:12:48,215 Epoch[10] Batch [370]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.132429,	
2017-07-12 16:12:53,644 Epoch[10] Batch [380]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.132980,	
2017-07-12 16:12:58,817 Epoch[10] Batch [390]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.133176,	
2017-07-12 16:13:03,782 Epoch[10] Batch [400]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.133078,	
2017-07-12 16:13:08,624 Epoch[10] Batch [410]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.132953,	
2017-07-12 16:13:13,862 Epoch[10] Batch [420]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.132701,	
2017-07-12 16:13:18,888 Epoch[10] Batch [430]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.132608,	
2017-07-12 16:13:24,605 Epoch[10] Batch [440]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.132700,	
2017-07-12 16:13:30,162 Epoch[10] Batch [450]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.132553,	
2017-07-12 16:13:35,605 Epoch[10] Batch [460]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.132403,	
2017-07-12 16:13:40,997 Epoch[10] Batch [470]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.132485,	
2017-07-12 16:13:46,019 Epoch[10] Batch [480]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.132276,	
2017-07-12 16:13:51,133 Epoch[10] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.132169,	
2017-07-12 16:13:55,920 Epoch[10] Batch [500]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.131922,	
2017-07-12 16:14:00,976 Epoch[10] Batch [510]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.131686,	
2017-07-12 16:14:06,405 Epoch[10] Batch [520]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.131493,	
2017-07-12 16:14:11,734 Epoch[10] Batch [530]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131643,	
2017-07-12 16:14:16,844 Epoch[10] Batch [540]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.131717,	
2017-07-12 16:14:22,274 Epoch[10] Batch [550]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.131424,	
2017-07-12 16:14:28,132 Epoch[10] Batch [560]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.131374,	
2017-07-12 16:14:33,195 Epoch[10] Batch [570]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.131073,	
2017-07-12 16:14:38,293 Epoch[10] Batch [580]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.130986,	
2017-07-12 16:14:43,173 Epoch[10] Batch [590]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.130812,	
2017-07-12 16:14:48,445 Epoch[10] Batch [600]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.130915,	
2017-07-12 16:14:53,521 Epoch[10] Batch [610]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.131355,	
2017-07-12 16:14:59,135 Epoch[10] Batch [620]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.131376,	
2017-07-12 16:15:04,494 Epoch[10] Batch [630]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131165,	
2017-07-12 16:15:09,532 Epoch[10] Batch [640]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.130958,	
2017-07-12 16:15:14,872 Epoch[10] Batch [650]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130818,	
2017-07-12 16:15:20,004 Epoch[10] Batch [660]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.130878,	
2017-07-12 16:15:24,871 Epoch[10] Batch [670]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.130907,	
2017-07-12 16:15:29,967 Epoch[10] Batch [680]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.130995,	
2017-07-12 16:15:35,102 Epoch[10] Batch [690]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.131131,	
2017-07-12 16:15:40,388 Epoch[10] Batch [700]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.131213,	
2017-07-12 16:15:45,534 Epoch[10] Batch [710]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.131342,	
2017-07-12 16:15:50,613 Epoch[10] Batch [720]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.131456,	
2017-07-12 16:15:55,854 Epoch[10] Batch [730]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.131238,	
2017-07-12 16:16:00,902 Epoch[10] Batch [740]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.131285,	
2017-07-12 16:16:06,006 Epoch[10] Batch [750]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.131220,	
2017-07-12 16:16:11,012 Epoch[10] Batch [760]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.131178,	
2017-07-12 16:16:15,847 Epoch[10] Batch [770]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.131094,	
2017-07-12 16:16:20,908 Epoch[10] Batch [780]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.131045,	
2017-07-12 16:16:26,260 Epoch[10] Batch [790]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131159,	
2017-07-12 16:16:31,373 Epoch[10] Batch [800]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.131081,	
2017-07-12 16:16:36,481 Epoch[10] Batch [810]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.130913,	
2017-07-12 16:16:41,499 Epoch[10] Batch [820]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.131035,	
2017-07-12 16:16:46,359 Epoch[10] Batch [830]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.130983,	
2017-07-12 16:16:52,028 Epoch[10] Batch [840]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.130784,	
2017-07-12 16:16:57,045 Epoch[10] Batch [850]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.130803,	
2017-07-12 16:17:01,917 Epoch[10] Batch [860]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.130878,	
2017-07-12 16:17:07,209 Epoch[10] Batch [870]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.130673,	
2017-07-12 16:17:12,537 Epoch[10] Batch [880]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130535,	
2017-07-12 16:17:17,663 Epoch[10] Batch [890]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.130518,	
2017-07-12 16:17:22,766 Epoch[10] Batch [900]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.130447,	
2017-07-12 16:17:27,754 Epoch[10] Batch [910]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.130317,	
2017-07-12 16:17:32,994 Epoch[10] Batch [920]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.130211,	
2017-07-12 16:17:38,079 Epoch[10] Batch [930]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.129821,	
2017-07-12 16:17:43,301 Epoch[10] Batch [940]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.129728,	
2017-07-12 16:17:48,900 Epoch[10] Batch [950]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.129522,	
2017-07-12 16:17:54,041 Epoch[10] Batch [960]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.129460,	
2017-07-12 16:17:58,974 Epoch[10] Batch [970]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.129352,	
2017-07-12 16:18:03,963 Epoch[10] Batch [980]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.129290,	
2017-07-12 16:18:08,959 Epoch[10] Batch [990]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.129189,	
2017-07-12 16:18:14,326 Epoch[10] Batch [1000]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.129108,	
2017-07-12 16:18:19,374 Epoch[10] Batch [1010]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.129075,	
2017-07-12 16:18:24,224 Epoch[10] Batch [1020]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.128970,	
2017-07-12 16:18:29,579 Epoch[10] Batch [1030]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.128905,	
2017-07-12 16:18:34,649 Epoch[10] Batch [1040]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.128792,	
2017-07-12 16:18:39,758 Epoch[10] Batch [1050]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.128725,	
2017-07-12 16:18:45,078 Epoch[10] Batch [1060]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.128707,	
2017-07-12 16:18:50,562 Epoch[10] Batch [1070]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.128669,	
2017-07-12 16:18:55,884 Epoch[10] Batch [1080]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.128673,	
2017-07-12 16:19:01,405 Epoch[10] Batch [1090]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.128680,	
2017-07-12 16:19:06,728 Epoch[10] Batch [1100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.128583,	
2017-07-12 16:19:11,906 Epoch[10] Batch [1110]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.128656,	
2017-07-12 16:19:17,009 Epoch[10] Batch [1120]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.128488,	
2017-07-12 16:19:21,934 Epoch[10] Batch [1130]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.128544,	
2017-07-12 16:19:26,799 Epoch[10] Batch [1140]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.128695,	
2017-07-12 16:19:31,814 Epoch[10] Batch [1150]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.128634,	
2017-07-12 16:19:36,861 Epoch[10] Batch [1160]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.128719,	
2017-07-12 16:19:42,078 Epoch[10] Batch [1170]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.128732,	
2017-07-12 16:19:47,503 Epoch[10] Batch [1180]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.128751,	
2017-07-12 16:19:52,962 Epoch[10] Batch [1190]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.128747,	
2017-07-12 16:19:58,019 Epoch[10] Batch [1200]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.128699,	
2017-07-12 16:20:02,876 Epoch[10] Batch [1210]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.128776,	
2017-07-12 16:20:07,853 Epoch[10] Batch [1220]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.128724,	
2017-07-12 16:20:12,733 Epoch[10] Batch [1230]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.128715,	
2017-07-12 16:20:17,797 Epoch[10] Batch [1240]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.128716,	
2017-07-12 16:20:22,846 Epoch[10] Batch [1250]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.128759,	
2017-07-12 16:20:28,269 Epoch[10] Batch [1260]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.128743,	
2017-07-12 16:20:33,932 Epoch[10] Batch [1270]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.128850,	
2017-07-12 16:20:39,425 Epoch[10] Batch [1280]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.128877,	
2017-07-12 16:20:44,830 Epoch[10] Batch [1290]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.128837,	
2017-07-12 16:20:49,869 Epoch[10] Batch [1300]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.128811,	
2017-07-12 16:20:54,823 Epoch[10] Batch [1310]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.128705,	
2017-07-12 16:20:59,929 Epoch[10] Batch [1320]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.128848,	
2017-07-12 16:21:05,441 Epoch[10] Batch [1330]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.128787,	
2017-07-12 16:21:10,697 Epoch[10] Batch [1340]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.128644,	
2017-07-12 16:21:17,097 Epoch[10] Batch [1350]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.128707,	
2017-07-12 16:21:22,721 Epoch[10] Batch [1360]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.128701,	
2017-07-12 16:21:28,298 Epoch[10] Batch [1370]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.128609,	
2017-07-12 16:21:33,685 Epoch[10] Batch [1380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.128613,	
2017-07-12 16:21:39,317 Epoch[10] Batch [1390]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.128651,	
2017-07-12 16:21:44,639 Epoch[10] Batch [1400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.128710,	
2017-07-12 16:21:50,081 Epoch[10] Batch [1410]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.128632,	
2017-07-12 16:21:55,291 Epoch[10] Batch [1420]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.128570,	
2017-07-12 16:22:00,350 Epoch[10] Batch [1430]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.128536,	
2017-07-12 16:22:05,442 Epoch[10] Batch [1440]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.128530,	
2017-07-12 16:22:10,798 Epoch[10] Batch [1450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.128597,	
2017-07-12 16:22:15,997 Epoch[10] Batch [1460]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.128558,	
2017-07-12 16:22:21,957 Epoch[10] Batch [1470]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.128577,	
2017-07-12 16:22:27,029 Epoch[10] Batch [1480]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.128639,	
2017-07-12 16:22:30,057 Epoch[10] Train-FCNLogLoss=0.128594
2017-07-12 16:22:30,057 Epoch[10] Time cost=775.733
2017-07-12 16:22:30,979 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0011.params"
2017-07-12 16:22:34,082 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0011.states"
2017-07-12 16:22:39,868 Epoch[11] Batch [10]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.131432,	
2017-07-12 16:22:45,109 Epoch[11] Batch [20]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.139598,	
2017-07-12 16:22:50,585 Epoch[11] Batch [30]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.137775,	
2017-07-12 16:22:55,961 Epoch[11] Batch [40]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.134948,	
2017-07-12 16:23:00,920 Epoch[11] Batch [50]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.130148,	
2017-07-12 16:23:06,081 Epoch[11] Batch [60]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.126707,	
2017-07-12 16:23:11,140 Epoch[11] Batch [70]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.127073,	
2017-07-12 16:23:16,780 Epoch[11] Batch [80]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.126605,	
2017-07-12 16:23:22,337 Epoch[11] Batch [90]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.125898,	
2017-07-12 16:23:27,617 Epoch[11] Batch [100]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125128,	
2017-07-12 16:23:33,183 Epoch[11] Batch [110]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.124739,	
2017-07-12 16:23:38,023 Epoch[11] Batch [120]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.124093,	
2017-07-12 16:23:43,421 Epoch[11] Batch [130]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.124504,	
2017-07-12 16:23:48,500 Epoch[11] Batch [140]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.125166,	
2017-07-12 16:23:54,195 Epoch[11] Batch [150]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.125535,	
2017-07-12 16:23:59,294 Epoch[11] Batch [160]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.125845,	
2017-07-12 16:24:04,149 Epoch[11] Batch [170]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.125375,	
2017-07-12 16:24:09,398 Epoch[11] Batch [180]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.126521,	
2017-07-12 16:24:14,725 Epoch[11] Batch [190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125572,	
2017-07-12 16:24:19,784 Epoch[11] Batch [200]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.125066,	
2017-07-12 16:24:25,012 Epoch[11] Batch [210]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.124911,	
2017-07-12 16:24:30,243 Epoch[11] Batch [220]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.124982,	
2017-07-12 16:24:35,471 Epoch[11] Batch [230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.124947,	
2017-07-12 16:24:40,792 Epoch[11] Batch [240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125064,	
2017-07-12 16:24:46,041 Epoch[11] Batch [250]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.125356,	
2017-07-12 16:24:51,336 Epoch[11] Batch [260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125205,	
2017-07-12 16:24:56,332 Epoch[11] Batch [270]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.125271,	
2017-07-12 16:25:01,607 Epoch[11] Batch [280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125005,	
2017-07-12 16:25:06,757 Epoch[11] Batch [290]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.125035,	
2017-07-12 16:25:11,773 Epoch[11] Batch [300]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.125245,	
2017-07-12 16:25:17,043 Epoch[11] Batch [310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.125642,	
2017-07-12 16:25:22,675 Epoch[11] Batch [320]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.125469,	
2017-07-12 16:25:27,656 Epoch[11] Batch [330]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.125826,	
2017-07-12 16:25:33,000 Epoch[11] Batch [340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125712,	
2017-07-12 16:25:38,318 Epoch[11] Batch [350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.126180,	
2017-07-12 16:25:43,593 Epoch[11] Batch [360]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125949,	
2017-07-12 16:25:48,848 Epoch[11] Batch [370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.125641,	
2017-07-12 16:25:54,035 Epoch[11] Batch [380]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.125741,	
2017-07-12 16:25:59,225 Epoch[11] Batch [390]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.125680,	
2017-07-12 16:26:04,259 Epoch[11] Batch [400]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.125386,	
2017-07-12 16:26:09,303 Epoch[11] Batch [410]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.124737,	
2017-07-12 16:26:14,411 Epoch[11] Batch [420]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.124662,	
2017-07-12 16:26:19,639 Epoch[11] Batch [430]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.124521,	
2017-07-12 16:26:24,621 Epoch[11] Batch [440]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.124761,	
2017-07-12 16:26:29,737 Epoch[11] Batch [450]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.124206,	
2017-07-12 16:26:35,519 Epoch[11] Batch [460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.124177,	
2017-07-12 16:26:40,801 Epoch[11] Batch [470]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.124056,	
2017-07-12 16:26:45,964 Epoch[11] Batch [480]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.123772,	
2017-07-12 16:26:50,949 Epoch[11] Batch [490]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.123655,	
2017-07-12 16:26:56,341 Epoch[11] Batch [500]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.123457,	
2017-07-12 16:27:02,344 Epoch[11] Batch [510]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.123329,	
2017-07-12 16:27:07,858 Epoch[11] Batch [520]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.123650,	
2017-07-12 16:27:13,168 Epoch[11] Batch [530]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.123641,	
2017-07-12 16:27:18,736 Epoch[11] Batch [540]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.123789,	
2017-07-12 16:27:24,090 Epoch[11] Batch [550]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.123877,	
2017-07-12 16:27:29,472 Epoch[11] Batch [560]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.123946,	
2017-07-12 16:27:34,936 Epoch[11] Batch [570]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.123980,	
2017-07-12 16:27:39,896 Epoch[11] Batch [580]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.123886,	
2017-07-12 16:27:45,104 Epoch[11] Batch [590]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.124045,	
2017-07-12 16:27:50,523 Epoch[11] Batch [600]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.124206,	
2017-07-12 16:27:56,185 Epoch[11] Batch [610]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.124251,	
2017-07-12 16:28:01,538 Epoch[11] Batch [620]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124316,	
2017-07-12 16:28:06,403 Epoch[11] Batch [630]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.124280,	
2017-07-12 16:28:11,738 Epoch[11] Batch [640]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124370,	
2017-07-12 16:28:17,132 Epoch[11] Batch [650]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.124478,	
2017-07-12 16:28:22,160 Epoch[11] Batch [660]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.124612,	
2017-07-12 16:28:27,000 Epoch[11] Batch [670]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.124607,	
2017-07-12 16:28:31,173 Epoch[11] Batch [680]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.124539,	
2017-07-12 16:28:35,809 Epoch[11] Batch [690]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.124777,	
2017-07-12 16:28:41,317 Epoch[11] Batch [700]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.124681,	
2017-07-12 16:28:46,333 Epoch[11] Batch [710]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.124793,	
2017-07-12 16:28:51,505 Epoch[11] Batch [720]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.124918,	
2017-07-12 16:28:56,613 Epoch[11] Batch [730]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.124884,	
2017-07-12 16:29:01,611 Epoch[11] Batch [740]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.124933,	
2017-07-12 16:29:06,540 Epoch[11] Batch [750]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.124940,	
2017-07-12 16:29:11,504 Epoch[11] Batch [760]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.124976,	
2017-07-12 16:29:16,483 Epoch[11] Batch [770]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.124847,	
2017-07-12 16:29:21,481 Epoch[11] Batch [780]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.124734,	
2017-07-12 16:29:26,412 Epoch[11] Batch [790]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.124714,	
2017-07-12 16:29:31,534 Epoch[11] Batch [800]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.124670,	
2017-07-12 16:29:36,576 Epoch[11] Batch [810]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.124624,	
2017-07-12 16:29:41,720 Epoch[11] Batch [820]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.124634,	
2017-07-12 16:29:46,749 Epoch[11] Batch [830]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.124577,	
2017-07-12 16:29:51,700 Epoch[11] Batch [840]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.124391,	
2017-07-12 16:29:56,878 Epoch[11] Batch [850]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.124407,	
2017-07-12 16:30:02,427 Epoch[11] Batch [860]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.124367,	
2017-07-12 16:30:07,733 Epoch[11] Batch [870]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124375,	
2017-07-12 16:30:12,944 Epoch[11] Batch [880]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.124386,	
2017-07-12 16:30:18,162 Epoch[11] Batch [890]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.124236,	
2017-07-12 16:30:23,506 Epoch[11] Batch [900]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124295,	
2017-07-12 16:30:29,513 Epoch[11] Batch [910]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.124147,	
2017-07-12 16:30:34,862 Epoch[11] Batch [920]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124141,	
2017-07-12 16:30:40,124 Epoch[11] Batch [930]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124129,	
2017-07-12 16:30:45,182 Epoch[11] Batch [940]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.124109,	
2017-07-12 16:30:50,287 Epoch[11] Batch [950]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.124322,	
2017-07-12 16:30:55,527 Epoch[11] Batch [960]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.124307,	
2017-07-12 16:31:00,884 Epoch[11] Batch [970]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124329,	
2017-07-12 16:31:05,945 Epoch[11] Batch [980]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.124551,	
2017-07-12 16:31:11,035 Epoch[11] Batch [990]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.124609,	
2017-07-12 16:31:16,116 Epoch[11] Batch [1000]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.124759,	
2017-07-12 16:31:21,691 Epoch[11] Batch [1010]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.124820,	
2017-07-12 16:31:27,707 Epoch[11] Batch [1020]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.124993,	
2017-07-12 16:31:33,472 Epoch[11] Batch [1030]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.125129,	
2017-07-12 16:31:39,032 Epoch[11] Batch [1040]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.125626,	
2017-07-12 16:31:44,048 Epoch[11] Batch [1050]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.125728,	
2017-07-12 16:31:49,428 Epoch[11] Batch [1060]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125844,	
2017-07-12 16:31:54,823 Epoch[11] Batch [1070]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.125994,	
2017-07-12 16:31:59,971 Epoch[11] Batch [1080]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.125938,	
2017-07-12 16:32:05,131 Epoch[11] Batch [1090]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.125971,	
2017-07-12 16:32:10,025 Epoch[11] Batch [1100]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.125930,	
2017-07-12 16:32:15,096 Epoch[11] Batch [1110]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.125915,	
2017-07-12 16:32:20,019 Epoch[11] Batch [1120]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.125943,	
2017-07-12 16:32:24,843 Epoch[11] Batch [1130]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.125960,	
2017-07-12 16:32:30,040 Epoch[11] Batch [1140]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.126135,	
2017-07-12 16:32:34,907 Epoch[11] Batch [1150]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.126332,	
2017-07-12 16:32:39,856 Epoch[11] Batch [1160]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.126353,	
2017-07-12 16:32:44,977 Epoch[11] Batch [1170]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.126347,	
2017-07-12 16:32:50,119 Epoch[11] Batch [1180]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.126388,	
2017-07-12 16:32:54,977 Epoch[11] Batch [1190]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.126515,	
2017-07-12 16:33:00,193 Epoch[11] Batch [1200]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.126481,	
2017-07-12 16:33:05,646 Epoch[11] Batch [1210]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.126433,	
2017-07-12 16:33:11,019 Epoch[11] Batch [1220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.126452,	
2017-07-12 16:33:16,087 Epoch[11] Batch [1230]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.126485,	
2017-07-12 16:33:21,337 Epoch[11] Batch [1240]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.126595,	
2017-07-12 16:33:26,412 Epoch[11] Batch [1250]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.126763,	
2017-07-12 16:33:31,665 Epoch[11] Batch [1260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.126765,	
2017-07-12 16:33:36,788 Epoch[11] Batch [1270]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.126691,	
2017-07-12 16:33:41,820 Epoch[11] Batch [1280]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.126629,	
2017-07-12 16:33:47,249 Epoch[11] Batch [1290]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.126488,	
2017-07-12 16:33:52,633 Epoch[11] Batch [1300]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.126500,	
2017-07-12 16:33:57,868 Epoch[11] Batch [1310]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.126565,	
2017-07-12 16:34:02,735 Epoch[11] Batch [1320]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.126446,	
2017-07-12 16:34:08,336 Epoch[11] Batch [1330]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.126416,	
2017-07-12 16:34:13,708 Epoch[11] Batch [1340]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.126371,	
2017-07-12 16:34:19,512 Epoch[11] Batch [1350]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.126396,	
2017-07-12 16:34:24,417 Epoch[11] Batch [1360]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.126434,	
2017-07-12 16:34:29,878 Epoch[11] Batch [1370]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.126382,	
2017-07-12 16:34:35,196 Epoch[11] Batch [1380]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.126404,	
2017-07-12 16:34:40,485 Epoch[11] Batch [1390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.126286,	
2017-07-12 16:34:45,963 Epoch[11] Batch [1400]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.126265,	
2017-07-12 16:34:51,344 Epoch[11] Batch [1410]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.126343,	
2017-07-12 16:34:56,719 Epoch[11] Batch [1420]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.126238,	
2017-07-12 16:35:01,767 Epoch[11] Batch [1430]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.126348,	
2017-07-12 16:35:06,777 Epoch[11] Batch [1440]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.126316,	
2017-07-12 16:35:11,901 Epoch[11] Batch [1450]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.126366,	
2017-07-12 16:35:17,129 Epoch[11] Batch [1460]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.126249,	
2017-07-12 16:35:23,016 Epoch[11] Batch [1470]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.126116,	
2017-07-12 16:35:28,432 Epoch[11] Batch [1480]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.126022,	
2017-07-12 16:35:31,955 Epoch[11] Train-FCNLogLoss=0.126027
2017-07-12 16:35:31,955 Epoch[11] Time cost=777.873
2017-07-12 16:35:32,855 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0012.params"
2017-07-12 16:35:36,080 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0012.states"
2017-07-12 16:35:42,649 Epoch[12] Batch [10]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.133509,	
2017-07-12 16:35:47,854 Epoch[12] Batch [20]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126180,	
2017-07-12 16:35:52,851 Epoch[12] Batch [30]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.136013,	
2017-07-12 16:35:58,247 Epoch[12] Batch [40]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.132200,	
2017-07-12 16:36:03,340 Epoch[12] Batch [50]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.130942,	
2017-07-12 16:36:08,555 Epoch[12] Batch [60]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.128796,	
2017-07-12 16:36:14,506 Epoch[12] Batch [70]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.128102,	
2017-07-12 16:36:20,035 Epoch[12] Batch [80]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.128906,	
2017-07-12 16:36:26,154 Epoch[12] Batch [90]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.128666,	
2017-07-12 16:36:31,678 Epoch[12] Batch [100]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.126824,	
2017-07-12 16:36:37,540 Epoch[12] Batch [110]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.126997,	
2017-07-12 16:36:43,463 Epoch[12] Batch [120]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.127770,	
2017-07-12 16:36:48,400 Epoch[12] Batch [130]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.126209,	
2017-07-12 16:36:53,955 Epoch[12] Batch [140]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.126328,	
2017-07-12 16:36:58,955 Epoch[12] Batch [150]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.126845,	
2017-07-12 16:37:04,154 Epoch[12] Batch [160]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.125571,	
2017-07-12 16:37:09,729 Epoch[12] Batch [170]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.125523,	
2017-07-12 16:37:15,281 Epoch[12] Batch [180]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.125067,	
2017-07-12 16:37:20,974 Epoch[12] Batch [190]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.124429,	
2017-07-12 16:37:26,617 Epoch[12] Batch [200]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.124582,	
2017-07-12 16:37:32,385 Epoch[12] Batch [210]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.124089,	
2017-07-12 16:37:37,900 Epoch[12] Batch [220]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.123777,	
2017-07-12 16:37:43,080 Epoch[12] Batch [230]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.124218,	
2017-07-12 16:37:49,218 Epoch[12] Batch [240]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.123571,	
2017-07-12 16:37:54,892 Epoch[12] Batch [250]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.123714,	
2017-07-12 16:38:00,834 Epoch[12] Batch [260]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.123644,	
2017-07-12 16:38:06,642 Epoch[12] Batch [270]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.123484,	
2017-07-12 16:38:12,150 Epoch[12] Batch [280]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.123196,	
2017-07-12 16:38:17,845 Epoch[12] Batch [290]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.123180,	
2017-07-12 16:38:23,335 Epoch[12] Batch [300]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.123182,	
2017-07-12 16:38:28,501 Epoch[12] Batch [310]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.123298,	
2017-07-12 16:38:33,556 Epoch[12] Batch [320]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.124077,	
2017-07-12 16:38:38,629 Epoch[12] Batch [330]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.124094,	
2017-07-12 16:38:44,036 Epoch[12] Batch [340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.123626,	
2017-07-12 16:38:49,508 Epoch[12] Batch [350]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.123632,	
2017-07-12 16:38:54,270 Epoch[12] Batch [360]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.123549,	
2017-07-12 16:38:59,582 Epoch[12] Batch [370]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124185,	
2017-07-12 16:39:04,717 Epoch[12] Batch [380]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.124219,	
2017-07-12 16:39:10,487 Epoch[12] Batch [390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.124152,	
2017-07-12 16:39:15,664 Epoch[12] Batch [400]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.124247,	
2017-07-12 16:39:24,028 Epoch[12] Batch [410]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.124231,	
2017-07-12 16:39:37,992 Epoch[12] Batch [420]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.123941,	
2017-07-12 16:39:51,328 Epoch[12] Batch [430]	Speed: 3.00 samples/sec	Train-FCNLogLoss=0.124049,	
2017-07-12 16:40:03,843 Epoch[12] Batch [440]	Speed: 3.20 samples/sec	Train-FCNLogLoss=0.123821,	
2017-07-12 16:40:14,417 Epoch[12] Batch [450]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.123855,	
2017-07-12 16:40:25,261 Epoch[12] Batch [460]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.123832,	
2017-07-12 16:40:35,657 Epoch[12] Batch [470]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.123418,	
2017-07-12 16:40:45,404 Epoch[12] Batch [480]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.123375,	
2017-07-12 16:40:56,190 Epoch[12] Batch [490]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.123609,	
2017-07-12 16:41:05,290 Epoch[12] Batch [500]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.123770,	
2017-07-12 16:41:13,853 Epoch[12] Batch [510]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.123984,	
2017-07-12 16:41:21,557 Epoch[12] Batch [520]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.124295,	
2017-07-12 16:41:28,700 Epoch[12] Batch [530]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.124192,	
2017-07-12 16:41:35,890 Epoch[12] Batch [540]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.124145,	
2017-07-12 16:41:42,872 Epoch[12] Batch [550]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.124378,	
2017-07-12 16:41:49,411 Epoch[12] Batch [560]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.124215,	
2017-07-12 16:41:55,470 Epoch[12] Batch [570]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.124433,	
2017-07-12 16:42:01,313 Epoch[12] Batch [580]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.124602,	
2017-07-12 16:42:07,718 Epoch[12] Batch [590]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.124502,	
2017-07-12 16:42:13,755 Epoch[12] Batch [600]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.124550,	
2017-07-12 16:42:20,095 Epoch[12] Batch [610]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.124503,	
2017-07-12 16:42:26,762 Epoch[12] Batch [620]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.124248,	
2017-07-12 16:42:32,660 Epoch[12] Batch [630]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.124284,	
2017-07-12 16:42:38,899 Epoch[12] Batch [640]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.124174,	
2017-07-12 16:42:45,616 Epoch[12] Batch [650]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.124316,	
2017-07-12 16:42:51,834 Epoch[12] Batch [660]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.124226,	
2017-07-12 16:42:58,575 Epoch[12] Batch [670]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.124043,	
2017-07-12 16:43:05,305 Epoch[12] Batch [680]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.123957,	
2017-07-12 16:43:11,882 Epoch[12] Batch [690]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.124006,	
2017-07-12 16:43:18,209 Epoch[12] Batch [700]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.123960,	
2017-07-12 16:43:24,654 Epoch[12] Batch [710]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.123904,	
2017-07-12 16:43:31,220 Epoch[12] Batch [720]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.123721,	
2017-07-12 16:43:37,761 Epoch[12] Batch [730]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.123771,	
2017-07-12 16:43:43,573 Epoch[12] Batch [740]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.123731,	
2017-07-12 16:43:49,732 Epoch[12] Batch [750]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.123543,	
2017-07-12 16:43:55,575 Epoch[12] Batch [760]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.123612,	
2017-07-12 16:44:01,502 Epoch[12] Batch [770]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.123533,	
2017-07-12 16:44:07,721 Epoch[12] Batch [780]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.123717,	
2017-07-12 16:44:13,241 Epoch[12] Batch [790]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.123691,	
2017-07-12 16:44:18,879 Epoch[12] Batch [800]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.123694,	
2017-07-12 16:44:24,641 Epoch[12] Batch [810]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.123541,	
2017-07-12 16:44:30,243 Epoch[12] Batch [820]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.123509,	
2017-07-12 16:44:35,924 Epoch[12] Batch [830]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.123683,	
2017-07-12 16:44:41,817 Epoch[12] Batch [840]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.123768,	
2017-07-12 16:44:47,906 Epoch[12] Batch [850]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.123769,	
2017-07-12 16:44:53,951 Epoch[12] Batch [860]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.123752,	
2017-07-12 16:44:59,611 Epoch[12] Batch [870]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.123790,	
2017-07-12 16:45:05,007 Epoch[12] Batch [880]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.124009,	
2017-07-12 16:45:10,869 Epoch[12] Batch [890]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.124013,	
2017-07-12 16:45:16,561 Epoch[12] Batch [900]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.123919,	
2017-07-12 16:45:22,419 Epoch[12] Batch [910]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.123861,	
2017-07-12 16:45:27,949 Epoch[12] Batch [920]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.123748,	
2017-07-12 16:45:33,672 Epoch[12] Batch [930]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.123725,	
2017-07-12 16:45:39,069 Epoch[12] Batch [940]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.123970,	
2017-07-12 16:45:44,824 Epoch[12] Batch [950]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.123980,	
2017-07-12 16:45:50,587 Epoch[12] Batch [960]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.124067,	
2017-07-12 16:45:56,037 Epoch[12] Batch [970]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.124028,	
2017-07-12 16:46:01,942 Epoch[12] Batch [980]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.124226,	
2017-07-12 16:46:08,181 Epoch[12] Batch [990]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.124406,	
2017-07-12 16:46:13,869 Epoch[12] Batch [1000]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.124356,	
2017-07-12 16:46:20,223 Epoch[12] Batch [1010]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.124353,	
2017-07-12 16:46:26,207 Epoch[12] Batch [1020]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.124250,	
2017-07-12 16:46:32,250 Epoch[12] Batch [1030]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.124264,	
2017-07-12 16:46:37,885 Epoch[12] Batch [1040]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.124184,	
2017-07-12 16:46:44,046 Epoch[12] Batch [1050]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.124061,	
2017-07-12 16:46:50,102 Epoch[12] Batch [1060]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.124013,	
2017-07-12 16:46:56,191 Epoch[12] Batch [1070]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.123961,	
2017-07-12 16:47:01,920 Epoch[12] Batch [1080]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.124129,	
2017-07-12 16:47:07,774 Epoch[12] Batch [1090]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.124147,	
2017-07-12 16:47:13,431 Epoch[12] Batch [1100]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.124089,	
2017-07-12 16:47:19,335 Epoch[12] Batch [1110]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.124011,	
2017-07-12 16:47:24,957 Epoch[12] Batch [1120]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.124312,	
2017-07-12 16:47:30,822 Epoch[12] Batch [1130]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.124428,	
2017-07-12 16:47:36,655 Epoch[12] Batch [1140]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.124437,	
2017-07-12 16:47:42,394 Epoch[12] Batch [1150]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.124416,	
2017-07-12 16:47:48,633 Epoch[12] Batch [1160]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.124569,	
2017-07-12 16:47:54,521 Epoch[12] Batch [1170]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.124477,	
2017-07-12 16:48:00,566 Epoch[12] Batch [1180]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.124467,	
2017-07-12 16:48:06,573 Epoch[12] Batch [1190]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.124406,	
2017-07-12 16:48:12,735 Epoch[12] Batch [1200]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.124336,	
2017-07-12 16:48:17,696 Epoch[12] Batch [1210]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.124231,	
2017-07-12 16:48:22,427 Epoch[12] Batch [1220]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.124278,	
2017-07-12 16:48:27,103 Epoch[12] Batch [1230]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.124237,	
2017-07-12 16:48:32,581 Epoch[12] Batch [1240]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.124269,	
2017-07-12 16:48:38,457 Epoch[12] Batch [1250]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.124259,	
2017-07-12 16:48:44,716 Epoch[12] Batch [1260]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.124261,	
2017-07-12 16:48:50,655 Epoch[12] Batch [1270]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.124202,	
2017-07-12 16:49:03,191 Epoch[12] Batch [1280]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.124192,	
2017-07-12 16:49:15,485 Epoch[12] Batch [1290]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.124197,	
2017-07-12 16:49:29,710 Epoch[12] Batch [1300]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.124140,	
2017-07-12 16:49:42,665 Epoch[12] Batch [1310]	Speed: 3.09 samples/sec	Train-FCNLogLoss=0.124051,	
2017-07-12 16:49:53,160 Epoch[12] Batch [1320]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.124024,	
2017-07-12 16:50:03,560 Epoch[12] Batch [1330]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.123924,	
2017-07-12 16:50:12,217 Epoch[12] Batch [1340]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.123777,	
2017-07-12 16:50:22,161 Epoch[12] Batch [1350]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.123780,	
2017-07-12 16:50:31,583 Epoch[12] Batch [1360]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.123811,	
2017-07-12 16:50:38,867 Epoch[12] Batch [1370]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.123784,	
2017-07-12 16:50:47,267 Epoch[12] Batch [1380]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.123897,	
2017-07-12 16:50:54,574 Epoch[12] Batch [1390]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.123929,	
2017-07-12 16:51:00,914 Epoch[12] Batch [1400]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.123908,	
2017-07-12 16:51:07,327 Epoch[12] Batch [1410]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.123905,	
2017-07-12 16:51:14,514 Epoch[12] Batch [1420]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.123876,	
2017-07-12 16:51:20,691 Epoch[12] Batch [1430]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.123869,	
2017-07-12 16:51:26,937 Epoch[12] Batch [1440]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.123879,	
2017-07-12 16:51:33,704 Epoch[12] Batch [1450]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.124066,	
2017-07-12 16:51:40,150 Epoch[12] Batch [1460]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.124146,	
2017-07-12 16:51:46,985 Epoch[12] Batch [1470]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.124095,	
2017-07-12 16:51:53,283 Epoch[12] Batch [1480]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.124138,	
2017-07-12 16:51:56,825 Epoch[12] Train-FCNLogLoss=0.124097
2017-07-12 16:51:56,825 Epoch[12] Time cost=980.745
2017-07-12 16:51:57,694 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0013.params"
2017-07-12 16:52:01,156 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0013.states"
2017-07-12 16:52:07,655 Epoch[13] Batch [10]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.095197,	
2017-07-12 16:52:15,687 Epoch[13] Batch [20]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.103781,	
2017-07-12 16:52:23,247 Epoch[13] Batch [30]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.105644,	
2017-07-12 16:52:30,015 Epoch[13] Batch [40]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.108083,	
2017-07-12 16:52:36,397 Epoch[13] Batch [50]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.107688,	
2017-07-12 16:52:42,264 Epoch[13] Batch [60]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.107526,	
2017-07-12 16:52:48,079 Epoch[13] Batch [70]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108860,	
2017-07-12 16:52:53,898 Epoch[13] Batch [80]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.109425,	
2017-07-12 16:52:59,501 Epoch[13] Batch [90]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.110984,	
2017-07-12 16:53:04,549 Epoch[13] Batch [100]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.113719,	
2017-07-12 16:53:09,881 Epoch[13] Batch [110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113613,	
2017-07-12 16:53:15,024 Epoch[13] Batch [120]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.113449,	
2017-07-12 16:53:20,562 Epoch[13] Batch [130]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.113381,	
2017-07-12 16:53:25,724 Epoch[13] Batch [140]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.113816,	
2017-07-12 16:53:31,267 Epoch[13] Batch [150]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.113873,	
2017-07-12 16:53:36,488 Epoch[13] Batch [160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.113686,	
2017-07-12 16:53:42,489 Epoch[13] Batch [170]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.113071,	
2017-07-12 16:53:47,486 Epoch[13] Batch [180]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.113464,	
2017-07-12 16:53:53,026 Epoch[13] Batch [190]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.114387,	
2017-07-12 16:53:58,466 Epoch[13] Batch [200]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.114513,	
2017-07-12 16:54:03,625 Epoch[13] Batch [210]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.114689,	
2017-07-12 16:54:09,036 Epoch[13] Batch [220]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.114958,	
2017-07-12 16:54:14,488 Epoch[13] Batch [230]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.115117,	
2017-07-12 16:54:19,756 Epoch[13] Batch [240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.114993,	
2017-07-12 16:54:24,903 Epoch[13] Batch [250]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.114951,	
2017-07-12 16:54:30,525 Epoch[13] Batch [260]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.115110,	
2017-07-12 16:54:36,038 Epoch[13] Batch [270]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.115516,	
2017-07-12 16:54:41,559 Epoch[13] Batch [280]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.115068,	
2017-07-12 16:54:47,261 Epoch[13] Batch [290]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.115202,	
2017-07-12 16:54:52,795 Epoch[13] Batch [300]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.115763,	
2017-07-12 16:54:58,283 Epoch[13] Batch [310]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.116047,	
2017-07-12 16:55:03,895 Epoch[13] Batch [320]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.117489,	
2017-07-12 16:55:09,446 Epoch[13] Batch [330]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.117845,	
2017-07-12 16:55:14,535 Epoch[13] Batch [340]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.118925,	
2017-07-12 16:55:19,839 Epoch[13] Batch [350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119197,	
2017-07-12 16:55:25,050 Epoch[13] Batch [360]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.119078,	
2017-07-12 16:55:30,563 Epoch[13] Batch [370]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.119526,	
2017-07-12 16:55:36,113 Epoch[13] Batch [380]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.119703,	
2017-07-12 16:55:41,522 Epoch[13] Batch [390]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.119659,	
2017-07-12 16:55:46,974 Epoch[13] Batch [400]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.119808,	
2017-07-12 16:55:52,270 Epoch[13] Batch [410]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.119704,	
2017-07-12 16:55:57,491 Epoch[13] Batch [420]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.119520,	
2017-07-12 16:56:03,080 Epoch[13] Batch [430]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.119464,	
2017-07-12 16:56:08,593 Epoch[13] Batch [440]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.119911,	
2017-07-12 16:56:14,120 Epoch[13] Batch [450]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.120132,	
2017-07-12 16:56:19,601 Epoch[13] Batch [460]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.119921,	
2017-07-12 16:56:25,217 Epoch[13] Batch [470]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.119944,	
2017-07-12 16:56:30,554 Epoch[13] Batch [480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119905,	
2017-07-12 16:56:36,096 Epoch[13] Batch [490]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.119863,	
2017-07-12 16:56:43,030 Epoch[13] Batch [500]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.119642,	
2017-07-12 16:56:53,072 Epoch[13] Batch [510]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.119562,	
2017-07-12 16:57:03,572 Epoch[13] Batch [520]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.119283,	
2017-07-12 16:57:13,043 Epoch[13] Batch [530]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.119689,	
2017-07-12 16:57:23,286 Epoch[13] Batch [540]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.119352,	
2017-07-12 16:57:32,948 Epoch[13] Batch [550]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.119462,	
2017-07-12 16:57:41,639 Epoch[13] Batch [560]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.119580,	
2017-07-12 16:57:46,505 Epoch[13] Batch [570]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.119523,	
2017-07-12 16:57:51,203 Epoch[13] Batch [580]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.119445,	
2017-07-12 16:57:55,467 Epoch[13] Batch [590]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.119464,	
2017-07-12 16:57:59,961 Epoch[13] Batch [600]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.119502,	
2017-07-12 16:58:04,746 Epoch[13] Batch [610]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.119444,	
2017-07-12 16:58:09,238 Epoch[13] Batch [620]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.119441,	
2017-07-12 16:58:19,654 Epoch[13] Batch [630]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.119411,	
2017-07-12 16:58:31,868 Epoch[13] Batch [640]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.119665,	
2017-07-12 16:58:43,588 Epoch[13] Batch [650]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.119659,	
2017-07-12 16:58:54,847 Epoch[13] Batch [660]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.119612,	
2017-07-12 16:59:03,935 Epoch[13] Batch [670]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.119785,	
2017-07-12 16:59:13,227 Epoch[13] Batch [680]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.119678,	
2017-07-12 16:59:22,643 Epoch[13] Batch [690]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.119976,	
2017-07-12 16:59:30,435 Epoch[13] Batch [700]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.120145,	
2017-07-12 16:59:37,743 Epoch[13] Batch [710]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.120127,	
2017-07-12 16:59:46,972 Epoch[13] Batch [720]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.120486,	
2017-07-12 16:59:54,266 Epoch[13] Batch [730]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.120542,	
2017-07-12 17:00:01,695 Epoch[13] Batch [740]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.120400,	
2017-07-12 17:00:08,322 Epoch[13] Batch [750]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.120282,	
2017-07-12 17:00:14,180 Epoch[13] Batch [760]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.120294,	
2017-07-12 17:00:20,170 Epoch[13] Batch [770]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.120214,	
2017-07-12 17:00:26,196 Epoch[13] Batch [780]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.120382,	
2017-07-12 17:00:31,580 Epoch[13] Batch [790]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.120380,	
2017-07-12 17:00:37,057 Epoch[13] Batch [800]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.120377,	
2017-07-12 17:00:42,109 Epoch[13] Batch [810]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.120427,	
2017-07-12 17:00:47,349 Epoch[13] Batch [820]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.120582,	
2017-07-12 17:00:52,544 Epoch[13] Batch [830]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.120569,	
2017-07-12 17:00:57,545 Epoch[13] Batch [840]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.120601,	
2017-07-12 17:01:02,818 Epoch[13] Batch [850]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.120443,	
2017-07-12 17:01:08,047 Epoch[13] Batch [860]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.120384,	
2017-07-12 17:01:13,812 Epoch[13] Batch [870]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.120541,	
2017-07-12 17:01:18,995 Epoch[13] Batch [880]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120393,	
2017-07-12 17:01:24,494 Epoch[13] Batch [890]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.120361,	
2017-07-12 17:01:29,502 Epoch[13] Batch [900]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.120520,	
2017-07-12 17:01:34,515 Epoch[13] Batch [910]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.120428,	
2017-07-12 17:01:39,670 Epoch[13] Batch [920]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.120333,	
2017-07-12 17:01:44,764 Epoch[13] Batch [930]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.120321,	
2017-07-12 17:01:49,555 Epoch[13] Batch [940]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.120356,	
2017-07-12 17:01:54,635 Epoch[13] Batch [950]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.120272,	
2017-07-12 17:01:59,528 Epoch[13] Batch [960]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.120158,	
2017-07-12 17:02:04,764 Epoch[13] Batch [970]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.120184,	
2017-07-12 17:02:10,187 Epoch[13] Batch [980]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.120178,	
2017-07-12 17:02:15,664 Epoch[13] Batch [990]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.120214,	
2017-07-12 17:02:21,339 Epoch[13] Batch [1000]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.120127,	
2017-07-12 17:02:26,439 Epoch[13] Batch [1010]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.120136,	
2017-07-12 17:02:31,672 Epoch[13] Batch [1020]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.120171,	
2017-07-12 17:02:36,567 Epoch[13] Batch [1030]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.120295,	
2017-07-12 17:02:41,612 Epoch[13] Batch [1040]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.120264,	
2017-07-12 17:02:46,424 Epoch[13] Batch [1050]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.120310,	
2017-07-12 17:02:51,390 Epoch[13] Batch [1060]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.120244,	
2017-07-12 17:02:56,305 Epoch[13] Batch [1070]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.120293,	
2017-07-12 17:03:01,119 Epoch[13] Batch [1080]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.120134,	
2017-07-12 17:03:06,140 Epoch[13] Batch [1090]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.120024,	
2017-07-12 17:03:10,996 Epoch[13] Batch [1100]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.120306,	
2017-07-12 17:03:15,957 Epoch[13] Batch [1110]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.120336,	
2017-07-12 17:03:20,899 Epoch[13] Batch [1120]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.120376,	
2017-07-12 17:03:25,777 Epoch[13] Batch [1130]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.120403,	
2017-07-12 17:03:30,818 Epoch[13] Batch [1140]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.120406,	
2017-07-12 17:03:36,098 Epoch[13] Batch [1150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.120288,	
2017-07-12 17:03:41,120 Epoch[13] Batch [1160]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.120334,	
2017-07-12 17:03:46,263 Epoch[13] Batch [1170]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.120595,	
2017-07-12 17:03:51,080 Epoch[13] Batch [1180]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.120943,	
2017-07-12 17:03:56,056 Epoch[13] Batch [1190]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.120986,	
2017-07-12 17:04:01,159 Epoch[13] Batch [1200]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.121007,	
2017-07-12 17:04:06,226 Epoch[13] Batch [1210]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.121075,	
2017-07-12 17:04:11,137 Epoch[13] Batch [1220]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.121038,	
2017-07-12 17:04:16,097 Epoch[13] Batch [1230]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.120975,	
2017-07-12 17:04:21,086 Epoch[13] Batch [1240]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.120865,	
2017-07-12 17:04:26,693 Epoch[13] Batch [1250]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.120857,	
2017-07-12 17:04:31,709 Epoch[13] Batch [1260]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.120841,	
2017-07-12 17:04:37,000 Epoch[13] Batch [1270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.120803,	
2017-07-12 17:04:42,037 Epoch[13] Batch [1280]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.120793,	
2017-07-12 17:04:47,083 Epoch[13] Batch [1290]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.120667,	
2017-07-12 17:04:52,432 Epoch[13] Batch [1300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.120677,	
2017-07-12 17:04:57,813 Epoch[13] Batch [1310]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.120638,	
2017-07-12 17:05:02,924 Epoch[13] Batch [1320]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.120591,	
2017-07-12 17:05:08,276 Epoch[13] Batch [1330]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.120495,	
2017-07-12 17:05:13,393 Epoch[13] Batch [1340]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.120557,	
2017-07-12 17:05:18,385 Epoch[13] Batch [1350]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.120542,	
2017-07-12 17:05:23,711 Epoch[13] Batch [1360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.120601,	
2017-07-12 17:05:28,501 Epoch[13] Batch [1370]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.120501,	
2017-07-12 17:05:33,426 Epoch[13] Batch [1380]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.120457,	
2017-07-12 17:05:38,615 Epoch[13] Batch [1390]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.120344,	
2017-07-12 17:05:43,573 Epoch[13] Batch [1400]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.120313,	
2017-07-12 17:05:48,494 Epoch[13] Batch [1410]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.120346,	
2017-07-12 17:05:53,525 Epoch[13] Batch [1420]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.120322,	
2017-07-12 17:05:58,650 Epoch[13] Batch [1430]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.120361,	
2017-07-12 17:06:03,835 Epoch[13] Batch [1440]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.120281,	
2017-07-12 17:06:08,776 Epoch[13] Batch [1450]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.120226,	
2017-07-12 17:06:13,913 Epoch[13] Batch [1460]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.120241,	
2017-07-12 17:06:18,964 Epoch[13] Batch [1470]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.120175,	
2017-07-12 17:06:24,227 Epoch[13] Batch [1480]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.120198,	
2017-07-12 17:06:27,145 Epoch[13] Train-FCNLogLoss=0.120156
2017-07-12 17:06:27,145 Epoch[13] Time cost=865.989
2017-07-12 17:06:28,086 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0014.params"
2017-07-12 17:06:31,379 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0014.states"
2017-07-12 17:06:37,136 Epoch[14] Batch [10]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.111467,	
2017-07-12 17:06:42,034 Epoch[14] Batch [20]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.116230,	
2017-07-12 17:06:46,879 Epoch[14] Batch [30]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.119594,	
2017-07-12 17:06:51,776 Epoch[14] Batch [40]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.117929,	
2017-07-12 17:06:56,689 Epoch[14] Batch [50]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.118661,	
2017-07-12 17:07:01,355 Epoch[14] Batch [60]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.117667,	
2017-07-12 17:07:06,468 Epoch[14] Batch [70]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.117538,	
2017-07-12 17:07:11,482 Epoch[14] Batch [80]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.117025,	
2017-07-12 17:07:17,152 Epoch[14] Batch [90]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.116314,	
2017-07-12 17:07:22,349 Epoch[14] Batch [100]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.116045,	
2017-07-12 17:07:27,559 Epoch[14] Batch [110]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.116305,	
2017-07-12 17:07:32,612 Epoch[14] Batch [120]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.115957,	
2017-07-12 17:07:37,484 Epoch[14] Batch [130]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.115850,	
2017-07-12 17:07:42,484 Epoch[14] Batch [140]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.115037,	
2017-07-12 17:07:47,401 Epoch[14] Batch [150]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.115698,	
2017-07-12 17:07:52,380 Epoch[14] Batch [160]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.115540,	
2017-07-12 17:07:57,527 Epoch[14] Batch [170]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.116185,	
2017-07-12 17:08:02,949 Epoch[14] Batch [180]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.117509,	
2017-07-12 17:08:08,298 Epoch[14] Batch [190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118350,	
2017-07-12 17:08:13,240 Epoch[14] Batch [200]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.118430,	
2017-07-12 17:08:18,568 Epoch[14] Batch [210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.118476,	
2017-07-12 17:08:23,456 Epoch[14] Batch [220]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.118888,	
2017-07-12 17:08:28,969 Epoch[14] Batch [230]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.118395,	
2017-07-12 17:08:34,505 Epoch[14] Batch [240]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.117992,	
2017-07-12 17:08:39,437 Epoch[14] Batch [250]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.117345,	
2017-07-12 17:08:44,746 Epoch[14] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.117309,	
2017-07-12 17:08:49,987 Epoch[14] Batch [270]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.119000,	
2017-07-12 17:08:54,793 Epoch[14] Batch [280]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.118789,	
2017-07-12 17:08:59,728 Epoch[14] Batch [290]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.118666,	
2017-07-12 17:09:04,470 Epoch[14] Batch [300]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.119006,	
2017-07-12 17:09:08,988 Epoch[14] Batch [310]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.118783,	
2017-07-12 17:09:13,571 Epoch[14] Batch [320]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.118431,	
2017-07-12 17:09:18,461 Epoch[14] Batch [330]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.118327,	
2017-07-12 17:09:23,494 Epoch[14] Batch [340]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.118439,	
2017-07-12 17:09:28,541 Epoch[14] Batch [350]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.118046,	
2017-07-12 17:09:33,848 Epoch[14] Batch [360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.117990,	
2017-07-12 17:09:39,393 Epoch[14] Batch [370]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.118173,	
2017-07-12 17:09:45,132 Epoch[14] Batch [380]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.118625,	
2017-07-12 17:09:50,024 Epoch[14] Batch [390]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.124021,	
2017-07-12 17:09:55,001 Epoch[14] Batch [400]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.124582,	
2017-07-12 17:09:59,865 Epoch[14] Batch [410]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.125904,	
2017-07-12 17:10:04,962 Epoch[14] Batch [420]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.126609,	
2017-07-12 17:10:14,928 Epoch[14] Batch [430]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.127050,	
2017-07-12 17:10:27,762 Epoch[14] Batch [440]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.127647,	
2017-07-12 17:10:40,862 Epoch[14] Batch [450]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.128252,	
2017-07-12 17:10:52,943 Epoch[14] Batch [460]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.128426,	
2017-07-12 17:11:02,965 Epoch[14] Batch [470]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.128867,	
2017-07-12 17:11:12,777 Epoch[14] Batch [480]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.128538,	
2017-07-12 17:11:21,918 Epoch[14] Batch [490]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.128376,	
2017-07-12 17:11:31,569 Epoch[14] Batch [500]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.128374,	
2017-07-12 17:11:41,044 Epoch[14] Batch [510]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.128300,	
2017-07-12 17:11:49,155 Epoch[14] Batch [520]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.128147,	
2017-07-12 17:11:57,611 Epoch[14] Batch [530]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.127800,	
2017-07-12 17:12:05,541 Epoch[14] Batch [540]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.127564,	
2017-07-12 17:12:13,293 Epoch[14] Batch [550]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.127297,	
2017-07-12 17:12:20,570 Epoch[14] Batch [560]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.127064,	
2017-07-12 17:12:28,764 Epoch[14] Batch [570]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.126893,	
2017-07-12 17:12:35,921 Epoch[14] Batch [580]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.126724,	
2017-07-12 17:12:43,456 Epoch[14] Batch [590]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.126535,	
2017-07-12 17:12:50,812 Epoch[14] Batch [600]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.126237,	
2017-07-12 17:12:56,655 Epoch[14] Batch [610]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.126104,	
2017-07-12 17:13:01,536 Epoch[14] Batch [620]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.126279,	
2017-07-12 17:13:06,198 Epoch[14] Batch [630]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.126177,	
2017-07-12 17:13:10,880 Epoch[14] Batch [640]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.126119,	
2017-07-12 17:13:15,218 Epoch[14] Batch [650]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.126054,	
2017-07-12 17:13:19,490 Epoch[14] Batch [660]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.126118,	
2017-07-12 17:13:23,974 Epoch[14] Batch [670]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.126032,	
2017-07-12 17:13:28,388 Epoch[14] Batch [680]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.126022,	
2017-07-12 17:13:32,473 Epoch[14] Batch [690]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.126121,	
2017-07-12 17:13:36,736 Epoch[14] Batch [700]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.126072,	
2017-07-12 17:13:41,058 Epoch[14] Batch [710]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.125905,	
2017-07-12 17:13:45,226 Epoch[14] Batch [720]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.125799,	
2017-07-12 17:13:49,387 Epoch[14] Batch [730]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.125568,	
2017-07-12 17:13:53,516 Epoch[14] Batch [740]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.125434,	
2017-07-12 17:13:57,624 Epoch[14] Batch [750]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.125248,	
2017-07-12 17:14:01,787 Epoch[14] Batch [760]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.124969,	
2017-07-12 17:14:05,933 Epoch[14] Batch [770]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.124871,	
2017-07-12 17:14:10,024 Epoch[14] Batch [780]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.124616,	
2017-07-12 17:14:14,278 Epoch[14] Batch [790]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.124632,	
2017-07-12 17:14:18,558 Epoch[14] Batch [800]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.124318,	
2017-07-12 17:14:22,701 Epoch[14] Batch [810]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.124348,	
2017-07-12 17:14:27,009 Epoch[14] Batch [820]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.124247,	
2017-07-12 17:14:31,101 Epoch[14] Batch [830]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.124233,	
2017-07-12 17:14:35,356 Epoch[14] Batch [840]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.124155,	
2017-07-12 17:14:39,504 Epoch[14] Batch [850]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.124088,	
2017-07-12 17:14:43,583 Epoch[14] Batch [860]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.124123,	
2017-07-12 17:14:47,614 Epoch[14] Batch [870]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.124155,	
2017-07-12 17:14:51,763 Epoch[14] Batch [880]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.123969,	
2017-07-12 17:14:55,977 Epoch[14] Batch [890]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.123842,	
2017-07-12 17:15:00,049 Epoch[14] Batch [900]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.124136,	
2017-07-12 17:15:04,181 Epoch[14] Batch [910]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.124349,	
2017-07-12 17:15:08,430 Epoch[14] Batch [920]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.124154,	
2017-07-12 17:15:12,505 Epoch[14] Batch [930]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.124076,	
2017-07-12 17:15:16,644 Epoch[14] Batch [940]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.124018,	
2017-07-12 17:15:20,825 Epoch[14] Batch [950]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.124103,	
2017-07-12 17:15:24,919 Epoch[14] Batch [960]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.123913,	
2017-07-12 17:15:28,951 Epoch[14] Batch [970]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.123761,	
2017-07-12 17:15:33,225 Epoch[14] Batch [980]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.123689,	
2017-07-12 17:15:37,302 Epoch[14] Batch [990]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.123469,	
2017-07-12 17:15:41,434 Epoch[14] Batch [1000]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.123621,	
2017-07-12 17:15:45,569 Epoch[14] Batch [1010]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.123526,	
2017-07-12 17:15:49,878 Epoch[14] Batch [1020]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.123536,	
2017-07-12 17:15:54,006 Epoch[14] Batch [1030]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.123430,	
2017-07-12 17:15:58,092 Epoch[14] Batch [1040]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.123367,	
2017-07-12 17:16:02,165 Epoch[14] Batch [1050]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.123255,	
2017-07-12 17:16:06,262 Epoch[14] Batch [1060]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.123182,	
2017-07-12 17:16:10,479 Epoch[14] Batch [1070]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.123143,	
2017-07-12 17:16:14,703 Epoch[14] Batch [1080]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.123100,	
2017-07-12 17:16:18,861 Epoch[14] Batch [1090]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.122960,	
2017-07-12 17:16:22,935 Epoch[14] Batch [1100]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.122892,	
2017-07-12 17:16:27,167 Epoch[14] Batch [1110]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.122798,	
2017-07-12 17:16:31,200 Epoch[14] Batch [1120]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.122600,	
2017-07-12 17:16:35,372 Epoch[14] Batch [1130]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.122590,	
2017-07-12 17:16:39,476 Epoch[14] Batch [1140]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.122657,	
2017-07-12 17:16:43,832 Epoch[14] Batch [1150]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.122675,	
2017-07-12 17:16:47,726 Epoch[14] Batch [1160]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.122533,	
2017-07-12 17:16:51,981 Epoch[14] Batch [1170]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.122522,	
2017-07-12 17:16:56,083 Epoch[14] Batch [1180]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.122574,	
2017-07-12 17:17:00,280 Epoch[14] Batch [1190]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.122383,	
2017-07-12 17:17:04,461 Epoch[14] Batch [1200]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.122419,	
2017-07-12 17:17:08,750 Epoch[14] Batch [1210]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.122447,	
2017-07-12 17:17:12,821 Epoch[14] Batch [1220]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.122602,	
2017-07-12 17:17:16,905 Epoch[14] Batch [1230]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.122612,	
2017-07-12 17:17:20,992 Epoch[14] Batch [1240]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.122584,	
2017-07-12 17:17:25,318 Epoch[14] Batch [1250]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.122658,	
2017-07-12 17:17:29,357 Epoch[14] Batch [1260]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.122613,	
2017-07-12 17:17:33,579 Epoch[14] Batch [1270]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.122676,	
2017-07-12 17:17:37,734 Epoch[14] Batch [1280]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.122653,	
2017-07-12 17:17:41,868 Epoch[14] Batch [1290]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.122639,	
2017-07-12 17:17:46,002 Epoch[14] Batch [1300]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.122656,	
2017-07-12 17:17:50,356 Epoch[14] Batch [1310]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.122519,	
2017-07-12 17:17:54,692 Epoch[14] Batch [1320]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.122587,	
2017-07-12 17:17:58,929 Epoch[14] Batch [1330]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.122521,	
2017-07-12 17:18:03,341 Epoch[14] Batch [1340]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.122586,	
2017-07-12 17:18:08,110 Epoch[14] Batch [1350]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.122555,	
2017-07-12 17:18:12,282 Epoch[14] Batch [1360]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.122497,	
2017-07-12 17:18:16,417 Epoch[14] Batch [1370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.122520,	
2017-07-12 17:18:20,743 Epoch[14] Batch [1380]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.122449,	
2017-07-12 17:18:24,860 Epoch[14] Batch [1390]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.122519,	
2017-07-12 17:18:29,030 Epoch[14] Batch [1400]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.122397,	
2017-07-12 17:18:33,282 Epoch[14] Batch [1410]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.122363,	
2017-07-12 17:18:37,891 Epoch[14] Batch [1420]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.122376,	
2017-07-12 17:18:42,125 Epoch[14] Batch [1430]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.122212,	
2017-07-12 17:18:46,290 Epoch[14] Batch [1440]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.122163,	
2017-07-12 17:18:50,366 Epoch[14] Batch [1450]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.122084,	
2017-07-12 17:18:54,632 Epoch[14] Batch [1460]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.121990,	
2017-07-12 17:18:58,917 Epoch[14] Batch [1470]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.121982,	
2017-07-12 17:19:03,197 Epoch[14] Batch [1480]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.122033,	
2017-07-12 17:19:05,826 Epoch[14] Train-FCNLogLoss=0.121991
2017-07-12 17:19:05,826 Epoch[14] Time cost=754.447
2017-07-12 17:19:06,673 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0015.params"
2017-07-12 17:19:08,661 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0015.states"
2017-07-12 17:19:13,718 Epoch[15] Batch [10]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.115209,	
2017-07-12 17:19:18,087 Epoch[15] Batch [20]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.109521,	
2017-07-12 17:19:22,383 Epoch[15] Batch [30]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.111371,	
2017-07-12 17:19:26,886 Epoch[15] Batch [40]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.108492,	
2017-07-12 17:19:30,941 Epoch[15] Batch [50]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.107462,	
2017-07-12 17:19:35,080 Epoch[15] Batch [60]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.107589,	
2017-07-12 17:19:39,396 Epoch[15] Batch [70]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.107582,	
2017-07-12 17:19:43,713 Epoch[15] Batch [80]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.106415,	
2017-07-12 17:19:48,311 Epoch[15] Batch [90]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.107130,	
2017-07-12 17:19:53,032 Epoch[15] Batch [100]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.108156,	
2017-07-12 17:19:57,070 Epoch[15] Batch [110]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.110348,	
2017-07-12 17:20:01,702 Epoch[15] Batch [120]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.111035,	
2017-07-12 17:20:05,904 Epoch[15] Batch [130]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.110469,	
2017-07-12 17:20:09,998 Epoch[15] Batch [140]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110469,	
2017-07-12 17:20:14,132 Epoch[15] Batch [150]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.110840,	
2017-07-12 17:20:18,440 Epoch[15] Batch [160]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.111169,	
2017-07-12 17:20:22,780 Epoch[15] Batch [170]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.111707,	
2017-07-12 17:20:27,157 Epoch[15] Batch [180]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.111564,	
2017-07-12 17:20:31,363 Epoch[15] Batch [190]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.111330,	
2017-07-12 17:20:35,587 Epoch[15] Batch [200]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.111359,	
2017-07-12 17:20:39,915 Epoch[15] Batch [210]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.111159,	
2017-07-12 17:20:44,282 Epoch[15] Batch [220]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.110528,	
2017-07-12 17:20:48,991 Epoch[15] Batch [230]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.110862,	
2017-07-12 17:20:53,384 Epoch[15] Batch [240]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.111490,	
2017-07-12 17:20:57,818 Epoch[15] Batch [250]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111370,	
2017-07-12 17:21:02,534 Epoch[15] Batch [260]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.111353,	
2017-07-12 17:21:06,696 Epoch[15] Batch [270]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.111711,	
2017-07-12 17:21:11,064 Epoch[15] Batch [280]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.111854,	
2017-07-12 17:21:15,617 Epoch[15] Batch [290]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.112225,	
2017-07-12 17:21:19,892 Epoch[15] Batch [300]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.112168,	
2017-07-12 17:21:24,296 Epoch[15] Batch [310]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.112273,	
2017-07-12 17:21:28,793 Epoch[15] Batch [320]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.112603,	
2017-07-12 17:21:33,227 Epoch[15] Batch [330]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.112884,	
2017-07-12 17:21:37,731 Epoch[15] Batch [340]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.112805,	
2017-07-12 17:21:42,126 Epoch[15] Batch [350]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.113124,	
2017-07-12 17:21:46,440 Epoch[15] Batch [360]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.113080,	
2017-07-12 17:21:50,995 Epoch[15] Batch [370]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.113084,	
2017-07-12 17:21:55,335 Epoch[15] Batch [380]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.113878,	
2017-07-12 17:22:00,010 Epoch[15] Batch [390]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.113751,	
2017-07-12 17:22:04,446 Epoch[15] Batch [400]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.113850,	
2017-07-12 17:22:08,918 Epoch[15] Batch [410]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.114236,	
2017-07-12 17:22:13,277 Epoch[15] Batch [420]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.114052,	
2017-07-12 17:22:17,620 Epoch[15] Batch [430]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.114473,	
2017-07-12 17:22:22,164 Epoch[15] Batch [440]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.114514,	
2017-07-12 17:22:26,898 Epoch[15] Batch [450]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.114344,	
2017-07-12 17:22:31,547 Epoch[15] Batch [460]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.114389,	
2017-07-12 17:22:36,556 Epoch[15] Batch [470]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.114405,	
2017-07-12 17:22:41,182 Epoch[15] Batch [480]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.114475,	
2017-07-12 17:22:45,482 Epoch[15] Batch [490]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.114522,	
2017-07-12 17:22:49,892 Epoch[15] Batch [500]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.114777,	
2017-07-12 17:22:54,544 Epoch[15] Batch [510]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.114780,	
2017-07-12 17:22:59,453 Epoch[15] Batch [520]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.114974,	
2017-07-12 17:23:04,249 Epoch[15] Batch [530]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.115315,	
2017-07-12 17:23:08,564 Epoch[15] Batch [540]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.115511,	
2017-07-12 17:23:13,363 Epoch[15] Batch [550]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.115584,	
2017-07-12 17:23:18,311 Epoch[15] Batch [560]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.115491,	
2017-07-12 17:23:22,723 Epoch[15] Batch [570]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.115365,	
2017-07-12 17:23:27,395 Epoch[15] Batch [580]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.115308,	
2017-07-12 17:23:32,424 Epoch[15] Batch [590]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.115466,	
2017-07-12 17:23:37,139 Epoch[15] Batch [600]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.115402,	
2017-07-12 17:23:41,883 Epoch[15] Batch [610]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.115680,	
2017-07-12 17:23:46,870 Epoch[15] Batch [620]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.115696,	
2017-07-12 17:23:51,986 Epoch[15] Batch [630]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.115796,	
2017-07-12 17:23:56,763 Epoch[15] Batch [640]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.115867,	
2017-07-12 17:24:01,412 Epoch[15] Batch [650]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.115918,	
2017-07-12 17:24:05,758 Epoch[15] Batch [660]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.115883,	
2017-07-12 17:24:10,737 Epoch[15] Batch [670]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.115903,	
2017-07-12 17:24:15,061 Epoch[15] Batch [680]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.115864,	
2017-07-12 17:24:19,697 Epoch[15] Batch [690]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.115720,	
2017-07-12 17:24:24,264 Epoch[15] Batch [700]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.115730,	
2017-07-12 17:24:28,460 Epoch[15] Batch [710]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.115489,	
2017-07-12 17:24:32,724 Epoch[15] Batch [720]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.115537,	
2017-07-12 17:24:37,116 Epoch[15] Batch [730]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.115505,	
2017-07-12 17:24:41,618 Epoch[15] Batch [740]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.115478,	
2017-07-12 17:24:46,168 Epoch[15] Batch [750]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.115332,	
2017-07-12 17:24:51,236 Epoch[15] Batch [760]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.115222,	
2017-07-12 17:24:55,887 Epoch[15] Batch [770]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.115305,	
2017-07-12 17:25:00,395 Epoch[15] Batch [780]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.115163,	
2017-07-12 17:25:05,109 Epoch[15] Batch [790]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.115186,	
2017-07-12 17:25:09,633 Epoch[15] Batch [800]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.115083,	
2017-07-12 17:25:14,207 Epoch[15] Batch [810]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.115004,	
2017-07-12 17:25:18,437 Epoch[15] Batch [820]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.115086,	
2017-07-12 17:25:22,931 Epoch[15] Batch [830]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.115031,	
2017-07-12 17:25:27,564 Epoch[15] Batch [840]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.115030,	
2017-07-12 17:25:32,020 Epoch[15] Batch [850]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.115037,	
2017-07-12 17:25:36,863 Epoch[15] Batch [860]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.115242,	
2017-07-12 17:25:41,662 Epoch[15] Batch [870]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.115269,	
2017-07-12 17:25:46,606 Epoch[15] Batch [880]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.115144,	
2017-07-12 17:25:51,386 Epoch[15] Batch [890]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.114980,	
2017-07-12 17:25:55,703 Epoch[15] Batch [900]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.114992,	
2017-07-12 17:26:00,076 Epoch[15] Batch [910]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.115414,	
2017-07-12 17:26:05,389 Epoch[15] Batch [920]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.115434,	
2017-07-12 17:26:09,932 Epoch[15] Batch [930]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.115432,	
2017-07-12 17:26:14,395 Epoch[15] Batch [940]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.115553,	
2017-07-12 17:26:19,304 Epoch[15] Batch [950]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.115618,	
2017-07-12 17:26:24,226 Epoch[15] Batch [960]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.115711,	
2017-07-12 17:26:28,761 Epoch[15] Batch [970]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.115766,	
2017-07-12 17:26:33,808 Epoch[15] Batch [980]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.115804,	
2017-07-12 17:26:38,673 Epoch[15] Batch [990]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.115791,	
2017-07-12 17:26:43,880 Epoch[15] Batch [1000]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.115874,	
2017-07-12 17:26:48,566 Epoch[15] Batch [1010]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.115904,	
2017-07-12 17:26:53,015 Epoch[15] Batch [1020]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.116030,	
2017-07-12 17:26:57,567 Epoch[15] Batch [1030]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.115987,	
2017-07-12 17:27:02,656 Epoch[15] Batch [1040]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.116049,	
2017-07-12 17:27:07,474 Epoch[15] Batch [1050]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.115992,	
2017-07-12 17:27:12,357 Epoch[15] Batch [1060]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.115925,	
2017-07-12 17:27:17,439 Epoch[15] Batch [1070]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.116000,	
2017-07-12 17:27:22,090 Epoch[15] Batch [1080]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.115990,	
2017-07-12 17:27:26,549 Epoch[15] Batch [1090]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.115923,	
2017-07-12 17:27:31,238 Epoch[15] Batch [1100]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.116034,	
2017-07-12 17:27:35,747 Epoch[15] Batch [1110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.115897,	
2017-07-12 17:27:40,322 Epoch[15] Batch [1120]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.115868,	
2017-07-12 17:27:45,218 Epoch[15] Batch [1130]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.115874,	
2017-07-12 17:27:49,795 Epoch[15] Batch [1140]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.115862,	
2017-07-12 17:27:54,876 Epoch[15] Batch [1150]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.115817,	
2017-07-12 17:27:59,666 Epoch[15] Batch [1160]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.115657,	
2017-07-12 17:28:04,908 Epoch[15] Batch [1170]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.115699,	
2017-07-12 17:28:09,449 Epoch[15] Batch [1180]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.115642,	
2017-07-12 17:28:14,254 Epoch[15] Batch [1190]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.115707,	
2017-07-12 17:28:18,854 Epoch[15] Batch [1200]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.115612,	
2017-07-12 17:28:23,614 Epoch[15] Batch [1210]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.115731,	
2017-07-12 17:28:28,467 Epoch[15] Batch [1220]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.115801,	
2017-07-12 17:28:32,978 Epoch[15] Batch [1230]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.115964,	
2017-07-12 17:28:37,859 Epoch[15] Batch [1240]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.116010,	
2017-07-12 17:28:42,755 Epoch[15] Batch [1250]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.116025,	
2017-07-12 17:28:47,310 Epoch[15] Batch [1260]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.116109,	
2017-07-12 17:28:51,952 Epoch[15] Batch [1270]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.116187,	
2017-07-12 17:28:56,727 Epoch[15] Batch [1280]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.116234,	
2017-07-12 17:29:01,599 Epoch[15] Batch [1290]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.116272,	
2017-07-12 17:29:06,528 Epoch[15] Batch [1300]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.116311,	
2017-07-12 17:29:11,299 Epoch[15] Batch [1310]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.116321,	
2017-07-12 17:29:15,999 Epoch[15] Batch [1320]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.116270,	
2017-07-12 17:29:20,701 Epoch[15] Batch [1330]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.116211,	
2017-07-12 17:29:25,688 Epoch[15] Batch [1340]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.116211,	
2017-07-12 17:29:30,665 Epoch[15] Batch [1350]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.116215,	
2017-07-12 17:29:35,678 Epoch[15] Batch [1360]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.116232,	
2017-07-12 17:29:40,490 Epoch[15] Batch [1370]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.116115,	
2017-07-12 17:29:45,560 Epoch[15] Batch [1380]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.116356,	
2017-07-12 17:29:50,231 Epoch[15] Batch [1390]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.116365,	
2017-07-12 17:29:55,078 Epoch[15] Batch [1400]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.116471,	
2017-07-12 17:29:59,929 Epoch[15] Batch [1410]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.116488,	
2017-07-12 17:30:04,959 Epoch[15] Batch [1420]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.116428,	
2017-07-12 17:30:10,179 Epoch[15] Batch [1430]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.116336,	
2017-07-12 17:30:15,253 Epoch[15] Batch [1440]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.116293,	
2017-07-12 17:30:19,888 Epoch[15] Batch [1450]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.116286,	
2017-07-12 17:30:24,938 Epoch[15] Batch [1460]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.116412,	
2017-07-12 17:30:29,625 Epoch[15] Batch [1470]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.116481,	
2017-07-12 17:30:33,663 Epoch[15] Batch [1480]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.116489,	
2017-07-12 17:30:36,622 Epoch[15] Train-FCNLogLoss=0.116488
2017-07-12 17:30:36,622 Epoch[15] Time cost=687.961
2017-07-12 17:30:37,480 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0016.params"
2017-07-12 17:30:39,290 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0016.states"
2017-07-12 17:30:45,684 Epoch[16] Batch [10]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.124974,	
2017-07-12 17:30:50,983 Epoch[16] Batch [20]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.117840,	
2017-07-12 17:30:55,709 Epoch[16] Batch [30]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.118699,	
2017-07-12 17:31:00,598 Epoch[16] Batch [40]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.123423,	
2017-07-12 17:31:05,795 Epoch[16] Batch [50]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.125048,	
2017-07-12 17:31:11,036 Epoch[16] Batch [60]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.123568,	
2017-07-12 17:31:16,424 Epoch[16] Batch [70]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.122948,	
2017-07-12 17:31:21,414 Epoch[16] Batch [80]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.121992,	
2017-07-12 17:31:26,645 Epoch[16] Batch [90]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.121456,	
2017-07-12 17:31:31,501 Epoch[16] Batch [100]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.121745,	
2017-07-12 17:31:36,464 Epoch[16] Batch [110]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.121606,	
2017-07-12 17:31:41,461 Epoch[16] Batch [120]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.120304,	
2017-07-12 17:31:46,453 Epoch[16] Batch [130]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.120333,	
2017-07-12 17:31:51,419 Epoch[16] Batch [140]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.119800,	
2017-07-12 17:31:56,334 Epoch[16] Batch [150]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.119649,	
2017-07-12 17:32:01,516 Epoch[16] Batch [160]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.119631,	
2017-07-12 17:32:06,583 Epoch[16] Batch [170]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.118956,	
2017-07-12 17:32:11,460 Epoch[16] Batch [180]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.118980,	
2017-07-12 17:32:16,995 Epoch[16] Batch [190]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.118360,	
2017-07-12 17:32:22,624 Epoch[16] Batch [200]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.118113,	
2017-07-12 17:32:28,047 Epoch[16] Batch [210]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.117602,	
2017-07-12 17:32:33,212 Epoch[16] Batch [220]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.118132,	
2017-07-12 17:32:38,704 Epoch[16] Batch [230]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.117837,	
2017-07-12 17:32:44,472 Epoch[16] Batch [240]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.117531,	
2017-07-12 17:32:50,123 Epoch[16] Batch [250]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.117466,	
2017-07-12 17:32:55,585 Epoch[16] Batch [260]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.117604,	
2017-07-12 17:33:01,094 Epoch[16] Batch [270]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.116859,	
2017-07-12 17:33:06,578 Epoch[16] Batch [280]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.116615,	
2017-07-12 17:33:12,351 Epoch[16] Batch [290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.116288,	
2017-07-12 17:33:18,038 Epoch[16] Batch [300]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.116181,	
2017-07-12 17:33:23,524 Epoch[16] Batch [310]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.115935,	
2017-07-12 17:33:29,163 Epoch[16] Batch [320]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.115608,	
2017-07-12 17:33:34,628 Epoch[16] Batch [330]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.115358,	
2017-07-12 17:33:40,036 Epoch[16] Batch [340]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.115112,	
2017-07-12 17:33:45,288 Epoch[16] Batch [350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.115494,	
2017-07-12 17:33:50,881 Epoch[16] Batch [360]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.115407,	
2017-07-12 17:33:56,328 Epoch[16] Batch [370]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.115461,	
2017-07-12 17:34:02,001 Epoch[16] Batch [380]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.115058,	
2017-07-12 17:34:07,284 Epoch[16] Batch [390]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.115430,	
2017-07-12 17:34:13,022 Epoch[16] Batch [400]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.115626,	
2017-07-12 17:34:18,575 Epoch[16] Batch [410]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.115766,	
2017-07-12 17:34:24,148 Epoch[16] Batch [420]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.115934,	
2017-07-12 17:34:29,502 Epoch[16] Batch [430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.115948,	
2017-07-12 17:34:34,988 Epoch[16] Batch [440]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.116024,	
2017-07-12 17:34:39,924 Epoch[16] Batch [450]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.116241,	
2017-07-12 17:34:45,055 Epoch[16] Batch [460]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.116452,	
2017-07-12 17:34:50,050 Epoch[16] Batch [470]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.116301,	
2017-07-12 17:34:55,697 Epoch[16] Batch [480]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.116302,	
2017-07-12 17:35:00,896 Epoch[16] Batch [490]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.116192,	
2017-07-12 17:35:06,483 Epoch[16] Batch [500]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.116010,	
2017-07-12 17:35:12,138 Epoch[16] Batch [510]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.115876,	
2017-07-12 17:35:17,623 Epoch[16] Batch [520]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.115709,	
2017-07-12 17:35:23,335 Epoch[16] Batch [530]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.115660,	
2017-07-12 17:35:28,856 Epoch[16] Batch [540]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.115412,	
2017-07-12 17:35:34,302 Epoch[16] Batch [550]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.115310,	
2017-07-12 17:35:40,185 Epoch[16] Batch [560]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.115172,	
2017-07-12 17:35:45,407 Epoch[16] Batch [570]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.115183,	
2017-07-12 17:35:50,848 Epoch[16] Batch [580]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.114994,	
2017-07-12 17:35:56,442 Epoch[16] Batch [590]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.114981,	
2017-07-12 17:36:02,074 Epoch[16] Batch [600]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.114908,	
2017-07-12 17:36:07,231 Epoch[16] Batch [610]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.114872,	
2017-07-12 17:36:12,938 Epoch[16] Batch [620]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.114848,	
2017-07-12 17:36:18,559 Epoch[16] Batch [630]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.114741,	
2017-07-12 17:36:23,886 Epoch[16] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.114717,	
2017-07-12 17:36:29,113 Epoch[16] Batch [650]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.114621,	
2017-07-12 17:36:34,668 Epoch[16] Batch [660]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.114724,	
2017-07-12 17:36:40,522 Epoch[16] Batch [670]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.114746,	
2017-07-12 17:36:45,825 Epoch[16] Batch [680]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.114695,	
2017-07-12 17:36:51,555 Epoch[16] Batch [690]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.114789,	
2017-07-12 17:36:57,402 Epoch[16] Batch [700]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.114859,	
2017-07-12 17:37:02,961 Epoch[16] Batch [710]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.114646,	
2017-07-12 17:37:08,889 Epoch[16] Batch [720]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.114825,	
2017-07-12 17:37:14,557 Epoch[16] Batch [730]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.114687,	
2017-07-12 17:37:19,925 Epoch[16] Batch [740]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114548,	
2017-07-12 17:37:25,230 Epoch[16] Batch [750]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.114481,	
2017-07-12 17:37:30,561 Epoch[16] Batch [760]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.114621,	
2017-07-12 17:37:36,339 Epoch[16] Batch [770]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.114536,	
2017-07-12 17:37:41,700 Epoch[16] Batch [780]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.114496,	
2017-07-12 17:37:47,060 Epoch[16] Batch [790]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.114431,	
2017-07-12 17:37:52,609 Epoch[16] Batch [800]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.114490,	
2017-07-12 17:37:58,610 Epoch[16] Batch [810]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.114422,	
2017-07-12 17:38:04,332 Epoch[16] Batch [820]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.114419,	
2017-07-12 17:38:10,218 Epoch[16] Batch [830]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.114358,	
2017-07-12 17:38:15,821 Epoch[16] Batch [840]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.114459,	
2017-07-12 17:38:21,506 Epoch[16] Batch [850]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.114599,	
2017-07-12 17:38:26,913 Epoch[16] Batch [860]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.114573,	
2017-07-12 17:38:32,416 Epoch[16] Batch [870]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.114672,	
2017-07-12 17:38:38,313 Epoch[16] Batch [880]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.114616,	
2017-07-12 17:38:43,821 Epoch[16] Batch [890]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.114390,	
2017-07-12 17:38:49,403 Epoch[16] Batch [900]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.114400,	
2017-07-12 17:38:54,897 Epoch[16] Batch [910]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.114290,	
2017-07-12 17:39:00,362 Epoch[16] Batch [920]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.114420,	
2017-07-12 17:39:05,782 Epoch[16] Batch [930]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.114357,	
2017-07-12 17:39:11,614 Epoch[16] Batch [940]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.114248,	
2017-07-12 17:39:16,978 Epoch[16] Batch [950]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.114230,	
2017-07-12 17:39:22,298 Epoch[16] Batch [960]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114114,	
2017-07-12 17:39:27,738 Epoch[16] Batch [970]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.114192,	
2017-07-12 17:39:33,655 Epoch[16] Batch [980]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.114180,	
2017-07-12 17:39:39,017 Epoch[16] Batch [990]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.114320,	
2017-07-12 17:39:44,377 Epoch[16] Batch [1000]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.114246,	
2017-07-12 17:39:50,005 Epoch[16] Batch [1010]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.114151,	
2017-07-12 17:39:55,417 Epoch[16] Batch [1020]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.114010,	
2017-07-12 17:40:00,643 Epoch[16] Batch [1030]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.114227,	
2017-07-12 17:40:06,064 Epoch[16] Batch [1040]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.114218,	
2017-07-12 17:40:11,295 Epoch[16] Batch [1050]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.114244,	
2017-07-12 17:40:16,759 Epoch[16] Batch [1060]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.114177,	
2017-07-12 17:40:22,104 Epoch[16] Batch [1070]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.114212,	
2017-07-12 17:40:27,423 Epoch[16] Batch [1080]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114149,	
2017-07-12 17:40:32,706 Epoch[16] Batch [1090]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.114259,	
2017-07-12 17:40:38,122 Epoch[16] Batch [1100]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.114289,	
2017-07-12 17:40:43,578 Epoch[16] Batch [1110]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.114224,	
2017-07-12 17:40:48,835 Epoch[16] Batch [1120]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.114168,	
2017-07-12 17:40:54,242 Epoch[16] Batch [1130]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.114041,	
2017-07-12 17:41:00,010 Epoch[16] Batch [1140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.113847,	
2017-07-12 17:41:05,385 Epoch[16] Batch [1150]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.113865,	
2017-07-12 17:41:10,994 Epoch[16] Batch [1160]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.113854,	
2017-07-12 17:41:16,503 Epoch[16] Batch [1170]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.113843,	
2017-07-12 17:41:21,994 Epoch[16] Batch [1180]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.113739,	
2017-07-12 17:41:27,467 Epoch[16] Batch [1190]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.113773,	
2017-07-12 17:41:33,898 Epoch[16] Batch [1200]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.113757,	
2017-07-12 17:41:40,238 Epoch[16] Batch [1210]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.113730,	
2017-07-12 17:41:46,521 Epoch[16] Batch [1220]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.113655,	
2017-07-12 17:41:52,684 Epoch[16] Batch [1230]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.113639,	
2017-07-12 17:41:58,723 Epoch[16] Batch [1240]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.113574,	
2017-07-12 17:42:05,121 Epoch[16] Batch [1250]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.113699,	
2017-07-12 17:42:11,390 Epoch[16] Batch [1260]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.113493,	
2017-07-12 17:42:17,392 Epoch[16] Batch [1270]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.113609,	
2017-07-12 17:42:23,764 Epoch[16] Batch [1280]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.113638,	
2017-07-12 17:42:30,035 Epoch[16] Batch [1290]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.113725,	
2017-07-12 17:42:36,539 Epoch[16] Batch [1300]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.113819,	
2017-07-12 17:42:42,728 Epoch[16] Batch [1310]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.113743,	
2017-07-12 17:42:48,954 Epoch[16] Batch [1320]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.113755,	
2017-07-12 17:42:55,181 Epoch[16] Batch [1330]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.113689,	
2017-07-12 17:43:01,499 Epoch[16] Batch [1340]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.113671,	
2017-07-12 17:43:07,882 Epoch[16] Batch [1350]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.113613,	
2017-07-12 17:43:14,279 Epoch[16] Batch [1360]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.113568,	
2017-07-12 17:43:21,016 Epoch[16] Batch [1370]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.113558,	
2017-07-12 17:43:27,321 Epoch[16] Batch [1380]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.113569,	
2017-07-12 17:43:33,440 Epoch[16] Batch [1390]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.113525,	
2017-07-12 17:43:39,542 Epoch[16] Batch [1400]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.113547,	
2017-07-12 17:43:46,006 Epoch[16] Batch [1410]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.113586,	
2017-07-12 17:43:52,558 Epoch[16] Batch [1420]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.113715,	
2017-07-12 17:43:59,280 Epoch[16] Batch [1430]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.113636,	
2017-07-12 17:44:05,877 Epoch[16] Batch [1440]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.113598,	
2017-07-12 17:44:12,302 Epoch[16] Batch [1450]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.113728,	
2017-07-12 17:44:18,651 Epoch[16] Batch [1460]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.113708,	
2017-07-12 17:44:25,240 Epoch[16] Batch [1470]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.113655,	
2017-07-12 17:44:31,526 Epoch[16] Batch [1480]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.113658,	
2017-07-12 17:44:35,598 Epoch[16] Train-FCNLogLoss=0.113645
2017-07-12 17:44:35,598 Epoch[16] Time cost=836.308
2017-07-12 17:44:36,548 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0017.params"
2017-07-12 17:44:38,509 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0017.states"
2017-07-12 17:44:45,867 Epoch[17] Batch [10]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.104752,	
2017-07-12 17:44:51,989 Epoch[17] Batch [20]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.104430,	
2017-07-12 17:44:58,351 Epoch[17] Batch [30]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.105247,	
2017-07-12 17:45:04,691 Epoch[17] Batch [40]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.104812,	
2017-07-12 17:45:10,857 Epoch[17] Batch [50]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.104475,	
2017-07-12 17:45:17,071 Epoch[17] Batch [60]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.104263,	
2017-07-12 17:45:23,498 Epoch[17] Batch [70]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.104380,	
2017-07-12 17:45:30,288 Epoch[17] Batch [80]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.104853,	
2017-07-12 17:45:36,571 Epoch[17] Batch [90]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.105604,	
2017-07-12 17:45:42,996 Epoch[17] Batch [100]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.106606,	
2017-07-12 17:45:49,307 Epoch[17] Batch [110]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.107002,	
2017-07-12 17:45:55,574 Epoch[17] Batch [120]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.107196,	
2017-07-12 17:46:01,690 Epoch[17] Batch [130]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.105952,	
2017-07-12 17:46:07,854 Epoch[17] Batch [140]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.107027,	
2017-07-12 17:46:14,584 Epoch[17] Batch [150]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.106684,	
2017-07-12 17:46:21,014 Epoch[17] Batch [160]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.107376,	
2017-07-12 17:46:27,955 Epoch[17] Batch [170]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.107336,	
2017-07-12 17:46:34,552 Epoch[17] Batch [180]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.108415,	
2017-07-12 17:46:41,228 Epoch[17] Batch [190]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.108426,	
2017-07-12 17:46:48,021 Epoch[17] Batch [200]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.107793,	
2017-07-12 17:46:54,588 Epoch[17] Batch [210]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.107536,	
2017-07-12 17:47:01,061 Epoch[17] Batch [220]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.107753,	
2017-07-12 17:47:07,479 Epoch[17] Batch [230]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.107666,	
2017-07-12 17:47:13,805 Epoch[17] Batch [240]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.107466,	
2017-07-12 17:47:20,265 Epoch[17] Batch [250]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.107453,	
2017-07-12 17:47:26,945 Epoch[17] Batch [260]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.107733,	
2017-07-12 17:47:34,275 Epoch[17] Batch [270]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.107462,	
2017-07-12 17:47:40,649 Epoch[17] Batch [280]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.108045,	
2017-07-12 17:47:47,265 Epoch[17] Batch [290]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.108295,	
2017-07-12 17:47:53,555 Epoch[17] Batch [300]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.108438,	
2017-07-12 17:48:00,450 Epoch[17] Batch [310]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.108975,	
2017-07-12 17:48:06,951 Epoch[17] Batch [320]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.109140,	
2017-07-12 17:48:13,211 Epoch[17] Batch [330]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.108894,	
2017-07-12 17:48:19,674 Epoch[17] Batch [340]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.108738,	
2017-07-12 17:48:26,117 Epoch[17] Batch [350]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.108895,	
2017-07-12 17:48:32,556 Epoch[17] Batch [360]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.109267,	
2017-07-12 17:48:39,090 Epoch[17] Batch [370]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.109286,	
2017-07-12 17:48:45,416 Epoch[17] Batch [380]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.109118,	
2017-07-12 17:48:52,117 Epoch[17] Batch [390]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.108819,	
2017-07-12 17:48:58,600 Epoch[17] Batch [400]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.108631,	
2017-07-12 17:49:04,861 Epoch[17] Batch [410]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.108618,	
2017-07-12 17:49:11,498 Epoch[17] Batch [420]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.108535,	
2017-07-12 17:49:18,500 Epoch[17] Batch [430]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.108587,	
2017-07-12 17:49:25,045 Epoch[17] Batch [440]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.108640,	
2017-07-12 17:49:32,184 Epoch[17] Batch [450]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.108664,	
2017-07-12 17:49:38,739 Epoch[17] Batch [460]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.108598,	
2017-07-12 17:49:45,456 Epoch[17] Batch [470]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.108476,	
2017-07-12 17:49:52,143 Epoch[17] Batch [480]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.108342,	
2017-07-12 17:49:58,637 Epoch[17] Batch [490]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.108561,	
2017-07-12 17:50:05,079 Epoch[17] Batch [500]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.108382,	
2017-07-12 17:50:11,584 Epoch[17] Batch [510]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.108300,	
2017-07-12 17:50:18,079 Epoch[17] Batch [520]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.108425,	
2017-07-12 17:50:25,153 Epoch[17] Batch [530]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.108625,	
2017-07-12 17:50:31,702 Epoch[17] Batch [540]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.108681,	
2017-07-12 17:50:38,203 Epoch[17] Batch [550]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.108907,	
2017-07-12 17:50:44,390 Epoch[17] Batch [560]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.108911,	
2017-07-12 17:50:50,914 Epoch[17] Batch [570]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.109039,	
2017-07-12 17:50:57,261 Epoch[17] Batch [580]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.109028,	
2017-07-12 17:51:03,702 Epoch[17] Batch [590]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.109374,	
2017-07-12 17:51:10,135 Epoch[17] Batch [600]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.109558,	
2017-07-12 17:51:16,581 Epoch[17] Batch [610]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.109819,	
2017-07-12 17:51:23,106 Epoch[17] Batch [620]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.109603,	
2017-07-12 17:51:29,630 Epoch[17] Batch [630]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.109577,	
2017-07-12 17:51:36,092 Epoch[17] Batch [640]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.109386,	
2017-07-12 17:51:42,532 Epoch[17] Batch [650]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.109189,	
2017-07-12 17:51:48,922 Epoch[17] Batch [660]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.109143,	
2017-07-12 17:51:55,745 Epoch[17] Batch [670]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.109130,	
2017-07-12 17:52:02,593 Epoch[17] Batch [680]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.109014,	
2017-07-12 17:52:09,300 Epoch[17] Batch [690]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.109002,	
2017-07-12 17:52:15,895 Epoch[17] Batch [700]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.108899,	
2017-07-12 17:52:22,502 Epoch[17] Batch [710]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.109004,	
2017-07-12 17:52:28,935 Epoch[17] Batch [720]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.108977,	
2017-07-12 17:52:35,587 Epoch[17] Batch [730]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.109157,	
2017-07-12 17:52:42,302 Epoch[17] Batch [740]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.109141,	
2017-07-12 17:52:48,788 Epoch[17] Batch [750]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.109123,	
2017-07-12 17:52:55,452 Epoch[17] Batch [760]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109160,	
2017-07-12 17:53:01,988 Epoch[17] Batch [770]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.109177,	
2017-07-12 17:53:08,554 Epoch[17] Batch [780]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.109461,	
2017-07-12 17:53:15,295 Epoch[17] Batch [790]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.109610,	
2017-07-12 17:53:21,565 Epoch[17] Batch [800]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.109545,	
2017-07-12 17:53:28,339 Epoch[17] Batch [810]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.109588,	
2017-07-12 17:53:34,917 Epoch[17] Batch [820]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.109671,	
2017-07-12 17:53:41,783 Epoch[17] Batch [830]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.109919,	
2017-07-12 17:53:48,233 Epoch[17] Batch [840]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.109835,	
2017-07-12 17:53:54,692 Epoch[17] Batch [850]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.109848,	
2017-07-12 17:54:00,963 Epoch[17] Batch [860]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.109809,	
2017-07-12 17:54:07,379 Epoch[17] Batch [870]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.109866,	
2017-07-12 17:54:13,803 Epoch[17] Batch [880]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.109757,	
2017-07-12 17:54:20,402 Epoch[17] Batch [890]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.109749,	
2017-07-12 17:54:26,797 Epoch[17] Batch [900]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.109797,	
2017-07-12 17:54:33,261 Epoch[17] Batch [910]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.109825,	
2017-07-12 17:54:39,958 Epoch[17] Batch [920]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.109741,	
2017-07-12 17:54:46,753 Epoch[17] Batch [930]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.109650,	
2017-07-12 17:54:53,117 Epoch[17] Batch [940]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.109602,	
2017-07-12 17:54:59,846 Epoch[17] Batch [950]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.109670,	
2017-07-12 17:55:06,308 Epoch[17] Batch [960]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.109669,	
2017-07-12 17:55:12,895 Epoch[17] Batch [970]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.109620,	
2017-07-12 17:55:19,458 Epoch[17] Batch [980]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.109508,	
2017-07-12 17:55:25,964 Epoch[17] Batch [990]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.109509,	
2017-07-12 17:55:32,618 Epoch[17] Batch [1000]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.109624,	
2017-07-12 17:55:39,072 Epoch[17] Batch [1010]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.109720,	
2017-07-12 17:55:45,627 Epoch[17] Batch [1020]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.109722,	
2017-07-12 17:55:52,323 Epoch[17] Batch [1030]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.109720,	
2017-07-12 17:55:58,896 Epoch[17] Batch [1040]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.109670,	
2017-07-12 17:56:05,416 Epoch[17] Batch [1050]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.109719,	
2017-07-12 17:56:12,372 Epoch[17] Batch [1060]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.109847,	
2017-07-12 17:56:18,918 Epoch[17] Batch [1070]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.109926,	
2017-07-12 17:56:25,749 Epoch[17] Batch [1080]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.109919,	
2017-07-12 17:56:32,283 Epoch[17] Batch [1090]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.110014,	
2017-07-12 17:56:38,773 Epoch[17] Batch [1100]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.110192,	
2017-07-12 17:56:45,353 Epoch[17] Batch [1110]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.110255,	
2017-07-12 17:56:52,003 Epoch[17] Batch [1120]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.110330,	
2017-07-12 17:56:58,338 Epoch[17] Batch [1130]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.110356,	
2017-07-12 17:57:04,762 Epoch[17] Batch [1140]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.110362,	
2017-07-12 17:57:11,803 Epoch[17] Batch [1150]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.110371,	
2017-07-12 17:57:18,817 Epoch[17] Batch [1160]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.110363,	
2017-07-12 17:57:25,587 Epoch[17] Batch [1170]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.110404,	
2017-07-12 17:57:32,030 Epoch[17] Batch [1180]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.110451,	
2017-07-12 17:57:38,584 Epoch[17] Batch [1190]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.110554,	
2017-07-12 17:57:45,233 Epoch[17] Batch [1200]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.110447,	
2017-07-12 17:57:51,771 Epoch[17] Batch [1210]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.110420,	
2017-07-12 17:57:58,569 Epoch[17] Batch [1220]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.110361,	
2017-07-12 17:58:05,205 Epoch[17] Batch [1230]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.110331,	
2017-07-12 17:58:11,769 Epoch[17] Batch [1240]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.110417,	
2017-07-12 17:58:18,269 Epoch[17] Batch [1250]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.110487,	
2017-07-12 17:58:25,058 Epoch[17] Batch [1260]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.110463,	
2017-07-12 17:58:31,465 Epoch[17] Batch [1270]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.110496,	
2017-07-12 17:58:37,887 Epoch[17] Batch [1280]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.110420,	
2017-07-12 17:58:44,231 Epoch[17] Batch [1290]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.110353,	
2017-07-12 17:58:50,859 Epoch[17] Batch [1300]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.110426,	
2017-07-12 17:58:57,321 Epoch[17] Batch [1310]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.110348,	
2017-07-12 17:59:03,618 Epoch[17] Batch [1320]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.110332,	
2017-07-12 17:59:10,175 Epoch[17] Batch [1330]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.110385,	
2017-07-12 17:59:16,269 Epoch[17] Batch [1340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.110371,	
2017-07-12 17:59:23,060 Epoch[17] Batch [1350]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.110300,	
2017-07-12 17:59:29,261 Epoch[17] Batch [1360]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.110283,	
2017-07-12 17:59:35,869 Epoch[17] Batch [1370]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.110258,	
2017-07-12 17:59:42,207 Epoch[17] Batch [1380]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.110150,	
2017-07-12 17:59:48,750 Epoch[17] Batch [1390]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.110202,	
2017-07-12 17:59:55,339 Epoch[17] Batch [1400]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.110309,	
2017-07-12 18:00:01,906 Epoch[17] Batch [1410]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.110305,	
2017-07-12 18:00:08,426 Epoch[17] Batch [1420]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.110323,	
2017-07-12 18:00:14,809 Epoch[17] Batch [1430]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.110263,	
2017-07-12 18:00:21,565 Epoch[17] Batch [1440]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.110223,	
2017-07-12 18:00:28,410 Epoch[17] Batch [1450]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.110250,	
2017-07-12 18:00:35,210 Epoch[17] Batch [1460]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.110230,	
2017-07-12 18:00:42,028 Epoch[17] Batch [1470]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.110237,	
2017-07-12 18:00:48,385 Epoch[17] Batch [1480]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.110154,	
2017-07-12 18:00:52,444 Epoch[17] Train-FCNLogLoss=0.110182
2017-07-12 18:00:52,445 Epoch[17] Time cost=973.936
2017-07-12 18:00:53,401 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0018.params"
2017-07-12 18:00:55,192 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0018.states"
2017-07-12 18:01:02,543 Epoch[18] Batch [10]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.112833,	
2017-07-12 18:01:09,334 Epoch[18] Batch [20]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.113863,	
2017-07-12 18:01:15,722 Epoch[18] Batch [30]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.112096,	
2017-07-12 18:01:22,161 Epoch[18] Batch [40]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.110761,	
2017-07-12 18:01:28,672 Epoch[18] Batch [50]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.110050,	
2017-07-12 18:01:35,185 Epoch[18] Batch [60]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.110855,	
2017-07-12 18:01:41,818 Epoch[18] Batch [70]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.108963,	
2017-07-12 18:01:48,426 Epoch[18] Batch [80]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.109572,	
2017-07-12 18:01:55,114 Epoch[18] Batch [90]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.109637,	
2017-07-12 18:02:01,960 Epoch[18] Batch [100]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.110032,	
2017-07-12 18:02:08,480 Epoch[18] Batch [110]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.109976,	
2017-07-12 18:02:15,318 Epoch[18] Batch [120]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.109451,	
2017-07-12 18:02:21,742 Epoch[18] Batch [130]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.108498,	
2017-07-12 18:02:28,244 Epoch[18] Batch [140]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.107797,	
2017-07-12 18:02:34,888 Epoch[18] Batch [150]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.107783,	
2017-07-12 18:02:41,080 Epoch[18] Batch [160]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.108054,	
2017-07-12 18:02:47,646 Epoch[18] Batch [170]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.108261,	
2017-07-12 18:02:54,116 Epoch[18] Batch [180]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.108386,	
2017-07-12 18:03:00,344 Epoch[18] Batch [190]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.108315,	
2017-07-12 18:03:06,444 Epoch[18] Batch [200]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107820,	
2017-07-12 18:03:12,643 Epoch[18] Batch [210]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.107926,	
2017-07-12 18:03:19,311 Epoch[18] Batch [220]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.107682,	
2017-07-12 18:03:25,729 Epoch[18] Batch [230]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.107175,	
2017-07-12 18:03:32,019 Epoch[18] Batch [240]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.107207,	
2017-07-12 18:03:38,324 Epoch[18] Batch [250]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.107124,	
2017-07-12 18:03:44,636 Epoch[18] Batch [260]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.107210,	
2017-07-12 18:03:51,234 Epoch[18] Batch [270]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.107197,	
2017-07-12 18:03:57,604 Epoch[18] Batch [280]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.107110,	
2017-07-12 18:04:04,306 Epoch[18] Batch [290]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.107198,	
2017-07-12 18:04:10,717 Epoch[18] Batch [300]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.107005,	
2017-07-12 18:04:17,063 Epoch[18] Batch [310]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.106875,	
2017-07-12 18:04:23,204 Epoch[18] Batch [320]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.107495,	
2017-07-12 18:04:29,639 Epoch[18] Batch [330]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.107420,	
2017-07-12 18:04:35,895 Epoch[18] Batch [340]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.107675,	
2017-07-12 18:04:42,493 Epoch[18] Batch [350]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.107860,	
2017-07-12 18:04:48,992 Epoch[18] Batch [360]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.107548,	
2017-07-12 18:04:55,468 Epoch[18] Batch [370]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.107536,	
2017-07-12 18:05:01,973 Epoch[18] Batch [380]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.107630,	
2017-07-12 18:05:08,839 Epoch[18] Batch [390]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.107634,	
2017-07-12 18:05:15,675 Epoch[18] Batch [400]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.107484,	
2017-07-12 18:05:22,215 Epoch[18] Batch [410]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.107385,	
2017-07-12 18:05:28,755 Epoch[18] Batch [420]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.107425,	
2017-07-12 18:05:35,289 Epoch[18] Batch [430]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.107508,	
2017-07-12 18:05:41,523 Epoch[18] Batch [440]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.107611,	
2017-07-12 18:05:48,007 Epoch[18] Batch [450]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.107624,	
2017-07-12 18:05:54,379 Epoch[18] Batch [460]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.107751,	
2017-07-12 18:06:00,945 Epoch[18] Batch [470]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.107701,	
2017-07-12 18:06:07,276 Epoch[18] Batch [480]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.107931,	
2017-07-12 18:06:13,906 Epoch[18] Batch [490]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.107931,	
2017-07-12 18:06:20,192 Epoch[18] Batch [500]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.107961,	
2017-07-12 18:06:26,654 Epoch[18] Batch [510]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.107939,	
2017-07-12 18:06:32,897 Epoch[18] Batch [520]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.107806,	
2017-07-12 18:06:39,351 Epoch[18] Batch [530]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.107877,	
2017-07-12 18:06:45,917 Epoch[18] Batch [540]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.107719,	
2017-07-12 18:06:52,258 Epoch[18] Batch [550]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.107729,	
2017-07-12 18:06:58,431 Epoch[18] Batch [560]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.107600,	
2017-07-12 18:07:04,810 Epoch[18] Batch [570]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.107559,	
2017-07-12 18:07:11,394 Epoch[18] Batch [580]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.107654,	
2017-07-12 18:07:17,805 Epoch[18] Batch [590]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.107644,	
2017-07-12 18:07:24,372 Epoch[18] Batch [600]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.107660,	
2017-07-12 18:07:31,166 Epoch[18] Batch [610]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.107846,	
2017-07-12 18:07:38,094 Epoch[18] Batch [620]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.107582,	
2017-07-12 18:07:44,725 Epoch[18] Batch [630]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.107651,	
2017-07-12 18:07:50,964 Epoch[18] Batch [640]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.107545,	
2017-07-12 18:07:57,131 Epoch[18] Batch [650]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.107520,	
2017-07-12 18:08:03,204 Epoch[18] Batch [660]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107244,	
2017-07-12 18:08:09,904 Epoch[18] Batch [670]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.107307,	
2017-07-12 18:08:16,465 Epoch[18] Batch [680]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.107500,	
2017-07-12 18:08:22,686 Epoch[18] Batch [690]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.107456,	
2017-07-12 18:08:29,105 Epoch[18] Batch [700]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.107461,	
2017-07-12 18:08:35,523 Epoch[18] Batch [710]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.107789,	
2017-07-12 18:08:41,978 Epoch[18] Batch [720]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.108237,	
2017-07-12 18:08:48,538 Epoch[18] Batch [730]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.108244,	
2017-07-12 18:08:54,875 Epoch[18] Batch [740]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.108171,	
2017-07-12 18:09:01,534 Epoch[18] Batch [750]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.108293,	
2017-07-12 18:09:07,974 Epoch[18] Batch [760]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.108081,	
2017-07-12 18:09:14,249 Epoch[18] Batch [770]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.108001,	
2017-07-12 18:09:20,669 Epoch[18] Batch [780]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.107925,	
2017-07-12 18:09:27,239 Epoch[18] Batch [790]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.108348,	
2017-07-12 18:09:33,509 Epoch[18] Batch [800]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.108412,	
2017-07-12 18:09:40,499 Epoch[18] Batch [810]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.108962,	
2017-07-12 18:09:46,914 Epoch[18] Batch [820]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.109245,	
2017-07-12 18:09:53,164 Epoch[18] Batch [830]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.109263,	
2017-07-12 18:09:59,670 Epoch[18] Batch [840]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.109536,	
2017-07-12 18:10:06,046 Epoch[18] Batch [850]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.109719,	
2017-07-12 18:10:12,561 Epoch[18] Batch [860]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.109834,	
2017-07-12 18:10:19,226 Epoch[18] Batch [870]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109798,	
2017-07-12 18:10:25,602 Epoch[18] Batch [880]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.109820,	
2017-07-12 18:10:32,424 Epoch[18] Batch [890]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.109768,	
2017-07-12 18:10:38,990 Epoch[18] Batch [900]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.109721,	
2017-07-12 18:10:45,615 Epoch[18] Batch [910]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.109608,	
2017-07-12 18:10:52,027 Epoch[18] Batch [920]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.109714,	
2017-07-12 18:10:58,527 Epoch[18] Batch [930]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.109670,	
2017-07-12 18:11:05,248 Epoch[18] Batch [940]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.109648,	
2017-07-12 18:11:11,840 Epoch[18] Batch [950]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.109700,	
2017-07-12 18:11:18,405 Epoch[18] Batch [960]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.109633,	
2017-07-12 18:11:24,644 Epoch[18] Batch [970]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.109675,	
2017-07-12 18:11:30,988 Epoch[18] Batch [980]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.109723,	
2017-07-12 18:11:37,599 Epoch[18] Batch [990]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.109712,	
2017-07-12 18:11:44,128 Epoch[18] Batch [1000]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.109654,	
2017-07-12 18:11:50,434 Epoch[18] Batch [1010]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.109625,	
2017-07-12 18:11:56,854 Epoch[18] Batch [1020]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.109602,	
2017-07-12 18:12:03,368 Epoch[18] Batch [1030]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.109534,	
2017-07-12 18:12:09,589 Epoch[18] Batch [1040]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.109529,	
2017-07-12 18:12:16,004 Epoch[18] Batch [1050]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.109527,	
2017-07-12 18:12:22,389 Epoch[18] Batch [1060]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.109528,	
2017-07-12 18:12:28,474 Epoch[18] Batch [1070]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.109576,	
2017-07-12 18:12:34,864 Epoch[18] Batch [1080]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.109468,	
2017-07-12 18:12:41,164 Epoch[18] Batch [1090]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.109582,	
2017-07-12 18:12:47,625 Epoch[18] Batch [1100]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.109520,	
2017-07-12 18:12:53,986 Epoch[18] Batch [1110]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.109604,	
2017-07-12 18:13:00,548 Epoch[18] Batch [1120]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.109690,	
2017-07-12 18:13:06,973 Epoch[18] Batch [1130]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.109688,	
2017-07-12 18:13:13,563 Epoch[18] Batch [1140]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.109754,	
2017-07-12 18:13:19,902 Epoch[18] Batch [1150]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.109865,	
2017-07-12 18:13:26,570 Epoch[18] Batch [1160]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109849,	
2017-07-12 18:13:33,092 Epoch[18] Batch [1170]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.109811,	
2017-07-12 18:13:39,827 Epoch[18] Batch [1180]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.109772,	
2017-07-12 18:13:46,296 Epoch[18] Batch [1190]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.109754,	
2017-07-12 18:13:53,176 Epoch[18] Batch [1200]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.109817,	
2017-07-12 18:13:59,689 Epoch[18] Batch [1210]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.109848,	
2017-07-12 18:14:06,084 Epoch[18] Batch [1220]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.109844,	
2017-07-12 18:14:12,541 Epoch[18] Batch [1230]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.109840,	
2017-07-12 18:14:18,834 Epoch[18] Batch [1240]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.109843,	
2017-07-12 18:14:25,089 Epoch[18] Batch [1250]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.109827,	
2017-07-12 18:14:31,549 Epoch[18] Batch [1260]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.109779,	
2017-07-12 18:14:37,993 Epoch[18] Batch [1270]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.109845,	
2017-07-12 18:14:44,410 Epoch[18] Batch [1280]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.110062,	
2017-07-12 18:14:50,726 Epoch[18] Batch [1290]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.110118,	
2017-07-12 18:14:57,297 Epoch[18] Batch [1300]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.110209,	
2017-07-12 18:15:03,724 Epoch[18] Batch [1310]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.110297,	
2017-07-12 18:15:10,535 Epoch[18] Batch [1320]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.110292,	
2017-07-12 18:15:17,240 Epoch[18] Batch [1330]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.110471,	
2017-07-12 18:15:23,659 Epoch[18] Batch [1340]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.110575,	
2017-07-12 18:15:29,987 Epoch[18] Batch [1350]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.110612,	
2017-07-12 18:15:36,560 Epoch[18] Batch [1360]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.110696,	
2017-07-12 18:15:43,131 Epoch[18] Batch [1370]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.110698,	
2017-07-12 18:15:49,719 Epoch[18] Batch [1380]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.110634,	
2017-07-12 18:15:56,299 Epoch[18] Batch [1390]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.110568,	
2017-07-12 18:16:02,663 Epoch[18] Batch [1400]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.110555,	
2017-07-12 18:16:08,987 Epoch[18] Batch [1410]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.110555,	
2017-07-12 18:16:15,300 Epoch[18] Batch [1420]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.110543,	
2017-07-12 18:16:21,704 Epoch[18] Batch [1430]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.110484,	
2017-07-12 18:16:28,602 Epoch[18] Batch [1440]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.110353,	
2017-07-12 18:16:35,226 Epoch[18] Batch [1450]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.110384,	
2017-07-12 18:16:41,956 Epoch[18] Batch [1460]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.110354,	
2017-07-12 18:16:48,553 Epoch[18] Batch [1470]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.110430,	
2017-07-12 18:16:55,221 Epoch[18] Batch [1480]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.110521,	
2017-07-12 18:16:59,326 Epoch[18] Train-FCNLogLoss=0.110521
2017-07-12 18:16:59,326 Epoch[18] Time cost=964.133
2017-07-12 18:17:00,234 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0019.params"
2017-07-12 18:17:01,851 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0019.states"
2017-07-12 18:17:09,390 Epoch[19] Batch [10]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.128235,	
2017-07-12 18:17:16,151 Epoch[19] Batch [20]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.121086,	
2017-07-12 18:17:22,921 Epoch[19] Batch [30]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.117487,	
2017-07-12 18:17:29,648 Epoch[19] Batch [40]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.114599,	
2017-07-12 18:17:36,166 Epoch[19] Batch [50]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.116113,	
2017-07-12 18:17:42,975 Epoch[19] Batch [60]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.114872,	
2017-07-12 18:17:49,673 Epoch[19] Batch [70]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.113987,	
2017-07-12 18:17:56,558 Epoch[19] Batch [80]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.112135,	
2017-07-12 18:18:03,282 Epoch[19] Batch [90]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.110110,	
2017-07-12 18:18:09,782 Epoch[19] Batch [100]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.109908,	
2017-07-12 18:18:16,016 Epoch[19] Batch [110]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.109940,	
2017-07-12 18:18:22,267 Epoch[19] Batch [120]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.108725,	
2017-07-12 18:18:28,709 Epoch[19] Batch [130]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.109675,	
2017-07-12 18:18:34,994 Epoch[19] Batch [140]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.109727,	
2017-07-12 18:18:40,696 Epoch[19] Batch [150]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.109355,	
2017-07-12 18:18:46,681 Epoch[19] Batch [160]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.109465,	
2017-07-12 18:18:53,518 Epoch[19] Batch [170]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.108846,	
2017-07-12 18:19:00,316 Epoch[19] Batch [180]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.108228,	
2017-07-12 18:19:06,866 Epoch[19] Batch [190]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.108716,	
2017-07-12 18:19:13,726 Epoch[19] Batch [200]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.108837,	
2017-07-12 18:19:20,677 Epoch[19] Batch [210]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.109221,	
2017-07-12 18:19:27,528 Epoch[19] Batch [220]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.108705,	
2017-07-12 18:19:33,852 Epoch[19] Batch [230]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.108799,	
2017-07-12 18:19:40,220 Epoch[19] Batch [240]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.109077,	
2017-07-12 18:19:46,645 Epoch[19] Batch [250]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.109235,	
2017-07-12 18:19:53,180 Epoch[19] Batch [260]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.109050,	
2017-07-12 18:19:59,831 Epoch[19] Batch [270]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.109347,	
2017-07-12 18:20:06,542 Epoch[19] Batch [280]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.109359,	
2017-07-12 18:20:12,916 Epoch[19] Batch [290]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.109301,	
2017-07-12 18:20:19,549 Epoch[19] Batch [300]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.109765,	
2017-07-12 18:20:26,392 Epoch[19] Batch [310]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.109863,	
2017-07-12 18:20:32,955 Epoch[19] Batch [320]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.110274,	
2017-07-12 18:20:39,540 Epoch[19] Batch [330]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.110565,	
2017-07-12 18:20:46,004 Epoch[19] Batch [340]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.110961,	
2017-07-12 18:20:52,450 Epoch[19] Batch [350]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.110555,	
2017-07-12 18:20:58,945 Epoch[19] Batch [360]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.110456,	
2017-07-12 18:21:05,671 Epoch[19] Batch [370]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.110311,	
2017-07-12 18:21:12,367 Epoch[19] Batch [380]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.110282,	
2017-07-12 18:21:18,837 Epoch[19] Batch [390]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.110590,	
2017-07-12 18:21:25,633 Epoch[19] Batch [400]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.110615,	
2017-07-12 18:21:32,144 Epoch[19] Batch [410]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.110670,	
2017-07-12 18:21:36,386 Epoch[19] Batch [420]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.110425,	
2017-07-12 18:21:40,448 Epoch[19] Batch [430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110305,	
2017-07-12 18:21:44,542 Epoch[19] Batch [440]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110314,	
2017-07-12 18:21:48,546 Epoch[19] Batch [450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.110526,	
2017-07-12 18:21:52,589 Epoch[19] Batch [460]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110387,	
2017-07-12 18:21:56,673 Epoch[19] Batch [470]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.110291,	
2017-07-12 18:22:00,706 Epoch[19] Batch [480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110105,	
2017-07-12 18:22:04,747 Epoch[19] Batch [490]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110009,	
2017-07-12 18:22:08,706 Epoch[19] Batch [500]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.110107,	
2017-07-12 18:22:12,796 Epoch[19] Batch [510]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110422,	
2017-07-12 18:22:16,824 Epoch[19] Batch [520]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110378,	
2017-07-12 18:22:20,910 Epoch[19] Batch [530]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110423,	
2017-07-12 18:22:24,797 Epoch[19] Batch [540]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.110537,	
2017-07-12 18:22:28,842 Epoch[19] Batch [550]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110662,	
2017-07-12 18:22:32,876 Epoch[19] Batch [560]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110684,	
2017-07-12 18:22:36,951 Epoch[19] Batch [570]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.110515,	
2017-07-12 18:22:40,995 Epoch[19] Batch [580]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110295,	
2017-07-12 18:22:44,966 Epoch[19] Batch [590]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.110289,	
2017-07-12 18:22:48,982 Epoch[19] Batch [600]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110317,	
2017-07-12 18:22:53,014 Epoch[19] Batch [610]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110456,	
2017-07-12 18:22:56,978 Epoch[19] Batch [620]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.110471,	
2017-07-12 18:23:01,117 Epoch[19] Batch [630]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.111205,	
2017-07-12 18:23:05,287 Epoch[19] Batch [640]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.111429,	
2017-07-12 18:23:09,553 Epoch[19] Batch [650]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.111439,	
2017-07-12 18:23:13,728 Epoch[19] Batch [660]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.111537,	
2017-07-12 18:23:17,851 Epoch[19] Batch [670]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.111563,	
2017-07-12 18:23:22,040 Epoch[19] Batch [680]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.111433,	
2017-07-12 18:23:26,121 Epoch[19] Batch [690]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111654,	
2017-07-12 18:23:30,346 Epoch[19] Batch [700]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.111691,	
2017-07-12 18:23:34,451 Epoch[19] Batch [710]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111708,	
2017-07-12 18:23:38,531 Epoch[19] Batch [720]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111794,	
2017-07-12 18:23:42,608 Epoch[19] Batch [730]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.111940,	
2017-07-12 18:23:46,872 Epoch[19] Batch [740]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.112030,	
2017-07-12 18:23:51,007 Epoch[19] Batch [750]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.111938,	
2017-07-12 18:23:55,115 Epoch[19] Batch [760]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.111892,	
2017-07-12 18:23:59,377 Epoch[19] Batch [770]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.111636,	
2017-07-12 18:24:03,419 Epoch[19] Batch [780]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111681,	
2017-07-12 18:24:07,604 Epoch[19] Batch [790]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.111531,	
2017-07-12 18:24:11,628 Epoch[19] Batch [800]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111488,	
2017-07-12 18:24:15,779 Epoch[19] Batch [810]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.111554,	
2017-07-12 18:24:19,918 Epoch[19] Batch [820]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.111610,	
2017-07-12 18:24:24,046 Epoch[19] Batch [830]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.111509,	
2017-07-12 18:24:28,581 Epoch[19] Batch [840]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.111361,	
2017-07-12 18:24:32,785 Epoch[19] Batch [850]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.111387,	
2017-07-12 18:24:37,056 Epoch[19] Batch [860]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.111250,	
2017-07-12 18:24:41,349 Epoch[19] Batch [870]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.111241,	
2017-07-12 18:24:45,445 Epoch[19] Batch [880]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.111144,	
2017-07-12 18:24:49,788 Epoch[19] Batch [890]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.111080,	
2017-07-12 18:24:54,073 Epoch[19] Batch [900]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.110972,	
2017-07-12 18:24:58,404 Epoch[19] Batch [910]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.110931,	
2017-07-12 18:25:02,683 Epoch[19] Batch [920]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.110804,	
2017-07-12 18:25:06,946 Epoch[19] Batch [930]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.110657,	
2017-07-12 18:25:11,212 Epoch[19] Batch [940]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.110654,	
2017-07-12 18:25:15,635 Epoch[19] Batch [950]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.110515,	
2017-07-12 18:25:19,765 Epoch[19] Batch [960]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.110556,	
2017-07-12 18:25:24,191 Epoch[19] Batch [970]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.110755,	
2017-07-12 18:25:28,477 Epoch[19] Batch [980]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.110844,	
2017-07-12 18:25:32,751 Epoch[19] Batch [990]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.110910,	
2017-07-12 18:25:37,132 Epoch[19] Batch [1000]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.110770,	
2017-07-12 18:25:41,426 Epoch[19] Batch [1010]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.110745,	
2017-07-12 18:25:45,765 Epoch[19] Batch [1020]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.110711,	
2017-07-12 18:25:50,035 Epoch[19] Batch [1030]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.110709,	
2017-07-12 18:25:54,410 Epoch[19] Batch [1040]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.110812,	
2017-07-12 18:25:58,616 Epoch[19] Batch [1050]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.110746,	
2017-07-12 18:26:03,214 Epoch[19] Batch [1060]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.110758,	
2017-07-12 18:26:07,467 Epoch[19] Batch [1070]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.110685,	
2017-07-12 18:26:11,869 Epoch[19] Batch [1080]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.110640,	
2017-07-12 18:26:15,891 Epoch[19] Batch [1090]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110655,	
2017-07-12 18:26:19,873 Epoch[19] Batch [1100]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.110749,	
2017-07-12 18:26:23,981 Epoch[19] Batch [1110]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.110744,	
2017-07-12 18:26:28,006 Epoch[19] Batch [1120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.110723,	
2017-07-12 18:26:32,065 Epoch[19] Batch [1130]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110646,	
2017-07-12 18:26:36,241 Epoch[19] Batch [1140]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110609,	
2017-07-12 18:26:40,197 Epoch[19] Batch [1150]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.110537,	
2017-07-12 18:26:44,159 Epoch[19] Batch [1160]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.110488,	
2017-07-12 18:26:48,216 Epoch[19] Batch [1170]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110299,	
2017-07-12 18:26:52,308 Epoch[19] Batch [1180]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110270,	
2017-07-12 18:26:56,366 Epoch[19] Batch [1190]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110291,	
2017-07-12 18:27:00,493 Epoch[19] Batch [1200]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.110239,	
2017-07-12 18:27:04,616 Epoch[19] Batch [1210]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110279,	
2017-07-12 18:27:08,671 Epoch[19] Batch [1220]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110225,	
2017-07-12 18:27:12,762 Epoch[19] Batch [1230]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110086,	
2017-07-12 18:27:16,865 Epoch[19] Batch [1240]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.109972,	
2017-07-12 18:27:20,848 Epoch[19] Batch [1250]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.109885,	
2017-07-12 18:27:24,847 Epoch[19] Batch [1260]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109914,	
2017-07-12 18:27:28,822 Epoch[19] Batch [1270]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.109952,	
2017-07-12 18:27:32,689 Epoch[19] Batch [1280]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.110238,	
2017-07-12 18:27:36,730 Epoch[19] Batch [1290]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110434,	
2017-07-12 18:27:40,878 Epoch[19] Batch [1300]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.110811,	
2017-07-12 18:27:44,806 Epoch[19] Batch [1310]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110822,	
2017-07-12 18:27:48,903 Epoch[19] Batch [1320]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.110882,	
2017-07-12 18:27:53,043 Epoch[19] Batch [1330]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110861,	
2017-07-12 18:27:57,109 Epoch[19] Batch [1340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.111049,	
2017-07-12 18:28:01,078 Epoch[19] Batch [1350]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.111058,	
2017-07-12 18:28:05,172 Epoch[19] Batch [1360]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.111086,	
2017-07-12 18:28:09,100 Epoch[19] Batch [1370]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.111591,	
2017-07-12 18:28:13,078 Epoch[19] Batch [1380]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.112074,	
2017-07-12 18:28:17,103 Epoch[19] Batch [1390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112906,	
2017-07-12 18:28:21,201 Epoch[19] Batch [1400]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113433,	
2017-07-12 18:28:25,128 Epoch[19] Batch [1410]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.113747,	
2017-07-12 18:28:29,313 Epoch[19] Batch [1420]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.113941,	
2017-07-12 18:28:33,441 Epoch[19] Batch [1430]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.114010,	
2017-07-12 18:28:37,520 Epoch[19] Batch [1440]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.114058,	
2017-07-12 18:28:41,612 Epoch[19] Batch [1450]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114190,	
2017-07-12 18:28:45,755 Epoch[19] Batch [1460]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.114189,	
2017-07-12 18:28:49,970 Epoch[19] Batch [1470]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.114221,	
2017-07-12 18:28:53,967 Epoch[19] Batch [1480]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.114187,	
2017-07-12 18:28:56,389 Epoch[19] Train-FCNLogLoss=0.114246
2017-07-12 18:28:56,389 Epoch[19] Time cost=714.538
2017-07-12 18:28:57,197 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0020.params"
2017-07-12 18:28:59,061 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0020.states"
2017-07-12 18:29:04,039 Epoch[20] Batch [10]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.113973,	
2017-07-12 18:29:08,114 Epoch[20] Batch [20]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112826,	
2017-07-12 18:29:12,062 Epoch[20] Batch [30]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.116857,	
2017-07-12 18:29:16,227 Epoch[20] Batch [40]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.121123,	
2017-07-12 18:29:20,244 Epoch[20] Batch [50]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.131354,	
2017-07-12 18:29:24,368 Epoch[20] Batch [60]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.135540,	
2017-07-12 18:29:28,543 Epoch[20] Batch [70]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.133782,	
2017-07-12 18:29:32,731 Epoch[20] Batch [80]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.140049,	
2017-07-12 18:29:36,835 Epoch[20] Batch [90]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.149205,	
2017-07-12 18:29:41,141 Epoch[20] Batch [100]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.155289,	
2017-07-12 18:29:45,123 Epoch[20] Batch [110]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.159281,	
2017-07-12 18:29:49,350 Epoch[20] Batch [120]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.165826,	
2017-07-12 18:29:53,673 Epoch[20] Batch [130]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.164125,	
2017-07-12 18:29:57,750 Epoch[20] Batch [140]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.162144,	
2017-07-12 18:30:01,811 Epoch[20] Batch [150]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.161466,	
2017-07-12 18:30:05,716 Epoch[20] Batch [160]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.160231,	
2017-07-12 18:30:09,843 Epoch[20] Batch [170]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.159020,	
2017-07-12 18:30:13,917 Epoch[20] Batch [180]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.157610,	
2017-07-12 18:30:17,925 Epoch[20] Batch [190]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.156564,	
2017-07-12 18:30:21,922 Epoch[20] Batch [200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.154972,	
2017-07-12 18:30:26,190 Epoch[20] Batch [210]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.153335,	
2017-07-12 18:30:30,259 Epoch[20] Batch [220]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.151683,	
2017-07-12 18:30:34,352 Epoch[20] Batch [230]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.150653,	
2017-07-12 18:30:38,429 Epoch[20] Batch [240]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.149617,	
2017-07-12 18:30:42,509 Epoch[20] Batch [250]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.149318,	
2017-07-12 18:30:46,586 Epoch[20] Batch [260]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.148574,	
2017-07-12 18:30:50,847 Epoch[20] Batch [270]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.147251,	
2017-07-12 18:30:54,880 Epoch[20] Batch [280]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.145788,	
2017-07-12 18:30:58,950 Epoch[20] Batch [290]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.144568,	
2017-07-12 18:31:03,166 Epoch[20] Batch [300]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.143443,	
2017-07-12 18:31:07,406 Epoch[20] Batch [310]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.142715,	
2017-07-12 18:31:11,576 Epoch[20] Batch [320]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.142120,	
2017-07-12 18:31:16,027 Epoch[20] Batch [330]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.141496,	
2017-07-12 18:31:20,501 Epoch[20] Batch [340]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.140532,	
2017-07-12 18:31:24,825 Epoch[20] Batch [350]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.139676,	
2017-07-12 18:31:29,476 Epoch[20] Batch [360]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.139460,	
2017-07-12 18:31:33,858 Epoch[20] Batch [370]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.138495,	
2017-07-12 18:31:38,460 Epoch[20] Batch [380]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.137810,	
2017-07-12 18:31:42,607 Epoch[20] Batch [390]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.137075,	
2017-07-12 18:31:47,323 Epoch[20] Batch [400]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.136364,	
2017-07-12 18:31:51,834 Epoch[20] Batch [410]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.135858,	
2017-07-12 18:31:56,091 Epoch[20] Batch [420]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.135397,	
2017-07-12 18:32:00,696 Epoch[20] Batch [430]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.134629,	
2017-07-12 18:32:04,941 Epoch[20] Batch [440]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.134203,	
2017-07-12 18:32:09,513 Epoch[20] Batch [450]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.133928,	
2017-07-12 18:32:13,958 Epoch[20] Batch [460]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.133182,	
2017-07-12 18:32:18,168 Epoch[20] Batch [470]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.132720,	
2017-07-12 18:32:23,012 Epoch[20] Batch [480]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.132141,	
2017-07-12 18:32:27,364 Epoch[20] Batch [490]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.132393,	
2017-07-12 18:32:32,070 Epoch[20] Batch [500]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.132309,	
2017-07-12 18:32:36,412 Epoch[20] Batch [510]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.131991,	
2017-07-12 18:32:40,651 Epoch[20] Batch [520]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.131776,	
2017-07-12 18:32:45,441 Epoch[20] Batch [530]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.131623,	
2017-07-12 18:32:49,860 Epoch[20] Batch [540]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.131229,	
2017-07-12 18:32:54,346 Epoch[20] Batch [550]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.130706,	
2017-07-12 18:32:58,801 Epoch[20] Batch [560]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.130520,	
2017-07-12 18:33:03,266 Epoch[20] Batch [570]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.132038,	
2017-07-12 18:33:07,901 Epoch[20] Batch [580]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.132582,	
2017-07-12 18:33:12,248 Epoch[20] Batch [590]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.132747,	
2017-07-12 18:33:16,528 Epoch[20] Batch [600]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.132469,	
2017-07-12 18:33:21,304 Epoch[20] Batch [610]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.132534,	
2017-07-12 18:33:25,562 Epoch[20] Batch [620]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.132312,	
2017-07-12 18:33:30,122 Epoch[20] Batch [630]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.132245,	
2017-07-12 18:33:34,789 Epoch[20] Batch [640]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.132016,	
2017-07-12 18:33:39,181 Epoch[20] Batch [650]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.131980,	
2017-07-12 18:33:43,935 Epoch[20] Batch [660]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.131831,	
2017-07-12 18:33:48,586 Epoch[20] Batch [670]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.131454,	
2017-07-12 18:33:53,191 Epoch[20] Batch [680]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.131184,	
2017-07-12 18:33:58,126 Epoch[20] Batch [690]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.130790,	
2017-07-12 18:34:02,535 Epoch[20] Batch [700]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.130297,	
2017-07-12 18:34:07,019 Epoch[20] Batch [710]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.130041,	
2017-07-12 18:34:11,824 Epoch[20] Batch [720]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.129854,	
2017-07-12 18:34:16,347 Epoch[20] Batch [730]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.129770,	
2017-07-12 18:34:20,895 Epoch[20] Batch [740]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.129422,	
2017-07-12 18:34:25,760 Epoch[20] Batch [750]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.129218,	
2017-07-12 18:34:30,233 Epoch[20] Batch [760]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.129031,	
2017-07-12 18:34:34,905 Epoch[20] Batch [770]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.128929,	
2017-07-12 18:34:39,865 Epoch[20] Batch [780]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.128984,	
2017-07-12 18:34:44,409 Epoch[20] Batch [790]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.128849,	
2017-07-12 18:34:49,160 Epoch[20] Batch [800]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.128544,	
2017-07-12 18:34:53,824 Epoch[20] Batch [810]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.128366,	
2017-07-12 18:34:58,459 Epoch[20] Batch [820]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.128155,	
2017-07-12 18:35:03,357 Epoch[20] Batch [830]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.128029,	
2017-07-12 18:35:08,129 Epoch[20] Batch [840]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.128031,	
2017-07-12 18:35:12,623 Epoch[20] Batch [850]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.127852,	
2017-07-12 18:35:17,963 Epoch[20] Batch [860]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.127882,	
2017-07-12 18:35:22,515 Epoch[20] Batch [870]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.127656,	
2017-07-12 18:35:27,147 Epoch[20] Batch [880]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.127585,	
2017-07-12 18:35:32,250 Epoch[20] Batch [890]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.127335,	
2017-07-12 18:35:36,829 Epoch[20] Batch [900]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.127156,	
2017-07-12 18:35:41,543 Epoch[20] Batch [910]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.126925,	
2017-07-12 18:35:46,536 Epoch[20] Batch [920]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.126657,	
2017-07-12 18:35:51,029 Epoch[20] Batch [930]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.126466,	
2017-07-12 18:35:55,554 Epoch[20] Batch [940]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.126401,	
2017-07-12 18:36:00,653 Epoch[20] Batch [950]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.126330,	
2017-07-12 18:36:05,160 Epoch[20] Batch [960]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.126157,	
2017-07-12 18:36:10,006 Epoch[20] Batch [970]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.125864,	
2017-07-12 18:36:15,121 Epoch[20] Batch [980]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.125898,	
2017-07-12 18:36:19,726 Epoch[20] Batch [990]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.125810,	
2017-07-12 18:36:24,809 Epoch[20] Batch [1000]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.125747,	
2017-07-12 18:36:29,758 Epoch[20] Batch [1010]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.125592,	
2017-07-12 18:36:34,524 Epoch[20] Batch [1020]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.125361,	
2017-07-12 18:36:39,796 Epoch[20] Batch [1030]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.125238,	
2017-07-12 18:36:44,190 Epoch[20] Batch [1040]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.125110,	
2017-07-12 18:36:48,803 Epoch[20] Batch [1050]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.124867,	
2017-07-12 18:36:53,914 Epoch[20] Batch [1060]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.124820,	
2017-07-12 18:36:58,508 Epoch[20] Batch [1070]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.124628,	
2017-07-12 18:37:03,270 Epoch[20] Batch [1080]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.124426,	
2017-07-12 18:37:08,329 Epoch[20] Batch [1090]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.124295,	
2017-07-12 18:37:12,958 Epoch[20] Batch [1100]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.124133,	
2017-07-12 18:37:18,247 Epoch[20] Batch [1110]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.123895,	
2017-07-12 18:37:23,098 Epoch[20] Batch [1120]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.123777,	
2017-07-12 18:37:27,545 Epoch[20] Batch [1130]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.123731,	
2017-07-12 18:37:32,913 Epoch[20] Batch [1140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.123637,	
2017-07-12 18:37:37,640 Epoch[20] Batch [1150]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.123540,	
2017-07-12 18:37:42,495 Epoch[20] Batch [1160]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.123403,	
2017-07-12 18:37:47,687 Epoch[20] Batch [1170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.123296,	
2017-07-12 18:37:52,282 Epoch[20] Batch [1180]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.123209,	
2017-07-12 18:37:56,983 Epoch[20] Batch [1190]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.123116,	
2017-07-12 18:38:02,147 Epoch[20] Batch [1200]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.122987,	
2017-07-12 18:38:06,826 Epoch[20] Batch [1210]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.122921,	
2017-07-12 18:38:11,695 Epoch[20] Batch [1220]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.122813,	
2017-07-12 18:38:16,774 Epoch[20] Batch [1230]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.122682,	
2017-07-12 18:38:21,396 Epoch[20] Batch [1240]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.122481,	
2017-07-12 18:38:26,391 Epoch[20] Batch [1250]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.122298,	
2017-07-12 18:38:31,348 Epoch[20] Batch [1260]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.122127,	
2017-07-12 18:38:36,013 Epoch[20] Batch [1270]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.121929,	
2017-07-12 18:38:40,483 Epoch[20] Batch [1280]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121829,	
2017-07-12 18:38:45,368 Epoch[20] Batch [1290]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.121683,	
2017-07-12 18:38:50,138 Epoch[20] Batch [1300]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.121603,	
2017-07-12 18:38:55,068 Epoch[20] Batch [1310]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.121388,	
2017-07-12 18:39:00,329 Epoch[20] Batch [1320]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.121335,	
2017-07-12 18:39:04,984 Epoch[20] Batch [1330]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.121233,	
2017-07-12 18:39:09,823 Epoch[20] Batch [1340]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.121144,	
2017-07-12 18:39:14,780 Epoch[20] Batch [1350]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.120918,	
2017-07-12 18:39:19,722 Epoch[20] Batch [1360]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.120883,	
2017-07-12 18:39:24,514 Epoch[20] Batch [1370]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.120777,	
2017-07-12 18:39:29,239 Epoch[20] Batch [1380]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.120756,	
2017-07-12 18:39:34,151 Epoch[20] Batch [1390]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.120615,	
2017-07-12 18:39:39,363 Epoch[20] Batch [1400]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.120507,	
2017-07-12 18:39:44,112 Epoch[20] Batch [1410]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.120381,	
2017-07-12 18:39:48,868 Epoch[20] Batch [1420]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.120345,	
2017-07-12 18:39:54,246 Epoch[20] Batch [1430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.120245,	
2017-07-12 18:39:58,972 Epoch[20] Batch [1440]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.120229,	
2017-07-12 18:40:04,042 Epoch[20] Batch [1450]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.120174,	
2017-07-12 18:40:09,250 Epoch[20] Batch [1460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.120195,	
2017-07-12 18:40:14,091 Epoch[20] Batch [1470]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.120215,	
2017-07-12 18:40:18,942 Epoch[20] Batch [1480]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.120196,	
2017-07-12 18:40:22,020 Epoch[20] Train-FCNLogLoss=0.120216
2017-07-12 18:40:22,020 Epoch[20] Time cost=682.959
2017-07-12 18:40:22,955 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0021.params"
2017-07-12 18:40:24,831 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0021.states"
2017-07-12 18:40:30,367 Epoch[21] Batch [10]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.113287,	
2017-07-12 18:40:35,525 Epoch[21] Batch [20]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.112797,	
2017-07-12 18:40:40,643 Epoch[21] Batch [30]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.113184,	
2017-07-12 18:40:45,515 Epoch[21] Batch [40]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.113768,	
2017-07-12 18:40:50,701 Epoch[21] Batch [50]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.113106,	
2017-07-12 18:40:55,514 Epoch[21] Batch [60]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.115138,	
2017-07-12 18:41:00,347 Epoch[21] Batch [70]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.113981,	
2017-07-12 18:41:05,629 Epoch[21] Batch [80]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.113565,	
2017-07-12 18:41:10,562 Epoch[21] Batch [90]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.114979,	
2017-07-12 18:41:15,361 Epoch[21] Batch [100]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.115108,	
2017-07-12 18:41:20,662 Epoch[21] Batch [110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.115243,	
2017-07-12 18:41:25,892 Epoch[21] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.114430,	
2017-07-12 18:41:30,777 Epoch[21] Batch [130]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.114632,	
2017-07-12 18:41:36,288 Epoch[21] Batch [140]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.114181,	
2017-07-12 18:41:41,233 Epoch[21] Batch [150]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.114056,	
2017-07-12 18:41:46,163 Epoch[21] Batch [160]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.114078,	
2017-07-12 18:41:51,383 Epoch[21] Batch [170]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.113777,	
2017-07-12 18:41:56,609 Epoch[21] Batch [180]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.113637,	
2017-07-12 18:42:01,570 Epoch[21] Batch [190]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.113856,	
2017-07-12 18:42:07,045 Epoch[21] Batch [200]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.113503,	
2017-07-12 18:42:12,199 Epoch[21] Batch [210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.113731,	
2017-07-12 18:42:17,078 Epoch[21] Batch [220]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.113101,	
2017-07-12 18:42:22,509 Epoch[21] Batch [230]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.112633,	
2017-07-12 18:42:27,585 Epoch[21] Batch [240]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.111540,	
2017-07-12 18:42:32,724 Epoch[21] Batch [250]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.111591,	
2017-07-12 18:42:38,330 Epoch[21] Batch [260]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.111518,	
2017-07-12 18:42:43,345 Epoch[21] Batch [270]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.111011,	
2017-07-12 18:42:48,387 Epoch[21] Batch [280]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.111034,	
2017-07-12 18:42:53,924 Epoch[21] Batch [290]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.110596,	
2017-07-12 18:42:59,011 Epoch[21] Batch [300]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.110483,	
2017-07-12 18:43:04,511 Epoch[21] Batch [310]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.110921,	
2017-07-12 18:43:10,141 Epoch[21] Batch [320]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.111268,	
2017-07-12 18:43:15,075 Epoch[21] Batch [330]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.111407,	
2017-07-12 18:43:20,323 Epoch[21] Batch [340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111199,	
2017-07-12 18:43:26,017 Epoch[21] Batch [350]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.111126,	
2017-07-12 18:43:31,003 Epoch[21] Batch [360]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.111053,	
2017-07-12 18:43:36,153 Epoch[21] Batch [370]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.110766,	
2017-07-12 18:43:41,337 Epoch[21] Batch [380]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.110626,	
2017-07-12 18:43:46,235 Epoch[21] Batch [390]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.110643,	
2017-07-12 18:43:51,252 Epoch[21] Batch [400]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.110368,	
2017-07-12 18:43:56,703 Epoch[21] Batch [410]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.110190,	
2017-07-12 18:44:01,795 Epoch[21] Batch [420]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.110103,	
2017-07-12 18:44:06,946 Epoch[21] Batch [430]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.109933,	
2017-07-12 18:44:12,367 Epoch[21] Batch [440]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.109888,	
2017-07-12 18:44:17,574 Epoch[21] Batch [450]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.109905,	
2017-07-12 18:44:22,877 Epoch[21] Batch [460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.109951,	
2017-07-12 18:44:28,363 Epoch[21] Batch [470]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.109972,	
2017-07-12 18:44:33,516 Epoch[21] Batch [480]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.109841,	
2017-07-12 18:44:38,842 Epoch[21] Batch [490]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.109774,	
2017-07-12 18:44:44,305 Epoch[21] Batch [500]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.109784,	
2017-07-12 18:44:49,263 Epoch[21] Batch [510]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.109595,	
2017-07-12 18:44:54,248 Epoch[21] Batch [520]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.109664,	
2017-07-12 18:44:59,541 Epoch[21] Batch [530]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.109607,	
2017-07-12 18:45:04,707 Epoch[21] Batch [540]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.109478,	
2017-07-12 18:45:09,620 Epoch[21] Batch [550]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.109225,	
2017-07-12 18:45:15,009 Epoch[21] Batch [560]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.109184,	
2017-07-12 18:45:20,261 Epoch[21] Batch [570]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.109080,	
2017-07-12 18:45:25,206 Epoch[21] Batch [580]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.108840,	
2017-07-12 18:45:30,846 Epoch[21] Batch [590]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.108690,	
2017-07-12 18:45:36,279 Epoch[21] Batch [600]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.108603,	
2017-07-12 18:45:41,364 Epoch[21] Batch [610]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.108431,	
2017-07-12 18:45:46,912 Epoch[21] Batch [620]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.108354,	
2017-07-12 18:45:52,065 Epoch[21] Batch [630]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.108456,	
2017-07-12 18:45:57,124 Epoch[21] Batch [640]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.108648,	
2017-07-12 18:46:02,434 Epoch[21] Batch [650]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.108714,	
2017-07-12 18:46:07,828 Epoch[21] Batch [660]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.108673,	
2017-07-12 18:46:12,710 Epoch[21] Batch [670]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.108732,	
2017-07-12 18:46:18,106 Epoch[21] Batch [680]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.108587,	
2017-07-12 18:46:23,691 Epoch[21] Batch [690]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.108675,	
2017-07-12 18:46:28,731 Epoch[21] Batch [700]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.108642,	
2017-07-12 18:46:34,088 Epoch[21] Batch [710]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.108799,	
2017-07-12 18:46:39,614 Epoch[21] Batch [720]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.108781,	
2017-07-12 18:46:44,701 Epoch[21] Batch [730]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.108488,	
2017-07-12 18:46:49,683 Epoch[21] Batch [740]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.108382,	
2017-07-12 18:46:55,219 Epoch[21] Batch [750]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.108344,	
2017-07-12 18:47:00,306 Epoch[21] Batch [760]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.108214,	
2017-07-12 18:47:05,704 Epoch[21] Batch [770]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.108115,	
2017-07-12 18:47:11,377 Epoch[21] Batch [780]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.108014,	
2017-07-12 18:47:16,571 Epoch[21] Batch [790]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.107966,	
2017-07-12 18:47:22,130 Epoch[21] Batch [800]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.107995,	
2017-07-12 18:47:27,698 Epoch[21] Batch [810]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.108106,	
2017-07-12 18:47:32,737 Epoch[21] Batch [820]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.108020,	
2017-07-12 18:47:38,253 Epoch[21] Batch [830]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.107999,	
2017-07-12 18:47:43,736 Epoch[21] Batch [840]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.107987,	
2017-07-12 18:47:48,777 Epoch[21] Batch [850]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.107938,	
2017-07-12 18:47:54,101 Epoch[21] Batch [860]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107823,	
2017-07-12 18:47:59,959 Epoch[21] Batch [870]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107920,	
2017-07-12 18:48:05,145 Epoch[21] Batch [880]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.107852,	
2017-07-12 18:48:10,735 Epoch[21] Batch [890]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.107826,	
2017-07-12 18:48:16,267 Epoch[21] Batch [900]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.107735,	
2017-07-12 18:48:21,871 Epoch[21] Batch [910]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.107627,	
2017-07-12 18:48:27,796 Epoch[21] Batch [920]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107573,	
2017-07-12 18:48:33,509 Epoch[21] Batch [930]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.107455,	
2017-07-12 18:48:39,295 Epoch[21] Batch [940]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107343,	
2017-07-12 18:48:45,370 Epoch[21] Batch [950]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107388,	
2017-07-12 18:48:51,397 Epoch[21] Batch [960]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.107262,	
2017-07-12 18:48:57,196 Epoch[21] Batch [970]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107264,	
2017-07-12 18:49:03,319 Epoch[21] Batch [980]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.107276,	
2017-07-12 18:49:09,131 Epoch[21] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107249,	
2017-07-12 18:49:15,174 Epoch[21] Batch [1000]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.107234,	
2017-07-12 18:49:20,568 Epoch[21] Batch [1010]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.107239,	
2017-07-12 18:49:26,956 Epoch[21] Batch [1020]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.107267,	
2017-07-12 18:49:32,874 Epoch[21] Batch [1030]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107218,	
2017-07-12 18:49:38,665 Epoch[21] Batch [1040]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.107158,	
2017-07-12 18:49:44,315 Epoch[21] Batch [1050]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.107184,	
2017-07-12 18:49:49,231 Epoch[21] Batch [1060]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.107144,	
2017-07-12 18:49:55,094 Epoch[21] Batch [1070]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.107102,	
2017-07-12 18:50:00,748 Epoch[21] Batch [1080]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.107284,	
2017-07-12 18:50:06,473 Epoch[21] Batch [1090]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.107338,	
2017-07-12 18:50:12,757 Epoch[21] Batch [1100]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.107352,	
2017-07-12 18:50:18,723 Epoch[21] Batch [1110]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.107196,	
2017-07-12 18:50:24,200 Epoch[21] Batch [1120]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.107384,	
2017-07-12 18:50:30,071 Epoch[21] Batch [1130]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.107653,	
2017-07-12 18:50:35,996 Epoch[21] Batch [1140]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107696,	
2017-07-12 18:50:42,362 Epoch[21] Batch [1150]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.107624,	
2017-07-12 18:50:47,873 Epoch[21] Batch [1160]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.107757,	
2017-07-12 18:50:53,992 Epoch[21] Batch [1170]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.107696,	
2017-07-12 18:50:59,671 Epoch[21] Batch [1180]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.107503,	
2017-07-12 18:51:05,537 Epoch[21] Batch [1190]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.107462,	
2017-07-12 18:51:11,615 Epoch[21] Batch [1200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107356,	
2017-07-12 18:51:17,539 Epoch[21] Batch [1210]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107300,	
2017-07-12 18:51:23,352 Epoch[21] Batch [1220]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107242,	
2017-07-12 18:51:28,940 Epoch[21] Batch [1230]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.107259,	
2017-07-12 18:51:34,394 Epoch[21] Batch [1240]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.107326,	
2017-07-12 18:51:40,323 Epoch[21] Batch [1250]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107309,	
2017-07-12 18:51:46,076 Epoch[21] Batch [1260]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.107336,	
2017-07-12 18:51:52,239 Epoch[21] Batch [1270]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.107404,	
2017-07-12 18:51:57,873 Epoch[21] Batch [1280]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.107430,	
2017-07-12 18:52:03,643 Epoch[21] Batch [1290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107468,	
2017-07-12 18:52:09,425 Epoch[21] Batch [1300]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107445,	
2017-07-12 18:52:14,931 Epoch[21] Batch [1310]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.107520,	
2017-07-12 18:52:21,187 Epoch[21] Batch [1320]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.107499,	
2017-07-12 18:52:26,946 Epoch[21] Batch [1330]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.107562,	
2017-07-12 18:52:32,924 Epoch[21] Batch [1340]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.107591,	
2017-07-12 18:52:38,625 Epoch[21] Batch [1350]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.107573,	
2017-07-12 18:52:44,534 Epoch[21] Batch [1360]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.107524,	
2017-07-12 18:52:50,502 Epoch[21] Batch [1370]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.107585,	
2017-07-12 18:52:56,109 Epoch[21] Batch [1380]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.107665,	
2017-07-12 18:53:01,817 Epoch[21] Batch [1390]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.107663,	
2017-07-12 18:53:07,512 Epoch[21] Batch [1400]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.107670,	
2017-07-12 18:53:12,980 Epoch[21] Batch [1410]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.107746,	
2017-07-12 18:53:18,915 Epoch[21] Batch [1420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107834,	
2017-07-12 18:53:24,856 Epoch[21] Batch [1430]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.107975,	
2017-07-12 18:53:30,835 Epoch[21] Batch [1440]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.107995,	
2017-07-12 18:53:36,350 Epoch[21] Batch [1450]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.108024,	
2017-07-12 18:53:42,245 Epoch[21] Batch [1460]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.108057,	
2017-07-12 18:53:48,225 Epoch[21] Batch [1470]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.108061,	
2017-07-12 18:53:54,074 Epoch[21] Batch [1480]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.108185,	
2017-07-12 18:53:57,634 Epoch[21] Train-FCNLogLoss=0.108265
2017-07-12 18:53:57,634 Epoch[21] Time cost=812.803
2017-07-12 18:53:58,542 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0022.params"
2017-07-12 18:54:00,319 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0022.states"
2017-07-12 18:54:07,145 Epoch[22] Batch [10]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.111225,	
2017-07-12 18:54:13,312 Epoch[22] Batch [20]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.118565,	
2017-07-12 18:54:18,963 Epoch[22] Batch [30]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.119975,	
2017-07-12 18:54:25,146 Epoch[22] Batch [40]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.115091,	
2017-07-12 18:54:30,975 Epoch[22] Batch [50]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.111821,	
2017-07-12 18:54:36,875 Epoch[22] Batch [60]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.111465,	
2017-07-12 18:54:42,870 Epoch[22] Batch [70]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.109219,	
2017-07-12 18:54:48,232 Epoch[22] Batch [80]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.107117,	
2017-07-12 18:54:54,245 Epoch[22] Batch [90]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107542,	
2017-07-12 18:55:00,021 Epoch[22] Batch [100]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.107275,	
2017-07-12 18:55:05,720 Epoch[22] Batch [110]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.107287,	
2017-07-12 18:55:11,736 Epoch[22] Batch [120]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107885,	
2017-07-12 18:55:17,843 Epoch[22] Batch [130]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.107782,	
2017-07-12 18:55:24,186 Epoch[22] Batch [140]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.108122,	
2017-07-12 18:55:29,935 Epoch[22] Batch [150]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.108173,	
2017-07-12 18:55:35,999 Epoch[22] Batch [160]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108322,	
2017-07-12 18:55:41,712 Epoch[22] Batch [170]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.110458,	
2017-07-12 18:55:47,518 Epoch[22] Batch [180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.114463,	
2017-07-12 18:55:53,458 Epoch[22] Batch [190]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.118148,	
2017-07-12 18:55:59,011 Epoch[22] Batch [200]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.120898,	
2017-07-12 18:56:04,721 Epoch[22] Batch [210]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.125240,	
2017-07-12 18:56:10,614 Epoch[22] Batch [220]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.126495,	
2017-07-12 18:56:16,509 Epoch[22] Batch [230]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.127685,	
2017-07-12 18:56:22,233 Epoch[22] Batch [240]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.128223,	
2017-07-12 18:56:27,758 Epoch[22] Batch [250]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.128685,	
2017-07-12 18:56:33,549 Epoch[22] Batch [260]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.129484,	
2017-07-12 18:56:39,684 Epoch[22] Batch [270]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.129558,	
2017-07-12 18:56:45,524 Epoch[22] Batch [280]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.132327,	
2017-07-12 18:56:51,540 Epoch[22] Batch [290]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.136528,	
2017-07-12 18:56:57,238 Epoch[22] Batch [300]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.138542,	
2017-07-12 18:57:03,035 Epoch[22] Batch [310]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.139455,	
2017-07-12 18:57:08,937 Epoch[22] Batch [320]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.140129,	
2017-07-12 18:57:14,664 Epoch[22] Batch [330]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.140347,	
2017-07-12 18:57:20,476 Epoch[22] Batch [340]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.140284,	
2017-07-12 18:57:26,441 Epoch[22] Batch [350]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.140303,	
2017-07-12 18:57:32,270 Epoch[22] Batch [360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.140329,	
2017-07-12 18:57:38,409 Epoch[22] Batch [370]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.140902,	
2017-07-12 18:57:44,301 Epoch[22] Batch [380]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.140592,	
2017-07-12 18:57:50,358 Epoch[22] Batch [390]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.140253,	
2017-07-12 18:57:56,577 Epoch[22] Batch [400]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.139671,	
2017-07-12 18:58:02,337 Epoch[22] Batch [410]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.139426,	
2017-07-12 18:58:08,200 Epoch[22] Batch [420]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.138962,	
2017-07-12 18:58:14,312 Epoch[22] Batch [430]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.138717,	
2017-07-12 18:58:20,467 Epoch[22] Batch [440]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.138440,	
2017-07-12 18:58:26,185 Epoch[22] Batch [450]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.138333,	
2017-07-12 18:58:31,987 Epoch[22] Batch [460]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.138068,	
2017-07-12 18:58:37,792 Epoch[22] Batch [470]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.137535,	
2017-07-12 18:58:44,168 Epoch[22] Batch [480]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.137001,	
2017-07-12 18:58:49,508 Epoch[22] Batch [490]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.136378,	
2017-07-12 18:58:55,583 Epoch[22] Batch [500]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.135753,	
2017-07-12 18:59:01,517 Epoch[22] Batch [510]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.135599,	
2017-07-12 18:59:07,236 Epoch[22] Batch [520]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.135473,	
2017-07-12 18:59:13,170 Epoch[22] Batch [530]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.135294,	
2017-07-12 18:59:18,882 Epoch[22] Batch [540]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.134842,	
2017-07-12 18:59:24,982 Epoch[22] Batch [550]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.134416,	
2017-07-12 18:59:31,021 Epoch[22] Batch [560]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.133984,	
2017-07-12 18:59:37,139 Epoch[22] Batch [570]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.133538,	
2017-07-12 18:59:43,255 Epoch[22] Batch [580]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.132970,	
2017-07-12 18:59:49,662 Epoch[22] Batch [590]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.133015,	
2017-07-12 18:59:55,826 Epoch[22] Batch [600]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.132732,	
2017-07-12 19:00:02,201 Epoch[22] Batch [610]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.132633,	
2017-07-12 19:00:08,386 Epoch[22] Batch [620]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.132283,	
2017-07-12 19:00:14,549 Epoch[22] Batch [630]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.131883,	
2017-07-12 19:00:20,823 Epoch[22] Batch [640]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.131512,	
2017-07-12 19:00:26,696 Epoch[22] Batch [650]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.131311,	
2017-07-12 19:00:32,861 Epoch[22] Batch [660]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.131016,	
2017-07-12 19:00:38,782 Epoch[22] Batch [670]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.130391,	
2017-07-12 19:00:45,098 Epoch[22] Batch [680]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.130089,	
2017-07-12 19:00:51,156 Epoch[22] Batch [690]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.129858,	
2017-07-12 19:00:57,194 Epoch[22] Batch [700]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.129547,	
2017-07-12 19:01:03,492 Epoch[22] Batch [710]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.129225,	
2017-07-12 19:01:09,175 Epoch[22] Batch [720]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.128853,	
2017-07-12 19:01:15,239 Epoch[22] Batch [730]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.128449,	
2017-07-12 19:01:21,258 Epoch[22] Batch [740]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.128693,	
2017-07-12 19:01:27,317 Epoch[22] Batch [750]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.128497,	
2017-07-12 19:01:33,383 Epoch[22] Batch [760]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.128063,	
2017-07-12 19:01:39,458 Epoch[22] Batch [770]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.127889,	
2017-07-12 19:01:45,434 Epoch[22] Batch [780]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.127611,	
2017-07-12 19:01:51,241 Epoch[22] Batch [790]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.127353,	
2017-07-12 19:01:57,385 Epoch[22] Batch [800]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.127083,	
2017-07-12 19:02:03,384 Epoch[22] Batch [810]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.126886,	
2017-07-12 19:02:09,311 Epoch[22] Batch [820]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.126582,	
2017-07-12 19:02:15,434 Epoch[22] Batch [830]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.126359,	
2017-07-12 19:02:21,269 Epoch[22] Batch [840]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.126228,	
2017-07-12 19:02:27,362 Epoch[22] Batch [850]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.126019,	
2017-07-12 19:02:33,124 Epoch[22] Batch [860]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.125806,	
2017-07-12 19:02:38,786 Epoch[22] Batch [870]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.125474,	
2017-07-12 19:02:44,945 Epoch[22] Batch [880]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.125393,	
2017-07-12 19:02:51,007 Epoch[22] Batch [890]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.125205,	
2017-07-12 19:02:57,012 Epoch[22] Batch [900]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.124956,	
2017-07-12 19:03:02,925 Epoch[22] Batch [910]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.124757,	
2017-07-12 19:03:08,374 Epoch[22] Batch [920]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.124567,	
2017-07-12 19:03:14,330 Epoch[22] Batch [930]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.124339,	
2017-07-12 19:03:20,054 Epoch[22] Batch [940]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.124165,	
2017-07-12 19:03:25,907 Epoch[22] Batch [950]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.124089,	
2017-07-12 19:03:32,054 Epoch[22] Batch [960]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.123888,	
2017-07-12 19:03:37,822 Epoch[22] Batch [970]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.123854,	
2017-07-12 19:03:43,798 Epoch[22] Batch [980]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.123687,	
2017-07-12 19:03:49,831 Epoch[22] Batch [990]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.123369,	
2017-07-12 19:03:55,785 Epoch[22] Batch [1000]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.123076,	
2017-07-12 19:04:01,692 Epoch[22] Batch [1010]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.122925,	
2017-07-12 19:04:07,752 Epoch[22] Batch [1020]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.122827,	
2017-07-12 19:04:14,080 Epoch[22] Batch [1030]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.122822,	
2017-07-12 19:04:19,919 Epoch[22] Batch [1040]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.122614,	
2017-07-12 19:04:26,048 Epoch[22] Batch [1050]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.122381,	
2017-07-12 19:04:32,173 Epoch[22] Batch [1060]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.122284,	
2017-07-12 19:04:38,292 Epoch[22] Batch [1070]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.122055,	
2017-07-12 19:04:44,385 Epoch[22] Batch [1080]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.122002,	
2017-07-12 19:04:50,314 Epoch[22] Batch [1090]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.121757,	
2017-07-12 19:04:56,298 Epoch[22] Batch [1100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.121642,	
2017-07-12 19:05:02,108 Epoch[22] Batch [1110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.121557,	
2017-07-12 19:05:08,160 Epoch[22] Batch [1120]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.121386,	
2017-07-12 19:05:14,404 Epoch[22] Batch [1130]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.121577,	
2017-07-12 19:05:20,521 Epoch[22] Batch [1140]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.121495,	
2017-07-12 19:05:26,653 Epoch[22] Batch [1150]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.121461,	
2017-07-12 19:05:32,394 Epoch[22] Batch [1160]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.121315,	
2017-07-12 19:05:38,516 Epoch[22] Batch [1170]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.121130,	
2017-07-12 19:05:44,975 Epoch[22] Batch [1180]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.120987,	
2017-07-12 19:05:51,022 Epoch[22] Batch [1190]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.120899,	
2017-07-12 19:05:57,078 Epoch[22] Batch [1200]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.120699,	
2017-07-12 19:06:02,936 Epoch[22] Batch [1210]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.120521,	
2017-07-12 19:06:09,179 Epoch[22] Batch [1220]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.120391,	
2017-07-12 19:06:15,185 Epoch[22] Batch [1230]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.120178,	
2017-07-12 19:06:21,224 Epoch[22] Batch [1240]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.120010,	
2017-07-12 19:06:27,646 Epoch[22] Batch [1250]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.119842,	
2017-07-12 19:06:33,959 Epoch[22] Batch [1260]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.119720,	
2017-07-12 19:06:40,107 Epoch[22] Batch [1270]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.119601,	
2017-07-12 19:06:45,848 Epoch[22] Batch [1280]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.119493,	
2017-07-12 19:06:52,109 Epoch[22] Batch [1290]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.119442,	
2017-07-12 19:06:58,058 Epoch[22] Batch [1300]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.119302,	
2017-07-12 19:07:04,320 Epoch[22] Batch [1310]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.119285,	
2017-07-12 19:07:10,497 Epoch[22] Batch [1320]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.119093,	
2017-07-12 19:07:16,745 Epoch[22] Batch [1330]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.119052,	
2017-07-12 19:07:22,890 Epoch[22] Batch [1340]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.118899,	
2017-07-12 19:07:29,168 Epoch[22] Batch [1350]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.118842,	
2017-07-12 19:07:35,334 Epoch[22] Batch [1360]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.118750,	
2017-07-12 19:07:41,291 Epoch[22] Batch [1370]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.118633,	
2017-07-12 19:07:47,229 Epoch[22] Batch [1380]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.118507,	
2017-07-12 19:07:53,286 Epoch[22] Batch [1390]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.118381,	
2017-07-12 19:07:59,568 Epoch[22] Batch [1400]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.118300,	
2017-07-12 19:08:05,705 Epoch[22] Batch [1410]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.118279,	
2017-07-12 19:08:11,838 Epoch[22] Batch [1420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.118149,	
2017-07-12 19:08:18,317 Epoch[22] Batch [1430]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.118065,	
2017-07-12 19:08:24,513 Epoch[22] Batch [1440]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.118097,	
2017-07-12 19:08:30,805 Epoch[22] Batch [1450]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.118085,	
2017-07-12 19:08:36,579 Epoch[22] Batch [1460]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.118039,	
2017-07-12 19:08:42,275 Epoch[22] Batch [1470]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.117939,	
2017-07-12 19:08:48,227 Epoch[22] Batch [1480]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.117829,	
2017-07-12 19:08:51,803 Epoch[22] Train-FCNLogLoss=0.117781
2017-07-12 19:08:51,803 Epoch[22] Time cost=891.484
2017-07-12 19:08:52,789 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0023.params"
2017-07-12 19:08:54,776 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0023.states"
2017-07-12 19:09:01,777 Epoch[23] Batch [10]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.117993,	
2017-07-12 19:09:07,571 Epoch[23] Batch [20]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.123613,	
2017-07-12 19:09:13,639 Epoch[23] Batch [30]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.119968,	
2017-07-12 19:09:19,560 Epoch[23] Batch [40]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.119398,	
2017-07-12 19:09:25,546 Epoch[23] Batch [50]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.115733,	
2017-07-12 19:09:31,432 Epoch[23] Batch [60]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.115203,	
2017-07-12 19:09:37,316 Epoch[23] Batch [70]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.115243,	
2017-07-12 19:09:43,494 Epoch[23] Batch [80]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.114075,	
2017-07-12 19:09:49,708 Epoch[23] Batch [90]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.112547,	
2017-07-12 19:09:55,758 Epoch[23] Batch [100]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.111789,	
2017-07-12 19:10:01,826 Epoch[23] Batch [110]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.112325,	
2017-07-12 19:10:07,592 Epoch[23] Batch [120]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.112305,	
2017-07-12 19:10:13,571 Epoch[23] Batch [130]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.112780,	
2017-07-12 19:10:19,584 Epoch[23] Batch [140]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.111812,	
2017-07-12 19:10:25,335 Epoch[23] Batch [150]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.111448,	
2017-07-12 19:10:31,189 Epoch[23] Batch [160]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.111197,	
2017-07-12 19:10:37,036 Epoch[23] Batch [170]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.111523,	
2017-07-12 19:10:42,874 Epoch[23] Batch [180]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.111088,	
2017-07-12 19:10:48,862 Epoch[23] Batch [190]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.110708,	
2017-07-12 19:10:54,463 Epoch[23] Batch [200]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.109929,	
2017-07-12 19:11:00,299 Epoch[23] Batch [210]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.109855,	
2017-07-12 19:11:06,060 Epoch[23] Batch [220]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.109671,	
2017-07-12 19:11:11,947 Epoch[23] Batch [230]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.109551,	
2017-07-12 19:11:17,880 Epoch[23] Batch [240]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108978,	
2017-07-12 19:11:24,121 Epoch[23] Batch [250]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.109129,	
2017-07-12 19:11:29,883 Epoch[23] Batch [260]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.109382,	
2017-07-12 19:11:36,092 Epoch[23] Batch [270]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.109428,	
2017-07-12 19:11:42,163 Epoch[23] Batch [280]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109071,	
2017-07-12 19:11:48,002 Epoch[23] Batch [290]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.108777,	
2017-07-12 19:11:53,760 Epoch[23] Batch [300]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.108722,	
2017-07-12 19:11:59,757 Epoch[23] Batch [310]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.108494,	
2017-07-12 19:12:05,745 Epoch[23] Batch [320]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.108886,	
2017-07-12 19:12:12,132 Epoch[23] Batch [330]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.108885,	
2017-07-12 19:12:17,882 Epoch[23] Batch [340]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.109317,	
2017-07-12 19:12:23,819 Epoch[23] Batch [350]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.109447,	
2017-07-12 19:12:29,521 Epoch[23] Batch [360]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.109565,	
2017-07-12 19:12:35,298 Epoch[23] Batch [370]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.109412,	
2017-07-12 19:12:41,280 Epoch[23] Batch [380]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.109191,	
2017-07-12 19:12:47,432 Epoch[23] Batch [390]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.108883,	
2017-07-12 19:12:53,507 Epoch[23] Batch [400]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109009,	
2017-07-12 19:12:59,918 Epoch[23] Batch [410]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.109066,	
2017-07-12 19:13:06,123 Epoch[23] Batch [420]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.109117,	
2017-07-12 19:13:12,137 Epoch[23] Batch [430]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.109020,	
2017-07-12 19:13:18,122 Epoch[23] Batch [440]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.108796,	
2017-07-12 19:13:24,026 Epoch[23] Batch [450]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108678,	
2017-07-12 19:13:29,930 Epoch[23] Batch [460]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108427,	
2017-07-12 19:13:36,180 Epoch[23] Batch [470]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.108242,	
2017-07-12 19:13:42,232 Epoch[23] Batch [480]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.108023,	
2017-07-12 19:13:48,336 Epoch[23] Batch [490]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.107988,	
2017-07-12 19:13:54,319 Epoch[23] Batch [500]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.107776,	
2017-07-12 19:14:00,461 Epoch[23] Batch [510]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.107901,	
2017-07-12 19:14:06,272 Epoch[23] Batch [520]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107860,	
2017-07-12 19:14:12,190 Epoch[23] Batch [530]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107859,	
2017-07-12 19:14:17,914 Epoch[23] Batch [540]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.107953,	
2017-07-12 19:14:23,929 Epoch[23] Batch [550]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107937,	
2017-07-12 19:14:29,862 Epoch[23] Batch [560]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107921,	
2017-07-12 19:14:35,878 Epoch[23] Batch [570]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107980,	
2017-07-12 19:14:42,003 Epoch[23] Batch [580]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.107952,	
2017-07-12 19:14:47,969 Epoch[23] Batch [590]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.107934,	
2017-07-12 19:14:53,848 Epoch[23] Batch [600]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.107913,	
2017-07-12 19:14:59,762 Epoch[23] Batch [610]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107894,	
2017-07-12 19:15:05,467 Epoch[23] Batch [620]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.107864,	
2017-07-12 19:15:11,538 Epoch[23] Batch [630]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107919,	
2017-07-12 19:15:17,514 Epoch[23] Batch [640]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.107910,	
2017-07-12 19:15:23,593 Epoch[23] Batch [650]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107941,	
2017-07-12 19:15:29,784 Epoch[23] Batch [660]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.107977,	
2017-07-12 19:15:35,861 Epoch[23] Batch [670]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107945,	
2017-07-12 19:15:41,797 Epoch[23] Batch [680]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107944,	
2017-07-12 19:15:48,015 Epoch[23] Batch [690]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.108010,	
2017-07-12 19:15:54,032 Epoch[23] Batch [700]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.108091,	
2017-07-12 19:16:00,038 Epoch[23] Batch [710]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.107962,	
2017-07-12 19:16:05,966 Epoch[23] Batch [720]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107862,	
2017-07-12 19:16:11,888 Epoch[23] Batch [730]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107702,	
2017-07-12 19:16:17,742 Epoch[23] Batch [740]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107643,	
2017-07-12 19:16:23,637 Epoch[23] Batch [750]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.107593,	
2017-07-12 19:16:29,688 Epoch[23] Batch [760]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107587,	
2017-07-12 19:16:35,842 Epoch[23] Batch [770]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.107424,	
2017-07-12 19:16:41,637 Epoch[23] Batch [780]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.107390,	
2017-07-12 19:16:47,513 Epoch[23] Batch [790]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.107403,	
2017-07-12 19:16:53,763 Epoch[23] Batch [800]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.107382,	
2017-07-12 19:16:59,698 Epoch[23] Batch [810]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107284,	
2017-07-12 19:17:06,105 Epoch[23] Batch [820]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.107202,	
2017-07-12 19:17:12,259 Epoch[23] Batch [830]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.107127,	
2017-07-12 19:17:18,225 Epoch[23] Batch [840]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.107147,	
2017-07-12 19:17:24,402 Epoch[23] Batch [850]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.107098,	
2017-07-12 19:17:30,752 Epoch[23] Batch [860]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.107018,	
2017-07-12 19:17:36,939 Epoch[23] Batch [870]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.106976,	
2017-07-12 19:17:42,985 Epoch[23] Batch [880]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.106727,	
2017-07-12 19:17:49,061 Epoch[23] Batch [890]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.106629,	
2017-07-12 19:17:55,036 Epoch[23] Batch [900]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.106640,	
2017-07-12 19:18:01,383 Epoch[23] Batch [910]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.106410,	
2017-07-12 19:18:07,922 Epoch[23] Batch [920]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.106439,	
2017-07-12 19:18:14,160 Epoch[23] Batch [930]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106478,	
2017-07-12 19:18:20,378 Epoch[23] Batch [940]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.106504,	
2017-07-12 19:18:26,714 Epoch[23] Batch [950]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.106522,	
2017-07-12 19:18:33,169 Epoch[23] Batch [960]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.106618,	
2017-07-12 19:18:39,234 Epoch[23] Batch [970]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.106729,	
2017-07-12 19:18:45,284 Epoch[23] Batch [980]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106772,	
2017-07-12 19:18:51,374 Epoch[23] Batch [990]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106843,	
2017-07-12 19:18:57,539 Epoch[23] Batch [1000]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.106886,	
2017-07-12 19:19:03,535 Epoch[23] Batch [1010]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.106947,	
2017-07-12 19:19:09,677 Epoch[23] Batch [1020]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.106989,	
2017-07-12 19:19:15,970 Epoch[23] Batch [1030]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.107007,	
2017-07-12 19:19:22,196 Epoch[23] Batch [1040]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.107030,	
2017-07-12 19:19:28,617 Epoch[23] Batch [1050]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.107265,	
2017-07-12 19:19:34,628 Epoch[23] Batch [1060]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.107246,	
2017-07-12 19:19:40,811 Epoch[23] Batch [1070]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.107179,	
2017-07-12 19:19:46,825 Epoch[23] Batch [1080]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107164,	
2017-07-12 19:19:52,812 Epoch[23] Batch [1090]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106996,	
2017-07-12 19:19:58,652 Epoch[23] Batch [1100]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107046,	
2017-07-12 19:20:04,637 Epoch[23] Batch [1110]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.107105,	
2017-07-12 19:20:11,083 Epoch[23] Batch [1120]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.107112,	
2017-07-12 19:20:17,261 Epoch[23] Batch [1130]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.106964,	
2017-07-12 19:20:23,843 Epoch[23] Batch [1140]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.106953,	
2017-07-12 19:20:30,014 Epoch[23] Batch [1150]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.106883,	
2017-07-12 19:20:36,356 Epoch[23] Batch [1160]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.106924,	
2017-07-12 19:20:42,476 Epoch[23] Batch [1170]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.106885,	
2017-07-12 19:20:48,693 Epoch[23] Batch [1180]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.106773,	
2017-07-12 19:20:54,921 Epoch[23] Batch [1190]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.106669,	
2017-07-12 19:21:01,051 Epoch[23] Batch [1200]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.106634,	
2017-07-12 19:21:07,388 Epoch[23] Batch [1210]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.106737,	
2017-07-12 19:21:13,230 Epoch[23] Batch [1220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.106700,	
2017-07-12 19:21:19,571 Epoch[23] Batch [1230]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.106702,	
2017-07-12 19:21:25,727 Epoch[23] Batch [1240]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.106704,	
2017-07-12 19:21:31,888 Epoch[23] Batch [1250]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.106646,	
2017-07-12 19:21:37,915 Epoch[23] Batch [1260]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.106594,	
2017-07-12 19:21:44,147 Epoch[23] Batch [1270]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.106511,	
2017-07-12 19:21:50,405 Epoch[23] Batch [1280]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.106456,	
2017-07-12 19:21:56,883 Epoch[23] Batch [1290]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.106404,	
2017-07-12 19:22:03,062 Epoch[23] Batch [1300]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.106523,	
2017-07-12 19:22:09,188 Epoch[23] Batch [1310]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.106599,	
2017-07-12 19:22:15,584 Epoch[23] Batch [1320]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.106666,	
2017-07-12 19:22:21,622 Epoch[23] Batch [1330]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.107020,	
2017-07-12 19:22:27,940 Epoch[23] Batch [1340]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.107184,	
2017-07-12 19:22:34,014 Epoch[23] Batch [1350]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107261,	
2017-07-12 19:22:40,195 Epoch[23] Batch [1360]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.107235,	
2017-07-12 19:22:46,267 Epoch[23] Batch [1370]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107208,	
2017-07-12 19:22:52,377 Epoch[23] Batch [1380]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.107147,	
2017-07-12 19:22:58,811 Epoch[23] Batch [1390]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.107115,	
2017-07-12 19:23:04,766 Epoch[23] Batch [1400]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.107050,	
2017-07-12 19:23:11,273 Epoch[23] Batch [1410]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.107090,	
2017-07-12 19:23:17,325 Epoch[23] Batch [1420]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107114,	
2017-07-12 19:23:23,199 Epoch[23] Batch [1430]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.107200,	
2017-07-12 19:23:29,765 Epoch[23] Batch [1440]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.107297,	
2017-07-12 19:23:35,963 Epoch[23] Batch [1450]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.107207,	
2017-07-12 19:23:42,171 Epoch[23] Batch [1460]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.107187,	
2017-07-12 19:23:48,376 Epoch[23] Batch [1470]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.107205,	
2017-07-12 19:23:54,890 Epoch[23] Batch [1480]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.107211,	
2017-07-12 19:23:58,498 Epoch[23] Train-FCNLogLoss=0.107236
2017-07-12 19:23:58,499 Epoch[23] Time cost=903.722
2017-07-12 19:23:59,521 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0024.params"
2017-07-12 19:24:01,216 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0024.states"
2017-07-12 19:24:08,251 Epoch[24] Batch [10]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.106134,	
2017-07-12 19:24:14,131 Epoch[24] Batch [20]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.106437,	
2017-07-12 19:24:20,342 Epoch[24] Batch [30]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.106420,	
2017-07-12 19:24:26,415 Epoch[24] Batch [40]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.104524,	
2017-07-12 19:24:32,830 Epoch[24] Batch [50]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.102303,	
2017-07-12 19:24:39,480 Epoch[24] Batch [60]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.099752,	
2017-07-12 19:24:45,789 Epoch[24] Batch [70]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.101548,	
2017-07-12 19:24:52,117 Epoch[24] Batch [80]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.100965,	
2017-07-12 19:24:58,316 Epoch[24] Batch [90]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.101997,	
2017-07-12 19:25:04,580 Epoch[24] Batch [100]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.101377,	
2017-07-12 19:25:10,465 Epoch[24] Batch [110]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.101230,	
2017-07-12 19:25:16,781 Epoch[24] Batch [120]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.100974,	
2017-07-12 19:25:22,912 Epoch[24] Batch [130]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101231,	
2017-07-12 19:25:29,088 Epoch[24] Batch [140]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.101048,	
2017-07-12 19:25:35,274 Epoch[24] Batch [150]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.101785,	
2017-07-12 19:25:41,378 Epoch[24] Batch [160]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102066,	
2017-07-12 19:25:47,596 Epoch[24] Batch [170]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.102029,	
2017-07-12 19:25:53,864 Epoch[24] Batch [180]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.101720,	
2017-07-12 19:26:00,094 Epoch[24] Batch [190]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.102204,	
2017-07-12 19:26:06,227 Epoch[24] Batch [200]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102745,	
2017-07-12 19:26:12,452 Epoch[24] Batch [210]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.103104,	
2017-07-12 19:26:18,356 Epoch[24] Batch [220]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.103098,	
2017-07-12 19:26:24,333 Epoch[24] Batch [230]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.103097,	
2017-07-12 19:26:30,638 Epoch[24] Batch [240]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.102962,	
2017-07-12 19:26:36,656 Epoch[24] Batch [250]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.103316,	
2017-07-12 19:26:42,797 Epoch[24] Batch [260]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.103183,	
2017-07-12 19:26:49,285 Epoch[24] Batch [270]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.103166,	
2017-07-12 19:26:55,607 Epoch[24] Batch [280]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.102880,	
2017-07-12 19:27:01,587 Epoch[24] Batch [290]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102853,	
2017-07-12 19:27:07,797 Epoch[24] Batch [300]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.103147,	
2017-07-12 19:27:14,331 Epoch[24] Batch [310]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.103273,	
2017-07-12 19:27:20,703 Epoch[24] Batch [320]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.103358,	
2017-07-12 19:27:26,966 Epoch[24] Batch [330]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.103682,	
2017-07-12 19:27:33,248 Epoch[24] Batch [340]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.103762,	
2017-07-12 19:27:39,811 Epoch[24] Batch [350]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.103785,	
2017-07-12 19:27:46,131 Epoch[24] Batch [360]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.103652,	
2017-07-12 19:27:52,427 Epoch[24] Batch [370]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.103643,	
2017-07-12 19:27:58,990 Epoch[24] Batch [380]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.103745,	
2017-07-12 19:28:05,027 Epoch[24] Batch [390]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103794,	
2017-07-12 19:28:11,209 Epoch[24] Batch [400]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.103788,	
2017-07-12 19:28:17,475 Epoch[24] Batch [410]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.103715,	
2017-07-12 19:28:23,516 Epoch[24] Batch [420]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103903,	
2017-07-12 19:28:30,207 Epoch[24] Batch [430]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.103614,	
2017-07-12 19:28:36,917 Epoch[24] Batch [440]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.103534,	
2017-07-12 19:28:43,239 Epoch[24] Batch [450]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.103708,	
2017-07-12 19:28:49,465 Epoch[24] Batch [460]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.103561,	
2017-07-12 19:28:55,927 Epoch[24] Batch [470]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.103474,	
2017-07-12 19:29:02,399 Epoch[24] Batch [480]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.103304,	
2017-07-12 19:29:08,932 Epoch[24] Batch [490]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.103438,	
2017-07-12 19:29:15,358 Epoch[24] Batch [500]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.103349,	
2017-07-12 19:29:21,911 Epoch[24] Batch [510]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.103014,	
2017-07-12 19:29:28,082 Epoch[24] Batch [520]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.102784,	
2017-07-12 19:29:34,517 Epoch[24] Batch [530]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.102817,	
2017-07-12 19:29:41,016 Epoch[24] Batch [540]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.102802,	
2017-07-12 19:29:47,107 Epoch[24] Batch [550]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103142,	
2017-07-12 19:29:53,295 Epoch[24] Batch [560]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.103260,	
2017-07-12 19:29:59,417 Epoch[24] Batch [570]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103299,	
2017-07-12 19:30:05,486 Epoch[24] Batch [580]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103593,	
2017-07-12 19:30:11,594 Epoch[24] Batch [590]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103644,	
2017-07-12 19:30:17,755 Epoch[24] Batch [600]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.103757,	
2017-07-12 19:30:24,154 Epoch[24] Batch [610]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.103772,	
2017-07-12 19:30:30,630 Epoch[24] Batch [620]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.103766,	
2017-07-12 19:30:36,970 Epoch[24] Batch [630]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.103826,	
2017-07-12 19:30:43,359 Epoch[24] Batch [640]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103908,	
2017-07-12 19:30:49,813 Epoch[24] Batch [650]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.103685,	
2017-07-12 19:30:56,286 Epoch[24] Batch [660]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.103530,	
2017-07-12 19:31:02,592 Epoch[24] Batch [670]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.103697,	
2017-07-12 19:31:09,054 Epoch[24] Batch [680]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.103805,	
2017-07-12 19:31:15,440 Epoch[24] Batch [690]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103891,	
2017-07-12 19:31:21,583 Epoch[24] Batch [700]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.103753,	
2017-07-12 19:31:27,888 Epoch[24] Batch [710]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.103751,	
2017-07-12 19:31:34,454 Epoch[24] Batch [720]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.103756,	
2017-07-12 19:31:41,114 Epoch[24] Batch [730]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.103702,	
2017-07-12 19:31:47,474 Epoch[24] Batch [740]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.103851,	
2017-07-12 19:31:53,681 Epoch[24] Batch [750]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.103803,	
2017-07-12 19:31:59,922 Epoch[24] Batch [760]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.103744,	
2017-07-12 19:32:06,234 Epoch[24] Batch [770]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.103937,	
2017-07-12 19:32:12,339 Epoch[24] Batch [780]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104160,	
2017-07-12 19:32:19,054 Epoch[24] Batch [790]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.104286,	
2017-07-12 19:32:25,209 Epoch[24] Batch [800]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.104470,	
2017-07-12 19:32:31,331 Epoch[24] Batch [810]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.104650,	
2017-07-12 19:32:37,474 Epoch[24] Batch [820]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.104686,	
2017-07-12 19:32:44,137 Epoch[24] Batch [830]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.104698,	
2017-07-12 19:32:50,236 Epoch[24] Batch [840]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.104582,	
2017-07-12 19:32:56,585 Epoch[24] Batch [850]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.104606,	
2017-07-12 19:33:02,899 Epoch[24] Batch [860]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.104432,	
2017-07-12 19:33:09,211 Epoch[24] Batch [870]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.104498,	
2017-07-12 19:33:15,652 Epoch[24] Batch [880]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.104522,	
2017-07-12 19:33:22,323 Epoch[24] Batch [890]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.104511,	
2017-07-12 19:33:28,827 Epoch[24] Batch [900]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.104390,	
2017-07-12 19:33:35,156 Epoch[24] Batch [910]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.104277,	
2017-07-12 19:33:41,443 Epoch[24] Batch [920]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.104165,	
2017-07-12 19:33:47,766 Epoch[24] Batch [930]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.104150,	
2017-07-12 19:33:53,984 Epoch[24] Batch [940]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.104241,	
2017-07-12 19:34:00,245 Epoch[24] Batch [950]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.104268,	
2017-07-12 19:34:06,672 Epoch[24] Batch [960]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.104290,	
2017-07-12 19:34:12,830 Epoch[24] Batch [970]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.104346,	
2017-07-12 19:34:19,111 Epoch[24] Batch [980]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.104399,	
2017-07-12 19:34:25,551 Epoch[24] Batch [990]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.104373,	
2017-07-12 19:34:31,984 Epoch[24] Batch [1000]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.104386,	
2017-07-12 19:34:38,473 Epoch[24] Batch [1010]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.104379,	
2017-07-12 19:34:45,344 Epoch[24] Batch [1020]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.104407,	
2017-07-12 19:34:51,689 Epoch[24] Batch [1030]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.104420,	
2017-07-12 19:34:58,068 Epoch[24] Batch [1040]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.104393,	
2017-07-12 19:35:04,356 Epoch[24] Batch [1050]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.104283,	
2017-07-12 19:35:10,825 Epoch[24] Batch [1060]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.104265,	
2017-07-12 19:35:17,127 Epoch[24] Batch [1070]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.104229,	
2017-07-12 19:35:23,303 Epoch[24] Batch [1080]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.104213,	
2017-07-12 19:35:30,281 Epoch[24] Batch [1090]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.104224,	
2017-07-12 19:35:36,713 Epoch[24] Batch [1100]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.104255,	
2017-07-12 19:35:42,891 Epoch[24] Batch [1110]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.104229,	
2017-07-12 19:35:49,382 Epoch[24] Batch [1120]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.104223,	
2017-07-12 19:35:55,893 Epoch[24] Batch [1130]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.104215,	
2017-07-12 19:36:02,247 Epoch[24] Batch [1140]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.104227,	
2017-07-12 19:36:08,498 Epoch[24] Batch [1150]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.104199,	
2017-07-12 19:36:14,974 Epoch[24] Batch [1160]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.104160,	
2017-07-12 19:36:21,689 Epoch[24] Batch [1170]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.104154,	
2017-07-12 19:36:28,362 Epoch[24] Batch [1180]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.104063,	
2017-07-12 19:36:34,733 Epoch[24] Batch [1190]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.104112,	
2017-07-12 19:36:41,143 Epoch[24] Batch [1200]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.104120,	
2017-07-12 19:36:47,447 Epoch[24] Batch [1210]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.104122,	
2017-07-12 19:36:53,528 Epoch[24] Batch [1220]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.104008,	
2017-07-12 19:36:59,868 Epoch[24] Batch [1230]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.103965,	
2017-07-12 19:37:06,311 Epoch[24] Batch [1240]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.103934,	
2017-07-12 19:37:13,074 Epoch[24] Batch [1250]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.104005,	
2017-07-12 19:37:19,517 Epoch[24] Batch [1260]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.104030,	
2017-07-12 19:37:25,719 Epoch[24] Batch [1270]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.104118,	
2017-07-12 19:37:32,200 Epoch[24] Batch [1280]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.104110,	
2017-07-12 19:37:38,245 Epoch[24] Batch [1290]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.104194,	
2017-07-12 19:37:45,003 Epoch[24] Batch [1300]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.104186,	
2017-07-12 19:37:51,284 Epoch[24] Batch [1310]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.104151,	
2017-07-12 19:37:57,603 Epoch[24] Batch [1320]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.104157,	
2017-07-12 19:38:03,790 Epoch[24] Batch [1330]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.104138,	
2017-07-12 19:38:10,247 Epoch[24] Batch [1340]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.104159,	
2017-07-12 19:38:16,671 Epoch[24] Batch [1350]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.104047,	
2017-07-12 19:38:23,435 Epoch[24] Batch [1360]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.103989,	
2017-07-12 19:38:29,692 Epoch[24] Batch [1370]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.103930,	
2017-07-12 19:38:36,056 Epoch[24] Batch [1380]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.103944,	
2017-07-12 19:38:42,373 Epoch[24] Batch [1390]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.103999,	
2017-07-12 19:38:48,658 Epoch[24] Batch [1400]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.103953,	
2017-07-12 19:38:55,319 Epoch[24] Batch [1410]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.103901,	
2017-07-12 19:39:01,835 Epoch[24] Batch [1420]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.103877,	
2017-07-12 19:39:08,215 Epoch[24] Batch [1430]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.103846,	
2017-07-12 19:39:14,512 Epoch[24] Batch [1440]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.103926,	
2017-07-12 19:39:21,042 Epoch[24] Batch [1450]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.103897,	
2017-07-12 19:39:27,531 Epoch[24] Batch [1460]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.103872,	
2017-07-12 19:39:33,998 Epoch[24] Batch [1470]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.103967,	
2017-07-12 19:39:40,272 Epoch[24] Batch [1480]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.103908,	
2017-07-12 19:39:44,216 Epoch[24] Train-FCNLogLoss=0.103872
2017-07-12 19:39:44,216 Epoch[24] Time cost=942.999
2017-07-12 19:39:45,060 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0025.params"
2017-07-12 19:39:46,732 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0025.states"
2017-07-12 19:39:54,083 Epoch[25] Batch [10]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.100768,	
2017-07-12 19:40:00,309 Epoch[25] Batch [20]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.097299,	
2017-07-12 19:40:06,847 Epoch[25] Batch [30]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.099207,	
2017-07-12 19:40:13,176 Epoch[25] Batch [40]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.101699,	
2017-07-12 19:40:19,475 Epoch[25] Batch [50]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.100196,	
2017-07-12 19:40:25,710 Epoch[25] Batch [60]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.100335,	
2017-07-12 19:40:32,367 Epoch[25] Batch [70]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.100086,	
2017-07-12 19:40:39,036 Epoch[25] Batch [80]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.099939,	
2017-07-12 19:40:45,363 Epoch[25] Batch [90]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.100364,	
2017-07-12 19:40:51,453 Epoch[25] Batch [100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101879,	
2017-07-12 19:40:57,825 Epoch[25] Batch [110]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.102861,	
2017-07-12 19:41:04,707 Epoch[25] Batch [120]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.101424,	
2017-07-12 19:41:11,163 Epoch[25] Batch [130]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.101451,	
2017-07-12 19:41:17,556 Epoch[25] Batch [140]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.101649,	
2017-07-12 19:41:23,638 Epoch[25] Batch [150]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101966,	
2017-07-12 19:41:30,110 Epoch[25] Batch [160]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.102070,	
2017-07-12 19:41:36,274 Epoch[25] Batch [170]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101699,	
2017-07-12 19:41:42,781 Epoch[25] Batch [180]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.101865,	
2017-07-12 19:41:49,492 Epoch[25] Batch [190]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.101763,	
2017-07-12 19:41:56,066 Epoch[25] Batch [200]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.101527,	
2017-07-12 19:42:02,479 Epoch[25] Batch [210]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.101442,	
2017-07-12 19:42:09,021 Epoch[25] Batch [220]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.101300,	
2017-07-12 19:42:15,322 Epoch[25] Batch [230]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.100992,	
2017-07-12 19:42:21,938 Epoch[25] Batch [240]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.100423,	
2017-07-12 19:42:28,557 Epoch[25] Batch [250]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.100295,	
2017-07-12 19:42:35,274 Epoch[25] Batch [260]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.099968,	
2017-07-12 19:42:41,768 Epoch[25] Batch [270]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.100174,	
2017-07-12 19:42:48,539 Epoch[25] Batch [280]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.099728,	
2017-07-12 19:42:55,194 Epoch[25] Batch [290]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.099696,	
2017-07-12 19:43:01,887 Epoch[25] Batch [300]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.099798,	
2017-07-12 19:43:08,543 Epoch[25] Batch [310]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.099748,	
2017-07-12 19:43:15,146 Epoch[25] Batch [320]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.099446,	
2017-07-12 19:43:21,977 Epoch[25] Batch [330]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.099578,	
2017-07-12 19:43:28,628 Epoch[25] Batch [340]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.099526,	
2017-07-12 19:43:35,189 Epoch[25] Batch [350]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.099624,	
2017-07-12 19:43:41,661 Epoch[25] Batch [360]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.099944,	
2017-07-12 19:43:48,780 Epoch[25] Batch [370]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.099989,	
2017-07-12 19:43:55,443 Epoch[25] Batch [380]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.099874,	
2017-07-12 19:44:01,625 Epoch[25] Batch [390]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.099759,	
2017-07-12 19:44:07,801 Epoch[25] Batch [400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.099687,	
2017-07-12 19:44:14,117 Epoch[25] Batch [410]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.099194,	
2017-07-12 19:44:21,089 Epoch[25] Batch [420]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.099315,	
2017-07-12 19:44:27,960 Epoch[25] Batch [430]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.099275,	
2017-07-12 19:44:34,629 Epoch[25] Batch [440]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.099317,	
2017-07-12 19:44:41,711 Epoch[25] Batch [450]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.099428,	
2017-07-12 19:44:48,744 Epoch[25] Batch [460]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.099327,	
2017-07-12 19:44:55,480 Epoch[25] Batch [470]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.099517,	
2017-07-12 19:45:02,221 Epoch[25] Batch [480]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.099443,	
2017-07-12 19:45:08,753 Epoch[25] Batch [490]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.099401,	
2017-07-12 19:45:15,445 Epoch[25] Batch [500]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.099713,	
2017-07-12 19:45:22,323 Epoch[25] Batch [510]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.099748,	
2017-07-12 19:45:29,187 Epoch[25] Batch [520]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.100121,	
2017-07-12 19:45:36,475 Epoch[25] Batch [530]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.100318,	
2017-07-12 19:45:43,488 Epoch[25] Batch [540]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.100084,	
2017-07-12 19:45:50,360 Epoch[25] Batch [550]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.100002,	
2017-07-12 19:45:57,194 Epoch[25] Batch [560]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.099864,	
2017-07-12 19:46:04,085 Epoch[25] Batch [570]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.100032,	
2017-07-12 19:46:10,956 Epoch[25] Batch [580]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.100046,	
2017-07-12 19:46:18,257 Epoch[25] Batch [590]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.100070,	
2017-07-12 19:46:25,265 Epoch[25] Batch [600]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.100093,	
2017-07-12 19:46:31,947 Epoch[25] Batch [610]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.099901,	
2017-07-12 19:46:38,516 Epoch[25] Batch [620]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.100022,	
2017-07-12 19:46:45,510 Epoch[25] Batch [630]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.100305,	
2017-07-12 19:46:52,671 Epoch[25] Batch [640]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.100437,	
2017-07-12 19:46:59,589 Epoch[25] Batch [650]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.101048,	
2017-07-12 19:47:06,665 Epoch[25] Batch [660]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.103294,	
2017-07-12 19:47:13,575 Epoch[25] Batch [670]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.104360,	
2017-07-12 19:47:20,765 Epoch[25] Batch [680]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.104861,	
2017-07-12 19:47:27,443 Epoch[25] Batch [690]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.105317,	
2017-07-12 19:47:34,257 Epoch[25] Batch [700]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.105451,	
2017-07-12 19:47:41,006 Epoch[25] Batch [710]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.105729,	
2017-07-12 19:47:47,822 Epoch[25] Batch [720]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.105793,	
2017-07-12 19:47:54,514 Epoch[25] Batch [730]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.105732,	
2017-07-12 19:48:01,525 Epoch[25] Batch [740]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.105817,	
2017-07-12 19:48:08,392 Epoch[25] Batch [750]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.105900,	
2017-07-12 19:48:15,211 Epoch[25] Batch [760]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.106040,	
2017-07-12 19:48:21,897 Epoch[25] Batch [770]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.106391,	
2017-07-12 19:48:28,814 Epoch[25] Batch [780]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.106501,	
2017-07-12 19:48:35,533 Epoch[25] Batch [790]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.106431,	
2017-07-12 19:48:42,754 Epoch[25] Batch [800]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.106507,	
2017-07-12 19:48:49,863 Epoch[25] Batch [810]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.106446,	
2017-07-12 19:48:56,748 Epoch[25] Batch [820]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106391,	
2017-07-12 19:49:03,607 Epoch[25] Batch [830]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.106503,	
2017-07-12 19:49:10,534 Epoch[25] Batch [840]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.106595,	
2017-07-12 19:49:17,513 Epoch[25] Batch [850]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.106426,	
2017-07-12 19:49:24,396 Epoch[25] Batch [860]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106445,	
2017-07-12 19:49:31,850 Epoch[25] Batch [870]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.106324,	
2017-07-12 19:49:38,781 Epoch[25] Batch [880]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.106218,	
2017-07-12 19:49:45,624 Epoch[25] Batch [890]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.106236,	
2017-07-12 19:49:52,962 Epoch[25] Batch [900]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.106374,	
2017-07-12 19:50:00,088 Epoch[25] Batch [910]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.106385,	
2017-07-12 19:50:06,829 Epoch[25] Batch [920]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.106368,	
2017-07-12 19:50:13,717 Epoch[25] Batch [930]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106375,	
2017-07-12 19:50:20,896 Epoch[25] Batch [940]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.106359,	
2017-07-12 19:50:27,835 Epoch[25] Batch [950]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.106451,	
2017-07-12 19:50:34,691 Epoch[25] Batch [960]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.106537,	
2017-07-12 19:50:41,642 Epoch[25] Batch [970]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.106553,	
2017-07-12 19:50:48,389 Epoch[25] Batch [980]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.106641,	
2017-07-12 19:50:55,207 Epoch[25] Batch [990]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.106599,	
2017-07-12 19:51:01,935 Epoch[25] Batch [1000]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.106532,	
2017-07-12 19:51:09,088 Epoch[25] Batch [1010]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.106588,	
2017-07-12 19:51:15,773 Epoch[25] Batch [1020]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.106479,	
2017-07-12 19:51:22,578 Epoch[25] Batch [1030]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.106441,	
2017-07-12 19:51:29,428 Epoch[25] Batch [1040]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.106563,	
2017-07-12 19:51:35,964 Epoch[25] Batch [1050]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.106519,	
2017-07-12 19:51:42,708 Epoch[25] Batch [1060]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.106371,	
2017-07-12 19:51:49,391 Epoch[25] Batch [1070]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.106371,	
2017-07-12 19:51:55,975 Epoch[25] Batch [1080]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.106243,	
2017-07-12 19:52:02,824 Epoch[25] Batch [1090]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.106239,	
2017-07-12 19:52:09,689 Epoch[25] Batch [1100]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.106120,	
2017-07-12 19:52:16,746 Epoch[25] Batch [1110]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.105979,	
2017-07-12 19:52:23,972 Epoch[25] Batch [1120]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.105937,	
2017-07-12 19:52:30,892 Epoch[25] Batch [1130]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.105885,	
2017-07-12 19:52:37,681 Epoch[25] Batch [1140]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.105801,	
2017-07-12 19:52:44,477 Epoch[25] Batch [1150]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.105672,	
2017-07-12 19:52:51,452 Epoch[25] Batch [1160]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.105649,	
2017-07-12 19:52:58,038 Epoch[25] Batch [1170]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.105637,	
2017-07-12 19:53:05,480 Epoch[25] Batch [1180]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.105709,	
2017-07-12 19:53:12,396 Epoch[25] Batch [1190]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.105798,	
2017-07-12 19:53:19,412 Epoch[25] Batch [1200]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.106028,	
2017-07-12 19:53:26,024 Epoch[25] Batch [1210]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.106193,	
2017-07-12 19:53:32,868 Epoch[25] Batch [1220]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.106264,	
2017-07-12 19:53:39,692 Epoch[25] Batch [1230]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.106202,	
2017-07-12 19:53:46,580 Epoch[25] Batch [1240]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106265,	
2017-07-12 19:53:53,455 Epoch[25] Batch [1250]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.106310,	
2017-07-12 19:54:00,418 Epoch[25] Batch [1260]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.106326,	
2017-07-12 19:54:07,599 Epoch[25] Batch [1270]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.106692,	
2017-07-12 19:54:14,496 Epoch[25] Batch [1280]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.106803,	
2017-07-12 19:54:21,383 Epoch[25] Batch [1290]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.106944,	
2017-07-12 19:54:28,179 Epoch[25] Batch [1300]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.107014,	
2017-07-12 19:54:35,409 Epoch[25] Batch [1310]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.107129,	
2017-07-12 19:54:42,294 Epoch[25] Batch [1320]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.107102,	
2017-07-12 19:54:49,423 Epoch[25] Batch [1330]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.107037,	
2017-07-12 19:54:56,190 Epoch[25] Batch [1340]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.107008,	
2017-07-12 19:55:03,050 Epoch[25] Batch [1350]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.106980,	
2017-07-12 19:55:09,859 Epoch[25] Batch [1360]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.106949,	
2017-07-12 19:55:16,761 Epoch[25] Batch [1370]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.106946,	
2017-07-12 19:55:23,683 Epoch[25] Batch [1380]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.107003,	
2017-07-12 19:55:30,821 Epoch[25] Batch [1390]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.106987,	
2017-07-12 19:55:38,145 Epoch[25] Batch [1400]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.106950,	
2017-07-12 19:55:45,174 Epoch[25] Batch [1410]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.106861,	
2017-07-12 19:55:52,006 Epoch[25] Batch [1420]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.106868,	
2017-07-12 19:55:59,280 Epoch[25] Batch [1430]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.106860,	
2017-07-12 19:56:06,270 Epoch[25] Batch [1440]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.106820,	
2017-07-12 19:56:13,628 Epoch[25] Batch [1450]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.106736,	
2017-07-12 19:56:20,001 Epoch[25] Batch [1460]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.106647,	
2017-07-12 19:56:26,606 Epoch[25] Batch [1470]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.106668,	
2017-07-12 19:56:33,564 Epoch[25] Batch [1480]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.106677,	
2017-07-12 19:56:37,629 Epoch[25] Train-FCNLogLoss=0.106689
2017-07-12 19:56:37,630 Epoch[25] Time cost=1010.897
2017-07-12 19:56:38,689 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0026.params"
2017-07-12 19:56:40,344 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0026.states"
2017-07-12 19:56:48,164 Epoch[26] Batch [10]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.097475,	
2017-07-12 19:56:54,885 Epoch[26] Batch [20]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.102146,	
2017-07-12 19:57:01,784 Epoch[26] Batch [30]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.100216,	
2017-07-12 19:57:09,126 Epoch[26] Batch [40]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.100602,	
2017-07-12 19:57:15,920 Epoch[26] Batch [50]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.099186,	
2017-07-12 19:57:22,458 Epoch[26] Batch [60]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.097443,	
2017-07-12 19:57:29,091 Epoch[26] Batch [70]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.098612,	
2017-07-12 19:57:35,585 Epoch[26] Batch [80]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.101308,	
2017-07-12 19:57:41,956 Epoch[26] Batch [90]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.103049,	
2017-07-12 19:57:48,524 Epoch[26] Batch [100]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.102854,	
2017-07-12 19:57:55,096 Epoch[26] Batch [110]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.102568,	
2017-07-12 19:58:01,467 Epoch[26] Batch [120]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.101737,	
2017-07-12 19:58:07,924 Epoch[26] Batch [130]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.102822,	
2017-07-12 19:58:14,314 Epoch[26] Batch [140]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103517,	
2017-07-12 19:58:21,241 Epoch[26] Batch [150]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.105063,	
2017-07-12 19:58:28,417 Epoch[26] Batch [160]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.105403,	
2017-07-12 19:58:35,209 Epoch[26] Batch [170]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.105987,	
2017-07-12 19:58:41,962 Epoch[26] Batch [180]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.105751,	
2017-07-12 19:58:49,120 Epoch[26] Batch [190]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.105797,	
2017-07-12 19:58:55,985 Epoch[26] Batch [200]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.105097,	
2017-07-12 19:59:02,378 Epoch[26] Batch [210]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.104805,	
2017-07-12 19:59:09,268 Epoch[26] Batch [220]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.104118,	
2017-07-12 19:59:15,918 Epoch[26] Batch [230]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.104000,	
2017-07-12 19:59:22,832 Epoch[26] Batch [240]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.104344,	
2017-07-12 19:59:29,517 Epoch[26] Batch [250]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.104327,	
2017-07-12 19:59:36,400 Epoch[26] Batch [260]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.104519,	
2017-07-12 19:59:43,232 Epoch[26] Batch [270]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.104669,	
2017-07-12 19:59:50,068 Epoch[26] Batch [280]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.104574,	
2017-07-12 19:59:56,839 Epoch[26] Batch [290]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.104458,	
2017-07-12 20:00:03,516 Epoch[26] Batch [300]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.104135,	
2017-07-12 20:00:10,444 Epoch[26] Batch [310]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.103880,	
2017-07-12 20:00:17,158 Epoch[26] Batch [320]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.104083,	
2017-07-12 20:00:24,882 Epoch[26] Batch [330]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.103735,	
2017-07-12 20:00:32,559 Epoch[26] Batch [340]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.103155,	
2017-07-12 20:00:39,979 Epoch[26] Batch [350]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.102928,	
2017-07-12 20:00:47,474 Epoch[26] Batch [360]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.103113,	
2017-07-12 20:00:54,529 Epoch[26] Batch [370]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.103321,	
2017-07-12 20:01:01,713 Epoch[26] Batch [380]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.103087,	
2017-07-12 20:01:09,163 Epoch[26] Batch [390]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.103240,	
2017-07-12 20:01:16,716 Epoch[26] Batch [400]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.102995,	
2017-07-12 20:01:24,055 Epoch[26] Batch [410]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.103038,	
2017-07-12 20:01:30,757 Epoch[26] Batch [420]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.103016,	
2017-07-12 20:01:37,469 Epoch[26] Batch [430]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.103198,	
2017-07-12 20:01:44,101 Epoch[26] Batch [440]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.103035,	
2017-07-12 20:01:51,210 Epoch[26] Batch [450]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.102793,	
2017-07-12 20:01:58,285 Epoch[26] Batch [460]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.102795,	
2017-07-12 20:02:05,429 Epoch[26] Batch [470]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.102553,	
2017-07-12 20:02:12,165 Epoch[26] Batch [480]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.102504,	
2017-07-12 20:02:19,004 Epoch[26] Batch [490]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.102454,	
2017-07-12 20:02:25,853 Epoch[26] Batch [500]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.102532,	
2017-07-12 20:02:33,005 Epoch[26] Batch [510]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.102343,	
2017-07-12 20:02:39,897 Epoch[26] Batch [520]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.102136,	
2017-07-12 20:02:46,715 Epoch[26] Batch [530]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.102056,	
2017-07-12 20:02:53,687 Epoch[26] Batch [540]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.102137,	
2017-07-12 20:03:00,636 Epoch[26] Batch [550]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102140,	
2017-07-12 20:03:07,578 Epoch[26] Batch [560]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.101970,	
2017-07-12 20:03:14,434 Epoch[26] Batch [570]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.101802,	
2017-07-12 20:03:21,072 Epoch[26] Batch [580]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.101883,	
2017-07-12 20:03:27,958 Epoch[26] Batch [590]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.101766,	
2017-07-12 20:03:34,547 Epoch[26] Batch [600]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.101683,	
2017-07-12 20:03:41,288 Epoch[26] Batch [610]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.101679,	
2017-07-12 20:03:48,110 Epoch[26] Batch [620]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.101430,	
2017-07-12 20:03:54,864 Epoch[26] Batch [630]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.101368,	
2017-07-12 20:04:01,769 Epoch[26] Batch [640]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.101293,	
2017-07-12 20:04:08,613 Epoch[26] Batch [650]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.101432,	
2017-07-12 20:04:15,744 Epoch[26] Batch [660]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.101413,	
2017-07-12 20:04:22,423 Epoch[26] Batch [670]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.101454,	
2017-07-12 20:04:29,283 Epoch[26] Batch [680]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.101508,	
2017-07-12 20:04:36,168 Epoch[26] Batch [690]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.101414,	
2017-07-12 20:04:43,093 Epoch[26] Batch [700]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.101544,	
2017-07-12 20:04:49,887 Epoch[26] Batch [710]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.101544,	
2017-07-12 20:04:56,743 Epoch[26] Batch [720]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.101441,	
2017-07-12 20:05:03,534 Epoch[26] Batch [730]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.101215,	
2017-07-12 20:05:10,514 Epoch[26] Batch [740]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.101051,	
2017-07-12 20:05:17,470 Epoch[26] Batch [750]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.101070,	
2017-07-12 20:05:24,353 Epoch[26] Batch [760]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.101034,	
2017-07-12 20:05:31,883 Epoch[26] Batch [770]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.101016,	
2017-07-12 20:05:39,068 Epoch[26] Batch [780]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.100933,	
2017-07-12 20:05:45,840 Epoch[26] Batch [790]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.100877,	
2017-07-12 20:05:52,564 Epoch[26] Batch [800]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.100798,	
2017-07-12 20:05:59,417 Epoch[26] Batch [810]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.100784,	
2017-07-12 20:06:06,176 Epoch[26] Batch [820]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.100676,	
2017-07-12 20:06:12,977 Epoch[26] Batch [830]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.100701,	
2017-07-12 20:06:19,723 Epoch[26] Batch [840]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.100654,	
2017-07-12 20:06:26,849 Epoch[26] Batch [850]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.100786,	
2017-07-12 20:06:33,671 Epoch[26] Batch [860]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.100794,	
2017-07-12 20:06:40,700 Epoch[26] Batch [870]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.100664,	
2017-07-12 20:06:47,432 Epoch[26] Batch [880]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.100673,	
2017-07-12 20:06:53,858 Epoch[26] Batch [890]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.100794,	
2017-07-12 20:07:01,025 Epoch[26] Batch [900]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.100643,	
2017-07-12 20:07:08,341 Epoch[26] Batch [910]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.100755,	
2017-07-12 20:07:15,025 Epoch[26] Batch [920]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.100791,	
2017-07-12 20:07:22,137 Epoch[26] Batch [930]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.100786,	
2017-07-12 20:07:29,042 Epoch[26] Batch [940]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.100840,	
2017-07-12 20:07:35,788 Epoch[26] Batch [950]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.100858,	
2017-07-12 20:07:42,592 Epoch[26] Batch [960]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.100960,	
2017-07-12 20:07:49,452 Epoch[26] Batch [970]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.100930,	
2017-07-12 20:07:56,211 Epoch[26] Batch [980]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.100799,	
2017-07-12 20:08:03,312 Epoch[26] Batch [990]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.100877,	
2017-07-12 20:08:10,132 Epoch[26] Batch [1000]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.100894,	
2017-07-12 20:08:17,238 Epoch[26] Batch [1010]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.100818,	
2017-07-12 20:08:23,867 Epoch[26] Batch [1020]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.100915,	
2017-07-12 20:08:30,675 Epoch[26] Batch [1030]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.100880,	
2017-07-12 20:08:37,469 Epoch[26] Batch [1040]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.100917,	
2017-07-12 20:08:45,134 Epoch[26] Batch [1050]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.100902,	
2017-07-12 20:08:52,093 Epoch[26] Batch [1060]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.100922,	
2017-07-12 20:08:59,068 Epoch[26] Batch [1070]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.101005,	
2017-07-12 20:09:06,464 Epoch[26] Batch [1080]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.102144,	
2017-07-12 20:09:13,261 Epoch[26] Batch [1090]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.102782,	
2017-07-12 20:09:20,064 Epoch[26] Batch [1100]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.103327,	
2017-07-12 20:09:27,182 Epoch[26] Batch [1110]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.103619,	
2017-07-12 20:09:34,466 Epoch[26] Batch [1120]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.103878,	
2017-07-12 20:09:41,856 Epoch[26] Batch [1130]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.103933,	
2017-07-12 20:09:49,237 Epoch[26] Batch [1140]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.103908,	
2017-07-12 20:09:56,263 Epoch[26] Batch [1150]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.104000,	
2017-07-12 20:10:03,235 Epoch[26] Batch [1160]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.104005,	
2017-07-12 20:10:10,145 Epoch[26] Batch [1170]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.104100,	
2017-07-12 20:10:17,356 Epoch[26] Batch [1180]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.104134,	
2017-07-12 20:10:24,731 Epoch[26] Batch [1190]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.104122,	
2017-07-12 20:10:32,019 Epoch[26] Batch [1200]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.104031,	
2017-07-12 20:10:38,685 Epoch[26] Batch [1210]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.103963,	
2017-07-12 20:10:45,248 Epoch[26] Batch [1220]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.103962,	
2017-07-12 20:10:52,027 Epoch[26] Batch [1230]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.103902,	
2017-07-12 20:10:59,018 Epoch[26] Batch [1240]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.103970,	
2017-07-12 20:11:05,914 Epoch[26] Batch [1250]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.103986,	
2017-07-12 20:11:12,904 Epoch[26] Batch [1260]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.104042,	
2017-07-12 20:11:19,824 Epoch[26] Batch [1270]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.104024,	
2017-07-12 20:11:26,817 Epoch[26] Batch [1280]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.104014,	
2017-07-12 20:11:33,545 Epoch[26] Batch [1290]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.103956,	
2017-07-12 20:11:40,220 Epoch[26] Batch [1300]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.103938,	
2017-07-12 20:11:47,374 Epoch[26] Batch [1310]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.104063,	
2017-07-12 20:11:54,744 Epoch[26] Batch [1320]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.104227,	
2017-07-12 20:12:01,974 Epoch[26] Batch [1330]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.104308,	
2017-07-12 20:12:09,133 Epoch[26] Batch [1340]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.104330,	
2017-07-12 20:12:16,647 Epoch[26] Batch [1350]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.104401,	
2017-07-12 20:12:23,855 Epoch[26] Batch [1360]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.104490,	
2017-07-12 20:12:31,014 Epoch[26] Batch [1370]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.104452,	
2017-07-12 20:12:38,142 Epoch[26] Batch [1380]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.104405,	
2017-07-12 20:12:45,436 Epoch[26] Batch [1390]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.104475,	
2017-07-12 20:12:52,426 Epoch[26] Batch [1400]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.104435,	
2017-07-12 20:12:59,091 Epoch[26] Batch [1410]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.104465,	
2017-07-12 20:13:05,667 Epoch[26] Batch [1420]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.104481,	
2017-07-12 20:13:12,449 Epoch[26] Batch [1430]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.104470,	
2017-07-12 20:13:19,421 Epoch[26] Batch [1440]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.104460,	
2017-07-12 20:13:26,702 Epoch[26] Batch [1450]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.104514,	
2017-07-12 20:13:33,389 Epoch[26] Batch [1460]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.104467,	
2017-07-12 20:13:40,417 Epoch[26] Batch [1470]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.104489,	
2017-07-12 20:13:47,284 Epoch[26] Batch [1480]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.104388,	
2017-07-12 20:13:51,153 Epoch[26] Train-FCNLogLoss=0.104307
2017-07-12 20:13:51,154 Epoch[26] Time cost=1030.810
2017-07-12 20:13:52,125 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0027.params"
2017-07-12 20:13:56,656 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0027.states"
2017-07-12 20:14:04,828 Epoch[27] Batch [10]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.112662,	
2017-07-12 20:14:12,022 Epoch[27] Batch [20]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.109409,	
2017-07-12 20:14:19,130 Epoch[27] Batch [30]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.104772,	
2017-07-12 20:14:26,096 Epoch[27] Batch [40]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.104040,	
2017-07-12 20:14:32,882 Epoch[27] Batch [50]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.102852,	
2017-07-12 20:14:39,953 Epoch[27] Batch [60]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.101547,	
2017-07-12 20:14:47,001 Epoch[27] Batch [70]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.101204,	
2017-07-12 20:14:53,857 Epoch[27] Batch [80]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.101465,	
2017-07-12 20:15:00,829 Epoch[27] Batch [90]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.102115,	
2017-07-12 20:15:07,885 Epoch[27] Batch [100]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.101888,	
2017-07-12 20:15:15,153 Epoch[27] Batch [110]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.101837,	
2017-07-12 20:15:22,142 Epoch[27] Batch [120]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.102564,	
2017-07-12 20:15:29,342 Epoch[27] Batch [130]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.102125,	
2017-07-12 20:15:36,558 Epoch[27] Batch [140]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.102005,	
2017-07-12 20:15:43,353 Epoch[27] Batch [150]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.103222,	
2017-07-12 20:15:50,404 Epoch[27] Batch [160]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.103566,	
2017-07-12 20:15:57,310 Epoch[27] Batch [170]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.103882,	
2017-07-12 20:16:04,157 Epoch[27] Batch [180]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.103526,	
2017-07-12 20:16:11,116 Epoch[27] Batch [190]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.103332,	
2017-07-12 20:16:17,838 Epoch[27] Batch [200]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.103111,	
2017-07-12 20:16:24,685 Epoch[27] Batch [210]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.102959,	
2017-07-12 20:16:31,497 Epoch[27] Batch [220]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.102496,	
2017-07-12 20:16:38,669 Epoch[27] Batch [230]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.102242,	
2017-07-12 20:16:45,747 Epoch[27] Batch [240]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.102070,	
2017-07-12 20:16:52,854 Epoch[27] Batch [250]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.101956,	
2017-07-12 20:16:59,648 Epoch[27] Batch [260]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.102522,	
2017-07-12 20:17:06,579 Epoch[27] Batch [270]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.101766,	
2017-07-12 20:17:13,495 Epoch[27] Batch [280]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.101608,	
2017-07-12 20:17:20,022 Epoch[27] Batch [290]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.101559,	
2017-07-12 20:17:27,261 Epoch[27] Batch [300]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.101670,	
2017-07-12 20:17:34,849 Epoch[27] Batch [310]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.101676,	
2017-07-12 20:17:42,322 Epoch[27] Batch [320]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.101768,	
2017-07-12 20:17:49,752 Epoch[27] Batch [330]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.101693,	
2017-07-12 20:17:56,914 Epoch[27] Batch [340]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.101898,	
2017-07-12 20:18:04,505 Epoch[27] Batch [350]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.101735,	
2017-07-12 20:18:12,149 Epoch[27] Batch [360]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.101583,	
2017-07-12 20:18:19,439 Epoch[27] Batch [370]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.101732,	
2017-07-12 20:18:27,019 Epoch[27] Batch [380]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.101858,	
2017-07-12 20:18:34,406 Epoch[27] Batch [390]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.101767,	
2017-07-12 20:18:41,475 Epoch[27] Batch [400]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.101549,	
2017-07-12 20:18:48,405 Epoch[27] Batch [410]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.101836,	
2017-07-12 20:18:55,478 Epoch[27] Batch [420]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.101899,	
2017-07-12 20:19:02,481 Epoch[27] Batch [430]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.101836,	
2017-07-12 20:19:09,094 Epoch[27] Batch [440]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.101959,	
2017-07-12 20:19:15,693 Epoch[27] Batch [450]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.101953,	
2017-07-12 20:19:22,386 Epoch[27] Batch [460]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.102115,	
2017-07-12 20:19:28,917 Epoch[27] Batch [470]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.102022,	
2017-07-12 20:19:36,022 Epoch[27] Batch [480]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.101998,	
2017-07-12 20:19:43,041 Epoch[27] Batch [490]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.101886,	
2017-07-12 20:19:50,359 Epoch[27] Batch [500]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.101946,	
2017-07-12 20:19:57,790 Epoch[27] Batch [510]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.101643,	
2017-07-12 20:20:05,391 Epoch[27] Batch [520]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.101606,	
2017-07-12 20:20:12,786 Epoch[27] Batch [530]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.101498,	
2017-07-12 20:20:20,162 Epoch[27] Batch [540]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.101506,	
2017-07-12 20:20:27,719 Epoch[27] Batch [550]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.101469,	
2017-07-12 20:20:35,001 Epoch[27] Batch [560]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.101561,	
2017-07-12 20:20:42,478 Epoch[27] Batch [570]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.101503,	
2017-07-12 20:20:49,852 Epoch[27] Batch [580]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.101556,	
2017-07-12 20:20:56,928 Epoch[27] Batch [590]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.101799,	
2017-07-12 20:21:03,896 Epoch[27] Batch [600]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.101803,	
2017-07-12 20:21:10,932 Epoch[27] Batch [610]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.101697,	
2017-07-12 20:21:17,849 Epoch[27] Batch [620]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.101663,	
2017-07-12 20:21:24,985 Epoch[27] Batch [630]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.101964,	
2017-07-12 20:21:31,753 Epoch[27] Batch [640]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.102010,	
2017-07-12 20:21:38,629 Epoch[27] Batch [650]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.102100,	
2017-07-12 20:21:46,351 Epoch[27] Batch [660]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.101990,	
2017-07-12 20:21:53,611 Epoch[27] Batch [670]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.101942,	
2017-07-12 20:22:00,555 Epoch[27] Batch [680]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.101901,	
2017-07-12 20:22:07,627 Epoch[27] Batch [690]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.101700,	
2017-07-12 20:22:14,761 Epoch[27] Batch [700]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.101634,	
2017-07-12 20:22:22,085 Epoch[27] Batch [710]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.101553,	
2017-07-12 20:22:29,300 Epoch[27] Batch [720]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.101426,	
2017-07-12 20:22:36,585 Epoch[27] Batch [730]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.101365,	
2017-07-12 20:22:43,843 Epoch[27] Batch [740]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.101402,	
2017-07-12 20:22:50,891 Epoch[27] Batch [750]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.101438,	
2017-07-12 20:22:58,015 Epoch[27] Batch [760]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.101431,	
2017-07-12 20:23:05,247 Epoch[27] Batch [770]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.101359,	
2017-07-12 20:23:12,581 Epoch[27] Batch [780]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.101277,	
2017-07-12 20:23:19,543 Epoch[27] Batch [790]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.101419,	
2017-07-12 20:23:26,430 Epoch[27] Batch [800]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.101431,	
2017-07-12 20:23:33,428 Epoch[27] Batch [810]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.101296,	
2017-07-12 20:23:41,003 Epoch[27] Batch [820]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.101268,	
2017-07-12 20:23:48,681 Epoch[27] Batch [830]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.101298,	
2017-07-12 20:23:55,701 Epoch[27] Batch [840]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.101163,	
2017-07-12 20:24:02,815 Epoch[27] Batch [850]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.101179,	
2017-07-12 20:24:10,042 Epoch[27] Batch [860]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.101014,	
2017-07-12 20:24:16,904 Epoch[27] Batch [870]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.100901,	
2017-07-12 20:24:24,176 Epoch[27] Batch [880]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.100888,	
2017-07-12 20:24:30,894 Epoch[27] Batch [890]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.100866,	
2017-07-12 20:24:37,732 Epoch[27] Batch [900]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.100836,	
2017-07-12 20:24:44,848 Epoch[27] Batch [910]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.100796,	
2017-07-12 20:24:52,395 Epoch[27] Batch [920]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.100621,	
2017-07-12 20:24:59,422 Epoch[27] Batch [930]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.100556,	
2017-07-12 20:25:06,466 Epoch[27] Batch [940]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.100483,	
2017-07-12 20:25:13,607 Epoch[27] Batch [950]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.100334,	
2017-07-12 20:25:20,822 Epoch[27] Batch [960]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.100364,	
2017-07-12 20:25:28,001 Epoch[27] Batch [970]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.100476,	
2017-07-12 20:25:35,132 Epoch[27] Batch [980]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.100568,	
2017-07-12 20:25:42,017 Epoch[27] Batch [990]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.100524,	
2017-07-12 20:25:49,183 Epoch[27] Batch [1000]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.100448,	
2017-07-12 20:25:56,293 Epoch[27] Batch [1010]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.100428,	
2017-07-12 20:26:03,390 Epoch[27] Batch [1020]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.100395,	
2017-07-12 20:26:10,406 Epoch[27] Batch [1030]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.100363,	
2017-07-12 20:26:17,509 Epoch[27] Batch [1040]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.100269,	
2017-07-12 20:26:24,577 Epoch[27] Batch [1050]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.100237,	
2017-07-12 20:26:31,910 Epoch[27] Batch [1060]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.100195,	
2017-07-12 20:26:39,057 Epoch[27] Batch [1070]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.100170,	
2017-07-12 20:26:46,167 Epoch[27] Batch [1080]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.100198,	
2017-07-12 20:26:53,397 Epoch[27] Batch [1090]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.100096,	
2017-07-12 20:27:00,546 Epoch[27] Batch [1100]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.100064,	
2017-07-12 20:27:07,542 Epoch[27] Batch [1110]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.100098,	
2017-07-12 20:27:14,475 Epoch[27] Batch [1120]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.100099,	
2017-07-12 20:27:21,528 Epoch[27] Batch [1130]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.100097,	
2017-07-12 20:27:28,424 Epoch[27] Batch [1140]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.100067,	
2017-07-12 20:27:35,896 Epoch[27] Batch [1150]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.100013,	
2017-07-12 20:27:43,358 Epoch[27] Batch [1160]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.099902,	
2017-07-12 20:27:50,820 Epoch[27] Batch [1170]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.099977,	
2017-07-12 20:27:57,995 Epoch[27] Batch [1180]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.100084,	
2017-07-12 20:28:04,950 Epoch[27] Batch [1190]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.100078,	
2017-07-12 20:28:11,993 Epoch[27] Batch [1200]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.100080,	
2017-07-12 20:28:18,668 Epoch[27] Batch [1210]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.100065,	
2017-07-12 20:28:25,130 Epoch[27] Batch [1220]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.100207,	
2017-07-12 20:28:31,677 Epoch[27] Batch [1230]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.100222,	
2017-07-12 20:28:38,341 Epoch[27] Batch [1240]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.100181,	
2017-07-12 20:28:45,374 Epoch[27] Batch [1250]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.100142,	
2017-07-12 20:28:52,341 Epoch[27] Batch [1260]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.100186,	
2017-07-12 20:28:59,376 Epoch[27] Batch [1270]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.100240,	
2017-07-12 20:29:06,623 Epoch[27] Batch [1280]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.100246,	
2017-07-12 20:29:14,439 Epoch[27] Batch [1290]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.100299,	
2017-07-12 20:29:22,078 Epoch[27] Batch [1300]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.100271,	
2017-07-12 20:29:29,824 Epoch[27] Batch [1310]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.100252,	
2017-07-12 20:29:37,568 Epoch[27] Batch [1320]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.100235,	
2017-07-12 20:29:45,274 Epoch[27] Batch [1330]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.100161,	
2017-07-12 20:29:53,131 Epoch[27] Batch [1340]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.100161,	
2017-07-12 20:30:00,614 Epoch[27] Batch [1350]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.100141,	
2017-07-12 20:30:08,125 Epoch[27] Batch [1360]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.100099,	
2017-07-12 20:30:15,497 Epoch[27] Batch [1370]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.100135,	
2017-07-12 20:30:22,711 Epoch[27] Batch [1380]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.100230,	
2017-07-12 20:30:29,578 Epoch[27] Batch [1390]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.100190,	
2017-07-12 20:30:36,614 Epoch[27] Batch [1400]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.100249,	
2017-07-12 20:30:43,730 Epoch[27] Batch [1410]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.100220,	
2017-07-12 20:30:50,939 Epoch[27] Batch [1420]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.100222,	
2017-07-12 20:30:58,071 Epoch[27] Batch [1430]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.100227,	
2017-07-12 20:31:05,359 Epoch[27] Batch [1440]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.100226,	
2017-07-12 20:31:12,230 Epoch[27] Batch [1450]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.100260,	
2017-07-12 20:31:19,175 Epoch[27] Batch [1460]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.100261,	
2017-07-12 20:31:26,685 Epoch[27] Batch [1470]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.100297,	
2017-07-12 20:31:33,892 Epoch[27] Batch [1480]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.100308,	
2017-07-12 20:31:38,321 Epoch[27] Train-FCNLogLoss=0.100243
2017-07-12 20:31:38,321 Epoch[27] Time cost=1061.665
2017-07-12 20:31:39,530 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0028.params"
2017-07-12 20:31:44,211 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0028.states"
2017-07-12 20:31:52,932 Epoch[28] Batch [10]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.092210,	
2017-07-12 20:32:00,616 Epoch[28] Batch [20]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.098552,	
2017-07-12 20:32:08,264 Epoch[28] Batch [30]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.099073,	
2017-07-12 20:32:15,997 Epoch[28] Batch [40]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.099118,	
2017-07-12 20:32:23,473 Epoch[28] Batch [50]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.102098,	
2017-07-12 20:32:31,174 Epoch[28] Batch [60]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.099868,	
2017-07-12 20:32:37,998 Epoch[28] Batch [70]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.100223,	
2017-07-12 20:32:45,119 Epoch[28] Batch [80]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.099705,	
2017-07-12 20:32:52,057 Epoch[28] Batch [90]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.099193,	
2017-07-12 20:32:58,843 Epoch[28] Batch [100]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.099346,	
2017-07-12 20:33:05,711 Epoch[28] Batch [110]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.099797,	
2017-07-12 20:33:12,578 Epoch[28] Batch [120]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.099671,	
2017-07-12 20:33:19,831 Epoch[28] Batch [130]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.099473,	
2017-07-12 20:33:26,877 Epoch[28] Batch [140]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.099820,	
2017-07-12 20:33:33,458 Epoch[28] Batch [150]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.099370,	
2017-07-12 20:33:39,930 Epoch[28] Batch [160]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.099518,	
2017-07-12 20:33:47,145 Epoch[28] Batch [170]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.099397,	
2017-07-12 20:33:55,077 Epoch[28] Batch [180]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.099385,	
2017-07-12 20:34:03,079 Epoch[28] Batch [190]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.099383,	
2017-07-12 20:34:10,883 Epoch[28] Batch [200]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.099291,	
2017-07-12 20:34:18,635 Epoch[28] Batch [210]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.099155,	
2017-07-12 20:34:26,412 Epoch[28] Batch [220]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.098924,	
2017-07-12 20:34:34,297 Epoch[28] Batch [230]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.098667,	
2017-07-12 20:34:42,231 Epoch[28] Batch [240]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.098712,	
2017-07-12 20:34:50,054 Epoch[28] Batch [250]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.098874,	
2017-07-12 20:34:57,052 Epoch[28] Batch [260]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.098680,	
2017-07-12 20:35:04,364 Epoch[28] Batch [270]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.098199,	
2017-07-12 20:35:11,515 Epoch[28] Batch [280]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.097956,	
2017-07-12 20:35:18,713 Epoch[28] Batch [290]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.097927,	
2017-07-12 20:35:25,887 Epoch[28] Batch [300]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.098038,	
2017-07-12 20:35:33,048 Epoch[28] Batch [310]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.098099,	
2017-07-12 20:35:39,929 Epoch[28] Batch [320]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.098109,	
2017-07-12 20:35:46,752 Epoch[28] Batch [330]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.098238,	
2017-07-12 20:35:53,637 Epoch[28] Batch [340]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.098203,	
2017-07-12 20:36:00,909 Epoch[28] Batch [350]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.098343,	
2017-07-12 20:36:08,764 Epoch[28] Batch [360]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098265,	
2017-07-12 20:36:16,353 Epoch[28] Batch [370]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098336,	
2017-07-12 20:36:23,740 Epoch[28] Batch [380]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098480,	
2017-07-12 20:36:31,134 Epoch[28] Batch [390]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.098493,	
2017-07-12 20:36:38,722 Epoch[28] Batch [400]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098593,	
2017-07-12 20:36:46,305 Epoch[28] Batch [410]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098866,	
2017-07-12 20:36:53,703 Epoch[28] Batch [420]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.098758,	
2017-07-12 20:37:01,098 Epoch[28] Batch [430]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.098587,	
2017-07-12 20:37:08,534 Epoch[28] Batch [440]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.098946,	
2017-07-12 20:37:15,559 Epoch[28] Batch [450]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.098981,	
2017-07-12 20:37:22,164 Epoch[28] Batch [460]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.098850,	
2017-07-12 20:37:28,625 Epoch[28] Batch [470]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.098803,	
2017-07-12 20:37:35,157 Epoch[28] Batch [480]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.098948,	
2017-07-12 20:37:42,071 Epoch[28] Batch [490]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.098747,	
2017-07-12 20:37:49,258 Epoch[28] Batch [500]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.098640,	
2017-07-12 20:37:56,096 Epoch[28] Batch [510]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.098590,	
2017-07-12 20:38:03,862 Epoch[28] Batch [520]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.098330,	
2017-07-12 20:38:10,855 Epoch[28] Batch [530]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.098249,	
2017-07-12 20:38:18,870 Epoch[28] Batch [540]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.098197,	
2017-07-12 20:38:26,332 Epoch[28] Batch [550]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.098331,	
2017-07-12 20:38:33,424 Epoch[28] Batch [560]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.098449,	
2017-07-12 20:38:40,752 Epoch[28] Batch [570]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.098587,	
2017-07-12 20:38:48,127 Epoch[28] Batch [580]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098631,	
2017-07-12 20:38:55,383 Epoch[28] Batch [590]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.098531,	
2017-07-12 20:39:02,786 Epoch[28] Batch [600]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.098737,	
2017-07-12 20:39:10,242 Epoch[28] Batch [610]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.098808,	
2017-07-12 20:39:17,704 Epoch[28] Batch [620]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.098770,	
2017-07-12 20:39:25,342 Epoch[28] Batch [630]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098843,	
2017-07-12 20:39:32,504 Epoch[28] Batch [640]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.098867,	
2017-07-12 20:39:39,757 Epoch[28] Batch [650]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.099173,	
2017-07-12 20:39:46,902 Epoch[28] Batch [660]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.099285,	
2017-07-12 20:39:54,157 Epoch[28] Batch [670]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.099395,	
2017-07-12 20:40:01,820 Epoch[28] Batch [680]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.099284,	
2017-07-12 20:40:09,057 Epoch[28] Batch [690]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.099289,	
2017-07-12 20:40:16,186 Epoch[28] Batch [700]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.099369,	
2017-07-12 20:40:23,112 Epoch[28] Batch [710]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.099236,	
2017-07-12 20:40:30,682 Epoch[28] Batch [720]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098993,	
2017-07-12 20:40:39,005 Epoch[28] Batch [730]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.099020,	
2017-07-12 20:40:47,621 Epoch[28] Batch [740]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.098931,	
2017-07-12 20:40:55,344 Epoch[28] Batch [750]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.098741,	
2017-07-12 20:41:03,008 Epoch[28] Batch [760]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.098821,	
2017-07-12 20:41:10,604 Epoch[28] Batch [770]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098745,	
2017-07-12 20:41:18,322 Epoch[28] Batch [780]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.098748,	
2017-07-12 20:41:25,895 Epoch[28] Batch [790]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098732,	
2017-07-12 20:41:33,664 Epoch[28] Batch [800]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.098726,	
2017-07-12 20:41:41,263 Epoch[28] Batch [810]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.098744,	
2017-07-12 20:41:48,759 Epoch[28] Batch [820]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098785,	
2017-07-12 20:41:55,877 Epoch[28] Batch [830]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.098798,	
2017-07-12 20:42:03,467 Epoch[28] Batch [840]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098789,	
2017-07-12 20:42:10,591 Epoch[28] Batch [850]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.098720,	
2017-07-12 20:42:17,566 Epoch[28] Batch [860]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.098673,	
2017-07-12 20:42:24,408 Epoch[28] Batch [870]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.098576,	
2017-07-12 20:42:31,368 Epoch[28] Batch [880]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.098563,	
2017-07-12 20:42:38,193 Epoch[28] Batch [890]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.098404,	
2017-07-12 20:42:45,091 Epoch[28] Batch [900]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.098447,	
2017-07-12 20:42:51,904 Epoch[28] Batch [910]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.098423,	
2017-07-12 20:42:59,080 Epoch[28] Batch [920]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.098350,	
2017-07-12 20:43:06,642 Epoch[28] Batch [930]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098284,	
2017-07-12 20:43:13,915 Epoch[28] Batch [940]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.098345,	
2017-07-12 20:43:21,599 Epoch[28] Batch [950]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.098418,	
2017-07-12 20:43:29,334 Epoch[28] Batch [960]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.098442,	
2017-07-12 20:43:36,876 Epoch[28] Batch [970]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.098431,	
2017-07-12 20:43:44,482 Epoch[28] Batch [980]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.098507,	
2017-07-12 20:43:51,988 Epoch[28] Batch [990]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.098306,	
2017-07-12 20:43:59,466 Epoch[28] Batch [1000]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.098361,	
2017-07-12 20:44:06,858 Epoch[28] Batch [1010]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.098422,	
2017-07-12 20:44:14,236 Epoch[28] Batch [1020]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098389,	
2017-07-12 20:44:21,185 Epoch[28] Batch [1030]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.098408,	
2017-07-12 20:44:28,209 Epoch[28] Batch [1040]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.098379,	
2017-07-12 20:44:35,031 Epoch[28] Batch [1050]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.098396,	
2017-07-12 20:44:42,050 Epoch[28] Batch [1060]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.098315,	
2017-07-12 20:44:49,300 Epoch[28] Batch [1070]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.098434,	
2017-07-12 20:44:56,398 Epoch[28] Batch [1080]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.098463,	
2017-07-12 20:45:03,412 Epoch[28] Batch [1090]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.098541,	
2017-07-12 20:45:10,329 Epoch[28] Batch [1100]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.098617,	
2017-07-12 20:45:17,484 Epoch[28] Batch [1110]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.098532,	
2017-07-12 20:45:24,773 Epoch[28] Batch [1120]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.098389,	
2017-07-12 20:45:32,010 Epoch[28] Batch [1130]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.098382,	
2017-07-12 20:45:39,395 Epoch[28] Batch [1140]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098299,	
2017-07-12 20:45:46,446 Epoch[28] Batch [1150]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.098307,	
2017-07-12 20:45:53,603 Epoch[28] Batch [1160]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.098274,	
2017-07-12 20:46:00,784 Epoch[28] Batch [1170]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.098175,	
2017-07-12 20:46:07,859 Epoch[28] Batch [1180]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.098254,	
2017-07-12 20:46:14,743 Epoch[28] Batch [1190]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.098213,	
2017-07-12 20:46:21,600 Epoch[28] Batch [1200]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.098128,	
2017-07-12 20:46:28,358 Epoch[28] Batch [1210]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.098062,	
2017-07-12 20:46:35,182 Epoch[28] Batch [1220]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.098128,	
2017-07-12 20:46:41,943 Epoch[28] Batch [1230]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.098211,	
2017-07-12 20:46:48,911 Epoch[28] Batch [1240]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.098207,	
2017-07-12 20:46:56,288 Epoch[28] Batch [1250]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098157,	
2017-07-12 20:47:03,809 Epoch[28] Batch [1260]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.098169,	
2017-07-12 20:47:11,075 Epoch[28] Batch [1270]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.098139,	
2017-07-12 20:47:18,671 Epoch[28] Batch [1280]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098017,	
2017-07-12 20:47:26,008 Epoch[28] Batch [1290]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.097978,	
2017-07-12 20:47:33,326 Epoch[28] Batch [1300]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.097992,	
2017-07-12 20:47:40,663 Epoch[28] Batch [1310]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.097881,	
2017-07-12 20:47:48,038 Epoch[28] Batch [1320]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.097798,	
2017-07-12 20:47:55,189 Epoch[28] Batch [1330]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.097867,	
2017-07-12 20:48:02,393 Epoch[28] Batch [1340]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.097936,	
2017-07-12 20:48:09,663 Epoch[28] Batch [1350]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.097939,	
2017-07-12 20:48:16,971 Epoch[28] Batch [1360]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.097978,	
2017-07-12 20:48:24,308 Epoch[28] Batch [1370]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.097984,	
2017-07-12 20:48:31,644 Epoch[28] Batch [1380]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.098052,	
2017-07-12 20:48:39,139 Epoch[28] Batch [1390]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098057,	
2017-07-12 20:48:46,267 Epoch[28] Batch [1400]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.098010,	
2017-07-12 20:48:53,585 Epoch[28] Batch [1410]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.097962,	
2017-07-12 20:49:00,890 Epoch[28] Batch [1420]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097988,	
2017-07-12 20:49:08,185 Epoch[28] Batch [1430]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097963,	
2017-07-12 20:49:15,298 Epoch[28] Batch [1440]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.097942,	
2017-07-12 20:49:22,708 Epoch[28] Batch [1450]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.098019,	
2017-07-12 20:49:29,996 Epoch[28] Batch [1460]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.098020,	
2017-07-12 20:49:37,302 Epoch[28] Batch [1470]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097973,	
2017-07-12 20:49:44,558 Epoch[28] Batch [1480]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.097993,	
2017-07-12 20:49:48,651 Epoch[28] Train-FCNLogLoss=0.098061
2017-07-12 20:49:48,651 Epoch[28] Time cost=1084.440
2017-07-12 20:49:50,075 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0029.params"
2017-07-12 20:49:54,263 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0029.states"
2017-07-12 20:50:01,261 Epoch[29] Batch [10]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085074,	
2017-07-12 20:50:08,321 Epoch[29] Batch [20]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.100709,	
2017-07-12 20:50:15,506 Epoch[29] Batch [30]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.100652,	
2017-07-12 20:50:22,629 Epoch[29] Batch [40]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.099019,	
2017-07-12 20:50:29,416 Epoch[29] Batch [50]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.098288,	
2017-07-12 20:50:36,353 Epoch[29] Batch [60]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.098695,	
2017-07-12 20:50:43,346 Epoch[29] Batch [70]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.096586,	
2017-07-12 20:50:50,387 Epoch[29] Batch [80]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.097400,	
2017-07-12 20:50:57,331 Epoch[29] Batch [90]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.097427,	
2017-07-12 20:51:04,595 Epoch[29] Batch [100]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.097351,	
2017-07-12 20:51:12,543 Epoch[29] Batch [110]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.098254,	
2017-07-12 20:51:20,317 Epoch[29] Batch [120]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.098113,	
2017-07-12 20:51:28,295 Epoch[29] Batch [130]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.098220,	
2017-07-12 20:51:35,961 Epoch[29] Batch [140]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.098526,	
2017-07-12 20:51:43,653 Epoch[29] Batch [150]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.097921,	
2017-07-12 20:51:51,507 Epoch[29] Batch [160]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.098430,	
2017-07-12 20:51:59,259 Epoch[29] Batch [170]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.098405,	
2017-07-12 20:52:06,888 Epoch[29] Batch [180]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098616,	
2017-07-12 20:52:14,263 Epoch[29] Batch [190]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098779,	
2017-07-12 20:52:21,136 Epoch[29] Batch [200]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.098750,	
2017-07-12 20:52:27,758 Epoch[29] Batch [210]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.098596,	
2017-07-12 20:52:34,317 Epoch[29] Batch [220]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.099151,	
2017-07-12 20:52:41,075 Epoch[29] Batch [230]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.098917,	
2017-07-12 20:52:48,111 Epoch[29] Batch [240]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.099071,	
2017-07-12 20:52:55,594 Epoch[29] Batch [250]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.098212,	
2017-07-12 20:53:02,475 Epoch[29] Batch [260]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.098440,	
2017-07-12 20:53:09,990 Epoch[29] Batch [270]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.098380,	
2017-07-12 20:53:16,571 Epoch[29] Batch [280]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.097924,	
2017-07-12 20:53:23,847 Epoch[29] Batch [290]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.097942,	
2017-07-12 20:53:31,545 Epoch[29] Batch [300]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.097984,	
2017-07-12 20:53:39,246 Epoch[29] Batch [310]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.097843,	
2017-07-12 20:53:46,965 Epoch[29] Batch [320]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.098043,	
2017-07-12 20:53:54,789 Epoch[29] Batch [330]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.098202,	
2017-07-12 20:54:02,317 Epoch[29] Batch [340]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.098054,	
2017-07-12 20:54:10,045 Epoch[29] Batch [350]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.097768,	
2017-07-12 20:54:17,931 Epoch[29] Batch [360]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.097867,	
2017-07-12 20:54:25,549 Epoch[29] Batch [370]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.097882,	
2017-07-12 20:54:32,729 Epoch[29] Batch [380]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.098181,	
2017-07-12 20:54:39,677 Epoch[29] Batch [390]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.098503,	
2017-07-12 20:54:46,460 Epoch[29] Batch [400]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.098439,	
2017-07-12 20:54:53,154 Epoch[29] Batch [410]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.098419,	
2017-07-12 20:55:00,031 Epoch[29] Batch [420]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.098310,	
2017-07-12 20:55:07,101 Epoch[29] Batch [430]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.098487,	
2017-07-12 20:55:13,979 Epoch[29] Batch [440]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.098498,	
2017-07-12 20:55:20,816 Epoch[29] Batch [450]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.098506,	
2017-07-12 20:55:27,628 Epoch[29] Batch [460]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.098742,	
2017-07-12 20:55:33,978 Epoch[29] Batch [470]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.098588,	
2017-07-12 20:55:41,127 Epoch[29] Batch [480]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.098360,	
2017-07-12 20:55:48,727 Epoch[29] Batch [490]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.098275,	
2017-07-12 20:55:56,304 Epoch[29] Batch [500]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098281,	
2017-07-12 20:56:03,877 Epoch[29] Batch [510]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098073,	
2017-07-12 20:56:11,514 Epoch[29] Batch [520]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098277,	
2017-07-12 20:56:19,162 Epoch[29] Batch [530]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.098394,	
2017-07-12 20:56:26,797 Epoch[29] Batch [540]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098392,	
2017-07-12 20:56:34,479 Epoch[29] Batch [550]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.098487,	
2017-07-12 20:56:41,924 Epoch[29] Batch [560]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.098386,	
2017-07-12 20:56:49,181 Epoch[29] Batch [570]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.098216,	
2017-07-12 20:56:56,078 Epoch[29] Batch [580]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.098221,	
2017-07-12 20:57:02,746 Epoch[29] Batch [590]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.098098,	
2017-07-12 20:57:09,763 Epoch[29] Batch [600]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.098012,	
2017-07-12 20:57:16,657 Epoch[29] Batch [610]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.097896,	
2017-07-12 20:57:23,461 Epoch[29] Batch [620]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.097806,	
2017-07-12 20:57:30,685 Epoch[29] Batch [630]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.097844,	
2017-07-12 20:57:37,786 Epoch[29] Batch [640]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.097747,	
2017-07-12 20:57:44,594 Epoch[29] Batch [650]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.097648,	
2017-07-12 20:57:51,390 Epoch[29] Batch [660]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.097838,	
2017-07-12 20:57:58,552 Epoch[29] Batch [670]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.097937,	
2017-07-12 20:58:06,177 Epoch[29] Batch [680]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.098178,	
2017-07-12 20:58:13,811 Epoch[29] Batch [690]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098187,	
2017-07-12 20:58:21,354 Epoch[29] Batch [700]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.098543,	
2017-07-12 20:58:29,004 Epoch[29] Batch [710]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.098586,	
2017-07-12 20:58:36,560 Epoch[29] Batch [720]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098548,	
2017-07-12 20:58:44,093 Epoch[29] Batch [730]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.098584,	
2017-07-12 20:58:51,577 Epoch[29] Batch [740]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098657,	
2017-07-12 20:58:59,172 Epoch[29] Batch [750]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098683,	
2017-07-12 20:59:06,216 Epoch[29] Batch [760]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.098720,	
2017-07-12 20:59:13,038 Epoch[29] Batch [770]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.098840,	
2017-07-12 20:59:20,010 Epoch[29] Batch [780]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.098785,	
2017-07-12 20:59:26,805 Epoch[29] Batch [790]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.098854,	
2017-07-12 20:59:33,723 Epoch[29] Batch [800]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.098990,	
2017-07-12 20:59:40,512 Epoch[29] Batch [810]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.099046,	
2017-07-12 20:59:47,289 Epoch[29] Batch [820]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.099098,	
2017-07-12 20:59:54,092 Epoch[29] Batch [830]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.098989,	
2017-07-12 21:00:01,085 Epoch[29] Batch [840]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.098904,	
2017-07-12 21:00:07,828 Epoch[29] Batch [850]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.098876,	
2017-07-12 21:00:15,001 Epoch[29] Batch [860]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.098773,	
2017-07-12 21:00:22,485 Epoch[29] Batch [870]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.098776,	
2017-07-12 21:00:30,192 Epoch[29] Batch [880]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.098785,	
2017-07-12 21:00:37,963 Epoch[29] Batch [890]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.098815,	
2017-07-12 21:00:45,674 Epoch[29] Batch [900]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.098837,	
2017-07-12 21:00:53,569 Epoch[29] Batch [910]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.098810,	
2017-07-12 21:01:01,160 Epoch[29] Batch [920]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098809,	
2017-07-12 21:01:08,842 Epoch[29] Batch [930]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.098799,	
2017-07-12 21:01:16,619 Epoch[29] Batch [940]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.098732,	
2017-07-12 21:01:24,096 Epoch[29] Batch [950]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.098698,	
2017-07-12 21:01:31,236 Epoch[29] Batch [960]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.098737,	
2017-07-12 21:01:38,206 Epoch[29] Batch [970]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.098775,	
2017-07-12 21:01:45,186 Epoch[29] Batch [980]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.098843,	
2017-07-12 21:01:52,404 Epoch[29] Batch [990]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.098782,	
2017-07-12 21:01:59,906 Epoch[29] Batch [1000]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.098724,	
2017-07-12 21:02:07,007 Epoch[29] Batch [1010]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.098652,	
2017-07-12 21:02:14,123 Epoch[29] Batch [1020]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.098584,	
2017-07-12 21:02:21,233 Epoch[29] Batch [1030]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.098642,	
2017-07-12 21:02:28,573 Epoch[29] Batch [1040]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.098543,	
2017-07-12 21:02:36,052 Epoch[29] Batch [1050]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.098555,	
2017-07-12 21:02:43,775 Epoch[29] Batch [1060]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.098537,	
2017-07-12 21:02:51,387 Epoch[29] Batch [1070]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.098506,	
2017-07-12 21:02:59,095 Epoch[29] Batch [1080]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.098535,	
2017-07-12 21:03:06,687 Epoch[29] Batch [1090]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.098523,	
2017-07-12 21:03:14,228 Epoch[29] Batch [1100]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.098549,	
2017-07-12 21:03:22,079 Epoch[29] Batch [1110]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.098487,	
2017-07-12 21:03:29,951 Epoch[29] Batch [1120]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.098469,	
2017-07-12 21:03:37,495 Epoch[29] Batch [1130]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.098425,	
2017-07-12 21:03:44,835 Epoch[29] Batch [1140]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.098357,	
2017-07-12 21:03:51,592 Epoch[29] Batch [1150]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.098393,	
2017-07-12 21:03:58,900 Epoch[29] Batch [1160]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.098417,	
2017-07-12 21:04:05,825 Epoch[29] Batch [1170]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.098490,	
2017-07-12 21:04:12,895 Epoch[29] Batch [1180]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.098545,	
2017-07-12 21:04:19,785 Epoch[29] Batch [1190]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.098511,	
2017-07-12 21:04:26,443 Epoch[29] Batch [1200]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.098436,	
2017-07-12 21:04:33,318 Epoch[29] Batch [1210]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.098344,	
2017-07-12 21:04:40,312 Epoch[29] Batch [1220]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.098276,	
2017-07-12 21:04:47,265 Epoch[29] Batch [1230]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.098257,	
2017-07-12 21:04:54,881 Epoch[29] Batch [1240]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.098207,	
2017-07-12 21:05:02,455 Epoch[29] Batch [1250]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.098165,	
2017-07-12 21:05:09,788 Epoch[29] Batch [1260]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.098183,	
2017-07-12 21:05:17,329 Epoch[29] Batch [1270]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.098203,	
2017-07-12 21:05:24,986 Epoch[29] Batch [1280]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.098204,	
2017-07-12 21:05:32,353 Epoch[29] Batch [1290]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.098174,	
2017-07-12 21:05:40,012 Epoch[29] Batch [1300]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.098108,	
2017-07-12 21:05:47,702 Epoch[29] Batch [1310]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098119,	
2017-07-12 21:05:55,429 Epoch[29] Batch [1320]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.098118,	
2017-07-12 21:06:02,674 Epoch[29] Batch [1330]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.098203,	
2017-07-12 21:06:09,832 Epoch[29] Batch [1340]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.098166,	
2017-07-12 21:06:16,496 Epoch[29] Batch [1350]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.098183,	
2017-07-12 21:06:23,189 Epoch[29] Batch [1360]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.098193,	
2017-07-12 21:06:30,095 Epoch[29] Batch [1370]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.098200,	
2017-07-12 21:06:37,298 Epoch[29] Batch [1380]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.098171,	
2017-07-12 21:06:44,585 Epoch[29] Batch [1390]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.098150,	
2017-07-12 21:06:52,326 Epoch[29] Batch [1400]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.098263,	
2017-07-12 21:06:59,388 Epoch[29] Batch [1410]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.098281,	
2017-07-12 21:07:06,835 Epoch[29] Batch [1420]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.098272,	
2017-07-12 21:07:14,212 Epoch[29] Batch [1430]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098237,	
2017-07-12 21:07:21,657 Epoch[29] Batch [1440]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.098283,	
2017-07-12 21:07:29,044 Epoch[29] Batch [1450]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098248,	
2017-07-12 21:07:36,357 Epoch[29] Batch [1460]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.098218,	
2017-07-12 21:07:43,893 Epoch[29] Batch [1470]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.098225,	
2017-07-12 21:07:51,461 Epoch[29] Batch [1480]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098195,	
2017-07-12 21:07:55,952 Epoch[29] Train-FCNLogLoss=0.098214
2017-07-12 21:07:55,952 Epoch[29] Time cost=1081.689
2017-07-12 21:07:57,239 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0030.params"
2017-07-12 21:08:02,225 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0030.states"
2017-07-12 21:08:10,857 Epoch[30] Batch [10]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.100129,	
2017-07-12 21:08:18,360 Epoch[30] Batch [20]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099155,	
2017-07-12 21:08:25,660 Epoch[30] Batch [30]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.098492,	
2017-07-12 21:08:32,847 Epoch[30] Batch [40]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.099567,	
2017-07-12 21:08:40,190 Epoch[30] Batch [50]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.098579,	
2017-07-12 21:08:47,575 Epoch[30] Batch [60]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098074,	
2017-07-12 21:08:54,946 Epoch[30] Batch [70]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.098574,	
2017-07-12 21:09:01,976 Epoch[30] Batch [80]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.096901,	
2017-07-12 21:09:09,237 Epoch[30] Batch [90]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.097253,	
2017-07-12 21:09:16,389 Epoch[30] Batch [100]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.098994,	
2017-07-12 21:09:23,582 Epoch[30] Batch [110]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.101949,	
2017-07-12 21:09:30,909 Epoch[30] Batch [120]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.102541,	
2017-07-12 21:09:38,206 Epoch[30] Batch [130]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.102680,	
2017-07-12 21:09:45,367 Epoch[30] Batch [140]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.102061,	
2017-07-12 21:09:52,415 Epoch[30] Batch [150]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.102216,	
2017-07-12 21:09:59,614 Epoch[30] Batch [160]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.102707,	
2017-07-12 21:10:06,820 Epoch[30] Batch [170]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.102105,	
2017-07-12 21:10:13,786 Epoch[30] Batch [180]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.101856,	
2017-07-12 21:10:20,809 Epoch[30] Batch [190]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.101843,	
2017-07-12 21:10:28,002 Epoch[30] Batch [200]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.101968,	
2017-07-12 21:10:35,208 Epoch[30] Batch [210]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.102052,	
2017-07-12 21:10:42,455 Epoch[30] Batch [220]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.101855,	
2017-07-12 21:10:49,602 Epoch[30] Batch [230]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.102019,	
2017-07-12 21:10:57,014 Epoch[30] Batch [240]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.102226,	
2017-07-12 21:11:04,567 Epoch[30] Batch [250]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.101988,	
2017-07-12 21:11:12,347 Epoch[30] Batch [260]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.101313,	
2017-07-12 21:11:20,168 Epoch[30] Batch [270]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.101162,	
2017-07-12 21:11:28,023 Epoch[30] Batch [280]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.101575,	
2017-07-12 21:11:35,195 Epoch[30] Batch [290]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.101886,	
2017-07-12 21:11:42,610 Epoch[30] Batch [300]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.101888,	
2017-07-12 21:11:49,788 Epoch[30] Batch [310]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.102087,	
2017-07-12 21:11:57,150 Epoch[30] Batch [320]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.101918,	
2017-07-12 21:12:04,375 Epoch[30] Batch [330]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.101858,	
2017-07-12 21:12:11,467 Epoch[30] Batch [340]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.101648,	
2017-07-12 21:12:18,560 Epoch[30] Batch [350]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.101446,	
2017-07-12 21:12:25,721 Epoch[30] Batch [360]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.101507,	
2017-07-12 21:12:33,010 Epoch[30] Batch [370]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.101539,	
2017-07-12 21:12:40,058 Epoch[30] Batch [380]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.101301,	
2017-07-12 21:12:47,118 Epoch[30] Batch [390]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.101057,	
2017-07-12 21:12:54,172 Epoch[30] Batch [400]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.100964,	
2017-07-12 21:13:01,216 Epoch[30] Batch [410]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.100945,	
2017-07-12 21:13:08,624 Epoch[30] Batch [420]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.100962,	
2017-07-12 21:13:15,832 Epoch[30] Batch [430]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.100798,	
2017-07-12 21:13:23,249 Epoch[30] Batch [440]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.100631,	
2017-07-12 21:13:30,257 Epoch[30] Batch [450]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.100608,	
2017-07-12 21:13:36,980 Epoch[30] Batch [460]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.100444,	
2017-07-12 21:13:43,749 Epoch[30] Batch [470]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.100375,	
2017-07-12 21:13:51,027 Epoch[30] Batch [480]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.100095,	
2017-07-12 21:13:58,223 Epoch[30] Batch [490]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.100192,	
2017-07-12 21:14:05,332 Epoch[30] Batch [500]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.100217,	
2017-07-12 21:14:12,527 Epoch[30] Batch [510]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.099962,	
2017-07-12 21:14:20,170 Epoch[30] Batch [520]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.099808,	
2017-07-12 21:14:27,470 Epoch[30] Batch [530]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.099800,	
2017-07-12 21:14:34,928 Epoch[30] Batch [540]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.099525,	
2017-07-12 21:14:42,337 Epoch[30] Batch [550]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.099524,	
2017-07-12 21:14:49,658 Epoch[30] Batch [560]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.099689,	
2017-07-12 21:14:57,282 Epoch[30] Batch [570]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.099560,	
2017-07-12 21:15:04,790 Epoch[30] Batch [580]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099449,	
2017-07-12 21:15:12,379 Epoch[30] Batch [590]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.099381,	
2017-07-12 21:15:19,860 Epoch[30] Batch [600]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.099925,	
2017-07-12 21:15:27,226 Epoch[30] Batch [610]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.100082,	
2017-07-12 21:15:34,564 Epoch[30] Batch [620]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.100431,	
2017-07-12 21:15:42,087 Epoch[30] Batch [630]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.100484,	
2017-07-12 21:15:49,466 Epoch[30] Batch [640]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.100388,	
2017-07-12 21:15:56,858 Epoch[30] Batch [650]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.100381,	
2017-07-12 21:16:04,408 Epoch[30] Batch [660]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.100178,	
2017-07-12 21:16:12,108 Epoch[30] Batch [670]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.100193,	
2017-07-12 21:16:19,686 Epoch[30] Batch [680]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.100091,	
2017-07-12 21:16:27,237 Epoch[30] Batch [690]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.099935,	
2017-07-12 21:16:34,647 Epoch[30] Batch [700]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.100044,	
2017-07-12 21:16:41,758 Epoch[30] Batch [710]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.100133,	
2017-07-12 21:16:49,193 Epoch[30] Batch [720]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.100082,	
2017-07-12 21:16:56,366 Epoch[30] Batch [730]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.099914,	
2017-07-12 21:17:03,689 Epoch[30] Batch [740]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.099854,	
2017-07-12 21:17:11,471 Epoch[30] Batch [750]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.099790,	
2017-07-12 21:17:18,800 Epoch[30] Batch [760]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.099764,	
2017-07-12 21:17:26,416 Epoch[30] Batch [770]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.099697,	
2017-07-12 21:17:33,918 Epoch[30] Batch [780]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099730,	
2017-07-12 21:17:41,753 Epoch[30] Batch [790]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.099719,	
2017-07-12 21:17:49,394 Epoch[30] Batch [800]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.099640,	
2017-07-12 21:17:57,195 Epoch[30] Batch [810]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.099648,	
2017-07-12 21:18:05,158 Epoch[30] Batch [820]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.099569,	
2017-07-12 21:18:12,955 Epoch[30] Batch [830]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.099503,	
2017-07-12 21:18:20,715 Epoch[30] Batch [840]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.099510,	
2017-07-12 21:18:28,387 Epoch[30] Batch [850]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.099385,	
2017-07-12 21:18:36,041 Epoch[30] Batch [860]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.099297,	
2017-07-12 21:18:43,729 Epoch[30] Batch [870]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.099306,	
2017-07-12 21:18:50,880 Epoch[30] Batch [880]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.099273,	
2017-07-12 21:18:58,045 Epoch[30] Batch [890]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.099292,	
2017-07-12 21:19:05,202 Epoch[30] Batch [900]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.099290,	
2017-07-12 21:19:12,403 Epoch[30] Batch [910]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.099346,	
2017-07-12 21:19:19,621 Epoch[30] Batch [920]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.099310,	
2017-07-12 21:19:26,745 Epoch[30] Batch [930]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.099236,	
2017-07-12 21:19:33,881 Epoch[30] Batch [940]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.099275,	
2017-07-12 21:19:40,984 Epoch[30] Batch [950]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.099317,	
2017-07-12 21:19:48,038 Epoch[30] Batch [960]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.099212,	
2017-07-12 21:19:55,492 Epoch[30] Batch [970]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.099152,	
2017-07-12 21:20:03,144 Epoch[30] Batch [980]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.099130,	
2017-07-12 21:20:10,725 Epoch[30] Batch [990]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.099246,	
2017-07-12 21:20:18,200 Epoch[30] Batch [1000]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.099266,	
2017-07-12 21:20:25,887 Epoch[30] Batch [1010]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.099391,	
2017-07-12 21:20:33,393 Epoch[30] Batch [1020]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.099414,	
2017-07-12 21:20:40,939 Epoch[30] Batch [1030]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.099295,	
2017-07-12 21:20:48,408 Epoch[30] Batch [1040]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.099205,	
2017-07-12 21:20:55,870 Epoch[30] Batch [1050]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.099224,	
2017-07-12 21:21:03,350 Epoch[30] Batch [1060]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.099242,	
2017-07-12 21:21:10,347 Epoch[30] Batch [1070]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.099152,	
2017-07-12 21:21:17,533 Epoch[30] Batch [1080]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.099050,	
2017-07-12 21:21:24,690 Epoch[30] Batch [1090]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.099086,	
2017-07-12 21:21:31,659 Epoch[30] Batch [1100]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.099096,	
2017-07-12 21:21:38,745 Epoch[30] Batch [1110]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.099147,	
2017-07-12 21:21:46,028 Epoch[30] Batch [1120]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.099193,	
2017-07-12 21:21:52,968 Epoch[30] Batch [1130]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.099182,	
2017-07-12 21:22:00,144 Epoch[30] Batch [1140]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.099143,	
2017-07-12 21:22:07,268 Epoch[30] Batch [1150]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.099131,	
2017-07-12 21:22:14,875 Epoch[30] Batch [1160]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.099135,	
2017-07-12 21:22:22,529 Epoch[30] Batch [1170]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.099102,	
2017-07-12 21:22:29,546 Epoch[30] Batch [1180]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.099039,	
2017-07-12 21:22:37,120 Epoch[30] Batch [1190]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.099038,	
2017-07-12 21:22:44,151 Epoch[30] Batch [1200]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.098977,	
2017-07-12 21:22:51,433 Epoch[30] Batch [1210]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.098914,	
2017-07-12 21:22:59,163 Epoch[30] Batch [1220]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.098860,	
2017-07-12 21:23:06,804 Epoch[30] Batch [1230]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.098831,	
2017-07-12 21:23:14,305 Epoch[30] Batch [1240]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.098839,	
2017-07-12 21:23:21,619 Epoch[30] Batch [1250]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.098811,	
2017-07-12 21:23:28,817 Epoch[30] Batch [1260]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.098800,	
2017-07-12 21:23:35,929 Epoch[30] Batch [1270]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.098764,	
2017-07-12 21:23:43,298 Epoch[30] Batch [1280]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.098780,	
2017-07-12 21:23:50,657 Epoch[30] Batch [1290]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.098716,	
2017-07-12 21:23:57,950 Epoch[30] Batch [1300]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.098781,	
2017-07-12 21:24:04,952 Epoch[30] Batch [1310]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.098741,	
2017-07-12 21:24:12,092 Epoch[30] Batch [1320]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.098739,	
2017-07-12 21:24:19,175 Epoch[30] Batch [1330]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.098641,	
2017-07-12 21:24:26,196 Epoch[30] Batch [1340]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.098660,	
2017-07-12 21:24:33,882 Epoch[30] Batch [1350]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098636,	
2017-07-12 21:24:41,278 Epoch[30] Batch [1360]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.098574,	
2017-07-12 21:24:48,655 Epoch[30] Batch [1370]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.098594,	
2017-07-12 21:24:56,013 Epoch[30] Batch [1380]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.098548,	
2017-07-12 21:25:03,336 Epoch[30] Batch [1390]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.098576,	
2017-07-12 21:25:10,981 Epoch[30] Batch [1400]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.098560,	
2017-07-12 21:25:18,438 Epoch[30] Batch [1410]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.098460,	
2017-07-12 21:25:25,758 Epoch[30] Batch [1420]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.098442,	
2017-07-12 21:25:33,184 Epoch[30] Batch [1430]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.098376,	
2017-07-12 21:25:40,590 Epoch[30] Batch [1440]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.098442,	
2017-07-12 21:25:48,530 Epoch[30] Batch [1450]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.098411,	
2017-07-12 21:25:56,093 Epoch[30] Batch [1460]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.098395,	
2017-07-12 21:26:03,629 Epoch[30] Batch [1470]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.098382,	
2017-07-12 21:26:11,235 Epoch[30] Batch [1480]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.098367,	
2017-07-12 21:26:15,803 Epoch[30] Train-FCNLogLoss=0.098375
2017-07-12 21:26:15,804 Epoch[30] Time cost=1093.578
2017-07-12 21:26:17,231 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0031.params"
2017-07-12 21:26:21,860 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0031.states"
2017-07-12 21:26:30,502 Epoch[31] Batch [10]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.086516,	
2017-07-12 21:26:38,472 Epoch[31] Batch [20]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.092098,	
2017-07-12 21:26:46,331 Epoch[31] Batch [30]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.093443,	
2017-07-12 21:26:53,613 Epoch[31] Batch [40]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.093787,	
2017-07-12 21:27:01,033 Epoch[31] Batch [50]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.094329,	
2017-07-12 21:27:08,558 Epoch[31] Batch [60]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.094864,	
2017-07-12 21:27:16,068 Epoch[31] Batch [70]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.095324,	
2017-07-12 21:27:23,652 Epoch[31] Batch [80]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096588,	
2017-07-12 21:27:31,041 Epoch[31] Batch [90]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.096245,	
2017-07-12 21:27:38,215 Epoch[31] Batch [100]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.096309,	
2017-07-12 21:27:45,831 Epoch[31] Batch [110]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095709,	
2017-07-12 21:27:53,163 Epoch[31] Batch [120]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.095016,	
2017-07-12 21:28:00,939 Epoch[31] Batch [130]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.095143,	
2017-07-12 21:28:08,445 Epoch[31] Batch [140]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.095170,	
2017-07-12 21:28:15,990 Epoch[31] Batch [150]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.095344,	
2017-07-12 21:28:23,684 Epoch[31] Batch [160]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.095363,	
2017-07-12 21:28:31,546 Epoch[31] Batch [170]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.095352,	
2017-07-12 21:28:38,934 Epoch[31] Batch [180]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.094964,	
2017-07-12 21:28:46,729 Epoch[31] Batch [190]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.095046,	
2017-07-12 21:28:54,384 Epoch[31] Batch [200]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.095172,	
2017-07-12 21:29:02,017 Epoch[31] Batch [210]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095213,	
2017-07-12 21:29:09,737 Epoch[31] Batch [220]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.095545,	
2017-07-12 21:29:17,233 Epoch[31] Batch [230]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.096276,	
2017-07-12 21:29:25,132 Epoch[31] Batch [240]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.096767,	
2017-07-12 21:29:33,055 Epoch[31] Batch [250]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.096195,	
2017-07-12 21:29:40,855 Epoch[31] Batch [260]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.096044,	
2017-07-12 21:29:48,736 Epoch[31] Batch [270]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.096158,	
2017-07-12 21:29:56,688 Epoch[31] Batch [280]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.096612,	
2017-07-12 21:30:04,236 Epoch[31] Batch [290]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.096946,	
2017-07-12 21:30:11,887 Epoch[31] Batch [300]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.097370,	
2017-07-12 21:30:19,729 Epoch[31] Batch [310]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.097352,	
2017-07-12 21:30:27,214 Epoch[31] Batch [320]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.096790,	
2017-07-12 21:30:34,733 Epoch[31] Batch [330]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.097038,	
2017-07-12 21:30:42,171 Epoch[31] Batch [340]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.097000,	
2017-07-12 21:30:49,636 Epoch[31] Batch [350]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.096919,	
2017-07-12 21:30:57,268 Epoch[31] Batch [360]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.096893,	
2017-07-12 21:31:04,859 Epoch[31] Batch [370]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.096835,	
2017-07-12 21:31:12,530 Epoch[31] Batch [380]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.096767,	
2017-07-12 21:31:20,039 Epoch[31] Batch [390]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.096800,	
2017-07-12 21:31:27,800 Epoch[31] Batch [400]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.096841,	
2017-07-12 21:31:35,463 Epoch[31] Batch [410]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.096943,	
2017-07-12 21:31:43,001 Epoch[31] Batch [420]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.096738,	
2017-07-12 21:31:50,403 Epoch[31] Batch [430]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.096672,	
2017-07-12 21:31:58,388 Epoch[31] Batch [440]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.096909,	
2017-07-12 21:32:06,362 Epoch[31] Batch [450]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.096922,	
2017-07-12 21:32:14,206 Epoch[31] Batch [460]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.096934,	
2017-07-12 21:32:22,200 Epoch[31] Batch [470]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.097102,	
2017-07-12 21:32:30,193 Epoch[31] Batch [480]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.097126,	
2017-07-12 21:32:37,991 Epoch[31] Batch [490]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.097260,	
2017-07-12 21:32:45,447 Epoch[31] Batch [500]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.097314,	
2017-07-12 21:32:53,094 Epoch[31] Batch [510]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.097139,	
2017-07-12 21:33:00,488 Epoch[31] Batch [520]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.096973,	
2017-07-12 21:33:08,054 Epoch[31] Batch [530]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096666,	
2017-07-12 21:33:15,768 Epoch[31] Batch [540]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.096491,	
2017-07-12 21:33:23,442 Epoch[31] Batch [550]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.096526,	
2017-07-12 21:33:31,270 Epoch[31] Batch [560]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.096410,	
2017-07-12 21:33:38,778 Epoch[31] Batch [570]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.096274,	
2017-07-12 21:33:46,566 Epoch[31] Batch [580]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.096261,	
2017-07-12 21:33:54,553 Epoch[31] Batch [590]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.096392,	
2017-07-12 21:34:02,534 Epoch[31] Batch [600]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.096237,	
2017-07-12 21:34:10,630 Epoch[31] Batch [610]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.096203,	
2017-07-12 21:34:18,590 Epoch[31] Batch [620]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.096072,	
2017-07-12 21:34:26,326 Epoch[31] Batch [630]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.095978,	
2017-07-12 21:34:34,221 Epoch[31] Batch [640]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.095792,	
2017-07-12 21:34:42,183 Epoch[31] Batch [650]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.095875,	
2017-07-12 21:34:50,194 Epoch[31] Batch [660]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.095738,	
2017-07-12 21:34:58,097 Epoch[31] Batch [670]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.095668,	
2017-07-12 21:35:05,856 Epoch[31] Batch [680]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.095794,	
2017-07-12 21:35:13,655 Epoch[31] Batch [690]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.095814,	
2017-07-12 21:35:21,130 Epoch[31] Batch [700]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.095768,	
2017-07-12 21:35:28,651 Epoch[31] Batch [710]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.095703,	
2017-07-12 21:35:36,286 Epoch[31] Batch [720]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095661,	
2017-07-12 21:35:43,777 Epoch[31] Batch [730]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.095587,	
2017-07-12 21:35:51,446 Epoch[31] Batch [740]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.095743,	
2017-07-12 21:35:58,985 Epoch[31] Batch [750]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095699,	
2017-07-12 21:36:06,654 Epoch[31] Batch [760]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.095543,	
2017-07-12 21:36:14,125 Epoch[31] Batch [770]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.095469,	
2017-07-12 21:36:21,720 Epoch[31] Batch [780]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.095467,	
2017-07-12 21:36:29,494 Epoch[31] Batch [790]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.095342,	
2017-07-12 21:36:37,225 Epoch[31] Batch [800]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.095286,	
2017-07-12 21:36:44,964 Epoch[31] Batch [810]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.095228,	
2017-07-12 21:36:52,681 Epoch[31] Batch [820]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.095345,	
2017-07-12 21:37:00,358 Epoch[31] Batch [830]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.095257,	
2017-07-12 21:37:08,080 Epoch[31] Batch [840]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.095231,	
2017-07-12 21:37:15,785 Epoch[31] Batch [850]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.095371,	
2017-07-12 21:37:23,558 Epoch[31] Batch [860]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.095377,	
2017-07-12 21:37:30,917 Epoch[31] Batch [870]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.095336,	
2017-07-12 21:37:38,494 Epoch[31] Batch [880]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.095263,	
2017-07-12 21:37:46,304 Epoch[31] Batch [890]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.095253,	
2017-07-12 21:37:53,861 Epoch[31] Batch [900]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.095217,	
2017-07-12 21:38:01,542 Epoch[31] Batch [910]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.095216,	
2017-07-12 21:38:09,283 Epoch[31] Batch [920]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.095183,	
2017-07-12 21:38:16,685 Epoch[31] Batch [930]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.095215,	
2017-07-12 21:38:24,240 Epoch[31] Batch [940]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.095231,	
2017-07-12 21:38:31,878 Epoch[31] Batch [950]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095195,	
2017-07-12 21:38:39,491 Epoch[31] Batch [960]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095200,	
2017-07-12 21:38:46,535 Epoch[31] Batch [970]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.095221,	
2017-07-12 21:38:53,668 Epoch[31] Batch [980]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.095173,	
2017-07-12 21:39:00,884 Epoch[31] Batch [990]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.095167,	
2017-07-12 21:39:08,436 Epoch[31] Batch [1000]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.095277,	
2017-07-12 21:39:16,292 Epoch[31] Batch [1010]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.095232,	
2017-07-12 21:39:23,913 Epoch[31] Batch [1020]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095143,	
2017-07-12 21:39:31,624 Epoch[31] Batch [1030]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.095087,	
2017-07-12 21:39:39,160 Epoch[31] Batch [1040]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095220,	
2017-07-12 21:39:46,725 Epoch[31] Batch [1050]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.095466,	
2017-07-12 21:39:54,416 Epoch[31] Batch [1060]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.095768,	
2017-07-12 21:40:02,130 Epoch[31] Batch [1070]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.095778,	
2017-07-12 21:40:09,664 Epoch[31] Batch [1080]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095831,	
2017-07-12 21:40:17,205 Epoch[31] Batch [1090]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.095826,	
2017-07-12 21:40:24,497 Epoch[31] Batch [1100]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.095798,	
2017-07-12 21:40:31,670 Epoch[31] Batch [1110]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.095761,	
2017-07-12 21:40:38,974 Epoch[31] Batch [1120]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.095732,	
2017-07-12 21:40:46,078 Epoch[31] Batch [1130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.095730,	
2017-07-12 21:40:53,588 Epoch[31] Batch [1140]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.095829,	
2017-07-12 21:41:01,379 Epoch[31] Batch [1150]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.095905,	
2017-07-12 21:41:08,927 Epoch[31] Batch [1160]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.095959,	
2017-07-12 21:41:16,730 Epoch[31] Batch [1170]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.095984,	
2017-07-12 21:41:24,575 Epoch[31] Batch [1180]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.095993,	
2017-07-12 21:41:32,206 Epoch[31] Batch [1190]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095943,	
2017-07-12 21:41:39,972 Epoch[31] Batch [1200]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.095990,	
2017-07-12 21:41:47,863 Epoch[31] Batch [1210]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.095950,	
2017-07-12 21:41:55,173 Epoch[31] Batch [1220]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.096012,	
2017-07-12 21:42:03,091 Epoch[31] Batch [1230]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.095965,	
2017-07-12 21:42:10,721 Epoch[31] Batch [1240]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095974,	
2017-07-12 21:42:18,398 Epoch[31] Batch [1250]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.095881,	
2017-07-12 21:42:26,051 Epoch[31] Batch [1260]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.095833,	
2017-07-12 21:42:33,668 Epoch[31] Batch [1270]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095773,	
2017-07-12 21:42:41,240 Epoch[31] Batch [1280]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.095808,	
2017-07-12 21:42:48,760 Epoch[31] Batch [1290]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.095786,	
2017-07-12 21:42:56,521 Epoch[31] Batch [1300]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.095668,	
2017-07-12 21:43:04,332 Epoch[31] Batch [1310]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.095705,	
2017-07-12 21:43:12,187 Epoch[31] Batch [1320]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.095759,	
2017-07-12 21:43:19,848 Epoch[31] Batch [1330]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.095778,	
2017-07-12 21:43:27,362 Epoch[31] Batch [1340]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.095727,	
2017-07-12 21:43:35,133 Epoch[31] Batch [1350]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.095683,	
2017-07-12 21:43:42,798 Epoch[31] Batch [1360]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.095638,	
2017-07-12 21:43:50,541 Epoch[31] Batch [1370]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.095644,	
2017-07-12 21:43:58,337 Epoch[31] Batch [1380]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.095648,	
2017-07-12 21:44:06,010 Epoch[31] Batch [1390]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.095666,	
2017-07-12 21:44:13,724 Epoch[31] Batch [1400]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.095696,	
2017-07-12 21:44:21,186 Epoch[31] Batch [1410]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.095602,	
2017-07-12 21:44:28,795 Epoch[31] Batch [1420]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.095653,	
2017-07-12 21:44:36,500 Epoch[31] Batch [1430]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.095668,	
2017-07-12 21:44:44,098 Epoch[31] Batch [1440]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.095615,	
2017-07-12 21:44:51,594 Epoch[31] Batch [1450]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.095642,	
2017-07-12 21:44:59,410 Epoch[31] Batch [1460]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.095710,	
2017-07-12 21:45:06,946 Epoch[31] Batch [1470]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095711,	
2017-07-12 21:45:14,593 Epoch[31] Batch [1480]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.095704,	
2017-07-12 21:45:19,198 Epoch[31] Train-FCNLogLoss=0.095706
2017-07-12 21:45:19,198 Epoch[31] Time cost=1137.338
2017-07-12 21:45:20,572 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0032.params"
2017-07-12 21:45:25,227 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0032.states"
2017-07-12 21:45:33,803 Epoch[32] Batch [10]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.093146,	
2017-07-12 21:45:41,286 Epoch[32] Batch [20]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.088480,	
2017-07-12 21:45:48,839 Epoch[32] Batch [30]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.091436,	
2017-07-12 21:45:56,370 Epoch[32] Batch [40]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.091940,	
2017-07-12 21:46:04,040 Epoch[32] Batch [50]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.093736,	
2017-07-12 21:46:11,683 Epoch[32] Batch [60]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.092795,	
2017-07-12 21:46:19,262 Epoch[32] Batch [70]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.094329,	
2017-07-12 21:46:26,700 Epoch[32] Batch [80]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.093888,	
2017-07-12 21:46:34,265 Epoch[32] Batch [90]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.094403,	
2017-07-12 21:46:41,736 Epoch[32] Batch [100]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.093364,	
2017-07-12 21:46:49,166 Epoch[32] Batch [110]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.094623,	
2017-07-12 21:46:56,686 Epoch[32] Batch [120]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.094594,	
2017-07-12 21:47:04,273 Epoch[32] Batch [130]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.094154,	
2017-07-12 21:47:11,882 Epoch[32] Batch [140]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.094488,	
2017-07-12 21:47:19,265 Epoch[32] Batch [150]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.095479,	
2017-07-12 21:47:26,724 Epoch[32] Batch [160]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.095537,	
2017-07-12 21:47:34,212 Epoch[32] Batch [170]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.095745,	
2017-07-12 21:47:41,852 Epoch[32] Batch [180]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095797,	
2017-07-12 21:47:49,483 Epoch[32] Batch [190]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095777,	
2017-07-12 21:47:57,218 Epoch[32] Batch [200]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.095645,	
2017-07-12 21:48:04,999 Epoch[32] Batch [210]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.096355,	
2017-07-12 21:48:12,732 Epoch[32] Batch [220]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.096981,	
2017-07-12 21:48:20,199 Epoch[32] Batch [230]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.097639,	
2017-07-12 21:48:27,892 Epoch[32] Batch [240]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.098173,	
2017-07-12 21:48:35,526 Epoch[32] Batch [250]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.098069,	
2017-07-12 21:48:43,168 Epoch[32] Batch [260]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.097902,	
2017-07-12 21:48:50,505 Epoch[32] Batch [270]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.097529,	
2017-07-12 21:48:57,805 Epoch[32] Batch [280]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097483,	
2017-07-12 21:49:05,207 Epoch[32] Batch [290]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.097556,	
2017-07-12 21:49:12,615 Epoch[32] Batch [300]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.097603,	
2017-07-12 21:49:19,913 Epoch[32] Batch [310]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.097626,	
2017-07-12 21:49:26,918 Epoch[32] Batch [320]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.097634,	
2017-07-12 21:49:33,748 Epoch[32] Batch [330]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.097489,	
2017-07-12 21:49:40,894 Epoch[32] Batch [340]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.097067,	
2017-07-12 21:49:48,330 Epoch[32] Batch [350]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.096902,	
2017-07-12 21:49:55,848 Epoch[32] Batch [360]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.096843,	
2017-07-12 21:50:03,322 Epoch[32] Batch [370]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096812,	
2017-07-12 21:50:10,931 Epoch[32] Batch [380]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.096712,	
2017-07-12 21:50:18,570 Epoch[32] Batch [390]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.096530,	
2017-07-12 21:50:26,405 Epoch[32] Batch [400]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.096576,	
2017-07-12 21:50:34,036 Epoch[32] Batch [410]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.096570,	
2017-07-12 21:50:41,649 Epoch[32] Batch [420]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.096722,	
2017-07-12 21:50:49,340 Epoch[32] Batch [430]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.096397,	
2017-07-12 21:50:57,051 Epoch[32] Batch [440]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.096400,	
2017-07-12 21:51:04,494 Epoch[32] Batch [450]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.096280,	
2017-07-12 21:51:11,939 Epoch[32] Batch [460]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.096662,	
2017-07-12 21:51:19,258 Epoch[32] Batch [470]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.096442,	
2017-07-12 21:51:26,659 Epoch[32] Batch [480]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.096534,	
2017-07-12 21:51:34,221 Epoch[32] Batch [490]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.096379,	
2017-07-12 21:51:41,537 Epoch[32] Batch [500]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.096252,	
2017-07-12 21:51:49,157 Epoch[32] Batch [510]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.096386,	
2017-07-12 21:51:56,639 Epoch[32] Batch [520]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096438,	
2017-07-12 21:52:03,944 Epoch[32] Batch [530]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.096464,	
2017-07-12 21:52:11,518 Epoch[32] Batch [540]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.096318,	
2017-07-12 21:52:18,898 Epoch[32] Batch [550]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.096359,	
2017-07-12 21:52:26,435 Epoch[32] Batch [560]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.096159,	
2017-07-12 21:52:34,120 Epoch[32] Batch [570]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.096213,	
2017-07-12 21:52:41,380 Epoch[32] Batch [580]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.096224,	
2017-07-12 21:52:48,850 Epoch[32] Batch [590]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.096101,	
2017-07-12 21:52:56,379 Epoch[32] Batch [600]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.095961,	
2017-07-12 21:53:04,033 Epoch[32] Batch [610]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.095841,	
2017-07-12 21:53:11,386 Epoch[32] Batch [620]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.095842,	
2017-07-12 21:53:18,929 Epoch[32] Batch [630]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.095938,	
2017-07-12 21:53:26,452 Epoch[32] Batch [640]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.096016,	
2017-07-12 21:53:34,040 Epoch[32] Batch [650]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.095882,	
2017-07-12 21:53:41,480 Epoch[32] Batch [660]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.095711,	
2017-07-12 21:53:49,093 Epoch[32] Batch [670]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.095678,	
2017-07-12 21:53:56,690 Epoch[32] Batch [680]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.095943,	
2017-07-12 21:54:04,364 Epoch[32] Batch [690]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.095877,	
2017-07-12 21:54:11,730 Epoch[32] Batch [700]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.095706,	
2017-07-12 21:54:19,138 Epoch[32] Batch [710]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.095551,	
2017-07-12 21:54:26,776 Epoch[32] Batch [720]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.095576,	
2017-07-12 21:54:33,411 Epoch[32] Batch [730]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.095588,	
2017-07-12 21:54:39,887 Epoch[32] Batch [740]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.095344,	
2017-07-12 21:54:46,492 Epoch[32] Batch [750]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.095362,	
2017-07-12 21:54:53,034 Epoch[32] Batch [760]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.095483,	
2017-07-12 21:54:59,677 Epoch[32] Batch [770]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.095476,	
2017-07-12 21:55:05,763 Epoch[32] Batch [780]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.095450,	
2017-07-12 21:55:11,580 Epoch[32] Batch [790]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095561,	
2017-07-12 21:55:18,142 Epoch[32] Batch [800]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.095494,	
2017-07-12 21:55:24,985 Epoch[32] Batch [810]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.095561,	
2017-07-12 21:55:31,765 Epoch[32] Batch [820]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.095522,	
2017-07-12 21:55:38,383 Epoch[32] Batch [830]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.095562,	
2017-07-12 21:55:44,839 Epoch[32] Batch [840]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.095662,	
2017-07-12 21:55:51,377 Epoch[32] Batch [850]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.095701,	
2017-07-12 21:55:58,068 Epoch[32] Batch [860]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.095681,	
2017-07-12 21:56:04,778 Epoch[32] Batch [870]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.095581,	
2017-07-12 21:56:11,328 Epoch[32] Batch [880]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.095616,	
2017-07-12 21:56:17,826 Epoch[32] Batch [890]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.095652,	
2017-07-12 21:56:24,179 Epoch[32] Batch [900]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.095659,	
2017-07-12 21:56:30,616 Epoch[32] Batch [910]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.095519,	
2017-07-12 21:56:37,020 Epoch[32] Batch [920]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.095573,	
2017-07-12 21:56:43,514 Epoch[32] Batch [930]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.095427,	
2017-07-12 21:56:50,098 Epoch[32] Batch [940]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.095443,	
2017-07-12 21:56:56,528 Epoch[32] Batch [950]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.095351,	
2017-07-12 21:57:03,088 Epoch[32] Batch [960]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.095404,	
2017-07-12 21:57:10,133 Epoch[32] Batch [970]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.095792,	
2017-07-12 21:57:16,863 Epoch[32] Batch [980]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.096025,	
2017-07-12 21:57:23,342 Epoch[32] Batch [990]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.096107,	
2017-07-12 21:57:29,927 Epoch[32] Batch [1000]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.096053,	
2017-07-12 21:57:36,536 Epoch[32] Batch [1010]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.096017,	
2017-07-12 21:57:43,424 Epoch[32] Batch [1020]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.096021,	
2017-07-12 21:57:50,425 Epoch[32] Batch [1030]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.095986,	
2017-07-12 21:57:57,103 Epoch[32] Batch [1040]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.096074,	
2017-07-12 21:58:03,524 Epoch[32] Batch [1050]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.096187,	
2017-07-12 21:58:10,073 Epoch[32] Batch [1060]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.096236,	
2017-07-12 21:58:16,560 Epoch[32] Batch [1070]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.096254,	
2017-07-12 21:58:23,134 Epoch[32] Batch [1080]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.096260,	
2017-07-12 21:58:29,786 Epoch[32] Batch [1090]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.096211,	
2017-07-12 21:58:35,949 Epoch[32] Batch [1100]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.096344,	
2017-07-12 21:58:42,635 Epoch[32] Batch [1110]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.096367,	
2017-07-12 21:58:49,389 Epoch[32] Batch [1120]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.096401,	
2017-07-12 21:58:56,143 Epoch[32] Batch [1130]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.096415,	
2017-07-12 21:59:02,507 Epoch[32] Batch [1140]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.096441,	
2017-07-12 21:59:09,169 Epoch[32] Batch [1150]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.096521,	
2017-07-12 21:59:15,490 Epoch[32] Batch [1160]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.096474,	
2017-07-12 21:59:21,904 Epoch[32] Batch [1170]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.096457,	
2017-07-12 21:59:28,582 Epoch[32] Batch [1180]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.096434,	
2017-07-12 21:59:35,162 Epoch[32] Batch [1190]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.096311,	
2017-07-12 21:59:41,663 Epoch[32] Batch [1200]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.096298,	
2017-07-12 21:59:48,519 Epoch[32] Batch [1210]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.096212,	
2017-07-12 21:59:55,225 Epoch[32] Batch [1220]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.096143,	
2017-07-12 22:00:01,976 Epoch[32] Batch [1230]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.096086,	
2017-07-12 22:00:08,438 Epoch[32] Batch [1240]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.096084,	
2017-07-12 22:00:15,081 Epoch[32] Batch [1250]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.096052,	
2017-07-12 22:00:21,740 Epoch[32] Batch [1260]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.096070,	
2017-07-12 22:00:28,206 Epoch[32] Batch [1270]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.096054,	
2017-07-12 22:00:35,030 Epoch[32] Batch [1280]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.096057,	
2017-07-12 22:00:41,652 Epoch[32] Batch [1290]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.096004,	
2017-07-12 22:00:48,022 Epoch[32] Batch [1300]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.095991,	
2017-07-12 22:00:54,228 Epoch[32] Batch [1310]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.095963,	
2017-07-12 22:01:00,605 Epoch[32] Batch [1320]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.095922,	
2017-07-12 22:01:07,006 Epoch[32] Batch [1330]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.095944,	
2017-07-12 22:01:13,324 Epoch[32] Batch [1340]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.095864,	
2017-07-12 22:01:19,910 Epoch[32] Batch [1350]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.095895,	
2017-07-12 22:01:26,085 Epoch[32] Batch [1360]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.095962,	
2017-07-12 22:01:32,498 Epoch[32] Batch [1370]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.095968,	
2017-07-12 22:01:38,826 Epoch[32] Batch [1380]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.095966,	
2017-07-12 22:01:45,144 Epoch[32] Batch [1390]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.095967,	
2017-07-12 22:01:51,610 Epoch[32] Batch [1400]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.095934,	
2017-07-12 22:01:58,132 Epoch[32] Batch [1410]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.095847,	
2017-07-12 22:02:04,526 Epoch[32] Batch [1420]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.095936,	
2017-07-12 22:02:11,025 Epoch[32] Batch [1430]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.095822,	
2017-07-12 22:02:17,604 Epoch[32] Batch [1440]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.095828,	
2017-07-12 22:02:24,182 Epoch[32] Batch [1450]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.095795,	
2017-07-12 22:02:30,797 Epoch[32] Batch [1460]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.095754,	
2017-07-12 22:02:37,328 Epoch[32] Batch [1470]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.095775,	
2017-07-12 22:02:44,082 Epoch[32] Batch [1480]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.095804,	
2017-07-12 22:02:48,089 Epoch[32] Train-FCNLogLoss=0.095762
2017-07-12 22:02:48,090 Epoch[32] Time cost=1042.862
2017-07-12 22:02:48,980 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0033.params"
2017-07-12 22:02:50,629 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0033.states"
2017-07-12 22:02:58,058 Epoch[33] Batch [10]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.100569,	
2017-07-12 22:03:04,693 Epoch[33] Batch [20]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.099594,	
2017-07-12 22:03:11,130 Epoch[33] Batch [30]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.095218,	
2017-07-12 22:03:17,629 Epoch[33] Batch [40]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.093477,	
2017-07-12 22:03:24,296 Epoch[33] Batch [50]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.093573,	
2017-07-12 22:03:30,890 Epoch[33] Batch [60]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.093267,	
2017-07-12 22:03:37,298 Epoch[33] Batch [70]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.092029,	
2017-07-12 22:03:43,914 Epoch[33] Batch [80]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.091627,	
2017-07-12 22:03:50,434 Epoch[33] Batch [90]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.091909,	
2017-07-12 22:03:56,722 Epoch[33] Batch [100]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.092381,	
2017-07-12 22:04:03,336 Epoch[33] Batch [110]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.091769,	
2017-07-12 22:04:10,039 Epoch[33] Batch [120]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.091140,	
2017-07-12 22:04:16,555 Epoch[33] Batch [130]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.090966,	
2017-07-12 22:04:22,883 Epoch[33] Batch [140]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.090724,	
2017-07-12 22:04:28,676 Epoch[33] Batch [150]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.090741,	
2017-07-12 22:04:35,110 Epoch[33] Batch [160]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.090982,	
2017-07-12 22:04:41,518 Epoch[33] Batch [170]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.091493,	
2017-07-12 22:04:47,973 Epoch[33] Batch [180]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.091902,	
2017-07-12 22:04:54,410 Epoch[33] Batch [190]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.092145,	
2017-07-12 22:05:01,095 Epoch[33] Batch [200]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.092214,	
2017-07-12 22:05:07,480 Epoch[33] Batch [210]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.092501,	
2017-07-12 22:05:14,116 Epoch[33] Batch [220]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.092551,	
2017-07-12 22:05:20,692 Epoch[33] Batch [230]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.093024,	
2017-07-12 22:05:27,404 Epoch[33] Batch [240]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.092768,	
2017-07-12 22:05:34,111 Epoch[33] Batch [250]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.092871,	
2017-07-12 22:05:40,540 Epoch[33] Batch [260]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.092721,	
2017-07-12 22:05:46,979 Epoch[33] Batch [270]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.092823,	
2017-07-12 22:05:53,707 Epoch[33] Batch [280]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.092703,	
2017-07-12 22:06:00,712 Epoch[33] Batch [290]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.092771,	
2017-07-12 22:06:07,154 Epoch[33] Batch [300]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.092644,	
2017-07-12 22:06:13,551 Epoch[33] Batch [310]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.092832,	
2017-07-12 22:06:19,934 Epoch[33] Batch [320]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.092929,	
2017-07-12 22:06:26,413 Epoch[33] Batch [330]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.092984,	
2017-07-12 22:06:33,316 Epoch[33] Batch [340]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.093077,	
2017-07-12 22:06:39,396 Epoch[33] Batch [350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.092839,	
2017-07-12 22:06:46,001 Epoch[33] Batch [360]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.092754,	
2017-07-12 22:06:52,560 Epoch[33] Batch [370]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.093266,	
2017-07-12 22:06:59,429 Epoch[33] Batch [380]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.093370,	
2017-07-12 22:07:05,916 Epoch[33] Batch [390]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.093850,	
2017-07-12 22:07:12,643 Epoch[33] Batch [400]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.094415,	
2017-07-12 22:07:18,802 Epoch[33] Batch [410]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.094736,	
2017-07-12 22:07:25,106 Epoch[33] Batch [420]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.094978,	
2017-07-12 22:07:31,803 Epoch[33] Batch [430]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.095068,	
2017-07-12 22:07:38,497 Epoch[33] Batch [440]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.095079,	
2017-07-12 22:07:45,233 Epoch[33] Batch [450]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.095057,	
2017-07-12 22:07:51,884 Epoch[33] Batch [460]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.095070,	
2017-07-12 22:07:58,020 Epoch[33] Batch [470]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.095022,	
2017-07-12 22:08:04,817 Epoch[33] Batch [480]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.095158,	
2017-07-12 22:08:11,228 Epoch[33] Batch [490]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.095213,	
2017-07-12 22:08:17,739 Epoch[33] Batch [500]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.095023,	
2017-07-12 22:08:23,888 Epoch[33] Batch [510]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.095010,	
2017-07-12 22:08:30,430 Epoch[33] Batch [520]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.095148,	
2017-07-12 22:08:37,025 Epoch[33] Batch [530]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.095093,	
2017-07-12 22:08:43,561 Epoch[33] Batch [540]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.094884,	
2017-07-12 22:08:50,171 Epoch[33] Batch [550]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.094958,	
2017-07-12 22:08:56,647 Epoch[33] Batch [560]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.095124,	
2017-07-12 22:09:03,251 Epoch[33] Batch [570]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.095177,	
2017-07-12 22:09:09,716 Epoch[33] Batch [580]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.095121,	
2017-07-12 22:09:16,333 Epoch[33] Batch [590]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.095145,	
2017-07-12 22:09:22,976 Epoch[33] Batch [600]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.095117,	
2017-07-12 22:09:29,570 Epoch[33] Batch [610]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.095152,	
2017-07-12 22:09:36,152 Epoch[33] Batch [620]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.095079,	
2017-07-12 22:09:42,946 Epoch[33] Batch [630]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.095020,	
2017-07-12 22:09:49,842 Epoch[33] Batch [640]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.095109,	
2017-07-12 22:09:55,941 Epoch[33] Batch [650]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.094905,	
2017-07-12 22:10:02,416 Epoch[33] Batch [660]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.094799,	
2017-07-12 22:10:08,915 Epoch[33] Batch [670]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.094778,	
2017-07-12 22:10:15,329 Epoch[33] Batch [680]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.094668,	
2017-07-12 22:10:22,076 Epoch[33] Batch [690]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.094632,	
2017-07-12 22:10:28,398 Epoch[33] Batch [700]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.094617,	
2017-07-12 22:10:34,857 Epoch[33] Batch [710]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.094527,	
2017-07-12 22:10:41,770 Epoch[33] Batch [720]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.094534,	
2017-07-12 22:10:48,350 Epoch[33] Batch [730]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.094643,	
2017-07-12 22:10:54,952 Epoch[33] Batch [740]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.094683,	
2017-07-12 22:11:01,741 Epoch[33] Batch [750]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.094584,	
2017-07-12 22:11:08,100 Epoch[33] Batch [760]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.094693,	
2017-07-12 22:11:14,582 Epoch[33] Batch [770]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.094861,	
2017-07-12 22:11:21,231 Epoch[33] Batch [780]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.094805,	
2017-07-12 22:11:27,668 Epoch[33] Batch [790]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.094812,	
2017-07-12 22:11:33,841 Epoch[33] Batch [800]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.094778,	
2017-07-12 22:11:40,270 Epoch[33] Batch [810]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.094688,	
2017-07-12 22:11:46,262 Epoch[33] Batch [820]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094642,	
2017-07-12 22:11:52,130 Epoch[33] Batch [830]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.094690,	
2017-07-12 22:11:58,623 Epoch[33] Batch [840]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.094763,	
2017-07-12 22:12:05,021 Epoch[33] Batch [850]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.094678,	
2017-07-12 22:12:11,582 Epoch[33] Batch [860]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.094648,	
2017-07-12 22:12:17,918 Epoch[33] Batch [870]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.094761,	
2017-07-12 22:12:24,054 Epoch[33] Batch [880]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.094770,	
2017-07-12 22:12:30,482 Epoch[33] Batch [890]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.094684,	
2017-07-12 22:12:37,239 Epoch[33] Batch [900]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.094737,	
2017-07-12 22:12:43,764 Epoch[33] Batch [910]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.094664,	
2017-07-12 22:12:50,274 Epoch[33] Batch [920]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.094585,	
2017-07-12 22:12:56,664 Epoch[33] Batch [930]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.094557,	
2017-07-12 22:13:03,297 Epoch[33] Batch [940]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.094478,	
2017-07-12 22:13:09,862 Epoch[33] Batch [950]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.094511,	
2017-07-12 22:13:16,694 Epoch[33] Batch [960]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.094600,	
2017-07-12 22:13:23,112 Epoch[33] Batch [970]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.094527,	
2017-07-12 22:13:29,574 Epoch[33] Batch [980]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.094479,	
2017-07-12 22:13:36,000 Epoch[33] Batch [990]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.094517,	
2017-07-12 22:13:42,260 Epoch[33] Batch [1000]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.094497,	
2017-07-12 22:13:48,599 Epoch[33] Batch [1010]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.094403,	
2017-07-12 22:13:54,912 Epoch[33] Batch [1020]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.094312,	
2017-07-12 22:14:01,602 Epoch[33] Batch [1030]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.094281,	
2017-07-12 22:14:08,040 Epoch[33] Batch [1040]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.094385,	
2017-07-12 22:14:14,326 Epoch[33] Batch [1050]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.094440,	
2017-07-12 22:14:20,538 Epoch[33] Batch [1060]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.094425,	
2017-07-12 22:14:27,024 Epoch[33] Batch [1070]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.094392,	
2017-07-12 22:14:33,543 Epoch[33] Batch [1080]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.094383,	
2017-07-12 22:14:39,703 Epoch[33] Batch [1090]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.094330,	
2017-07-12 22:14:45,693 Epoch[33] Batch [1100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094494,	
2017-07-12 22:14:52,080 Epoch[33] Batch [1110]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.094402,	
2017-07-12 22:14:58,283 Epoch[33] Batch [1120]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.094469,	
2017-07-12 22:15:04,484 Epoch[33] Batch [1130]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.094389,	
2017-07-12 22:15:10,960 Epoch[33] Batch [1140]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.094316,	
2017-07-12 22:15:17,198 Epoch[33] Batch [1150]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.094314,	
2017-07-12 22:15:23,264 Epoch[33] Batch [1160]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.094280,	
2017-07-12 22:15:29,381 Epoch[33] Batch [1170]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.094233,	
2017-07-12 22:15:35,772 Epoch[33] Batch [1180]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.094266,	
2017-07-12 22:15:42,069 Epoch[33] Batch [1190]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.094217,	
2017-07-12 22:15:48,422 Epoch[33] Batch [1200]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.094309,	
2017-07-12 22:15:54,745 Epoch[33] Batch [1210]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.094235,	
2017-07-12 22:16:01,616 Epoch[33] Batch [1220]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.094211,	
2017-07-12 22:16:07,545 Epoch[33] Batch [1230]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.094170,	
2017-07-12 22:16:13,498 Epoch[33] Batch [1240]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094209,	
2017-07-12 22:16:19,559 Epoch[33] Batch [1250]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.094117,	
2017-07-12 22:16:25,853 Epoch[33] Batch [1260]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.094065,	
2017-07-12 22:16:31,924 Epoch[33] Batch [1270]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.094068,	
2017-07-12 22:16:38,342 Epoch[33] Batch [1280]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.094054,	
2017-07-12 22:16:44,546 Epoch[33] Batch [1290]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.093970,	
2017-07-12 22:16:50,316 Epoch[33] Batch [1300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094027,	
2017-07-12 22:16:56,867 Epoch[33] Batch [1310]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.094054,	
2017-07-12 22:17:02,873 Epoch[33] Batch [1320]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.094076,	
2017-07-12 22:17:08,762 Epoch[33] Batch [1330]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.094124,	
2017-07-12 22:17:15,091 Epoch[33] Batch [1340]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094085,	
2017-07-12 22:17:21,321 Epoch[33] Batch [1350]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.093987,	
2017-07-12 22:17:27,677 Epoch[33] Batch [1360]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.094073,	
2017-07-12 22:17:33,833 Epoch[33] Batch [1370]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.094014,	
2017-07-12 22:17:39,782 Epoch[33] Batch [1380]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094018,	
2017-07-12 22:17:46,201 Epoch[33] Batch [1390]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.093985,	
2017-07-12 22:17:52,533 Epoch[33] Batch [1400]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094013,	
2017-07-12 22:17:58,420 Epoch[33] Batch [1410]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.094024,	
2017-07-12 22:18:05,044 Epoch[33] Batch [1420]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.094038,	
2017-07-12 22:18:11,367 Epoch[33] Batch [1430]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.093975,	
2017-07-12 22:18:17,738 Epoch[33] Batch [1440]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.094051,	
2017-07-12 22:18:24,178 Epoch[33] Batch [1450]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.094142,	
2017-07-12 22:18:30,513 Epoch[33] Batch [1460]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.094244,	
2017-07-12 22:18:36,467 Epoch[33] Batch [1470]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094371,	
2017-07-12 22:18:42,460 Epoch[33] Batch [1480]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094405,	
2017-07-12 22:18:45,884 Epoch[33] Train-FCNLogLoss=0.094401
2017-07-12 22:18:45,884 Epoch[33] Time cost=955.255
2017-07-12 22:18:46,759 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0034.params"
2017-07-12 22:18:48,425 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0034.states"
2017-07-12 22:18:55,590 Epoch[34] Batch [10]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.094465,	
2017-07-12 22:19:01,547 Epoch[34] Batch [20]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.091763,	
2017-07-12 22:19:07,754 Epoch[34] Batch [30]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.093877,	
2017-07-12 22:19:13,926 Epoch[34] Batch [40]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.092953,	
2017-07-12 22:19:19,711 Epoch[34] Batch [50]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.096130,	
2017-07-12 22:19:26,114 Epoch[34] Batch [60]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.094183,	
2017-07-12 22:19:32,397 Epoch[34] Batch [70]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.095296,	
2017-07-12 22:19:38,538 Epoch[34] Batch [80]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.094582,	
2017-07-12 22:19:44,552 Epoch[34] Batch [90]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.094461,	
2017-07-12 22:19:50,691 Epoch[34] Batch [100]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.093084,	
2017-07-12 22:19:56,693 Epoch[34] Batch [110]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.093400,	
2017-07-12 22:20:02,929 Epoch[34] Batch [120]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093346,	
2017-07-12 22:20:08,849 Epoch[34] Batch [130]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.093912,	
2017-07-12 22:20:14,446 Epoch[34] Batch [140]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.094271,	
2017-07-12 22:20:20,312 Epoch[34] Batch [150]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.093983,	
2017-07-12 22:20:26,156 Epoch[34] Batch [160]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.093710,	
2017-07-12 22:20:32,147 Epoch[34] Batch [170]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094309,	
2017-07-12 22:20:38,263 Epoch[34] Batch [180]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.093645,	
2017-07-12 22:20:44,076 Epoch[34] Batch [190]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.094101,	
2017-07-12 22:20:50,208 Epoch[34] Batch [200]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.093861,	
2017-07-12 22:20:56,173 Epoch[34] Batch [210]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.093401,	
2017-07-12 22:21:02,021 Epoch[34] Batch [220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.093399,	
2017-07-12 22:21:08,255 Epoch[34] Batch [230]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.093494,	
2017-07-12 22:21:14,557 Epoch[34] Batch [240]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.093403,	
2017-07-12 22:21:20,662 Epoch[34] Batch [250]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.093401,	
2017-07-12 22:21:27,055 Epoch[34] Batch [260]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.093281,	
2017-07-12 22:21:32,943 Epoch[34] Batch [270]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.093190,	
2017-07-12 22:21:39,008 Epoch[34] Batch [280]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.093368,	
2017-07-12 22:21:45,298 Epoch[34] Batch [290]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.094362,	
2017-07-12 22:21:51,458 Epoch[34] Batch [300]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.094371,	
2017-07-12 22:21:57,658 Epoch[34] Batch [310]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.094484,	
2017-07-12 22:22:03,956 Epoch[34] Batch [320]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.094420,	
2017-07-12 22:22:10,121 Epoch[34] Batch [330]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.094336,	
2017-07-12 22:22:16,419 Epoch[34] Batch [340]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.094236,	
2017-07-12 22:22:22,125 Epoch[34] Batch [350]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.094292,	
2017-07-12 22:22:27,897 Epoch[34] Batch [360]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094152,	
2017-07-12 22:22:34,289 Epoch[34] Batch [370]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.094396,	
2017-07-12 22:22:40,326 Epoch[34] Batch [380]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.094215,	
2017-07-12 22:22:46,045 Epoch[34] Batch [390]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.094346,	
2017-07-12 22:22:52,258 Epoch[34] Batch [400]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.094374,	
2017-07-12 22:22:58,696 Epoch[34] Batch [410]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.094045,	
2017-07-12 22:23:04,364 Epoch[34] Batch [420]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.094073,	
2017-07-12 22:23:10,431 Epoch[34] Batch [430]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.094344,	
2017-07-12 22:23:16,306 Epoch[34] Batch [440]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.094193,	
2017-07-12 22:23:21,955 Epoch[34] Batch [450]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.094244,	
2017-07-12 22:23:28,094 Epoch[34] Batch [460]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.094479,	
2017-07-12 22:23:34,498 Epoch[34] Batch [470]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.094396,	
2017-07-12 22:23:40,943 Epoch[34] Batch [480]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.094173,	
2017-07-12 22:23:47,603 Epoch[34] Batch [490]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.094235,	
2017-07-12 22:23:53,321 Epoch[34] Batch [500]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.094129,	
2017-07-12 22:23:59,362 Epoch[34] Batch [510]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.094144,	
2017-07-12 22:24:05,835 Epoch[34] Batch [520]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.094174,	
2017-07-12 22:24:11,890 Epoch[34] Batch [530]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.094349,	
2017-07-12 22:24:17,768 Epoch[34] Batch [540]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.094163,	
2017-07-12 22:24:23,732 Epoch[34] Batch [550]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.094089,	
2017-07-12 22:24:29,615 Epoch[34] Batch [560]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.094238,	
2017-07-12 22:24:35,628 Epoch[34] Batch [570]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.094245,	
2017-07-12 22:24:41,598 Epoch[34] Batch [580]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.094188,	
2017-07-12 22:24:47,694 Epoch[34] Batch [590]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.094472,	
2017-07-12 22:24:54,431 Epoch[34] Batch [600]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.094508,	
2017-07-12 22:25:00,529 Epoch[34] Batch [610]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.094672,	
2017-07-12 22:25:06,920 Epoch[34] Batch [620]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.094686,	
2017-07-12 22:25:13,006 Epoch[34] Batch [630]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.094760,	
2017-07-12 22:25:18,780 Epoch[34] Batch [640]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094625,	
2017-07-12 22:25:24,993 Epoch[34] Batch [650]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.094606,	
2017-07-12 22:25:31,103 Epoch[34] Batch [660]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.094670,	
2017-07-12 22:25:37,073 Epoch[34] Batch [670]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.094685,	
2017-07-12 22:25:42,987 Epoch[34] Batch [680]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.094594,	
2017-07-12 22:25:48,998 Epoch[34] Batch [690]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.094502,	
2017-07-12 22:25:54,980 Epoch[34] Batch [700]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.094384,	
2017-07-12 22:26:01,111 Epoch[34] Batch [710]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.094562,	
2017-07-12 22:26:07,154 Epoch[34] Batch [720]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.094614,	
2017-07-12 22:26:13,259 Epoch[34] Batch [730]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.094693,	
2017-07-12 22:26:19,680 Epoch[34] Batch [740]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.094739,	
2017-07-12 22:26:25,866 Epoch[34] Batch [750]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.094712,	
2017-07-12 22:26:31,798 Epoch[34] Batch [760]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.094717,	
2017-07-12 22:26:37,973 Epoch[34] Batch [770]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.094551,	
2017-07-12 22:26:44,035 Epoch[34] Batch [780]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.094416,	
2017-07-12 22:26:50,123 Epoch[34] Batch [790]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.094432,	
2017-07-12 22:26:56,205 Epoch[34] Batch [800]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.094483,	
2017-07-12 22:27:02,233 Epoch[34] Batch [810]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.094508,	
2017-07-12 22:27:08,143 Epoch[34] Batch [820]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.094373,	
2017-07-12 22:27:14,474 Epoch[34] Batch [830]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094472,	
2017-07-12 22:27:20,457 Epoch[34] Batch [840]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.094440,	
2017-07-12 22:27:26,234 Epoch[34] Batch [850]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.094388,	
2017-07-12 22:27:32,412 Epoch[34] Batch [860]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.094393,	
2017-07-12 22:27:38,872 Epoch[34] Batch [870]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.094491,	
2017-07-12 22:27:45,069 Epoch[34] Batch [880]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.094594,	
2017-07-12 22:27:51,742 Epoch[34] Batch [890]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.094512,	
2017-07-12 22:27:57,805 Epoch[34] Batch [900]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.094429,	
2017-07-12 22:28:04,082 Epoch[34] Batch [910]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.094484,	
2017-07-12 22:28:10,088 Epoch[34] Batch [920]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.094437,	
2017-07-12 22:28:15,945 Epoch[34] Batch [930]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.094373,	
2017-07-12 22:28:22,270 Epoch[34] Batch [940]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094383,	
2017-07-12 22:28:28,372 Epoch[34] Batch [950]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.094385,	
2017-07-12 22:28:34,381 Epoch[34] Batch [960]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.094359,	
2017-07-12 22:28:40,270 Epoch[34] Batch [970]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.094235,	
2017-07-12 22:28:46,336 Epoch[34] Batch [980]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.094230,	
2017-07-12 22:28:52,742 Epoch[34] Batch [990]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.094290,	
2017-07-12 22:28:58,720 Epoch[34] Batch [1000]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.094200,	
2017-07-12 22:29:04,713 Epoch[34] Batch [1010]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094160,	
2017-07-12 22:29:10,329 Epoch[34] Batch [1020]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.094194,	
2017-07-12 22:29:15,823 Epoch[34] Batch [1030]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.094089,	
2017-07-12 22:29:21,273 Epoch[34] Batch [1040]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093987,	
2017-07-12 22:29:27,190 Epoch[34] Batch [1050]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.093950,	
2017-07-12 22:29:33,459 Epoch[34] Batch [1060]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.093904,	
2017-07-12 22:29:39,459 Epoch[34] Batch [1070]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.093974,	
2017-07-12 22:29:45,816 Epoch[34] Batch [1080]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.093988,	
2017-07-12 22:29:51,890 Epoch[34] Batch [1090]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093920,	
2017-07-12 22:29:57,530 Epoch[34] Batch [1100]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.093940,	
2017-07-12 22:30:03,749 Epoch[34] Batch [1110]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.093874,	
2017-07-12 22:30:09,976 Epoch[34] Batch [1120]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.093806,	
2017-07-12 22:30:16,261 Epoch[34] Batch [1130]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.093749,	
2017-07-12 22:30:22,829 Epoch[34] Batch [1140]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.093885,	
2017-07-12 22:30:28,873 Epoch[34] Batch [1150]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093878,	
2017-07-12 22:30:35,187 Epoch[34] Batch [1160]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.093897,	
2017-07-12 22:30:41,500 Epoch[34] Batch [1170]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.093879,	
2017-07-12 22:30:47,458 Epoch[34] Batch [1180]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.093864,	
2017-07-12 22:30:53,552 Epoch[34] Batch [1190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.093829,	
2017-07-12 22:30:59,720 Epoch[34] Batch [1200]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.093807,	
2017-07-12 22:31:05,488 Epoch[34] Batch [1210]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.093828,	
2017-07-12 22:31:11,612 Epoch[34] Batch [1220]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093834,	
2017-07-12 22:31:17,681 Epoch[34] Batch [1230]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093888,	
2017-07-12 22:31:23,913 Epoch[34] Batch [1240]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.093887,	
2017-07-12 22:31:29,917 Epoch[34] Batch [1250]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.093924,	
2017-07-12 22:31:36,020 Epoch[34] Batch [1260]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.093934,	
2017-07-12 22:31:42,215 Epoch[34] Batch [1270]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.093892,	
2017-07-12 22:31:48,580 Epoch[34] Batch [1280]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.093792,	
2017-07-12 22:31:54,396 Epoch[34] Batch [1290]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.093701,	
2017-07-12 22:32:00,696 Epoch[34] Batch [1300]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.093677,	
2017-07-12 22:32:07,051 Epoch[34] Batch [1310]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.093619,	
2017-07-12 22:32:13,098 Epoch[34] Batch [1320]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093610,	
2017-07-12 22:32:19,584 Epoch[34] Batch [1330]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.093502,	
2017-07-12 22:32:25,635 Epoch[34] Batch [1340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.093416,	
2017-07-12 22:32:31,515 Epoch[34] Batch [1350]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093390,	
2017-07-12 22:32:37,256 Epoch[34] Batch [1360]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.093344,	
2017-07-12 22:32:43,383 Epoch[34] Batch [1370]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093340,	
2017-07-12 22:32:49,517 Epoch[34] Batch [1380]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.093235,	
2017-07-12 22:32:55,702 Epoch[34] Batch [1390]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.093312,	
2017-07-12 22:33:01,796 Epoch[34] Batch [1400]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.093368,	
2017-07-12 22:33:08,203 Epoch[34] Batch [1410]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.093425,	
2017-07-12 22:33:14,462 Epoch[34] Batch [1420]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.093465,	
2017-07-12 22:33:20,547 Epoch[34] Batch [1430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.093510,	
2017-07-12 22:33:26,357 Epoch[34] Batch [1440]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.093527,	
2017-07-12 22:33:32,426 Epoch[34] Batch [1450]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093545,	
2017-07-12 22:33:38,627 Epoch[34] Batch [1460]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.093542,	
2017-07-12 22:33:45,003 Epoch[34] Batch [1470]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.093535,	
2017-07-12 22:33:51,189 Epoch[34] Batch [1480]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.093575,	
2017-07-12 22:33:55,119 Epoch[34] Train-FCNLogLoss=0.093500
2017-07-12 22:33:55,120 Epoch[34] Time cost=906.694
2017-07-12 22:33:55,998 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0035.params"
2017-07-12 22:33:58,170 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0035.states"
2017-07-12 22:34:05,154 Epoch[35] Batch [10]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.089543,	
2017-07-12 22:34:11,732 Epoch[35] Batch [20]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.086302,	
2017-07-12 22:34:17,802 Epoch[35] Batch [30]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.091889,	
2017-07-12 22:34:23,899 Epoch[35] Batch [40]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.090379,	
2017-07-12 22:34:29,902 Epoch[35] Batch [50]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.089189,	
2017-07-12 22:34:36,051 Epoch[35] Batch [60]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.088932,	
2017-07-12 22:34:42,376 Epoch[35] Batch [70]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.088324,	
2017-07-12 22:34:48,322 Epoch[35] Batch [80]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.088753,	
2017-07-12 22:34:54,548 Epoch[35] Batch [90]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.089467,	
2017-07-12 22:35:00,661 Epoch[35] Batch [100]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.089683,	
2017-07-12 22:35:06,386 Epoch[35] Batch [110]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.089192,	
2017-07-12 22:35:12,413 Epoch[35] Batch [120]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.089366,	
2017-07-12 22:35:18,774 Epoch[35] Batch [130]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.089764,	
2017-07-12 22:35:24,756 Epoch[35] Batch [140]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.089818,	
2017-07-12 22:35:30,525 Epoch[35] Batch [150]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.090616,	
2017-07-12 22:35:36,607 Epoch[35] Batch [160]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.090576,	
2017-07-12 22:35:42,816 Epoch[35] Batch [170]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.090606,	
2017-07-12 22:35:48,814 Epoch[35] Batch [180]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.090760,	
2017-07-12 22:35:54,599 Epoch[35] Batch [190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.090873,	
2017-07-12 22:36:01,154 Epoch[35] Batch [200]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.091091,	
2017-07-12 22:36:07,199 Epoch[35] Batch [210]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.090963,	
2017-07-12 22:36:13,317 Epoch[35] Batch [220]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.090921,	
2017-07-12 22:36:19,441 Epoch[35] Batch [230]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.090620,	
2017-07-12 22:36:25,793 Epoch[35] Batch [240]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.090922,	
2017-07-12 22:36:31,960 Epoch[35] Batch [250]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.091003,	
2017-07-12 22:36:38,133 Epoch[35] Batch [260]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.090759,	
2017-07-12 22:36:44,437 Epoch[35] Batch [270]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.090933,	
2017-07-12 22:36:50,188 Epoch[35] Batch [280]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.090934,	
2017-07-12 22:36:56,246 Epoch[35] Batch [290]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.090803,	
2017-07-12 22:37:03,057 Epoch[35] Batch [300]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.090956,	
2017-07-12 22:37:09,132 Epoch[35] Batch [310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.091190,	
2017-07-12 22:37:15,690 Epoch[35] Batch [320]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.091048,	
2017-07-12 22:37:21,812 Epoch[35] Batch [330]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.091046,	
2017-07-12 22:37:28,153 Epoch[35] Batch [340]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.090885,	
2017-07-12 22:37:34,472 Epoch[35] Batch [350]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.091167,	
2017-07-12 22:37:39,868 Epoch[35] Batch [360]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090896,	
2017-07-12 22:37:45,509 Epoch[35] Batch [370]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.091203,	
2017-07-12 22:37:51,430 Epoch[35] Batch [380]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.091077,	
2017-07-12 22:37:56,935 Epoch[35] Batch [390]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.091297,	
2017-07-12 22:38:02,495 Epoch[35] Batch [400]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.091374,	
2017-07-12 22:38:08,215 Epoch[35] Batch [410]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.091556,	
2017-07-12 22:38:13,765 Epoch[35] Batch [420]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.091364,	
2017-07-12 22:38:19,558 Epoch[35] Batch [430]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.091422,	
2017-07-12 22:38:25,399 Epoch[35] Batch [440]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.091269,	
2017-07-12 22:38:31,477 Epoch[35] Batch [450]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.091388,	
2017-07-12 22:38:37,314 Epoch[35] Batch [460]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.091894,	
2017-07-12 22:38:43,050 Epoch[35] Batch [470]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.091927,	
2017-07-12 22:38:48,941 Epoch[35] Batch [480]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.092089,	
2017-07-12 22:38:54,964 Epoch[35] Batch [490]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.092075,	
2017-07-12 22:39:01,056 Epoch[35] Batch [500]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.092210,	
2017-07-12 22:39:07,110 Epoch[35] Batch [510]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.092228,	
2017-07-12 22:39:13,294 Epoch[35] Batch [520]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.092240,	
2017-07-12 22:39:19,238 Epoch[35] Batch [530]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.092105,	
2017-07-12 22:39:25,051 Epoch[35] Batch [540]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.092167,	
2017-07-12 22:39:30,858 Epoch[35] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.092094,	
2017-07-12 22:39:36,895 Epoch[35] Batch [560]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.091941,	
2017-07-12 22:39:42,548 Epoch[35] Batch [570]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.092088,	
2017-07-12 22:39:48,141 Epoch[35] Batch [580]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.092113,	
2017-07-12 22:39:54,320 Epoch[35] Batch [590]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.092155,	
2017-07-12 22:40:00,255 Epoch[35] Batch [600]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.092138,	
2017-07-12 22:40:06,266 Epoch[35] Batch [610]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.092144,	
2017-07-12 22:40:12,012 Epoch[35] Batch [620]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.092110,	
2017-07-12 22:40:17,849 Epoch[35] Batch [630]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.092206,	
2017-07-12 22:40:23,549 Epoch[35] Batch [640]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.092310,	
2017-07-12 22:40:29,304 Epoch[35] Batch [650]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.092173,	
2017-07-12 22:40:35,047 Epoch[35] Batch [660]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.092300,	
2017-07-12 22:40:41,199 Epoch[35] Batch [670]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.092348,	
2017-07-12 22:40:47,020 Epoch[35] Batch [680]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.092275,	
2017-07-12 22:40:53,209 Epoch[35] Batch [690]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.092168,	
2017-07-12 22:40:59,071 Epoch[35] Batch [700]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.092086,	
2017-07-12 22:41:04,891 Epoch[35] Batch [710]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.092006,	
2017-07-12 22:41:10,380 Epoch[35] Batch [720]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.091936,	
2017-07-12 22:41:16,403 Epoch[35] Batch [730]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.091895,	
2017-07-12 22:41:22,420 Epoch[35] Batch [740]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.091850,	
2017-07-12 22:41:28,308 Epoch[35] Batch [750]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.091923,	
2017-07-12 22:41:33,684 Epoch[35] Batch [760]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091864,	
2017-07-12 22:41:39,227 Epoch[35] Batch [770]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.091817,	
2017-07-12 22:41:44,969 Epoch[35] Batch [780]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.091761,	
2017-07-12 22:41:50,884 Epoch[35] Batch [790]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.091798,	
2017-07-12 22:41:57,034 Epoch[35] Batch [800]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.091805,	
2017-07-12 22:42:02,919 Epoch[35] Batch [810]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.091809,	
2017-07-12 22:42:08,700 Epoch[35] Batch [820]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.091785,	
2017-07-12 22:42:14,616 Epoch[35] Batch [830]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.091852,	
2017-07-12 22:42:20,335 Epoch[35] Batch [840]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.091854,	
2017-07-12 22:42:25,877 Epoch[35] Batch [850]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.091889,	
2017-07-12 22:42:31,775 Epoch[35] Batch [860]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.091905,	
2017-07-12 22:42:37,744 Epoch[35] Batch [870]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.092040,	
2017-07-12 22:42:43,639 Epoch[35] Batch [880]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.092031,	
2017-07-12 22:42:49,351 Epoch[35] Batch [890]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.091980,	
2017-07-12 22:42:55,297 Epoch[35] Batch [900]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.091988,	
2017-07-12 22:43:01,282 Epoch[35] Batch [910]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.092080,	
2017-07-12 22:43:07,313 Epoch[35] Batch [920]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.092044,	
2017-07-12 22:43:13,173 Epoch[35] Batch [930]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.092096,	
2017-07-12 22:43:19,106 Epoch[35] Batch [940]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.092346,	
2017-07-12 22:43:25,008 Epoch[35] Batch [950]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.092468,	
2017-07-12 22:43:30,852 Epoch[35] Batch [960]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.092486,	
2017-07-12 22:43:36,748 Epoch[35] Batch [970]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.092430,	
2017-07-12 22:43:42,541 Epoch[35] Batch [980]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.092452,	
2017-07-12 22:43:48,315 Epoch[35] Batch [990]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.092415,	
2017-07-12 22:43:54,340 Epoch[35] Batch [1000]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.092421,	
2017-07-12 22:43:59,980 Epoch[35] Batch [1010]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.092421,	
2017-07-12 22:44:06,057 Epoch[35] Batch [1020]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.092461,	
2017-07-12 22:44:11,855 Epoch[35] Batch [1030]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.092520,	
2017-07-12 22:44:17,533 Epoch[35] Batch [1040]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.092534,	
2017-07-12 22:44:23,380 Epoch[35] Batch [1050]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.092547,	
2017-07-12 22:44:28,836 Epoch[35] Batch [1060]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.092450,	
2017-07-12 22:44:34,670 Epoch[35] Batch [1070]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.092501,	
2017-07-12 22:44:40,702 Epoch[35] Batch [1080]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.092480,	
2017-07-12 22:44:46,554 Epoch[35] Batch [1090]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.092438,	
2017-07-12 22:44:52,546 Epoch[35] Batch [1100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.092507,	
2017-07-12 22:44:58,375 Epoch[35] Batch [1110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.092539,	
2017-07-12 22:45:04,234 Epoch[35] Batch [1120]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.092522,	
2017-07-12 22:45:10,069 Epoch[35] Batch [1130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.092455,	
2017-07-12 22:45:15,826 Epoch[35] Batch [1140]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.092444,	
2017-07-12 22:45:21,474 Epoch[35] Batch [1150]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.092431,	
2017-07-12 22:45:27,207 Epoch[35] Batch [1160]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.092469,	
2017-07-12 22:45:32,978 Epoch[35] Batch [1170]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.092419,	
2017-07-12 22:45:38,801 Epoch[35] Batch [1180]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.092403,	
2017-07-12 22:45:44,351 Epoch[35] Batch [1190]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.092490,	
2017-07-12 22:45:50,278 Epoch[35] Batch [1200]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.092648,	
2017-07-12 22:45:56,493 Epoch[35] Batch [1210]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.093031,	
2017-07-12 22:46:02,671 Epoch[35] Batch [1220]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.093221,	
2017-07-12 22:46:08,517 Epoch[35] Batch [1230]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.093385,	
2017-07-12 22:46:14,177 Epoch[35] Batch [1240]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.093535,	
2017-07-12 22:46:20,057 Epoch[35] Batch [1250]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093628,	
2017-07-12 22:46:26,392 Epoch[35] Batch [1260]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.093727,	
2017-07-12 22:46:32,210 Epoch[35] Batch [1270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.093758,	
2017-07-12 22:46:38,518 Epoch[35] Batch [1280]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.093735,	
2017-07-12 22:46:44,644 Epoch[35] Batch [1290]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093697,	
2017-07-12 22:46:50,711 Epoch[35] Batch [1300]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093728,	
2017-07-12 22:46:56,900 Epoch[35] Batch [1310]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.093798,	
2017-07-12 22:47:02,958 Epoch[35] Batch [1320]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.093754,	
2017-07-12 22:47:09,032 Epoch[35] Batch [1330]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093855,	
2017-07-12 22:47:14,615 Epoch[35] Batch [1340]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.093899,	
2017-07-12 22:47:19,406 Epoch[35] Batch [1350]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.093887,	
2017-07-12 22:47:25,389 Epoch[35] Batch [1360]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.093953,	
2017-07-12 22:47:31,721 Epoch[35] Batch [1370]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.093922,	
2017-07-12 22:47:37,959 Epoch[35] Batch [1380]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093858,	
2017-07-12 22:47:44,649 Epoch[35] Batch [1390]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.093869,	
2017-07-12 22:47:50,878 Epoch[35] Batch [1400]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.093945,	
2017-07-12 22:47:56,997 Epoch[35] Batch [1410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.093922,	
2017-07-12 22:48:03,070 Epoch[35] Batch [1420]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093969,	
2017-07-12 22:48:09,016 Epoch[35] Batch [1430]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093975,	
2017-07-12 22:48:15,063 Epoch[35] Batch [1440]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.094039,	
2017-07-12 22:48:21,088 Epoch[35] Batch [1450]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.094011,	
2017-07-12 22:48:27,037 Epoch[35] Batch [1460]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.094000,	
2017-07-12 22:48:33,774 Epoch[35] Batch [1470]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.094024,	
2017-07-12 22:48:40,220 Epoch[35] Batch [1480]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.094011,	
2017-07-12 22:48:44,054 Epoch[35] Train-FCNLogLoss=0.093967
2017-07-12 22:48:44,054 Epoch[35] Time cost=885.884
2017-07-12 22:48:45,338 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0036.params"
2017-07-12 22:48:50,012 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0036.states"
2017-07-12 22:48:57,310 Epoch[36] Batch [10]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.097690,	
2017-07-12 22:49:03,241 Epoch[36] Batch [20]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.102099,	
2017-07-12 22:49:09,323 Epoch[36] Batch [30]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.104437,	
2017-07-12 22:49:14,990 Epoch[36] Batch [40]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.102641,	
2017-07-12 22:49:20,947 Epoch[36] Batch [50]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.100702,	
2017-07-12 22:49:26,910 Epoch[36] Batch [60]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099908,	
2017-07-12 22:49:33,053 Epoch[36] Batch [70]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.099509,	
2017-07-12 22:49:39,203 Epoch[36] Batch [80]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.099245,	
2017-07-12 22:49:45,313 Epoch[36] Batch [90]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099095,	
2017-07-12 22:49:51,465 Epoch[36] Batch [100]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.098346,	
2017-07-12 22:49:57,555 Epoch[36] Batch [110]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098207,	
2017-07-12 22:50:03,397 Epoch[36] Batch [120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.097188,	
2017-07-12 22:50:09,193 Epoch[36] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.097148,	
2017-07-12 22:50:15,332 Epoch[36] Batch [140]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.096550,	
2017-07-12 22:50:20,887 Epoch[36] Batch [150]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.096350,	
2017-07-12 22:50:27,035 Epoch[36] Batch [160]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.096339,	
2017-07-12 22:50:33,227 Epoch[36] Batch [170]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.096203,	
2017-07-12 22:50:38,999 Epoch[36] Batch [180]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.096051,	
2017-07-12 22:50:45,085 Epoch[36] Batch [190]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.095512,	
2017-07-12 22:50:51,123 Epoch[36] Batch [200]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.094826,	
2017-07-12 22:50:56,874 Epoch[36] Batch [210]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.094692,	
2017-07-12 22:51:02,943 Epoch[36] Batch [220]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.094789,	
2017-07-12 22:51:09,153 Epoch[36] Batch [230]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.094672,	
2017-07-12 22:51:15,145 Epoch[36] Batch [240]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.094815,	
2017-07-12 22:51:21,549 Epoch[36] Batch [250]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.094870,	
2017-07-12 22:51:27,564 Epoch[36] Batch [260]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.094796,	
2017-07-12 22:51:33,315 Epoch[36] Batch [270]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.094640,	
2017-07-12 22:51:39,537 Epoch[36] Batch [280]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.094303,	
2017-07-12 22:51:45,555 Epoch[36] Batch [290]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.094444,	
2017-07-12 22:51:51,886 Epoch[36] Batch [300]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094188,	
2017-07-12 22:51:58,040 Epoch[36] Batch [310]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.094079,	
2017-07-12 22:52:03,946 Epoch[36] Batch [320]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.094177,	
2017-07-12 22:52:10,061 Epoch[36] Batch [330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.093807,	
2017-07-12 22:52:15,781 Epoch[36] Batch [340]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.093757,	
2017-07-12 22:52:21,684 Epoch[36] Batch [350]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.093718,	
2017-07-12 22:52:28,058 Epoch[36] Batch [360]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.093631,	
2017-07-12 22:52:34,170 Epoch[36] Batch [370]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.093796,	
2017-07-12 22:52:40,197 Epoch[36] Batch [380]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.094111,	
2017-07-12 22:52:46,529 Epoch[36] Batch [390]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.094111,	
2017-07-12 22:52:52,177 Epoch[36] Batch [400]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.093984,	
2017-07-12 22:52:58,341 Epoch[36] Batch [410]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.094083,	
2017-07-12 22:53:04,594 Epoch[36] Batch [420]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.094222,	
2017-07-12 22:53:10,058 Epoch[36] Batch [430]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.094297,	
2017-07-12 22:53:16,407 Epoch[36] Batch [440]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.094420,	
2017-07-12 22:53:22,772 Epoch[36] Batch [450]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.094381,	
2017-07-12 22:53:28,669 Epoch[36] Batch [460]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.094144,	
2017-07-12 22:53:34,736 Epoch[36] Batch [470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.094220,	
2017-07-12 22:53:40,714 Epoch[36] Batch [480]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.094107,	
2017-07-12 22:53:46,931 Epoch[36] Batch [490]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.093965,	
2017-07-12 22:53:53,323 Epoch[36] Batch [500]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.093843,	
2017-07-12 22:53:59,111 Epoch[36] Batch [510]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.093829,	
2017-07-12 22:54:05,087 Epoch[36] Batch [520]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.093809,	
2017-07-12 22:54:10,831 Epoch[36] Batch [530]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.093835,	
2017-07-12 22:54:16,678 Epoch[36] Batch [540]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.093898,	
2017-07-12 22:54:23,096 Epoch[36] Batch [550]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.093750,	
2017-07-12 22:54:29,107 Epoch[36] Batch [560]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.093691,	
2017-07-12 22:54:35,048 Epoch[36] Batch [570]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093653,	
2017-07-12 22:54:41,356 Epoch[36] Batch [580]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.093686,	
2017-07-12 22:54:47,495 Epoch[36] Batch [590]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.093618,	
2017-07-12 22:54:53,426 Epoch[36] Batch [600]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.093769,	
2017-07-12 22:54:59,633 Epoch[36] Batch [610]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.093898,	
2017-07-12 22:55:05,395 Epoch[36] Batch [620]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.093910,	
2017-07-12 22:55:11,389 Epoch[36] Batch [630]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.093984,	
2017-07-12 22:55:17,408 Epoch[36] Batch [640]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.093964,	
2017-07-12 22:55:23,294 Epoch[36] Batch [650]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093924,	
2017-07-12 22:55:29,208 Epoch[36] Batch [660]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.094023,	
2017-07-12 22:55:35,638 Epoch[36] Batch [670]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.093942,	
2017-07-12 22:55:41,741 Epoch[36] Batch [680]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.093924,	
2017-07-12 22:55:47,793 Epoch[36] Batch [690]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.093899,	
2017-07-12 22:55:53,699 Epoch[36] Batch [700]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.093926,	
2017-07-12 22:55:59,495 Epoch[36] Batch [710]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093862,	
2017-07-12 22:56:05,648 Epoch[36] Batch [720]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.093732,	
2017-07-12 22:56:11,949 Epoch[36] Batch [730]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.093762,	
2017-07-12 22:56:18,134 Epoch[36] Batch [740]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.093719,	
2017-07-12 22:56:23,611 Epoch[36] Batch [750]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093829,	
2017-07-12 22:56:29,503 Epoch[36] Batch [760]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.093676,	
2017-07-12 22:56:35,722 Epoch[36] Batch [770]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.093674,	
2017-07-12 22:56:42,067 Epoch[36] Batch [780]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.093803,	
2017-07-12 22:56:48,587 Epoch[36] Batch [790]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.093674,	
2017-07-12 22:56:54,468 Epoch[36] Batch [800]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093690,	
2017-07-12 22:57:00,901 Epoch[36] Batch [810]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.093711,	
2017-07-12 22:57:07,005 Epoch[36] Batch [820]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.093852,	
2017-07-12 22:57:13,066 Epoch[36] Batch [830]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.093900,	
2017-07-12 22:57:19,480 Epoch[36] Batch [840]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.093963,	
2017-07-12 22:57:25,531 Epoch[36] Batch [850]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.093970,	
2017-07-12 22:57:31,327 Epoch[36] Batch [860]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.094007,	
2017-07-12 22:57:37,547 Epoch[36] Batch [870]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.094069,	
2017-07-12 22:57:43,625 Epoch[36] Batch [880]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.094099,	
2017-07-12 22:57:49,822 Epoch[36] Batch [890]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.094146,	
2017-07-12 22:57:56,220 Epoch[36] Batch [900]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.094132,	
2017-07-12 22:58:02,014 Epoch[36] Batch [910]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.094103,	
2017-07-12 22:58:08,380 Epoch[36] Batch [920]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.094174,	
2017-07-12 22:58:14,700 Epoch[36] Batch [930]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.094265,	
2017-07-12 22:58:20,819 Epoch[36] Batch [940]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.094319,	
2017-07-12 22:58:26,737 Epoch[36] Batch [950]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.094284,	
2017-07-12 22:58:33,107 Epoch[36] Batch [960]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.094261,	
2017-07-12 22:58:38,912 Epoch[36] Batch [970]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.094254,	
2017-07-12 22:58:44,579 Epoch[36] Batch [980]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.094157,	
2017-07-12 22:58:50,627 Epoch[36] Batch [990]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.094162,	
2017-07-12 22:58:56,667 Epoch[36] Batch [1000]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.094092,	
2017-07-12 22:59:03,174 Epoch[36] Batch [1010]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.094108,	
2017-07-12 22:59:09,028 Epoch[36] Batch [1020]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.094190,	
2017-07-12 22:59:15,226 Epoch[36] Batch [1030]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.094069,	
2017-07-12 22:59:21,515 Epoch[36] Batch [1040]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.094048,	
2017-07-12 22:59:27,737 Epoch[36] Batch [1050]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.094073,	
2017-07-12 22:59:33,838 Epoch[36] Batch [1060]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.094143,	
2017-07-12 22:59:39,616 Epoch[36] Batch [1070]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.094084,	
2017-07-12 22:59:45,561 Epoch[36] Batch [1080]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.094057,	
2017-07-12 22:59:51,980 Epoch[36] Batch [1090]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.094029,	
2017-07-12 22:59:58,220 Epoch[36] Batch [1100]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093852,	
2017-07-12 23:00:04,691 Epoch[36] Batch [1110]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.093796,	
2017-07-12 23:00:10,590 Epoch[36] Batch [1120]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.093780,	
2017-07-12 23:00:16,828 Epoch[36] Batch [1130]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093719,	
2017-07-12 23:00:23,160 Epoch[36] Batch [1140]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.093655,	
2017-07-12 23:00:29,375 Epoch[36] Batch [1150]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.093642,	
2017-07-12 23:00:35,640 Epoch[36] Batch [1160]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.093635,	
2017-07-12 23:00:41,574 Epoch[36] Batch [1170]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.093512,	
2017-07-12 23:00:48,072 Epoch[36] Batch [1180]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.093515,	
2017-07-12 23:00:54,281 Epoch[36] Batch [1190]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.093516,	
2017-07-12 23:01:00,285 Epoch[36] Batch [1200]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.093436,	
2017-07-12 23:01:06,747 Epoch[36] Batch [1210]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.093494,	
2017-07-12 23:01:12,894 Epoch[36] Batch [1220]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.093449,	
2017-07-12 23:01:18,967 Epoch[36] Batch [1230]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093438,	
2017-07-12 23:01:25,334 Epoch[36] Batch [1240]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.093480,	
2017-07-12 23:01:31,649 Epoch[36] Batch [1250]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.093462,	
2017-07-12 23:01:37,911 Epoch[36] Batch [1260]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.093421,	
2017-07-12 23:01:43,852 Epoch[36] Batch [1270]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093345,	
2017-07-12 23:01:50,171 Epoch[36] Batch [1280]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.093336,	
2017-07-12 23:01:56,539 Epoch[36] Batch [1290]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.093342,	
2017-07-12 23:02:02,768 Epoch[36] Batch [1300]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.093273,	
2017-07-12 23:02:08,939 Epoch[36] Batch [1310]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.093258,	
2017-07-12 23:02:14,888 Epoch[36] Batch [1320]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.093250,	
2017-07-12 23:02:20,683 Epoch[36] Batch [1330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093223,	
2017-07-12 23:02:26,797 Epoch[36] Batch [1340]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.093102,	
2017-07-12 23:02:32,731 Epoch[36] Batch [1350]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.093125,	
2017-07-12 23:02:38,785 Epoch[36] Batch [1360]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.093075,	
2017-07-12 23:02:44,961 Epoch[36] Batch [1370]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.093078,	
2017-07-12 23:02:50,758 Epoch[36] Batch [1380]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093075,	
2017-07-12 23:02:56,548 Epoch[36] Batch [1390]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.093160,	
2017-07-12 23:03:02,352 Epoch[36] Batch [1400]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.093192,	
2017-07-12 23:03:08,582 Epoch[36] Batch [1410]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.093170,	
2017-07-12 23:03:14,789 Epoch[36] Batch [1420]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.093138,	
2017-07-12 23:03:21,350 Epoch[36] Batch [1430]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.093136,	
2017-07-12 23:03:27,509 Epoch[36] Batch [1440]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.093172,	
2017-07-12 23:03:33,431 Epoch[36] Batch [1450]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.093168,	
2017-07-12 23:03:39,179 Epoch[36] Batch [1460]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.093141,	
2017-07-12 23:03:45,082 Epoch[36] Batch [1470]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.093110,	
2017-07-12 23:03:51,295 Epoch[36] Batch [1480]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.093042,	
2017-07-12 23:03:55,266 Epoch[36] Train-FCNLogLoss=0.093010
2017-07-12 23:03:55,267 Epoch[36] Time cost=905.254
2017-07-12 23:03:56,483 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0037.params"
2017-07-12 23:04:01,056 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0037.states"
2017-07-12 23:04:08,302 Epoch[37] Batch [10]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.084082,	
2017-07-12 23:04:14,784 Epoch[37] Batch [20]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.085897,	
2017-07-12 23:04:20,986 Epoch[37] Batch [30]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086481,	
2017-07-12 23:04:27,329 Epoch[37] Batch [40]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.087053,	
2017-07-12 23:04:33,477 Epoch[37] Batch [50]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.087678,	
2017-07-12 23:04:39,204 Epoch[37] Batch [60]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086931,	
2017-07-12 23:04:45,325 Epoch[37] Batch [70]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.086422,	
2017-07-12 23:04:51,939 Epoch[37] Batch [80]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.086196,	
2017-07-12 23:04:57,575 Epoch[37] Batch [90]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.087744,	
2017-07-12 23:05:03,368 Epoch[37] Batch [100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087518,	
2017-07-12 23:05:09,308 Epoch[37] Batch [110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087387,	
2017-07-12 23:05:15,220 Epoch[37] Batch [120]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087601,	
2017-07-12 23:05:21,655 Epoch[37] Batch [130]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088086,	
2017-07-12 23:05:27,954 Epoch[37] Batch [140]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.089008,	
2017-07-12 23:05:34,022 Epoch[37] Batch [150]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.088850,	
2017-07-12 23:05:40,206 Epoch[37] Batch [160]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088777,	
2017-07-12 23:05:46,252 Epoch[37] Batch [170]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.088952,	
2017-07-12 23:05:52,669 Epoch[37] Batch [180]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088942,	
2017-07-12 23:05:58,944 Epoch[37] Batch [190]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.088699,	
2017-07-12 23:06:05,216 Epoch[37] Batch [200]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.089273,	
2017-07-12 23:06:11,512 Epoch[37] Batch [210]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.089869,	
2017-07-12 23:06:17,511 Epoch[37] Batch [220]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.089973,	
2017-07-12 23:06:24,375 Epoch[37] Batch [230]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.090126,	
2017-07-12 23:06:30,981 Epoch[37] Batch [240]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.090340,	
2017-07-12 23:06:37,048 Epoch[37] Batch [250]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.090388,	
2017-07-12 23:06:43,640 Epoch[37] Batch [260]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.090535,	
2017-07-12 23:06:49,710 Epoch[37] Batch [270]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.090606,	
2017-07-12 23:06:56,082 Epoch[37] Batch [280]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.090960,	
2017-07-12 23:07:02,010 Epoch[37] Batch [290]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.091143,	
2017-07-12 23:07:08,058 Epoch[37] Batch [300]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.090951,	
2017-07-12 23:07:14,264 Epoch[37] Batch [310]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.090750,	
2017-07-12 23:07:20,487 Epoch[37] Batch [320]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.090760,	
2017-07-12 23:07:26,318 Epoch[37] Batch [330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.090730,	
2017-07-12 23:07:32,799 Epoch[37] Batch [340]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.090774,	
2017-07-12 23:07:38,862 Epoch[37] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.090572,	
2017-07-12 23:07:45,318 Epoch[37] Batch [360]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.090699,	
2017-07-12 23:07:51,779 Epoch[37] Batch [370]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.090725,	
2017-07-12 23:07:58,070 Epoch[37] Batch [380]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.090704,	
2017-07-12 23:08:04,474 Epoch[37] Batch [390]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.090822,	
2017-07-12 23:08:10,747 Epoch[37] Batch [400]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.090838,	
2017-07-12 23:08:17,104 Epoch[37] Batch [410]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.090987,	
2017-07-12 23:08:23,256 Epoch[37] Batch [420]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.090858,	
2017-07-12 23:08:29,811 Epoch[37] Batch [430]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.090776,	
2017-07-12 23:08:35,993 Epoch[37] Batch [440]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.090902,	
2017-07-12 23:08:42,131 Epoch[37] Batch [450]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.090885,	
2017-07-12 23:08:48,626 Epoch[37] Batch [460]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.090828,	
2017-07-12 23:08:54,888 Epoch[37] Batch [470]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.090907,	
2017-07-12 23:09:01,117 Epoch[37] Batch [480]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.090761,	
2017-07-12 23:09:07,367 Epoch[37] Batch [490]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.090629,	
2017-07-12 23:09:13,575 Epoch[37] Batch [500]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.090609,	
2017-07-12 23:09:20,172 Epoch[37] Batch [510]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.090636,	
2017-07-12 23:09:26,138 Epoch[37] Batch [520]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.090722,	
2017-07-12 23:09:32,760 Epoch[37] Batch [530]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.090831,	
2017-07-12 23:09:39,080 Epoch[37] Batch [540]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.090837,	
2017-07-12 23:09:45,491 Epoch[37] Batch [550]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.090951,	
2017-07-12 23:09:51,912 Epoch[37] Batch [560]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.091002,	
2017-07-12 23:09:58,188 Epoch[37] Batch [570]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.091031,	
2017-07-12 23:10:04,648 Epoch[37] Batch [580]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.090939,	
2017-07-12 23:10:10,461 Epoch[37] Batch [590]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.090974,	
2017-07-12 23:10:16,703 Epoch[37] Batch [600]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.090877,	
2017-07-12 23:10:22,881 Epoch[37] Batch [610]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.090873,	
2017-07-12 23:10:29,035 Epoch[37] Batch [620]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.090847,	
2017-07-12 23:10:35,218 Epoch[37] Batch [630]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.090766,	
2017-07-12 23:10:41,721 Epoch[37] Batch [640]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.090763,	
2017-07-12 23:10:47,886 Epoch[37] Batch [650]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.090785,	
2017-07-12 23:10:54,330 Epoch[37] Batch [660]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.090793,	
2017-07-12 23:11:00,047 Epoch[37] Batch [670]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.090893,	
2017-07-12 23:11:06,544 Epoch[37] Batch [680]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.090781,	
2017-07-12 23:11:13,033 Epoch[37] Batch [690]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.090720,	
2017-07-12 23:11:19,138 Epoch[37] Batch [700]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.090854,	
2017-07-12 23:11:25,476 Epoch[37] Batch [710]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.090941,	
2017-07-12 23:11:31,664 Epoch[37] Batch [720]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.090920,	
2017-07-12 23:11:37,985 Epoch[37] Batch [730]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.090883,	
2017-07-12 23:11:44,455 Epoch[37] Batch [740]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.090811,	
2017-07-12 23:11:50,907 Epoch[37] Batch [750]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.090924,	
2017-07-12 23:11:57,133 Epoch[37] Batch [760]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.091083,	
2017-07-12 23:12:03,107 Epoch[37] Batch [770]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.091055,	
2017-07-12 23:12:09,374 Epoch[37] Batch [780]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.091154,	
2017-07-12 23:12:15,700 Epoch[37] Batch [790]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.091109,	
2017-07-12 23:12:22,166 Epoch[37] Batch [800]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.091085,	
2017-07-12 23:12:28,367 Epoch[37] Batch [810]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.091092,	
2017-07-12 23:12:34,363 Epoch[37] Batch [820]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.091124,	
2017-07-12 23:12:40,632 Epoch[37] Batch [830]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.091137,	
2017-07-12 23:12:47,203 Epoch[37] Batch [840]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.091227,	
2017-07-12 23:12:53,687 Epoch[37] Batch [850]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.091221,	
2017-07-12 23:12:59,879 Epoch[37] Batch [860]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.091427,	
2017-07-12 23:13:05,955 Epoch[37] Batch [870]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.091349,	
2017-07-12 23:13:12,551 Epoch[37] Batch [880]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.091278,	
2017-07-12 23:13:18,844 Epoch[37] Batch [890]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.091263,	
2017-07-12 23:13:25,234 Epoch[37] Batch [900]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.091214,	
2017-07-12 23:13:31,412 Epoch[37] Batch [910]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.091230,	
2017-07-12 23:13:37,186 Epoch[37] Batch [920]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.091169,	
2017-07-12 23:13:43,437 Epoch[37] Batch [930]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.091127,	
2017-07-12 23:13:49,561 Epoch[37] Batch [940]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.091145,	
2017-07-12 23:13:56,100 Epoch[37] Batch [950]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.091104,	
2017-07-12 23:14:02,592 Epoch[37] Batch [960]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.091071,	
2017-07-12 23:14:08,766 Epoch[37] Batch [970]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.090956,	
2017-07-12 23:14:15,632 Epoch[37] Batch [980]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.090967,	
2017-07-12 23:14:21,840 Epoch[37] Batch [990]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.091043,	
2017-07-12 23:14:28,144 Epoch[37] Batch [1000]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.091023,	
2017-07-12 23:14:34,616 Epoch[37] Batch [1010]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.090977,	
2017-07-12 23:14:40,862 Epoch[37] Batch [1020]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.090881,	
2017-07-12 23:14:47,525 Epoch[37] Batch [1030]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.090925,	
2017-07-12 23:14:53,535 Epoch[37] Batch [1040]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.090923,	
2017-07-12 23:15:00,141 Epoch[37] Batch [1050]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.091023,	
2017-07-12 23:15:06,178 Epoch[37] Batch [1060]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.091078,	
2017-07-12 23:15:12,526 Epoch[37] Batch [1070]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.091208,	
2017-07-12 23:15:18,550 Epoch[37] Batch [1080]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.091258,	
2017-07-12 23:15:24,524 Epoch[37] Batch [1090]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.091137,	
2017-07-12 23:15:30,753 Epoch[37] Batch [1100]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.091068,	
2017-07-12 23:15:36,700 Epoch[37] Batch [1110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.091086,	
2017-07-12 23:15:42,719 Epoch[37] Batch [1120]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.091157,	
2017-07-12 23:15:49,025 Epoch[37] Batch [1130]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.091061,	
2017-07-12 23:15:55,200 Epoch[37] Batch [1140]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.091134,	
2017-07-12 23:16:01,508 Epoch[37] Batch [1150]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.091098,	
2017-07-12 23:16:07,557 Epoch[37] Batch [1160]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.091107,	
2017-07-12 23:16:13,694 Epoch[37] Batch [1170]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.091139,	
2017-07-12 23:16:20,460 Epoch[37] Batch [1180]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.091143,	
2017-07-12 23:16:26,734 Epoch[37] Batch [1190]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.091139,	
2017-07-12 23:16:33,095 Epoch[37] Batch [1200]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.091098,	
2017-07-12 23:16:39,258 Epoch[37] Batch [1210]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.091198,	
2017-07-12 23:16:45,798 Epoch[37] Batch [1220]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.091205,	
2017-07-12 23:16:51,722 Epoch[37] Batch [1230]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.091242,	
2017-07-12 23:16:58,207 Epoch[37] Batch [1240]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.091201,	
2017-07-12 23:17:04,475 Epoch[37] Batch [1250]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.091238,	
2017-07-12 23:17:10,816 Epoch[37] Batch [1260]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.091307,	
2017-07-12 23:17:17,432 Epoch[37] Batch [1270]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.091264,	
2017-07-12 23:17:23,333 Epoch[37] Batch [1280]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.091247,	
2017-07-12 23:17:29,547 Epoch[37] Batch [1290]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.091299,	
2017-07-12 23:17:35,799 Epoch[37] Batch [1300]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.091330,	
2017-07-12 23:17:42,306 Epoch[37] Batch [1310]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.091327,	
2017-07-12 23:17:48,403 Epoch[37] Batch [1320]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.091276,	
2017-07-12 23:17:54,947 Epoch[37] Batch [1330]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.091327,	
2017-07-12 23:18:00,947 Epoch[37] Batch [1340]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.091385,	
2017-07-12 23:18:07,518 Epoch[37] Batch [1350]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.091251,	
2017-07-12 23:18:13,654 Epoch[37] Batch [1360]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.091201,	
2017-07-12 23:18:19,731 Epoch[37] Batch [1370]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.091169,	
2017-07-12 23:18:26,080 Epoch[37] Batch [1380]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.091141,	
2017-07-12 23:18:32,026 Epoch[37] Batch [1390]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.091171,	
2017-07-12 23:18:38,310 Epoch[37] Batch [1400]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.091095,	
2017-07-12 23:18:44,764 Epoch[37] Batch [1410]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.091054,	
2017-07-12 23:18:50,851 Epoch[37] Batch [1420]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.091050,	
2017-07-12 23:18:57,126 Epoch[37] Batch [1430]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.091029,	
2017-07-12 23:19:03,411 Epoch[37] Batch [1440]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.091025,	
2017-07-12 23:19:10,169 Epoch[37] Batch [1450]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.090900,	
2017-07-12 23:19:16,570 Epoch[37] Batch [1460]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.090853,	
2017-07-12 23:19:22,759 Epoch[37] Batch [1470]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.090879,	
2017-07-12 23:19:28,722 Epoch[37] Batch [1480]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.090882,	
2017-07-12 23:19:32,366 Epoch[37] Train-FCNLogLoss=0.090918
2017-07-12 23:19:32,366 Epoch[37] Time cost=931.310
2017-07-12 23:19:33,580 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0038.params"
2017-07-12 23:19:38,445 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0038.states"
2017-07-12 23:19:46,270 Epoch[38] Batch [10]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.096757,	
2017-07-12 23:19:53,064 Epoch[38] Batch [20]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.094329,	
2017-07-12 23:20:00,060 Epoch[38] Batch [30]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.096524,	
2017-07-12 23:20:06,551 Epoch[38] Batch [40]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.095078,	
2017-07-12 23:20:13,365 Epoch[38] Batch [50]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.093228,	
2017-07-12 23:20:20,052 Epoch[38] Batch [60]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.091224,	
2017-07-12 23:20:26,736 Epoch[38] Batch [70]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.091930,	
2017-07-12 23:20:33,092 Epoch[38] Batch [80]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.091146,	
2017-07-12 23:20:39,893 Epoch[38] Batch [90]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.091588,	
2017-07-12 23:20:46,362 Epoch[38] Batch [100]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.091813,	
2017-07-12 23:20:53,059 Epoch[38] Batch [110]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.091489,	
2017-07-12 23:20:59,889 Epoch[38] Batch [120]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.090891,	
2017-07-12 23:21:06,650 Epoch[38] Batch [130]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.091157,	
2017-07-12 23:21:12,980 Epoch[38] Batch [140]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.091405,	
2017-07-12 23:21:19,571 Epoch[38] Batch [150]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.090921,	
2017-07-12 23:21:25,911 Epoch[38] Batch [160]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.091484,	
2017-07-12 23:21:33,077 Epoch[38] Batch [170]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.090771,	
2017-07-12 23:21:39,362 Epoch[38] Batch [180]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.090618,	
2017-07-12 23:21:46,122 Epoch[38] Batch [190]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.090842,	
2017-07-12 23:21:52,631 Epoch[38] Batch [200]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.090518,	
2017-07-12 23:21:59,683 Epoch[38] Batch [210]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.090629,	
2017-07-12 23:22:06,475 Epoch[38] Batch [220]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.090754,	
2017-07-12 23:22:13,375 Epoch[38] Batch [230]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.091019,	
2017-07-12 23:22:19,490 Epoch[38] Batch [240]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.091004,	
2017-07-12 23:22:25,964 Epoch[38] Batch [250]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.090614,	
2017-07-12 23:22:31,921 Epoch[38] Batch [260]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.090344,	
2017-07-12 23:22:38,250 Epoch[38] Batch [270]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.090305,	
2017-07-12 23:22:44,856 Epoch[38] Batch [280]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.090157,	
2017-07-12 23:22:50,803 Epoch[38] Batch [290]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.089717,	
2017-07-12 23:22:57,384 Epoch[38] Batch [300]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.089361,	
2017-07-12 23:23:03,633 Epoch[38] Batch [310]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.089236,	
2017-07-12 23:23:10,373 Epoch[38] Batch [320]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.089151,	
2017-07-12 23:23:17,261 Epoch[38] Batch [330]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.089132,	
2017-07-12 23:23:23,547 Epoch[38] Batch [340]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.089135,	
2017-07-12 23:23:30,025 Epoch[38] Batch [350]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088892,	
2017-07-12 23:23:36,360 Epoch[38] Batch [360]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088833,	
2017-07-12 23:23:42,792 Epoch[38] Batch [370]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088831,	
2017-07-12 23:23:49,144 Epoch[38] Batch [380]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.088841,	
2017-07-12 23:23:55,631 Epoch[38] Batch [390]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088648,	
2017-07-12 23:24:01,794 Epoch[38] Batch [400]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.088714,	
2017-07-12 23:24:08,149 Epoch[38] Batch [410]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.088914,	
2017-07-12 23:24:14,258 Epoch[38] Batch [420]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.089003,	
2017-07-12 23:24:20,503 Epoch[38] Batch [430]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.089264,	
2017-07-12 23:24:26,851 Epoch[38] Batch [440]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.089290,	
2017-07-12 23:24:33,222 Epoch[38] Batch [450]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.089500,	
2017-07-12 23:24:39,927 Epoch[38] Batch [460]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.089493,	
2017-07-12 23:24:46,262 Epoch[38] Batch [470]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.089709,	
2017-07-12 23:24:52,840 Epoch[38] Batch [480]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.089738,	
2017-07-12 23:24:59,176 Epoch[38] Batch [490]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.089846,	
2017-07-12 23:25:05,672 Epoch[38] Batch [500]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.089843,	
2017-07-12 23:25:12,364 Epoch[38] Batch [510]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.089848,	
2017-07-12 23:25:18,810 Epoch[38] Batch [520]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.089789,	
2017-07-12 23:25:25,017 Epoch[38] Batch [530]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.089755,	
2017-07-12 23:25:31,186 Epoch[38] Batch [540]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.089642,	
2017-07-12 23:25:37,551 Epoch[38] Batch [550]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.089639,	
2017-07-12 23:25:44,101 Epoch[38] Batch [560]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.089575,	
2017-07-12 23:25:50,132 Epoch[38] Batch [570]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.089444,	
2017-07-12 23:25:56,597 Epoch[38] Batch [580]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.089450,	
2017-07-12 23:26:02,742 Epoch[38] Batch [590]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.089532,	
2017-07-12 23:26:09,543 Epoch[38] Batch [600]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.089645,	
2017-07-12 23:26:15,832 Epoch[38] Batch [610]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.089761,	
2017-07-12 23:26:22,511 Epoch[38] Batch [620]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.089782,	
2017-07-12 23:26:28,790 Epoch[38] Batch [630]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.089836,	
2017-07-12 23:26:35,105 Epoch[38] Batch [640]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.089698,	
2017-07-12 23:26:41,462 Epoch[38] Batch [650]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.089734,	
2017-07-12 23:26:47,519 Epoch[38] Batch [660]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.089736,	
2017-07-12 23:26:53,454 Epoch[38] Batch [670]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.089654,	
2017-07-12 23:26:59,910 Epoch[38] Batch [680]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.089644,	
2017-07-12 23:27:06,167 Epoch[38] Batch [690]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.089575,	
2017-07-12 23:27:12,671 Epoch[38] Batch [700]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.089488,	
2017-07-12 23:27:19,031 Epoch[38] Batch [710]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.089370,	
2017-07-12 23:27:25,605 Epoch[38] Batch [720]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.089297,	
2017-07-12 23:27:31,606 Epoch[38] Batch [730]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.089352,	
2017-07-12 23:27:37,727 Epoch[38] Batch [740]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.089395,	
2017-07-12 23:27:44,224 Epoch[38] Batch [750]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.089462,	
2017-07-12 23:27:50,600 Epoch[38] Batch [760]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.089517,	
2017-07-12 23:27:57,257 Epoch[38] Batch [770]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.089537,	
2017-07-12 23:28:03,671 Epoch[38] Batch [780]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.089551,	
2017-07-12 23:28:10,209 Epoch[38] Batch [790]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.089441,	
2017-07-12 23:28:16,307 Epoch[38] Batch [800]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.089433,	
2017-07-12 23:28:22,147 Epoch[38] Batch [810]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.089421,	
2017-07-12 23:28:27,892 Epoch[38] Batch [820]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.089369,	
2017-07-12 23:28:33,971 Epoch[38] Batch [830]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.089350,	
2017-07-12 23:28:39,731 Epoch[38] Batch [840]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.089296,	
2017-07-12 23:28:45,755 Epoch[38] Batch [850]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.089287,	
2017-07-12 23:28:51,795 Epoch[38] Batch [860]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.089276,	
2017-07-12 23:28:57,546 Epoch[38] Batch [870]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.089228,	
2017-07-12 23:29:03,395 Epoch[38] Batch [880]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.089477,	
2017-07-12 23:29:09,535 Epoch[38] Batch [890]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.089506,	
2017-07-12 23:29:15,273 Epoch[38] Batch [900]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.089581,	
2017-07-12 23:29:21,031 Epoch[38] Batch [910]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.089566,	
2017-07-12 23:29:27,062 Epoch[38] Batch [920]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.089545,	
2017-07-12 23:29:32,842 Epoch[38] Batch [930]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.089588,	
2017-07-12 23:29:38,766 Epoch[38] Batch [940]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.089569,	
2017-07-12 23:29:44,620 Epoch[38] Batch [950]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.089696,	
2017-07-12 23:29:50,381 Epoch[38] Batch [960]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.089619,	
2017-07-12 23:29:56,146 Epoch[38] Batch [970]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.089578,	
2017-07-12 23:30:01,999 Epoch[38] Batch [980]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.089572,	
2017-07-12 23:30:07,747 Epoch[38] Batch [990]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.089569,	
2017-07-12 23:30:13,913 Epoch[38] Batch [1000]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.089635,	
2017-07-12 23:30:20,032 Epoch[38] Batch [1010]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.089662,	
2017-07-12 23:30:26,181 Epoch[38] Batch [1020]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.089721,	
2017-07-12 23:30:32,231 Epoch[38] Batch [1030]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.089809,	
2017-07-12 23:30:38,275 Epoch[38] Batch [1040]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.089845,	
2017-07-12 23:30:44,221 Epoch[38] Batch [1050]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.089835,	
2017-07-12 23:30:50,223 Epoch[38] Batch [1060]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.089820,	
2017-07-12 23:30:56,461 Epoch[38] Batch [1070]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.089872,	
2017-07-12 23:31:02,665 Epoch[38] Batch [1080]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.089820,	
2017-07-12 23:31:09,174 Epoch[38] Batch [1090]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.089743,	
2017-07-12 23:31:15,384 Epoch[38] Batch [1100]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.089779,	
2017-07-12 23:31:21,212 Epoch[38] Batch [1110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.089785,	
2017-07-12 23:31:27,254 Epoch[38] Batch [1120]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.089842,	
2017-07-12 23:31:33,106 Epoch[38] Batch [1130]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.089896,	
2017-07-12 23:31:39,116 Epoch[38] Batch [1140]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.089919,	
2017-07-12 23:31:45,189 Epoch[38] Batch [1150]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.090046,	
2017-07-12 23:31:51,376 Epoch[38] Batch [1160]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.090013,	
2017-07-12 23:31:57,235 Epoch[38] Batch [1170]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.090050,	
2017-07-12 23:32:03,334 Epoch[38] Batch [1180]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.089984,	
2017-07-12 23:32:09,445 Epoch[38] Batch [1190]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.090016,	
2017-07-12 23:32:15,236 Epoch[38] Batch [1200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.089993,	
2017-07-12 23:32:20,847 Epoch[38] Batch [1210]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.090005,	
2017-07-12 23:32:26,791 Epoch[38] Batch [1220]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.090119,	
2017-07-12 23:32:32,368 Epoch[38] Batch [1230]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.090166,	
2017-07-12 23:32:38,458 Epoch[38] Batch [1240]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.090203,	
2017-07-12 23:32:44,255 Epoch[38] Batch [1250]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.090199,	
2017-07-12 23:32:50,348 Epoch[38] Batch [1260]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.090254,	
2017-07-12 23:32:56,527 Epoch[38] Batch [1270]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.090242,	
2017-07-12 23:33:02,391 Epoch[38] Batch [1280]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.090275,	
2017-07-12 23:33:08,512 Epoch[38] Batch [1290]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.090264,	
2017-07-12 23:33:14,566 Epoch[38] Batch [1300]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.090337,	
2017-07-12 23:33:20,875 Epoch[38] Batch [1310]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.090428,	
2017-07-12 23:33:26,802 Epoch[38] Batch [1320]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.090413,	
2017-07-12 23:33:32,659 Epoch[38] Batch [1330]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.090418,	
2017-07-12 23:33:38,637 Epoch[38] Batch [1340]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.090409,	
2017-07-12 23:33:44,461 Epoch[38] Batch [1350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.090410,	
2017-07-12 23:33:50,530 Epoch[38] Batch [1360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.090429,	
2017-07-12 23:33:56,521 Epoch[38] Batch [1370]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.090477,	
2017-07-12 23:34:02,629 Epoch[38] Batch [1380]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.090488,	
2017-07-12 23:34:08,675 Epoch[38] Batch [1390]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.090481,	
2017-07-12 23:34:14,589 Epoch[38] Batch [1400]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.090538,	
2017-07-12 23:34:20,363 Epoch[38] Batch [1410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.090553,	
2017-07-12 23:34:26,328 Epoch[38] Batch [1420]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.090545,	
2017-07-12 23:34:32,146 Epoch[38] Batch [1430]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.090591,	
2017-07-12 23:34:38,237 Epoch[38] Batch [1440]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.090595,	
2017-07-12 23:34:44,279 Epoch[38] Batch [1450]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.090565,	
2017-07-12 23:34:50,470 Epoch[38] Batch [1460]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.090590,	
2017-07-12 23:34:56,650 Epoch[38] Batch [1470]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.090580,	
2017-07-12 23:35:02,687 Epoch[38] Batch [1480]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.090548,	
2017-07-12 23:35:06,337 Epoch[38] Train-FCNLogLoss=0.090569
2017-07-12 23:35:06,338 Epoch[38] Time cost=927.892
2017-07-12 23:35:07,210 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0039.params"
2017-07-12 23:35:11,773 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0039.states"
2017-07-12 23:35:18,420 Epoch[39] Batch [10]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.089905,	
2017-07-12 23:35:24,375 Epoch[39] Batch [20]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.091053,	
2017-07-12 23:35:30,350 Epoch[39] Batch [30]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.090661,	
2017-07-12 23:35:36,452 Epoch[39] Batch [40]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.091819,	
2017-07-12 23:35:42,358 Epoch[39] Batch [50]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.090102,	
2017-07-12 23:35:48,354 Epoch[39] Batch [60]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.089720,	
2017-07-12 23:35:54,313 Epoch[39] Batch [70]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.090099,	
2017-07-12 23:36:00,112 Epoch[39] Batch [80]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.090762,	
2017-07-12 23:36:05,510 Epoch[39] Batch [90]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090086,	
2017-07-12 23:36:11,395 Epoch[39] Batch [100]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.089663,	
2017-07-12 23:36:17,337 Epoch[39] Batch [110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.089826,	
2017-07-12 23:36:23,635 Epoch[39] Batch [120]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.090883,	
2017-07-12 23:36:30,212 Epoch[39] Batch [130]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.091212,	
2017-07-12 23:36:36,349 Epoch[39] Batch [140]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.090308,	
2017-07-12 23:36:42,912 Epoch[39] Batch [150]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.089983,	
2017-07-12 23:36:49,151 Epoch[39] Batch [160]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.090424,	
2017-07-12 23:36:55,287 Epoch[39] Batch [170]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.090315,	
2017-07-12 23:37:01,633 Epoch[39] Batch [180]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.089860,	
2017-07-12 23:37:08,173 Epoch[39] Batch [190]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.089609,	
2017-07-12 23:37:14,693 Epoch[39] Batch [200]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.089786,	
2017-07-12 23:37:21,207 Epoch[39] Batch [210]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.089844,	
2017-07-12 23:37:27,761 Epoch[39] Batch [220]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.089577,	
2017-07-12 23:37:34,332 Epoch[39] Batch [230]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.089234,	
2017-07-12 23:37:40,604 Epoch[39] Batch [240]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.089300,	
2017-07-12 23:37:47,295 Epoch[39] Batch [250]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088933,	
2017-07-12 23:37:53,788 Epoch[39] Batch [260]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088942,	
2017-07-12 23:38:00,595 Epoch[39] Batch [270]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.088277,	
2017-07-12 23:38:07,521 Epoch[39] Batch [280]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088547,	
2017-07-12 23:38:13,964 Epoch[39] Batch [290]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.088545,	
2017-07-12 23:38:20,304 Epoch[39] Batch [300]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088474,	
2017-07-12 23:38:26,388 Epoch[39] Batch [310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.088672,	
2017-07-12 23:38:32,920 Epoch[39] Batch [320]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.088566,	
2017-07-12 23:38:39,325 Epoch[39] Batch [330]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.088810,	
2017-07-12 23:38:45,865 Epoch[39] Batch [340]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.088909,	
2017-07-12 23:38:52,216 Epoch[39] Batch [350]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.089104,	
2017-07-12 23:38:59,012 Epoch[39] Batch [360]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.088834,	
2017-07-12 23:39:05,438 Epoch[39] Batch [370]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088755,	
2017-07-12 23:39:11,768 Epoch[39] Batch [380]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088747,	
2017-07-12 23:39:18,523 Epoch[39] Batch [390]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.088834,	
2017-07-12 23:39:24,894 Epoch[39] Batch [400]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.088941,	
2017-07-12 23:39:31,548 Epoch[39] Batch [410]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.089106,	
2017-07-12 23:39:37,866 Epoch[39] Batch [420]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.089180,	
2017-07-12 23:39:44,278 Epoch[39] Batch [430]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.089081,	
2017-07-12 23:39:50,633 Epoch[39] Batch [440]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.089022,	
2017-07-12 23:39:56,522 Epoch[39] Batch [450]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088983,	
2017-07-12 23:40:02,312 Epoch[39] Batch [460]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.089161,	
2017-07-12 23:40:08,227 Epoch[39] Batch [470]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.089168,	
2017-07-12 23:40:14,456 Epoch[39] Batch [480]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.089218,	
2017-07-12 23:40:20,979 Epoch[39] Batch [490]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.089434,	
2017-07-12 23:40:27,518 Epoch[39] Batch [500]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.089486,	
2017-07-12 23:40:33,755 Epoch[39] Batch [510]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.089258,	
2017-07-12 23:40:40,260 Epoch[39] Batch [520]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.089333,	
2017-07-12 23:40:46,111 Epoch[39] Batch [530]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.089377,	
2017-07-12 23:40:52,458 Epoch[39] Batch [540]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.089402,	
2017-07-12 23:40:58,248 Epoch[39] Batch [550]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.089414,	
2017-07-12 23:41:04,385 Epoch[39] Batch [560]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.089376,	
2017-07-12 23:41:11,152 Epoch[39] Batch [570]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.089623,	
2017-07-12 23:41:17,590 Epoch[39] Batch [580]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.089841,	
2017-07-12 23:41:23,828 Epoch[39] Batch [590]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.089943,	
2017-07-12 23:41:30,061 Epoch[39] Batch [600]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.090304,	
2017-07-12 23:41:36,295 Epoch[39] Batch [610]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.091302,	
2017-07-12 23:41:43,001 Epoch[39] Batch [620]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.092105,	
2017-07-12 23:41:48,891 Epoch[39] Batch [630]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.093083,	
2017-07-12 23:41:55,135 Epoch[39] Batch [640]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.093746,	
2017-07-12 23:42:01,652 Epoch[39] Batch [650]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.094465,	
2017-07-12 23:42:07,760 Epoch[39] Batch [660]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.095541,	
2017-07-12 23:42:14,290 Epoch[39] Batch [670]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.096278,	
2017-07-12 23:42:20,776 Epoch[39] Batch [680]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.096710,	
2017-07-12 23:42:27,213 Epoch[39] Batch [690]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.097291,	
2017-07-12 23:42:34,080 Epoch[39] Batch [700]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.097586,	
2017-07-12 23:42:40,010 Epoch[39] Batch [710]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.097711,	
2017-07-12 23:42:46,361 Epoch[39] Batch [720]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.097868,	
2017-07-12 23:42:52,650 Epoch[39] Batch [730]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.097915,	
2017-07-12 23:42:59,085 Epoch[39] Batch [740]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.097906,	
2017-07-12 23:43:05,225 Epoch[39] Batch [750]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.097880,	
2017-07-12 23:43:11,469 Epoch[39] Batch [760]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.097868,	
2017-07-12 23:43:18,074 Epoch[39] Batch [770]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.097693,	
2017-07-12 23:43:24,585 Epoch[39] Batch [780]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.097691,	
2017-07-12 23:43:31,191 Epoch[39] Batch [790]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.097726,	
2017-07-12 23:43:37,722 Epoch[39] Batch [800]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.097697,	
2017-07-12 23:43:44,097 Epoch[39] Batch [810]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.097653,	
2017-07-12 23:43:50,842 Epoch[39] Batch [820]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.097699,	
2017-07-12 23:43:57,437 Epoch[39] Batch [830]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.097708,	
2017-07-12 23:44:04,248 Epoch[39] Batch [840]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.097640,	
2017-07-12 23:44:10,555 Epoch[39] Batch [850]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.097587,	
2017-07-12 23:44:16,855 Epoch[39] Batch [860]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.097683,	
2017-07-12 23:44:23,530 Epoch[39] Batch [870]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.097580,	
2017-07-12 23:44:30,137 Epoch[39] Batch [880]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.097549,	
2017-07-12 23:44:36,642 Epoch[39] Batch [890]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.097646,	
2017-07-12 23:44:42,799 Epoch[39] Batch [900]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.097785,	
2017-07-12 23:44:49,591 Epoch[39] Batch [910]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.097889,	
2017-07-12 23:44:55,714 Epoch[39] Batch [920]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.097780,	
2017-07-12 23:45:01,986 Epoch[39] Batch [930]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.097756,	
2017-07-12 23:45:08,486 Epoch[39] Batch [940]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.097793,	
2017-07-12 23:45:14,684 Epoch[39] Batch [950]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.097784,	
2017-07-12 23:45:21,417 Epoch[39] Batch [960]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.097725,	
2017-07-12 23:45:27,702 Epoch[39] Batch [970]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.097703,	
2017-07-12 23:45:34,254 Epoch[39] Batch [980]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.097763,	
2017-07-12 23:45:40,465 Epoch[39] Batch [990]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.097650,	
2017-07-12 23:45:46,594 Epoch[39] Batch [1000]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.097547,	
2017-07-12 23:45:52,942 Epoch[39] Batch [1010]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.097400,	
2017-07-12 23:45:58,978 Epoch[39] Batch [1020]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.097368,	
2017-07-12 23:46:04,986 Epoch[39] Batch [1030]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.097279,	
2017-07-12 23:46:11,628 Epoch[39] Batch [1040]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.097200,	
2017-07-12 23:46:17,735 Epoch[39] Batch [1050]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.097068,	
2017-07-12 23:46:23,791 Epoch[39] Batch [1060]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.096924,	
2017-07-12 23:46:30,086 Epoch[39] Batch [1070]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.096896,	
2017-07-12 23:46:36,214 Epoch[39] Batch [1080]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.096818,	
2017-07-12 23:46:42,795 Epoch[39] Batch [1090]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.096748,	
2017-07-12 23:46:49,206 Epoch[39] Batch [1100]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.096744,	
2017-07-12 23:46:55,523 Epoch[39] Batch [1110]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.096697,	
2017-07-12 23:47:01,837 Epoch[39] Batch [1120]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.096615,	
2017-07-12 23:47:08,266 Epoch[39] Batch [1130]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.096573,	
2017-07-12 23:47:14,320 Epoch[39] Batch [1140]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.096628,	
2017-07-12 23:47:20,640 Epoch[39] Batch [1150]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.096748,	
2017-07-12 23:47:27,392 Epoch[39] Batch [1160]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.096665,	
2017-07-12 23:47:33,468 Epoch[39] Batch [1170]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.096616,	
2017-07-12 23:47:40,458 Epoch[39] Batch [1180]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.096473,	
2017-07-12 23:47:46,912 Epoch[39] Batch [1190]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.096476,	
2017-07-12 23:47:53,206 Epoch[39] Batch [1200]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.096477,	
2017-07-12 23:47:59,833 Epoch[39] Batch [1210]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.096422,	
2017-07-12 23:48:06,192 Epoch[39] Batch [1220]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.096419,	
2017-07-12 23:48:12,830 Epoch[39] Batch [1230]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.096355,	
2017-07-12 23:48:19,310 Epoch[39] Batch [1240]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.096364,	
2017-07-12 23:48:25,809 Epoch[39] Batch [1250]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.096332,	
2017-07-12 23:48:32,577 Epoch[39] Batch [1260]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.096330,	
2017-07-12 23:48:39,055 Epoch[39] Batch [1270]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.096310,	
2017-07-12 23:48:45,484 Epoch[39] Batch [1280]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.096243,	
2017-07-12 23:48:51,821 Epoch[39] Batch [1290]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.096233,	
2017-07-12 23:48:58,451 Epoch[39] Batch [1300]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.096202,	
2017-07-12 23:49:04,815 Epoch[39] Batch [1310]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.096183,	
2017-07-12 23:49:11,215 Epoch[39] Batch [1320]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.096167,	
2017-07-12 23:49:17,008 Epoch[39] Batch [1330]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.096146,	
2017-07-12 23:49:23,067 Epoch[39] Batch [1340]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.096136,	
2017-07-12 23:49:29,393 Epoch[39] Batch [1350]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.096019,	
2017-07-12 23:49:35,500 Epoch[39] Batch [1360]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.095901,	
2017-07-12 23:49:42,126 Epoch[39] Batch [1370]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.095843,	
2017-07-12 23:49:48,648 Epoch[39] Batch [1380]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.095832,	
2017-07-12 23:49:55,502 Epoch[39] Batch [1390]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.095809,	
2017-07-12 23:50:02,103 Epoch[39] Batch [1400]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.095777,	
2017-07-12 23:50:08,583 Epoch[39] Batch [1410]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.095771,	
2017-07-12 23:50:14,986 Epoch[39] Batch [1420]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.095704,	
2017-07-12 23:50:21,798 Epoch[39] Batch [1430]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.095626,	
2017-07-12 23:50:28,538 Epoch[39] Batch [1440]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.095574,	
2017-07-12 23:50:35,265 Epoch[39] Batch [1450]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.095535,	
2017-07-12 23:50:41,792 Epoch[39] Batch [1460]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.095526,	
2017-07-12 23:50:48,050 Epoch[39] Batch [1470]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.095483,	
2017-07-12 23:50:54,388 Epoch[39] Batch [1480]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.095492,	
2017-07-12 23:50:58,291 Epoch[39] Train-FCNLogLoss=0.095428
2017-07-12 23:50:58,291 Epoch[39] Time cost=946.518
2017-07-12 23:50:59,137 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0040.params"
2017-07-12 23:51:03,625 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0040.states"
2017-07-12 23:51:11,035 Epoch[40] Batch [10]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.088489,	
2017-07-12 23:51:17,514 Epoch[40] Batch [20]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088650,	
2017-07-12 23:51:24,087 Epoch[40] Batch [30]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.085718,	
2017-07-12 23:51:30,686 Epoch[40] Batch [40]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.083785,	
2017-07-12 23:51:37,047 Epoch[40] Batch [50]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.085715,	
2017-07-12 23:51:43,066 Epoch[40] Batch [60]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.086340,	
2017-07-12 23:51:49,363 Epoch[40] Batch [70]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.085394,	
2017-07-12 23:51:55,793 Epoch[40] Batch [80]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.085788,	
2017-07-12 23:52:02,285 Epoch[40] Batch [90]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.086215,	
2017-07-12 23:52:08,683 Epoch[40] Batch [100]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087257,	
2017-07-12 23:52:14,807 Epoch[40] Batch [110]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.087669,	
2017-07-12 23:52:21,613 Epoch[40] Batch [120]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.087087,	
2017-07-12 23:52:27,801 Epoch[40] Batch [130]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088047,	
2017-07-12 23:52:34,210 Epoch[40] Batch [140]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088518,	
2017-07-12 23:52:40,467 Epoch[40] Batch [150]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088645,	
2017-07-12 23:52:46,935 Epoch[40] Batch [160]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088856,	
2017-07-12 23:52:53,140 Epoch[40] Batch [170]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.088490,	
2017-07-12 23:52:59,520 Epoch[40] Batch [180]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088281,	
2017-07-12 23:53:05,911 Epoch[40] Batch [190]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.089877,	
2017-07-12 23:53:12,491 Epoch[40] Batch [200]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.091448,	
2017-07-12 23:53:18,978 Epoch[40] Batch [210]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.092130,	
2017-07-12 23:53:25,723 Epoch[40] Batch [220]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.093009,	
2017-07-12 23:53:31,882 Epoch[40] Batch [230]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.093708,	
2017-07-12 23:53:38,393 Epoch[40] Batch [240]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.093614,	
2017-07-12 23:53:44,804 Epoch[40] Batch [250]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.093271,	
2017-07-12 23:53:51,164 Epoch[40] Batch [260]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.093670,	
2017-07-12 23:53:57,722 Epoch[40] Batch [270]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.093676,	
2017-07-12 23:54:04,298 Epoch[40] Batch [280]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.093630,	
2017-07-12 23:54:10,834 Epoch[40] Batch [290]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.093505,	
2017-07-12 23:54:17,479 Epoch[40] Batch [300]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.093487,	
2017-07-12 23:54:23,601 Epoch[40] Batch [310]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093340,	
2017-07-12 23:54:30,172 Epoch[40] Batch [320]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.092930,	
2017-07-12 23:54:36,726 Epoch[40] Batch [330]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.092722,	
2017-07-12 23:54:42,908 Epoch[40] Batch [340]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.092717,	
2017-07-12 23:54:49,379 Epoch[40] Batch [350]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.092636,	
2017-07-12 23:54:55,537 Epoch[40] Batch [360]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.092769,	
2017-07-12 23:55:01,850 Epoch[40] Batch [370]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.092805,	
2017-07-12 23:55:08,173 Epoch[40] Batch [380]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.092676,	
2017-07-12 23:55:14,548 Epoch[40] Batch [390]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.092770,	
2017-07-12 23:55:21,178 Epoch[40] Batch [400]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.092660,	
2017-07-12 23:55:27,392 Epoch[40] Batch [410]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.092569,	
2017-07-12 23:55:33,897 Epoch[40] Batch [420]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.092423,	
2017-07-12 23:55:40,841 Epoch[40] Batch [430]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.092176,	
2017-07-12 23:55:47,164 Epoch[40] Batch [440]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.092142,	
2017-07-12 23:55:53,839 Epoch[40] Batch [450]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.092151,	
2017-07-12 23:56:00,173 Epoch[40] Batch [460]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.092363,	
2017-07-12 23:56:06,686 Epoch[40] Batch [470]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.092267,	
2017-07-12 23:56:13,068 Epoch[40] Batch [480]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.092455,	
2017-07-12 23:56:19,402 Epoch[40] Batch [490]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.092616,	
2017-07-12 23:56:25,905 Epoch[40] Batch [500]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.092589,	
2017-07-12 23:56:32,339 Epoch[40] Batch [510]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.092515,	
2017-07-12 23:56:38,862 Epoch[40] Batch [520]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.092511,	
2017-07-12 23:56:45,504 Epoch[40] Batch [530]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.092440,	
2017-07-12 23:56:52,103 Epoch[40] Batch [540]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.092467,	
2017-07-12 23:56:58,452 Epoch[40] Batch [550]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.092694,	
2017-07-12 23:57:04,529 Epoch[40] Batch [560]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.092737,	
2017-07-12 23:57:10,731 Epoch[40] Batch [570]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.092698,	
2017-07-12 23:57:16,794 Epoch[40] Batch [580]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.092602,	
2017-07-12 23:57:23,546 Epoch[40] Batch [590]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.092353,	
2017-07-12 23:57:30,115 Epoch[40] Batch [600]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.092375,	
2017-07-12 23:57:36,410 Epoch[40] Batch [610]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.092420,	
2017-07-12 23:57:42,711 Epoch[40] Batch [620]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.092326,	
2017-07-12 23:57:48,595 Epoch[40] Batch [630]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.092187,	
2017-07-12 23:57:54,549 Epoch[40] Batch [640]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.092183,	
2017-07-12 23:58:00,322 Epoch[40] Batch [650]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.092057,	
2017-07-12 23:58:07,227 Epoch[40] Batch [660]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.092026,	
2017-07-12 23:58:13,664 Epoch[40] Batch [670]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.091918,	
2017-07-12 23:58:20,314 Epoch[40] Batch [680]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.091778,	
2017-07-12 23:58:26,498 Epoch[40] Batch [690]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.091732,	
2017-07-12 23:58:33,173 Epoch[40] Batch [700]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.091812,	
2017-07-12 23:58:39,375 Epoch[40] Batch [710]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.091760,	
2017-07-12 23:58:45,877 Epoch[40] Batch [720]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.091746,	
2017-07-12 23:58:52,535 Epoch[40] Batch [730]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.091765,	
2017-07-12 23:58:58,857 Epoch[40] Batch [740]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.091797,	
2017-07-12 23:59:05,531 Epoch[40] Batch [750]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.091860,	
2017-07-12 23:59:11,881 Epoch[40] Batch [760]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.091824,	
2017-07-12 23:59:18,421 Epoch[40] Batch [770]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.091799,	
2017-07-12 23:59:24,876 Epoch[40] Batch [780]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.091885,	
2017-07-12 23:59:30,823 Epoch[40] Batch [790]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.091905,	
2017-07-12 23:59:37,281 Epoch[40] Batch [800]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.091891,	
2017-07-12 23:59:43,775 Epoch[40] Batch [810]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.091892,	
2017-07-12 23:59:50,243 Epoch[40] Batch [820]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.091929,	
2017-07-12 23:59:56,823 Epoch[40] Batch [830]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.091967,	
2017-07-13 00:00:03,253 Epoch[40] Batch [840]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.091832,	
2017-07-13 00:00:10,057 Epoch[40] Batch [850]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.091821,	
2017-07-13 00:00:16,349 Epoch[40] Batch [860]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.091865,	
2017-07-13 00:00:23,305 Epoch[40] Batch [870]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.091797,	
2017-07-13 00:00:29,444 Epoch[40] Batch [880]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.091740,	
2017-07-13 00:00:35,753 Epoch[40] Batch [890]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.091657,	
2017-07-13 00:00:42,282 Epoch[40] Batch [900]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.091710,	
2017-07-13 00:00:48,776 Epoch[40] Batch [910]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.091583,	
2017-07-13 00:00:55,464 Epoch[40] Batch [920]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.091551,	
2017-07-13 00:01:01,740 Epoch[40] Batch [930]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.091605,	
2017-07-13 00:01:08,164 Epoch[40] Batch [940]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.091511,	
2017-07-13 00:01:14,596 Epoch[40] Batch [950]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.091549,	
2017-07-13 00:01:21,127 Epoch[40] Batch [960]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.091512,	
2017-07-13 00:01:27,289 Epoch[40] Batch [970]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.091548,	
2017-07-13 00:01:33,739 Epoch[40] Batch [980]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.091503,	
2017-07-13 00:01:40,354 Epoch[40] Batch [990]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.091446,	
2017-07-13 00:01:46,852 Epoch[40] Batch [1000]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.091497,	
2017-07-13 00:01:53,295 Epoch[40] Batch [1010]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.091410,	
2017-07-13 00:01:59,709 Epoch[40] Batch [1020]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.091356,	
2017-07-13 00:02:06,031 Epoch[40] Batch [1030]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.091323,	
2017-07-13 00:02:12,500 Epoch[40] Batch [1040]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.091317,	
2017-07-13 00:02:18,753 Epoch[40] Batch [1050]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.091320,	
2017-07-13 00:02:25,318 Epoch[40] Batch [1060]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.091360,	
2017-07-13 00:02:31,528 Epoch[40] Batch [1070]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.091351,	
2017-07-13 00:02:37,953 Epoch[40] Batch [1080]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.091472,	
2017-07-13 00:02:44,645 Epoch[40] Batch [1090]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.091486,	
2017-07-13 00:02:50,721 Epoch[40] Batch [1100]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.091636,	
2017-07-13 00:02:57,846 Epoch[40] Batch [1110]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.091624,	
2017-07-13 00:03:04,295 Epoch[40] Batch [1120]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.091624,	
2017-07-13 00:03:10,755 Epoch[40] Batch [1130]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.091611,	
2017-07-13 00:03:17,378 Epoch[40] Batch [1140]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.091558,	
2017-07-13 00:03:24,552 Epoch[40] Batch [1150]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.091551,	
2017-07-13 00:03:30,987 Epoch[40] Batch [1160]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.091571,	
2017-07-13 00:03:37,296 Epoch[40] Batch [1170]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.091571,	
2017-07-13 00:03:43,674 Epoch[40] Batch [1180]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.091690,	
2017-07-13 00:03:50,019 Epoch[40] Batch [1190]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.091751,	
2017-07-13 00:03:56,367 Epoch[40] Batch [1200]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.091772,	
2017-07-13 00:04:03,339 Epoch[40] Batch [1210]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.091765,	
2017-07-13 00:04:10,244 Epoch[40] Batch [1220]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.091704,	
2017-07-13 00:04:16,326 Epoch[40] Batch [1230]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.091673,	
2017-07-13 00:04:23,067 Epoch[40] Batch [1240]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.091629,	
2017-07-13 00:04:29,442 Epoch[40] Batch [1250]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.091560,	
2017-07-13 00:04:36,313 Epoch[40] Batch [1260]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.091619,	
2017-07-13 00:04:44,114 Epoch[40] Batch [1270]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.091732,	
2017-07-13 00:04:51,551 Epoch[40] Batch [1280]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.091692,	
2017-07-13 00:04:58,953 Epoch[40] Batch [1290]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.091711,	
2017-07-13 00:05:05,753 Epoch[40] Batch [1300]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.091736,	
2017-07-13 00:05:12,745 Epoch[40] Batch [1310]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.091720,	
2017-07-13 00:05:19,670 Epoch[40] Batch [1320]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.091738,	
2017-07-13 00:05:26,378 Epoch[40] Batch [1330]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.091815,	
2017-07-13 00:05:32,868 Epoch[40] Batch [1340]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.091776,	
2017-07-13 00:05:39,474 Epoch[40] Batch [1350]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.091814,	
2017-07-13 00:05:46,477 Epoch[40] Batch [1360]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.091821,	
2017-07-13 00:05:53,203 Epoch[40] Batch [1370]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.091803,	
2017-07-13 00:05:59,507 Epoch[40] Batch [1380]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.091857,	
2017-07-13 00:06:05,983 Epoch[40] Batch [1390]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.091841,	
2017-07-13 00:06:12,172 Epoch[40] Batch [1400]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.091770,	
2017-07-13 00:06:18,393 Epoch[40] Batch [1410]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.091734,	
2017-07-13 00:06:24,510 Epoch[40] Batch [1420]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.091790,	
2017-07-13 00:06:30,865 Epoch[40] Batch [1430]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.091795,	
2017-07-13 00:06:37,404 Epoch[40] Batch [1440]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.091702,	
2017-07-13 00:06:43,957 Epoch[40] Batch [1450]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.091713,	
2017-07-13 00:06:50,665 Epoch[40] Batch [1460]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.091666,	
2017-07-13 00:06:56,701 Epoch[40] Batch [1470]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.091617,	
2017-07-13 00:07:03,508 Epoch[40] Batch [1480]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.091599,	
2017-07-13 00:07:07,126 Epoch[40] Train-FCNLogLoss=0.091568
2017-07-13 00:07:07,126 Epoch[40] Time cost=963.500
2017-07-13 00:07:08,132 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0041.params"
2017-07-13 00:07:13,092 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0041.states"
2017-07-13 00:07:21,015 Epoch[41] Batch [10]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.089331,	
2017-07-13 00:07:27,738 Epoch[41] Batch [20]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.089044,	
2017-07-13 00:07:34,376 Epoch[41] Batch [30]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.090954,	
2017-07-13 00:07:41,405 Epoch[41] Batch [40]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088957,	
2017-07-13 00:07:48,473 Epoch[41] Batch [50]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088696,	
2017-07-13 00:07:55,359 Epoch[41] Batch [60]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.088974,	
2017-07-13 00:08:01,997 Epoch[41] Batch [70]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.090711,	
2017-07-13 00:08:08,460 Epoch[41] Batch [80]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.091511,	
2017-07-13 00:08:15,873 Epoch[41] Batch [90]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.090973,	
2017-07-13 00:08:22,237 Epoch[41] Batch [100]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.090990,	
2017-07-13 00:08:28,754 Epoch[41] Batch [110]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.091230,	
2017-07-13 00:08:35,138 Epoch[41] Batch [120]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.090519,	
2017-07-13 00:08:41,599 Epoch[41] Batch [130]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.090705,	
2017-07-13 00:08:48,340 Epoch[41] Batch [140]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.090404,	
2017-07-13 00:08:54,635 Epoch[41] Batch [150]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.090433,	
2017-07-13 00:09:01,241 Epoch[41] Batch [160]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.090110,	
2017-07-13 00:09:07,680 Epoch[41] Batch [170]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.089557,	
2017-07-13 00:09:14,450 Epoch[41] Batch [180]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.089673,	
2017-07-13 00:09:21,189 Epoch[41] Batch [190]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.089432,	
2017-07-13 00:09:27,739 Epoch[41] Batch [200]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.089227,	
2017-07-13 00:09:34,401 Epoch[41] Batch [210]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.089088,	
2017-07-13 00:09:40,952 Epoch[41] Batch [220]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088887,	
2017-07-13 00:09:48,049 Epoch[41] Batch [230]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088390,	
2017-07-13 00:09:54,448 Epoch[41] Batch [240]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.088564,	
2017-07-13 00:10:01,163 Epoch[41] Batch [250]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.088142,	
2017-07-13 00:10:07,803 Epoch[41] Batch [260]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087819,	
2017-07-13 00:10:14,469 Epoch[41] Batch [270]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.088032,	
2017-07-13 00:10:21,157 Epoch[41] Batch [280]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088063,	
2017-07-13 00:10:27,805 Epoch[41] Batch [290]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087989,	
2017-07-13 00:10:34,520 Epoch[41] Batch [300]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.087668,	
2017-07-13 00:10:41,246 Epoch[41] Batch [310]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.087729,	
2017-07-13 00:10:47,954 Epoch[41] Batch [320]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.087700,	
2017-07-13 00:10:54,707 Epoch[41] Batch [330]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.087580,	
2017-07-13 00:11:01,562 Epoch[41] Batch [340]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087911,	
2017-07-13 00:11:08,225 Epoch[41] Batch [350]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.087810,	
2017-07-13 00:11:15,001 Epoch[41] Batch [360]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.087786,	
2017-07-13 00:11:22,065 Epoch[41] Batch [370]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087806,	
2017-07-13 00:11:28,722 Epoch[41] Batch [380]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087928,	
2017-07-13 00:11:35,529 Epoch[41] Batch [390]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.088308,	
2017-07-13 00:11:42,179 Epoch[41] Batch [400]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.088278,	
2017-07-13 00:11:48,836 Epoch[41] Batch [410]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088087,	
2017-07-13 00:11:55,573 Epoch[41] Batch [420]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.088201,	
2017-07-13 00:12:01,768 Epoch[41] Batch [430]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088067,	
2017-07-13 00:12:08,229 Epoch[41] Batch [440]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.087969,	
2017-07-13 00:12:14,629 Epoch[41] Batch [450]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087990,	
2017-07-13 00:12:20,945 Epoch[41] Batch [460]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087707,	
2017-07-13 00:12:27,525 Epoch[41] Batch [470]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087645,	
2017-07-13 00:12:34,063 Epoch[41] Batch [480]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.087521,	
2017-07-13 00:12:40,629 Epoch[41] Batch [490]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.087419,	
2017-07-13 00:12:46,995 Epoch[41] Batch [500]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087364,	
2017-07-13 00:12:53,687 Epoch[41] Batch [510]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087408,	
2017-07-13 00:12:59,983 Epoch[41] Batch [520]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087660,	
2017-07-13 00:13:06,447 Epoch[41] Batch [530]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.087632,	
2017-07-13 00:13:13,072 Epoch[41] Batch [540]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.087613,	
2017-07-13 00:13:19,440 Epoch[41] Batch [550]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087766,	
2017-07-13 00:13:26,249 Epoch[41] Batch [560]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.087750,	
2017-07-13 00:13:32,654 Epoch[41] Batch [570]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087812,	
2017-07-13 00:13:39,342 Epoch[41] Batch [580]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087848,	
2017-07-13 00:13:45,674 Epoch[41] Batch [590]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.087862,	
2017-07-13 00:13:51,944 Epoch[41] Batch [600]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.088091,	
2017-07-13 00:13:58,578 Epoch[41] Batch [610]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.088058,	
2017-07-13 00:14:04,677 Epoch[41] Batch [620]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.088030,	
2017-07-13 00:14:11,001 Epoch[41] Batch [630]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087920,	
2017-07-13 00:14:16,965 Epoch[41] Batch [640]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088075,	
2017-07-13 00:14:22,926 Epoch[41] Batch [650]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088086,	
2017-07-13 00:14:28,996 Epoch[41] Batch [660]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.088138,	
2017-07-13 00:14:35,084 Epoch[41] Batch [670]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.088165,	
2017-07-13 00:14:41,701 Epoch[41] Batch [680]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.087994,	
2017-07-13 00:14:48,183 Epoch[41] Batch [690]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.087943,	
2017-07-13 00:14:55,340 Epoch[41] Batch [700]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087853,	
2017-07-13 00:15:02,140 Epoch[41] Batch [710]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.087880,	
2017-07-13 00:15:09,020 Epoch[41] Batch [720]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.087712,	
2017-07-13 00:15:16,063 Epoch[41] Batch [730]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.087667,	
2017-07-13 00:15:23,279 Epoch[41] Batch [740]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.087692,	
2017-07-13 00:15:30,241 Epoch[41] Batch [750]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.087786,	
2017-07-13 00:15:37,312 Epoch[41] Batch [760]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.087760,	
2017-07-13 00:15:44,388 Epoch[41] Batch [770]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087746,	
2017-07-13 00:15:51,640 Epoch[41] Batch [780]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.087695,	
2017-07-13 00:15:58,530 Epoch[41] Batch [790]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.087961,	
2017-07-13 00:16:05,385 Epoch[41] Batch [800]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.088025,	
2017-07-13 00:16:12,242 Epoch[41] Batch [810]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087940,	
2017-07-13 00:16:18,674 Epoch[41] Batch [820]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.087990,	
2017-07-13 00:16:25,144 Epoch[41] Batch [830]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088099,	
2017-07-13 00:16:31,776 Epoch[41] Batch [840]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.088113,	
2017-07-13 00:16:38,240 Epoch[41] Batch [850]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088125,	
2017-07-13 00:16:45,175 Epoch[41] Batch [860]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.088121,	
2017-07-13 00:16:51,522 Epoch[41] Batch [870]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.088033,	
2017-07-13 00:16:58,194 Epoch[41] Batch [880]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.088011,	
2017-07-13 00:17:04,892 Epoch[41] Batch [890]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.088090,	
2017-07-13 00:17:11,638 Epoch[41] Batch [900]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.088009,	
2017-07-13 00:17:18,646 Epoch[41] Batch [910]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.088125,	
2017-07-13 00:17:24,911 Epoch[41] Batch [920]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088138,	
2017-07-13 00:17:31,402 Epoch[41] Batch [930]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088140,	
2017-07-13 00:17:37,828 Epoch[41] Batch [940]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088265,	
2017-07-13 00:17:44,609 Epoch[41] Batch [950]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.088176,	
2017-07-13 00:17:51,059 Epoch[41] Batch [960]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088147,	
2017-07-13 00:17:57,573 Epoch[41] Batch [970]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.088251,	
2017-07-13 00:18:04,304 Epoch[41] Batch [980]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.088316,	
2017-07-13 00:18:10,724 Epoch[41] Batch [990]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088387,	
2017-07-13 00:18:17,693 Epoch[41] Batch [1000]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.088379,	
2017-07-13 00:18:24,124 Epoch[41] Batch [1010]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088266,	
2017-07-13 00:18:30,668 Epoch[41] Batch [1020]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088310,	
2017-07-13 00:18:37,814 Epoch[41] Batch [1030]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088278,	
2017-07-13 00:18:44,400 Epoch[41] Batch [1040]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.088238,	
2017-07-13 00:18:51,021 Epoch[41] Batch [1050]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088209,	
2017-07-13 00:18:57,607 Epoch[41] Batch [1060]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.088185,	
2017-07-13 00:19:04,451 Epoch[41] Batch [1070]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.088124,	
2017-07-13 00:19:10,782 Epoch[41] Batch [1080]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088201,	
2017-07-13 00:19:17,439 Epoch[41] Batch [1090]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088196,	
2017-07-13 00:19:23,855 Epoch[41] Batch [1100]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088118,	
2017-07-13 00:19:30,450 Epoch[41] Batch [1110]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.088101,	
2017-07-13 00:19:36,585 Epoch[41] Batch [1120]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088047,	
2017-07-13 00:19:42,693 Epoch[41] Batch [1130]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.088086,	
2017-07-13 00:19:48,921 Epoch[41] Batch [1140]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.088059,	
2017-07-13 00:19:55,028 Epoch[41] Batch [1150]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.088017,	
2017-07-13 00:20:01,257 Epoch[41] Batch [1160]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.088006,	
2017-07-13 00:20:07,558 Epoch[41] Batch [1170]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088002,	
2017-07-13 00:20:13,948 Epoch[41] Batch [1180]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088009,	
2017-07-13 00:20:20,288 Epoch[41] Batch [1190]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.088013,	
2017-07-13 00:20:26,585 Epoch[41] Batch [1200]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087962,	
2017-07-13 00:20:32,951 Epoch[41] Batch [1210]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087929,	
2017-07-13 00:20:39,398 Epoch[41] Batch [1220]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.087883,	
2017-07-13 00:20:45,501 Epoch[41] Batch [1230]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.087926,	
2017-07-13 00:20:51,727 Epoch[41] Batch [1240]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087935,	
2017-07-13 00:20:58,195 Epoch[41] Batch [1250]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.087983,	
2017-07-13 00:21:04,399 Epoch[41] Batch [1260]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.088012,	
2017-07-13 00:21:10,837 Epoch[41] Batch [1270]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087989,	
2017-07-13 00:21:17,529 Epoch[41] Batch [1280]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088066,	
2017-07-13 00:21:24,384 Epoch[41] Batch [1290]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.088025,	
2017-07-13 00:21:30,651 Epoch[41] Batch [1300]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.088024,	
2017-07-13 00:21:37,416 Epoch[41] Batch [1310]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.088131,	
2017-07-13 00:21:43,543 Epoch[41] Batch [1320]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.088138,	
2017-07-13 00:21:49,948 Epoch[41] Batch [1330]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088190,	
2017-07-13 00:21:56,496 Epoch[41] Batch [1340]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088213,	
2017-07-13 00:22:02,677 Epoch[41] Batch [1350]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088288,	
2017-07-13 00:22:08,889 Epoch[41] Batch [1360]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.088313,	
2017-07-13 00:22:14,898 Epoch[41] Batch [1370]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.088317,	
2017-07-13 00:22:21,018 Epoch[41] Batch [1380]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088408,	
2017-07-13 00:22:27,429 Epoch[41] Batch [1390]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088423,	
2017-07-13 00:22:33,728 Epoch[41] Batch [1400]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088428,	
2017-07-13 00:22:39,554 Epoch[41] Batch [1410]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088496,	
2017-07-13 00:22:45,503 Epoch[41] Batch [1420]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.088454,	
2017-07-13 00:22:51,375 Epoch[41] Batch [1430]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.088430,	
2017-07-13 00:22:57,767 Epoch[41] Batch [1440]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088418,	
2017-07-13 00:23:04,027 Epoch[41] Batch [1450]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088443,	
2017-07-13 00:23:10,141 Epoch[41] Batch [1460]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088421,	
2017-07-13 00:23:16,121 Epoch[41] Batch [1470]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.088471,	
2017-07-13 00:23:22,185 Epoch[41] Batch [1480]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.088475,	
2017-07-13 00:23:25,951 Epoch[41] Train-FCNLogLoss=0.088488
2017-07-13 00:23:25,952 Epoch[41] Time cost=972.859
2017-07-13 00:23:26,998 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0042.params"
2017-07-13 00:23:31,659 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0042.states"
2017-07-13 00:23:38,628 Epoch[42] Batch [10]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.085981,	
2017-07-13 00:23:44,834 Epoch[42] Batch [20]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086063,	
2017-07-13 00:23:50,891 Epoch[42] Batch [30]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.085542,	
2017-07-13 00:23:56,727 Epoch[42] Batch [40]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085872,	
2017-07-13 00:24:03,030 Epoch[42] Batch [50]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.086010,	
2017-07-13 00:24:09,393 Epoch[42] Batch [60]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087142,	
2017-07-13 00:24:15,066 Epoch[42] Batch [70]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087483,	
2017-07-13 00:24:21,449 Epoch[42] Batch [80]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088214,	
2017-07-13 00:24:27,575 Epoch[42] Batch [90]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.087426,	
2017-07-13 00:24:33,617 Epoch[42] Batch [100]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087322,	
2017-07-13 00:24:39,850 Epoch[42] Batch [110]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.086401,	
2017-07-13 00:24:46,014 Epoch[42] Batch [120]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.086086,	
2017-07-13 00:24:52,075 Epoch[42] Batch [130]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.085891,	
2017-07-13 00:24:58,319 Epoch[42] Batch [140]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.085828,	
2017-07-13 00:25:04,301 Epoch[42] Batch [150]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086120,	
2017-07-13 00:25:10,557 Epoch[42] Batch [160]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.086140,	
2017-07-13 00:25:16,666 Epoch[42] Batch [170]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.086143,	
2017-07-13 00:25:23,006 Epoch[42] Batch [180]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.086696,	
2017-07-13 00:25:29,175 Epoch[42] Batch [190]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087911,	
2017-07-13 00:25:35,018 Epoch[42] Batch [200]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088501,	
2017-07-13 00:25:41,100 Epoch[42] Batch [210]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.088531,	
2017-07-13 00:25:47,369 Epoch[42] Batch [220]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.088598,	
2017-07-13 00:25:53,564 Epoch[42] Batch [230]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088579,	
2017-07-13 00:26:00,368 Epoch[42] Batch [240]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.088314,	
2017-07-13 00:26:06,373 Epoch[42] Batch [250]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.088363,	
2017-07-13 00:26:12,398 Epoch[42] Batch [260]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.088543,	
2017-07-13 00:26:18,715 Epoch[42] Batch [270]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.088820,	
2017-07-13 00:26:25,112 Epoch[42] Batch [280]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.088635,	
2017-07-13 00:26:31,225 Epoch[42] Batch [290]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088516,	
2017-07-13 00:26:37,496 Epoch[42] Batch [300]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.088519,	
2017-07-13 00:26:43,680 Epoch[42] Batch [310]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088401,	
2017-07-13 00:26:49,864 Epoch[42] Batch [320]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088674,	
2017-07-13 00:26:56,062 Epoch[42] Batch [330]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.088639,	
2017-07-13 00:27:02,278 Epoch[42] Batch [340]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.088599,	
2017-07-13 00:27:08,455 Epoch[42] Batch [350]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.088656,	
2017-07-13 00:27:14,402 Epoch[42] Batch [360]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.088372,	
2017-07-13 00:27:20,386 Epoch[42] Batch [370]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.088445,	
2017-07-13 00:27:26,428 Epoch[42] Batch [380]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.088289,	
2017-07-13 00:27:32,499 Epoch[42] Batch [390]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.088254,	
2017-07-13 00:27:38,634 Epoch[42] Batch [400]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088229,	
2017-07-13 00:27:45,079 Epoch[42] Batch [410]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.088323,	
2017-07-13 00:27:51,217 Epoch[42] Batch [420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088254,	
2017-07-13 00:27:57,382 Epoch[42] Batch [430]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.088089,	
2017-07-13 00:28:03,746 Epoch[42] Batch [440]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.088157,	
2017-07-13 00:28:10,006 Epoch[42] Batch [450]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088146,	
2017-07-13 00:28:16,438 Epoch[42] Batch [460]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088263,	
2017-07-13 00:28:23,091 Epoch[42] Batch [470]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088320,	
2017-07-13 00:28:29,706 Epoch[42] Batch [480]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088215,	
2017-07-13 00:28:36,761 Epoch[42] Batch [490]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.088517,	
2017-07-13 00:28:43,458 Epoch[42] Batch [500]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.088519,	
2017-07-13 00:28:50,164 Epoch[42] Batch [510]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.088452,	
2017-07-13 00:28:56,277 Epoch[42] Batch [520]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088422,	
2017-07-13 00:29:02,494 Epoch[42] Batch [530]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.088542,	
2017-07-13 00:29:09,074 Epoch[42] Batch [540]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.088542,	
2017-07-13 00:29:15,380 Epoch[42] Batch [550]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.088590,	
2017-07-13 00:29:22,587 Epoch[42] Batch [560]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.088569,	
2017-07-13 00:29:29,042 Epoch[42] Batch [570]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088784,	
2017-07-13 00:29:35,665 Epoch[42] Batch [580]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088888,	
2017-07-13 00:29:42,544 Epoch[42] Batch [590]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088850,	
2017-07-13 00:29:49,502 Epoch[42] Batch [600]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.088639,	
2017-07-13 00:29:56,274 Epoch[42] Batch [610]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.088678,	
2017-07-13 00:30:02,725 Epoch[42] Batch [620]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088768,	
2017-07-13 00:30:09,251 Epoch[42] Batch [630]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.088853,	
2017-07-13 00:30:15,626 Epoch[42] Batch [640]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088792,	
2017-07-13 00:30:22,101 Epoch[42] Batch [650]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088770,	
2017-07-13 00:30:28,537 Epoch[42] Batch [660]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088705,	
2017-07-13 00:30:35,198 Epoch[42] Batch [670]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088658,	
2017-07-13 00:30:41,962 Epoch[42] Batch [680]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.088634,	
2017-07-13 00:30:48,319 Epoch[42] Batch [690]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.088710,	
2017-07-13 00:30:54,708 Epoch[42] Batch [700]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088714,	
2017-07-13 00:31:01,007 Epoch[42] Batch [710]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088787,	
2017-07-13 00:31:07,299 Epoch[42] Batch [720]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.088809,	
2017-07-13 00:31:13,931 Epoch[42] Batch [730]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.088731,	
2017-07-13 00:31:19,885 Epoch[42] Batch [740]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.088859,	
2017-07-13 00:31:26,273 Epoch[42] Batch [750]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088886,	
2017-07-13 00:31:32,506 Epoch[42] Batch [760]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.088862,	
2017-07-13 00:31:39,127 Epoch[42] Batch [770]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088915,	
2017-07-13 00:31:45,657 Epoch[42] Batch [780]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.089037,	
2017-07-13 00:31:52,806 Epoch[42] Batch [790]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.089120,	
2017-07-13 00:31:59,471 Epoch[42] Batch [800]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.088959,	
2017-07-13 00:32:06,121 Epoch[42] Batch [810]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.088891,	
2017-07-13 00:32:12,812 Epoch[42] Batch [820]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088879,	
2017-07-13 00:32:19,203 Epoch[42] Batch [830]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.088860,	
2017-07-13 00:32:26,273 Epoch[42] Batch [840]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.088853,	
2017-07-13 00:32:32,817 Epoch[42] Batch [850]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088884,	
2017-07-13 00:32:39,651 Epoch[42] Batch [860]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088934,	
2017-07-13 00:32:46,234 Epoch[42] Batch [870]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.088830,	
2017-07-13 00:32:52,931 Epoch[42] Batch [880]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.088846,	
2017-07-13 00:32:59,731 Epoch[42] Batch [890]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.088767,	
2017-07-13 00:33:06,390 Epoch[42] Batch [900]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088701,	
2017-07-13 00:33:13,136 Epoch[42] Batch [910]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.088634,	
2017-07-13 00:33:20,001 Epoch[42] Batch [920]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.088558,	
2017-07-13 00:33:26,910 Epoch[42] Batch [930]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.088439,	
2017-07-13 00:33:34,069 Epoch[42] Batch [940]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.088353,	
2017-07-13 00:33:40,829 Epoch[42] Batch [950]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.088344,	
2017-07-13 00:33:47,432 Epoch[42] Batch [960]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088414,	
2017-07-13 00:33:54,052 Epoch[42] Batch [970]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088364,	
2017-07-13 00:34:00,487 Epoch[42] Batch [980]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088429,	
2017-07-13 00:34:07,124 Epoch[42] Batch [990]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088419,	
2017-07-13 00:34:13,596 Epoch[42] Batch [1000]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088320,	
2017-07-13 00:34:20,251 Epoch[42] Batch [1010]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088447,	
2017-07-13 00:34:26,717 Epoch[42] Batch [1020]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088492,	
2017-07-13 00:34:33,407 Epoch[42] Batch [1030]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088470,	
2017-07-13 00:34:40,131 Epoch[42] Batch [1040]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.088487,	
2017-07-13 00:34:46,614 Epoch[42] Batch [1050]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088454,	
2017-07-13 00:34:53,238 Epoch[42] Batch [1060]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088448,	
2017-07-13 00:34:59,800 Epoch[42] Batch [1070]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.088413,	
2017-07-13 00:35:06,436 Epoch[42] Batch [1080]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.088364,	
2017-07-13 00:35:12,849 Epoch[42] Batch [1090]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088254,	
2017-07-13 00:35:20,013 Epoch[42] Batch [1100]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.088248,	
2017-07-13 00:35:26,609 Epoch[42] Batch [1110]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088301,	
2017-07-13 00:35:33,483 Epoch[42] Batch [1120]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088271,	
2017-07-13 00:35:40,230 Epoch[42] Batch [1130]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.088172,	
2017-07-13 00:35:46,633 Epoch[42] Batch [1140]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.088127,	
2017-07-13 00:35:53,495 Epoch[42] Batch [1150]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.088108,	
2017-07-13 00:35:59,798 Epoch[42] Batch [1160]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088100,	
2017-07-13 00:36:06,266 Epoch[42] Batch [1170]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088107,	
2017-07-13 00:36:12,843 Epoch[42] Batch [1180]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.088095,	
2017-07-13 00:36:19,377 Epoch[42] Batch [1190]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.088086,	
2017-07-13 00:36:26,213 Epoch[42] Batch [1200]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088066,	
2017-07-13 00:36:32,898 Epoch[42] Batch [1210]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088030,	
2017-07-13 00:36:39,642 Epoch[42] Batch [1220]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.088080,	
2017-07-13 00:36:46,191 Epoch[42] Batch [1230]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088026,	
2017-07-13 00:36:53,294 Epoch[42] Batch [1240]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.088051,	
2017-07-13 00:36:59,579 Epoch[42] Batch [1250]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.088066,	
2017-07-13 00:37:06,698 Epoch[42] Batch [1260]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.087985,	
2017-07-13 00:37:13,290 Epoch[42] Batch [1270]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.087980,	
2017-07-13 00:37:20,148 Epoch[42] Batch [1280]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.088019,	
2017-07-13 00:37:26,838 Epoch[42] Batch [1290]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087995,	
2017-07-13 00:37:33,388 Epoch[42] Batch [1300]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088008,	
2017-07-13 00:37:40,079 Epoch[42] Batch [1310]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087965,	
2017-07-13 00:37:46,725 Epoch[42] Batch [1320]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087958,	
2017-07-13 00:37:53,395 Epoch[42] Batch [1330]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.087956,	
2017-07-13 00:38:00,053 Epoch[42] Batch [1340]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087932,	
2017-07-13 00:38:06,549 Epoch[42] Batch [1350]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.087971,	
2017-07-13 00:38:13,224 Epoch[42] Batch [1360]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.088012,	
2017-07-13 00:38:19,902 Epoch[42] Batch [1370]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.088080,	
2017-07-13 00:38:26,273 Epoch[42] Batch [1380]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.088109,	
2017-07-13 00:38:32,697 Epoch[42] Batch [1390]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088099,	
2017-07-13 00:38:39,321 Epoch[42] Batch [1400]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088068,	
2017-07-13 00:38:45,648 Epoch[42] Batch [1410]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088049,	
2017-07-13 00:38:51,892 Epoch[42] Batch [1420]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.088048,	
2017-07-13 00:38:58,512 Epoch[42] Batch [1430]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088080,	
2017-07-13 00:39:05,229 Epoch[42] Batch [1440]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.088067,	
2017-07-13 00:39:11,582 Epoch[42] Batch [1450]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.088084,	
2017-07-13 00:39:18,180 Epoch[42] Batch [1460]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.088079,	
2017-07-13 00:39:24,287 Epoch[42] Batch [1470]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.088044,	
2017-07-13 00:39:30,464 Epoch[42] Batch [1480]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.088046,	
2017-07-13 00:39:34,349 Epoch[42] Train-FCNLogLoss=0.088015
2017-07-13 00:39:34,349 Epoch[42] Time cost=962.690
2017-07-13 00:39:35,646 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0043.params"
2017-07-13 00:39:40,628 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0043.states"
2017-07-13 00:39:48,590 Epoch[43] Batch [10]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.090906,	
2017-07-13 00:39:55,175 Epoch[43] Batch [20]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.085913,	
2017-07-13 00:40:02,262 Epoch[43] Batch [30]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.085905,	
2017-07-13 00:40:08,927 Epoch[43] Batch [40]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.087811,	
2017-07-13 00:40:16,219 Epoch[43] Batch [50]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.087103,	
2017-07-13 00:40:23,153 Epoch[43] Batch [60]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.087576,	
2017-07-13 00:40:29,800 Epoch[43] Batch [70]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087139,	
2017-07-13 00:40:36,440 Epoch[43] Batch [80]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087036,	
2017-07-13 00:40:43,447 Epoch[43] Batch [90]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.087672,	
2017-07-13 00:40:50,044 Epoch[43] Batch [100]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087356,	
2017-07-13 00:40:56,967 Epoch[43] Batch [110]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088732,	
2017-07-13 00:41:03,939 Epoch[43] Batch [120]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.089747,	
2017-07-13 00:41:10,993 Epoch[43] Batch [130]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.089845,	
2017-07-13 00:41:17,721 Epoch[43] Batch [140]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.090075,	
2017-07-13 00:41:24,715 Epoch[43] Batch [150]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.089454,	
2017-07-13 00:41:31,338 Epoch[43] Batch [160]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.089598,	
2017-07-13 00:41:38,278 Epoch[43] Batch [170]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.088882,	
2017-07-13 00:41:44,965 Epoch[43] Batch [180]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.088348,	
2017-07-13 00:41:51,645 Epoch[43] Batch [190]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.087948,	
2017-07-13 00:41:58,254 Epoch[43] Batch [200]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088599,	
2017-07-13 00:42:04,691 Epoch[43] Batch [210]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.088286,	
2017-07-13 00:42:11,434 Epoch[43] Batch [220]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.088143,	
2017-07-13 00:42:17,864 Epoch[43] Batch [230]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.087602,	
2017-07-13 00:42:24,659 Epoch[43] Batch [240]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.087580,	
2017-07-13 00:42:31,789 Epoch[43] Batch [250]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.087404,	
2017-07-13 00:42:39,072 Epoch[43] Batch [260]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.087367,	
2017-07-13 00:42:45,718 Epoch[43] Batch [270]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087107,	
2017-07-13 00:42:52,496 Epoch[43] Batch [280]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086852,	
2017-07-13 00:42:59,416 Epoch[43] Batch [290]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.086990,	
2017-07-13 00:43:06,403 Epoch[43] Batch [300]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.087213,	
2017-07-13 00:43:13,092 Epoch[43] Batch [310]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087149,	
2017-07-13 00:43:19,914 Epoch[43] Batch [320]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.086832,	
2017-07-13 00:43:26,475 Epoch[43] Batch [330]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.086553,	
2017-07-13 00:43:33,229 Epoch[43] Batch [340]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.086324,	
2017-07-13 00:43:40,091 Epoch[43] Batch [350]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086379,	
2017-07-13 00:43:47,146 Epoch[43] Batch [360]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086441,	
2017-07-13 00:43:53,915 Epoch[43] Batch [370]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.086444,	
2017-07-13 00:44:00,894 Epoch[43] Batch [380]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086582,	
2017-07-13 00:44:07,733 Epoch[43] Batch [390]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.086412,	
2017-07-13 00:44:14,719 Epoch[43] Batch [400]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.086575,	
2017-07-13 00:44:21,440 Epoch[43] Batch [410]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.086883,	
2017-07-13 00:44:28,470 Epoch[43] Batch [420]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.086973,	
2017-07-13 00:44:35,239 Epoch[43] Batch [430]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.087122,	
2017-07-13 00:44:42,393 Epoch[43] Batch [440]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087069,	
2017-07-13 00:44:48,946 Epoch[43] Batch [450]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.087174,	
2017-07-13 00:44:55,508 Epoch[43] Batch [460]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.087076,	
2017-07-13 00:45:02,055 Epoch[43] Batch [470]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.086971,	
2017-07-13 00:45:08,934 Epoch[43] Batch [480]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.087179,	
2017-07-13 00:45:15,830 Epoch[43] Batch [490]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087167,	
2017-07-13 00:45:22,597 Epoch[43] Batch [500]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.087139,	
2017-07-13 00:45:29,321 Epoch[43] Batch [510]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.087261,	
2017-07-13 00:45:35,863 Epoch[43] Batch [520]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087313,	
2017-07-13 00:45:42,663 Epoch[43] Batch [530]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.087274,	
2017-07-13 00:45:49,034 Epoch[43] Batch [540]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087267,	
2017-07-13 00:45:55,660 Epoch[43] Batch [550]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.087616,	
2017-07-13 00:46:02,361 Epoch[43] Batch [560]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.087651,	
2017-07-13 00:46:08,961 Epoch[43] Batch [570]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087546,	
2017-07-13 00:46:15,791 Epoch[43] Batch [580]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.087371,	
2017-07-13 00:46:22,189 Epoch[43] Batch [590]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087400,	
2017-07-13 00:46:28,826 Epoch[43] Batch [600]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.087229,	
2017-07-13 00:46:35,539 Epoch[43] Batch [610]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.087442,	
2017-07-13 00:46:42,180 Epoch[43] Batch [620]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.087610,	
2017-07-13 00:46:49,136 Epoch[43] Batch [630]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.087793,	
2017-07-13 00:46:56,025 Epoch[43] Batch [640]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.087862,	
2017-07-13 00:47:03,193 Epoch[43] Batch [650]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.088514,	
2017-07-13 00:47:10,130 Epoch[43] Batch [660]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.088720,	
2017-07-13 00:47:16,702 Epoch[43] Batch [670]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.088768,	
2017-07-13 00:47:23,537 Epoch[43] Batch [680]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088781,	
2017-07-13 00:47:30,406 Epoch[43] Batch [690]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088825,	
2017-07-13 00:47:37,278 Epoch[43] Batch [700]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.088770,	
2017-07-13 00:47:43,873 Epoch[43] Batch [710]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.088833,	
2017-07-13 00:47:50,327 Epoch[43] Batch [720]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088868,	
2017-07-13 00:47:56,850 Epoch[43] Batch [730]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.088820,	
2017-07-13 00:48:03,464 Epoch[43] Batch [740]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088811,	
2017-07-13 00:48:10,587 Epoch[43] Batch [750]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.088824,	
2017-07-13 00:48:17,121 Epoch[43] Batch [760]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.088916,	
2017-07-13 00:48:24,214 Epoch[43] Batch [770]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.088921,	
2017-07-13 00:48:30,874 Epoch[43] Batch [780]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.088894,	
2017-07-13 00:48:37,699 Epoch[43] Batch [790]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.088786,	
2017-07-13 00:48:44,150 Epoch[43] Batch [800]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088814,	
2017-07-13 00:48:51,349 Epoch[43] Batch [810]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088772,	
2017-07-13 00:48:58,062 Epoch[43] Batch [820]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.088742,	
2017-07-13 00:49:04,506 Epoch[43] Batch [830]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.088708,	
2017-07-13 00:49:10,988 Epoch[43] Batch [840]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088670,	
2017-07-13 00:49:17,828 Epoch[43] Batch [850]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.088600,	
2017-07-13 00:49:24,588 Epoch[43] Batch [860]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.088670,	
2017-07-13 00:49:31,237 Epoch[43] Batch [870]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.088759,	
2017-07-13 00:49:38,018 Epoch[43] Batch [880]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.088681,	
2017-07-13 00:49:44,644 Epoch[43] Batch [890]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.088621,	
2017-07-13 00:49:51,148 Epoch[43] Batch [900]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.088614,	
2017-07-13 00:49:58,178 Epoch[43] Batch [910]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088543,	
2017-07-13 00:50:05,108 Epoch[43] Batch [920]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.088531,	
2017-07-13 00:50:12,082 Epoch[43] Batch [930]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.088543,	
2017-07-13 00:50:18,999 Epoch[43] Batch [940]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.088571,	
2017-07-13 00:50:26,023 Epoch[43] Batch [950]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088580,	
2017-07-13 00:50:32,985 Epoch[43] Batch [960]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.088576,	
2017-07-13 00:50:40,025 Epoch[43] Batch [970]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.088597,	
2017-07-13 00:50:46,928 Epoch[43] Batch [980]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.088515,	
2017-07-13 00:50:53,987 Epoch[43] Batch [990]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.088601,	
2017-07-13 00:51:00,579 Epoch[43] Batch [1000]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.088606,	
2017-07-13 00:51:07,524 Epoch[43] Batch [1010]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.088672,	
2017-07-13 00:51:15,030 Epoch[43] Batch [1020]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.088724,	
2017-07-13 00:51:22,065 Epoch[43] Batch [1030]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.088719,	
2017-07-13 00:51:28,971 Epoch[43] Batch [1040]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.088736,	
2017-07-13 00:51:36,169 Epoch[43] Batch [1050]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.088779,	
2017-07-13 00:51:43,278 Epoch[43] Batch [1060]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.088811,	
2017-07-13 00:51:50,274 Epoch[43] Batch [1070]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.088872,	
2017-07-13 00:51:57,373 Epoch[43] Batch [1080]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.088909,	
2017-07-13 00:52:04,381 Epoch[43] Batch [1090]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.088920,	
2017-07-13 00:52:11,427 Epoch[43] Batch [1100]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.088979,	
2017-07-13 00:52:18,518 Epoch[43] Batch [1110]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.089173,	
2017-07-13 00:52:25,692 Epoch[43] Batch [1120]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.089176,	
2017-07-13 00:52:32,574 Epoch[43] Batch [1130]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.089207,	
2017-07-13 00:52:39,571 Epoch[43] Batch [1140]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.089144,	
2017-07-13 00:52:46,189 Epoch[43] Batch [1150]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.089150,	
2017-07-13 00:52:53,060 Epoch[43] Batch [1160]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.089238,	
2017-07-13 00:53:00,044 Epoch[43] Batch [1170]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.089234,	
2017-07-13 00:53:07,147 Epoch[43] Batch [1180]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.089213,	
2017-07-13 00:53:14,164 Epoch[43] Batch [1190]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.089202,	
2017-07-13 00:53:21,356 Epoch[43] Batch [1200]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.089160,	
2017-07-13 00:53:28,221 Epoch[43] Batch [1210]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.089168,	
2017-07-13 00:53:35,483 Epoch[43] Batch [1220]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.089257,	
2017-07-13 00:53:42,554 Epoch[43] Batch [1230]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.089268,	
2017-07-13 00:53:49,668 Epoch[43] Batch [1240]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.089256,	
2017-07-13 00:53:56,721 Epoch[43] Batch [1250]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.089305,	
2017-07-13 00:54:03,822 Epoch[43] Batch [1260]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.089212,	
2017-07-13 00:54:10,707 Epoch[43] Batch [1270]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.089237,	
2017-07-13 00:54:17,695 Epoch[43] Batch [1280]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.089180,	
2017-07-13 00:54:24,283 Epoch[43] Batch [1290]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.089149,	
2017-07-13 00:54:31,264 Epoch[43] Batch [1300]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.089160,	
2017-07-13 00:54:38,142 Epoch[43] Batch [1310]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.089124,	
2017-07-13 00:54:45,040 Epoch[43] Batch [1320]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.089008,	
2017-07-13 00:54:51,978 Epoch[43] Batch [1330]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.088992,	
2017-07-13 00:54:59,323 Epoch[43] Batch [1340]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.089027,	
2017-07-13 00:55:06,083 Epoch[43] Batch [1350]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.088996,	
2017-07-13 00:55:13,159 Epoch[43] Batch [1360]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.089015,	
2017-07-13 00:55:20,307 Epoch[43] Batch [1370]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.089039,	
2017-07-13 00:55:27,563 Epoch[43] Batch [1380]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.089155,	
2017-07-13 00:55:34,499 Epoch[43] Batch [1390]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.089148,	
2017-07-13 00:55:41,553 Epoch[43] Batch [1400]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.089216,	
2017-07-13 00:55:48,302 Epoch[43] Batch [1410]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.089221,	
2017-07-13 00:55:55,444 Epoch[43] Batch [1420]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.089242,	
2017-07-13 00:56:02,212 Epoch[43] Batch [1430]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.089200,	
2017-07-13 00:56:09,113 Epoch[43] Batch [1440]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.089135,	
2017-07-13 00:56:15,926 Epoch[43] Batch [1450]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.089122,	
2017-07-13 00:56:22,556 Epoch[43] Batch [1460]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.089087,	
2017-07-13 00:56:29,165 Epoch[43] Batch [1470]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.089079,	
2017-07-13 00:56:35,861 Epoch[43] Batch [1480]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.089135,	
2017-07-13 00:56:39,724 Epoch[43] Train-FCNLogLoss=0.089159
2017-07-13 00:56:39,724 Epoch[43] Time cost=1019.095
2017-07-13 00:56:40,604 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0044.params"
2017-07-13 00:56:45,565 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0044.states"
2017-07-13 00:56:53,567 Epoch[44] Batch [10]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.083859,	
2017-07-13 00:57:00,522 Epoch[44] Batch [20]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.085076,	
2017-07-13 00:57:07,498 Epoch[44] Batch [30]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.085228,	
2017-07-13 00:57:13,999 Epoch[44] Batch [40]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.086049,	
2017-07-13 00:57:20,648 Epoch[44] Batch [50]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.086322,	
2017-07-13 00:57:27,357 Epoch[44] Batch [60]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.085239,	
2017-07-13 00:57:34,109 Epoch[44] Batch [70]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.084671,	
2017-07-13 00:57:40,973 Epoch[44] Batch [80]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.085047,	
2017-07-13 00:57:47,780 Epoch[44] Batch [90]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.085018,	
2017-07-13 00:57:54,844 Epoch[44] Batch [100]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.084881,	
2017-07-13 00:58:01,868 Epoch[44] Batch [110]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.085765,	
2017-07-13 00:58:08,748 Epoch[44] Batch [120]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.085998,	
2017-07-13 00:58:15,616 Epoch[44] Batch [130]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.085840,	
2017-07-13 00:58:22,704 Epoch[44] Batch [140]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.085890,	
2017-07-13 00:58:29,603 Epoch[44] Batch [150]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087109,	
2017-07-13 00:58:36,608 Epoch[44] Batch [160]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.088454,	
2017-07-13 00:58:43,631 Epoch[44] Batch [170]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.088484,	
2017-07-13 00:58:50,771 Epoch[44] Batch [180]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.088673,	
2017-07-13 00:58:57,927 Epoch[44] Batch [190]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.089259,	
2017-07-13 00:59:04,968 Epoch[44] Batch [200]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.089744,	
2017-07-13 00:59:12,048 Epoch[44] Batch [210]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.090383,	
2017-07-13 00:59:19,244 Epoch[44] Batch [220]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.095631,	
2017-07-13 00:59:26,292 Epoch[44] Batch [230]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.097563,	
2017-07-13 00:59:33,309 Epoch[44] Batch [240]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.100200,	
2017-07-13 00:59:40,631 Epoch[44] Batch [250]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.103076,	
2017-07-13 00:59:47,613 Epoch[44] Batch [260]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.104562,	
2017-07-13 00:59:54,674 Epoch[44] Batch [270]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.105315,	
2017-07-13 01:00:02,387 Epoch[44] Batch [280]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.105359,	
2017-07-13 01:00:09,197 Epoch[44] Batch [290]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.105418,	
2017-07-13 01:00:16,115 Epoch[44] Batch [300]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.104875,	
2017-07-13 01:00:23,075 Epoch[44] Batch [310]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.104396,	
2017-07-13 01:00:30,019 Epoch[44] Batch [320]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.104345,	
2017-07-13 01:00:37,122 Epoch[44] Batch [330]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.104011,	
2017-07-13 01:00:44,063 Epoch[44] Batch [340]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.104039,	
2017-07-13 01:00:50,841 Epoch[44] Batch [350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.103779,	
2017-07-13 01:00:57,840 Epoch[44] Batch [360]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.103482,	
2017-07-13 01:01:04,961 Epoch[44] Batch [370]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.103349,	
2017-07-13 01:01:11,897 Epoch[44] Batch [380]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.102929,	
2017-07-13 01:01:18,865 Epoch[44] Batch [390]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.102750,	
2017-07-13 01:01:25,810 Epoch[44] Batch [400]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102395,	
2017-07-13 01:01:33,405 Epoch[44] Batch [410]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.102295,	
2017-07-13 01:01:40,158 Epoch[44] Batch [420]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.101931,	
2017-07-13 01:01:46,993 Epoch[44] Batch [430]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.101617,	
2017-07-13 01:01:53,154 Epoch[44] Batch [440]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101275,	
2017-07-13 01:01:59,772 Epoch[44] Batch [450]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.101008,	
2017-07-13 01:02:06,476 Epoch[44] Batch [460]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.100846,	
2017-07-13 01:02:12,887 Epoch[44] Batch [470]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.100741,	
2017-07-13 01:02:19,333 Epoch[44] Batch [480]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.100578,	
2017-07-13 01:02:26,359 Epoch[44] Batch [490]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.100248,	
2017-07-13 01:02:33,053 Epoch[44] Batch [500]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.100036,	
2017-07-13 01:02:39,833 Epoch[44] Batch [510]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.099932,	
2017-07-13 01:02:46,334 Epoch[44] Batch [520]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.099658,	
2017-07-13 01:02:53,063 Epoch[44] Batch [530]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.099594,	
2017-07-13 01:02:59,281 Epoch[44] Batch [540]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.099427,	
2017-07-13 01:03:05,593 Epoch[44] Batch [550]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.099251,	
2017-07-13 01:03:12,026 Epoch[44] Batch [560]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.099429,	
2017-07-13 01:03:18,326 Epoch[44] Batch [570]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.099169,	
2017-07-13 01:03:24,566 Epoch[44] Batch [580]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.098828,	
2017-07-13 01:03:30,993 Epoch[44] Batch [590]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.098556,	
2017-07-13 01:03:37,531 Epoch[44] Batch [600]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.098144,	
2017-07-13 01:03:44,218 Epoch[44] Batch [610]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.098093,	
2017-07-13 01:03:50,818 Epoch[44] Batch [620]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.098149,	
2017-07-13 01:03:57,167 Epoch[44] Batch [630]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.098128,	
2017-07-13 01:04:03,531 Epoch[44] Batch [640]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.098107,	
2017-07-13 01:04:09,677 Epoch[44] Batch [650]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.097900,	
2017-07-13 01:04:16,355 Epoch[44] Batch [660]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.097823,	
2017-07-13 01:04:22,863 Epoch[44] Batch [670]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.097566,	
2017-07-13 01:04:29,447 Epoch[44] Batch [680]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.097356,	
2017-07-13 01:04:35,531 Epoch[44] Batch [690]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097170,	
2017-07-13 01:04:41,863 Epoch[44] Batch [700]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.097005,	
2017-07-13 01:04:48,530 Epoch[44] Batch [710]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.096884,	
2017-07-13 01:04:53,909 Epoch[44] Batch [720]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096897,	
2017-07-13 01:04:59,391 Epoch[44] Batch [730]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.096840,	
2017-07-13 01:05:04,510 Epoch[44] Batch [740]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.096762,	
2017-07-13 01:05:09,097 Epoch[44] Batch [750]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.096642,	
2017-07-13 01:05:13,869 Epoch[44] Batch [760]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.096594,	
2017-07-13 01:05:18,628 Epoch[44] Batch [770]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.096418,	
2017-07-13 01:05:23,014 Epoch[44] Batch [780]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.096242,	
2017-07-13 01:05:27,525 Epoch[44] Batch [790]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.095975,	
2017-07-13 01:05:31,942 Epoch[44] Batch [800]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.095896,	
2017-07-13 01:05:36,603 Epoch[44] Batch [810]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095859,	
2017-07-13 01:05:41,476 Epoch[44] Batch [820]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.095847,	
2017-07-13 01:05:46,288 Epoch[44] Batch [830]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.095724,	
2017-07-13 01:05:50,784 Epoch[44] Batch [840]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.095538,	
2017-07-13 01:05:55,731 Epoch[44] Batch [850]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.095393,	
2017-07-13 01:06:00,554 Epoch[44] Batch [860]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.095374,	
2017-07-13 01:06:05,740 Epoch[44] Batch [870]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095418,	
2017-07-13 01:06:10,431 Epoch[44] Batch [880]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.095365,	
2017-07-13 01:06:15,054 Epoch[44] Batch [890]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.095267,	
2017-07-13 01:06:19,749 Epoch[44] Batch [900]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.095198,	
2017-07-13 01:06:24,407 Epoch[44] Batch [910]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.095184,	
2017-07-13 01:06:28,885 Epoch[44] Batch [920]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.095165,	
2017-07-13 01:06:33,520 Epoch[44] Batch [930]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.095218,	
2017-07-13 01:06:38,782 Epoch[44] Batch [940]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.095178,	
2017-07-13 01:06:43,478 Epoch[44] Batch [950]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.095014,	
2017-07-13 01:06:48,151 Epoch[44] Batch [960]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.095006,	
2017-07-13 01:06:53,103 Epoch[44] Batch [970]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.095019,	
2017-07-13 01:06:57,961 Epoch[44] Batch [980]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.094886,	
2017-07-13 01:07:02,949 Epoch[44] Batch [990]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.094811,	
2017-07-13 01:07:07,715 Epoch[44] Batch [1000]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094749,	
2017-07-13 01:07:12,813 Epoch[44] Batch [1010]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.094740,	
2017-07-13 01:07:17,891 Epoch[44] Batch [1020]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.094753,	
2017-07-13 01:07:22,654 Epoch[44] Batch [1030]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.094682,	
2017-07-13 01:07:27,627 Epoch[44] Batch [1040]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.094609,	
2017-07-13 01:07:32,484 Epoch[44] Batch [1050]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.094549,	
2017-07-13 01:07:37,430 Epoch[44] Batch [1060]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.094491,	
2017-07-13 01:07:42,932 Epoch[44] Batch [1070]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.094463,	
2017-07-13 01:07:47,941 Epoch[44] Batch [1080]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.094489,	
2017-07-13 01:07:52,729 Epoch[44] Batch [1090]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.094417,	
2017-07-13 01:07:57,746 Epoch[44] Batch [1100]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.094348,	
2017-07-13 01:08:03,186 Epoch[44] Batch [1110]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.094302,	
2017-07-13 01:08:08,228 Epoch[44] Batch [1120]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.094213,	
2017-07-13 01:08:13,165 Epoch[44] Batch [1130]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.094136,	
2017-07-13 01:08:17,956 Epoch[44] Batch [1140]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.094117,	
2017-07-13 01:08:23,247 Epoch[44] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094093,	
2017-07-13 01:08:28,538 Epoch[44] Batch [1160]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094047,	
2017-07-13 01:08:33,082 Epoch[44] Batch [1170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.094073,	
2017-07-13 01:08:38,234 Epoch[44] Batch [1180]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094030,	
2017-07-13 01:08:43,533 Epoch[44] Batch [1190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093941,	
2017-07-13 01:08:48,246 Epoch[44] Batch [1200]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.093796,	
2017-07-13 01:08:52,670 Epoch[44] Batch [1210]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.093722,	
2017-07-13 01:08:57,224 Epoch[44] Batch [1220]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.093595,	
2017-07-13 01:09:02,172 Epoch[44] Batch [1230]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.093557,	
2017-07-13 01:09:07,191 Epoch[44] Batch [1240]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.093484,	
2017-07-13 01:09:12,215 Epoch[44] Batch [1250]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.093442,	
2017-07-13 01:09:16,920 Epoch[44] Batch [1260]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.093496,	
2017-07-13 01:09:21,750 Epoch[44] Batch [1270]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.093512,	
2017-07-13 01:09:26,244 Epoch[44] Batch [1280]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.093447,	
2017-07-13 01:09:31,222 Epoch[44] Batch [1290]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.093357,	
2017-07-13 01:09:36,011 Epoch[44] Batch [1300]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.093391,	
2017-07-13 01:09:40,633 Epoch[44] Batch [1310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.093404,	
2017-07-13 01:09:45,964 Epoch[44] Batch [1320]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093332,	
2017-07-13 01:09:50,558 Epoch[44] Batch [1330]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.093285,	
2017-07-13 01:09:55,588 Epoch[44] Batch [1340]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.093263,	
2017-07-13 01:10:00,730 Epoch[44] Batch [1350]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093203,	
2017-07-13 01:10:05,592 Epoch[44] Batch [1360]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.093227,	
2017-07-13 01:10:11,111 Epoch[44] Batch [1370]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.093177,	
2017-07-13 01:10:16,041 Epoch[44] Batch [1380]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.093114,	
2017-07-13 01:10:20,956 Epoch[44] Batch [1390]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.093129,	
2017-07-13 01:10:26,493 Epoch[44] Batch [1400]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.093103,	
2017-07-13 01:10:31,659 Epoch[44] Batch [1410]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093063,	
2017-07-13 01:10:36,304 Epoch[44] Batch [1420]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.093059,	
2017-07-13 01:10:41,376 Epoch[44] Batch [1430]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.093088,	
2017-07-13 01:10:46,044 Epoch[44] Batch [1440]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.093014,	
2017-07-13 01:10:50,635 Epoch[44] Batch [1450]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092916,	
2017-07-13 01:10:55,327 Epoch[44] Batch [1460]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092877,	
2017-07-13 01:11:00,142 Epoch[44] Batch [1470]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092787,	
2017-07-13 01:11:04,998 Epoch[44] Batch [1480]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.092755,	
2017-07-13 01:11:08,267 Epoch[44] Train-FCNLogLoss=0.092676
2017-07-13 01:11:08,267 Epoch[44] Time cost=862.702
2017-07-13 01:11:09,105 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0045.params"
2017-07-13 01:11:12,450 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0045.states"
2017-07-13 01:11:18,391 Epoch[45] Batch [10]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.091229,	
2017-07-13 01:11:23,061 Epoch[45] Batch [20]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089660,	
2017-07-13 01:11:27,672 Epoch[45] Batch [30]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.085951,	
2017-07-13 01:11:32,153 Epoch[45] Batch [40]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087780,	
2017-07-13 01:11:36,450 Epoch[45] Batch [50]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087209,	
2017-07-13 01:11:41,225 Epoch[45] Batch [60]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087428,	
2017-07-13 01:11:45,728 Epoch[45] Batch [70]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.087826,	
2017-07-13 01:11:51,181 Epoch[45] Batch [80]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.086512,	
2017-07-13 01:11:56,146 Epoch[45] Batch [90]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.085785,	
2017-07-13 01:12:00,983 Epoch[45] Batch [100]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.085411,	
2017-07-13 01:12:06,069 Epoch[45] Batch [110]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.085967,	
2017-07-13 01:12:10,944 Epoch[45] Batch [120]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.085478,	
2017-07-13 01:12:15,815 Epoch[45] Batch [130]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.084970,	
2017-07-13 01:12:20,450 Epoch[45] Batch [140]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.085838,	
2017-07-13 01:12:24,786 Epoch[45] Batch [150]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.086087,	
2017-07-13 01:12:29,339 Epoch[45] Batch [160]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086625,	
2017-07-13 01:12:34,059 Epoch[45] Batch [170]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.086746,	
2017-07-13 01:12:38,537 Epoch[45] Batch [180]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086472,	
2017-07-13 01:12:43,179 Epoch[45] Batch [190]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086075,	
2017-07-13 01:12:47,870 Epoch[45] Batch [200]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.086153,	
2017-07-13 01:12:52,651 Epoch[45] Batch [210]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086656,	
2017-07-13 01:12:57,169 Epoch[45] Batch [220]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.086777,	
2017-07-13 01:13:01,752 Epoch[45] Batch [230]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.086458,	
2017-07-13 01:13:06,938 Epoch[45] Batch [240]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.086397,	
2017-07-13 01:13:11,731 Epoch[45] Batch [250]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.086425,	
2017-07-13 01:13:16,552 Epoch[45] Batch [260]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086549,	
2017-07-13 01:13:21,366 Epoch[45] Batch [270]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.086635,	
2017-07-13 01:13:26,177 Epoch[45] Batch [280]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.086760,	
2017-07-13 01:13:30,715 Epoch[45] Batch [290]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.086659,	
2017-07-13 01:13:35,180 Epoch[45] Batch [300]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.086554,	
2017-07-13 01:13:40,057 Epoch[45] Batch [310]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.086585,	
2017-07-13 01:13:45,242 Epoch[45] Batch [320]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.086368,	
2017-07-13 01:13:49,956 Epoch[45] Batch [330]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.086132,	
2017-07-13 01:13:54,702 Epoch[45] Batch [340]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.086157,	
2017-07-13 01:13:59,407 Epoch[45] Batch [350]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.086158,	
2017-07-13 01:14:04,375 Epoch[45] Batch [360]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086117,	
2017-07-13 01:14:08,716 Epoch[45] Batch [370]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.086081,	
2017-07-13 01:14:13,424 Epoch[45] Batch [380]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.086001,	
2017-07-13 01:14:18,050 Epoch[45] Batch [390]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.085922,	
2017-07-13 01:14:22,615 Epoch[45] Batch [400]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.086087,	
2017-07-13 01:14:27,485 Epoch[45] Batch [410]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086093,	
2017-07-13 01:14:32,364 Epoch[45] Batch [420]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.086229,	
2017-07-13 01:14:37,880 Epoch[45] Batch [430]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.086456,	
2017-07-13 01:14:42,779 Epoch[45] Batch [440]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086492,	
2017-07-13 01:14:48,037 Epoch[45] Batch [450]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086493,	
2017-07-13 01:14:53,714 Epoch[45] Batch [460]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.086583,	
2017-07-13 01:14:58,887 Epoch[45] Batch [470]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.086674,	
2017-07-13 01:15:04,256 Epoch[45] Batch [480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.086924,	
2017-07-13 01:15:09,120 Epoch[45] Batch [490]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086911,	
2017-07-13 01:15:13,911 Epoch[45] Batch [500]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.087077,	
2017-07-13 01:15:18,597 Epoch[45] Batch [510]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087037,	
2017-07-13 01:15:23,662 Epoch[45] Batch [520]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086998,	
2017-07-13 01:15:28,698 Epoch[45] Batch [530]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.086877,	
2017-07-13 01:15:33,580 Epoch[45] Batch [540]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.086961,	
2017-07-13 01:15:39,282 Epoch[45] Batch [550]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.086858,	
2017-07-13 01:15:44,407 Epoch[45] Batch [560]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086864,	
2017-07-13 01:15:49,250 Epoch[45] Batch [570]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086769,	
2017-07-13 01:15:54,179 Epoch[45] Batch [580]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.086755,	
2017-07-13 01:15:58,580 Epoch[45] Batch [590]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.086748,	
2017-07-13 01:16:03,297 Epoch[45] Batch [600]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.086662,	
2017-07-13 01:16:08,442 Epoch[45] Batch [610]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.086749,	
2017-07-13 01:16:13,646 Epoch[45] Batch [620]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.086624,	
2017-07-13 01:16:18,715 Epoch[45] Batch [630]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086561,	
2017-07-13 01:16:23,042 Epoch[45] Batch [640]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.086488,	
2017-07-13 01:16:27,468 Epoch[45] Batch [650]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.086476,	
2017-07-13 01:16:31,952 Epoch[45] Batch [660]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086529,	
2017-07-13 01:16:36,730 Epoch[45] Batch [670]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086538,	
2017-07-13 01:16:41,802 Epoch[45] Batch [680]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086456,	
2017-07-13 01:16:46,149 Epoch[45] Batch [690]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.086359,	
2017-07-13 01:16:50,282 Epoch[45] Batch [700]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.086440,	
2017-07-13 01:16:54,400 Epoch[45] Batch [710]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.086363,	
2017-07-13 01:16:58,620 Epoch[45] Batch [720]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.086409,	
2017-07-13 01:17:03,725 Epoch[45] Batch [730]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086381,	
2017-07-13 01:17:08,567 Epoch[45] Batch [740]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086304,	
2017-07-13 01:17:13,683 Epoch[45] Batch [750]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086361,	
2017-07-13 01:17:18,654 Epoch[45] Batch [760]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086434,	
2017-07-13 01:17:24,011 Epoch[45] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.086448,	
2017-07-13 01:17:29,381 Epoch[45] Batch [780]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.086486,	
2017-07-13 01:17:34,438 Epoch[45] Batch [790]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086486,	
2017-07-13 01:17:39,494 Epoch[45] Batch [800]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.086512,	
2017-07-13 01:17:44,728 Epoch[45] Batch [810]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086651,	
2017-07-13 01:17:49,958 Epoch[45] Batch [820]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.086735,	
2017-07-13 01:17:54,597 Epoch[45] Batch [830]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086783,	
2017-07-13 01:17:59,843 Epoch[45] Batch [840]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086775,	
2017-07-13 01:18:04,386 Epoch[45] Batch [850]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.086724,	
2017-07-13 01:18:08,611 Epoch[45] Batch [860]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.086788,	
2017-07-13 01:18:13,599 Epoch[45] Batch [870]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086774,	
2017-07-13 01:18:18,302 Epoch[45] Batch [880]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.086774,	
2017-07-13 01:18:23,367 Epoch[45] Batch [890]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.086831,	
2017-07-13 01:18:28,458 Epoch[45] Batch [900]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086882,	
2017-07-13 01:18:34,028 Epoch[45] Batch [910]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.086823,	
2017-07-13 01:18:39,410 Epoch[45] Batch [920]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.086861,	
2017-07-13 01:18:44,338 Epoch[45] Batch [930]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.086865,	
2017-07-13 01:18:49,686 Epoch[45] Batch [940]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.086904,	
2017-07-13 01:18:54,804 Epoch[45] Batch [950]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086884,	
2017-07-13 01:18:59,569 Epoch[45] Batch [960]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.086831,	
2017-07-13 01:19:04,620 Epoch[45] Batch [970]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.086792,	
2017-07-13 01:19:09,488 Epoch[45] Batch [980]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086825,	
2017-07-13 01:19:14,128 Epoch[45] Batch [990]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086890,	
2017-07-13 01:19:18,777 Epoch[45] Batch [1000]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086963,	
2017-07-13 01:19:23,590 Epoch[45] Batch [1010]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.086945,	
2017-07-13 01:19:28,563 Epoch[45] Batch [1020]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.086946,	
2017-07-13 01:19:33,165 Epoch[45] Batch [1030]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.086877,	
2017-07-13 01:19:38,707 Epoch[45] Batch [1040]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.086835,	
2017-07-13 01:19:44,131 Epoch[45] Batch [1050]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.086934,	
2017-07-13 01:19:48,682 Epoch[45] Batch [1060]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086835,	
2017-07-13 01:19:53,332 Epoch[45] Batch [1070]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086816,	
2017-07-13 01:19:58,506 Epoch[45] Batch [1080]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.086863,	
2017-07-13 01:20:03,732 Epoch[45] Batch [1090]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086858,	
2017-07-13 01:20:08,872 Epoch[45] Batch [1100]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.086886,	
2017-07-13 01:20:13,700 Epoch[45] Batch [1110]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086901,	
2017-07-13 01:20:18,812 Epoch[45] Batch [1120]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.086887,	
2017-07-13 01:20:23,763 Epoch[45] Batch [1130]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.086883,	
2017-07-13 01:20:28,890 Epoch[45] Batch [1140]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.086843,	
2017-07-13 01:20:34,115 Epoch[45] Batch [1150]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.086970,	
2017-07-13 01:20:39,142 Epoch[45] Batch [1160]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.086944,	
2017-07-13 01:20:44,216 Epoch[45] Batch [1170]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086954,	
2017-07-13 01:20:48,850 Epoch[45] Batch [1180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.086960,	
2017-07-13 01:20:53,752 Epoch[45] Batch [1190]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086895,	
2017-07-13 01:20:58,064 Epoch[45] Batch [1200]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.086947,	
2017-07-13 01:21:02,806 Epoch[45] Batch [1210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.086982,	
2017-07-13 01:21:07,294 Epoch[45] Batch [1220]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087037,	
2017-07-13 01:21:11,983 Epoch[45] Batch [1230]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087093,	
2017-07-13 01:21:16,704 Epoch[45] Batch [1240]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.087079,	
2017-07-13 01:21:21,621 Epoch[45] Batch [1250]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.087099,	
2017-07-13 01:21:26,451 Epoch[45] Batch [1260]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.087086,	
2017-07-13 01:21:31,161 Epoch[45] Batch [1270]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087087,	
2017-07-13 01:21:36,083 Epoch[45] Batch [1280]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.087044,	
2017-07-13 01:21:41,045 Epoch[45] Batch [1290]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.086983,	
2017-07-13 01:21:45,916 Epoch[45] Batch [1300]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086961,	
2017-07-13 01:21:50,871 Epoch[45] Batch [1310]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.086947,	
2017-07-13 01:21:55,475 Epoch[45] Batch [1320]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.086941,	
2017-07-13 01:22:00,033 Epoch[45] Batch [1330]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.086857,	
2017-07-13 01:22:04,569 Epoch[45] Batch [1340]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.086830,	
2017-07-13 01:22:09,603 Epoch[45] Batch [1350]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.086854,	
2017-07-13 01:22:14,707 Epoch[45] Batch [1360]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086817,	
2017-07-13 01:22:19,939 Epoch[45] Batch [1370]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.086790,	
2017-07-13 01:22:25,179 Epoch[45] Batch [1380]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086750,	
2017-07-13 01:22:30,326 Epoch[45] Batch [1390]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.086817,	
2017-07-13 01:22:35,259 Epoch[45] Batch [1400]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.086740,	
2017-07-13 01:22:40,330 Epoch[45] Batch [1410]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086739,	
2017-07-13 01:22:45,118 Epoch[45] Batch [1420]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.086800,	
2017-07-13 01:22:49,973 Epoch[45] Batch [1430]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.086781,	
2017-07-13 01:22:54,459 Epoch[45] Batch [1440]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086738,	
2017-07-13 01:22:58,982 Epoch[45] Batch [1450]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086701,	
2017-07-13 01:23:03,896 Epoch[45] Batch [1460]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.086720,	
2017-07-13 01:23:08,660 Epoch[45] Batch [1470]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.086770,	
2017-07-13 01:23:13,623 Epoch[45] Batch [1480]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.086819,	
2017-07-13 01:23:16,272 Epoch[45] Train-FCNLogLoss=0.086848
2017-07-13 01:23:16,273 Epoch[45] Time cost=723.822
2017-07-13 01:23:17,436 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0046.params"
2017-07-13 01:23:21,772 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0046.states"
2017-07-13 01:23:27,026 Epoch[46] Batch [10]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.077925,	
2017-07-13 01:23:31,713 Epoch[46] Batch [20]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089928,	
2017-07-13 01:23:36,295 Epoch[46] Batch [30]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089591,	
2017-07-13 01:23:41,172 Epoch[46] Batch [40]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090532,	
2017-07-13 01:23:45,962 Epoch[46] Batch [50]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089295,	
2017-07-13 01:23:50,367 Epoch[46] Batch [60]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.089252,	
2017-07-13 01:23:54,977 Epoch[46] Batch [70]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088673,	
2017-07-13 01:23:59,705 Epoch[46] Batch [80]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089432,	
2017-07-13 01:24:04,165 Epoch[46] Batch [90]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.088951,	
2017-07-13 01:24:08,742 Epoch[46] Batch [100]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089452,	
2017-07-13 01:24:13,154 Epoch[46] Batch [110]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088450,	
2017-07-13 01:24:17,504 Epoch[46] Batch [120]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.088054,	
2017-07-13 01:24:22,199 Epoch[46] Batch [130]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087269,	
2017-07-13 01:24:26,957 Epoch[46] Batch [140]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087002,	
2017-07-13 01:24:31,478 Epoch[46] Batch [150]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087027,	
2017-07-13 01:24:36,349 Epoch[46] Batch [160]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086536,	
2017-07-13 01:24:40,755 Epoch[46] Batch [170]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.086028,	
2017-07-13 01:24:45,407 Epoch[46] Batch [180]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086132,	
2017-07-13 01:24:50,170 Epoch[46] Batch [190]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.085955,	
2017-07-13 01:24:54,688 Epoch[46] Batch [200]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.086077,	
2017-07-13 01:24:59,573 Epoch[46] Batch [210]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.085908,	
2017-07-13 01:25:04,862 Epoch[46] Batch [220]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.085858,	
2017-07-13 01:25:09,559 Epoch[46] Batch [230]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.085816,	
2017-07-13 01:25:13,935 Epoch[46] Batch [240]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.085608,	
2017-07-13 01:25:18,838 Epoch[46] Batch [250]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.085601,	
2017-07-13 01:25:23,301 Epoch[46] Batch [260]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.085579,	
2017-07-13 01:25:27,735 Epoch[46] Batch [270]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.085615,	
2017-07-13 01:25:32,112 Epoch[46] Batch [280]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.085894,	
2017-07-13 01:25:36,651 Epoch[46] Batch [290]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.085903,	
2017-07-13 01:25:41,133 Epoch[46] Batch [300]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.085907,	
2017-07-13 01:25:45,792 Epoch[46] Batch [310]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.085725,	
2017-07-13 01:25:50,554 Epoch[46] Batch [320]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.085820,	
2017-07-13 01:25:54,924 Epoch[46] Batch [330]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.086003,	
2017-07-13 01:25:59,601 Epoch[46] Batch [340]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.085670,	
2017-07-13 01:26:04,341 Epoch[46] Batch [350]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.085681,	
2017-07-13 01:26:09,258 Epoch[46] Batch [360]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.086043,	
2017-07-13 01:26:15,037 Epoch[46] Batch [370]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086129,	
2017-07-13 01:26:19,897 Epoch[46] Batch [380]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.086076,	
2017-07-13 01:26:24,642 Epoch[46] Batch [390]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.086080,	
2017-07-13 01:26:29,028 Epoch[46] Batch [400]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086103,	
2017-07-13 01:26:33,679 Epoch[46] Batch [410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086165,	
2017-07-13 01:26:38,751 Epoch[46] Batch [420]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086291,	
2017-07-13 01:26:43,431 Epoch[46] Batch [430]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.086136,	
2017-07-13 01:26:48,120 Epoch[46] Batch [440]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.085993,	
2017-07-13 01:26:52,584 Epoch[46] Batch [450]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.085821,	
2017-07-13 01:26:57,382 Epoch[46] Batch [460]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.085760,	
2017-07-13 01:27:02,704 Epoch[46] Batch [470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.085849,	
2017-07-13 01:27:07,245 Epoch[46] Batch [480]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.085943,	
2017-07-13 01:27:12,242 Epoch[46] Batch [490]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.085962,	
2017-07-13 01:27:16,819 Epoch[46] Batch [500]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.086090,	
2017-07-13 01:27:21,661 Epoch[46] Batch [510]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.086171,	
2017-07-13 01:27:26,646 Epoch[46] Batch [520]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.086217,	
2017-07-13 01:27:31,158 Epoch[46] Batch [530]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.086335,	
2017-07-13 01:27:35,916 Epoch[46] Batch [540]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.086308,	
2017-07-13 01:27:40,737 Epoch[46] Batch [550]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086270,	
2017-07-13 01:27:45,079 Epoch[46] Batch [560]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.086284,	
2017-07-13 01:27:49,848 Epoch[46] Batch [570]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.086241,	
2017-07-13 01:27:54,612 Epoch[46] Batch [580]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.086323,	
2017-07-13 01:27:59,135 Epoch[46] Batch [590]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086237,	
2017-07-13 01:28:03,702 Epoch[46] Batch [600]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.086094,	
2017-07-13 01:28:08,280 Epoch[46] Batch [610]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.086039,	
2017-07-13 01:28:12,864 Epoch[46] Batch [620]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.085958,	
2017-07-13 01:28:18,047 Epoch[46] Batch [630]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.085894,	
2017-07-13 01:28:22,763 Epoch[46] Batch [640]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.085859,	
2017-07-13 01:28:27,298 Epoch[46] Batch [650]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.085898,	
2017-07-13 01:28:31,848 Epoch[46] Batch [660]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.085918,	
2017-07-13 01:28:36,355 Epoch[46] Batch [670]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.085933,	
2017-07-13 01:28:41,179 Epoch[46] Batch [680]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086001,	
2017-07-13 01:28:45,991 Epoch[46] Batch [690]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.085958,	
2017-07-13 01:28:50,604 Epoch[46] Batch [700]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.085923,	
2017-07-13 01:28:55,085 Epoch[46] Batch [710]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086036,	
2017-07-13 01:28:59,979 Epoch[46] Batch [720]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086055,	
2017-07-13 01:29:04,983 Epoch[46] Batch [730]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.086044,	
2017-07-13 01:29:09,951 Epoch[46] Batch [740]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.086162,	
2017-07-13 01:29:14,853 Epoch[46] Batch [750]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.086178,	
2017-07-13 01:29:19,441 Epoch[46] Batch [760]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.086165,	
2017-07-13 01:29:24,416 Epoch[46] Batch [770]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.086157,	
2017-07-13 01:29:28,896 Epoch[46] Batch [780]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086045,	
2017-07-13 01:29:33,503 Epoch[46] Batch [790]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.086205,	
2017-07-13 01:29:38,029 Epoch[46] Batch [800]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086163,	
2017-07-13 01:29:42,904 Epoch[46] Batch [810]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086142,	
2017-07-13 01:29:47,689 Epoch[46] Batch [820]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086228,	
2017-07-13 01:29:52,514 Epoch[46] Batch [830]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086172,	
2017-07-13 01:29:57,022 Epoch[46] Batch [840]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.086306,	
2017-07-13 01:30:01,503 Epoch[46] Batch [850]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.086319,	
2017-07-13 01:30:06,935 Epoch[46] Batch [860]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086336,	
2017-07-13 01:30:11,802 Epoch[46] Batch [870]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086299,	
2017-07-13 01:30:16,534 Epoch[46] Batch [880]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.086278,	
2017-07-13 01:30:21,175 Epoch[46] Batch [890]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.086196,	
2017-07-13 01:30:26,104 Epoch[46] Batch [900]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.086251,	
2017-07-13 01:30:31,223 Epoch[46] Batch [910]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086244,	
2017-07-13 01:30:36,187 Epoch[46] Batch [920]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.086333,	
2017-07-13 01:30:41,333 Epoch[46] Batch [930]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.086344,	
2017-07-13 01:30:46,025 Epoch[46] Batch [940]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.086432,	
2017-07-13 01:30:50,604 Epoch[46] Batch [950]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.086443,	
2017-07-13 01:30:55,406 Epoch[46] Batch [960]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.086460,	
2017-07-13 01:30:59,990 Epoch[46] Batch [970]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.086599,	
2017-07-13 01:31:04,841 Epoch[46] Batch [980]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086732,	
2017-07-13 01:31:09,618 Epoch[46] Batch [990]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086688,	
2017-07-13 01:31:14,193 Epoch[46] Batch [1000]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.086737,	
2017-07-13 01:31:18,718 Epoch[46] Batch [1010]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.086921,	
2017-07-13 01:31:23,419 Epoch[46] Batch [1020]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.086879,	
2017-07-13 01:31:28,195 Epoch[46] Batch [1030]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.086871,	
2017-07-13 01:31:33,008 Epoch[46] Batch [1040]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.086789,	
2017-07-13 01:31:37,806 Epoch[46] Batch [1050]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086680,	
2017-07-13 01:31:42,459 Epoch[46] Batch [1060]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.086759,	
2017-07-13 01:31:47,396 Epoch[46] Batch [1070]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086719,	
2017-07-13 01:31:52,394 Epoch[46] Batch [1080]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.086718,	
2017-07-13 01:31:57,155 Epoch[46] Batch [1090]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.086621,	
2017-07-13 01:32:02,802 Epoch[46] Batch [1100]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086695,	
2017-07-13 01:32:08,044 Epoch[46] Batch [1110]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086616,	
2017-07-13 01:32:12,853 Epoch[46] Batch [1120]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.086639,	
2017-07-13 01:32:17,931 Epoch[46] Batch [1130]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086546,	
2017-07-13 01:32:23,260 Epoch[46] Batch [1140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086508,	
2017-07-13 01:32:28,035 Epoch[46] Batch [1150]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.086414,	
2017-07-13 01:32:32,661 Epoch[46] Batch [1160]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086432,	
2017-07-13 01:32:37,915 Epoch[46] Batch [1170]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086452,	
2017-07-13 01:32:42,900 Epoch[46] Batch [1180]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.086438,	
2017-07-13 01:32:47,611 Epoch[46] Batch [1190]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.086454,	
2017-07-13 01:32:53,172 Epoch[46] Batch [1200]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.086478,	
2017-07-13 01:32:58,110 Epoch[46] Batch [1210]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086546,	
2017-07-13 01:33:02,815 Epoch[46] Batch [1220]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.086462,	
2017-07-13 01:33:07,950 Epoch[46] Batch [1230]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.086438,	
2017-07-13 01:33:13,421 Epoch[46] Batch [1240]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.086422,	
2017-07-13 01:33:19,241 Epoch[46] Batch [1250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086364,	
2017-07-13 01:33:24,509 Epoch[46] Batch [1260]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086392,	
2017-07-13 01:33:29,265 Epoch[46] Batch [1270]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.086379,	
2017-07-13 01:33:34,281 Epoch[46] Batch [1280]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.086396,	
2017-07-13 01:33:39,378 Epoch[46] Batch [1290]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.086299,	
2017-07-13 01:33:44,227 Epoch[46] Batch [1300]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086301,	
2017-07-13 01:33:49,477 Epoch[46] Batch [1310]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086344,	
2017-07-13 01:33:54,588 Epoch[46] Batch [1320]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.086312,	
2017-07-13 01:33:59,439 Epoch[46] Batch [1330]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086311,	
2017-07-13 01:34:04,545 Epoch[46] Batch [1340]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.086302,	
2017-07-13 01:34:09,666 Epoch[46] Batch [1350]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086288,	
2017-07-13 01:34:14,484 Epoch[46] Batch [1360]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.086233,	
2017-07-13 01:34:20,024 Epoch[46] Batch [1370]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.086242,	
2017-07-13 01:34:25,017 Epoch[46] Batch [1380]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.086220,	
2017-07-13 01:34:29,795 Epoch[46] Batch [1390]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086204,	
2017-07-13 01:34:35,036 Epoch[46] Batch [1400]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086232,	
2017-07-13 01:34:40,315 Epoch[46] Batch [1410]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086278,	
2017-07-13 01:34:45,112 Epoch[46] Batch [1420]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086277,	
2017-07-13 01:34:50,775 Epoch[46] Batch [1430]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.086277,	
2017-07-13 01:34:56,008 Epoch[46] Batch [1440]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086270,	
2017-07-13 01:35:01,593 Epoch[46] Batch [1450]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.086322,	
2017-07-13 01:35:07,322 Epoch[46] Batch [1460]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086348,	
2017-07-13 01:35:12,580 Epoch[46] Batch [1470]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.086273,	
2017-07-13 01:35:18,200 Epoch[46] Batch [1480]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.086295,	
2017-07-13 01:35:21,652 Epoch[46] Train-FCNLogLoss=0.086299
2017-07-13 01:35:21,652 Epoch[46] Time cost=719.880
2017-07-13 01:35:22,565 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0047.params"
2017-07-13 01:35:27,544 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0047.states"
2017-07-13 01:35:33,935 Epoch[47] Batch [10]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.092155,	
2017-07-13 01:35:39,695 Epoch[47] Batch [20]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.090767,	
2017-07-13 01:35:44,964 Epoch[47] Batch [30]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088985,	
2017-07-13 01:35:50,137 Epoch[47] Batch [40]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087306,	
2017-07-13 01:35:55,611 Epoch[47] Batch [50]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.086048,	
2017-07-13 01:36:01,141 Epoch[47] Batch [60]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.084335,	
2017-07-13 01:36:06,703 Epoch[47] Batch [70]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.085043,	
2017-07-13 01:36:12,283 Epoch[47] Batch [80]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.084101,	
2017-07-13 01:36:17,849 Epoch[47] Batch [90]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.083944,	
2017-07-13 01:36:24,291 Epoch[47] Batch [100]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.085016,	
2017-07-13 01:36:30,752 Epoch[47] Batch [110]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.085309,	
2017-07-13 01:36:36,367 Epoch[47] Batch [120]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.085796,	
2017-07-13 01:36:41,922 Epoch[47] Batch [130]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.085706,	
2017-07-13 01:36:48,042 Epoch[47] Batch [140]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.085030,	
2017-07-13 01:36:52,807 Epoch[47] Batch [150]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.085199,	
2017-07-13 01:36:58,027 Epoch[47] Batch [160]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.085064,	
2017-07-13 01:37:03,895 Epoch[47] Batch [170]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.084431,	
2017-07-13 01:37:08,834 Epoch[47] Batch [180]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.084098,	
2017-07-13 01:37:14,188 Epoch[47] Batch [190]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.084413,	
2017-07-13 01:37:19,530 Epoch[47] Batch [200]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.084336,	
2017-07-13 01:37:24,460 Epoch[47] Batch [210]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.084416,	
2017-07-13 01:37:30,433 Epoch[47] Batch [220]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.084624,	
2017-07-13 01:37:35,643 Epoch[47] Batch [230]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.084496,	
2017-07-13 01:37:40,871 Epoch[47] Batch [240]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.084509,	
2017-07-13 01:37:45,645 Epoch[47] Batch [250]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.084376,	
2017-07-13 01:37:50,785 Epoch[47] Batch [260]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.084579,	
2017-07-13 01:37:56,135 Epoch[47] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.084662,	
2017-07-13 01:38:01,415 Epoch[47] Batch [280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.084828,	
2017-07-13 01:38:07,044 Epoch[47] Batch [290]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.084535,	
2017-07-13 01:38:11,794 Epoch[47] Batch [300]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.084634,	
2017-07-13 01:38:16,804 Epoch[47] Batch [310]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.084456,	
2017-07-13 01:38:21,720 Epoch[47] Batch [320]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.084264,	
2017-07-13 01:38:26,531 Epoch[47] Batch [330]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.084228,	
2017-07-13 01:38:31,821 Epoch[47] Batch [340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.084197,	
2017-07-13 01:38:37,190 Epoch[47] Batch [350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.084350,	
2017-07-13 01:38:42,498 Epoch[47] Batch [360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.084265,	
2017-07-13 01:38:47,872 Epoch[47] Batch [370]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.084391,	
2017-07-13 01:38:53,203 Epoch[47] Batch [380]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.084425,	
2017-07-13 01:38:58,443 Epoch[47] Batch [390]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.084414,	
2017-07-13 01:39:03,808 Epoch[47] Batch [400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.084188,	
2017-07-13 01:39:09,240 Epoch[47] Batch [410]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.084293,	
2017-07-13 01:39:14,795 Epoch[47] Batch [420]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.084501,	
2017-07-13 01:39:20,714 Epoch[47] Batch [430]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.084651,	
2017-07-13 01:39:25,778 Epoch[47] Batch [440]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.084851,	
2017-07-13 01:39:30,853 Epoch[47] Batch [450]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.084759,	
2017-07-13 01:39:35,933 Epoch[47] Batch [460]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.084742,	
2017-07-13 01:39:40,783 Epoch[47] Batch [470]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.084825,	
2017-07-13 01:39:46,071 Epoch[47] Batch [480]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.084905,	
2017-07-13 01:39:51,122 Epoch[47] Batch [490]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.084965,	
2017-07-13 01:39:56,262 Epoch[47] Batch [500]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.085034,	
2017-07-13 01:40:01,473 Epoch[47] Batch [510]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.084972,	
2017-07-13 01:40:06,748 Epoch[47] Batch [520]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.084957,	
2017-07-13 01:40:12,526 Epoch[47] Batch [530]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.084914,	
2017-07-13 01:40:17,899 Epoch[47] Batch [540]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.084973,	
2017-07-13 01:40:23,271 Epoch[47] Batch [550]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.084931,	
2017-07-13 01:40:28,399 Epoch[47] Batch [560]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.084841,	
2017-07-13 01:40:33,467 Epoch[47] Batch [570]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.084949,	
2017-07-13 01:40:38,400 Epoch[47] Batch [580]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.085024,	
2017-07-13 01:40:43,434 Epoch[47] Batch [590]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.084743,	
2017-07-13 01:40:48,536 Epoch[47] Batch [600]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.084789,	
2017-07-13 01:40:54,492 Epoch[47] Batch [610]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.084824,	
2017-07-13 01:40:59,746 Epoch[47] Batch [620]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.084859,	
2017-07-13 01:41:04,887 Epoch[47] Batch [630]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.084861,	
2017-07-13 01:41:10,112 Epoch[47] Batch [640]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.084990,	
2017-07-13 01:41:15,128 Epoch[47] Batch [650]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.084915,	
2017-07-13 01:41:20,740 Epoch[47] Batch [660]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.085187,	
2017-07-13 01:41:26,537 Epoch[47] Batch [670]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.085139,	
2017-07-13 01:41:32,096 Epoch[47] Batch [680]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.085191,	
2017-07-13 01:41:37,172 Epoch[47] Batch [690]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.085222,	
2017-07-13 01:41:42,294 Epoch[47] Batch [700]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.085187,	
2017-07-13 01:41:47,569 Epoch[47] Batch [710]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.085183,	
2017-07-13 01:41:52,928 Epoch[47] Batch [720]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.085171,	
2017-07-13 01:41:57,796 Epoch[47] Batch [730]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.085202,	
2017-07-13 01:42:03,228 Epoch[47] Batch [740]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085205,	
2017-07-13 01:42:08,391 Epoch[47] Batch [750]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.085103,	
2017-07-13 01:42:13,901 Epoch[47] Batch [760]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.085272,	
2017-07-13 01:42:19,980 Epoch[47] Batch [770]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.085257,	
2017-07-13 01:42:25,269 Epoch[47] Batch [780]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.085302,	
2017-07-13 01:42:31,528 Epoch[47] Batch [790]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.085303,	
2017-07-13 01:42:36,838 Epoch[47] Batch [800]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.085320,	
2017-07-13 01:42:41,926 Epoch[47] Batch [810]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.085262,	
2017-07-13 01:42:46,721 Epoch[47] Batch [820]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.085294,	
2017-07-13 01:42:51,964 Epoch[47] Batch [830]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.085336,	
2017-07-13 01:42:56,831 Epoch[47] Batch [840]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.085351,	
2017-07-13 01:43:01,544 Epoch[47] Batch [850]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.085415,	
2017-07-13 01:43:06,452 Epoch[47] Batch [860]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.085507,	
2017-07-13 01:43:11,759 Epoch[47] Batch [870]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.085542,	
2017-07-13 01:43:17,015 Epoch[47] Batch [880]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.085558,	
2017-07-13 01:43:22,878 Epoch[47] Batch [890]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.085449,	
2017-07-13 01:43:27,740 Epoch[47] Batch [900]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.085474,	
2017-07-13 01:43:32,751 Epoch[47] Batch [910]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.085412,	
2017-07-13 01:43:37,962 Epoch[47] Batch [920]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.085396,	
2017-07-13 01:43:42,753 Epoch[47] Batch [930]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.085363,	
2017-07-13 01:43:47,801 Epoch[47] Batch [940]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.085299,	
2017-07-13 01:43:52,972 Epoch[47] Batch [950]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.085360,	
2017-07-13 01:43:58,037 Epoch[47] Batch [960]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.085408,	
2017-07-13 01:44:03,099 Epoch[47] Batch [970]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.085503,	
2017-07-13 01:44:07,967 Epoch[47] Batch [980]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.085443,	
2017-07-13 01:44:13,207 Epoch[47] Batch [990]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.085382,	
2017-07-13 01:44:18,179 Epoch[47] Batch [1000]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.085321,	
2017-07-13 01:44:23,950 Epoch[47] Batch [1010]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085446,	
2017-07-13 01:44:29,070 Epoch[47] Batch [1020]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.085478,	
2017-07-13 01:44:35,068 Epoch[47] Batch [1030]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085497,	
2017-07-13 01:44:39,630 Epoch[47] Batch [1040]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.085489,	
2017-07-13 01:44:44,225 Epoch[47] Batch [1050]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.085547,	
2017-07-13 01:44:48,877 Epoch[47] Batch [1060]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.085513,	
2017-07-13 01:44:54,146 Epoch[47] Batch [1070]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.085494,	
2017-07-13 01:44:59,589 Epoch[47] Batch [1080]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.085593,	
2017-07-13 01:45:04,983 Epoch[47] Batch [1090]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.085653,	
2017-07-13 01:45:10,534 Epoch[47] Batch [1100]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.085721,	
2017-07-13 01:45:15,745 Epoch[47] Batch [1110]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.085740,	
2017-07-13 01:45:21,230 Epoch[47] Batch [1120]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.085882,	
2017-07-13 01:45:26,609 Epoch[47] Batch [1130]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.085995,	
2017-07-13 01:45:31,392 Epoch[47] Batch [1140]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.086075,	
2017-07-13 01:45:36,399 Epoch[47] Batch [1150]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.086063,	
2017-07-13 01:45:41,242 Epoch[47] Batch [1160]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.085999,	
2017-07-13 01:45:46,316 Epoch[47] Batch [1170]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.085961,	
2017-07-13 01:45:51,389 Epoch[47] Batch [1180]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.085941,	
2017-07-13 01:45:55,714 Epoch[47] Batch [1190]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.085908,	
2017-07-13 01:46:00,568 Epoch[47] Batch [1200]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.085815,	
2017-07-13 01:46:05,338 Epoch[47] Batch [1210]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.085840,	
2017-07-13 01:46:10,173 Epoch[47] Batch [1220]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.085833,	
2017-07-13 01:46:16,138 Epoch[47] Batch [1230]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.085793,	
2017-07-13 01:46:21,112 Epoch[47] Batch [1240]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.085836,	
2017-07-13 01:46:26,133 Epoch[47] Batch [1250]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.085827,	
2017-07-13 01:46:31,436 Epoch[47] Batch [1260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.085768,	
2017-07-13 01:46:36,388 Epoch[47] Batch [1270]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.085721,	
2017-07-13 01:46:41,654 Epoch[47] Batch [1280]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.085736,	
2017-07-13 01:46:46,582 Epoch[47] Batch [1290]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.085761,	
2017-07-13 01:46:51,230 Epoch[47] Batch [1300]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.085739,	
2017-07-13 01:46:56,279 Epoch[47] Batch [1310]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.085734,	
2017-07-13 01:47:01,688 Epoch[47] Batch [1320]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.085743,	
2017-07-13 01:47:06,427 Epoch[47] Batch [1330]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.085759,	
2017-07-13 01:47:11,637 Epoch[47] Batch [1340]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.085739,	
2017-07-13 01:47:16,951 Epoch[47] Batch [1350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.085680,	
2017-07-13 01:47:21,731 Epoch[47] Batch [1360]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.085668,	
2017-07-13 01:47:27,346 Epoch[47] Batch [1370]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.085617,	
2017-07-13 01:47:33,033 Epoch[47] Batch [1380]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.085628,	
2017-07-13 01:47:38,288 Epoch[47] Batch [1390]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.085663,	
2017-07-13 01:47:44,314 Epoch[47] Batch [1400]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.085723,	
2017-07-13 01:47:50,073 Epoch[47] Batch [1410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.085677,	
2017-07-13 01:47:55,045 Epoch[47] Batch [1420]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.085760,	
2017-07-13 01:48:00,049 Epoch[47] Batch [1430]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.085803,	
2017-07-13 01:48:05,709 Epoch[47] Batch [1440]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.085874,	
2017-07-13 01:48:11,601 Epoch[47] Batch [1450]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085870,	
2017-07-13 01:48:17,378 Epoch[47] Batch [1460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085920,	
2017-07-13 01:48:22,458 Epoch[47] Batch [1470]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.086015,	
2017-07-13 01:48:28,255 Epoch[47] Batch [1480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086111,	
2017-07-13 01:48:31,546 Epoch[47] Train-FCNLogLoss=0.086182
2017-07-13 01:48:31,546 Epoch[47] Time cost=784.002
2017-07-13 01:48:32,719 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0048.params"
2017-07-13 01:48:37,689 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0048.states"
2017-07-13 01:48:43,722 Epoch[48] Batch [10]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.127201,	
2017-07-13 01:48:48,664 Epoch[48] Batch [20]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.116215,	
2017-07-13 01:48:54,111 Epoch[48] Batch [30]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.112601,	
2017-07-13 01:48:59,688 Epoch[48] Batch [40]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.112816,	
2017-07-13 01:49:04,813 Epoch[48] Batch [50]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.109676,	
2017-07-13 01:49:10,445 Epoch[48] Batch [60]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.106486,	
2017-07-13 01:49:15,806 Epoch[48] Batch [70]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104312,	
2017-07-13 01:49:21,298 Epoch[48] Batch [80]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.100628,	
2017-07-13 01:49:26,904 Epoch[48] Batch [90]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098632,	
2017-07-13 01:49:31,527 Epoch[48] Batch [100]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.097390,	
2017-07-13 01:49:36,472 Epoch[48] Batch [110]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.096911,	
2017-07-13 01:49:41,254 Epoch[48] Batch [120]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.095633,	
2017-07-13 01:49:46,494 Epoch[48] Batch [130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.094814,	
2017-07-13 01:49:51,526 Epoch[48] Batch [140]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.094588,	
2017-07-13 01:49:56,821 Epoch[48] Batch [150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094143,	
2017-07-13 01:50:02,263 Epoch[48] Batch [160]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093554,	
2017-07-13 01:50:07,138 Epoch[48] Batch [170]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.093092,	
2017-07-13 01:50:12,111 Epoch[48] Batch [180]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.092484,	
2017-07-13 01:50:17,037 Epoch[48] Batch [190]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.092462,	
2017-07-13 01:50:22,634 Epoch[48] Batch [200]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.092741,	
2017-07-13 01:50:28,036 Epoch[48] Batch [210]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.092733,	
2017-07-13 01:50:33,715 Epoch[48] Batch [220]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.092691,	
2017-07-13 01:50:40,131 Epoch[48] Batch [230]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.093547,	
2017-07-13 01:50:45,403 Epoch[48] Batch [240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094152,	
2017-07-13 01:50:51,163 Epoch[48] Batch [250]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.094322,	
2017-07-13 01:50:56,720 Epoch[48] Batch [260]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.093851,	
2017-07-13 01:51:02,294 Epoch[48] Batch [270]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.093886,	
2017-07-13 01:51:08,639 Epoch[48] Batch [280]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.093789,	
2017-07-13 01:51:13,614 Epoch[48] Batch [290]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.093560,	
2017-07-13 01:51:18,833 Epoch[48] Batch [300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093306,	
2017-07-13 01:51:23,823 Epoch[48] Batch [310]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093231,	
2017-07-13 01:51:28,861 Epoch[48] Batch [320]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.093861,	
2017-07-13 01:51:33,953 Epoch[48] Batch [330]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.095143,	
2017-07-13 01:51:38,785 Epoch[48] Batch [340]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.095842,	
2017-07-13 01:51:43,807 Epoch[48] Batch [350]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.095974,	
2017-07-13 01:51:48,726 Epoch[48] Batch [360]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.096650,	
2017-07-13 01:51:53,706 Epoch[48] Batch [370]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.096586,	
2017-07-13 01:51:58,574 Epoch[48] Batch [380]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.096472,	
2017-07-13 01:52:04,176 Epoch[48] Batch [390]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.096851,	
2017-07-13 01:52:09,705 Epoch[48] Batch [400]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.097003,	
2017-07-13 01:52:15,745 Epoch[48] Batch [410]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097505,	
2017-07-13 01:52:21,337 Epoch[48] Batch [420]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098337,	
2017-07-13 01:52:26,153 Epoch[48] Batch [430]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.098548,	
2017-07-13 01:52:30,797 Epoch[48] Batch [440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.098546,	
2017-07-13 01:52:35,903 Epoch[48] Batch [450]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.099278,	
2017-07-13 01:52:40,796 Epoch[48] Batch [460]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.099471,	
2017-07-13 01:52:45,818 Epoch[48] Batch [470]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.099580,	
2017-07-13 01:52:51,576 Epoch[48] Batch [480]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.099609,	
2017-07-13 01:52:57,638 Epoch[48] Batch [490]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099643,	
2017-07-13 01:53:02,990 Epoch[48] Batch [500]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.099489,	
2017-07-13 01:53:07,929 Epoch[48] Batch [510]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.099394,	
2017-07-13 01:53:12,901 Epoch[48] Batch [520]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.099224,	
2017-07-13 01:53:17,794 Epoch[48] Batch [530]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.099133,	
2017-07-13 01:53:23,403 Epoch[48] Batch [540]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.099001,	
2017-07-13 01:53:29,727 Epoch[48] Batch [550]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.098789,	
2017-07-13 01:53:34,983 Epoch[48] Batch [560]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.098745,	
2017-07-13 01:53:40,596 Epoch[48] Batch [570]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.098779,	
2017-07-13 01:53:45,826 Epoch[48] Batch [580]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.098500,	
2017-07-13 01:53:51,515 Epoch[48] Batch [590]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.098262,	
2017-07-13 01:53:56,429 Epoch[48] Batch [600]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.098236,	
2017-07-13 01:54:01,283 Epoch[48] Batch [610]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.097936,	
2017-07-13 01:54:06,469 Epoch[48] Batch [620]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.097655,	
2017-07-13 01:54:13,492 Epoch[48] Batch [630]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.097611,	
2017-07-13 01:54:19,337 Epoch[48] Batch [640]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.097594,	
2017-07-13 01:54:24,635 Epoch[48] Batch [650]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097650,	
2017-07-13 01:54:29,800 Epoch[48] Batch [660]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097594,	
2017-07-13 01:54:34,679 Epoch[48] Batch [670]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.097663,	
2017-07-13 01:54:40,160 Epoch[48] Batch [680]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.097531,	
2017-07-13 01:54:46,231 Epoch[48] Batch [690]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097635,	
2017-07-13 01:54:51,242 Epoch[48] Batch [700]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.097456,	
2017-07-13 01:54:56,128 Epoch[48] Batch [710]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.097353,	
2017-07-13 01:55:00,960 Epoch[48] Batch [720]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.097175,	
2017-07-13 01:55:05,815 Epoch[48] Batch [730]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.096979,	
2017-07-13 01:55:10,989 Epoch[48] Batch [740]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.096828,	
2017-07-13 01:55:15,999 Epoch[48] Batch [750]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.096733,	
2017-07-13 01:55:20,863 Epoch[48] Batch [760]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.096539,	
2017-07-13 01:55:25,434 Epoch[48] Batch [770]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.096303,	
2017-07-13 01:55:30,214 Epoch[48] Batch [780]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.096172,	
2017-07-13 01:55:35,245 Epoch[48] Batch [790]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.095985,	
2017-07-13 01:55:40,098 Epoch[48] Batch [800]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.095880,	
2017-07-13 01:55:44,692 Epoch[48] Batch [810]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.095781,	
2017-07-13 01:55:49,354 Epoch[48] Batch [820]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.095639,	
2017-07-13 01:55:54,370 Epoch[48] Batch [830]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.095524,	
2017-07-13 01:55:59,294 Epoch[48] Batch [840]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.095375,	
2017-07-13 01:56:04,019 Epoch[48] Batch [850]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.095321,	
2017-07-13 01:56:08,719 Epoch[48] Batch [860]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.095210,	
2017-07-13 01:56:13,518 Epoch[48] Batch [870]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.095200,	
2017-07-13 01:56:18,835 Epoch[48] Batch [880]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095087,	
2017-07-13 01:56:23,331 Epoch[48] Batch [890]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.094994,	
2017-07-13 01:56:28,275 Epoch[48] Batch [900]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.094936,	
2017-07-13 01:56:33,264 Epoch[48] Batch [910]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.094914,	
2017-07-13 01:56:38,148 Epoch[48] Batch [920]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.094902,	
2017-07-13 01:56:43,311 Epoch[48] Batch [930]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094929,	
2017-07-13 01:56:47,843 Epoch[48] Batch [940]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.094969,	
2017-07-13 01:56:52,615 Epoch[48] Batch [950]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.094871,	
2017-07-13 01:56:57,427 Epoch[48] Batch [960]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.094733,	
2017-07-13 01:57:02,069 Epoch[48] Batch [970]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.094772,	
2017-07-13 01:57:06,885 Epoch[48] Batch [980]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.094726,	
2017-07-13 01:57:11,615 Epoch[48] Batch [990]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.094704,	
2017-07-13 01:57:16,386 Epoch[48] Batch [1000]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.094595,	
2017-07-13 01:57:21,225 Epoch[48] Batch [1010]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.094538,	
2017-07-13 01:57:26,114 Epoch[48] Batch [1020]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.094496,	
2017-07-13 01:57:31,182 Epoch[48] Batch [1030]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.094392,	
2017-07-13 01:57:35,753 Epoch[48] Batch [1040]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.094348,	
2017-07-13 01:57:40,672 Epoch[48] Batch [1050]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.094252,	
2017-07-13 01:57:46,021 Epoch[48] Batch [1060]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094153,	
2017-07-13 01:57:50,938 Epoch[48] Batch [1070]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.094123,	
2017-07-13 01:57:56,058 Epoch[48] Batch [1080]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094060,	
2017-07-13 01:58:01,422 Epoch[48] Batch [1090]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093963,	
2017-07-13 01:58:06,113 Epoch[48] Batch [1100]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.093892,	
2017-07-13 01:58:11,281 Epoch[48] Batch [1110]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093771,	
2017-07-13 01:58:16,268 Epoch[48] Batch [1120]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.093640,	
2017-07-13 01:58:21,096 Epoch[48] Batch [1130]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.093594,	
2017-07-13 01:58:25,952 Epoch[48] Batch [1140]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.093578,	
2017-07-13 01:58:30,828 Epoch[48] Batch [1150]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.093522,	
2017-07-13 01:58:35,447 Epoch[48] Batch [1160]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.093427,	
2017-07-13 01:58:40,119 Epoch[48] Batch [1170]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.093370,	
2017-07-13 01:58:44,777 Epoch[48] Batch [1180]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.093295,	
2017-07-13 01:58:49,280 Epoch[48] Batch [1190]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.093208,	
2017-07-13 01:58:54,313 Epoch[48] Batch [1200]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.093149,	
2017-07-13 01:58:59,131 Epoch[48] Batch [1210]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.093087,	
2017-07-13 01:59:03,888 Epoch[48] Batch [1220]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092953,	
2017-07-13 01:59:08,586 Epoch[48] Batch [1230]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.092944,	
2017-07-13 01:59:13,073 Epoch[48] Batch [1240]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.092935,	
2017-07-13 01:59:17,894 Epoch[48] Batch [1250]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092900,	
2017-07-13 01:59:22,306 Epoch[48] Batch [1260]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.092849,	
2017-07-13 01:59:26,747 Epoch[48] Batch [1270]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.092836,	
2017-07-13 01:59:31,262 Epoch[48] Batch [1280]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092734,	
2017-07-13 01:59:36,085 Epoch[48] Batch [1290]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092610,	
2017-07-13 01:59:40,900 Epoch[48] Batch [1300]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092541,	
2017-07-13 01:59:45,714 Epoch[48] Batch [1310]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092499,	
2017-07-13 01:59:50,211 Epoch[48] Batch [1320]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.092469,	
2017-07-13 01:59:54,846 Epoch[48] Batch [1330]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.092466,	
2017-07-13 02:00:00,095 Epoch[48] Batch [1340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.092394,	
2017-07-13 02:00:04,450 Epoch[48] Batch [1350]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.092418,	
2017-07-13 02:00:09,140 Epoch[48] Batch [1360]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092376,	
2017-07-13 02:00:13,578 Epoch[48] Batch [1370]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.092419,	
2017-07-13 02:00:18,238 Epoch[48] Batch [1380]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.092420,	
2017-07-13 02:00:23,031 Epoch[48] Batch [1390]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092460,	
2017-07-13 02:00:27,572 Epoch[48] Batch [1400]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092488,	
2017-07-13 02:00:32,296 Epoch[48] Batch [1410]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092389,	
2017-07-13 02:00:37,244 Epoch[48] Batch [1420]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.092356,	
2017-07-13 02:00:41,843 Epoch[48] Batch [1430]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092307,	
2017-07-13 02:00:46,741 Epoch[48] Batch [1440]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.092252,	
2017-07-13 02:00:52,133 Epoch[48] Batch [1450]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092214,	
2017-07-13 02:00:56,950 Epoch[48] Batch [1460]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.092231,	
2017-07-13 02:01:02,039 Epoch[48] Batch [1470]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.092214,	
2017-07-13 02:01:06,731 Epoch[48] Batch [1480]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092195,	
2017-07-13 02:01:09,498 Epoch[48] Train-FCNLogLoss=0.092180
2017-07-13 02:01:09,498 Epoch[48] Time cost=751.809
2017-07-13 02:01:10,345 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0049.params"
2017-07-13 02:01:14,916 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0049.states"
2017-07-13 02:01:21,060 Epoch[49] Batch [10]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.084977,	
2017-07-13 02:01:25,979 Epoch[49] Batch [20]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.085423,	
2017-07-13 02:01:30,542 Epoch[49] Batch [30]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.085804,	
2017-07-13 02:01:35,374 Epoch[49] Batch [40]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.084679,	
2017-07-13 02:01:40,267 Epoch[49] Batch [50]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.082455,	
2017-07-13 02:01:44,817 Epoch[49] Batch [60]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.081917,	
2017-07-13 02:01:49,576 Epoch[49] Batch [70]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.082360,	
2017-07-13 02:01:54,902 Epoch[49] Batch [80]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.081987,	
2017-07-13 02:02:00,310 Epoch[49] Batch [90]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.081017,	
2017-07-13 02:02:06,115 Epoch[49] Batch [100]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.081143,	
2017-07-13 02:02:11,162 Epoch[49] Batch [110]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.081054,	
2017-07-13 02:02:16,191 Epoch[49] Batch [120]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.081754,	
2017-07-13 02:02:21,929 Epoch[49] Batch [130]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.081967,	
2017-07-13 02:02:27,343 Epoch[49] Batch [140]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.082216,	
2017-07-13 02:02:32,453 Epoch[49] Batch [150]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.082190,	
2017-07-13 02:02:37,494 Epoch[49] Batch [160]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.082030,	
2017-07-13 02:02:42,283 Epoch[49] Batch [170]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.082136,	
2017-07-13 02:02:47,182 Epoch[49] Batch [180]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.082149,	
2017-07-13 02:02:52,050 Epoch[49] Batch [190]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.082429,	
2017-07-13 02:02:57,544 Epoch[49] Batch [200]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.082618,	
2017-07-13 02:03:02,811 Epoch[49] Batch [210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.082490,	
2017-07-13 02:03:07,695 Epoch[49] Batch [220]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.082389,	
2017-07-13 02:03:12,672 Epoch[49] Batch [230]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.082595,	
2017-07-13 02:03:17,429 Epoch[49] Batch [240]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.082757,	
2017-07-13 02:03:22,351 Epoch[49] Batch [250]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.082815,	
2017-07-13 02:03:27,131 Epoch[49] Batch [260]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.082618,	
2017-07-13 02:03:32,165 Epoch[49] Batch [270]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.082763,	
2017-07-13 02:03:36,949 Epoch[49] Batch [280]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.083019,	
2017-07-13 02:03:41,801 Epoch[49] Batch [290]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.083413,	
2017-07-13 02:03:46,993 Epoch[49] Batch [300]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.083495,	
2017-07-13 02:03:51,919 Epoch[49] Batch [310]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.083486,	
2017-07-13 02:03:56,830 Epoch[49] Batch [320]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.083505,	
2017-07-13 02:04:01,441 Epoch[49] Batch [330]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.083531,	
2017-07-13 02:04:06,273 Epoch[49] Batch [340]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.083499,	
2017-07-13 02:04:11,236 Epoch[49] Batch [350]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.083503,	
2017-07-13 02:04:16,226 Epoch[49] Batch [360]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.083369,	
2017-07-13 02:04:21,011 Epoch[49] Batch [370]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.083275,	
2017-07-13 02:04:25,682 Epoch[49] Batch [380]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.083434,	
2017-07-13 02:04:30,581 Epoch[49] Batch [390]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.083442,	
2017-07-13 02:04:35,610 Epoch[49] Batch [400]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.083641,	
2017-07-13 02:04:40,584 Epoch[49] Batch [410]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.083653,	
2017-07-13 02:04:45,516 Epoch[49] Batch [420]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.083556,	
2017-07-13 02:04:50,448 Epoch[49] Batch [430]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.083544,	
2017-07-13 02:04:55,453 Epoch[49] Batch [440]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.083571,	
2017-07-13 02:05:01,229 Epoch[49] Batch [450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.083547,	
2017-07-13 02:05:06,620 Epoch[49] Batch [460]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.083760,	
2017-07-13 02:05:11,747 Epoch[49] Batch [470]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.083835,	
2017-07-13 02:05:16,615 Epoch[49] Batch [480]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.083807,	
2017-07-13 02:05:21,708 Epoch[49] Batch [490]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.083991,	
2017-07-13 02:05:26,913 Epoch[49] Batch [500]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.083848,	
2017-07-13 02:05:32,277 Epoch[49] Batch [510]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.083808,	
2017-07-13 02:05:37,611 Epoch[49] Batch [520]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.083866,	
2017-07-13 02:05:42,916 Epoch[49] Batch [530]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.083998,	
2017-07-13 02:05:48,012 Epoch[49] Batch [540]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.084105,	
2017-07-13 02:05:52,962 Epoch[49] Batch [550]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.084058,	
2017-07-13 02:05:58,153 Epoch[49] Batch [560]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.083934,	
2017-07-13 02:06:03,397 Epoch[49] Batch [570]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.084001,	
2017-07-13 02:06:08,504 Epoch[49] Batch [580]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.083917,	
2017-07-13 02:06:13,933 Epoch[49] Batch [590]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.083916,	
2017-07-13 02:06:19,137 Epoch[49] Batch [600]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.083900,	
2017-07-13 02:06:24,618 Epoch[49] Batch [610]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.083845,	
2017-07-13 02:06:29,979 Epoch[49] Batch [620]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.083787,	
2017-07-13 02:06:35,587 Epoch[49] Batch [630]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.083796,	
2017-07-13 02:06:41,481 Epoch[49] Batch [640]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.083857,	
2017-07-13 02:06:46,756 Epoch[49] Batch [650]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.083850,	
2017-07-13 02:06:51,813 Epoch[49] Batch [660]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.083918,	
2017-07-13 02:06:57,095 Epoch[49] Batch [670]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.083969,	
2017-07-13 02:07:03,258 Epoch[49] Batch [680]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.084079,	
2017-07-13 02:07:09,466 Epoch[49] Batch [690]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.084221,	
2017-07-13 02:07:15,454 Epoch[49] Batch [700]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.084116,	
2017-07-13 02:07:20,804 Epoch[49] Batch [710]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.084236,	
2017-07-13 02:07:26,558 Epoch[49] Batch [720]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.084297,	
2017-07-13 02:07:32,531 Epoch[49] Batch [730]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.084355,	
2017-07-13 02:07:38,178 Epoch[49] Batch [740]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.084351,	
2017-07-13 02:07:43,460 Epoch[49] Batch [750]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.084402,	
2017-07-13 02:07:49,157 Epoch[49] Batch [760]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.084440,	
2017-07-13 02:07:54,508 Epoch[49] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.084420,	
2017-07-13 02:08:00,012 Epoch[49] Batch [780]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.084425,	
2017-07-13 02:08:05,641 Epoch[49] Batch [790]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.084353,	
2017-07-13 02:08:10,843 Epoch[49] Batch [800]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.084390,	
2017-07-13 02:08:15,932 Epoch[49] Batch [810]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.084434,	
2017-07-13 02:08:21,621 Epoch[49] Batch [820]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.084392,	
2017-07-13 02:08:27,444 Epoch[49] Batch [830]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.084410,	
2017-07-13 02:08:32,896 Epoch[49] Batch [840]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.084536,	
2017-07-13 02:08:38,582 Epoch[49] Batch [850]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.084508,	
2017-07-13 02:08:44,204 Epoch[49] Batch [860]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.084496,	
2017-07-13 02:08:50,073 Epoch[49] Batch [870]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.084507,	
2017-07-13 02:08:55,638 Epoch[49] Batch [880]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.084379,	
2017-07-13 02:09:00,752 Epoch[49] Batch [890]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.084392,	
2017-07-13 02:09:05,925 Epoch[49] Batch [900]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.084432,	
2017-07-13 02:09:11,205 Epoch[49] Batch [910]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.084512,	
2017-07-13 02:09:16,836 Epoch[49] Batch [920]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.084524,	
2017-07-13 02:09:22,581 Epoch[49] Batch [930]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.084566,	
2017-07-13 02:09:27,703 Epoch[49] Batch [940]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.084560,	
2017-07-13 02:09:33,314 Epoch[49] Batch [950]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.084586,	
2017-07-13 02:09:38,178 Epoch[49] Batch [960]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.084624,	
2017-07-13 02:09:43,159 Epoch[49] Batch [970]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.084605,	
2017-07-13 02:09:48,283 Epoch[49] Batch [980]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.084633,	
2017-07-13 02:09:53,866 Epoch[49] Batch [990]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.084695,	
2017-07-13 02:09:58,963 Epoch[49] Batch [1000]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.084647,	
2017-07-13 02:10:04,053 Epoch[49] Batch [1010]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.084604,	
2017-07-13 02:10:09,255 Epoch[49] Batch [1020]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.084580,	
2017-07-13 02:10:15,027 Epoch[49] Batch [1030]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.084539,	
2017-07-13 02:10:20,876 Epoch[49] Batch [1040]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.084585,	
2017-07-13 02:10:26,504 Epoch[49] Batch [1050]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.084620,	
2017-07-13 02:10:32,602 Epoch[49] Batch [1060]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.084643,	
2017-07-13 02:10:38,224 Epoch[49] Batch [1070]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.084690,	
2017-07-13 02:10:43,827 Epoch[49] Batch [1080]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.084662,	
2017-07-13 02:10:49,482 Epoch[49] Batch [1090]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.084701,	
2017-07-13 02:10:55,268 Epoch[49] Batch [1100]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.084705,	
2017-07-13 02:11:00,865 Epoch[49] Batch [1110]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.084763,	
2017-07-13 02:11:06,758 Epoch[49] Batch [1120]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.084785,	
2017-07-13 02:11:12,370 Epoch[49] Batch [1130]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.084765,	
2017-07-13 02:11:18,137 Epoch[49] Batch [1140]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.084734,	
2017-07-13 02:11:23,730 Epoch[49] Batch [1150]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.084719,	
2017-07-13 02:11:29,797 Epoch[49] Batch [1160]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.084794,	
2017-07-13 02:11:35,527 Epoch[49] Batch [1170]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.084809,	
2017-07-13 02:11:41,701 Epoch[49] Batch [1180]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.084812,	
2017-07-13 02:11:47,368 Epoch[49] Batch [1190]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.084859,	
2017-07-13 02:11:52,562 Epoch[49] Batch [1200]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.085211,	
2017-07-13 02:11:57,891 Epoch[49] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.085390,	
2017-07-13 02:12:02,941 Epoch[49] Batch [1220]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.085845,	
2017-07-13 02:12:08,039 Epoch[49] Batch [1230]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.086782,	
2017-07-13 02:12:13,385 Epoch[49] Batch [1240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087036,	
2017-07-13 02:12:18,419 Epoch[49] Batch [1250]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087303,	
2017-07-13 02:12:23,379 Epoch[49] Batch [1260]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.087545,	
2017-07-13 02:12:28,258 Epoch[49] Batch [1270]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.087588,	
2017-07-13 02:12:33,302 Epoch[49] Batch [1280]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087639,	
2017-07-13 02:12:38,282 Epoch[49] Batch [1290]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.088030,	
2017-07-13 02:12:43,149 Epoch[49] Batch [1300]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.088185,	
2017-07-13 02:12:48,814 Epoch[49] Batch [1310]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.088314,	
2017-07-13 02:12:54,166 Epoch[49] Batch [1320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088383,	
2017-07-13 02:12:59,479 Epoch[49] Batch [1330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088479,	
2017-07-13 02:13:04,418 Epoch[49] Batch [1340]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.088533,	
2017-07-13 02:13:09,661 Epoch[49] Batch [1350]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088592,	
2017-07-13 02:13:14,760 Epoch[49] Batch [1360]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088562,	
2017-07-13 02:13:19,312 Epoch[49] Batch [1370]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088589,	
2017-07-13 02:13:24,473 Epoch[49] Batch [1380]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088595,	
2017-07-13 02:13:30,030 Epoch[49] Batch [1390]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088586,	
2017-07-13 02:13:35,187 Epoch[49] Batch [1400]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088602,	
2017-07-13 02:13:40,959 Epoch[49] Batch [1410]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088651,	
2017-07-13 02:13:46,860 Epoch[49] Batch [1420]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.088646,	
2017-07-13 02:13:52,545 Epoch[49] Batch [1430]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088657,	
2017-07-13 02:13:57,387 Epoch[49] Batch [1440]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088718,	
2017-07-13 02:14:02,005 Epoch[49] Batch [1450]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088739,	
2017-07-13 02:14:06,721 Epoch[49] Batch [1460]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088730,	
2017-07-13 02:14:11,692 Epoch[49] Batch [1470]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088768,	
2017-07-13 02:14:16,578 Epoch[49] Batch [1480]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088723,	
2017-07-13 02:14:19,463 Epoch[49] Train-FCNLogLoss=0.088700
2017-07-13 02:14:19,463 Epoch[49] Time cost=784.547
2017-07-13 02:14:20,278 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0050.params"
2017-07-13 02:14:23,799 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0050.states"
2017-07-13 02:14:29,532 Epoch[50] Batch [10]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.085306,	
2017-07-13 02:14:34,285 Epoch[50] Batch [20]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.084145,	
2017-07-13 02:14:39,141 Epoch[50] Batch [30]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.085130,	
2017-07-13 02:14:44,281 Epoch[50] Batch [40]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.083909,	
2017-07-13 02:14:49,480 Epoch[50] Batch [50]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.084382,	
2017-07-13 02:14:54,622 Epoch[50] Batch [60]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.085755,	
2017-07-13 02:14:59,766 Epoch[50] Batch [70]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.086303,	
2017-07-13 02:15:04,639 Epoch[50] Batch [80]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.086430,	
2017-07-13 02:15:09,345 Epoch[50] Batch [90]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.086685,	
2017-07-13 02:15:14,090 Epoch[50] Batch [100]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087778,	
2017-07-13 02:15:18,871 Epoch[50] Batch [110]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089265,	
2017-07-13 02:15:23,879 Epoch[50] Batch [120]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089574,	
2017-07-13 02:15:28,790 Epoch[50] Batch [130]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089654,	
2017-07-13 02:15:33,847 Epoch[50] Batch [140]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089482,	
2017-07-13 02:15:38,853 Epoch[50] Batch [150]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088874,	
2017-07-13 02:15:43,575 Epoch[50] Batch [160]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088567,	
2017-07-13 02:15:49,011 Epoch[50] Batch [170]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088333,	
2017-07-13 02:15:53,837 Epoch[50] Batch [180]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088595,	
2017-07-13 02:15:58,894 Epoch[50] Batch [190]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088127,	
2017-07-13 02:16:04,081 Epoch[50] Batch [200]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088110,	
2017-07-13 02:16:09,067 Epoch[50] Batch [210]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.087695,	
2017-07-13 02:16:13,818 Epoch[50] Batch [220]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087635,	
2017-07-13 02:16:18,762 Epoch[50] Batch [230]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.087891,	
2017-07-13 02:16:23,694 Epoch[50] Batch [240]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.087382,	
2017-07-13 02:16:28,854 Epoch[50] Batch [250]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087293,	
2017-07-13 02:16:34,375 Epoch[50] Batch [260]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.087331,	
2017-07-13 02:16:39,969 Epoch[50] Batch [270]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087512,	
2017-07-13 02:16:44,901 Epoch[50] Batch [280]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.087541,	
2017-07-13 02:16:50,545 Epoch[50] Batch [290]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.087827,	
2017-07-13 02:16:56,013 Epoch[50] Batch [300]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.087821,	
2017-07-13 02:17:01,602 Epoch[50] Batch [310]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.087856,	
2017-07-13 02:17:06,446 Epoch[50] Batch [320]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088170,	
2017-07-13 02:17:11,119 Epoch[50] Batch [330]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088103,	
2017-07-13 02:17:16,224 Epoch[50] Batch [340]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088125,	
2017-07-13 02:17:21,760 Epoch[50] Batch [350]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.087923,	
2017-07-13 02:17:27,222 Epoch[50] Batch [360]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.087628,	
2017-07-13 02:17:32,307 Epoch[50] Batch [370]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087392,	
2017-07-13 02:17:37,106 Epoch[50] Batch [380]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.087227,	
2017-07-13 02:17:42,311 Epoch[50] Batch [390]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087320,	
2017-07-13 02:17:47,025 Epoch[50] Batch [400]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087199,	
2017-07-13 02:17:52,412 Epoch[50] Batch [410]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.087260,	
2017-07-13 02:17:57,623 Epoch[50] Batch [420]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087217,	
2017-07-13 02:18:03,332 Epoch[50] Batch [430]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.087392,	
2017-07-13 02:18:09,236 Epoch[50] Batch [440]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087314,	
2017-07-13 02:18:14,471 Epoch[50] Batch [450]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087262,	
2017-07-13 02:18:19,915 Epoch[50] Batch [460]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.087291,	
2017-07-13 02:18:26,275 Epoch[50] Batch [470]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087291,	
2017-07-13 02:18:31,227 Epoch[50] Batch [480]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087257,	
2017-07-13 02:18:36,151 Epoch[50] Batch [490]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.087190,	
2017-07-13 02:18:41,106 Epoch[50] Batch [500]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.087304,	
2017-07-13 02:18:46,248 Epoch[50] Batch [510]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.087433,	
2017-07-13 02:18:51,169 Epoch[50] Batch [520]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.087166,	
2017-07-13 02:18:56,063 Epoch[50] Batch [530]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087231,	
2017-07-13 02:19:01,546 Epoch[50] Batch [540]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.087431,	
2017-07-13 02:19:06,960 Epoch[50] Batch [550]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.087467,	
2017-07-13 02:19:11,829 Epoch[50] Batch [560]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.087459,	
2017-07-13 02:19:16,598 Epoch[50] Batch [570]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.087559,	
2017-07-13 02:19:21,666 Epoch[50] Batch [580]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.087681,	
2017-07-13 02:19:26,708 Epoch[50] Batch [590]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.087872,	
2017-07-13 02:19:31,960 Epoch[50] Batch [600]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087958,	
2017-07-13 02:19:37,534 Epoch[50] Batch [610]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088250,	
2017-07-13 02:19:43,048 Epoch[50] Batch [620]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.088417,	
2017-07-13 02:19:48,470 Epoch[50] Batch [630]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.088496,	
2017-07-13 02:19:54,174 Epoch[50] Batch [640]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088517,	
2017-07-13 02:19:59,189 Epoch[50] Batch [650]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088479,	
2017-07-13 02:20:04,572 Epoch[50] Batch [660]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088519,	
2017-07-13 02:20:10,389 Epoch[50] Batch [670]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088578,	
2017-07-13 02:20:15,330 Epoch[50] Batch [680]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.088482,	
2017-07-13 02:20:20,657 Epoch[50] Batch [690]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088446,	
2017-07-13 02:20:25,478 Epoch[50] Batch [700]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088534,	
2017-07-13 02:20:30,504 Epoch[50] Batch [710]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088608,	
2017-07-13 02:20:35,398 Epoch[50] Batch [720]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088627,	
2017-07-13 02:20:40,206 Epoch[50] Batch [730]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.088632,	
2017-07-13 02:20:45,376 Epoch[50] Batch [740]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.088434,	
2017-07-13 02:20:50,284 Epoch[50] Batch [750]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.088491,	
2017-07-13 02:20:55,110 Epoch[50] Batch [760]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.088547,	
2017-07-13 02:21:00,424 Epoch[50] Batch [770]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088495,	
2017-07-13 02:21:06,056 Epoch[50] Batch [780]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.088553,	
2017-07-13 02:21:11,616 Epoch[50] Batch [790]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088572,	
2017-07-13 02:21:16,714 Epoch[50] Batch [800]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088548,	
2017-07-13 02:21:21,852 Epoch[50] Batch [810]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088539,	
2017-07-13 02:21:26,875 Epoch[50] Batch [820]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088520,	
2017-07-13 02:21:31,604 Epoch[50] Batch [830]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.088454,	
2017-07-13 02:21:36,706 Epoch[50] Batch [840]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088437,	
2017-07-13 02:21:42,084 Epoch[50] Batch [850]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088407,	
2017-07-13 02:21:46,996 Epoch[50] Batch [860]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088425,	
2017-07-13 02:21:51,706 Epoch[50] Batch [870]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088455,	
2017-07-13 02:21:56,297 Epoch[50] Batch [880]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088442,	
2017-07-13 02:22:01,242 Epoch[50] Batch [890]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.088391,	
2017-07-13 02:22:06,504 Epoch[50] Batch [900]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088478,	
2017-07-13 02:22:11,587 Epoch[50] Batch [910]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088425,	
2017-07-13 02:22:16,296 Epoch[50] Batch [920]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088340,	
2017-07-13 02:22:21,799 Epoch[50] Batch [930]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.088352,	
2017-07-13 02:22:27,379 Epoch[50] Batch [940]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088191,	
2017-07-13 02:22:32,514 Epoch[50] Batch [950]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088165,	
2017-07-13 02:22:37,367 Epoch[50] Batch [960]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088167,	
2017-07-13 02:22:42,407 Epoch[50] Batch [970]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088149,	
2017-07-13 02:22:47,149 Epoch[50] Batch [980]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088038,	
2017-07-13 02:22:52,240 Epoch[50] Batch [990]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.088010,	
2017-07-13 02:22:57,161 Epoch[50] Batch [1000]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.087913,	
2017-07-13 02:23:02,991 Epoch[50] Batch [1010]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087929,	
2017-07-13 02:23:08,075 Epoch[50] Batch [1020]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.087916,	
2017-07-13 02:23:13,579 Epoch[50] Batch [1030]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.087956,	
2017-07-13 02:23:19,028 Epoch[50] Batch [1040]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.088001,	
2017-07-13 02:23:23,863 Epoch[50] Batch [1050]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088087,	
2017-07-13 02:23:28,706 Epoch[50] Batch [1060]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088130,	
2017-07-13 02:23:33,537 Epoch[50] Batch [1070]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088115,	
2017-07-13 02:23:38,262 Epoch[50] Batch [1080]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088066,	
2017-07-13 02:23:43,267 Epoch[50] Batch [1090]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.088116,	
2017-07-13 02:23:47,984 Epoch[50] Batch [1100]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088153,	
2017-07-13 02:23:53,006 Epoch[50] Batch [1110]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.088119,	
2017-07-13 02:23:57,861 Epoch[50] Batch [1120]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088057,	
2017-07-13 02:24:02,825 Epoch[50] Batch [1130]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.088013,	
2017-07-13 02:24:07,860 Epoch[50] Batch [1140]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.087992,	
2017-07-13 02:24:12,934 Epoch[50] Batch [1150]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.087948,	
2017-07-13 02:24:17,802 Epoch[50] Batch [1160]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.087957,	
2017-07-13 02:24:22,714 Epoch[50] Batch [1170]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.087841,	
2017-07-13 02:24:27,983 Epoch[50] Batch [1180]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087794,	
2017-07-13 02:24:33,533 Epoch[50] Batch [1190]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087815,	
2017-07-13 02:24:38,413 Epoch[50] Batch [1200]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.087777,	
2017-07-13 02:24:43,610 Epoch[50] Batch [1210]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087752,	
2017-07-13 02:24:48,478 Epoch[50] Batch [1220]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.087725,	
2017-07-13 02:24:53,302 Epoch[50] Batch [1230]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.087688,	
2017-07-13 02:24:58,352 Epoch[50] Batch [1240]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087633,	
2017-07-13 02:25:03,091 Epoch[50] Batch [1250]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087656,	
2017-07-13 02:25:08,248 Epoch[50] Batch [1260]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.087636,	
2017-07-13 02:25:13,221 Epoch[50] Batch [1270]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.087718,	
2017-07-13 02:25:18,121 Epoch[50] Batch [1280]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.087635,	
2017-07-13 02:25:23,183 Epoch[50] Batch [1290]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.087579,	
2017-07-13 02:25:28,417 Epoch[50] Batch [1300]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.087574,	
2017-07-13 02:25:33,076 Epoch[50] Batch [1310]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.087499,	
2017-07-13 02:25:38,357 Epoch[50] Batch [1320]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087511,	
2017-07-13 02:25:43,221 Epoch[50] Batch [1330]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.087451,	
2017-07-13 02:25:47,919 Epoch[50] Batch [1340]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087422,	
2017-07-13 02:25:52,837 Epoch[50] Batch [1350]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.087476,	
2017-07-13 02:25:58,144 Epoch[50] Batch [1360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087457,	
2017-07-13 02:26:02,693 Epoch[50] Batch [1370]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.087418,	
2017-07-13 02:26:07,307 Epoch[50] Batch [1380]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087402,	
2017-07-13 02:26:12,640 Epoch[50] Batch [1390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087371,	
2017-07-13 02:26:18,514 Epoch[50] Batch [1400]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087302,	
2017-07-13 02:26:24,133 Epoch[50] Batch [1410]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.087357,	
2017-07-13 02:26:28,907 Epoch[50] Batch [1420]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.087330,	
2017-07-13 02:26:34,433 Epoch[50] Batch [1430]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.087354,	
2017-07-13 02:26:39,991 Epoch[50] Batch [1440]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.087378,	
2017-07-13 02:26:45,167 Epoch[50] Batch [1450]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087370,	
2017-07-13 02:26:50,991 Epoch[50] Batch [1460]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.087343,	
2017-07-13 02:26:56,327 Epoch[50] Batch [1470]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087323,	
2017-07-13 02:27:01,838 Epoch[50] Batch [1480]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.087301,	
2017-07-13 02:27:04,744 Epoch[50] Train-FCNLogLoss=0.087264
2017-07-13 02:27:04,744 Epoch[50] Time cost=760.945
2017-07-13 02:27:05,668 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0051.params"
2017-07-13 02:27:09,337 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0051.states"
2017-07-13 02:27:15,226 Epoch[51] Batch [10]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.081021,	
2017-07-13 02:27:20,113 Epoch[51] Batch [20]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.084429,	
2017-07-13 02:27:25,765 Epoch[51] Batch [30]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086974,	
2017-07-13 02:27:30,817 Epoch[51] Batch [40]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.085607,	
2017-07-13 02:27:35,998 Epoch[51] Batch [50]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.086555,	
2017-07-13 02:27:41,155 Epoch[51] Batch [60]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.085468,	
2017-07-13 02:27:46,012 Epoch[51] Batch [70]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.084822,	
2017-07-13 02:27:51,527 Epoch[51] Batch [80]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.085105,	
2017-07-13 02:27:56,820 Epoch[51] Batch [90]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.086241,	
2017-07-13 02:28:01,817 Epoch[51] Batch [100]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.085585,	
2017-07-13 02:28:06,621 Epoch[51] Batch [110]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.085572,	
2017-07-13 02:28:11,982 Epoch[51] Batch [120]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.085656,	
2017-07-13 02:28:17,743 Epoch[51] Batch [130]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.085292,	
2017-07-13 02:28:23,200 Epoch[51] Batch [140]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.084730,	
2017-07-13 02:28:28,350 Epoch[51] Batch [150]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.084671,	
2017-07-13 02:28:33,753 Epoch[51] Batch [160]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.084534,	
2017-07-13 02:28:39,136 Epoch[51] Batch [170]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.084196,	
2017-07-13 02:28:44,949 Epoch[51] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.083907,	
2017-07-13 02:28:50,067 Epoch[51] Batch [190]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.083967,	
2017-07-13 02:28:55,050 Epoch[51] Batch [200]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.083726,	
2017-07-13 02:29:00,415 Epoch[51] Batch [210]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.083734,	
2017-07-13 02:29:05,686 Epoch[51] Batch [220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.083852,	
2017-07-13 02:29:10,706 Epoch[51] Batch [230]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.084054,	
2017-07-13 02:29:15,970 Epoch[51] Batch [240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.083889,	
2017-07-13 02:29:21,579 Epoch[51] Batch [250]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.083995,	
2017-07-13 02:29:28,126 Epoch[51] Batch [260]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.083891,	
2017-07-13 02:29:33,786 Epoch[51] Batch [270]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.083939,	
2017-07-13 02:29:39,365 Epoch[51] Batch [280]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.084206,	
2017-07-13 02:29:44,375 Epoch[51] Batch [290]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.084483,	
2017-07-13 02:29:49,254 Epoch[51] Batch [300]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.085000,	
2017-07-13 02:29:54,364 Epoch[51] Batch [310]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.084852,	
2017-07-13 02:29:59,478 Epoch[51] Batch [320]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.084905,	
2017-07-13 02:30:04,162 Epoch[51] Batch [330]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.084789,	
2017-07-13 02:30:09,636 Epoch[51] Batch [340]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.084790,	
2017-07-13 02:30:14,837 Epoch[51] Batch [350]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.084836,	
2017-07-13 02:30:19,896 Epoch[51] Batch [360]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.084707,	
2017-07-13 02:30:25,368 Epoch[51] Batch [370]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.084536,	
2017-07-13 02:30:30,789 Epoch[51] Batch [380]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.084360,	
2017-07-13 02:30:36,065 Epoch[51] Batch [390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.084299,	
2017-07-13 02:30:41,187 Epoch[51] Batch [400]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.084248,	
2017-07-13 02:30:46,076 Epoch[51] Batch [410]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.084262,	
2017-07-13 02:30:51,274 Epoch[51] Batch [420]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.084316,	
2017-07-13 02:30:56,786 Epoch[51] Batch [430]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.084129,	
2017-07-13 02:31:02,888 Epoch[51] Batch [440]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.084044,	
2017-07-13 02:31:08,489 Epoch[51] Batch [450]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.084248,	
2017-07-13 02:31:14,099 Epoch[51] Batch [460]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.084083,	
2017-07-13 02:31:19,638 Epoch[51] Batch [470]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.084078,	
2017-07-13 02:31:24,968 Epoch[51] Batch [480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.083950,	
2017-07-13 02:31:30,807 Epoch[51] Batch [490]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.084040,	
2017-07-13 02:31:36,446 Epoch[51] Batch [500]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.084107,	
2017-07-13 02:31:42,029 Epoch[51] Batch [510]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.084197,	
2017-07-13 02:31:47,504 Epoch[51] Batch [520]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.084243,	
2017-07-13 02:31:53,432 Epoch[51] Batch [530]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.084511,	
2017-07-13 02:31:59,143 Epoch[51] Batch [540]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.084662,	
2017-07-13 02:32:04,681 Epoch[51] Batch [550]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.084927,	
2017-07-13 02:32:10,064 Epoch[51] Batch [560]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.084968,	
2017-07-13 02:32:15,610 Epoch[51] Batch [570]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.085167,	
2017-07-13 02:32:21,144 Epoch[51] Batch [580]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.085141,	
2017-07-13 02:32:26,448 Epoch[51] Batch [590]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.085216,	
2017-07-13 02:32:31,900 Epoch[51] Batch [600]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.085125,	
2017-07-13 02:32:37,742 Epoch[51] Batch [610]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085266,	
2017-07-13 02:32:43,551 Epoch[51] Batch [620]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.085400,	
2017-07-13 02:32:49,334 Epoch[51] Batch [630]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085559,	
2017-07-13 02:32:54,837 Epoch[51] Batch [640]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.085539,	
2017-07-13 02:32:59,882 Epoch[51] Batch [650]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.085617,	
2017-07-13 02:33:04,948 Epoch[51] Batch [660]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.085615,	
2017-07-13 02:33:10,041 Epoch[51] Batch [670]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.085630,	
2017-07-13 02:33:16,102 Epoch[51] Batch [680]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.085663,	
2017-07-13 02:33:21,260 Epoch[51] Batch [690]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.085631,	
2017-07-13 02:33:26,417 Epoch[51] Batch [700]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.085481,	
2017-07-13 02:33:31,217 Epoch[51] Batch [710]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.085442,	
2017-07-13 02:33:36,622 Epoch[51] Batch [720]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.085384,	
2017-07-13 02:33:42,474 Epoch[51] Batch [730]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085507,	
2017-07-13 02:33:47,507 Epoch[51] Batch [740]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.085528,	
2017-07-13 02:33:52,620 Epoch[51] Batch [750]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.085401,	
2017-07-13 02:33:57,917 Epoch[51] Batch [760]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.085317,	
2017-07-13 02:34:02,887 Epoch[51] Batch [770]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.085356,	
2017-07-13 02:34:08,624 Epoch[51] Batch [780]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.085382,	
2017-07-13 02:34:14,395 Epoch[51] Batch [790]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085303,	
2017-07-13 02:34:19,598 Epoch[51] Batch [800]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.085386,	
2017-07-13 02:34:25,345 Epoch[51] Batch [810]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.085408,	
2017-07-13 02:34:30,751 Epoch[51] Batch [820]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.085319,	
2017-07-13 02:34:36,283 Epoch[51] Batch [830]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.085300,	
2017-07-13 02:34:42,161 Epoch[51] Batch [840]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.085227,	
2017-07-13 02:34:47,516 Epoch[51] Batch [850]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.085091,	
2017-07-13 02:34:53,021 Epoch[51] Batch [860]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.085172,	
2017-07-13 02:34:58,843 Epoch[51] Batch [870]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.085116,	
2017-07-13 02:35:04,752 Epoch[51] Batch [880]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085015,	
2017-07-13 02:35:10,377 Epoch[51] Batch [890]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.084942,	
2017-07-13 02:35:15,464 Epoch[51] Batch [900]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.084889,	
2017-07-13 02:35:20,495 Epoch[51] Batch [910]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.084884,	
2017-07-13 02:35:25,850 Epoch[51] Batch [920]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.084779,	
2017-07-13 02:35:31,307 Epoch[51] Batch [930]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.084897,	
2017-07-13 02:35:36,769 Epoch[51] Batch [940]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.084988,	
2017-07-13 02:35:42,263 Epoch[51] Batch [950]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.085092,	
2017-07-13 02:35:47,417 Epoch[51] Batch [960]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.085071,	
2017-07-13 02:35:52,438 Epoch[51] Batch [970]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.085060,	
2017-07-13 02:35:58,108 Epoch[51] Batch [980]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.085108,	
2017-07-13 02:36:03,361 Epoch[51] Batch [990]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.085118,	
2017-07-13 02:36:08,492 Epoch[51] Batch [1000]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.085107,	
2017-07-13 02:36:13,463 Epoch[51] Batch [1010]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.085139,	
2017-07-13 02:36:18,612 Epoch[51] Batch [1020]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.085116,	
2017-07-13 02:36:23,846 Epoch[51] Batch [1030]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.085043,	
2017-07-13 02:36:29,096 Epoch[51] Batch [1040]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.085048,	
2017-07-13 02:36:34,189 Epoch[51] Batch [1050]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.085003,	
2017-07-13 02:36:39,290 Epoch[51] Batch [1060]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.085029,	
2017-07-13 02:36:44,853 Epoch[51] Batch [1070]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.084958,	
2017-07-13 02:36:50,290 Epoch[51] Batch [1080]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085012,	
2017-07-13 02:36:55,436 Epoch[51] Batch [1090]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.085033,	
2017-07-13 02:37:00,344 Epoch[51] Batch [1100]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.085046,	
2017-07-13 02:37:05,102 Epoch[51] Batch [1110]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.085010,	
2017-07-13 02:37:10,052 Epoch[51] Batch [1120]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.085004,	
2017-07-13 02:37:15,068 Epoch[51] Batch [1130]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.085043,	
2017-07-13 02:37:20,420 Epoch[51] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.085078,	
2017-07-13 02:37:26,407 Epoch[51] Batch [1150]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.085051,	
2017-07-13 02:37:31,456 Epoch[51] Batch [1160]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.085056,	
2017-07-13 02:37:36,868 Epoch[51] Batch [1170]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.085041,	
2017-07-13 02:37:41,855 Epoch[51] Batch [1180]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.085124,	
2017-07-13 02:37:46,836 Epoch[51] Batch [1190]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.085126,	
2017-07-13 02:37:51,852 Epoch[51] Batch [1200]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.085176,	
2017-07-13 02:37:56,719 Epoch[51] Batch [1210]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.085261,	
2017-07-13 02:38:02,089 Epoch[51] Batch [1220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.085240,	
2017-07-13 02:38:07,506 Epoch[51] Batch [1230]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.085297,	
2017-07-13 02:38:13,285 Epoch[51] Batch [1240]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085348,	
2017-07-13 02:38:19,075 Epoch[51] Batch [1250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.085375,	
2017-07-13 02:38:24,512 Epoch[51] Batch [1260]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085537,	
2017-07-13 02:38:30,102 Epoch[51] Batch [1270]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.085601,	
2017-07-13 02:38:35,581 Epoch[51] Batch [1280]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.085729,	
2017-07-13 02:38:40,940 Epoch[51] Batch [1290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.085843,	
2017-07-13 02:38:46,493 Epoch[51] Batch [1300]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.085879,	
2017-07-13 02:38:52,105 Epoch[51] Batch [1310]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.085893,	
2017-07-13 02:38:57,513 Epoch[51] Batch [1320]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.085857,	
2017-07-13 02:39:03,169 Epoch[51] Batch [1330]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.085919,	
2017-07-13 02:39:08,786 Epoch[51] Batch [1340]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.085861,	
2017-07-13 02:39:14,973 Epoch[51] Batch [1350]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085835,	
2017-07-13 02:39:20,865 Epoch[51] Batch [1360]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085931,	
2017-07-13 02:39:26,560 Epoch[51] Batch [1370]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.085935,	
2017-07-13 02:39:32,534 Epoch[51] Batch [1380]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.085911,	
2017-07-13 02:39:38,509 Epoch[51] Batch [1390]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.085937,	
2017-07-13 02:39:44,580 Epoch[51] Batch [1400]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.085906,	
2017-07-13 02:39:50,473 Epoch[51] Batch [1410]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085953,	
2017-07-13 02:39:56,440 Epoch[51] Batch [1420]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.085906,	
2017-07-13 02:40:01,965 Epoch[51] Batch [1430]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.085887,	
2017-07-13 02:40:07,663 Epoch[51] Batch [1440]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.085865,	
2017-07-13 02:40:13,394 Epoch[51] Batch [1450]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.085854,	
2017-07-13 02:40:18,970 Epoch[51] Batch [1460]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.085796,	
2017-07-13 02:40:24,495 Epoch[51] Batch [1470]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.085769,	
2017-07-13 02:40:30,477 Epoch[51] Batch [1480]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.085744,	
2017-07-13 02:40:33,921 Epoch[51] Train-FCNLogLoss=0.085745
2017-07-13 02:40:33,921 Epoch[51] Time cost=804.584
2017-07-13 02:40:35,041 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0052.params"
2017-07-13 02:40:38,780 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0052.states"
2017-07-13 02:40:45,120 Epoch[52] Batch [10]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.080409,	
2017-07-13 02:40:50,681 Epoch[52] Batch [20]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.082147,	
2017-07-13 02:40:56,788 Epoch[52] Batch [30]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.083856,	
2017-07-13 02:41:02,735 Epoch[52] Batch [40]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.082506,	
2017-07-13 02:41:08,384 Epoch[52] Batch [50]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.083312,	
2017-07-13 02:41:14,448 Epoch[52] Batch [60]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.083846,	
2017-07-13 02:41:20,089 Epoch[52] Batch [70]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.083977,	
2017-07-13 02:41:25,268 Epoch[52] Batch [80]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.083548,	
2017-07-13 02:41:30,934 Epoch[52] Batch [90]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.082211,	
2017-07-13 02:41:35,824 Epoch[52] Batch [100]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.082474,	
2017-07-13 02:41:41,269 Epoch[52] Batch [110]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.082563,	
2017-07-13 02:41:47,216 Epoch[52] Batch [120]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.082817,	
2017-07-13 02:41:53,190 Epoch[52] Batch [130]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.082555,	
2017-07-13 02:41:58,508 Epoch[52] Batch [140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.082322,	
2017-07-13 02:42:03,931 Epoch[52] Batch [150]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.082594,	
2017-07-13 02:42:09,366 Epoch[52] Batch [160]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.082782,	
2017-07-13 02:42:14,975 Epoch[52] Batch [170]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.082574,	
2017-07-13 02:42:20,732 Epoch[52] Batch [180]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.082335,	
2017-07-13 02:42:26,261 Epoch[52] Batch [190]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.082853,	
2017-07-13 02:42:32,067 Epoch[52] Batch [200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.083367,	
2017-07-13 02:42:37,340 Epoch[52] Batch [210]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.083404,	
2017-07-13 02:42:42,668 Epoch[52] Batch [220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.083347,	
2017-07-13 02:42:48,267 Epoch[52] Batch [230]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.083312,	
2017-07-13 02:42:53,783 Epoch[52] Batch [240]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.083298,	
2017-07-13 02:42:59,365 Epoch[52] Batch [250]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.082986,	
2017-07-13 02:43:05,238 Epoch[52] Batch [260]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.083025,	
2017-07-13 02:43:10,845 Epoch[52] Batch [270]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.082812,	
2017-07-13 02:43:16,478 Epoch[52] Batch [280]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.083139,	
2017-07-13 02:43:21,919 Epoch[52] Batch [290]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.083137,	
2017-07-13 02:43:27,560 Epoch[52] Batch [300]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.082997,	
2017-07-13 02:43:33,150 Epoch[52] Batch [310]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.082880,	
2017-07-13 02:43:38,802 Epoch[52] Batch [320]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.082885,	
2017-07-13 02:43:44,393 Epoch[52] Batch [330]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.082617,	
2017-07-13 02:43:50,137 Epoch[52] Batch [340]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.082454,	
2017-07-13 02:43:55,486 Epoch[52] Batch [350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.082437,	
2017-07-13 02:44:00,943 Epoch[52] Batch [360]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.082371,	
2017-07-13 02:44:06,578 Epoch[52] Batch [370]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.082246,	
2017-07-13 02:44:12,337 Epoch[52] Batch [380]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.082305,	
2017-07-13 02:44:17,856 Epoch[52] Batch [390]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.082234,	
2017-07-13 02:44:23,464 Epoch[52] Batch [400]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.082123,	
2017-07-13 02:44:28,701 Epoch[52] Batch [410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.082150,	
2017-07-13 02:44:34,122 Epoch[52] Batch [420]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.082334,	
2017-07-13 02:44:39,683 Epoch[52] Batch [430]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.082435,	
2017-07-13 02:44:44,961 Epoch[52] Batch [440]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.082301,	
2017-07-13 02:44:50,375 Epoch[52] Batch [450]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.082164,	
2017-07-13 02:44:56,092 Epoch[52] Batch [460]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.082211,	
2017-07-13 02:45:01,601 Epoch[52] Batch [470]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.082466,	
2017-07-13 02:45:06,783 Epoch[52] Batch [480]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.082274,	
2017-07-13 02:45:11,901 Epoch[52] Batch [490]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.082200,	
2017-07-13 02:45:17,097 Epoch[52] Batch [500]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.082296,	
2017-07-13 02:45:22,724 Epoch[52] Batch [510]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.082139,	
2017-07-13 02:45:28,537 Epoch[52] Batch [520]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.082108,	
2017-07-13 02:45:34,230 Epoch[52] Batch [530]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.082303,	
2017-07-13 02:45:39,800 Epoch[52] Batch [540]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.082298,	
2017-07-13 02:45:45,435 Epoch[52] Batch [550]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.082335,	
2017-07-13 02:45:51,256 Epoch[52] Batch [560]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.082349,	
2017-07-13 02:45:57,096 Epoch[52] Batch [570]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.082495,	
2017-07-13 02:46:03,298 Epoch[52] Batch [580]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.082433,	
2017-07-13 02:46:09,151 Epoch[52] Batch [590]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.082461,	
2017-07-13 02:46:15,024 Epoch[52] Batch [600]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.082509,	
2017-07-13 02:46:20,889 Epoch[52] Batch [610]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.082653,	
2017-07-13 02:46:26,298 Epoch[52] Batch [620]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.082609,	
2017-07-13 02:46:31,777 Epoch[52] Batch [630]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.082560,	
2017-07-13 02:46:37,238 Epoch[52] Batch [640]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.082689,	
2017-07-13 02:46:42,481 Epoch[52] Batch [650]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.082821,	
2017-07-13 02:46:48,260 Epoch[52] Batch [660]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.082833,	
2017-07-13 02:46:53,843 Epoch[52] Batch [670]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.082796,	
2017-07-13 02:46:59,189 Epoch[52] Batch [680]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.082856,	
2017-07-13 02:47:04,744 Epoch[52] Batch [690]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.083028,	
2017-07-13 02:47:10,507 Epoch[52] Batch [700]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.082963,	
2017-07-13 02:47:15,814 Epoch[52] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.082889,	
2017-07-13 02:47:21,706 Epoch[52] Batch [720]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.082899,	
2017-07-13 02:47:26,863 Epoch[52] Batch [730]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.082821,	
2017-07-13 02:47:32,104 Epoch[52] Batch [740]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.082815,	
2017-07-13 02:47:37,668 Epoch[52] Batch [750]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.082703,	
2017-07-13 02:47:43,254 Epoch[52] Batch [760]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.082746,	
2017-07-13 02:47:48,916 Epoch[52] Batch [770]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.082884,	
2017-07-13 02:47:54,540 Epoch[52] Batch [780]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.083454,	
2017-07-13 02:48:00,664 Epoch[52] Batch [790]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.083679,	
2017-07-13 02:48:06,154 Epoch[52] Batch [800]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.083900,	
2017-07-13 02:48:11,502 Epoch[52] Batch [810]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.083993,	
2017-07-13 02:48:17,200 Epoch[52] Batch [820]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.084098,	
2017-07-13 02:48:22,831 Epoch[52] Batch [830]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.084067,	
2017-07-13 02:48:28,430 Epoch[52] Batch [840]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.084162,	
2017-07-13 02:48:34,126 Epoch[52] Batch [850]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.084448,	
2017-07-13 02:48:39,661 Epoch[52] Batch [860]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.084535,	
2017-07-13 02:48:45,387 Epoch[52] Batch [870]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.084579,	
2017-07-13 02:48:51,042 Epoch[52] Batch [880]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.084653,	
2017-07-13 02:48:56,337 Epoch[52] Batch [890]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.084545,	
2017-07-13 02:49:02,052 Epoch[52] Batch [900]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.084451,	
2017-07-13 02:49:07,867 Epoch[52] Batch [910]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.084443,	
2017-07-13 02:49:13,309 Epoch[52] Batch [920]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.084324,	
2017-07-13 02:49:18,987 Epoch[52] Batch [930]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.084355,	
2017-07-13 02:49:24,809 Epoch[52] Batch [940]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.084388,	
2017-07-13 02:49:30,247 Epoch[52] Batch [950]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.084346,	
2017-07-13 02:49:35,915 Epoch[52] Batch [960]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.084294,	
2017-07-13 02:49:41,662 Epoch[52] Batch [970]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.084275,	
2017-07-13 02:49:47,162 Epoch[52] Batch [980]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.084273,	
2017-07-13 02:49:52,957 Epoch[52] Batch [990]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.084240,	
2017-07-13 02:49:58,449 Epoch[52] Batch [1000]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.084244,	
2017-07-13 02:50:03,925 Epoch[52] Batch [1010]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.084286,	
2017-07-13 02:50:09,685 Epoch[52] Batch [1020]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.084316,	
2017-07-13 02:50:15,383 Epoch[52] Batch [1030]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.084282,	
2017-07-13 02:50:21,075 Epoch[52] Batch [1040]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.084199,	
2017-07-13 02:50:26,201 Epoch[52] Batch [1050]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.084239,	
2017-07-13 02:50:32,000 Epoch[52] Batch [1060]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.084245,	
2017-07-13 02:50:37,377 Epoch[52] Batch [1070]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.084323,	
2017-07-13 02:50:43,118 Epoch[52] Batch [1080]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.084319,	
2017-07-13 02:50:48,781 Epoch[52] Batch [1090]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.084290,	
2017-07-13 02:50:54,085 Epoch[52] Batch [1100]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.084282,	
2017-07-13 02:50:59,394 Epoch[52] Batch [1110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.084306,	
2017-07-13 02:51:04,657 Epoch[52] Batch [1120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.084314,	
2017-07-13 02:51:10,013 Epoch[52] Batch [1130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.084296,	
2017-07-13 02:51:15,502 Epoch[52] Batch [1140]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.084273,	
2017-07-13 02:51:21,320 Epoch[52] Batch [1150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.084319,	
2017-07-13 02:51:27,356 Epoch[52] Batch [1160]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.084329,	
2017-07-13 02:51:32,523 Epoch[52] Batch [1170]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.084397,	
2017-07-13 02:51:37,911 Epoch[52] Batch [1180]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.084489,	
2017-07-13 02:51:43,825 Epoch[52] Batch [1190]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.084504,	
2017-07-13 02:51:49,512 Epoch[52] Batch [1200]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.084470,	
2017-07-13 02:51:55,178 Epoch[52] Batch [1210]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.084498,	
2017-07-13 02:52:00,535 Epoch[52] Batch [1220]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.084559,	
2017-07-13 02:52:06,690 Epoch[52] Batch [1230]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.084568,	
2017-07-13 02:52:12,918 Epoch[52] Batch [1240]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.084552,	
2017-07-13 02:52:18,577 Epoch[52] Batch [1250]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.084556,	
2017-07-13 02:52:24,511 Epoch[52] Batch [1260]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.084558,	
2017-07-13 02:52:29,996 Epoch[52] Batch [1270]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.084601,	
2017-07-13 02:52:35,849 Epoch[52] Batch [1280]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.084623,	
2017-07-13 02:52:41,713 Epoch[52] Batch [1290]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.084669,	
2017-07-13 02:52:48,161 Epoch[52] Batch [1300]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.084645,	
2017-07-13 02:52:54,118 Epoch[52] Batch [1310]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.084649,	
2017-07-13 02:53:00,333 Epoch[52] Batch [1320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.084662,	
2017-07-13 02:53:06,421 Epoch[52] Batch [1330]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.084670,	
2017-07-13 02:53:12,349 Epoch[52] Batch [1340]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.084660,	
2017-07-13 02:53:18,264 Epoch[52] Batch [1350]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.084631,	
2017-07-13 02:53:24,609 Epoch[52] Batch [1360]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.084658,	
2017-07-13 02:53:31,013 Epoch[52] Batch [1370]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.084660,	
2017-07-13 02:53:37,393 Epoch[52] Batch [1380]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.084617,	
2017-07-13 02:53:43,440 Epoch[52] Batch [1390]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.084598,	
2017-07-13 02:53:49,334 Epoch[52] Batch [1400]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.084584,	
2017-07-13 02:53:55,458 Epoch[52] Batch [1410]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.084548,	
2017-07-13 02:54:01,368 Epoch[52] Batch [1420]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.084575,	
2017-07-13 02:54:07,350 Epoch[52] Batch [1430]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.084503,	
2017-07-13 02:54:13,377 Epoch[52] Batch [1440]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.084527,	
2017-07-13 02:54:19,653 Epoch[52] Batch [1450]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.084509,	
2017-07-13 02:54:25,761 Epoch[52] Batch [1460]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.084500,	
2017-07-13 02:54:31,340 Epoch[52] Batch [1470]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.084530,	
2017-07-13 02:54:37,279 Epoch[52] Batch [1480]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.084494,	
2017-07-13 02:54:40,641 Epoch[52] Train-FCNLogLoss=0.084504
2017-07-13 02:54:40,642 Epoch[52] Time cost=841.861
2017-07-13 02:54:41,784 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0053.params"
2017-07-13 02:54:45,436 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0053.states"
2017-07-13 02:54:52,193 Epoch[53] Batch [10]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087819,	
2017-07-13 02:54:57,550 Epoch[53] Batch [20]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.083757,	
2017-07-13 02:55:03,419 Epoch[53] Batch [30]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.082670,	
2017-07-13 02:55:09,018 Epoch[53] Batch [40]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.084732,	
2017-07-13 02:55:14,968 Epoch[53] Batch [50]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.083364,	
2017-07-13 02:55:20,632 Epoch[53] Batch [60]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.083937,	
2017-07-13 02:55:26,368 Epoch[53] Batch [70]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.085050,	
2017-07-13 02:55:32,414 Epoch[53] Batch [80]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.084443,	
2017-07-13 02:55:38,335 Epoch[53] Batch [90]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.084565,	
2017-07-13 02:55:44,174 Epoch[53] Batch [100]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.083992,	
2017-07-13 02:55:49,879 Epoch[53] Batch [110]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.083996,	
2017-07-13 02:55:55,822 Epoch[53] Batch [120]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.084126,	
2017-07-13 02:56:01,463 Epoch[53] Batch [130]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.083232,	
2017-07-13 02:56:07,237 Epoch[53] Batch [140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.083033,	
2017-07-13 02:56:13,231 Epoch[53] Batch [150]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.083572,	
2017-07-13 02:56:18,672 Epoch[53] Batch [160]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.083388,	
2017-07-13 02:56:24,095 Epoch[53] Batch [170]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.083517,	
2017-07-13 02:56:29,552 Epoch[53] Batch [180]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.083884,	
2017-07-13 02:56:34,807 Epoch[53] Batch [190]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.083751,	
2017-07-13 02:56:40,053 Epoch[53] Batch [200]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.083917,	
2017-07-13 02:56:45,554 Epoch[53] Batch [210]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.083657,	
2017-07-13 02:56:51,225 Epoch[53] Batch [220]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.083498,	
2017-07-13 02:56:56,583 Epoch[53] Batch [230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.083864,	
2017-07-13 02:57:01,899 Epoch[53] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.084140,	
2017-07-13 02:57:07,908 Epoch[53] Batch [250]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.083838,	
2017-07-13 02:57:13,773 Epoch[53] Batch [260]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.083762,	
2017-07-13 02:57:19,765 Epoch[53] Batch [270]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.083890,	
2017-07-13 02:57:25,457 Epoch[53] Batch [280]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.083855,	
2017-07-13 02:57:31,320 Epoch[53] Batch [290]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.083906,	
2017-07-13 02:57:37,134 Epoch[53] Batch [300]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.083619,	
2017-07-13 02:57:43,672 Epoch[53] Batch [310]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.083546,	
2017-07-13 02:57:49,744 Epoch[53] Batch [320]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.083710,	
2017-07-13 02:57:55,084 Epoch[53] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.083665,	
2017-07-13 02:58:00,865 Epoch[53] Batch [340]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.083472,	
2017-07-13 02:58:05,966 Epoch[53] Batch [350]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.083394,	
2017-07-13 02:58:10,975 Epoch[53] Batch [360]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.083572,	
2017-07-13 02:58:16,285 Epoch[53] Batch [370]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.083373,	
2017-07-13 02:58:21,839 Epoch[53] Batch [380]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.083268,	
2017-07-13 02:58:26,876 Epoch[53] Batch [390]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.083227,	
2017-07-13 02:58:32,159 Epoch[53] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.083142,	
2017-07-13 02:58:37,414 Epoch[53] Batch [410]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.083028,	
2017-07-13 02:58:42,709 Epoch[53] Batch [420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.083256,	
2017-07-13 02:58:48,092 Epoch[53] Batch [430]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.083255,	
2017-07-13 02:58:53,471 Epoch[53] Batch [440]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.083114,	
2017-07-13 02:58:58,516 Epoch[53] Batch [450]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.083184,	
2017-07-13 02:59:03,875 Epoch[53] Batch [460]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.083111,	
2017-07-13 02:59:10,099 Epoch[53] Batch [470]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.082948,	
2017-07-13 02:59:15,996 Epoch[53] Batch [480]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.083015,	
2017-07-13 02:59:21,640 Epoch[53] Batch [490]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.083035,	
2017-07-13 02:59:27,565 Epoch[53] Batch [500]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.082940,	
2017-07-13 02:59:33,132 Epoch[53] Batch [510]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.083046,	
2017-07-13 02:59:39,243 Epoch[53] Batch [520]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.083265,	
2017-07-13 02:59:45,082 Epoch[53] Batch [530]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.083370,	
2017-07-13 02:59:50,999 Epoch[53] Batch [540]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.083166,	
2017-07-13 02:59:56,665 Epoch[53] Batch [550]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.083130,	
2017-07-13 03:00:02,811 Epoch[53] Batch [560]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.083098,	
2017-07-13 03:00:08,644 Epoch[53] Batch [570]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.083091,	
2017-07-13 03:00:14,474 Epoch[53] Batch [580]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.082962,	
2017-07-13 03:00:20,262 Epoch[53] Batch [590]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.083090,	
2017-07-13 03:00:26,148 Epoch[53] Batch [600]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.083069,	
2017-07-13 03:00:31,987 Epoch[53] Batch [610]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.083103,	
2017-07-13 03:00:37,978 Epoch[53] Batch [620]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.083125,	
2017-07-13 03:00:43,418 Epoch[53] Batch [630]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.083386,	
2017-07-13 03:00:48,806 Epoch[53] Batch [640]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.083423,	
2017-07-13 03:00:54,528 Epoch[53] Batch [650]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.083431,	
2017-07-13 03:01:00,110 Epoch[53] Batch [660]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.083305,	
2017-07-13 03:01:06,002 Epoch[53] Batch [670]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.083358,	
2017-07-13 03:01:11,889 Epoch[53] Batch [680]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.083419,	
2017-07-13 03:01:18,019 Epoch[53] Batch [690]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.083393,	
2017-07-13 03:01:24,232 Epoch[53] Batch [700]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.083342,	
2017-07-13 03:01:30,285 Epoch[53] Batch [710]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.083328,	
2017-07-13 03:01:36,520 Epoch[53] Batch [720]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.083272,	
2017-07-13 03:01:42,730 Epoch[53] Batch [730]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.083302,	
2017-07-13 03:01:48,613 Epoch[53] Batch [740]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.083389,	
2017-07-13 03:01:54,295 Epoch[53] Batch [750]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.083498,	
2017-07-13 03:02:00,408 Epoch[53] Batch [760]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.083603,	
2017-07-13 03:02:06,324 Epoch[53] Batch [770]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.083455,	
2017-07-13 03:02:12,084 Epoch[53] Batch [780]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.083505,	
2017-07-13 03:02:17,974 Epoch[53] Batch [790]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.083637,	
2017-07-13 03:02:23,813 Epoch[53] Batch [800]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.083647,	
2017-07-13 03:02:30,053 Epoch[53] Batch [810]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.083527,	
2017-07-13 03:02:35,851 Epoch[53] Batch [820]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.083433,	
2017-07-13 03:02:41,756 Epoch[53] Batch [830]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.083462,	
2017-07-13 03:02:47,776 Epoch[53] Batch [840]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.083468,	
2017-07-13 03:02:53,565 Epoch[53] Batch [850]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.083483,	
2017-07-13 03:02:59,811 Epoch[53] Batch [860]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.083393,	
2017-07-13 03:03:05,744 Epoch[53] Batch [870]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.083350,	
2017-07-13 03:03:12,595 Epoch[53] Batch [880]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.083271,	
2017-07-13 03:03:18,651 Epoch[53] Batch [890]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.083279,	
2017-07-13 03:03:25,386 Epoch[53] Batch [900]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.083342,	
2017-07-13 03:03:31,674 Epoch[53] Batch [910]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.083241,	
2017-07-13 03:03:38,054 Epoch[53] Batch [920]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.083300,	
2017-07-13 03:03:44,027 Epoch[53] Batch [930]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.083171,	
2017-07-13 03:03:50,630 Epoch[53] Batch [940]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.083171,	
2017-07-13 03:03:56,950 Epoch[53] Batch [950]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.083073,	
2017-07-13 03:04:03,933 Epoch[53] Batch [960]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.083088,	
2017-07-13 03:04:10,851 Epoch[53] Batch [970]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.083085,	
2017-07-13 03:04:17,690 Epoch[53] Batch [980]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.083136,	
2017-07-13 03:04:24,096 Epoch[53] Batch [990]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.083101,	
2017-07-13 03:04:30,584 Epoch[53] Batch [1000]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.083159,	
2017-07-13 03:04:36,870 Epoch[53] Batch [1010]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.083204,	
2017-07-13 03:04:43,552 Epoch[53] Batch [1020]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.083212,	
2017-07-13 03:04:50,519 Epoch[53] Batch [1030]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.083190,	
2017-07-13 03:04:57,010 Epoch[53] Batch [1040]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.083162,	
2017-07-13 03:05:03,487 Epoch[53] Batch [1050]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.083126,	
2017-07-13 03:05:09,985 Epoch[53] Batch [1060]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.083096,	
2017-07-13 03:05:16,834 Epoch[53] Batch [1070]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.083144,	
2017-07-13 03:05:23,391 Epoch[53] Batch [1080]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.083132,	
2017-07-13 03:05:29,690 Epoch[53] Batch [1090]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.083140,	
2017-07-13 03:05:36,005 Epoch[53] Batch [1100]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.083101,	
2017-07-13 03:05:42,914 Epoch[53] Batch [1110]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.083147,	
2017-07-13 03:05:49,622 Epoch[53] Batch [1120]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.083138,	
2017-07-13 03:05:56,392 Epoch[53] Batch [1130]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.083196,	
2017-07-13 03:06:03,151 Epoch[53] Batch [1140]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.083220,	
2017-07-13 03:06:09,709 Epoch[53] Batch [1150]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.083143,	
2017-07-13 03:06:16,438 Epoch[53] Batch [1160]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.083081,	
2017-07-13 03:06:23,557 Epoch[53] Batch [1170]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.083060,	
2017-07-13 03:06:30,336 Epoch[53] Batch [1180]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.083083,	
2017-07-13 03:06:37,329 Epoch[53] Batch [1190]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.083064,	
2017-07-13 03:06:44,142 Epoch[53] Batch [1200]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.083022,	
2017-07-13 03:06:50,896 Epoch[53] Batch [1210]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.083036,	
2017-07-13 03:06:57,837 Epoch[53] Batch [1220]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.082999,	
2017-07-13 03:07:04,685 Epoch[53] Batch [1230]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.083009,	
2017-07-13 03:07:11,456 Epoch[53] Batch [1240]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.082993,	
2017-07-13 03:07:18,480 Epoch[53] Batch [1250]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.082960,	
2017-07-13 03:07:25,523 Epoch[53] Batch [1260]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.082907,	
2017-07-13 03:07:32,270 Epoch[53] Batch [1270]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.082883,	
2017-07-13 03:07:39,354 Epoch[53] Batch [1280]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.082839,	
2017-07-13 03:07:46,046 Epoch[53] Batch [1290]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.082851,	
2017-07-13 03:07:52,947 Epoch[53] Batch [1300]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.082855,	
2017-07-13 03:07:59,916 Epoch[53] Batch [1310]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.082878,	
2017-07-13 03:08:06,583 Epoch[53] Batch [1320]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.082945,	
2017-07-13 03:08:13,607 Epoch[53] Batch [1330]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.082991,	
2017-07-13 03:08:20,690 Epoch[53] Batch [1340]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.082998,	
2017-07-13 03:08:28,074 Epoch[53] Batch [1350]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.083005,	
2017-07-13 03:08:35,301 Epoch[53] Batch [1360]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.083044,	
2017-07-13 03:08:42,510 Epoch[53] Batch [1370]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.083062,	
2017-07-13 03:08:49,714 Epoch[53] Batch [1380]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.083093,	
2017-07-13 03:08:57,185 Epoch[53] Batch [1390]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.083061,	
2017-07-13 03:09:04,372 Epoch[53] Batch [1400]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.083105,	
2017-07-13 03:09:11,700 Epoch[53] Batch [1410]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.083094,	
2017-07-13 03:09:19,045 Epoch[53] Batch [1420]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.083077,	
2017-07-13 03:09:26,150 Epoch[53] Batch [1430]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.083078,	
2017-07-13 03:09:33,386 Epoch[53] Batch [1440]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.083131,	
2017-07-13 03:09:40,431 Epoch[53] Batch [1450]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.083080,	
2017-07-13 03:09:47,691 Epoch[53] Batch [1460]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.083105,	
2017-07-13 03:09:55,072 Epoch[53] Batch [1470]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.083082,	
2017-07-13 03:10:02,118 Epoch[53] Batch [1480]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.083058,	
2017-07-13 03:10:06,433 Epoch[53] Train-FCNLogLoss=0.083017
2017-07-13 03:10:06,434 Epoch[53] Time cost=920.997
2017-07-13 03:10:07,598 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0054.params"
2017-07-13 03:10:11,528 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0054.states"
2017-07-13 03:10:19,384 Epoch[54] Batch [10]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.079136,	
2017-07-13 03:10:26,707 Epoch[54] Batch [20]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.078594,	
2017-07-13 03:10:33,937 Epoch[54] Batch [30]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.079323,	
2017-07-13 03:10:41,250 Epoch[54] Batch [40]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.082153,	
2017-07-13 03:10:48,439 Epoch[54] Batch [50]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.080804,	
2017-07-13 03:10:55,230 Epoch[54] Batch [60]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.080246,	
2017-07-13 03:11:02,539 Epoch[54] Batch [70]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.080573,	
2017-07-13 03:11:09,496 Epoch[54] Batch [80]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.081584,	
2017-07-13 03:11:16,342 Epoch[54] Batch [90]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.081627,	
2017-07-13 03:11:23,426 Epoch[54] Batch [100]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.082183,	
2017-07-13 03:11:30,407 Epoch[54] Batch [110]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.082241,	
2017-07-13 03:11:37,366 Epoch[54] Batch [120]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.081251,	
2017-07-13 03:11:44,347 Epoch[54] Batch [130]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.081180,	
2017-07-13 03:11:51,210 Epoch[54] Batch [140]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.081121,	
2017-07-13 03:11:58,275 Epoch[54] Batch [150]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.081053,	
2017-07-13 03:12:05,391 Epoch[54] Batch [160]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.081043,	
2017-07-13 03:12:12,384 Epoch[54] Batch [170]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.080805,	
2017-07-13 03:12:19,260 Epoch[54] Batch [180]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.081577,	
2017-07-13 03:12:26,079 Epoch[54] Batch [190]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.081301,	
2017-07-13 03:12:32,877 Epoch[54] Batch [200]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.081865,	
2017-07-13 03:12:39,247 Epoch[54] Batch [210]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.082321,	
2017-07-13 03:12:46,206 Epoch[54] Batch [220]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.083035,	
2017-07-13 03:12:53,116 Epoch[54] Batch [230]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.082960,	
2017-07-13 03:12:59,664 Epoch[54] Batch [240]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.083183,	
2017-07-13 03:13:06,669 Epoch[54] Batch [250]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.082770,	
2017-07-13 03:13:13,190 Epoch[54] Batch [260]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.082685,	
2017-07-13 03:13:20,074 Epoch[54] Batch [270]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.082630,	
2017-07-13 03:13:26,633 Epoch[54] Batch [280]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.082829,	
2017-07-13 03:13:33,251 Epoch[54] Batch [290]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.082871,	
2017-07-13 03:13:39,678 Epoch[54] Batch [300]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.082825,	
2017-07-13 03:13:46,418 Epoch[54] Batch [310]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.082911,	
2017-07-13 03:13:53,321 Epoch[54] Batch [320]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.083233,	
2017-07-13 03:14:00,350 Epoch[54] Batch [330]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.083305,	
2017-07-13 03:14:07,273 Epoch[54] Batch [340]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.083241,	
2017-07-13 03:14:14,058 Epoch[54] Batch [350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.083380,	
2017-07-13 03:14:21,107 Epoch[54] Batch [360]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.083282,	
2017-07-13 03:14:27,996 Epoch[54] Batch [370]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.083300,	
2017-07-13 03:14:34,923 Epoch[54] Batch [380]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.083145,	
2017-07-13 03:14:42,019 Epoch[54] Batch [390]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.083033,	
2017-07-13 03:14:49,018 Epoch[54] Batch [400]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.083019,	
2017-07-13 03:14:55,949 Epoch[54] Batch [410]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.083064,	
2017-07-13 03:15:02,959 Epoch[54] Batch [420]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.082879,	
2017-07-13 03:15:10,272 Epoch[54] Batch [430]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.082861,	
2017-07-13 03:15:17,252 Epoch[54] Batch [440]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.082723,	
2017-07-13 03:15:24,206 Epoch[54] Batch [450]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.082719,	
2017-07-13 03:15:31,366 Epoch[54] Batch [460]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.082673,	
2017-07-13 03:15:38,190 Epoch[54] Batch [470]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.082953,	
2017-07-13 03:15:45,588 Epoch[54] Batch [480]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.082967,	
2017-07-13 03:15:53,069 Epoch[54] Batch [490]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.082964,	
2017-07-13 03:16:00,234 Epoch[54] Batch [500]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.082865,	
2017-07-13 03:16:07,296 Epoch[54] Batch [510]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.082921,	
2017-07-13 03:16:14,518 Epoch[54] Batch [520]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.083079,	
2017-07-13 03:16:21,991 Epoch[54] Batch [530]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.083014,	
2017-07-13 03:16:28,992 Epoch[54] Batch [540]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.082891,	
2017-07-13 03:16:36,108 Epoch[54] Batch [550]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.083006,	
2017-07-13 03:16:43,237 Epoch[54] Batch [560]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.083096,	
2017-07-13 03:16:50,466 Epoch[54] Batch [570]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.083128,	
2017-07-13 03:16:57,657 Epoch[54] Batch [580]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.083289,	
2017-07-13 03:17:04,890 Epoch[54] Batch [590]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.083376,	
2017-07-13 03:17:12,000 Epoch[54] Batch [600]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.083370,	
2017-07-13 03:17:19,405 Epoch[54] Batch [610]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.083193,	
2017-07-13 03:17:26,647 Epoch[54] Batch [620]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.083219,	
2017-07-13 03:17:33,996 Epoch[54] Batch [630]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.083130,	
2017-07-13 03:17:41,528 Epoch[54] Batch [640]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.083124,	
2017-07-13 03:17:48,744 Epoch[54] Batch [650]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.083091,	
2017-07-13 03:17:56,042 Epoch[54] Batch [660]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.083168,	
2017-07-13 03:18:03,242 Epoch[54] Batch [670]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.083096,	
2017-07-13 03:18:10,598 Epoch[54] Batch [680]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.083120,	
2017-07-13 03:18:17,898 Epoch[54] Batch [690]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.083090,	
2017-07-13 03:18:25,335 Epoch[54] Batch [700]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.083062,	
2017-07-13 03:18:32,490 Epoch[54] Batch [710]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.083015,	
2017-07-13 03:18:39,912 Epoch[54] Batch [720]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.083024,	
2017-07-13 03:18:47,189 Epoch[54] Batch [730]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.083092,	
2017-07-13 03:18:54,499 Epoch[54] Batch [740]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.083075,	
2017-07-13 03:19:02,015 Epoch[54] Batch [750]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.083136,	
2017-07-13 03:19:09,042 Epoch[54] Batch [760]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.083138,	
2017-07-13 03:19:16,245 Epoch[54] Batch [770]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.083163,	
2017-07-13 03:19:23,719 Epoch[54] Batch [780]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.083308,	
2017-07-13 03:19:31,162 Epoch[54] Batch [790]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.083219,	
2017-07-13 03:19:38,694 Epoch[54] Batch [800]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.083164,	
2017-07-13 03:19:46,146 Epoch[54] Batch [810]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.083099,	
2017-07-13 03:19:53,657 Epoch[54] Batch [820]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.083068,	
2017-07-13 03:20:01,238 Epoch[54] Batch [830]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.083165,	
2017-07-13 03:20:08,781 Epoch[54] Batch [840]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.083241,	
2017-07-13 03:20:16,393 Epoch[54] Batch [850]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.083220,	
2017-07-13 03:20:23,759 Epoch[54] Batch [860]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.083209,	
2017-07-13 03:20:31,187 Epoch[54] Batch [870]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.083164,	
2017-07-13 03:20:38,688 Epoch[54] Batch [880]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.083052,	
2017-07-13 03:20:46,144 Epoch[54] Batch [890]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.083066,	
2017-07-13 03:20:53,703 Epoch[54] Batch [900]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.083081,	
2017-07-13 03:21:01,162 Epoch[54] Batch [910]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.083057,	
2017-07-13 03:21:08,496 Epoch[54] Batch [920]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.082965,	
2017-07-13 03:21:15,900 Epoch[54] Batch [930]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.082974,	
2017-07-13 03:21:23,347 Epoch[54] Batch [940]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.082976,	
2017-07-13 03:21:30,607 Epoch[54] Batch [950]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.083074,	
2017-07-13 03:21:37,744 Epoch[54] Batch [960]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.083020,	
2017-07-13 03:21:45,189 Epoch[54] Batch [970]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.083022,	
2017-07-13 03:21:52,517 Epoch[54] Batch [980]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.082999,	
2017-07-13 03:21:59,537 Epoch[54] Batch [990]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.082963,	
2017-07-13 03:22:06,649 Epoch[54] Batch [1000]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.083055,	
2017-07-13 03:22:13,676 Epoch[54] Batch [1010]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.083074,	
2017-07-13 03:22:20,836 Epoch[54] Batch [1020]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.083037,	
2017-07-13 03:22:28,172 Epoch[54] Batch [1030]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.083005,	
2017-07-13 03:22:35,259 Epoch[54] Batch [1040]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.083033,	
2017-07-13 03:22:42,482 Epoch[54] Batch [1050]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.083023,	
2017-07-13 03:22:49,797 Epoch[54] Batch [1060]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.082994,	
2017-07-13 03:22:57,126 Epoch[54] Batch [1070]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.082981,	
2017-07-13 03:23:04,729 Epoch[54] Batch [1080]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.082981,	
2017-07-13 03:23:12,098 Epoch[54] Batch [1090]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.082963,	
2017-07-13 03:23:19,198 Epoch[54] Batch [1100]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.082912,	
2017-07-13 03:23:26,623 Epoch[54] Batch [1110]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.082928,	
2017-07-13 03:23:34,005 Epoch[54] Batch [1120]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.082832,	
2017-07-13 03:23:41,239 Epoch[54] Batch [1130]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.082875,	
2017-07-13 03:23:48,463 Epoch[54] Batch [1140]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.082861,	
2017-07-13 03:23:55,649 Epoch[54] Batch [1150]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.082869,	
2017-07-13 03:24:02,765 Epoch[54] Batch [1160]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.082882,	
2017-07-13 03:24:10,037 Epoch[54] Batch [1170]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.082823,	
2017-07-13 03:24:17,377 Epoch[54] Batch [1180]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.082926,	
2017-07-13 03:24:24,671 Epoch[54] Batch [1190]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.082879,	
2017-07-13 03:24:31,936 Epoch[54] Batch [1200]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.082783,	
2017-07-13 03:24:39,285 Epoch[54] Batch [1210]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.082780,	
2017-07-13 03:24:46,716 Epoch[54] Batch [1220]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.082718,	
2017-07-13 03:24:54,111 Epoch[54] Batch [1230]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.082761,	
2017-07-13 03:25:01,092 Epoch[54] Batch [1240]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.082814,	
2017-07-13 03:25:08,124 Epoch[54] Batch [1250]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.082781,	
2017-07-13 03:25:15,246 Epoch[54] Batch [1260]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.082769,	
2017-07-13 03:25:22,518 Epoch[54] Batch [1270]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.082812,	
2017-07-13 03:25:29,585 Epoch[54] Batch [1280]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.082747,	
2017-07-13 03:25:36,888 Epoch[54] Batch [1290]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.082802,	
2017-07-13 03:25:43,751 Epoch[54] Batch [1300]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.082820,	
2017-07-13 03:25:51,100 Epoch[54] Batch [1310]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.082830,	
2017-07-13 03:25:58,722 Epoch[54] Batch [1320]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.082873,	
2017-07-13 03:26:05,996 Epoch[54] Batch [1330]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.082913,	
2017-07-13 03:26:13,190 Epoch[54] Batch [1340]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.082998,	
2017-07-13 03:26:20,482 Epoch[54] Batch [1350]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.083003,	
2017-07-13 03:26:27,976 Epoch[54] Batch [1360]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.082985,	
2017-07-13 03:26:35,358 Epoch[54] Batch [1370]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.082956,	
2017-07-13 03:26:42,659 Epoch[54] Batch [1380]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.082898,	
2017-07-13 03:26:49,933 Epoch[54] Batch [1390]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.082865,	
2017-07-13 03:26:57,182 Epoch[54] Batch [1400]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.082864,	
2017-07-13 03:27:04,356 Epoch[54] Batch [1410]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.082846,	
2017-07-13 03:27:11,702 Epoch[54] Batch [1420]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.082811,	
2017-07-13 03:27:18,869 Epoch[54] Batch [1430]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.082794,	
2017-07-13 03:27:26,125 Epoch[54] Batch [1440]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.082805,	
2017-07-13 03:27:33,724 Epoch[54] Batch [1450]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.082793,	
2017-07-13 03:27:41,110 Epoch[54] Batch [1460]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.082745,	
2017-07-13 03:27:48,446 Epoch[54] Batch [1470]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.082745,	
2017-07-13 03:27:55,890 Epoch[54] Batch [1480]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.082703,	
2017-07-13 03:28:00,091 Epoch[54] Train-FCNLogLoss=0.082713
2017-07-13 03:28:00,091 Epoch[54] Time cost=1068.562
2017-07-13 03:28:01,101 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0055.params"
2017-07-13 03:28:04,899 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0055.states"
2017-07-13 03:28:13,431 Epoch[55] Batch [10]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.082299,	
2017-07-13 03:28:20,712 Epoch[55] Batch [20]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.079004,	
2017-07-13 03:28:28,069 Epoch[55] Batch [30]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.080587,	
2017-07-13 03:28:35,488 Epoch[55] Batch [40]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.080422,	
2017-07-13 03:28:42,652 Epoch[55] Batch [50]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.081188,	
2017-07-13 03:28:50,164 Epoch[55] Batch [60]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.081792,	
2017-07-13 03:28:57,715 Epoch[55] Batch [70]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.082052,	
2017-07-13 03:29:05,151 Epoch[55] Batch [80]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.081695,	
2017-07-13 03:29:12,645 Epoch[55] Batch [90]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.081848,	
2017-07-13 03:29:19,920 Epoch[55] Batch [100]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.081303,	
2017-07-13 03:29:27,423 Epoch[55] Batch [110]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.081753,	
2017-07-13 03:29:34,782 Epoch[55] Batch [120]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.082202,	
2017-07-13 03:29:42,006 Epoch[55] Batch [130]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.081828,	
2017-07-13 03:29:49,497 Epoch[55] Batch [140]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.081660,	
2017-07-13 03:29:56,924 Epoch[55] Batch [150]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.082314,	
2017-07-13 03:30:04,418 Epoch[55] Batch [160]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.082380,	
2017-07-13 03:30:11,860 Epoch[55] Batch [170]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.082376,	
2017-07-13 03:30:19,228 Epoch[55] Batch [180]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.082745,	
2017-07-13 03:30:26,648 Epoch[55] Batch [190]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.082884,	
2017-07-13 03:30:33,970 Epoch[55] Batch [200]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.082961,	
2017-07-13 03:30:41,375 Epoch[55] Batch [210]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.082567,	
2017-07-13 03:30:48,649 Epoch[55] Batch [220]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.082684,	
2017-07-13 03:30:55,900 Epoch[55] Batch [230]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.082743,	
2017-07-13 03:31:02,955 Epoch[55] Batch [240]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.083048,	
2017-07-13 03:31:10,063 Epoch[55] Batch [250]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.082726,	
2017-07-13 03:31:17,297 Epoch[55] Batch [260]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.082428,	
2017-07-13 03:31:24,338 Epoch[55] Batch [270]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.082619,	
2017-07-13 03:31:31,558 Epoch[55] Batch [280]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.082557,	
2017-07-13 03:31:38,994 Epoch[55] Batch [290]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.082586,	
2017-07-13 03:31:46,293 Epoch[55] Batch [300]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.082383,	
2017-07-13 03:31:53,310 Epoch[55] Batch [310]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.082249,	
2017-07-13 03:32:00,593 Epoch[55] Batch [320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.081913,	
2017-07-13 03:32:07,715 Epoch[55] Batch [330]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.081825,	
2017-07-13 03:32:15,179 Epoch[55] Batch [340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.081904,	
2017-07-13 03:32:22,286 Epoch[55] Batch [350]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.081979,	
2017-07-13 03:32:29,408 Epoch[55] Batch [360]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.081972,	
2017-07-13 03:32:36,567 Epoch[55] Batch [370]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.081906,	
2017-07-13 03:32:43,837 Epoch[55] Batch [380]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.081978,	
2017-07-13 03:32:50,909 Epoch[55] Batch [390]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.082028,	
2017-07-13 03:32:57,860 Epoch[55] Batch [400]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.081986,	
2017-07-13 03:33:05,053 Epoch[55] Batch [410]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.082145,	
2017-07-13 03:33:12,295 Epoch[55] Batch [420]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.082237,	
2017-07-13 03:33:19,413 Epoch[55] Batch [430]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.082273,	
2017-07-13 03:33:26,576 Epoch[55] Batch [440]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.082202,	
2017-07-13 03:33:33,736 Epoch[55] Batch [450]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.082108,	
2017-07-13 03:33:40,739 Epoch[55] Batch [460]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.081852,	
2017-07-13 03:33:48,099 Epoch[55] Batch [470]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.081740,	
2017-07-13 03:33:55,084 Epoch[55] Batch [480]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.081630,	
2017-07-13 03:34:02,350 Epoch[55] Batch [490]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.081736,	
2017-07-13 03:34:09,411 Epoch[55] Batch [500]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.082190,	
2017-07-13 03:34:16,804 Epoch[55] Batch [510]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.082270,	
2017-07-13 03:34:23,997 Epoch[55] Batch [520]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.082299,	
2017-07-13 03:34:30,929 Epoch[55] Batch [530]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.082131,	
2017-07-13 03:34:37,979 Epoch[55] Batch [540]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.082197,	
2017-07-13 03:34:45,190 Epoch[55] Batch [550]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.082294,	
2017-07-13 03:34:52,218 Epoch[55] Batch [560]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.082455,	
2017-07-13 03:34:59,235 Epoch[55] Batch [570]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.082283,	
2017-07-13 03:35:06,245 Epoch[55] Batch [580]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.082076,	
2017-07-13 03:35:13,389 Epoch[55] Batch [590]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.082029,	
2017-07-13 03:35:20,408 Epoch[55] Batch [600]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.082063,	
2017-07-13 03:35:27,554 Epoch[55] Batch [610]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.082133,	
2017-07-13 03:35:34,598 Epoch[55] Batch [620]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.082051,	
2017-07-13 03:35:41,987 Epoch[55] Batch [630]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.082093,	
2017-07-13 03:35:49,311 Epoch[55] Batch [640]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.082212,	
2017-07-13 03:35:56,544 Epoch[55] Batch [650]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.082209,	
2017-07-13 03:36:03,495 Epoch[55] Batch [660]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.082305,	
2017-07-13 03:36:10,625 Epoch[55] Batch [670]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.082293,	
2017-07-13 03:36:17,765 Epoch[55] Batch [680]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.082359,	
2017-07-13 03:36:24,873 Epoch[55] Batch [690]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.082339,	
2017-07-13 03:36:32,032 Epoch[55] Batch [700]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.082394,	
2017-07-13 03:36:39,013 Epoch[55] Batch [710]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.082346,	
2017-07-13 03:36:45,971 Epoch[55] Batch [720]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.082320,	
2017-07-13 03:36:53,024 Epoch[55] Batch [730]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.082386,	
2017-07-13 03:36:59,898 Epoch[55] Batch [740]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.082501,	
2017-07-13 03:37:07,122 Epoch[55] Batch [750]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.082553,	
2017-07-13 03:37:14,187 Epoch[55] Batch [760]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.082660,	
2017-07-13 03:37:21,196 Epoch[55] Batch [770]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.082651,	
2017-07-13 03:37:28,478 Epoch[55] Batch [780]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.082553,	
2017-07-13 03:37:35,272 Epoch[55] Batch [790]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.082639,	
2017-07-13 03:37:42,465 Epoch[55] Batch [800]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.082640,	
2017-07-13 03:37:49,599 Epoch[55] Batch [810]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.082601,	
2017-07-13 03:37:56,769 Epoch[55] Batch [820]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.082575,	
2017-07-13 03:38:03,771 Epoch[55] Batch [830]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.082635,	
2017-07-13 03:38:10,929 Epoch[55] Batch [840]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.082648,	
2017-07-13 03:38:17,979 Epoch[55] Batch [850]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.082529,	
2017-07-13 03:38:25,132 Epoch[55] Batch [860]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.082601,	
2017-07-13 03:38:31,988 Epoch[55] Batch [870]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.082569,	
2017-07-13 03:38:39,112 Epoch[55] Batch [880]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.082644,	
2017-07-13 03:38:46,516 Epoch[55] Batch [890]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.082564,	
2017-07-13 03:38:53,832 Epoch[55] Batch [900]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.082517,	
2017-07-13 03:39:00,934 Epoch[55] Batch [910]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.082490,	
2017-07-13 03:39:08,259 Epoch[55] Batch [920]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.082338,	
2017-07-13 03:39:15,689 Epoch[55] Batch [930]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.082342,	
2017-07-13 03:39:23,094 Epoch[55] Batch [940]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.082369,	
2017-07-13 03:39:30,550 Epoch[55] Batch [950]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.082330,	
2017-07-13 03:39:38,037 Epoch[55] Batch [960]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.082270,	
2017-07-13 03:39:45,612 Epoch[55] Batch [970]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.082239,	
2017-07-13 03:39:53,011 Epoch[55] Batch [980]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.082295,	
2017-07-13 03:40:00,559 Epoch[55] Batch [990]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.082407,	
2017-07-13 03:40:08,235 Epoch[55] Batch [1000]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.082374,	
2017-07-13 03:40:15,560 Epoch[55] Batch [1010]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.082358,	
2017-07-13 03:40:23,047 Epoch[55] Batch [1020]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.082333,	
2017-07-13 03:40:30,311 Epoch[55] Batch [1030]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.082306,	
2017-07-13 03:40:37,665 Epoch[55] Batch [1040]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.082262,	
2017-07-13 03:40:45,213 Epoch[55] Batch [1050]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.082234,	
2017-07-13 03:40:52,737 Epoch[55] Batch [1060]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.082195,	
2017-07-13 03:41:00,283 Epoch[55] Batch [1070]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.082187,	
2017-07-13 03:41:07,819 Epoch[55] Batch [1080]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.082155,	
2017-07-13 03:41:15,338 Epoch[55] Batch [1090]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.082097,	
2017-07-13 03:41:22,882 Epoch[55] Batch [1100]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.082119,	
2017-07-13 03:41:30,260 Epoch[55] Batch [1110]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.082125,	
2017-07-13 03:41:37,779 Epoch[55] Batch [1120]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.082081,	
2017-07-13 03:41:45,304 Epoch[55] Batch [1130]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.082089,	
2017-07-13 03:41:52,526 Epoch[55] Batch [1140]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.082037,	
2017-07-13 03:41:59,905 Epoch[55] Batch [1150]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.081963,	
2017-07-13 03:42:07,204 Epoch[55] Batch [1160]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.081921,	
2017-07-13 03:42:14,360 Epoch[55] Batch [1170]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.081932,	
2017-07-13 03:42:21,657 Epoch[55] Batch [1180]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.081936,	
2017-07-13 03:42:28,941 Epoch[55] Batch [1190]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.082028,	
2017-07-13 03:42:36,142 Epoch[55] Batch [1200]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.082022,	
2017-07-13 03:42:43,346 Epoch[55] Batch [1210]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.082015,	
2017-07-13 03:42:50,548 Epoch[55] Batch [1220]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.081962,	
2017-07-13 03:42:57,901 Epoch[55] Batch [1230]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.081903,	
2017-07-13 03:43:05,157 Epoch[55] Batch [1240]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.081893,	
2017-07-13 03:43:12,260 Epoch[55] Batch [1250]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.081955,	
2017-07-13 03:43:19,585 Epoch[55] Batch [1260]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.081933,	
2017-07-13 03:43:26,969 Epoch[55] Batch [1270]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.081881,	
2017-07-13 03:43:34,307 Epoch[55] Batch [1280]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.081917,	
2017-07-13 03:43:41,709 Epoch[55] Batch [1290]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.081886,	
2017-07-13 03:43:48,947 Epoch[55] Batch [1300]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.081818,	
2017-07-13 03:43:56,277 Epoch[55] Batch [1310]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.081850,	
2017-07-13 03:44:03,559 Epoch[55] Batch [1320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.081850,	
2017-07-13 03:44:10,757 Epoch[55] Batch [1330]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.081815,	
2017-07-13 03:44:17,956 Epoch[55] Batch [1340]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.081815,	
2017-07-13 03:44:25,302 Epoch[55] Batch [1350]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.081828,	
2017-07-13 03:44:32,490 Epoch[55] Batch [1360]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.081897,	
2017-07-13 03:44:39,511 Epoch[55] Batch [1370]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.081897,	
2017-07-13 03:44:46,764 Epoch[55] Batch [1380]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.081815,	
2017-07-13 03:44:54,053 Epoch[55] Batch [1390]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.081858,	
2017-07-13 03:45:01,633 Epoch[55] Batch [1400]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.081865,	
2017-07-13 03:45:09,106 Epoch[55] Batch [1410]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.081919,	
2017-07-13 03:45:16,626 Epoch[55] Batch [1420]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.081854,	
2017-07-13 03:45:23,950 Epoch[55] Batch [1430]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.081885,	
2017-07-13 03:45:31,434 Epoch[55] Batch [1440]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.081928,	
2017-07-13 03:45:38,877 Epoch[55] Batch [1450]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.082075,	
2017-07-13 03:45:46,250 Epoch[55] Batch [1460]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.082139,	
2017-07-13 03:45:53,522 Epoch[55] Batch [1470]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.082170,	
2017-07-13 03:46:00,822 Epoch[55] Batch [1480]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.082174,	
2017-07-13 03:46:05,324 Epoch[55] Train-FCNLogLoss=0.082165
2017-07-13 03:46:05,324 Epoch[55] Time cost=1080.425
2017-07-13 03:46:06,720 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0056.params"
2017-07-13 03:46:10,335 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0056.states"
2017-07-13 03:46:18,519 Epoch[56] Batch [10]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.075712,	
2017-07-13 03:46:25,766 Epoch[56] Batch [20]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.079295,	
2017-07-13 03:46:33,306 Epoch[56] Batch [30]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.077859,	
2017-07-13 03:46:40,672 Epoch[56] Batch [40]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.080094,	
2017-07-13 03:46:48,010 Epoch[56] Batch [50]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.080324,	
2017-07-13 03:46:55,504 Epoch[56] Batch [60]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.082686,	
2017-07-13 03:47:02,952 Epoch[56] Batch [70]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.082326,	
2017-07-13 03:47:09,886 Epoch[56] Batch [80]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.082654,	
2017-07-13 03:47:17,054 Epoch[56] Batch [90]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.082998,	
2017-07-13 03:47:24,112 Epoch[56] Batch [100]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.082225,	
2017-07-13 03:47:31,087 Epoch[56] Batch [110]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.082111,	
2017-07-13 03:47:37,904 Epoch[56] Batch [120]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.081773,	
2017-07-13 03:47:44,858 Epoch[56] Batch [130]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.082594,	
2017-07-13 03:47:51,955 Epoch[56] Batch [140]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.083078,	
2017-07-13 03:47:59,130 Epoch[56] Batch [150]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.083391,	
2017-07-13 03:48:06,154 Epoch[56] Batch [160]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.082627,	
2017-07-13 03:48:13,356 Epoch[56] Batch [170]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.082827,	
2017-07-13 03:48:20,477 Epoch[56] Batch [180]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.082708,	
2017-07-13 03:48:27,680 Epoch[56] Batch [190]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.082199,	
2017-07-13 03:48:34,656 Epoch[56] Batch [200]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.082007,	
2017-07-13 03:48:41,699 Epoch[56] Batch [210]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.082250,	
2017-07-13 03:48:49,015 Epoch[56] Batch [220]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.082274,	
2017-07-13 03:48:56,625 Epoch[56] Batch [230]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.082138,	
2017-07-13 03:49:03,898 Epoch[56] Batch [240]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.081873,	
2017-07-13 03:49:11,336 Epoch[56] Batch [250]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.081715,	
2017-07-13 03:49:18,897 Epoch[56] Batch [260]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.081484,	
2017-07-13 03:49:26,469 Epoch[56] Batch [270]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.081482,	
2017-07-13 03:49:33,941 Epoch[56] Batch [280]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.081247,	
2017-07-13 03:49:41,322 Epoch[56] Batch [290]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.080953,	
2017-07-13 03:49:48,849 Epoch[56] Batch [300]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.081281,	
2017-07-13 03:49:56,528 Epoch[56] Batch [310]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.081195,	
2017-07-13 03:50:04,213 Epoch[56] Batch [320]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.081253,	
2017-07-13 03:50:11,631 Epoch[56] Batch [330]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.081220,	
2017-07-13 03:50:19,092 Epoch[56] Batch [340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.081062,	
2017-07-13 03:50:26,468 Epoch[56] Batch [350]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.080933,	
2017-07-13 03:50:33,871 Epoch[56] Batch [360]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.080914,	
2017-07-13 03:50:41,475 Epoch[56] Batch [370]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.081061,	
2017-07-13 03:50:48,920 Epoch[56] Batch [380]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.081178,	
2017-07-13 03:50:56,509 Epoch[56] Batch [390]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.080984,	
2017-07-13 03:51:03,985 Epoch[56] Batch [400]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.081141,	
2017-07-13 03:51:11,435 Epoch[56] Batch [410]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.081091,	
2017-07-13 03:51:18,770 Epoch[56] Batch [420]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.081308,	
2017-07-13 03:51:26,104 Epoch[56] Batch [430]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.081416,	
2017-07-13 03:51:33,570 Epoch[56] Batch [440]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.081458,	
2017-07-13 03:51:40,983 Epoch[56] Batch [450]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.081369,	
2017-07-13 03:51:48,516 Epoch[56] Batch [460]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.081274,	
2017-07-13 03:51:55,800 Epoch[56] Batch [470]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.081102,	
2017-07-13 03:52:03,468 Epoch[56] Batch [480]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.081160,	
2017-07-13 03:52:11,110 Epoch[56] Batch [490]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.081245,	
2017-07-13 03:52:18,692 Epoch[56] Batch [500]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.081238,	
2017-07-13 03:52:26,205 Epoch[56] Batch [510]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.081331,	
2017-07-13 03:52:33,579 Epoch[56] Batch [520]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.081409,	
2017-07-13 03:52:40,946 Epoch[56] Batch [530]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.081463,	
2017-07-13 03:52:48,281 Epoch[56] Batch [540]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.081375,	
2017-07-13 03:52:55,872 Epoch[56] Batch [550]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.081490,	
2017-07-13 03:53:03,392 Epoch[56] Batch [560]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.081531,	
2017-07-13 03:53:10,595 Epoch[56] Batch [570]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.081540,	
2017-07-13 03:53:17,978 Epoch[56] Batch [580]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.081547,	
2017-07-13 03:53:25,481 Epoch[56] Batch [590]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.081390,	
2017-07-13 03:53:32,859 Epoch[56] Batch [600]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.081345,	
2017-07-13 03:53:40,231 Epoch[56] Batch [610]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.081415,	
2017-07-13 03:53:47,682 Epoch[56] Batch [620]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.081448,	
2017-07-13 03:53:55,125 Epoch[56] Batch [630]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.081424,	
2017-07-13 03:54:02,696 Epoch[56] Batch [640]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.081470,	
2017-07-13 03:54:09,960 Epoch[56] Batch [650]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.081442,	
2017-07-13 03:54:17,372 Epoch[56] Batch [660]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.081436,	
2017-07-13 03:54:24,732 Epoch[56] Batch [670]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.081429,	
2017-07-13 03:54:32,193 Epoch[56] Batch [680]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.081447,	
2017-07-13 03:54:39,567 Epoch[56] Batch [690]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.081410,	
2017-07-13 03:54:46,846 Epoch[56] Batch [700]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.081371,	
2017-07-13 03:54:54,389 Epoch[56] Batch [710]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.081274,	
2017-07-13 03:55:01,901 Epoch[56] Batch [720]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.081193,	
2017-07-13 03:55:08,967 Epoch[56] Batch [730]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.081278,	
2017-07-13 03:55:14,045 Epoch[56] Batch [740]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.081184,	
2017-07-13 03:55:18,892 Epoch[56] Batch [750]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.081227,	
2017-07-13 03:55:23,595 Epoch[56] Batch [760]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.081298,	
2017-07-13 03:55:28,102 Epoch[56] Batch [770]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.081409,	
2017-07-13 03:55:32,759 Epoch[56] Batch [780]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.081382,	
2017-07-13 03:55:37,482 Epoch[56] Batch [790]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.081476,	
2017-07-13 03:55:42,191 Epoch[56] Batch [800]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.081551,	
2017-07-13 03:55:46,876 Epoch[56] Batch [810]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.081491,	
2017-07-13 03:55:51,600 Epoch[56] Batch [820]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.081412,	
2017-07-13 03:55:56,371 Epoch[56] Batch [830]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.081334,	
2017-07-13 03:56:00,886 Epoch[56] Batch [840]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.081336,	
2017-07-13 03:56:05,745 Epoch[56] Batch [850]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.081332,	
2017-07-13 03:56:10,673 Epoch[56] Batch [860]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.081374,	
2017-07-13 03:56:15,716 Epoch[56] Batch [870]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.081391,	
2017-07-13 03:56:20,594 Epoch[56] Batch [880]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.081395,	
2017-07-13 03:56:25,287 Epoch[56] Batch [890]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.081398,	
2017-07-13 03:56:30,671 Epoch[56] Batch [900]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.081432,	
2017-07-13 03:56:35,973 Epoch[56] Batch [910]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.081503,	
2017-07-13 03:56:41,021 Epoch[56] Batch [920]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.081507,	
2017-07-13 03:56:45,606 Epoch[56] Batch [930]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.081531,	
2017-07-13 03:56:50,845 Epoch[56] Batch [940]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.081544,	
2017-07-13 03:56:55,483 Epoch[56] Batch [950]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.081465,	
2017-07-13 03:57:00,399 Epoch[56] Batch [960]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.081516,	
2017-07-13 03:57:05,516 Epoch[56] Batch [970]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.081561,	
2017-07-13 03:57:11,342 Epoch[56] Batch [980]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.081626,	
2017-07-13 03:57:16,253 Epoch[56] Batch [990]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.081631,	
2017-07-13 03:57:21,287 Epoch[56] Batch [1000]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.081630,	
2017-07-13 03:57:25,992 Epoch[56] Batch [1010]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.081611,	
2017-07-13 03:57:30,951 Epoch[56] Batch [1020]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.081543,	
2017-07-13 03:57:35,887 Epoch[56] Batch [1030]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.081519,	
2017-07-13 03:57:40,690 Epoch[56] Batch [1040]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.081487,	
2017-07-13 03:57:45,607 Epoch[56] Batch [1050]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.081446,	
2017-07-13 03:57:50,520 Epoch[56] Batch [1060]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.081426,	
2017-07-13 03:57:55,787 Epoch[56] Batch [1070]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.081453,	
2017-07-13 03:58:01,354 Epoch[56] Batch [1080]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.081453,	
2017-07-13 03:58:06,171 Epoch[56] Batch [1090]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.081455,	
2017-07-13 03:58:11,079 Epoch[56] Batch [1100]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.081517,	
2017-07-13 03:58:16,233 Epoch[56] Batch [1110]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.081529,	
2017-07-13 03:58:21,205 Epoch[56] Batch [1120]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.081542,	
2017-07-13 03:58:26,096 Epoch[56] Batch [1130]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.081569,	
2017-07-13 03:58:30,949 Epoch[56] Batch [1140]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.081609,	
2017-07-13 03:58:35,753 Epoch[56] Batch [1150]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.081542,	
2017-07-13 03:58:40,612 Epoch[56] Batch [1160]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.081581,	
2017-07-13 03:58:45,394 Epoch[56] Batch [1170]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.081577,	
2017-07-13 03:58:50,173 Epoch[56] Batch [1180]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.081524,	
2017-07-13 03:58:55,281 Epoch[56] Batch [1190]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.081542,	
2017-07-13 03:59:00,056 Epoch[56] Batch [1200]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.081528,	
2017-07-13 03:59:04,702 Epoch[56] Batch [1210]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.081495,	
2017-07-13 03:59:09,599 Epoch[56] Batch [1220]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.081467,	
2017-07-13 03:59:14,247 Epoch[56] Batch [1230]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.081495,	
2017-07-13 03:59:18,898 Epoch[56] Batch [1240]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.081557,	
2017-07-13 03:59:23,575 Epoch[56] Batch [1250]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.081559,	
2017-07-13 03:59:28,336 Epoch[56] Batch [1260]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.081541,	
2017-07-13 03:59:32,935 Epoch[56] Batch [1270]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.081543,	
2017-07-13 03:59:37,779 Epoch[56] Batch [1280]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.081476,	
2017-07-13 03:59:42,692 Epoch[56] Batch [1290]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.081528,	
2017-07-13 03:59:47,547 Epoch[56] Batch [1300]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.081515,	
2017-07-13 03:59:52,324 Epoch[56] Batch [1310]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.081519,	
2017-07-13 03:59:57,203 Epoch[56] Batch [1320]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.081528,	
2017-07-13 04:00:01,822 Epoch[56] Batch [1330]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.081483,	
2017-07-13 04:00:06,541 Epoch[56] Batch [1340]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.081466,	
2017-07-13 04:00:11,240 Epoch[56] Batch [1350]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.081462,	
2017-07-13 04:00:16,108 Epoch[56] Batch [1360]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.081497,	
2017-07-13 04:00:21,731 Epoch[56] Batch [1370]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.081536,	
2017-07-13 04:00:26,730 Epoch[56] Batch [1380]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.081517,	
2017-07-13 04:00:31,765 Epoch[56] Batch [1390]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.081499,	
2017-07-13 04:00:37,131 Epoch[56] Batch [1400]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.081542,	
2017-07-13 04:00:42,518 Epoch[56] Batch [1410]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.081582,	
2017-07-13 04:00:47,446 Epoch[56] Batch [1420]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.081625,	
2017-07-13 04:00:52,196 Epoch[56] Batch [1430]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.081571,	
2017-07-13 04:00:57,638 Epoch[56] Batch [1440]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.081481,	
2017-07-13 04:01:02,710 Epoch[56] Batch [1450]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.081450,	
2017-07-13 04:01:07,545 Epoch[56] Batch [1460]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.081473,	
2017-07-13 04:01:13,020 Epoch[56] Batch [1470]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.081477,	
2017-07-13 04:01:18,341 Epoch[56] Batch [1480]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.081472,	
2017-07-13 04:01:21,091 Epoch[56] Train-FCNLogLoss=0.081507
2017-07-13 04:01:21,091 Epoch[56] Time cost=910.756
2017-07-13 04:01:21,906 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0057.params"
2017-07-13 04:01:25,267 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0057.states"
2017-07-13 04:01:30,776 Epoch[57] Batch [10]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.078995,	
2017-07-13 04:01:35,987 Epoch[57] Batch [20]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.081436,	
2017-07-13 04:01:41,614 Epoch[57] Batch [30]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.081910,	
2017-07-13 04:01:47,464 Epoch[57] Batch [40]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.081695,	
2017-07-13 04:01:52,394 Epoch[57] Batch [50]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.081625,	
2017-07-13 04:01:57,874 Epoch[57] Batch [60]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.081950,	
2017-07-13 04:02:02,779 Epoch[57] Batch [70]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.082964,	
2017-07-13 04:02:07,897 Epoch[57] Batch [80]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.082650,	
2017-07-13 04:02:12,911 Epoch[57] Batch [90]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.082289,	
2017-07-13 04:02:18,125 Epoch[57] Batch [100]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.081826,	
2017-07-13 04:02:22,991 Epoch[57] Batch [110]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.081595,	
2017-07-13 04:02:27,874 Epoch[57] Batch [120]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.081389,	
2017-07-13 04:02:33,131 Epoch[57] Batch [130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.081152,	
2017-07-13 04:02:38,007 Epoch[57] Batch [140]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.080680,	
2017-07-13 04:02:42,686 Epoch[57] Batch [150]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.080554,	
2017-07-13 04:02:47,364 Epoch[57] Batch [160]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.080721,	
2017-07-13 04:02:52,307 Epoch[57] Batch [170]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.081277,	
2017-07-13 04:02:57,315 Epoch[57] Batch [180]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.081132,	
2017-07-13 04:03:02,353 Epoch[57] Batch [190]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.081177,	
2017-07-13 04:03:07,027 Epoch[57] Batch [200]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.080874,	
2017-07-13 04:03:11,908 Epoch[57] Batch [210]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.080977,	
2017-07-13 04:03:16,831 Epoch[57] Batch [220]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.080921,	
2017-07-13 04:03:21,674 Epoch[57] Batch [230]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.081059,	
2017-07-13 04:03:26,580 Epoch[57] Batch [240]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.080733,	
2017-07-13 04:03:31,778 Epoch[57] Batch [250]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.081161,	
2017-07-13 04:03:36,865 Epoch[57] Batch [260]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.081182,	
2017-07-13 04:03:41,741 Epoch[57] Batch [270]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.080923,	
2017-07-13 04:03:46,473 Epoch[57] Batch [280]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.081192,	
2017-07-13 04:03:51,110 Epoch[57] Batch [290]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.080954,	
2017-07-13 04:03:55,934 Epoch[57] Batch [300]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.080782,	
2017-07-13 04:04:00,795 Epoch[57] Batch [310]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.081113,	
2017-07-13 04:04:05,999 Epoch[57] Batch [320]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.081377,	
2017-07-13 04:04:10,833 Epoch[57] Batch [330]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.081516,	
2017-07-13 04:04:15,924 Epoch[57] Batch [340]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.081472,	
2017-07-13 04:04:21,717 Epoch[57] Batch [350]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.081338,	
2017-07-13 04:04:27,218 Epoch[57] Batch [360]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.081307,	
2017-07-13 04:04:32,197 Epoch[57] Batch [370]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.081480,	
2017-07-13 04:04:36,803 Epoch[57] Batch [380]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.081445,	
2017-07-13 04:04:42,375 Epoch[57] Batch [390]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.081611,	
2017-07-13 04:04:47,371 Epoch[57] Batch [400]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.081396,	
2017-07-13 04:04:52,500 Epoch[57] Batch [410]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.081203,	
2017-07-13 04:04:58,458 Epoch[57] Batch [420]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.081112,	
2017-07-13 04:05:04,250 Epoch[57] Batch [430]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.081057,	
2017-07-13 04:05:09,284 Epoch[57] Batch [440]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.081026,	
2017-07-13 04:05:14,228 Epoch[57] Batch [450]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.081010,	
2017-07-13 04:05:19,329 Epoch[57] Batch [460]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.081178,	
2017-07-13 04:05:24,138 Epoch[57] Batch [470]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.081282,	
2017-07-13 04:05:29,411 Epoch[57] Batch [480]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.081330,	
2017-07-13 04:05:34,628 Epoch[57] Batch [490]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.081475,	
2017-07-13 04:05:40,515 Epoch[57] Batch [500]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.081546,	
2017-07-13 04:05:45,821 Epoch[57] Batch [510]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.081666,	
2017-07-13 04:05:50,661 Epoch[57] Batch [520]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.081623,	
2017-07-13 04:05:55,681 Epoch[57] Batch [530]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.081683,	
2017-07-13 04:06:00,797 Epoch[57] Batch [540]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.081707,	
2017-07-13 04:06:06,763 Epoch[57] Batch [550]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.081663,	
2017-07-13 04:06:11,595 Epoch[57] Batch [560]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.081596,	
2017-07-13 04:06:16,976 Epoch[57] Batch [570]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.081762,	
2017-07-13 04:06:21,917 Epoch[57] Batch [580]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.081827,	
2017-07-13 04:06:26,798 Epoch[57] Batch [590]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.081800,	
2017-07-13 04:06:32,223 Epoch[57] Batch [600]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.081751,	
2017-07-13 04:06:37,181 Epoch[57] Batch [610]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.081631,	
2017-07-13 04:06:42,343 Epoch[57] Batch [620]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.081652,	
2017-07-13 04:06:47,734 Epoch[57] Batch [630]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.081765,	
2017-07-13 04:06:53,389 Epoch[57] Batch [640]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.081709,	
2017-07-13 04:06:58,652 Epoch[57] Batch [650]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.081784,	
2017-07-13 04:07:03,907 Epoch[57] Batch [660]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.081651,	
2017-07-13 04:07:08,701 Epoch[57] Batch [670]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.081533,	
2017-07-13 04:07:13,780 Epoch[57] Batch [680]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.081487,	
2017-07-13 04:07:18,942 Epoch[57] Batch [690]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.081440,	
2017-07-13 04:07:23,911 Epoch[57] Batch [700]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.081439,	
2017-07-13 04:07:29,288 Epoch[57] Batch [710]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.081294,	
2017-07-13 04:07:34,826 Epoch[57] Batch [720]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.081275,	
2017-07-13 04:07:39,834 Epoch[57] Batch [730]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.081371,	
2017-07-13 04:07:45,081 Epoch[57] Batch [740]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.081368,	
2017-07-13 04:07:50,231 Epoch[57] Batch [750]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.081434,	
2017-07-13 04:07:55,339 Epoch[57] Batch [760]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.081369,	
2017-07-13 04:08:00,278 Epoch[57] Batch [770]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.081391,	
2017-07-13 04:08:05,378 Epoch[57] Batch [780]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.081425,	
2017-07-13 04:08:10,273 Epoch[57] Batch [790]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.081375,	
2017-07-13 04:08:15,184 Epoch[57] Batch [800]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.081352,	
2017-07-13 04:08:21,116 Epoch[57] Batch [810]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.081296,	
2017-07-13 04:08:26,337 Epoch[57] Batch [820]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.081314,	
2017-07-13 04:08:31,284 Epoch[57] Batch [830]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.081258,	
2017-07-13 04:08:36,592 Epoch[57] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.081214,	
2017-07-13 04:08:42,041 Epoch[57] Batch [850]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.081278,	
2017-07-13 04:08:47,018 Epoch[57] Batch [860]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.081323,	
2017-07-13 04:08:51,843 Epoch[57] Batch [870]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.081270,	
2017-07-13 04:08:56,830 Epoch[57] Batch [880]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.081220,	
2017-07-13 04:09:02,138 Epoch[57] Batch [890]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.081241,	
2017-07-13 04:09:07,409 Epoch[57] Batch [900]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.081162,	
2017-07-13 04:09:12,673 Epoch[57] Batch [910]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.081178,	
2017-07-13 04:09:17,815 Epoch[57] Batch [920]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.081089,	
2017-07-13 04:09:22,828 Epoch[57] Batch [930]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.081110,	
2017-07-13 04:09:27,976 Epoch[57] Batch [940]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.081055,	
2017-07-13 04:09:33,451 Epoch[57] Batch [950]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.081063,	
2017-07-13 04:09:38,992 Epoch[57] Batch [960]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.081130,	
2017-07-13 04:09:44,527 Epoch[57] Batch [970]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.081111,	
2017-07-13 04:09:49,818 Epoch[57] Batch [980]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.081143,	
2017-07-13 04:09:55,080 Epoch[57] Batch [990]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.081140,	
2017-07-13 04:10:00,403 Epoch[57] Batch [1000]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.081167,	
2017-07-13 04:10:05,487 Epoch[57] Batch [1010]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.081184,	
2017-07-13 04:10:10,702 Epoch[57] Batch [1020]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.081211,	
2017-07-13 04:10:15,753 Epoch[57] Batch [1030]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.081207,	
2017-07-13 04:10:20,851 Epoch[57] Batch [1040]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.081134,	
2017-07-13 04:10:26,036 Epoch[57] Batch [1050]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.081226,	
2017-07-13 04:10:30,871 Epoch[57] Batch [1060]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.081190,	
2017-07-13 04:10:36,862 Epoch[57] Batch [1070]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.081207,	
2017-07-13 04:10:42,255 Epoch[57] Batch [1080]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.081201,	
2017-07-13 04:10:47,279 Epoch[57] Batch [1090]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.081222,	
2017-07-13 04:10:52,247 Epoch[57] Batch [1100]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.081263,	
2017-07-13 04:10:57,224 Epoch[57] Batch [1110]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.081209,	
2017-07-13 04:11:02,423 Epoch[57] Batch [1120]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.081158,	
2017-07-13 04:11:07,258 Epoch[57] Batch [1130]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.081196,	
2017-07-13 04:11:12,307 Epoch[57] Batch [1140]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.081113,	
2017-07-13 04:11:17,583 Epoch[57] Batch [1150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.081081,	
2017-07-13 04:11:22,388 Epoch[57] Batch [1160]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.081035,	
2017-07-13 04:11:27,395 Epoch[57] Batch [1170]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.080965,	
2017-07-13 04:11:32,404 Epoch[57] Batch [1180]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.081024,	
2017-07-13 04:11:37,451 Epoch[57] Batch [1190]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.080963,	
2017-07-13 04:11:43,083 Epoch[57] Batch [1200]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.080940,	
2017-07-13 04:11:48,883 Epoch[57] Batch [1210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.080989,	
2017-07-13 04:11:54,827 Epoch[57] Batch [1220]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.080966,	
2017-07-13 04:11:59,941 Epoch[57] Batch [1230]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.080979,	
2017-07-13 04:12:05,317 Epoch[57] Batch [1240]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.081061,	
2017-07-13 04:12:11,102 Epoch[57] Batch [1250]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.081021,	
2017-07-13 04:12:16,424 Epoch[57] Batch [1260]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.081004,	
2017-07-13 04:12:21,442 Epoch[57] Batch [1270]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.080949,	
2017-07-13 04:12:26,771 Epoch[57] Batch [1280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.081000,	
2017-07-13 04:12:32,082 Epoch[57] Batch [1290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.081030,	
2017-07-13 04:12:37,503 Epoch[57] Batch [1300]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.081055,	
2017-07-13 04:12:42,594 Epoch[57] Batch [1310]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.081056,	
2017-07-13 04:12:47,843 Epoch[57] Batch [1320]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.081078,	
2017-07-13 04:12:53,058 Epoch[57] Batch [1330]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.081092,	
2017-07-13 04:12:58,751 Epoch[57] Batch [1340]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.081135,	
2017-07-13 04:13:04,090 Epoch[57] Batch [1350]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.081194,	
2017-07-13 04:13:10,104 Epoch[57] Batch [1360]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.081100,	
2017-07-13 04:13:16,254 Epoch[57] Batch [1370]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.081102,	
2017-07-13 04:13:22,141 Epoch[57] Batch [1380]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.081166,	
2017-07-13 04:13:28,235 Epoch[57] Batch [1390]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.081185,	
2017-07-13 04:13:34,312 Epoch[57] Batch [1400]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.081143,	
2017-07-13 04:13:40,451 Epoch[57] Batch [1410]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.081123,	
2017-07-13 04:13:46,389 Epoch[57] Batch [1420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.081134,	
2017-07-13 04:13:52,320 Epoch[57] Batch [1430]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.081143,	
2017-07-13 04:13:58,229 Epoch[57] Batch [1440]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.081122,	
2017-07-13 04:14:03,942 Epoch[57] Batch [1450]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.081104,	
2017-07-13 04:14:10,220 Epoch[57] Batch [1460]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.081096,	
2017-07-13 04:14:16,400 Epoch[57] Batch [1470]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.081114,	
2017-07-13 04:14:22,222 Epoch[57] Batch [1480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.081132,	
2017-07-13 04:14:25,856 Epoch[57] Train-FCNLogLoss=0.081139
2017-07-13 04:14:25,856 Epoch[57] Time cost=780.589
2017-07-13 04:14:27,233 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0058.params"
2017-07-13 04:14:30,803 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0058.states"
2017-07-13 04:14:37,815 Epoch[58] Batch [10]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.080994,	
2017-07-13 04:14:43,969 Epoch[58] Batch [20]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.077599,	
2017-07-13 04:14:50,185 Epoch[58] Batch [30]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.078191,	
2017-07-13 04:14:56,623 Epoch[58] Batch [40]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.076959,	
2017-07-13 04:15:03,190 Epoch[58] Batch [50]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.077826,	
2017-07-13 04:15:09,364 Epoch[58] Batch [60]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.077191,	
2017-07-13 04:15:15,489 Epoch[58] Batch [70]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.076374,	
2017-07-13 04:15:21,929 Epoch[58] Batch [80]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.076975,	
2017-07-13 04:15:28,216 Epoch[58] Batch [90]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.076703,	
2017-07-13 04:15:34,499 Epoch[58] Batch [100]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.076844,	
2017-07-13 04:15:40,657 Epoch[58] Batch [110]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.076678,	
2017-07-13 04:15:46,537 Epoch[58] Batch [120]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.076396,	
2017-07-13 04:15:52,756 Epoch[58] Batch [130]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.076972,	
2017-07-13 04:15:58,843 Epoch[58] Batch [140]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.077079,	
2017-07-13 04:16:05,117 Epoch[58] Batch [150]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.077656,	
2017-07-13 04:16:10,944 Epoch[58] Batch [160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.077851,	
2017-07-13 04:16:16,893 Epoch[58] Batch [170]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.078074,	
2017-07-13 04:16:23,170 Epoch[58] Batch [180]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.078196,	
2017-07-13 04:16:29,636 Epoch[58] Batch [190]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.078516,	
2017-07-13 04:16:35,927 Epoch[58] Batch [200]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.079236,	
2017-07-13 04:16:42,416 Epoch[58] Batch [210]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.079332,	
2017-07-13 04:16:48,543 Epoch[58] Batch [220]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.079380,	
2017-07-13 04:16:54,891 Epoch[58] Batch [230]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.079232,	
2017-07-13 04:17:01,464 Epoch[58] Batch [240]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.079055,	
2017-07-13 04:17:07,929 Epoch[58] Batch [250]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.078967,	
2017-07-13 04:17:15,046 Epoch[58] Batch [260]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.079124,	
2017-07-13 04:17:21,792 Epoch[58] Batch [270]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.079226,	
2017-07-13 04:17:29,125 Epoch[58] Batch [280]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.079206,	
2017-07-13 04:17:36,389 Epoch[58] Batch [290]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.079199,	
2017-07-13 04:17:43,526 Epoch[58] Batch [300]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.079491,	
2017-07-13 04:17:50,538 Epoch[58] Batch [310]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.079320,	
2017-07-13 04:17:57,680 Epoch[58] Batch [320]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.079300,	
2017-07-13 04:18:04,719 Epoch[58] Batch [330]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.079706,	
2017-07-13 04:18:11,658 Epoch[58] Batch [340]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.079583,	
2017-07-13 04:18:18,803 Epoch[58] Batch [350]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.079523,	
2017-07-13 04:18:26,010 Epoch[58] Batch [360]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.079672,	
2017-07-13 04:18:33,059 Epoch[58] Batch [370]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.079644,	
2017-07-13 04:18:40,153 Epoch[58] Batch [380]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.079566,	
2017-07-13 04:18:47,237 Epoch[58] Batch [390]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.079715,	
2017-07-13 04:18:54,375 Epoch[58] Batch [400]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.079730,	
2017-07-13 04:19:01,445 Epoch[58] Batch [410]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.079962,	
2017-07-13 04:19:08,757 Epoch[58] Batch [420]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.080274,	
2017-07-13 04:19:15,886 Epoch[58] Batch [430]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.080360,	
2017-07-13 04:19:23,110 Epoch[58] Batch [440]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.080558,	
2017-07-13 04:19:30,525 Epoch[58] Batch [450]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.080601,	
2017-07-13 04:19:37,850 Epoch[58] Batch [460]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.080648,	
2017-07-13 04:19:45,108 Epoch[58] Batch [470]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.080536,	
2017-07-13 04:19:52,456 Epoch[58] Batch [480]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.080468,	
2017-07-13 04:19:59,601 Epoch[58] Batch [490]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.080414,	
2017-07-13 04:20:06,938 Epoch[58] Batch [500]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.080376,	
2017-07-13 04:20:14,136 Epoch[58] Batch [510]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.080268,	
2017-07-13 04:20:21,426 Epoch[58] Batch [520]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.080432,	
2017-07-13 04:20:28,826 Epoch[58] Batch [530]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.080215,	
2017-07-13 04:20:36,332 Epoch[58] Batch [540]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.080393,	
2017-07-13 04:20:43,510 Epoch[58] Batch [550]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.080271,	
2017-07-13 04:20:50,999 Epoch[58] Batch [560]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.080244,	
2017-07-13 04:20:58,540 Epoch[58] Batch [570]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.080243,	
2017-07-13 04:21:06,104 Epoch[58] Batch [580]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.080342,	
2017-07-13 04:21:13,390 Epoch[58] Batch [590]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.080256,	
2017-07-13 04:21:20,932 Epoch[58] Batch [600]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.080241,	
2017-07-13 04:21:28,533 Epoch[58] Batch [610]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.080205,	
2017-07-13 04:21:36,213 Epoch[58] Batch [620]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.080211,	
2017-07-13 04:21:44,010 Epoch[58] Batch [630]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.080244,	
2017-07-13 04:21:51,592 Epoch[58] Batch [640]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.080256,	
2017-07-13 04:21:59,407 Epoch[58] Batch [650]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.080137,	
2017-07-13 04:22:07,093 Epoch[58] Batch [660]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.080160,	
2017-07-13 04:22:14,847 Epoch[58] Batch [670]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.080122,	
2017-07-13 04:22:22,627 Epoch[58] Batch [680]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.080104,	
2017-07-13 04:22:30,577 Epoch[58] Batch [690]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.080174,	
2017-07-13 04:22:38,075 Epoch[58] Batch [700]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.080132,	
2017-07-13 04:22:45,849 Epoch[58] Batch [710]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.080211,	
2017-07-13 04:22:53,493 Epoch[58] Batch [720]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.080268,	
2017-07-13 04:23:00,963 Epoch[58] Batch [730]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.080315,	
2017-07-13 04:23:08,673 Epoch[58] Batch [740]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.080416,	
2017-07-13 04:23:16,274 Epoch[58] Batch [750]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.080429,	
2017-07-13 04:23:23,847 Epoch[58] Batch [760]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.080396,	
2017-07-13 04:23:31,231 Epoch[58] Batch [770]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.080293,	
2017-07-13 04:23:38,744 Epoch[58] Batch [780]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.080225,	
2017-07-13 04:23:46,398 Epoch[58] Batch [790]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.080139,	
2017-07-13 04:23:54,253 Epoch[58] Batch [800]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.080176,	
2017-07-13 04:24:02,009 Epoch[58] Batch [810]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.080159,	
2017-07-13 04:24:09,804 Epoch[58] Batch [820]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.080128,	
2017-07-13 04:24:17,678 Epoch[58] Batch [830]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.080192,	
2017-07-13 04:24:25,668 Epoch[58] Batch [840]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.080177,	
2017-07-13 04:24:33,557 Epoch[58] Batch [850]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.080134,	
2017-07-13 04:24:41,350 Epoch[58] Batch [860]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.080055,	
2017-07-13 04:24:49,247 Epoch[58] Batch [870]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.080050,	
2017-07-13 04:24:56,962 Epoch[58] Batch [880]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.080019,	
2017-07-13 04:25:04,910 Epoch[58] Batch [890]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.079974,	
2017-07-13 04:25:12,641 Epoch[58] Batch [900]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.079975,	
2017-07-13 04:25:20,336 Epoch[58] Batch [910]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.079929,	
2017-07-13 04:25:28,088 Epoch[58] Batch [920]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.079840,	
2017-07-13 04:25:35,847 Epoch[58] Batch [930]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.079864,	
2017-07-13 04:25:43,665 Epoch[58] Batch [940]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.079794,	
2017-07-13 04:25:51,477 Epoch[58] Batch [950]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.079722,	
2017-07-13 04:25:59,326 Epoch[58] Batch [960]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.079725,	
2017-07-13 04:26:07,034 Epoch[58] Batch [970]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.079669,	
2017-07-13 04:26:14,724 Epoch[58] Batch [980]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.079576,	
2017-07-13 04:26:22,662 Epoch[58] Batch [990]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.079587,	
2017-07-13 04:26:30,455 Epoch[58] Batch [1000]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.079588,	
2017-07-13 04:26:38,306 Epoch[58] Batch [1010]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.079641,	
2017-07-13 04:26:46,220 Epoch[58] Batch [1020]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.079731,	
2017-07-13 04:26:54,045 Epoch[58] Batch [1030]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.079816,	
2017-07-13 04:27:01,716 Epoch[58] Batch [1040]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.079864,	
2017-07-13 04:27:09,642 Epoch[58] Batch [1050]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.079885,	
2017-07-13 04:27:17,507 Epoch[58] Batch [1060]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.079996,	
2017-07-13 04:27:25,201 Epoch[58] Batch [1070]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.080095,	
2017-07-13 04:27:32,984 Epoch[58] Batch [1080]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.080145,	
2017-07-13 04:27:40,541 Epoch[58] Batch [1090]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.080171,	
2017-07-13 04:27:48,348 Epoch[58] Batch [1100]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.080236,	
2017-07-13 04:27:55,973 Epoch[58] Batch [1110]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.080179,	
2017-07-13 04:28:03,642 Epoch[58] Batch [1120]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.080164,	
2017-07-13 04:28:11,321 Epoch[58] Batch [1130]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.080198,	
2017-07-13 04:28:19,185 Epoch[58] Batch [1140]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.080180,	
2017-07-13 04:28:26,945 Epoch[58] Batch [1150]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.080163,	
2017-07-13 04:28:34,863 Epoch[58] Batch [1160]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.080216,	
2017-07-13 04:28:42,603 Epoch[58] Batch [1170]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.080211,	
2017-07-13 04:28:50,338 Epoch[58] Batch [1180]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.080192,	
2017-07-13 04:28:58,029 Epoch[58] Batch [1190]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.080213,	
2017-07-13 04:29:05,780 Epoch[58] Batch [1200]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.080224,	
2017-07-13 04:29:13,435 Epoch[58] Batch [1210]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.080255,	
2017-07-13 04:29:21,595 Epoch[58] Batch [1220]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.080246,	
2017-07-13 04:29:29,349 Epoch[58] Batch [1230]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.080260,	
2017-07-13 04:29:37,170 Epoch[58] Batch [1240]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.080258,	
2017-07-13 04:29:45,124 Epoch[58] Batch [1250]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.080195,	
2017-07-13 04:29:53,037 Epoch[58] Batch [1260]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.080161,	
2017-07-13 04:29:58,751 Epoch[58] Batch [1270]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.080145,	
2017-07-13 04:30:02,760 Epoch[58] Batch [1280]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.080213,	
2017-07-13 04:30:06,941 Epoch[58] Batch [1290]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.080134,	
2017-07-13 04:30:11,082 Epoch[58] Batch [1300]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.080198,	
2017-07-13 04:30:15,211 Epoch[58] Batch [1310]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.080193,	
2017-07-13 04:30:19,271 Epoch[58] Batch [1320]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.080219,	
2017-07-13 04:30:23,203 Epoch[58] Batch [1330]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.080204,	
2017-07-13 04:30:27,497 Epoch[58] Batch [1340]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.080158,	
2017-07-13 04:30:31,620 Epoch[58] Batch [1350]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.080184,	
2017-07-13 04:30:35,859 Epoch[58] Batch [1360]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.080188,	
2017-07-13 04:30:40,111 Epoch[58] Batch [1370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.080118,	
2017-07-13 04:30:44,154 Epoch[58] Batch [1380]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.080132,	
2017-07-13 04:30:48,341 Epoch[58] Batch [1390]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.080115,	
2017-07-13 04:30:52,368 Epoch[58] Batch [1400]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.080143,	
2017-07-13 04:30:56,606 Epoch[58] Batch [1410]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.080197,	
2017-07-13 04:31:01,106 Epoch[58] Batch [1420]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.080217,	
2017-07-13 04:31:05,244 Epoch[58] Batch [1430]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.080234,	
2017-07-13 04:31:09,378 Epoch[58] Batch [1440]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.080209,	
2017-07-13 04:31:13,754 Epoch[58] Batch [1450]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.080270,	
2017-07-13 04:31:17,853 Epoch[58] Batch [1460]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.080290,	
2017-07-13 04:31:21,871 Epoch[58] Batch [1470]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.080325,	
2017-07-13 04:31:25,902 Epoch[58] Batch [1480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.080308,	
2017-07-13 04:31:28,287 Epoch[58] Train-FCNLogLoss=0.080328
2017-07-13 04:31:28,287 Epoch[58] Time cost=1017.484
2017-07-13 04:31:29,119 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0059.params"
2017-07-13 04:31:30,906 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0059.states"
2017-07-13 04:31:35,812 Epoch[59] Batch [10]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.070945,	
2017-07-13 04:31:39,798 Epoch[59] Batch [20]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.074135,	
2017-07-13 04:31:43,898 Epoch[59] Batch [30]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.074504,	
2017-07-13 04:31:47,892 Epoch[59] Batch [40]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.075978,	
2017-07-13 04:31:52,257 Epoch[59] Batch [50]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.075521,	
2017-07-13 04:31:56,370 Epoch[59] Batch [60]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.077978,	
2017-07-13 04:32:00,369 Epoch[59] Batch [70]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.078198,	
2017-07-13 04:32:04,553 Epoch[59] Batch [80]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.079246,	
2017-07-13 04:32:08,906 Epoch[59] Batch [90]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.080195,	
2017-07-13 04:32:12,988 Epoch[59] Batch [100]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.079568,	
2017-07-13 04:32:17,155 Epoch[59] Batch [110]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.080372,	
2017-07-13 04:32:21,366 Epoch[59] Batch [120]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.080520,	
2017-07-13 04:32:25,255 Epoch[59] Batch [130]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.080351,	
2017-07-13 04:32:29,184 Epoch[59] Batch [140]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.080883,	
2017-07-13 04:32:33,365 Epoch[59] Batch [150]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.080732,	
2017-07-13 04:32:37,781 Epoch[59] Batch [160]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.080504,	
2017-07-13 04:32:42,004 Epoch[59] Batch [170]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.080473,	
2017-07-13 04:32:46,150 Epoch[59] Batch [180]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.080844,	
2017-07-13 04:32:50,204 Epoch[59] Batch [190]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.080771,	
2017-07-13 04:32:54,342 Epoch[59] Batch [200]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.080805,	
2017-07-13 04:32:58,302 Epoch[59] Batch [210]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.080719,	
2017-07-13 04:33:02,538 Epoch[59] Batch [220]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.080841,	
2017-07-13 04:33:06,638 Epoch[59] Batch [230]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.080422,	
2017-07-13 04:33:10,927 Epoch[59] Batch [240]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.080359,	
2017-07-13 04:33:15,217 Epoch[59] Batch [250]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.080659,	
2017-07-13 04:33:19,352 Epoch[59] Batch [260]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.080283,	
2017-07-13 04:33:23,378 Epoch[59] Batch [270]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.080208,	
2017-07-13 04:33:27,470 Epoch[59] Batch [280]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.080122,	
2017-07-13 04:33:31,597 Epoch[59] Batch [290]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.080471,	
2017-07-13 04:33:35,884 Epoch[59] Batch [300]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.080647,	
2017-07-13 04:33:40,104 Epoch[59] Batch [310]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.080769,	
2017-07-13 04:33:44,152 Epoch[59] Batch [320]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.080751,	
2017-07-13 04:33:48,112 Epoch[59] Batch [330]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.080932,	
2017-07-13 04:33:52,282 Epoch[59] Batch [340]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.080828,	
2017-07-13 04:33:56,758 Epoch[59] Batch [350]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.080864,	
2017-07-13 04:34:00,887 Epoch[59] Batch [360]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.080730,	
2017-07-13 04:34:05,065 Epoch[59] Batch [370]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.080533,	
2017-07-13 04:34:09,089 Epoch[59] Batch [380]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.080580,	
2017-07-13 04:34:13,258 Epoch[59] Batch [390]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.080629,	
2017-07-13 04:34:17,316 Epoch[59] Batch [400]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.080767,	
2017-07-13 04:34:21,481 Epoch[59] Batch [410]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.080889,	
2017-07-13 04:34:25,606 Epoch[59] Batch [420]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.080771,	
2017-07-13 04:34:29,844 Epoch[59] Batch [430]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.080953,	
2017-07-13 04:34:34,110 Epoch[59] Batch [440]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.081139,	
2017-07-13 04:34:38,242 Epoch[59] Batch [450]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.080938,	
2017-07-13 04:34:42,431 Epoch[59] Batch [460]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.080820,	
2017-07-13 04:34:46,523 Epoch[59] Batch [470]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.080730,	
2017-07-13 04:34:50,890 Epoch[59] Batch [480]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.080741,	
2017-07-13 04:34:55,063 Epoch[59] Batch [490]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.080648,	
2017-07-13 04:34:59,202 Epoch[59] Batch [500]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.080677,	
2017-07-13 04:35:03,365 Epoch[59] Batch [510]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.080646,	
2017-07-13 04:35:07,424 Epoch[59] Batch [520]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.080602,	
2017-07-13 04:35:11,690 Epoch[59] Batch [530]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.080813,	
2017-07-13 04:35:15,695 Epoch[59] Batch [540]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.080725,	
2017-07-13 04:35:19,632 Epoch[59] Batch [550]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.080719,	
2017-07-13 04:35:23,851 Epoch[59] Batch [560]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.080731,	
2017-07-13 04:35:28,125 Epoch[59] Batch [570]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.080691,	
2017-07-13 04:35:32,419 Epoch[59] Batch [580]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.080761,	
2017-07-13 04:35:36,708 Epoch[59] Batch [590]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.080700,	
2017-07-13 04:35:40,808 Epoch[59] Batch [600]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.080576,	
2017-07-13 04:35:45,016 Epoch[59] Batch [610]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.080671,	
2017-07-13 04:35:49,105 Epoch[59] Batch [620]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.080762,	
2017-07-13 04:35:53,188 Epoch[59] Batch [630]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.080701,	
2017-07-13 04:35:57,507 Epoch[59] Batch [640]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.080668,	
2017-07-13 04:36:01,893 Epoch[59] Batch [650]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.080700,	
2017-07-13 04:36:06,376 Epoch[59] Batch [660]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.080617,	
2017-07-13 04:36:10,434 Epoch[59] Batch [670]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.080552,	
2017-07-13 04:36:14,406 Epoch[59] Batch [680]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.080544,	
2017-07-13 04:36:18,637 Epoch[59] Batch [690]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.080459,	
2017-07-13 04:36:22,816 Epoch[59] Batch [700]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.080419,	
2017-07-13 04:36:26,871 Epoch[59] Batch [710]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.080409,	
2017-07-13 04:36:30,878 Epoch[59] Batch [720]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.080351,	
2017-07-13 04:36:34,912 Epoch[59] Batch [730]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.080410,	
2017-07-13 04:36:38,997 Epoch[59] Batch [740]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.080418,	
2017-07-13 04:36:43,391 Epoch[59] Batch [750]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.080388,	
2017-07-13 04:36:47,792 Epoch[59] Batch [760]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.080309,	
2017-07-13 04:36:51,860 Epoch[59] Batch [770]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.080278,	
2017-07-13 04:36:56,062 Epoch[59] Batch [780]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.080212,	
2017-07-13 04:37:00,119 Epoch[59] Batch [790]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.080222,	
2017-07-13 04:37:04,314 Epoch[59] Batch [800]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.080194,	
2017-07-13 04:37:08,411 Epoch[59] Batch [810]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.080149,	
2017-07-13 04:37:12,495 Epoch[59] Batch [820]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.080181,	
2017-07-13 04:37:16,705 Epoch[59] Batch [830]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.080146,	
2017-07-13 04:37:20,694 Epoch[59] Batch [840]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.080080,	
2017-07-13 04:37:24,968 Epoch[59] Batch [850]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.080112,	
2017-07-13 04:37:29,117 Epoch[59] Batch [860]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.080124,	
2017-07-13 04:37:33,514 Epoch[59] Batch [870]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.080097,	
2017-07-13 04:37:37,868 Epoch[59] Batch [880]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.080051,	
2017-07-13 04:37:41,948 Epoch[59] Batch [890]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.080011,	
2017-07-13 04:37:45,987 Epoch[59] Batch [900]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.079980,	
2017-07-13 04:37:50,162 Epoch[59] Batch [910]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.079956,	
2017-07-13 04:37:54,494 Epoch[59] Batch [920]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.079937,	
2017-07-13 04:37:58,404 Epoch[59] Batch [930]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.079856,	
2017-07-13 04:38:02,656 Epoch[59] Batch [940]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.079942,	
2017-07-13 04:38:06,635 Epoch[59] Batch [950]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.080009,	
2017-07-13 04:38:10,602 Epoch[59] Batch [960]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.079992,	
2017-07-13 04:38:14,828 Epoch[59] Batch [970]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.080017,	
2017-07-13 04:38:18,890 Epoch[59] Batch [980]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.080058,	
2017-07-13 04:38:23,035 Epoch[59] Batch [990]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.080127,	
2017-07-13 04:38:27,032 Epoch[59] Batch [1000]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.080172,	
2017-07-13 04:38:31,157 Epoch[59] Batch [1010]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.080159,	
2017-07-13 04:38:35,625 Epoch[59] Batch [1020]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.080212,	
2017-07-13 04:38:39,902 Epoch[59] Batch [1030]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.080188,	
2017-07-13 04:38:44,077 Epoch[59] Batch [1040]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.080229,	
2017-07-13 04:38:48,174 Epoch[59] Batch [1050]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.080185,	
2017-07-13 04:38:52,372 Epoch[59] Batch [1060]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.080171,	
2017-07-13 04:38:56,537 Epoch[59] Batch [1070]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.080184,	
2017-07-13 04:39:00,727 Epoch[59] Batch [1080]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.080182,	
2017-07-13 04:39:04,674 Epoch[59] Batch [1090]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.080189,	
2017-07-13 04:39:08,798 Epoch[59] Batch [1100]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.080204,	
2017-07-13 04:39:12,887 Epoch[59] Batch [1110]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.080107,	
2017-07-13 04:39:17,076 Epoch[59] Batch [1120]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.080070,	
2017-07-13 04:39:21,397 Epoch[59] Batch [1130]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.080131,	
2017-07-13 04:39:25,596 Epoch[59] Batch [1140]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.080172,	
2017-07-13 04:39:29,754 Epoch[59] Batch [1150]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.080198,	
2017-07-13 04:39:34,043 Epoch[59] Batch [1160]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.080179,	
2017-07-13 04:39:38,236 Epoch[59] Batch [1170]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.080091,	
2017-07-13 04:39:42,402 Epoch[59] Batch [1180]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.080088,	
2017-07-13 04:39:46,395 Epoch[59] Batch [1190]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.080059,	
2017-07-13 04:39:50,695 Epoch[59] Batch [1200]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.080116,	
2017-07-13 04:39:54,744 Epoch[59] Batch [1210]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.080059,	
2017-07-13 04:39:58,848 Epoch[59] Batch [1220]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.080076,	
2017-07-13 04:40:02,985 Epoch[59] Batch [1230]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.080047,	
2017-07-13 04:40:07,059 Epoch[59] Batch [1240]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.080008,	
2017-07-13 04:40:11,404 Epoch[59] Batch [1250]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.080017,	
2017-07-13 04:40:16,090 Epoch[59] Batch [1260]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.080017,	
2017-07-13 04:40:20,169 Epoch[59] Batch [1270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.079955,	
2017-07-13 04:40:24,525 Epoch[59] Batch [1280]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.080015,	
2017-07-13 04:40:28,771 Epoch[59] Batch [1290]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.080060,	
2017-07-13 04:40:33,022 Epoch[59] Batch [1300]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.080048,	
2017-07-13 04:40:37,117 Epoch[59] Batch [1310]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.080005,	
2017-07-13 04:40:41,261 Epoch[59] Batch [1320]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.079966,	
2017-07-13 04:40:45,274 Epoch[59] Batch [1330]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.079949,	
2017-07-13 04:40:49,450 Epoch[59] Batch [1340]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.079951,	
2017-07-13 04:40:53,540 Epoch[59] Batch [1350]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.079901,	
2017-07-13 04:40:57,533 Epoch[59] Batch [1360]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.079922,	
2017-07-13 04:41:01,938 Epoch[59] Batch [1370]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.079883,	
2017-07-13 04:41:06,027 Epoch[59] Batch [1380]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.079865,	
2017-07-13 04:41:09,972 Epoch[59] Batch [1390]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.079896,	
2017-07-13 04:41:14,170 Epoch[59] Batch [1400]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.079846,	
2017-07-13 04:41:18,126 Epoch[59] Batch [1410]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.079859,	
2017-07-13 04:41:22,310 Epoch[59] Batch [1420]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.079854,	
2017-07-13 04:41:26,411 Epoch[59] Batch [1430]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.079810,	
2017-07-13 04:41:30,577 Epoch[59] Batch [1440]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.079855,	
2017-07-13 04:41:34,741 Epoch[59] Batch [1450]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.079839,	
2017-07-13 04:41:38,887 Epoch[59] Batch [1460]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.079824,	
2017-07-13 04:41:43,043 Epoch[59] Batch [1470]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.079873,	
2017-07-13 04:41:47,395 Epoch[59] Batch [1480]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.079920,	
2017-07-13 04:41:49,956 Epoch[59] Train-FCNLogLoss=0.079932
2017-07-13 04:41:49,956 Epoch[59] Time cost=619.050
2017-07-13 04:41:50,740 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0060.params"
2017-07-13 04:41:52,833 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0060.states"
2017-07-13 04:41:57,732 Epoch[60] Batch [10]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.083856,	
2017-07-13 04:42:01,820 Epoch[60] Batch [20]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.082342,	
2017-07-13 04:42:05,749 Epoch[60] Batch [30]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.081080,	
2017-07-13 04:42:10,089 Epoch[60] Batch [40]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.081238,	
2017-07-13 04:42:14,256 Epoch[60] Batch [50]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.081879,	
2017-07-13 04:42:18,372 Epoch[60] Batch [60]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.082643,	
2017-07-13 04:42:22,587 Epoch[60] Batch [70]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.082425,	
2017-07-13 04:42:26,478 Epoch[60] Batch [80]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.082136,	
2017-07-13 04:42:30,608 Epoch[60] Batch [90]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.082084,	
2017-07-13 04:42:34,921 Epoch[60] Batch [100]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.081690,	
2017-07-13 04:42:39,117 Epoch[60] Batch [110]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.081119,	
2017-07-13 04:42:43,138 Epoch[60] Batch [120]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.080719,	
2017-07-13 04:42:47,234 Epoch[60] Batch [130]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.080532,	
2017-07-13 04:42:51,529 Epoch[60] Batch [140]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.080390,	
2017-07-13 04:42:55,819 Epoch[60] Batch [150]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.080869,	
2017-07-13 04:43:00,037 Epoch[60] Batch [160]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.080267,	
2017-07-13 04:43:04,238 Epoch[60] Batch [170]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.080556,	
2017-07-13 04:43:08,202 Epoch[60] Batch [180]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.080792,	
2017-07-13 04:43:12,512 Epoch[60] Batch [190]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.080769,	
2017-07-13 04:43:16,582 Epoch[60] Batch [200]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.080840,	
2017-07-13 04:43:20,811 Epoch[60] Batch [210]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.081017,	
2017-07-13 04:43:25,000 Epoch[60] Batch [220]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.081327,	
2017-07-13 04:43:29,195 Epoch[60] Batch [230]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.080883,	
2017-07-13 04:43:33,637 Epoch[60] Batch [240]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.081013,	
2017-07-13 04:43:37,871 Epoch[60] Batch [250]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.080974,	
2017-07-13 04:43:41,996 Epoch[60] Batch [260]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.081219,	
2017-07-13 04:43:46,219 Epoch[60] Batch [270]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.081266,	
2017-07-13 04:43:50,474 Epoch[60] Batch [280]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.081257,	
2017-07-13 04:43:54,756 Epoch[60] Batch [290]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.081510,	
2017-07-13 04:43:58,904 Epoch[60] Batch [300]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.082312,	
2017-07-13 04:44:02,778 Epoch[60] Batch [310]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.082506,	
2017-07-13 04:44:06,814 Epoch[60] Batch [320]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.082786,	
2017-07-13 04:44:11,163 Epoch[60] Batch [330]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.083555,	
2017-07-13 04:44:15,245 Epoch[60] Batch [340]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.084682,	
2017-07-13 04:44:19,618 Epoch[60] Batch [350]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.085122,	
2017-07-13 04:44:23,541 Epoch[60] Batch [360]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.085468,	
2017-07-13 04:44:27,586 Epoch[60] Batch [370]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.085466,	
2017-07-13 04:44:31,839 Epoch[60] Batch [380]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.085409,	
2017-07-13 04:44:36,041 Epoch[60] Batch [390]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085343,	
2017-07-13 04:44:40,070 Epoch[60] Batch [400]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.085270,	
2017-07-13 04:44:44,263 Epoch[60] Batch [410]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.085152,	
2017-07-13 04:44:48,248 Epoch[60] Batch [420]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.085135,	
2017-07-13 04:44:52,448 Epoch[60] Batch [430]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.085029,	
2017-07-13 04:44:56,538 Epoch[60] Batch [440]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.085100,	
2017-07-13 04:45:00,703 Epoch[60] Batch [450]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.085014,	
2017-07-13 04:45:04,845 Epoch[60] Batch [460]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084990,	
2017-07-13 04:45:08,879 Epoch[60] Batch [470]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.084902,	
2017-07-13 04:45:13,119 Epoch[60] Batch [480]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.084682,	
2017-07-13 04:45:17,414 Epoch[60] Batch [490]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.084791,	
2017-07-13 04:45:21,482 Epoch[60] Batch [500]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.084682,	
2017-07-13 04:45:25,627 Epoch[60] Batch [510]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.084664,	
2017-07-13 04:45:29,897 Epoch[60] Batch [520]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.084674,	
2017-07-13 04:45:34,096 Epoch[60] Batch [530]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.084716,	
2017-07-13 04:45:38,263 Epoch[60] Batch [540]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.084578,	
2017-07-13 04:45:42,243 Epoch[60] Batch [550]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.084624,	
2017-07-13 04:45:46,447 Epoch[60] Batch [560]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.084698,	
2017-07-13 04:45:50,586 Epoch[60] Batch [570]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.084644,	
2017-07-13 04:45:54,806 Epoch[60] Batch [580]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.084527,	
2017-07-13 04:45:58,912 Epoch[60] Batch [590]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084458,	
2017-07-13 04:46:03,235 Epoch[60] Batch [600]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.084331,	
2017-07-13 04:46:07,361 Epoch[60] Batch [610]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.084310,	
2017-07-13 04:46:11,346 Epoch[60] Batch [620]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.084267,	
2017-07-13 04:46:15,633 Epoch[60] Batch [630]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.084365,	
2017-07-13 04:46:19,887 Epoch[60] Batch [640]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.084364,	
2017-07-13 04:46:23,910 Epoch[60] Batch [650]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.084346,	
2017-07-13 04:46:28,189 Epoch[60] Batch [660]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.084194,	
2017-07-13 04:46:32,296 Epoch[60] Batch [670]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.084064,	
2017-07-13 04:46:36,674 Epoch[60] Batch [680]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.084011,	
2017-07-13 04:46:40,899 Epoch[60] Batch [690]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.083980,	
2017-07-13 04:46:45,111 Epoch[60] Batch [700]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.083876,	
2017-07-13 04:46:49,551 Epoch[60] Batch [710]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.083727,	
2017-07-13 04:46:53,601 Epoch[60] Batch [720]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.083710,	
2017-07-13 04:46:57,854 Epoch[60] Batch [730]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.083762,	
2017-07-13 04:47:02,187 Epoch[60] Batch [740]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.083645,	
2017-07-13 04:47:06,468 Epoch[60] Batch [750]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.083593,	
2017-07-13 04:47:10,507 Epoch[60] Batch [760]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.083517,	
2017-07-13 04:47:14,727 Epoch[60] Batch [770]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.083419,	
2017-07-13 04:47:18,876 Epoch[60] Batch [780]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.083268,	
2017-07-13 04:47:23,057 Epoch[60] Batch [790]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.083211,	
2017-07-13 04:47:27,345 Epoch[60] Batch [800]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.083203,	
2017-07-13 04:47:31,873 Epoch[60] Batch [810]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.083119,	
2017-07-13 04:47:36,006 Epoch[60] Batch [820]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.083006,	
2017-07-13 04:47:39,971 Epoch[60] Batch [830]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.083013,	
2017-07-13 04:47:44,131 Epoch[60] Batch [840]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.082861,	
2017-07-13 04:47:48,200 Epoch[60] Batch [850]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.082791,	
2017-07-13 04:47:52,348 Epoch[60] Batch [860]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.082793,	
2017-07-13 04:47:56,658 Epoch[60] Batch [870]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.082832,	
2017-07-13 04:48:00,677 Epoch[60] Batch [880]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.082699,	
2017-07-13 04:48:04,926 Epoch[60] Batch [890]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.082649,	
2017-07-13 04:48:09,260 Epoch[60] Batch [900]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.082643,	
2017-07-13 04:48:13,375 Epoch[60] Batch [910]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.082644,	
2017-07-13 04:48:17,693 Epoch[60] Batch [920]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.082587,	
2017-07-13 04:48:22,138 Epoch[60] Batch [930]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.082482,	
2017-07-13 04:48:26,279 Epoch[60] Batch [940]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.082497,	
2017-07-13 04:48:30,415 Epoch[60] Batch [950]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.082424,	
2017-07-13 04:48:34,821 Epoch[60] Batch [960]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.082366,	
2017-07-13 04:48:39,036 Epoch[60] Batch [970]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.082358,	
2017-07-13 04:48:43,238 Epoch[60] Batch [980]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.082228,	
2017-07-13 04:48:47,473 Epoch[60] Batch [990]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.082261,	
2017-07-13 04:48:51,636 Epoch[60] Batch [1000]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.082266,	
2017-07-13 04:48:56,051 Epoch[60] Batch [1010]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.082214,	
2017-07-13 04:48:59,961 Epoch[60] Batch [1020]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.082183,	
2017-07-13 04:49:04,132 Epoch[60] Batch [1030]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.082188,	
2017-07-13 04:49:08,476 Epoch[60] Batch [1040]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.082172,	
2017-07-13 04:49:12,473 Epoch[60] Batch [1050]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.082201,	
2017-07-13 04:49:16,746 Epoch[60] Batch [1060]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.082206,	
2017-07-13 04:49:20,956 Epoch[60] Batch [1070]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.082109,	
2017-07-13 04:49:25,007 Epoch[60] Batch [1080]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.082052,	
2017-07-13 04:49:29,123 Epoch[60] Batch [1090]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.081964,	
2017-07-13 04:49:33,380 Epoch[60] Batch [1100]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.081937,	
2017-07-13 04:49:37,530 Epoch[60] Batch [1110]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.081967,	
2017-07-13 04:49:41,610 Epoch[60] Batch [1120]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.081963,	
2017-07-13 04:49:45,678 Epoch[60] Batch [1130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.081895,	
2017-07-13 04:49:49,821 Epoch[60] Batch [1140]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.081837,	
2017-07-13 04:49:53,929 Epoch[60] Batch [1150]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.081847,	
2017-07-13 04:49:58,116 Epoch[60] Batch [1160]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.081760,	
2017-07-13 04:50:02,210 Epoch[60] Batch [1170]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.081832,	
2017-07-13 04:50:06,397 Epoch[60] Batch [1180]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.081877,	
2017-07-13 04:50:10,725 Epoch[60] Batch [1190]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.081919,	
2017-07-13 04:50:14,705 Epoch[60] Batch [1200]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.081894,	
2017-07-13 04:50:18,897 Epoch[60] Batch [1210]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.081915,	
2017-07-13 04:50:22,922 Epoch[60] Batch [1220]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.081912,	
2017-07-13 04:50:27,095 Epoch[60] Batch [1230]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.081985,	
2017-07-13 04:50:31,371 Epoch[60] Batch [1240]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.081906,	
2017-07-13 04:50:35,527 Epoch[60] Batch [1250]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.081944,	
2017-07-13 04:50:39,660 Epoch[60] Batch [1260]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.081959,	
2017-07-13 04:50:43,995 Epoch[60] Batch [1270]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.081963,	
2017-07-13 04:50:48,043 Epoch[60] Batch [1280]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.081977,	
2017-07-13 04:50:52,372 Epoch[60] Batch [1290]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.081916,	
2017-07-13 04:50:56,419 Epoch[60] Batch [1300]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.081895,	
2017-07-13 04:51:00,611 Epoch[60] Batch [1310]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.081863,	
2017-07-13 04:51:04,854 Epoch[60] Batch [1320]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.081815,	
2017-07-13 04:51:08,986 Epoch[60] Batch [1330]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.081791,	
2017-07-13 04:51:13,099 Epoch[60] Batch [1340]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.081746,	
2017-07-13 04:51:17,062 Epoch[60] Batch [1350]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.081747,	
2017-07-13 04:51:21,412 Epoch[60] Batch [1360]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.081799,	
2017-07-13 04:51:25,499 Epoch[60] Batch [1370]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.081832,	
2017-07-13 04:51:29,295 Epoch[60] Batch [1380]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.081846,	
2017-07-13 04:51:33,216 Epoch[60] Batch [1390]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.081800,	
2017-07-13 04:51:37,306 Epoch[60] Batch [1400]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.081835,	
2017-07-13 04:51:41,512 Epoch[60] Batch [1410]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.081839,	
2017-07-13 04:51:45,460 Epoch[60] Batch [1420]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.081843,	
2017-07-13 04:51:49,617 Epoch[60] Batch [1430]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.081825,	
2017-07-13 04:51:53,850 Epoch[60] Batch [1440]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.081789,	
2017-07-13 04:51:58,065 Epoch[60] Batch [1450]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.081826,	
2017-07-13 04:52:02,081 Epoch[60] Batch [1460]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.081802,	
2017-07-13 04:52:06,380 Epoch[60] Batch [1470]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.081766,	
2017-07-13 04:52:10,657 Epoch[60] Batch [1480]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.081744,	
2017-07-13 04:52:13,172 Epoch[60] Train-FCNLogLoss=0.081768
2017-07-13 04:52:13,172 Epoch[60] Time cost=620.338
2017-07-13 04:52:13,842 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0061.params"
2017-07-13 04:52:15,628 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0061.states"
2017-07-13 04:52:20,317 Epoch[61] Batch [10]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.083665,	
2017-07-13 04:52:24,488 Epoch[61] Batch [20]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.083047,	
2017-07-13 04:52:28,671 Epoch[61] Batch [30]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.082315,	
2017-07-13 04:52:32,740 Epoch[61] Batch [40]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.082033,	
2017-07-13 04:52:36,920 Epoch[61] Batch [50]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.081587,	
2017-07-13 04:52:41,079 Epoch[61] Batch [60]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.081577,	
2017-07-13 04:52:45,200 Epoch[61] Batch [70]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.081539,	
2017-07-13 04:52:49,186 Epoch[61] Batch [80]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.081724,	
2017-07-13 04:52:53,385 Epoch[61] Batch [90]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.081834,	
2017-07-13 04:52:57,525 Epoch[61] Batch [100]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.081320,	
2017-07-13 04:53:01,751 Epoch[61] Batch [110]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.081360,	
2017-07-13 04:53:06,006 Epoch[61] Batch [120]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.081764,	
2017-07-13 04:53:10,363 Epoch[61] Batch [130]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.082507,	
2017-07-13 04:53:14,475 Epoch[61] Batch [140]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.082762,	
2017-07-13 04:53:18,745 Epoch[61] Batch [150]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.082810,	
2017-07-13 04:53:22,840 Epoch[61] Batch [160]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.082723,	
2017-07-13 04:53:27,055 Epoch[61] Batch [170]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.082682,	
2017-07-13 04:53:31,339 Epoch[61] Batch [180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.082610,	
2017-07-13 04:53:35,438 Epoch[61] Batch [190]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.082050,	
2017-07-13 04:53:39,441 Epoch[61] Batch [200]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.082441,	
2017-07-13 04:53:43,445 Epoch[61] Batch [210]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.082490,	
2017-07-13 04:53:47,506 Epoch[61] Batch [220]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.081887,	
2017-07-13 04:53:51,663 Epoch[61] Batch [230]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.082004,	
2017-07-13 04:53:55,753 Epoch[61] Batch [240]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.082238,	
2017-07-13 04:53:59,717 Epoch[61] Batch [250]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.082029,	
2017-07-13 04:54:03,982 Epoch[61] Batch [260]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.081960,	
2017-07-13 04:54:08,151 Epoch[61] Batch [270]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.081749,	
2017-07-13 04:54:12,629 Epoch[61] Batch [280]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.081555,	
2017-07-13 04:54:16,678 Epoch[61] Batch [290]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.081465,	
2017-07-13 04:54:20,689 Epoch[61] Batch [300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.081679,	
2017-07-13 04:54:24,808 Epoch[61] Batch [310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.081549,	
2017-07-13 04:54:29,108 Epoch[61] Batch [320]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.081508,	
2017-07-13 04:54:33,214 Epoch[61] Batch [330]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.081476,	
2017-07-13 04:54:37,437 Epoch[61] Batch [340]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.081267,	
2017-07-13 04:54:41,607 Epoch[61] Batch [350]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.081402,	
2017-07-13 04:54:45,854 Epoch[61] Batch [360]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.081442,	
2017-07-13 04:54:50,082 Epoch[61] Batch [370]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.081400,	
2017-07-13 04:54:54,601 Epoch[61] Batch [380]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.081198,	
2017-07-13 04:54:58,704 Epoch[61] Batch [390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.081267,	
2017-07-13 04:55:03,097 Epoch[61] Batch [400]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.081422,	
2017-07-13 04:55:07,392 Epoch[61] Batch [410]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.081371,	
2017-07-13 04:55:11,515 Epoch[61] Batch [420]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.081303,	
2017-07-13 04:55:15,575 Epoch[61] Batch [430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.081237,	
2017-07-13 04:55:20,241 Epoch[61] Batch [440]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.081318,	
2017-07-13 04:55:24,403 Epoch[61] Batch [450]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.081389,	
2017-07-13 04:55:28,671 Epoch[61] Batch [460]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.081474,	
2017-07-13 04:55:32,929 Epoch[61] Batch [470]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.081437,	
2017-07-13 04:55:37,405 Epoch[61] Batch [480]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.081301,	
2017-07-13 04:55:41,510 Epoch[61] Batch [490]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.081228,	
2017-07-13 04:55:45,647 Epoch[61] Batch [500]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.081206,	
2017-07-13 04:55:49,694 Epoch[61] Batch [510]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.081186,	
2017-07-13 04:55:54,097 Epoch[61] Batch [520]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.081119,	
2017-07-13 04:55:58,247 Epoch[61] Batch [530]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.081077,	
2017-07-13 04:56:02,362 Epoch[61] Batch [540]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.081004,	
2017-07-13 04:56:06,449 Epoch[61] Batch [550]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.081060,	
2017-07-13 04:56:10,758 Epoch[61] Batch [560]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.080969,	
2017-07-13 04:56:14,815 Epoch[61] Batch [570]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.081042,	
2017-07-13 04:56:18,951 Epoch[61] Batch [580]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.081047,	
2017-07-13 04:56:23,118 Epoch[61] Batch [590]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.080920,	
2017-07-13 04:56:27,397 Epoch[61] Batch [600]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.080923,	
2017-07-13 04:56:31,536 Epoch[61] Batch [610]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.080937,	
2017-07-13 04:56:35,746 Epoch[61] Batch [620]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.080994,	
2017-07-13 04:56:39,891 Epoch[61] Batch [630]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.080882,	
2017-07-13 04:56:44,217 Epoch[61] Batch [640]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.081000,	
2017-07-13 04:56:48,531 Epoch[61] Batch [650]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.081066,	
2017-07-13 04:56:52,675 Epoch[61] Batch [660]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.081017,	
2017-07-13 04:56:56,944 Epoch[61] Batch [670]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.080936,	
2017-07-13 04:57:01,030 Epoch[61] Batch [680]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.080986,	
2017-07-13 04:57:05,080 Epoch[61] Batch [690]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.081021,	
2017-07-13 04:57:09,282 Epoch[61] Batch [700]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.081085,	
2017-07-13 04:57:13,437 Epoch[61] Batch [710]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.081029,	
2017-07-13 04:57:17,541 Epoch[61] Batch [720]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.080987,	
2017-07-13 04:57:21,640 Epoch[61] Batch [730]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.080993,	
2017-07-13 04:57:25,800 Epoch[61] Batch [740]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.080840,	
2017-07-13 04:57:29,726 Epoch[61] Batch [750]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.080729,	
2017-07-13 04:57:33,846 Epoch[61] Batch [760]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.080760,	
2017-07-13 04:57:38,301 Epoch[61] Batch [770]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.080746,	
2017-07-13 04:57:42,471 Epoch[61] Batch [780]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.080649,	
2017-07-13 04:57:46,587 Epoch[61] Batch [790]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.080556,	
2017-07-13 04:57:50,723 Epoch[61] Batch [800]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.080610,	
2017-07-13 04:57:54,684 Epoch[61] Batch [810]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.080638,	
2017-07-13 04:57:58,849 Epoch[61] Batch [820]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.080747,	
2017-07-13 04:58:02,874 Epoch[61] Batch [830]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.080758,	
2017-07-13 04:58:07,108 Epoch[61] Batch [840]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.080723,	
2017-07-13 04:58:11,318 Epoch[61] Batch [850]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.080645,	
2017-07-13 04:58:15,519 Epoch[61] Batch [860]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.080696,	
2017-07-13 04:58:19,585 Epoch[61] Batch [870]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.080602,	
2017-07-13 04:58:23,857 Epoch[61] Batch [880]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.080654,	
2017-07-13 04:58:28,287 Epoch[61] Batch [890]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.080610,	
2017-07-13 04:58:32,540 Epoch[61] Batch [900]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.080702,	
2017-07-13 04:58:36,903 Epoch[61] Batch [910]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.080683,	
2017-07-13 04:58:41,138 Epoch[61] Batch [920]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.080693,	
2017-07-13 04:58:45,446 Epoch[61] Batch [930]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.080568,	
2017-07-13 04:58:49,397 Epoch[61] Batch [940]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.080549,	
2017-07-13 04:58:53,561 Epoch[61] Batch [950]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.080635,	
2017-07-13 04:58:57,702 Epoch[61] Batch [960]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.080575,	
2017-07-13 04:59:01,806 Epoch[61] Batch [970]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.080445,	
2017-07-13 04:59:06,031 Epoch[61] Batch [980]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.080488,	
2017-07-13 04:59:10,309 Epoch[61] Batch [990]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.080487,	
2017-07-13 04:59:14,582 Epoch[61] Batch [1000]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.080442,	
2017-07-13 04:59:18,923 Epoch[61] Batch [1010]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.080451,	
2017-07-13 04:59:23,002 Epoch[61] Batch [1020]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.080506,	
2017-07-13 04:59:27,190 Epoch[61] Batch [1030]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.080469,	
2017-07-13 04:59:31,429 Epoch[61] Batch [1040]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.080413,	
2017-07-13 04:59:35,355 Epoch[61] Batch [1050]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.080405,	
2017-07-13 04:59:39,573 Epoch[61] Batch [1060]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.080413,	
2017-07-13 04:59:43,696 Epoch[61] Batch [1070]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.080412,	
2017-07-13 04:59:47,674 Epoch[61] Batch [1080]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.080420,	
2017-07-13 04:59:51,993 Epoch[61] Batch [1090]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.080428,	
2017-07-13 04:59:56,075 Epoch[61] Batch [1100]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.080404,	
2017-07-13 05:00:00,159 Epoch[61] Batch [1110]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.080427,	
2017-07-13 05:00:04,172 Epoch[61] Batch [1120]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.080416,	
2017-07-13 05:00:08,330 Epoch[61] Batch [1130]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.080431,	
2017-07-13 05:00:12,311 Epoch[61] Batch [1140]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.080480,	
2017-07-13 05:00:16,461 Epoch[61] Batch [1150]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.080496,	
2017-07-13 05:00:20,435 Epoch[61] Batch [1160]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.080544,	
2017-07-13 05:00:24,487 Epoch[61] Batch [1170]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.080560,	
2017-07-13 05:00:28,683 Epoch[61] Batch [1180]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.080516,	
2017-07-13 05:00:33,060 Epoch[61] Batch [1190]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.080578,	
2017-07-13 05:00:36,987 Epoch[61] Batch [1200]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.080612,	
2017-07-13 05:00:41,024 Epoch[61] Batch [1210]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.080662,	
2017-07-13 05:00:45,072 Epoch[61] Batch [1220]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.080618,	
2017-07-13 05:00:49,324 Epoch[61] Batch [1230]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.080571,	
2017-07-13 05:00:53,368 Epoch[61] Batch [1240]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.080643,	
2017-07-13 05:00:57,484 Epoch[61] Batch [1250]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.080837,	
2017-07-13 05:01:01,696 Epoch[61] Batch [1260]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.081001,	
2017-07-13 05:01:05,892 Epoch[61] Batch [1270]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.081085,	
2017-07-13 05:01:10,043 Epoch[61] Batch [1280]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.081195,	
2017-07-13 05:01:13,919 Epoch[61] Batch [1290]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.081284,	
2017-07-13 05:01:18,196 Epoch[61] Batch [1300]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.081302,	
2017-07-13 05:01:22,164 Epoch[61] Batch [1310]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.081314,	
2017-07-13 05:01:26,331 Epoch[61] Batch [1320]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.081362,	
2017-07-13 05:01:30,265 Epoch[61] Batch [1330]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.081312,	
2017-07-13 05:01:34,206 Epoch[61] Batch [1340]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.081374,	
2017-07-13 05:01:38,139 Epoch[61] Batch [1350]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.081511,	
2017-07-13 05:01:42,526 Epoch[61] Batch [1360]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.081635,	
2017-07-13 05:01:46,767 Epoch[61] Batch [1370]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.081709,	
2017-07-13 05:01:50,970 Epoch[61] Batch [1380]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.081699,	
2017-07-13 05:01:55,376 Epoch[61] Batch [1390]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.081707,	
2017-07-13 05:01:59,350 Epoch[61] Batch [1400]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.081763,	
2017-07-13 05:02:03,385 Epoch[61] Batch [1410]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.081814,	
2017-07-13 05:02:07,628 Epoch[61] Batch [1420]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.081831,	
2017-07-13 05:02:12,143 Epoch[61] Batch [1430]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.081868,	
2017-07-13 05:02:16,252 Epoch[61] Batch [1440]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.081801,	
2017-07-13 05:02:20,310 Epoch[61] Batch [1450]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.081804,	
2017-07-13 05:02:24,795 Epoch[61] Batch [1460]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.081806,	
2017-07-13 05:02:28,903 Epoch[61] Batch [1470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.081804,	
2017-07-13 05:02:33,130 Epoch[61] Batch [1480]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.081816,	
2017-07-13 05:02:35,650 Epoch[61] Train-FCNLogLoss=0.081758
2017-07-13 05:02:35,650 Epoch[61] Time cost=620.022
2017-07-13 05:02:36,366 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0062.params"
2017-07-13 05:02:38,063 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0062.states"
2017-07-13 05:02:42,714 Epoch[62] Batch [10]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.089966,	
2017-07-13 05:02:46,806 Epoch[62] Batch [20]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.083726,	
2017-07-13 05:02:51,058 Epoch[62] Batch [30]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.081634,	
2017-07-13 05:02:55,144 Epoch[62] Batch [40]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.082509,	
2017-07-13 05:02:59,282 Epoch[62] Batch [50]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.081392,	
2017-07-13 05:03:03,885 Epoch[62] Batch [60]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.083930,	
2017-07-13 05:03:08,108 Epoch[62] Batch [70]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.083354,	
2017-07-13 05:03:12,403 Epoch[62] Batch [80]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.100125,	
2017-07-13 05:03:16,783 Epoch[62] Batch [90]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.107565,	
2017-07-13 05:03:21,368 Epoch[62] Batch [100]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.111075,	
2017-07-13 05:03:25,822 Epoch[62] Batch [110]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.116233,	
2017-07-13 05:03:29,977 Epoch[62] Batch [120]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.118606,	
2017-07-13 05:03:33,948 Epoch[62] Batch [130]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.123964,	
2017-07-13 05:03:38,001 Epoch[62] Batch [140]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.131089,	
2017-07-13 05:03:42,281 Epoch[62] Batch [150]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.133935,	
2017-07-13 05:03:46,442 Epoch[62] Batch [160]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.134528,	
2017-07-13 05:03:50,591 Epoch[62] Batch [170]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.135156,	
2017-07-13 05:03:54,664 Epoch[62] Batch [180]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.134676,	
2017-07-13 05:03:58,781 Epoch[62] Batch [190]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.135440,	
2017-07-13 05:04:02,850 Epoch[62] Batch [200]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.135077,	
2017-07-13 05:04:06,952 Epoch[62] Batch [210]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.134563,	
2017-07-13 05:04:11,073 Epoch[62] Batch [220]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.134531,	
2017-07-13 05:04:15,086 Epoch[62] Batch [230]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.133833,	
2017-07-13 05:04:19,016 Epoch[62] Batch [240]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.133215,	
2017-07-13 05:04:23,237 Epoch[62] Batch [250]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.132153,	
2017-07-13 05:04:27,289 Epoch[62] Batch [260]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.131740,	
2017-07-13 05:04:31,293 Epoch[62] Batch [270]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.130766,	
2017-07-13 05:04:35,537 Epoch[62] Batch [280]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.129412,	
2017-07-13 05:04:39,615 Epoch[62] Batch [290]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.128022,	
2017-07-13 05:04:43,752 Epoch[62] Batch [300]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.126755,	
2017-07-13 05:04:47,925 Epoch[62] Batch [310]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.125797,	
2017-07-13 05:04:51,852 Epoch[62] Batch [320]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.125604,	
2017-07-13 05:04:55,933 Epoch[62] Batch [330]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.125025,	
2017-07-13 05:04:59,832 Epoch[62] Batch [340]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.124469,	
2017-07-13 05:05:04,174 Epoch[62] Batch [350]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.123710,	
2017-07-13 05:05:08,454 Epoch[62] Batch [360]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.122984,	
2017-07-13 05:05:12,458 Epoch[62] Batch [370]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.122247,	
2017-07-13 05:05:17,132 Epoch[62] Batch [380]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.121135,	
2017-07-13 05:05:21,157 Epoch[62] Batch [390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.120601,	
2017-07-13 05:05:25,240 Epoch[62] Batch [400]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.119743,	
2017-07-13 05:05:29,721 Epoch[62] Batch [410]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.119191,	
2017-07-13 05:05:33,975 Epoch[62] Batch [420]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.118395,	
2017-07-13 05:05:38,012 Epoch[62] Batch [430]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117924,	
2017-07-13 05:05:42,071 Epoch[62] Batch [440]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.117303,	
2017-07-13 05:05:46,199 Epoch[62] Batch [450]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.116769,	
2017-07-13 05:05:50,412 Epoch[62] Batch [460]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.116032,	
2017-07-13 05:05:54,644 Epoch[62] Batch [470]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.115581,	
2017-07-13 05:05:58,856 Epoch[62] Batch [480]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.115076,	
2017-07-13 05:06:02,940 Epoch[62] Batch [490]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114705,	
2017-07-13 05:06:07,035 Epoch[62] Batch [500]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.114496,	
2017-07-13 05:06:11,334 Epoch[62] Batch [510]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.114092,	
2017-07-13 05:06:15,265 Epoch[62] Batch [520]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.113735,	
2017-07-13 05:06:19,329 Epoch[62] Batch [530]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113417,	
2017-07-13 05:06:23,415 Epoch[62] Batch [540]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112930,	
2017-07-13 05:06:27,497 Epoch[62] Batch [550]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112735,	
2017-07-13 05:06:31,573 Epoch[62] Batch [560]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112076,	
2017-07-13 05:06:35,828 Epoch[62] Batch [570]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.111731,	
2017-07-13 05:06:40,058 Epoch[62] Batch [580]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.111431,	
2017-07-13 05:06:44,344 Epoch[62] Batch [590]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.111140,	
2017-07-13 05:06:48,457 Epoch[62] Batch [600]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110898,	
2017-07-13 05:06:52,763 Epoch[62] Batch [610]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.110646,	
2017-07-13 05:06:56,940 Epoch[62] Batch [620]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110462,	
2017-07-13 05:07:00,685 Epoch[62] Batch [630]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.110211,	
2017-07-13 05:07:04,729 Epoch[62] Batch [640]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109852,	
2017-07-13 05:07:08,742 Epoch[62] Batch [650]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.109541,	
2017-07-13 05:07:12,873 Epoch[62] Batch [660]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.109138,	
2017-07-13 05:07:17,390 Epoch[62] Batch [670]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.108752,	
2017-07-13 05:07:21,581 Epoch[62] Batch [680]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108487,	
2017-07-13 05:07:25,810 Epoch[62] Batch [690]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.108189,	
2017-07-13 05:07:30,090 Epoch[62] Batch [700]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.107946,	
2017-07-13 05:07:34,090 Epoch[62] Batch [710]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.107685,	
2017-07-13 05:07:38,100 Epoch[62] Batch [720]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.107376,	
2017-07-13 05:07:42,070 Epoch[62] Batch [730]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.107177,	
2017-07-13 05:07:46,288 Epoch[62] Batch [740]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.106931,	
2017-07-13 05:07:50,490 Epoch[62] Batch [750]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.106618,	
2017-07-13 05:07:54,759 Epoch[62] Batch [760]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.106389,	
2017-07-13 05:07:59,248 Epoch[62] Batch [770]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.106117,	
2017-07-13 05:08:03,197 Epoch[62] Batch [780]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105856,	
2017-07-13 05:08:07,456 Epoch[62] Batch [790]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.105707,	
2017-07-13 05:08:11,513 Epoch[62] Batch [800]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.105531,	
2017-07-13 05:08:15,587 Epoch[62] Batch [810]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105241,	
2017-07-13 05:08:19,886 Epoch[62] Batch [820]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.105062,	
2017-07-13 05:08:23,923 Epoch[62] Batch [830]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104880,	
2017-07-13 05:08:28,214 Epoch[62] Batch [840]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.104707,	
2017-07-13 05:08:32,420 Epoch[62] Batch [850]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.104533,	
2017-07-13 05:08:36,621 Epoch[62] Batch [860]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.104312,	
2017-07-13 05:08:40,573 Epoch[62] Batch [870]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.104035,	
2017-07-13 05:08:44,853 Epoch[62] Batch [880]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.103855,	
2017-07-13 05:08:49,063 Epoch[62] Batch [890]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.103782,	
2017-07-13 05:08:53,097 Epoch[62] Batch [900]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103514,	
2017-07-13 05:08:57,263 Epoch[62] Batch [910]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.103253,	
2017-07-13 05:09:01,168 Epoch[62] Batch [920]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.102958,	
2017-07-13 05:09:05,200 Epoch[62] Batch [930]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.102775,	
2017-07-13 05:09:09,222 Epoch[62] Batch [940]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.102608,	
2017-07-13 05:09:13,596 Epoch[62] Batch [950]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.102411,	
2017-07-13 05:09:17,782 Epoch[62] Batch [960]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.102189,	
2017-07-13 05:09:22,076 Epoch[62] Batch [970]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.101967,	
2017-07-13 05:09:26,340 Epoch[62] Batch [980]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.101698,	
2017-07-13 05:09:30,932 Epoch[62] Batch [990]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.101475,	
2017-07-13 05:09:35,167 Epoch[62] Batch [1000]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.101364,	
2017-07-13 05:09:39,580 Epoch[62] Batch [1010]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.101147,	
2017-07-13 05:09:43,687 Epoch[62] Batch [1020]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.101057,	
2017-07-13 05:09:47,928 Epoch[62] Batch [1030]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100926,	
2017-07-13 05:09:52,134 Epoch[62] Batch [1040]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.100691,	
2017-07-13 05:09:56,510 Epoch[62] Batch [1050]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.100503,	
2017-07-13 05:10:00,497 Epoch[62] Batch [1060]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.100375,	
2017-07-13 05:10:04,582 Epoch[62] Batch [1070]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100389,	
2017-07-13 05:10:08,616 Epoch[62] Batch [1080]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100472,	
2017-07-13 05:10:12,581 Epoch[62] Batch [1090]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.100639,	
2017-07-13 05:10:16,669 Epoch[62] Batch [1100]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100667,	
2017-07-13 05:10:20,676 Epoch[62] Batch [1110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.100577,	
2017-07-13 05:10:24,703 Epoch[62] Batch [1120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100622,	
2017-07-13 05:10:28,880 Epoch[62] Batch [1130]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.100775,	
2017-07-13 05:10:33,135 Epoch[62] Batch [1140]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.100750,	
2017-07-13 05:10:37,310 Epoch[62] Batch [1150]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.100770,	
2017-07-13 05:10:41,560 Epoch[62] Batch [1160]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.100581,	
2017-07-13 05:10:45,564 Epoch[62] Batch [1170]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.100463,	
2017-07-13 05:10:50,027 Epoch[62] Batch [1180]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.100482,	
2017-07-13 05:10:54,392 Epoch[62] Batch [1190]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.100400,	
2017-07-13 05:10:58,372 Epoch[62] Batch [1200]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.100308,	
2017-07-13 05:11:02,757 Epoch[62] Batch [1210]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.100275,	
2017-07-13 05:11:06,910 Epoch[62] Batch [1220]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.100205,	
2017-07-13 05:11:11,166 Epoch[62] Batch [1230]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.100065,	
2017-07-13 05:11:15,214 Epoch[62] Batch [1240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.099952,	
2017-07-13 05:11:19,394 Epoch[62] Batch [1250]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.099822,	
2017-07-13 05:11:23,712 Epoch[62] Batch [1260]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.099653,	
2017-07-13 05:11:27,903 Epoch[62] Batch [1270]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.099510,	
2017-07-13 05:11:32,239 Epoch[62] Batch [1280]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.099289,	
2017-07-13 05:11:36,515 Epoch[62] Batch [1290]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.099184,	
2017-07-13 05:11:40,971 Epoch[62] Batch [1300]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.099034,	
2017-07-13 05:11:45,265 Epoch[62] Batch [1310]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.098883,	
2017-07-13 05:11:49,774 Epoch[62] Batch [1320]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.098780,	
2017-07-13 05:11:54,177 Epoch[62] Batch [1330]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098664,	
2017-07-13 05:11:58,646 Epoch[62] Batch [1340]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.098629,	
2017-07-13 05:12:03,065 Epoch[62] Batch [1350]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.098479,	
2017-07-13 05:12:07,459 Epoch[62] Batch [1360]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.098371,	
2017-07-13 05:12:11,851 Epoch[62] Batch [1370]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.098222,	
2017-07-13 05:12:16,371 Epoch[62] Batch [1380]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.098137,	
2017-07-13 05:12:20,771 Epoch[62] Batch [1390]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.098006,	
2017-07-13 05:12:25,456 Epoch[62] Batch [1400]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.097926,	
2017-07-13 05:12:29,571 Epoch[62] Batch [1410]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097802,	
2017-07-13 05:12:33,515 Epoch[62] Batch [1420]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.097728,	
2017-07-13 05:12:37,871 Epoch[62] Batch [1430]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.097546,	
2017-07-13 05:12:42,654 Epoch[62] Batch [1440]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.097513,	
2017-07-13 05:12:46,928 Epoch[62] Batch [1450]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097404,	
2017-07-13 05:12:51,022 Epoch[62] Batch [1460]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097311,	
2017-07-13 05:12:55,028 Epoch[62] Batch [1470]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097157,	
2017-07-13 05:12:59,522 Epoch[62] Batch [1480]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.097047,	
2017-07-13 05:13:02,000 Epoch[62] Train-FCNLogLoss=0.096966
2017-07-13 05:13:02,000 Epoch[62] Time cost=623.936
2017-07-13 05:13:02,635 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0063.params"
2017-07-13 05:13:04,537 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0063.states"
2017-07-13 05:13:09,455 Epoch[63] Batch [10]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.081030,	
2017-07-13 05:13:13,599 Epoch[63] Batch [20]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.079733,	
2017-07-13 05:13:17,905 Epoch[63] Batch [30]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.081686,	
2017-07-13 05:13:22,122 Epoch[63] Batch [40]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.080953,	
2017-07-13 05:13:26,304 Epoch[63] Batch [50]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.082367,	
2017-07-13 05:13:30,505 Epoch[63] Batch [60]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.081497,	
2017-07-13 05:13:34,796 Epoch[63] Batch [70]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.081404,	
2017-07-13 05:13:38,977 Epoch[63] Batch [80]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.081458,	
2017-07-13 05:13:42,875 Epoch[63] Batch [90]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.080460,	
2017-07-13 05:13:47,218 Epoch[63] Batch [100]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.080851,	
2017-07-13 05:13:51,495 Epoch[63] Batch [110]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.081620,	
2017-07-13 05:13:55,813 Epoch[63] Batch [120]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.081465,	
2017-07-13 05:14:00,255 Epoch[63] Batch [130]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.081296,	
2017-07-13 05:14:04,819 Epoch[63] Batch [140]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.080742,	
2017-07-13 05:14:09,044 Epoch[63] Batch [150]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.080716,	
2017-07-13 05:14:13,391 Epoch[63] Batch [160]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.080335,	
2017-07-13 05:14:17,470 Epoch[63] Batch [170]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.080667,	
2017-07-13 05:14:21,869 Epoch[63] Batch [180]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.080795,	
2017-07-13 05:14:26,356 Epoch[63] Batch [190]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.081038,	
2017-07-13 05:14:30,682 Epoch[63] Batch [200]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.080978,	
2017-07-13 05:14:35,106 Epoch[63] Batch [210]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.081026,	
2017-07-13 05:14:39,599 Epoch[63] Batch [220]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.080630,	
2017-07-13 05:14:44,088 Epoch[63] Batch [230]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.080504,	
2017-07-13 05:14:48,334 Epoch[63] Batch [240]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.080767,	
2017-07-13 05:14:52,713 Epoch[63] Batch [250]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.080724,	
2017-07-13 05:14:56,901 Epoch[63] Batch [260]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.080890,	
2017-07-13 05:15:01,329 Epoch[63] Batch [270]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.081095,	
2017-07-13 05:15:05,472 Epoch[63] Batch [280]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.080778,	
2017-07-13 05:15:09,788 Epoch[63] Batch [290]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.080721,	
2017-07-13 05:15:14,230 Epoch[63] Batch [300]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.080549,	
2017-07-13 05:15:18,541 Epoch[63] Batch [310]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.080419,	
2017-07-13 05:15:22,749 Epoch[63] Batch [320]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.080560,	
2017-07-13 05:15:26,897 Epoch[63] Batch [330]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.080503,	
2017-07-13 05:15:31,003 Epoch[63] Batch [340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.080347,	
2017-07-13 05:15:35,241 Epoch[63] Batch [350]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.080314,	
2017-07-13 05:15:39,460 Epoch[63] Batch [360]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.080090,	
2017-07-13 05:15:43,603 Epoch[63] Batch [370]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.080130,	
2017-07-13 05:15:47,726 Epoch[63] Batch [380]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.080409,	
2017-07-13 05:15:52,142 Epoch[63] Batch [390]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.080576,	
2017-07-13 05:15:56,380 Epoch[63] Batch [400]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.080568,	
2017-07-13 05:16:00,424 Epoch[63] Batch [410]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.080628,	
2017-07-13 05:16:04,965 Epoch[63] Batch [420]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.080605,	
2017-07-13 05:16:09,250 Epoch[63] Batch [430]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.080402,	
2017-07-13 05:16:13,438 Epoch[63] Batch [440]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.080572,	
2017-07-13 05:16:17,651 Epoch[63] Batch [450]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.080828,	
2017-07-13 05:16:21,994 Epoch[63] Batch [460]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.080951,	
2017-07-13 05:16:26,373 Epoch[63] Batch [470]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.081047,	
2017-07-13 05:16:30,506 Epoch[63] Batch [480]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.081399,	
2017-07-13 05:16:34,779 Epoch[63] Batch [490]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.081381,	
2017-07-13 05:16:39,149 Epoch[63] Batch [500]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.081394,	
2017-07-13 05:16:43,244 Epoch[63] Batch [510]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.081186,	
2017-07-13 05:16:47,267 Epoch[63] Batch [520]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.081241,	
2017-07-13 05:16:51,408 Epoch[63] Batch [530]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.081370,	
2017-07-13 05:16:55,597 Epoch[63] Batch [540]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.081365,	
2017-07-13 05:16:59,672 Epoch[63] Batch [550]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.081392,	
2017-07-13 05:17:03,772 Epoch[63] Batch [560]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.081681,	
2017-07-13 05:17:08,095 Epoch[63] Batch [570]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.081778,	
2017-07-13 05:17:12,755 Epoch[63] Batch [580]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.081800,	
2017-07-13 05:17:17,025 Epoch[63] Batch [590]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.081817,	
2017-07-13 05:17:21,393 Epoch[63] Batch [600]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.081925,	
2017-07-13 05:17:25,697 Epoch[63] Batch [610]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.081837,	
2017-07-13 05:17:30,124 Epoch[63] Batch [620]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.081844,	
2017-07-13 05:17:34,150 Epoch[63] Batch [630]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.081807,	
2017-07-13 05:17:38,379 Epoch[63] Batch [640]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.081820,	
2017-07-13 05:17:42,875 Epoch[63] Batch [650]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.081742,	
2017-07-13 05:17:47,214 Epoch[63] Batch [660]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.081729,	
2017-07-13 05:17:51,791 Epoch[63] Batch [670]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.081750,	
2017-07-13 05:17:56,379 Epoch[63] Batch [680]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.081759,	
2017-07-13 05:18:00,632 Epoch[63] Batch [690]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.081729,	
2017-07-13 05:18:04,837 Epoch[63] Batch [700]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.081763,	
2017-07-13 05:18:09,087 Epoch[63] Batch [710]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.081861,	
2017-07-13 05:18:13,351 Epoch[63] Batch [720]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.081892,	
2017-07-13 05:18:17,425 Epoch[63] Batch [730]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.081861,	
2017-07-13 05:18:21,720 Epoch[63] Batch [740]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.081850,	
2017-07-13 05:18:26,091 Epoch[63] Batch [750]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.081853,	
2017-07-13 05:18:30,719 Epoch[63] Batch [760]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.081776,	
2017-07-13 05:18:35,033 Epoch[63] Batch [770]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.081730,	
2017-07-13 05:18:39,737 Epoch[63] Batch [780]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.081838,	
2017-07-13 05:18:43,896 Epoch[63] Batch [790]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.081850,	
2017-07-13 05:18:47,974 Epoch[63] Batch [800]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.082071,	
2017-07-13 05:18:52,261 Epoch[63] Batch [810]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.082082,	
2017-07-13 05:18:56,414 Epoch[63] Batch [820]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.082188,	
2017-07-13 05:19:00,970 Epoch[63] Batch [830]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.082199,	
2017-07-13 05:19:05,248 Epoch[63] Batch [840]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.082308,	
2017-07-13 05:19:09,501 Epoch[63] Batch [850]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.082371,	
2017-07-13 05:19:13,767 Epoch[63] Batch [860]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.082287,	
2017-07-13 05:19:18,292 Epoch[63] Batch [870]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.082241,	
2017-07-13 05:19:22,789 Epoch[63] Batch [880]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.082257,	
2017-07-13 05:19:27,107 Epoch[63] Batch [890]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.082276,	
2017-07-13 05:19:31,331 Epoch[63] Batch [900]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.082216,	
2017-07-13 05:19:35,503 Epoch[63] Batch [910]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.082215,	
2017-07-13 05:19:39,476 Epoch[63] Batch [920]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.082139,	
2017-07-13 05:19:43,704 Epoch[63] Batch [930]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.082184,	
2017-07-13 05:19:48,045 Epoch[63] Batch [940]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.082170,	
2017-07-13 05:19:52,066 Epoch[63] Batch [950]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.082180,	
2017-07-13 05:19:56,160 Epoch[63] Batch [960]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.082133,	
2017-07-13 05:20:00,288 Epoch[63] Batch [970]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.082099,	
2017-07-13 05:20:04,650 Epoch[63] Batch [980]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.082063,	
2017-07-13 05:20:08,733 Epoch[63] Batch [990]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.082044,	
2017-07-13 05:20:12,881 Epoch[63] Batch [1000]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.082007,	
2017-07-13 05:20:17,023 Epoch[63] Batch [1010]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.081953,	
2017-07-13 05:20:21,228 Epoch[63] Batch [1020]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.081925,	
2017-07-13 05:20:25,401 Epoch[63] Batch [1030]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.081930,	
2017-07-13 05:20:29,599 Epoch[63] Batch [1040]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.081950,	
2017-07-13 05:20:33,756 Epoch[63] Batch [1050]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.081957,	
2017-07-13 05:20:37,807 Epoch[63] Batch [1060]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.081873,	
2017-07-13 05:20:41,916 Epoch[63] Batch [1070]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.081879,	
2017-07-13 05:20:45,982 Epoch[63] Batch [1080]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.081846,	
2017-07-13 05:20:50,290 Epoch[63] Batch [1090]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.081837,	
2017-07-13 05:20:54,477 Epoch[63] Batch [1100]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.081785,	
2017-07-13 05:20:58,780 Epoch[63] Batch [1110]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.081784,	
2017-07-13 05:21:02,917 Epoch[63] Batch [1120]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.081783,	
2017-07-13 05:21:07,030 Epoch[63] Batch [1130]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.081747,	
2017-07-13 05:21:11,106 Epoch[63] Batch [1140]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.081770,	
2017-07-13 05:21:15,409 Epoch[63] Batch [1150]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.081843,	
2017-07-13 05:21:19,540 Epoch[63] Batch [1160]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.081833,	
2017-07-13 05:21:23,580 Epoch[63] Batch [1170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.081883,	
2017-07-13 05:21:27,862 Epoch[63] Batch [1180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.081805,	
2017-07-13 05:21:31,958 Epoch[63] Batch [1190]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.081761,	
2017-07-13 05:21:36,107 Epoch[63] Batch [1200]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.081818,	
2017-07-13 05:21:40,380 Epoch[63] Batch [1210]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.081815,	
2017-07-13 05:21:44,709 Epoch[63] Batch [1220]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.081855,	
2017-07-13 05:21:48,988 Epoch[63] Batch [1230]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.081822,	
2017-07-13 05:21:53,068 Epoch[63] Batch [1240]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.081845,	
2017-07-13 05:21:57,505 Epoch[63] Batch [1250]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.081858,	
2017-07-13 05:22:01,853 Epoch[63] Batch [1260]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.081909,	
2017-07-13 05:22:05,970 Epoch[63] Batch [1270]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.081900,	
2017-07-13 05:22:10,095 Epoch[63] Batch [1280]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.081907,	
2017-07-13 05:22:14,298 Epoch[63] Batch [1290]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.081907,	
2017-07-13 05:22:18,337 Epoch[63] Batch [1300]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.081943,	
2017-07-13 05:22:22,420 Epoch[63] Batch [1310]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.081931,	
2017-07-13 05:22:26,777 Epoch[63] Batch [1320]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.081904,	
2017-07-13 05:22:30,834 Epoch[63] Batch [1330]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.081911,	
2017-07-13 05:22:35,056 Epoch[63] Batch [1340]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.081866,	
2017-07-13 05:22:39,450 Epoch[63] Batch [1350]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.081840,	
2017-07-13 05:22:43,752 Epoch[63] Batch [1360]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.081811,	
2017-07-13 05:22:47,828 Epoch[63] Batch [1370]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.081813,	
2017-07-13 05:22:52,285 Epoch[63] Batch [1380]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.081811,	
2017-07-13 05:22:56,753 Epoch[63] Batch [1390]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.081841,	
2017-07-13 05:23:01,219 Epoch[63] Batch [1400]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.081857,	
2017-07-13 05:23:05,928 Epoch[63] Batch [1410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.081904,	
2017-07-13 05:23:10,372 Epoch[63] Batch [1420]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.081942,	
2017-07-13 05:23:15,185 Epoch[63] Batch [1430]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.081931,	
2017-07-13 05:23:20,100 Epoch[63] Batch [1440]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.081930,	
2017-07-13 05:23:24,599 Epoch[63] Batch [1450]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.081976,	
2017-07-13 05:23:29,263 Epoch[63] Batch [1460]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.081982,	
2017-07-13 05:23:33,951 Epoch[63] Batch [1470]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.081993,	
2017-07-13 05:23:38,789 Epoch[63] Batch [1480]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.081951,	
2017-07-13 05:23:41,949 Epoch[63] Train-FCNLogLoss=0.081977
2017-07-13 05:23:41,949 Epoch[63] Time cost=637.412
2017-07-13 05:23:42,660 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0064.params"
2017-07-13 05:23:46,892 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0064.states"
2017-07-13 05:23:52,409 Epoch[64] Batch [10]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088903,	
2017-07-13 05:23:56,976 Epoch[64] Batch [20]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.086815,	
2017-07-13 05:24:01,574 Epoch[64] Batch [30]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.094647,	
2017-07-13 05:24:06,175 Epoch[64] Batch [40]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.101947,	
2017-07-13 05:24:10,763 Epoch[64] Batch [50]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.104425,	
2017-07-13 05:24:15,357 Epoch[64] Batch [60]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.107230,	
2017-07-13 05:24:19,888 Epoch[64] Batch [70]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.107192,	
2017-07-13 05:24:24,577 Epoch[64] Batch [80]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.108324,	
2017-07-13 05:24:29,275 Epoch[64] Batch [90]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.111992,	
2017-07-13 05:24:34,051 Epoch[64] Batch [100]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.113226,	
2017-07-13 05:24:38,682 Epoch[64] Batch [110]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.114184,	
2017-07-13 05:24:43,244 Epoch[64] Batch [120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.113859,	
2017-07-13 05:24:48,016 Epoch[64] Batch [130]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.112918,	
2017-07-13 05:24:52,315 Epoch[64] Batch [140]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.111286,	
2017-07-13 05:24:57,017 Epoch[64] Batch [150]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.109989,	
2017-07-13 05:25:02,281 Epoch[64] Batch [160]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.108442,	
2017-07-13 05:25:07,077 Epoch[64] Batch [170]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.106905,	
2017-07-13 05:25:12,232 Epoch[64] Batch [180]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.106082,	
2017-07-13 05:25:17,557 Epoch[64] Batch [190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105660,	
2017-07-13 05:25:22,855 Epoch[64] Batch [200]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.104679,	
2017-07-13 05:25:27,976 Epoch[64] Batch [210]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.103831,	
2017-07-13 05:25:33,166 Epoch[64] Batch [220]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.102721,	
2017-07-13 05:25:38,395 Epoch[64] Batch [230]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.102020,	
2017-07-13 05:25:43,532 Epoch[64] Batch [240]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.101604,	
2017-07-13 05:25:48,633 Epoch[64] Batch [250]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.101296,	
2017-07-13 05:25:54,029 Epoch[64] Batch [260]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.100594,	
2017-07-13 05:25:59,082 Epoch[64] Batch [270]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.099856,	
2017-07-13 05:26:03,946 Epoch[64] Batch [280]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.099608,	
2017-07-13 05:26:09,005 Epoch[64] Batch [290]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.099390,	
2017-07-13 05:26:14,304 Epoch[64] Batch [300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098949,	
2017-07-13 05:26:19,488 Epoch[64] Batch [310]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098685,	
2017-07-13 05:26:25,437 Epoch[64] Batch [320]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.098194,	
2017-07-13 05:26:30,799 Epoch[64] Batch [330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097896,	
2017-07-13 05:26:36,354 Epoch[64] Batch [340]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.097302,	
2017-07-13 05:26:42,038 Epoch[64] Batch [350]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.097074,	
2017-07-13 05:26:47,611 Epoch[64] Batch [360]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.096672,	
2017-07-13 05:26:53,597 Epoch[64] Batch [370]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.096257,	
2017-07-13 05:26:58,984 Epoch[64] Batch [380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.096132,	
2017-07-13 05:27:04,324 Epoch[64] Batch [390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096229,	
2017-07-13 05:27:09,763 Epoch[64] Batch [400]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.095956,	
2017-07-13 05:27:14,816 Epoch[64] Batch [410]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.095787,	
2017-07-13 05:27:20,276 Epoch[64] Batch [420]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.095578,	
2017-07-13 05:27:26,241 Epoch[64] Batch [430]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.095386,	
2017-07-13 05:27:32,128 Epoch[64] Batch [440]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.095135,	
2017-07-13 05:27:37,992 Epoch[64] Batch [450]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.094738,	
2017-07-13 05:27:43,988 Epoch[64] Batch [460]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.094435,	
2017-07-13 05:27:49,480 Epoch[64] Batch [470]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.094258,	
2017-07-13 05:27:55,273 Epoch[64] Batch [480]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.093958,	
2017-07-13 05:28:00,992 Epoch[64] Batch [490]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.093679,	
2017-07-13 05:28:06,798 Epoch[64] Batch [500]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.093404,	
2017-07-13 05:28:12,647 Epoch[64] Batch [510]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.093060,	
2017-07-13 05:28:18,136 Epoch[64] Batch [520]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092894,	
2017-07-13 05:28:23,816 Epoch[64] Batch [530]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.092540,	
2017-07-13 05:28:29,012 Epoch[64] Batch [540]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092275,	
2017-07-13 05:28:34,517 Epoch[64] Batch [550]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092208,	
2017-07-13 05:28:40,139 Epoch[64] Batch [560]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.092032,	
2017-07-13 05:28:45,598 Epoch[64] Batch [570]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091843,	
2017-07-13 05:28:50,817 Epoch[64] Batch [580]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.091602,	
2017-07-13 05:28:56,336 Epoch[64] Batch [590]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.091561,	
2017-07-13 05:29:02,001 Epoch[64] Batch [600]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.091535,	
2017-07-13 05:29:06,982 Epoch[64] Batch [610]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.091484,	
2017-07-13 05:29:12,313 Epoch[64] Batch [620]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091304,	
2017-07-13 05:29:18,082 Epoch[64] Batch [630]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.091074,	
2017-07-13 05:29:23,721 Epoch[64] Batch [640]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.090831,	
2017-07-13 05:29:28,950 Epoch[64] Batch [650]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090688,	
2017-07-13 05:29:34,396 Epoch[64] Batch [660]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.090583,	
2017-07-13 05:29:40,116 Epoch[64] Batch [670]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.090507,	
2017-07-13 05:29:45,636 Epoch[64] Batch [680]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.090276,	
2017-07-13 05:29:51,051 Epoch[64] Batch [690]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090291,	
2017-07-13 05:29:56,770 Epoch[64] Batch [700]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.090239,	
2017-07-13 05:30:02,470 Epoch[64] Batch [710]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.090107,	
2017-07-13 05:30:08,144 Epoch[64] Batch [720]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.089929,	
2017-07-13 05:30:14,815 Epoch[64] Batch [730]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.089834,	
2017-07-13 05:30:20,903 Epoch[64] Batch [740]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.089785,	
2017-07-13 05:30:26,842 Epoch[64] Batch [750]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.089535,	
2017-07-13 05:30:33,068 Epoch[64] Batch [760]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.089259,	
2017-07-13 05:30:38,738 Epoch[64] Batch [770]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089089,	
2017-07-13 05:30:45,046 Epoch[64] Batch [780]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.089014,	
2017-07-13 05:30:51,133 Epoch[64] Batch [790]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.088962,	
2017-07-13 05:30:57,149 Epoch[64] Batch [800]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088864,	
2017-07-13 05:31:03,119 Epoch[64] Batch [810]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.088699,	
2017-07-13 05:31:09,472 Epoch[64] Batch [820]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.088639,	
2017-07-13 05:31:15,485 Epoch[64] Batch [830]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088514,	
2017-07-13 05:31:21,746 Epoch[64] Batch [840]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088373,	
2017-07-13 05:31:28,238 Epoch[64] Batch [850]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.088280,	
2017-07-13 05:31:34,126 Epoch[64] Batch [860]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088235,	
2017-07-13 05:31:40,284 Epoch[64] Batch [870]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.088076,	
2017-07-13 05:31:46,180 Epoch[64] Batch [880]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.088042,	
2017-07-13 05:31:52,089 Epoch[64] Batch [890]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.088071,	
2017-07-13 05:31:58,382 Epoch[64] Batch [900]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.088061,	
2017-07-13 05:32:04,554 Epoch[64] Batch [910]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.088007,	
2017-07-13 05:32:10,720 Epoch[64] Batch [920]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087918,	
2017-07-13 05:32:16,905 Epoch[64] Batch [930]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.087783,	
2017-07-13 05:32:23,009 Epoch[64] Batch [940]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.087673,	
2017-07-13 05:32:29,415 Epoch[64] Batch [950]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087601,	
2017-07-13 05:32:35,556 Epoch[64] Batch [960]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.087529,	
2017-07-13 05:32:41,954 Epoch[64] Batch [970]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087423,	
2017-07-13 05:32:48,557 Epoch[64] Batch [980]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087310,	
2017-07-13 05:32:55,157 Epoch[64] Batch [990]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087205,	
2017-07-13 05:33:01,525 Epoch[64] Batch [1000]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087040,	
2017-07-13 05:33:08,057 Epoch[64] Batch [1010]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.086932,	
2017-07-13 05:33:15,362 Epoch[64] Batch [1020]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.086899,	
2017-07-13 05:33:22,544 Epoch[64] Batch [1030]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.086732,	
2017-07-13 05:33:30,051 Epoch[64] Batch [1040]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.086564,	
2017-07-13 05:33:37,490 Epoch[64] Batch [1050]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.086613,	
2017-07-13 05:33:45,000 Epoch[64] Batch [1060]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.086562,	
2017-07-13 05:33:52,456 Epoch[64] Batch [1070]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.086591,	
2017-07-13 05:33:59,891 Epoch[64] Batch [1080]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.086593,	
2017-07-13 05:34:07,414 Epoch[64] Batch [1090]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.086491,	
2017-07-13 05:34:14,684 Epoch[64] Batch [1100]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.086453,	
2017-07-13 05:34:22,231 Epoch[64] Batch [1110]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.086333,	
2017-07-13 05:34:29,625 Epoch[64] Batch [1120]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.086303,	
2017-07-13 05:34:37,048 Epoch[64] Batch [1130]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.086281,	
2017-07-13 05:34:44,615 Epoch[64] Batch [1140]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.086200,	
2017-07-13 05:34:52,088 Epoch[64] Batch [1150]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.086167,	
2017-07-13 05:34:59,628 Epoch[64] Batch [1160]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.086128,	
2017-07-13 05:35:07,128 Epoch[64] Batch [1170]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.086072,	
2017-07-13 05:35:14,455 Epoch[64] Batch [1180]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.086131,	
2017-07-13 05:35:21,680 Epoch[64] Batch [1190]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.086053,	
2017-07-13 05:35:29,290 Epoch[64] Batch [1200]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.086055,	
2017-07-13 05:35:36,605 Epoch[64] Batch [1210]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.085996,	
2017-07-13 05:35:43,824 Epoch[64] Batch [1220]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.085933,	
2017-07-13 05:35:51,103 Epoch[64] Batch [1230]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.085903,	
2017-07-13 05:35:58,199 Epoch[64] Batch [1240]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.085888,	
2017-07-13 05:36:05,397 Epoch[64] Batch [1250]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.085744,	
2017-07-13 05:36:12,872 Epoch[64] Batch [1260]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.085666,	
2017-07-13 05:36:20,196 Epoch[64] Batch [1270]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.085607,	
2017-07-13 05:36:27,523 Epoch[64] Batch [1280]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.085618,	
2017-07-13 05:36:34,985 Epoch[64] Batch [1290]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.085574,	
2017-07-13 05:36:42,463 Epoch[64] Batch [1300]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.085487,	
2017-07-13 05:36:49,754 Epoch[64] Batch [1310]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.085449,	
2017-07-13 05:36:57,012 Epoch[64] Batch [1320]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.085371,	
2017-07-13 05:37:04,556 Epoch[64] Batch [1330]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.085275,	
2017-07-13 05:37:12,108 Epoch[64] Batch [1340]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.085254,	
2017-07-13 05:37:19,610 Epoch[64] Batch [1350]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.085256,	
2017-07-13 05:37:27,103 Epoch[64] Batch [1360]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.085216,	
2017-07-13 05:37:34,449 Epoch[64] Batch [1370]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.085210,	
2017-07-13 05:37:41,884 Epoch[64] Batch [1380]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.085185,	
2017-07-13 05:37:49,326 Epoch[64] Batch [1390]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.085194,	
2017-07-13 05:37:56,762 Epoch[64] Batch [1400]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.085166,	
2017-07-13 05:38:04,527 Epoch[64] Batch [1410]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.085364,	
2017-07-13 05:38:12,238 Epoch[64] Batch [1420]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.085363,	
2017-07-13 05:38:20,001 Epoch[64] Batch [1430]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.085368,	
2017-07-13 05:38:27,843 Epoch[64] Batch [1440]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.085411,	
2017-07-13 05:38:35,404 Epoch[64] Batch [1450]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.085404,	
2017-07-13 05:38:43,122 Epoch[64] Batch [1460]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.085401,	
2017-07-13 05:38:51,021 Epoch[64] Batch [1470]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.085452,	
2017-07-13 05:38:58,768 Epoch[64] Batch [1480]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.085419,	
2017-07-13 05:39:03,239 Epoch[64] Train-FCNLogLoss=0.085403
2017-07-13 05:39:03,239 Epoch[64] Time cost=916.347
2017-07-13 05:39:04,153 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0065.params"
2017-07-13 05:39:07,716 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0065.states"
2017-07-13 05:39:16,328 Epoch[65] Batch [10]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.081942,	
2017-07-13 05:39:23,942 Epoch[65] Batch [20]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.081832,	
2017-07-13 05:39:31,682 Epoch[65] Batch [30]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.079969,	
2017-07-13 05:39:39,455 Epoch[65] Batch [40]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.080905,	
2017-07-13 05:39:47,491 Epoch[65] Batch [50]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.080762,	
2017-07-13 05:39:55,292 Epoch[65] Batch [60]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.079906,	
2017-07-13 05:40:02,929 Epoch[65] Batch [70]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.082017,	
2017-07-13 05:40:10,766 Epoch[65] Batch [80]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.081799,	
2017-07-13 05:40:18,498 Epoch[65] Batch [90]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.082083,	
2017-07-13 05:40:26,306 Epoch[65] Batch [100]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.082334,	
2017-07-13 05:40:34,213 Epoch[65] Batch [110]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.082701,	
2017-07-13 05:40:42,119 Epoch[65] Batch [120]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.082181,	
2017-07-13 05:40:50,052 Epoch[65] Batch [130]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.081721,	
2017-07-13 05:40:57,815 Epoch[65] Batch [140]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.081582,	
2017-07-13 05:41:05,350 Epoch[65] Batch [150]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.081258,	
2017-07-13 05:41:13,044 Epoch[65] Batch [160]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.080994,	
2017-07-13 05:41:19,661 Epoch[65] Batch [170]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.081104,	
2017-07-13 05:41:23,814 Epoch[65] Batch [180]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.080866,	
2017-07-13 05:41:27,879 Epoch[65] Batch [190]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.081040,	
2017-07-13 05:41:31,999 Epoch[65] Batch [200]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.081167,	
2017-07-13 05:41:36,229 Epoch[65] Batch [210]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.080931,	
2017-07-13 05:41:40,312 Epoch[65] Batch [220]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.081130,	
2017-07-13 05:41:44,567 Epoch[65] Batch [230]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.080865,	
2017-07-13 05:41:48,710 Epoch[65] Batch [240]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.080907,	
2017-07-13 05:41:52,870 Epoch[65] Batch [250]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.081012,	
2017-07-13 05:41:57,331 Epoch[65] Batch [260]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.080989,	
2017-07-13 05:42:01,378 Epoch[65] Batch [270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.080674,	
2017-07-13 05:42:05,620 Epoch[65] Batch [280]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.080681,	
2017-07-13 05:42:09,954 Epoch[65] Batch [290]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.080888,	
2017-07-13 05:42:14,074 Epoch[65] Batch [300]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.080861,	
2017-07-13 05:42:18,232 Epoch[65] Batch [310]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.081048,	
2017-07-13 05:42:22,600 Epoch[65] Batch [320]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.080931,	
2017-07-13 05:42:26,921 Epoch[65] Batch [330]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.080896,	
2017-07-13 05:42:31,091 Epoch[65] Batch [340]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.080866,	
2017-07-13 05:42:35,141 Epoch[65] Batch [350]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.080810,	
2017-07-13 05:42:39,165 Epoch[65] Batch [360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.080713,	
2017-07-13 05:42:43,630 Epoch[65] Batch [370]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.080523,	
2017-07-13 05:42:47,652 Epoch[65] Batch [380]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.080574,	
2017-07-13 05:42:51,930 Epoch[65] Batch [390]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.080502,	
2017-07-13 05:42:56,142 Epoch[65] Batch [400]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.080437,	
2017-07-13 05:43:00,438 Epoch[65] Batch [410]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.080417,	
2017-07-13 05:43:04,531 Epoch[65] Batch [420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.080190,	
2017-07-13 05:43:08,526 Epoch[65] Batch [430]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.080235,	
2017-07-13 05:43:12,858 Epoch[65] Batch [440]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.080090,	
2017-07-13 05:43:17,053 Epoch[65] Batch [450]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.079779,	
2017-07-13 05:43:21,181 Epoch[65] Batch [460]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.079728,	
2017-07-13 05:43:25,305 Epoch[65] Batch [470]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.079865,	
2017-07-13 05:43:29,481 Epoch[65] Batch [480]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.080004,	
2017-07-13 05:43:33,482 Epoch[65] Batch [490]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.080061,	
2017-07-13 05:43:37,562 Epoch[65] Batch [500]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.079895,	
2017-07-13 05:43:41,872 Epoch[65] Batch [510]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.079799,	
2017-07-13 05:43:45,821 Epoch[65] Batch [520]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.079776,	
2017-07-13 05:43:49,925 Epoch[65] Batch [530]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.079800,	
2017-07-13 05:43:54,066 Epoch[65] Batch [540]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.079672,	
2017-07-13 05:43:58,330 Epoch[65] Batch [550]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.079786,	
2017-07-13 05:44:02,649 Epoch[65] Batch [560]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.079723,	
2017-07-13 05:44:06,767 Epoch[65] Batch [570]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.079557,	
2017-07-13 05:44:11,132 Epoch[65] Batch [580]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.079676,	
2017-07-13 05:44:15,144 Epoch[65] Batch [590]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.079637,	
2017-07-13 05:44:19,303 Epoch[65] Batch [600]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.079654,	
2017-07-13 05:44:23,503 Epoch[65] Batch [610]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.079688,	
2017-07-13 05:44:27,544 Epoch[65] Batch [620]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.079708,	
2017-07-13 05:44:31,514 Epoch[65] Batch [630]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.079606,	
2017-07-13 05:44:35,779 Epoch[65] Batch [640]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.079511,	
2017-07-13 05:44:39,986 Epoch[65] Batch [650]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.079567,	
2017-07-13 05:44:44,277 Epoch[65] Batch [660]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.079642,	
2017-07-13 05:44:48,491 Epoch[65] Batch [670]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.079631,	
2017-07-13 05:44:52,556 Epoch[65] Batch [680]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.079834,	
2017-07-13 05:44:56,870 Epoch[65] Batch [690]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.079859,	
2017-07-13 05:45:01,035 Epoch[65] Batch [700]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.079834,	
2017-07-13 05:45:05,128 Epoch[65] Batch [710]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.079843,	
2017-07-13 05:45:09,140 Epoch[65] Batch [720]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.080052,	
2017-07-13 05:45:13,145 Epoch[65] Batch [730]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.080178,	
2017-07-13 05:45:17,220 Epoch[65] Batch [740]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.080182,	
2017-07-13 05:45:21,296 Epoch[65] Batch [750]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.080188,	
2017-07-13 05:45:25,654 Epoch[65] Batch [760]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.080143,	
2017-07-13 05:45:29,864 Epoch[65] Batch [770]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.080143,	
2017-07-13 05:45:34,148 Epoch[65] Batch [780]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.080151,	
2017-07-13 05:45:38,471 Epoch[65] Batch [790]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.080081,	
2017-07-13 05:45:43,084 Epoch[65] Batch [800]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.080079,	
2017-07-13 05:45:47,307 Epoch[65] Batch [810]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.080045,	
2017-07-13 05:45:51,439 Epoch[65] Batch [820]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.080018,	
2017-07-13 05:45:55,634 Epoch[65] Batch [830]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.080116,	
2017-07-13 05:45:59,693 Epoch[65] Batch [840]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.080086,	
2017-07-13 05:46:03,920 Epoch[65] Batch [850]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.080041,	
2017-07-13 05:46:07,988 Epoch[65] Batch [860]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.080127,	
2017-07-13 05:46:12,228 Epoch[65] Batch [870]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.080151,	
2017-07-13 05:46:16,531 Epoch[65] Batch [880]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.080177,	
2017-07-13 05:46:20,717 Epoch[65] Batch [890]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.080209,	
2017-07-13 05:46:25,156 Epoch[65] Batch [900]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.080216,	
2017-07-13 05:46:29,502 Epoch[65] Batch [910]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.080211,	
2017-07-13 05:46:33,477 Epoch[65] Batch [920]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.080133,	
2017-07-13 05:46:37,609 Epoch[65] Batch [930]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.080045,	
2017-07-13 05:46:41,565 Epoch[65] Batch [940]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.079990,	
2017-07-13 05:46:45,522 Epoch[65] Batch [950]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.079973,	
2017-07-13 05:46:49,720 Epoch[65] Batch [960]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.079920,	
2017-07-13 05:46:53,708 Epoch[65] Batch [970]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.079883,	
2017-07-13 05:46:57,621 Epoch[65] Batch [980]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.079823,	
2017-07-13 05:47:01,758 Epoch[65] Batch [990]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.079877,	
2017-07-13 05:47:05,834 Epoch[65] Batch [1000]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.079874,	
2017-07-13 05:47:09,984 Epoch[65] Batch [1010]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.079787,	
2017-07-13 05:47:14,221 Epoch[65] Batch [1020]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.079820,	
2017-07-13 05:47:18,290 Epoch[65] Batch [1030]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.079844,	
2017-07-13 05:47:22,586 Epoch[65] Batch [1040]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.079892,	
2017-07-13 05:47:26,793 Epoch[65] Batch [1050]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.079874,	
2017-07-13 05:47:30,700 Epoch[65] Batch [1060]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.079779,	
2017-07-13 05:47:34,637 Epoch[65] Batch [1070]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.079800,	
2017-07-13 05:47:38,824 Epoch[65] Batch [1080]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.079812,	
2017-07-13 05:47:42,934 Epoch[65] Batch [1090]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.079776,	
2017-07-13 05:47:46,984 Epoch[65] Batch [1100]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.079761,	
2017-07-13 05:47:51,007 Epoch[65] Batch [1110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.079744,	
2017-07-13 05:47:55,182 Epoch[65] Batch [1120]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.079762,	
2017-07-13 05:47:59,426 Epoch[65] Batch [1130]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.079714,	
2017-07-13 05:48:03,450 Epoch[65] Batch [1140]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.079742,	
2017-07-13 05:48:07,641 Epoch[65] Batch [1150]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.079675,	
2017-07-13 05:48:11,805 Epoch[65] Batch [1160]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.079639,	
2017-07-13 05:48:15,877 Epoch[65] Batch [1170]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.079619,	
2017-07-13 05:48:19,923 Epoch[65] Batch [1180]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.079575,	
2017-07-13 05:48:23,997 Epoch[65] Batch [1190]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.079568,	
2017-07-13 05:48:27,958 Epoch[65] Batch [1200]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.079621,	
2017-07-13 05:48:32,052 Epoch[65] Batch [1210]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.079622,	
2017-07-13 05:48:36,172 Epoch[65] Batch [1220]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.079635,	
2017-07-13 05:48:40,460 Epoch[65] Batch [1230]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.079549,	
2017-07-13 05:48:44,515 Epoch[65] Batch [1240]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.079550,	
2017-07-13 05:48:48,501 Epoch[65] Batch [1250]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.079568,	
2017-07-13 05:48:52,672 Epoch[65] Batch [1260]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.079563,	
2017-07-13 05:48:56,844 Epoch[65] Batch [1270]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.079507,	
2017-07-13 05:49:00,939 Epoch[65] Batch [1280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.079485,	
2017-07-13 05:49:05,095 Epoch[65] Batch [1290]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.079491,	
2017-07-13 05:49:09,270 Epoch[65] Batch [1300]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.079511,	
2017-07-13 05:49:13,384 Epoch[65] Batch [1310]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.079498,	
2017-07-13 05:49:17,514 Epoch[65] Batch [1320]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.079525,	
2017-07-13 05:49:21,535 Epoch[65] Batch [1330]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.079476,	
2017-07-13 05:49:25,538 Epoch[65] Batch [1340]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.079399,	
2017-07-13 05:49:29,894 Epoch[65] Batch [1350]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.079399,	
2017-07-13 05:49:34,172 Epoch[65] Batch [1360]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.079400,	
2017-07-13 05:49:38,289 Epoch[65] Batch [1370]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.079371,	
2017-07-13 05:49:42,384 Epoch[65] Batch [1380]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.079288,	
2017-07-13 05:49:46,501 Epoch[65] Batch [1390]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.079247,	
2017-07-13 05:49:50,682 Epoch[65] Batch [1400]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.079218,	
2017-07-13 05:49:54,852 Epoch[65] Batch [1410]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.079196,	
2017-07-13 05:49:58,869 Epoch[65] Batch [1420]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.079229,	
2017-07-13 05:50:02,918 Epoch[65] Batch [1430]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.079210,	
2017-07-13 05:50:07,078 Epoch[65] Batch [1440]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.079237,	
2017-07-13 05:50:11,563 Epoch[65] Batch [1450]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.079277,	
2017-07-13 05:50:15,665 Epoch[65] Batch [1460]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.079314,	
2017-07-13 05:50:19,747 Epoch[65] Batch [1470]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.079346,	
2017-07-13 05:50:24,013 Epoch[65] Batch [1480]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.079347,	
2017-07-13 05:50:26,316 Epoch[65] Train-FCNLogLoss=0.079349
2017-07-13 05:50:26,316 Epoch[65] Time cost=678.600
2017-07-13 05:50:27,001 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0066.params"
2017-07-13 05:50:30,440 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0066.states"
2017-07-13 05:50:35,416 Epoch[66] Batch [10]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.073366,	
2017-07-13 05:50:39,685 Epoch[66] Batch [20]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.078677,	
2017-07-13 05:50:43,848 Epoch[66] Batch [30]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.078142,	
2017-07-13 05:50:48,045 Epoch[66] Batch [40]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.077128,	
2017-07-13 05:50:51,977 Epoch[66] Batch [50]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.076672,	
2017-07-13 05:50:56,078 Epoch[66] Batch [60]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.077876,	
2017-07-13 05:51:00,504 Epoch[66] Batch [70]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.078114,	
2017-07-13 05:51:05,003 Epoch[66] Batch [80]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.078167,	
2017-07-13 05:51:09,223 Epoch[66] Batch [90]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.078837,	
2017-07-13 05:51:13,435 Epoch[66] Batch [100]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.078703,	
2017-07-13 05:51:17,777 Epoch[66] Batch [110]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.078612,	
2017-07-13 05:51:21,994 Epoch[66] Batch [120]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.078282,	
2017-07-13 05:51:26,154 Epoch[66] Batch [130]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.078405,	
2017-07-13 05:51:30,410 Epoch[66] Batch [140]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.078822,	
2017-07-13 05:51:34,638 Epoch[66] Batch [150]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.078876,	
2017-07-13 05:51:38,719 Epoch[66] Batch [160]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.078765,	
2017-07-13 05:51:42,632 Epoch[66] Batch [170]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.078276,	
2017-07-13 05:51:46,788 Epoch[66] Batch [180]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.078270,	
2017-07-13 05:51:51,017 Epoch[66] Batch [190]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.078035,	
2017-07-13 05:51:55,019 Epoch[66] Batch [200]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.077967,	
2017-07-13 05:51:59,008 Epoch[66] Batch [210]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.078258,	
2017-07-13 05:52:03,191 Epoch[66] Batch [220]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.078400,	
2017-07-13 05:52:07,178 Epoch[66] Batch [230]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.078365,	
2017-07-13 05:52:11,473 Epoch[66] Batch [240]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.078312,	
2017-07-13 05:52:15,535 Epoch[66] Batch [250]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.078332,	
2017-07-13 05:52:19,534 Epoch[66] Batch [260]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.078191,	
2017-07-13 05:52:23,842 Epoch[66] Batch [270]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.078284,	
2017-07-13 05:52:27,981 Epoch[66] Batch [280]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.078162,	
2017-07-13 05:52:32,167 Epoch[66] Batch [290]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.077988,	
2017-07-13 05:52:36,387 Epoch[66] Batch [300]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.077989,	
2017-07-13 05:52:40,765 Epoch[66] Batch [310]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.077979,	
2017-07-13 05:52:44,903 Epoch[66] Batch [320]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.077990,	
2017-07-13 05:52:49,717 Epoch[66] Batch [330]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077950,	
2017-07-13 05:52:54,070 Epoch[66] Batch [340]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.077993,	
2017-07-13 05:52:58,471 Epoch[66] Batch [350]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.078174,	
2017-07-13 05:53:02,577 Epoch[66] Batch [360]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.078159,	
2017-07-13 05:53:06,804 Epoch[66] Batch [370]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.077946,	
2017-07-13 05:53:10,752 Epoch[66] Batch [380]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.078041,	
2017-07-13 05:53:15,087 Epoch[66] Batch [390]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.078091,	
2017-07-13 05:53:19,347 Epoch[66] Batch [400]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.077900,	
2017-07-13 05:53:23,577 Epoch[66] Batch [410]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.077726,	
2017-07-13 05:53:27,940 Epoch[66] Batch [420]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.077659,	
2017-07-13 05:53:32,160 Epoch[66] Batch [430]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.077617,	
2017-07-13 05:53:36,218 Epoch[66] Batch [440]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.077629,	
2017-07-13 05:53:40,396 Epoch[66] Batch [450]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.077627,	
2017-07-13 05:53:44,543 Epoch[66] Batch [460]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.077621,	
2017-07-13 05:53:48,638 Epoch[66] Batch [470]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.077601,	
2017-07-13 05:53:52,779 Epoch[66] Batch [480]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.077615,	
2017-07-13 05:53:57,380 Epoch[66] Batch [490]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.077705,	
2017-07-13 05:54:01,831 Epoch[66] Batch [500]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.077842,	
2017-07-13 05:54:06,253 Epoch[66] Batch [510]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.077798,	
2017-07-13 05:54:10,538 Epoch[66] Batch [520]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.077944,	
2017-07-13 05:54:14,960 Epoch[66] Batch [530]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.077887,	
2017-07-13 05:54:19,127 Epoch[66] Batch [540]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.077853,	
2017-07-13 05:54:23,761 Epoch[66] Batch [550]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.077904,	
2017-07-13 05:54:28,248 Epoch[66] Batch [560]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.078019,	
2017-07-13 05:54:32,775 Epoch[66] Batch [570]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.078070,	
2017-07-13 05:54:37,233 Epoch[66] Batch [580]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.078195,	
2017-07-13 05:54:42,208 Epoch[66] Batch [590]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.078229,	
2017-07-13 05:54:46,956 Epoch[66] Batch [600]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.078208,	
2017-07-13 05:54:51,554 Epoch[66] Batch [610]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.078126,	
2017-07-13 05:54:56,651 Epoch[66] Batch [620]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.078176,	
2017-07-13 05:55:01,274 Epoch[66] Batch [630]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.078269,	
2017-07-13 05:55:06,126 Epoch[66] Batch [640]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.078293,	
2017-07-13 05:55:10,833 Epoch[66] Batch [650]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.078138,	
2017-07-13 05:55:15,942 Epoch[66] Batch [660]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.078112,	
2017-07-13 05:55:21,257 Epoch[66] Batch [670]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.078121,	
2017-07-13 05:55:27,169 Epoch[66] Batch [680]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.078055,	
2017-07-13 05:55:32,270 Epoch[66] Batch [690]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.077955,	
2017-07-13 05:55:37,509 Epoch[66] Batch [700]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.077946,	
2017-07-13 05:55:42,557 Epoch[66] Batch [710]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.077913,	
2017-07-13 05:55:47,245 Epoch[66] Batch [720]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.077860,	
2017-07-13 05:55:52,246 Epoch[66] Batch [730]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.077880,	
2017-07-13 05:55:57,345 Epoch[66] Batch [740]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.077947,	
2017-07-13 05:56:02,673 Epoch[66] Batch [750]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.078082,	
2017-07-13 05:56:07,808 Epoch[66] Batch [760]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.078109,	
2017-07-13 05:56:12,833 Epoch[66] Batch [770]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.078192,	
2017-07-13 05:56:17,872 Epoch[66] Batch [780]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.078225,	
2017-07-13 05:56:23,335 Epoch[66] Batch [790]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.078335,	
2017-07-13 05:56:28,226 Epoch[66] Batch [800]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.078349,	
2017-07-13 05:56:33,274 Epoch[66] Batch [810]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.078319,	
2017-07-13 05:56:38,228 Epoch[66] Batch [820]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.078359,	
2017-07-13 05:56:44,211 Epoch[66] Batch [830]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.078392,	
2017-07-13 05:56:49,593 Epoch[66] Batch [840]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.078370,	
2017-07-13 05:56:55,068 Epoch[66] Batch [850]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.078425,	
2017-07-13 05:57:00,127 Epoch[66] Batch [860]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.078368,	
2017-07-13 05:57:05,721 Epoch[66] Batch [870]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.078376,	
2017-07-13 05:57:11,420 Epoch[66] Batch [880]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.078352,	
2017-07-13 05:57:16,726 Epoch[66] Batch [890]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.078343,	
2017-07-13 05:57:22,264 Epoch[66] Batch [900]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.078268,	
2017-07-13 05:57:27,440 Epoch[66] Batch [910]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.078349,	
2017-07-13 05:57:32,751 Epoch[66] Batch [920]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.078353,	
2017-07-13 05:57:38,279 Epoch[66] Batch [930]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.078327,	
2017-07-13 05:57:43,766 Epoch[66] Batch [940]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.078365,	
2017-07-13 05:57:49,329 Epoch[66] Batch [950]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.078365,	
2017-07-13 05:57:55,117 Epoch[66] Batch [960]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.078269,	
2017-07-13 05:58:00,646 Epoch[66] Batch [970]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.078230,	
2017-07-13 05:58:06,058 Epoch[66] Batch [980]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.078217,	
2017-07-13 05:58:11,285 Epoch[66] Batch [990]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.078211,	
2017-07-13 05:58:16,728 Epoch[66] Batch [1000]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.078241,	
2017-07-13 05:58:22,299 Epoch[66] Batch [1010]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.078243,	
2017-07-13 05:58:27,867 Epoch[66] Batch [1020]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.078297,	
2017-07-13 05:58:33,836 Epoch[66] Batch [1030]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.078226,	
2017-07-13 05:58:39,486 Epoch[66] Batch [1040]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.078259,	
2017-07-13 05:58:45,284 Epoch[66] Batch [1050]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.078244,	
2017-07-13 05:58:51,527 Epoch[66] Batch [1060]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.078261,	
2017-07-13 05:58:57,343 Epoch[66] Batch [1070]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.078171,	
2017-07-13 05:59:03,106 Epoch[66] Batch [1080]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.078159,	
2017-07-13 05:59:08,698 Epoch[66] Batch [1090]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.078230,	
2017-07-13 05:59:14,276 Epoch[66] Batch [1100]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.078374,	
2017-07-13 05:59:20,115 Epoch[66] Batch [1110]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.078786,	
2017-07-13 05:59:25,813 Epoch[66] Batch [1120]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.078879,	
2017-07-13 05:59:31,546 Epoch[66] Batch [1130]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.079132,	
2017-07-13 05:59:36,959 Epoch[66] Batch [1140]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.079245,	
2017-07-13 05:59:42,988 Epoch[66] Batch [1150]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.079287,	
2017-07-13 05:59:49,191 Epoch[66] Batch [1160]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.079415,	
2017-07-13 05:59:55,887 Epoch[66] Batch [1170]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.079557,	
2017-07-13 06:00:01,961 Epoch[66] Batch [1180]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.079681,	
2017-07-13 06:00:08,184 Epoch[66] Batch [1190]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.079699,	
2017-07-13 06:00:14,678 Epoch[66] Batch [1200]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.079720,	
2017-07-13 06:00:21,045 Epoch[66] Batch [1210]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.079719,	
2017-07-13 06:00:27,607 Epoch[66] Batch [1220]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.079750,	
2017-07-13 06:00:33,907 Epoch[66] Batch [1230]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.079847,	
2017-07-13 06:00:40,209 Epoch[66] Batch [1240]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.079832,	
2017-07-13 06:00:46,344 Epoch[66] Batch [1250]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.079937,	
2017-07-13 06:00:52,621 Epoch[66] Batch [1260]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.079913,	
2017-07-13 06:00:59,293 Epoch[66] Batch [1270]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.079970,	
2017-07-13 06:01:06,392 Epoch[66] Batch [1280]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.080079,	
2017-07-13 06:01:13,310 Epoch[66] Batch [1290]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.080111,	
2017-07-13 06:01:20,246 Epoch[66] Batch [1300]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.080159,	
2017-07-13 06:01:27,209 Epoch[66] Batch [1310]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.080213,	
2017-07-13 06:01:34,004 Epoch[66] Batch [1320]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.080322,	
2017-07-13 06:01:40,963 Epoch[66] Batch [1330]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.080333,	
2017-07-13 06:01:48,005 Epoch[66] Batch [1340]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.080340,	
2017-07-13 06:01:54,902 Epoch[66] Batch [1350]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.080343,	
2017-07-13 06:02:02,002 Epoch[66] Batch [1360]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.080364,	
2017-07-13 06:02:09,215 Epoch[66] Batch [1370]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.080398,	
2017-07-13 06:02:16,158 Epoch[66] Batch [1380]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.080342,	
2017-07-13 06:02:23,345 Epoch[66] Batch [1390]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.080328,	
2017-07-13 06:02:30,766 Epoch[66] Batch [1400]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.080322,	
2017-07-13 06:02:38,387 Epoch[66] Batch [1410]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.080334,	
2017-07-13 06:02:45,761 Epoch[66] Batch [1420]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.080361,	
2017-07-13 06:02:53,499 Epoch[66] Batch [1430]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.080372,	
2017-07-13 06:03:01,209 Epoch[66] Batch [1440]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.080358,	
2017-07-13 06:03:08,691 Epoch[66] Batch [1450]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.080395,	
2017-07-13 06:03:16,239 Epoch[66] Batch [1460]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.080366,	
2017-07-13 06:03:23,761 Epoch[66] Batch [1470]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.080388,	
2017-07-13 06:03:31,278 Epoch[66] Batch [1480]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.080380,	
2017-07-13 06:03:35,894 Epoch[66] Train-FCNLogLoss=0.080381
2017-07-13 06:03:35,894 Epoch[66] Time cost=785.453
2017-07-13 06:03:36,777 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0067.params"
2017-07-13 06:03:40,164 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0067.states"
2017-07-13 06:03:49,010 Epoch[67] Batch [10]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.094317,	
2017-07-13 06:03:56,830 Epoch[67] Batch [20]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.085649,	
2017-07-13 06:04:04,206 Epoch[67] Batch [30]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.086787,	
2017-07-13 06:04:11,582 Epoch[67] Batch [40]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.085488,	
2017-07-13 06:04:19,052 Epoch[67] Batch [50]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.084655,	
2017-07-13 06:04:26,534 Epoch[67] Batch [60]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.084009,	
2017-07-13 06:04:34,110 Epoch[67] Batch [70]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.083059,	
2017-07-13 06:04:41,759 Epoch[67] Batch [80]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.082346,	
2017-07-13 06:04:49,239 Epoch[67] Batch [90]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.080872,	
2017-07-13 06:04:56,783 Epoch[67] Batch [100]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.080354,	
2017-07-13 06:05:04,227 Epoch[67] Batch [110]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.079469,	
2017-07-13 06:05:12,002 Epoch[67] Batch [120]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.079291,	
2017-07-13 06:05:19,560 Epoch[67] Batch [130]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.079659,	
2017-07-13 06:05:27,091 Epoch[67] Batch [140]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.079578,	
2017-07-13 06:05:34,837 Epoch[67] Batch [150]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.079448,	
2017-07-13 06:05:42,404 Epoch[67] Batch [160]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.079548,	
2017-07-13 06:05:50,321 Epoch[67] Batch [170]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.078943,	
2017-07-13 06:05:58,175 Epoch[67] Batch [180]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.079183,	
2017-07-13 06:06:05,827 Epoch[67] Batch [190]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.079179,	
2017-07-13 06:06:13,694 Epoch[67] Batch [200]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.079186,	
2017-07-13 06:06:21,680 Epoch[67] Batch [210]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.078996,	
2017-07-13 06:06:29,696 Epoch[67] Batch [220]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.078847,	
2017-07-13 06:06:37,376 Epoch[67] Batch [230]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.078812,	
2017-07-13 06:06:45,015 Epoch[67] Batch [240]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.078941,	
2017-07-13 06:06:53,115 Epoch[67] Batch [250]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.079043,	
2017-07-13 06:07:01,034 Epoch[67] Batch [260]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.079223,	
2017-07-13 06:07:08,906 Epoch[67] Batch [270]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.079074,	
2017-07-13 06:07:16,763 Epoch[67] Batch [280]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.078960,	
2017-07-13 06:07:24,347 Epoch[67] Batch [290]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.078988,	
2017-07-13 06:07:32,238 Epoch[67] Batch [300]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.079389,	
2017-07-13 06:07:39,885 Epoch[67] Batch [310]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.079308,	
2017-07-13 06:07:47,853 Epoch[67] Batch [320]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.079547,	
2017-07-13 06:07:55,567 Epoch[67] Batch [330]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.079580,	
2017-07-13 06:08:03,237 Epoch[67] Batch [340]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.079735,	
2017-07-13 06:08:10,544 Epoch[67] Batch [350]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.079489,	
2017-07-13 06:08:18,418 Epoch[67] Batch [360]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.079458,	
2017-07-13 06:08:26,256 Epoch[67] Batch [370]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.079572,	
2017-07-13 06:08:34,108 Epoch[67] Batch [380]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.079574,	
2017-07-13 06:08:42,102 Epoch[67] Batch [390]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.079339,	
2017-07-13 06:08:49,693 Epoch[67] Batch [400]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.079256,	
2017-07-13 06:08:57,337 Epoch[67] Batch [410]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.079022,	
2017-07-13 06:09:04,801 Epoch[67] Batch [420]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.078970,	
2017-07-13 06:09:14,449 Epoch[67] Batch [430]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.079135,	
2017-07-13 06:09:20,481 Epoch[67] Batch [440]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.079288,	
2017-07-13 06:09:26,208 Epoch[67] Batch [450]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.079276,	
2017-07-13 06:09:31,863 Epoch[67] Batch [460]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.079056,	
2017-07-13 06:09:37,684 Epoch[67] Batch [470]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.079165,	
2017-07-13 06:09:43,759 Epoch[67] Batch [480]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.079092,	
2017-07-13 06:09:49,542 Epoch[67] Batch [490]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.078928,	
2017-07-13 06:09:55,221 Epoch[67] Batch [500]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.078850,	
2017-07-13 06:10:01,150 Epoch[67] Batch [510]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.078913,	
2017-07-13 06:10:07,115 Epoch[67] Batch [520]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.078890,	
2017-07-13 06:10:12,773 Epoch[67] Batch [530]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.078735,	
2017-07-13 06:10:18,521 Epoch[67] Batch [540]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.078718,	
2017-07-13 06:10:24,401 Epoch[67] Batch [550]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.078590,	
2017-07-13 06:10:30,264 Epoch[67] Batch [560]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.078583,	
2017-07-13 06:10:35,942 Epoch[67] Batch [570]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.078602,	
2017-07-13 06:10:41,562 Epoch[67] Batch [580]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.078559,	
2017-07-13 06:10:47,550 Epoch[67] Batch [590]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.078549,	
2017-07-13 06:10:53,642 Epoch[67] Batch [600]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.078566,	
2017-07-13 06:10:59,640 Epoch[67] Batch [610]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.078433,	
2017-07-13 06:11:05,836 Epoch[67] Batch [620]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.078521,	
2017-07-13 06:11:11,707 Epoch[67] Batch [630]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.078600,	
2017-07-13 06:11:18,304 Epoch[67] Batch [640]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.078625,	
2017-07-13 06:11:24,058 Epoch[67] Batch [650]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.078529,	
2017-07-13 06:11:30,266 Epoch[67] Batch [660]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.078490,	
2017-07-13 06:11:36,289 Epoch[67] Batch [670]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.078554,	
2017-07-13 06:11:42,204 Epoch[67] Batch [680]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.078586,	
2017-07-13 06:11:48,133 Epoch[67] Batch [690]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.078734,	
2017-07-13 06:11:54,474 Epoch[67] Batch [700]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.078778,	
2017-07-13 06:12:01,063 Epoch[67] Batch [710]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.078860,	
2017-07-13 06:12:07,754 Epoch[67] Batch [720]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.078799,	
2017-07-13 06:12:14,682 Epoch[67] Batch [730]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.078849,	
2017-07-13 06:12:20,980 Epoch[67] Batch [740]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.078977,	
2017-07-13 06:12:27,789 Epoch[67] Batch [750]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.078844,	
2017-07-13 06:12:34,474 Epoch[67] Batch [760]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.078891,	
2017-07-13 06:12:41,182 Epoch[67] Batch [770]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.078818,	
2017-07-13 06:12:48,013 Epoch[67] Batch [780]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.078801,	
2017-07-13 06:12:54,603 Epoch[67] Batch [790]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.078845,	
2017-07-13 06:13:01,213 Epoch[67] Batch [800]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.078853,	
2017-07-13 06:13:08,121 Epoch[67] Batch [810]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.078914,	
2017-07-13 06:13:14,787 Epoch[67] Batch [820]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.078909,	
2017-07-13 06:13:21,682 Epoch[67] Batch [830]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.078986,	
2017-07-13 06:13:28,669 Epoch[67] Batch [840]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.079000,	
2017-07-13 06:13:35,317 Epoch[67] Batch [850]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.079169,	
2017-07-13 06:13:42,350 Epoch[67] Batch [860]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.079209,	
2017-07-13 06:13:49,193 Epoch[67] Batch [870]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.079216,	
2017-07-13 06:13:55,771 Epoch[67] Batch [880]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.079268,	
2017-07-13 06:14:02,583 Epoch[67] Batch [890]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.079269,	
2017-07-13 06:14:09,524 Epoch[67] Batch [900]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.079332,	
2017-07-13 06:14:16,196 Epoch[67] Batch [910]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.079347,	
2017-07-13 06:14:23,119 Epoch[67] Batch [920]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.079292,	
2017-07-13 06:14:30,042 Epoch[67] Batch [930]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.079345,	
2017-07-13 06:14:37,460 Epoch[67] Batch [940]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.079368,	
2017-07-13 06:14:44,631 Epoch[67] Batch [950]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.079335,	
2017-07-13 06:14:51,674 Epoch[67] Batch [960]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.079292,	
2017-07-13 06:14:58,794 Epoch[67] Batch [970]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.079367,	
2017-07-13 06:15:06,209 Epoch[67] Batch [980]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.079375,	
2017-07-13 06:15:13,406 Epoch[67] Batch [990]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.079369,	
2017-07-13 06:15:20,463 Epoch[67] Batch [1000]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.079439,	
2017-07-13 06:15:27,843 Epoch[67] Batch [1010]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.079453,	
2017-07-13 06:15:35,202 Epoch[67] Batch [1020]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.079437,	
2017-07-13 06:15:42,570 Epoch[67] Batch [1030]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.079417,	
2017-07-13 06:15:49,724 Epoch[67] Batch [1040]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.079466,	
2017-07-13 06:15:57,376 Epoch[67] Batch [1050]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.079501,	
2017-07-13 06:16:04,483 Epoch[67] Batch [1060]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.079501,	
2017-07-13 06:16:11,625 Epoch[67] Batch [1070]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.079578,	
2017-07-13 06:16:18,444 Epoch[67] Batch [1080]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.079672,	
2017-07-13 06:16:24,618 Epoch[67] Batch [1090]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.079725,	
2017-07-13 06:16:30,997 Epoch[67] Batch [1100]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.079787,	
2017-07-13 06:16:37,620 Epoch[67] Batch [1110]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.079775,	
2017-07-13 06:16:44,545 Epoch[67] Batch [1120]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.080132,	
2017-07-13 06:16:51,137 Epoch[67] Batch [1130]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.080263,	
2017-07-13 06:16:57,652 Epoch[67] Batch [1140]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.080298,	
2017-07-13 06:17:04,165 Epoch[67] Batch [1150]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.080370,	
2017-07-13 06:17:10,385 Epoch[67] Batch [1160]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.080478,	
2017-07-13 06:17:17,343 Epoch[67] Batch [1170]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.080519,	
2017-07-13 06:17:23,895 Epoch[67] Batch [1180]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.080552,	
2017-07-13 06:17:30,552 Epoch[67] Batch [1190]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.080469,	
2017-07-13 06:17:36,776 Epoch[67] Batch [1200]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.080511,	
2017-07-13 06:17:43,073 Epoch[67] Batch [1210]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.080486,	
2017-07-13 06:17:49,798 Epoch[67] Batch [1220]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.080446,	
2017-07-13 06:17:56,443 Epoch[67] Batch [1230]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.080446,	
2017-07-13 06:18:03,236 Epoch[67] Batch [1240]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.080471,	
2017-07-13 06:18:09,632 Epoch[67] Batch [1250]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.080429,	
2017-07-13 06:18:15,780 Epoch[67] Batch [1260]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.080396,	
2017-07-13 06:18:21,981 Epoch[67] Batch [1270]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.080366,	
2017-07-13 06:18:28,263 Epoch[67] Batch [1280]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.080346,	
2017-07-13 06:18:34,465 Epoch[67] Batch [1290]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.080280,	
2017-07-13 06:18:41,020 Epoch[67] Batch [1300]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.080196,	
2017-07-13 06:18:47,671 Epoch[67] Batch [1310]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.080219,	
2017-07-13 06:18:54,894 Epoch[67] Batch [1320]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.080190,	
2017-07-13 06:19:01,185 Epoch[67] Batch [1330]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.080216,	
2017-07-13 06:19:07,905 Epoch[67] Batch [1340]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.080210,	
2017-07-13 06:19:14,407 Epoch[67] Batch [1350]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.080156,	
2017-07-13 06:19:20,731 Epoch[67] Batch [1360]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.080128,	
2017-07-13 06:19:26,978 Epoch[67] Batch [1370]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.080067,	
2017-07-13 06:19:33,482 Epoch[67] Batch [1380]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.080115,	
2017-07-13 06:19:39,985 Epoch[67] Batch [1390]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.080091,	
2017-07-13 06:19:46,407 Epoch[67] Batch [1400]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.080082,	
2017-07-13 06:19:52,931 Epoch[67] Batch [1410]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.080085,	
2017-07-13 06:19:59,484 Epoch[67] Batch [1420]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.080048,	
2017-07-13 06:20:05,667 Epoch[67] Batch [1430]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.080034,	
2017-07-13 06:20:11,893 Epoch[67] Batch [1440]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.080021,	
2017-07-13 06:20:18,239 Epoch[67] Batch [1450]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.079974,	
2017-07-13 06:20:24,989 Epoch[67] Batch [1460]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.079957,	
2017-07-13 06:20:31,324 Epoch[67] Batch [1470]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.079980,	
2017-07-13 06:20:37,846 Epoch[67] Batch [1480]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.079933,	
2017-07-13 06:20:41,556 Epoch[67] Train-FCNLogLoss=0.079972
2017-07-13 06:20:41,556 Epoch[67] Time cost=1021.392
2017-07-13 06:20:42,203 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0068.params"
2017-07-13 06:20:45,743 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0068.states"
2017-07-13 06:20:53,190 Epoch[68] Batch [10]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.078982,	
2017-07-13 06:20:59,493 Epoch[68] Batch [20]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.078228,	
2017-07-13 06:21:05,707 Epoch[68] Batch [30]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.078563,	
2017-07-13 06:21:12,280 Epoch[68] Batch [40]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.078749,	
2017-07-13 06:21:18,415 Epoch[68] Batch [50]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.077858,	
2017-07-13 06:21:25,196 Epoch[68] Batch [60]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.079334,	
2017-07-13 06:21:31,581 Epoch[68] Batch [70]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.078195,	
2017-07-13 06:21:38,536 Epoch[68] Batch [80]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.077523,	
2017-07-13 06:21:45,087 Epoch[68] Batch [90]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.077354,	
2017-07-13 06:21:52,031 Epoch[68] Batch [100]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.077690,	
2017-07-13 06:21:58,639 Epoch[68] Batch [110]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.077890,	
2017-07-13 06:22:05,721 Epoch[68] Batch [120]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.078523,	
2017-07-13 06:22:12,595 Epoch[68] Batch [130]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.078440,	
2017-07-13 06:22:19,236 Epoch[68] Batch [140]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.077991,	
2017-07-13 06:22:26,216 Epoch[68] Batch [150]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.077810,	
2017-07-13 06:22:32,943 Epoch[68] Batch [160]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.077556,	
2017-07-13 06:22:40,126 Epoch[68] Batch [170]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.077497,	
2017-07-13 06:22:46,964 Epoch[68] Batch [180]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.077545,	
2017-07-13 06:22:53,735 Epoch[68] Batch [190]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.077837,	
2017-07-13 06:23:00,171 Epoch[68] Batch [200]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.077631,	
2017-07-13 06:23:06,775 Epoch[68] Batch [210]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.077737,	
2017-07-13 06:23:13,532 Epoch[68] Batch [220]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.077611,	
2017-07-13 06:23:20,555 Epoch[68] Batch [230]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.077737,	
2017-07-13 06:23:27,578 Epoch[68] Batch [240]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.077969,	
2017-07-13 06:23:34,095 Epoch[68] Batch [250]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.077954,	
2017-07-13 06:23:40,871 Epoch[68] Batch [260]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.078132,	
2017-07-13 06:23:47,710 Epoch[68] Batch [270]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.078752,	
2017-07-13 06:23:54,500 Epoch[68] Batch [280]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.078608,	
2017-07-13 06:24:01,176 Epoch[68] Batch [290]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.078381,	
2017-07-13 06:24:08,107 Epoch[68] Batch [300]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.078305,	
2017-07-13 06:24:14,781 Epoch[68] Batch [310]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.078462,	
2017-07-13 06:24:21,596 Epoch[68] Batch [320]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.078337,	
2017-07-13 06:24:28,616 Epoch[68] Batch [330]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.078563,	
2017-07-13 06:24:35,300 Epoch[68] Batch [340]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.078535,	
2017-07-13 06:24:41,994 Epoch[68] Batch [350]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.078193,	
2017-07-13 06:24:49,037 Epoch[68] Batch [360]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.078232,	
2017-07-13 06:24:56,363 Epoch[68] Batch [370]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.078149,	
2017-07-13 06:25:03,021 Epoch[68] Batch [380]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.077945,	
2017-07-13 06:25:09,520 Epoch[68] Batch [390]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.077999,	
2017-07-13 06:25:16,332 Epoch[68] Batch [400]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.077960,	
2017-07-13 06:25:22,968 Epoch[68] Batch [410]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.077702,	
2017-07-13 06:25:30,068 Epoch[68] Batch [420]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.077554,	
2017-07-13 06:25:36,656 Epoch[68] Batch [430]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.077610,	
2017-07-13 06:25:43,395 Epoch[68] Batch [440]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.077532,	
2017-07-13 06:25:49,781 Epoch[68] Batch [450]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.077534,	
2017-07-13 06:25:56,433 Epoch[68] Batch [460]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.077528,	
2017-07-13 06:26:03,183 Epoch[68] Batch [470]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.077584,	
2017-07-13 06:26:09,949 Epoch[68] Batch [480]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.077642,	
2017-07-13 06:26:17,313 Epoch[68] Batch [490]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.077698,	
2017-07-13 06:26:24,556 Epoch[68] Batch [500]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.077652,	
2017-07-13 06:26:31,843 Epoch[68] Batch [510]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.077599,	
2017-07-13 06:26:38,960 Epoch[68] Batch [520]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.077570,	
2017-07-13 06:26:46,606 Epoch[68] Batch [530]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.077495,	
2017-07-13 06:26:53,855 Epoch[68] Batch [540]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.077530,	
2017-07-13 06:27:01,017 Epoch[68] Batch [550]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.077503,	
2017-07-13 06:27:08,402 Epoch[68] Batch [560]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.077512,	
2017-07-13 06:27:15,776 Epoch[68] Batch [570]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.077513,	
2017-07-13 06:27:23,300 Epoch[68] Batch [580]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.077659,	
2017-07-13 06:27:31,025 Epoch[68] Batch [590]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.077772,	
2017-07-13 06:27:38,496 Epoch[68] Batch [600]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.077827,	
2017-07-13 06:27:45,899 Epoch[68] Batch [610]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.077743,	
2017-07-13 06:27:53,320 Epoch[68] Batch [620]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.077709,	
2017-07-13 06:28:00,640 Epoch[68] Batch [630]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.077652,	
2017-07-13 06:28:07,998 Epoch[68] Batch [640]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.077828,	
2017-07-13 06:28:15,590 Epoch[68] Batch [650]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.077839,	
2017-07-13 06:28:22,970 Epoch[68] Batch [660]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.077823,	
2017-07-13 06:28:30,636 Epoch[68] Batch [670]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.077872,	
2017-07-13 06:28:38,330 Epoch[68] Batch [680]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.077929,	
2017-07-13 06:28:45,833 Epoch[68] Batch [690]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.077879,	
2017-07-13 06:28:53,325 Epoch[68] Batch [700]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.077895,	
2017-07-13 06:29:00,938 Epoch[68] Batch [710]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.077785,	
2017-07-13 06:29:08,446 Epoch[68] Batch [720]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.077777,	
2017-07-13 06:29:15,898 Epoch[68] Batch [730]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.077857,	
2017-07-13 06:29:23,149 Epoch[68] Batch [740]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.077879,	
2017-07-13 06:29:30,589 Epoch[68] Batch [750]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.077932,	
2017-07-13 06:29:38,193 Epoch[68] Batch [760]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.077933,	
2017-07-13 06:29:45,430 Epoch[68] Batch [770]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.077905,	
2017-07-13 06:29:53,181 Epoch[68] Batch [780]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.077928,	
2017-07-13 06:30:00,879 Epoch[68] Batch [790]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.077989,	
2017-07-13 06:30:08,737 Epoch[68] Batch [800]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.077950,	
2017-07-13 06:30:16,336 Epoch[68] Batch [810]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.077966,	
2017-07-13 06:30:24,331 Epoch[68] Batch [820]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.077914,	
2017-07-13 06:30:31,992 Epoch[68] Batch [830]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.077885,	
2017-07-13 06:30:39,700 Epoch[68] Batch [840]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.077727,	
2017-07-13 06:30:47,228 Epoch[68] Batch [850]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.077730,	
2017-07-13 06:30:55,116 Epoch[68] Batch [860]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.077711,	
2017-07-13 06:31:03,229 Epoch[68] Batch [870]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.077672,	
2017-07-13 06:31:11,230 Epoch[68] Batch [880]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.077558,	
2017-07-13 06:31:19,329 Epoch[68] Batch [890]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.077520,	
2017-07-13 06:31:27,470 Epoch[68] Batch [900]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.077572,	
2017-07-13 06:31:35,501 Epoch[68] Batch [910]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.077524,	
2017-07-13 06:31:43,925 Epoch[68] Batch [920]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.077472,	
2017-07-13 06:31:52,203 Epoch[68] Batch [930]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.077500,	
2017-07-13 06:32:00,197 Epoch[68] Batch [940]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.077485,	
2017-07-13 06:32:08,185 Epoch[68] Batch [950]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.077435,	
2017-07-13 06:32:16,070 Epoch[68] Batch [960]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.077419,	
2017-07-13 06:32:24,123 Epoch[68] Batch [970]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.077473,	
2017-07-13 06:32:32,214 Epoch[68] Batch [980]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.077440,	
2017-07-13 06:32:40,523 Epoch[68] Batch [990]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.077383,	
2017-07-13 06:32:48,527 Epoch[68] Batch [1000]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.077455,	
2017-07-13 06:32:56,418 Epoch[68] Batch [1010]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.077440,	
2017-07-13 06:33:04,708 Epoch[68] Batch [1020]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.077407,	
2017-07-13 06:33:12,520 Epoch[68] Batch [1030]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.077326,	
2017-07-13 06:33:20,328 Epoch[68] Batch [1040]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.077402,	
2017-07-13 06:33:28,455 Epoch[68] Batch [1050]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.077328,	
2017-07-13 06:33:36,460 Epoch[68] Batch [1060]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.077331,	
2017-07-13 06:33:44,573 Epoch[68] Batch [1070]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.077289,	
2017-07-13 06:33:52,792 Epoch[68] Batch [1080]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.077311,	
2017-07-13 06:34:00,837 Epoch[68] Batch [1090]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.077379,	
2017-07-13 06:34:08,811 Epoch[68] Batch [1100]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.077359,	
2017-07-13 06:34:16,772 Epoch[68] Batch [1110]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.077352,	
2017-07-13 06:34:24,980 Epoch[68] Batch [1120]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.077338,	
2017-07-13 06:34:33,017 Epoch[68] Batch [1130]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.077326,	
2017-07-13 06:34:41,074 Epoch[68] Batch [1140]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.077333,	
2017-07-13 06:34:49,492 Epoch[68] Batch [1150]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.077349,	
2017-07-13 06:34:57,753 Epoch[68] Batch [1160]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.077442,	
2017-07-13 06:35:06,071 Epoch[68] Batch [1170]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.077510,	
2017-07-13 06:35:14,196 Epoch[68] Batch [1180]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.077595,	
2017-07-13 06:35:22,469 Epoch[68] Batch [1190]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.077597,	
2017-07-13 06:35:30,808 Epoch[68] Batch [1200]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.077611,	
2017-07-13 06:35:39,106 Epoch[68] Batch [1210]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.077635,	
2017-07-13 06:35:47,305 Epoch[68] Batch [1220]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.077608,	
2017-07-13 06:35:55,731 Epoch[68] Batch [1230]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.077636,	
2017-07-13 06:36:04,107 Epoch[68] Batch [1240]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.077643,	
2017-07-13 06:36:12,377 Epoch[68] Batch [1250]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.077648,	
2017-07-13 06:36:20,665 Epoch[68] Batch [1260]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.077645,	
2017-07-13 06:36:28,856 Epoch[68] Batch [1270]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.077540,	
2017-07-13 06:36:37,123 Epoch[68] Batch [1280]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.077524,	
2017-07-13 06:36:45,133 Epoch[68] Batch [1290]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.077558,	
2017-07-13 06:36:54,055 Epoch[68] Batch [1300]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.077584,	
2017-07-13 06:37:02,049 Epoch[68] Batch [1310]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.077641,	
2017-07-13 06:37:10,139 Epoch[68] Batch [1320]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.077647,	
2017-07-13 06:37:18,366 Epoch[68] Batch [1330]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.077627,	
2017-07-13 06:37:26,516 Epoch[68] Batch [1340]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.077675,	
2017-07-13 06:37:34,964 Epoch[68] Batch [1350]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.077707,	
2017-07-13 06:37:43,215 Epoch[68] Batch [1360]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.077670,	
2017-07-13 06:37:51,392 Epoch[68] Batch [1370]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.077696,	
2017-07-13 06:37:59,630 Epoch[68] Batch [1380]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.077675,	
2017-07-13 06:38:07,733 Epoch[68] Batch [1390]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.077688,	
2017-07-13 06:38:15,933 Epoch[68] Batch [1400]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.077713,	
2017-07-13 06:38:24,140 Epoch[68] Batch [1410]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.077767,	
2017-07-13 06:38:32,304 Epoch[68] Batch [1420]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.077763,	
2017-07-13 06:38:40,637 Epoch[68] Batch [1430]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.077819,	
2017-07-13 06:38:48,876 Epoch[68] Batch [1440]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.077831,	
2017-07-13 06:38:57,334 Epoch[68] Batch [1450]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.077817,	
2017-07-13 06:39:05,421 Epoch[68] Batch [1460]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.077820,	
2017-07-13 06:39:13,501 Epoch[68] Batch [1470]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.077850,	
2017-07-13 06:39:21,971 Epoch[68] Batch [1480]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.077857,	
2017-07-13 06:39:26,922 Epoch[68] Train-FCNLogLoss=0.077866
2017-07-13 06:39:26,922 Epoch[68] Time cost=1121.179
2017-07-13 06:39:28,048 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0069.params"
2017-07-13 06:39:31,508 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0069.states"
2017-07-13 06:39:40,853 Epoch[69] Batch [10]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.079180,	
2017-07-13 06:39:49,036 Epoch[69] Batch [20]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.078562,	
2017-07-13 06:39:57,403 Epoch[69] Batch [30]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.078061,	
2017-07-13 06:40:05,621 Epoch[69] Batch [40]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.076813,	
2017-07-13 06:40:14,052 Epoch[69] Batch [50]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.077882,	
2017-07-13 06:40:22,280 Epoch[69] Batch [60]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.078508,	
2017-07-13 06:40:30,691 Epoch[69] Batch [70]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.078974,	
2017-07-13 06:40:38,789 Epoch[69] Batch [80]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.079118,	
2017-07-13 06:40:47,163 Epoch[69] Batch [90]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.079426,	
2017-07-13 06:40:55,566 Epoch[69] Batch [100]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.079836,	
2017-07-13 06:41:03,735 Epoch[69] Batch [110]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.079601,	
2017-07-13 06:41:11,923 Epoch[69] Batch [120]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.079546,	
2017-07-13 06:41:20,077 Epoch[69] Batch [130]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.079492,	
2017-07-13 06:41:28,363 Epoch[69] Batch [140]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.081092,	
2017-07-13 06:41:36,519 Epoch[69] Batch [150]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.081903,	
2017-07-13 06:41:44,787 Epoch[69] Batch [160]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.083001,	
2017-07-13 06:41:53,166 Epoch[69] Batch [170]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.083942,	
2017-07-13 06:42:01,272 Epoch[69] Batch [180]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.084728,	
2017-07-13 06:42:09,750 Epoch[69] Batch [190]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.084600,	
2017-07-13 06:42:17,901 Epoch[69] Batch [200]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.084964,	
2017-07-13 06:42:25,938 Epoch[69] Batch [210]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.084952,	
2017-07-13 06:42:46,179 Epoch[69] Batch [220]	Speed: 1.98 samples/sec	Train-FCNLogLoss=0.085007,	
2017-07-13 06:43:16,092 Epoch[69] Batch [230]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.084761,	
2017-07-13 06:43:43,652 Epoch[69] Batch [240]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.084548,	
2017-07-13 06:44:13,240 Epoch[69] Batch [250]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.084647,	
2017-07-13 06:44:42,292 Epoch[69] Batch [260]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.084662,	
2017-07-13 06:45:14,966 Epoch[69] Batch [270]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.084424,	
2017-07-13 06:45:46,607 Epoch[69] Batch [280]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.084081,	
2017-07-13 06:46:17,694 Epoch[69] Batch [290]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.083559,	
2017-07-13 06:46:47,865 Epoch[69] Batch [300]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.083441,	
2017-07-13 06:47:15,644 Epoch[69] Batch [310]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.083239,	
2017-07-13 06:47:45,581 Epoch[69] Batch [320]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.083404,	
2017-07-13 06:48:15,544 Epoch[69] Batch [330]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.083316,	
2017-07-13 06:48:44,633 Epoch[69] Batch [340]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.083179,	
2017-07-13 06:49:16,755 Epoch[69] Batch [350]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.083285,	
2017-07-13 06:49:44,209 Epoch[69] Batch [360]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.083067,	
2017-07-13 06:50:15,482 Epoch[69] Batch [370]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.082956,	
2017-07-13 06:50:42,447 Epoch[69] Batch [380]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.082935,	
2017-07-13 06:51:10,899 Epoch[69] Batch [390]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.082888,	
2017-07-13 06:51:36,672 Epoch[69] Batch [400]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.082726,	
2017-07-13 06:52:03,194 Epoch[69] Batch [410]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.082628,	
2017-07-13 06:52:20,661 Epoch[69] Batch [420]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.082579,	
2017-07-13 06:52:29,354 Epoch[69] Batch [430]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.082326,	
2017-07-13 06:52:37,505 Epoch[69] Batch [440]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.082197,	
2017-07-13 06:52:45,931 Epoch[69] Batch [450]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.082250,	
2017-07-13 06:52:54,551 Epoch[69] Batch [460]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.082091,	
2017-07-13 06:53:02,713 Epoch[69] Batch [470]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.081956,	
2017-07-13 06:53:11,052 Epoch[69] Batch [480]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.081797,	
2017-07-13 06:53:19,650 Epoch[69] Batch [490]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.081849,	
2017-07-13 06:53:27,891 Epoch[69] Batch [500]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.081650,	
2017-07-13 06:53:36,107 Epoch[69] Batch [510]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.081555,	
2017-07-13 06:53:44,483 Epoch[69] Batch [520]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.081491,	
2017-07-13 06:53:52,853 Epoch[69] Batch [530]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.081666,	
2017-07-13 06:54:01,645 Epoch[69] Batch [540]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.081492,	
2017-07-13 06:54:10,170 Epoch[69] Batch [550]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.081567,	
2017-07-13 06:54:18,894 Epoch[69] Batch [560]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.081773,	
2017-07-13 06:54:27,384 Epoch[69] Batch [570]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.081633,	
2017-07-13 06:54:35,721 Epoch[69] Batch [580]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.081538,	
2017-07-13 06:54:43,882 Epoch[69] Batch [590]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.081373,	
2017-07-13 06:54:52,193 Epoch[69] Batch [600]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.081234,	
2017-07-13 06:55:00,771 Epoch[69] Batch [610]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.081186,	
2017-07-13 06:55:09,316 Epoch[69] Batch [620]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.081121,	
2017-07-13 06:55:17,731 Epoch[69] Batch [630]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.081040,	
2017-07-13 06:55:26,127 Epoch[69] Batch [640]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.080921,	
2017-07-13 06:55:42,180 Epoch[69] Batch [650]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.080777,	
2017-07-13 06:56:10,171 Epoch[69] Batch [660]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.080673,	
2017-07-13 06:56:38,602 Epoch[69] Batch [670]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.080666,	
2017-07-13 06:57:05,206 Epoch[69] Batch [680]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.080536,	
2017-07-13 06:57:32,611 Epoch[69] Batch [690]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.080456,	
2017-07-13 06:57:58,397 Epoch[69] Batch [700]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.080435,	
2017-07-13 06:58:25,159 Epoch[69] Batch [710]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.080362,	
2017-07-13 06:58:52,436 Epoch[69] Batch [720]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.080348,	
2017-07-13 06:59:17,989 Epoch[69] Batch [730]	Speed: 1.57 samples/sec	Train-FCNLogLoss=0.080220,	
2017-07-13 06:59:45,754 Epoch[69] Batch [740]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.080165,	
2017-07-13 07:00:15,479 Epoch[69] Batch [750]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.080080,	
2017-07-13 07:00:42,088 Epoch[69] Batch [760]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.079987,	
2017-07-13 07:01:08,859 Epoch[69] Batch [770]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.080054,	
2017-07-13 07:01:32,998 Epoch[69] Batch [780]	Speed: 1.66 samples/sec	Train-FCNLogLoss=0.079978,	
2017-07-13 07:02:00,600 Epoch[69] Batch [790]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.079819,	
2017-07-13 07:02:24,390 Epoch[69] Batch [800]	Speed: 1.68 samples/sec	Train-FCNLogLoss=0.079729,	
2017-07-13 07:02:50,333 Epoch[69] Batch [810]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.079672,	
2017-07-13 07:03:18,214 Epoch[69] Batch [820]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.079636,	
2017-07-13 07:03:48,263 Epoch[69] Batch [830]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.079633,	
2017-07-13 07:04:15,396 Epoch[69] Batch [840]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.079629,	
2017-07-13 07:04:43,751 Epoch[69] Batch [850]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.079601,	
2017-07-13 07:05:11,801 Epoch[69] Batch [860]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.079682,	
2017-07-13 07:05:40,011 Epoch[69] Batch [870]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.079592,	
2017-07-13 07:06:08,682 Epoch[69] Batch [880]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.079527,	
2017-07-13 07:06:36,240 Epoch[69] Batch [890]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.079536,	
2017-07-13 07:07:05,749 Epoch[69] Batch [900]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.079565,	
2017-07-13 07:07:36,371 Epoch[69] Batch [910]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.079632,	
2017-07-13 07:08:05,285 Epoch[69] Batch [920]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.079553,	
2017-07-13 07:08:31,009 Epoch[69] Batch [930]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.079576,	
2017-07-13 07:08:56,255 Epoch[69] Batch [940]	Speed: 1.58 samples/sec	Train-FCNLogLoss=0.079607,	
2017-07-13 07:09:23,292 Epoch[69] Batch [950]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.079614,	
2017-07-13 07:09:48,355 Epoch[69] Batch [960]	Speed: 1.60 samples/sec	Train-FCNLogLoss=0.079642,	
2017-07-13 07:10:15,778 Epoch[69] Batch [970]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.079652,	
2017-07-13 07:10:41,602 Epoch[69] Batch [980]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.079663,	
2017-07-13 07:11:09,916 Epoch[69] Batch [990]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.079643,	
2017-07-13 07:11:36,485 Epoch[69] Batch [1000]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.079652,	
2017-07-13 07:12:03,949 Epoch[69] Batch [1010]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.079577,	
2017-07-13 07:12:31,686 Epoch[69] Batch [1020]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.079609,	
2017-07-13 07:12:57,284 Epoch[69] Batch [1030]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.079620,	
2017-07-13 07:13:25,943 Epoch[69] Batch [1040]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.079670,	
2017-07-13 07:13:55,787 Epoch[69] Batch [1050]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.079640,	
2017-07-13 07:14:22,611 Epoch[69] Batch [1060]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.079660,	
2017-07-13 07:14:52,350 Epoch[69] Batch [1070]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.079648,	
2017-07-13 07:15:20,805 Epoch[69] Batch [1080]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.079618,	
2017-07-13 07:15:48,896 Epoch[69] Batch [1090]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.079605,	
2017-07-13 07:16:17,157 Epoch[69] Batch [1100]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.079598,	
2017-07-13 07:16:45,895 Epoch[69] Batch [1110]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.079532,	
2017-07-13 07:17:16,152 Epoch[69] Batch [1120]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.079398,	
2017-07-13 07:17:42,067 Epoch[69] Batch [1130]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.079463,	
2017-07-13 07:18:12,639 Epoch[69] Batch [1140]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.079461,	
2017-07-13 07:18:42,801 Epoch[69] Batch [1150]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.079350,	
2017-07-13 07:19:11,275 Epoch[69] Batch [1160]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.079287,	
2017-07-13 07:19:37,860 Epoch[69] Batch [1170]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.079234,	
2017-07-13 07:20:05,648 Epoch[69] Batch [1180]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.079201,	
2017-07-13 07:20:32,588 Epoch[69] Batch [1190]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.079132,	
2017-07-13 07:21:00,277 Epoch[69] Batch [1200]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.079165,	
2017-07-13 07:21:26,345 Epoch[69] Batch [1210]	Speed: 1.53 samples/sec	Train-FCNLogLoss=0.079156,	
2017-07-13 07:21:52,383 Epoch[69] Batch [1220]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.079084,	
2017-07-13 07:22:18,733 Epoch[69] Batch [1230]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.079063,	
2017-07-13 07:22:45,314 Epoch[69] Batch [1240]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.079025,	
2017-07-13 07:23:12,459 Epoch[69] Batch [1250]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.078949,	
2017-07-13 07:23:40,716 Epoch[69] Batch [1260]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.078924,	
2017-07-13 07:24:07,503 Epoch[69] Batch [1270]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.078930,	
2017-07-13 07:24:35,085 Epoch[69] Batch [1280]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.078869,	
2017-07-13 07:25:01,589 Epoch[69] Batch [1290]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.078863,	
2017-07-13 07:25:30,509 Epoch[69] Batch [1300]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.079059,	
2017-07-13 07:25:55,671 Epoch[69] Batch [1310]	Speed: 1.59 samples/sec	Train-FCNLogLoss=0.079207,	
2017-07-13 07:26:21,448 Epoch[69] Batch [1320]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.079376,	
2017-07-13 07:26:48,741 Epoch[69] Batch [1330]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.079519,	
2017-07-13 07:27:14,729 Epoch[69] Batch [1340]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.080003,	
2017-07-13 07:27:42,290 Epoch[69] Batch [1350]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.080329,	
2017-07-13 07:28:08,969 Epoch[69] Batch [1360]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.080728,	
2017-07-13 07:28:36,539 Epoch[69] Batch [1370]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.080975,	
2017-07-13 07:29:01,690 Epoch[69] Batch [1380]	Speed: 1.59 samples/sec	Train-FCNLogLoss=0.081191,	
2017-07-13 07:29:29,773 Epoch[69] Batch [1390]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.081334,	
2017-07-13 07:29:56,215 Epoch[69] Batch [1400]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.081438,	
2017-07-13 07:30:26,110 Epoch[69] Batch [1410]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.081494,	
2017-07-13 07:30:52,425 Epoch[69] Batch [1420]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.081594,	
2017-07-13 07:31:18,960 Epoch[69] Batch [1430]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.081653,	
2017-07-13 07:31:45,272 Epoch[69] Batch [1440]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.081616,	
2017-07-13 07:32:11,653 Epoch[69] Batch [1450]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.081729,	
2017-07-13 07:32:39,251 Epoch[69] Batch [1460]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.081837,	
2017-07-13 07:33:06,152 Epoch[69] Batch [1470]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.081867,	
2017-07-13 07:33:30,471 Epoch[69] Batch [1480]	Speed: 1.64 samples/sec	Train-FCNLogLoss=0.081868,	
2017-07-13 07:33:47,644 Epoch[69] Train-FCNLogLoss=0.082005
2017-07-13 07:33:47,644 Epoch[69] Time cost=3256.136
2017-07-13 07:33:54,226 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0070.params"
2017-07-13 07:34:18,037 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0070.states"
2017-07-13 07:34:49,621 Epoch[70] Batch [10]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.132720,	
2017-07-13 07:35:16,825 Epoch[70] Batch [20]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.120228,	
2017-07-13 07:35:44,639 Epoch[70] Batch [30]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.115593,	
2017-07-13 07:36:13,158 Epoch[70] Batch [40]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.109556,	
2017-07-13 07:36:40,723 Epoch[70] Batch [50]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.106175,	
2017-07-13 07:37:07,647 Epoch[70] Batch [60]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.103871,	
2017-07-13 07:37:33,947 Epoch[70] Batch [70]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.103741,	
2017-07-13 07:37:59,616 Epoch[70] Batch [80]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.101242,	
2017-07-13 07:38:26,526 Epoch[70] Batch [90]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.098941,	
2017-07-13 07:38:52,650 Epoch[70] Batch [100]	Speed: 1.53 samples/sec	Train-FCNLogLoss=0.098000,	
2017-07-13 07:39:18,247 Epoch[70] Batch [110]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.096593,	
2017-07-13 07:39:46,456 Epoch[70] Batch [120]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.095135,	
2017-07-13 07:40:15,295 Epoch[70] Batch [130]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.094783,	
2017-07-13 07:40:42,651 Epoch[70] Batch [140]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.093971,	
2017-07-13 07:41:11,230 Epoch[70] Batch [150]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.093774,	
2017-07-13 07:41:41,397 Epoch[70] Batch [160]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.093517,	
2017-07-13 07:42:09,403 Epoch[70] Batch [170]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.093089,	
2017-07-13 07:42:38,450 Epoch[70] Batch [180]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.092210,	
2017-07-13 07:43:07,386 Epoch[70] Batch [190]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.091216,	
2017-07-13 07:43:36,574 Epoch[70] Batch [200]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.090467,	
2017-07-13 07:44:02,076 Epoch[70] Batch [210]	Speed: 1.57 samples/sec	Train-FCNLogLoss=0.089638,	
2017-07-13 07:44:26,360 Epoch[70] Batch [220]	Speed: 1.65 samples/sec	Train-FCNLogLoss=0.088990,	
2017-07-13 07:44:48,820 Epoch[70] Batch [230]	Speed: 1.78 samples/sec	Train-FCNLogLoss=0.088568,	
2017-07-13 07:45:12,043 Epoch[70] Batch [240]	Speed: 1.72 samples/sec	Train-FCNLogLoss=0.088418,	
2017-07-13 07:45:36,804 Epoch[70] Batch [250]	Speed: 1.62 samples/sec	Train-FCNLogLoss=0.087568,	
2017-07-13 07:46:02,595 Epoch[70] Batch [260]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.087071,	
2017-07-13 07:46:28,636 Epoch[70] Batch [270]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.086669,	
2017-07-13 07:46:55,657 Epoch[70] Batch [280]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.086386,	
2017-07-13 07:47:18,523 Epoch[70] Batch [290]	Speed: 1.75 samples/sec	Train-FCNLogLoss=0.086335,	
2017-07-13 07:47:42,673 Epoch[70] Batch [300]	Speed: 1.66 samples/sec	Train-FCNLogLoss=0.086157,	
2017-07-13 07:48:08,374 Epoch[70] Batch [310]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.086104,	
2017-07-13 07:48:33,791 Epoch[70] Batch [320]	Speed: 1.57 samples/sec	Train-FCNLogLoss=0.086020,	
2017-07-13 07:49:00,324 Epoch[70] Batch [330]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.085858,	
2017-07-13 07:49:26,687 Epoch[70] Batch [340]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.085872,	
2017-07-13 07:49:51,656 Epoch[70] Batch [350]	Speed: 1.60 samples/sec	Train-FCNLogLoss=0.085716,	
2017-07-13 07:50:17,244 Epoch[70] Batch [360]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.085575,	
2017-07-13 07:50:40,727 Epoch[70] Batch [370]	Speed: 1.70 samples/sec	Train-FCNLogLoss=0.085508,	
2017-07-13 07:51:05,689 Epoch[70] Batch [380]	Speed: 1.60 samples/sec	Train-FCNLogLoss=0.085612,	
2017-07-13 07:51:32,952 Epoch[70] Batch [390]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.085408,	
2017-07-13 07:51:57,206 Epoch[70] Batch [400]	Speed: 1.65 samples/sec	Train-FCNLogLoss=0.085260,	
2017-07-13 07:52:27,210 Epoch[70] Batch [410]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.085078,	
2017-07-13 07:52:56,405 Epoch[70] Batch [420]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.085046,	
2017-07-13 07:53:23,923 Epoch[70] Batch [430]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.085018,	
2017-07-13 07:53:53,896 Epoch[70] Batch [440]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.084870,	
2017-07-13 07:54:23,006 Epoch[70] Batch [450]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.084897,	
2017-07-13 07:54:53,229 Epoch[70] Batch [460]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.084777,	
2017-07-13 07:55:19,322 Epoch[70] Batch [470]	Speed: 1.53 samples/sec	Train-FCNLogLoss=0.084482,	
2017-07-13 07:55:50,793 Epoch[70] Batch [480]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.084267,	
2017-07-13 07:56:20,213 Epoch[70] Batch [490]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.084235,	
2017-07-13 07:56:49,270 Epoch[70] Batch [500]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.084218,	
2017-07-13 07:57:15,956 Epoch[70] Batch [510]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.084085,	
2017-07-13 07:57:43,802 Epoch[70] Batch [520]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.083973,	
2017-07-13 07:58:09,858 Epoch[70] Batch [530]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.083994,	
2017-07-13 07:58:35,847 Epoch[70] Batch [540]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.083774,	
2017-07-13 07:59:05,403 Epoch[70] Batch [550]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.083656,	
2017-07-13 07:59:34,536 Epoch[70] Batch [560]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.083580,	
2017-07-13 07:59:58,811 Epoch[70] Batch [570]	Speed: 1.65 samples/sec	Train-FCNLogLoss=0.083458,	
2017-07-13 08:00:28,256 Epoch[70] Batch [580]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.083749,	
2017-07-13 08:00:54,634 Epoch[70] Batch [590]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.083866,	
2017-07-13 08:01:18,927 Epoch[70] Batch [600]	Speed: 1.65 samples/sec	Train-FCNLogLoss=0.084055,	
2017-07-13 08:01:49,409 Epoch[70] Batch [610]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.084870,	
2017-07-13 08:02:17,780 Epoch[70] Batch [620]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.086370,	
2017-07-13 08:02:46,939 Epoch[70] Batch [630]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.087203,	
2017-07-13 08:03:14,117 Epoch[70] Batch [640]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.087737,	
2017-07-13 08:03:42,901 Epoch[70] Batch [650]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.088726,	
2017-07-13 08:04:13,089 Epoch[70] Batch [660]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.089479,	
2017-07-13 08:04:40,777 Epoch[70] Batch [670]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.089951,	
2017-07-13 08:05:05,977 Epoch[70] Batch [680]	Speed: 1.59 samples/sec	Train-FCNLogLoss=0.090282,	
2017-07-13 08:05:34,216 Epoch[70] Batch [690]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.090327,	
2017-07-13 08:06:01,374 Epoch[70] Batch [700]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.090577,	
2017-07-13 08:06:27,441 Epoch[70] Batch [710]	Speed: 1.53 samples/sec	Train-FCNLogLoss=0.090724,	
2017-07-13 08:06:53,899 Epoch[70] Batch [720]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.090757,	
2017-07-13 08:07:19,818 Epoch[70] Batch [730]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.090889,	
2017-07-13 08:07:48,752 Epoch[70] Batch [740]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.090907,	
2017-07-13 08:08:18,258 Epoch[70] Batch [750]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.094246,	
2017-07-13 08:08:47,542 Epoch[70] Batch [760]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.099689,	
2017-07-13 08:09:15,995 Epoch[70] Batch [770]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.103858,	
2017-07-13 08:09:44,773 Epoch[70] Batch [780]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.106818,	
2017-07-13 08:10:12,091 Epoch[70] Batch [790]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.108807,	
2017-07-13 08:10:40,796 Epoch[70] Batch [800]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.109975,	
2017-07-13 08:11:06,227 Epoch[70] Batch [810]	Speed: 1.57 samples/sec	Train-FCNLogLoss=0.110762,	
2017-07-13 08:11:35,317 Epoch[70] Batch [820]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.111864,	
2017-07-13 08:12:02,055 Epoch[70] Batch [830]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.112599,	
2017-07-13 08:12:30,697 Epoch[70] Batch [840]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.114941,	
2017-07-13 08:12:58,515 Epoch[70] Batch [850]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.116336,	
2017-07-13 08:13:26,555 Epoch[70] Batch [860]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.118391,	
2017-07-13 08:13:42,758 Epoch[70] Batch [870]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.119766,	
2017-07-13 08:13:51,026 Epoch[70] Batch [880]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.120722,	
2017-07-13 08:13:59,300 Epoch[70] Batch [890]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.121346,	
2017-07-13 08:14:07,600 Epoch[70] Batch [900]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.122424,	
2017-07-13 08:14:15,750 Epoch[70] Batch [910]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.123653,	
2017-07-13 08:14:24,006 Epoch[70] Batch [920]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.124755,	
2017-07-13 08:14:32,307 Epoch[70] Batch [930]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.125620,	
2017-07-13 08:14:40,470 Epoch[70] Batch [940]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.126418,	
2017-07-13 08:14:48,675 Epoch[70] Batch [950]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.127078,	
2017-07-13 08:14:56,845 Epoch[70] Batch [960]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.128120,	
2017-07-13 08:15:05,017 Epoch[70] Batch [970]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.128676,	
2017-07-13 08:15:13,401 Epoch[70] Batch [980]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.128981,	
2017-07-13 08:15:21,743 Epoch[70] Batch [990]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.129336,	
2017-07-13 08:15:30,021 Epoch[70] Batch [1000]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.130169,	
2017-07-13 08:15:38,229 Epoch[70] Batch [1010]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.131787,	
2017-07-13 08:15:46,295 Epoch[70] Batch [1020]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.132634,	
2017-07-13 08:15:54,630 Epoch[70] Batch [1030]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.132983,	
2017-07-13 08:16:03,007 Epoch[70] Batch [1040]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.134428,	
2017-07-13 08:16:11,330 Epoch[70] Batch [1050]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.135457,	
2017-07-13 08:16:19,531 Epoch[70] Batch [1060]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.138534,	
2017-07-13 08:16:27,724 Epoch[70] Batch [1070]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.139105,	
2017-07-13 08:16:35,741 Epoch[70] Batch [1080]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.139808,	
2017-07-13 08:16:43,969 Epoch[70] Batch [1090]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.140463,	
2017-07-13 08:16:52,147 Epoch[70] Batch [1100]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.140821,	
2017-07-13 08:17:00,592 Epoch[70] Batch [1110]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.141196,	
2017-07-13 08:17:08,866 Epoch[70] Batch [1120]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.141563,	
2017-07-13 08:17:17,338 Epoch[70] Batch [1130]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.141778,	
2017-07-13 08:17:25,722 Epoch[70] Batch [1140]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.141859,	
2017-07-13 08:17:34,025 Epoch[70] Batch [1150]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.141928,	
2017-07-13 08:17:42,454 Epoch[70] Batch [1160]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.141933,	
2017-07-13 08:17:50,881 Epoch[70] Batch [1170]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.141861,	
2017-07-13 08:17:59,059 Epoch[70] Batch [1180]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.141914,	
2017-07-13 08:18:07,238 Epoch[70] Batch [1190]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.141880,	
2017-07-13 08:18:15,442 Epoch[70] Batch [1200]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.141855,	
2017-07-13 08:18:23,853 Epoch[70] Batch [1210]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.141773,	
2017-07-13 08:18:32,204 Epoch[70] Batch [1220]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.141816,	
2017-07-13 08:18:40,503 Epoch[70] Batch [1230]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.141973,	
2017-07-13 08:18:48,864 Epoch[70] Batch [1240]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.142118,	
2017-07-13 08:18:57,202 Epoch[70] Batch [1250]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.142106,	
2017-07-13 08:19:05,479 Epoch[70] Batch [1260]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.142014,	
2017-07-13 08:19:13,664 Epoch[70] Batch [1270]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.141888,	
2017-07-13 08:19:21,754 Epoch[70] Batch [1280]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.141871,	
2017-07-13 08:19:29,974 Epoch[70] Batch [1290]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.141812,	
2017-07-13 08:19:38,378 Epoch[70] Batch [1300]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.142000,	
2017-07-13 08:19:46,592 Epoch[70] Batch [1310]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.141991,	
2017-07-13 08:19:55,076 Epoch[70] Batch [1320]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.141703,	
2017-07-13 08:20:03,638 Epoch[70] Batch [1330]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.141500,	
2017-07-13 08:20:12,053 Epoch[70] Batch [1340]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.141262,	
2017-07-13 08:20:20,216 Epoch[70] Batch [1350]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.141036,	
2017-07-13 08:20:28,569 Epoch[70] Batch [1360]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.140863,	
2017-07-13 08:20:37,020 Epoch[70] Batch [1370]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.140845,	
2017-07-13 08:20:45,377 Epoch[70] Batch [1380]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.140824,	
2017-07-13 08:20:53,584 Epoch[70] Batch [1390]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.140639,	
2017-07-13 08:21:13,906 Epoch[70] Batch [1400]	Speed: 1.97 samples/sec	Train-FCNLogLoss=0.140567,	
2017-07-13 08:21:44,835 Epoch[70] Batch [1410]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.140370,	
2017-07-13 08:22:15,259 Epoch[70] Batch [1420]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.140230,	
2017-07-13 08:22:44,158 Epoch[70] Batch [1430]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.140032,	
2017-07-13 08:23:13,936 Epoch[70] Batch [1440]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.139928,	
2017-07-13 08:23:43,192 Epoch[70] Batch [1450]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.139761,	
2017-07-13 08:24:12,326 Epoch[70] Batch [1460]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.140087,	
2017-07-13 08:24:40,474 Epoch[70] Batch [1470]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.139989,	
2017-07-13 08:25:09,444 Epoch[70] Batch [1480]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.139858,	
2017-07-13 08:25:29,148 Epoch[70] Train-FCNLogLoss=0.139768
2017-07-13 08:25:29,148 Epoch[70] Time cost=3071.111
2017-07-13 08:25:35,848 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0071.params"
2017-07-13 08:25:57,525 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0071.states"
2017-07-13 08:26:29,921 Epoch[71] Batch [10]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.094861,	
2017-07-13 08:26:57,592 Epoch[71] Batch [20]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.108141,	
2017-07-13 08:27:27,193 Epoch[71] Batch [30]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.113380,	
2017-07-13 08:27:55,716 Epoch[71] Batch [40]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.115715,	
2017-07-13 08:28:25,753 Epoch[71] Batch [50]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.112432,	
2017-07-13 08:28:52,999 Epoch[71] Batch [60]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.111126,	
2017-07-13 08:29:20,563 Epoch[71] Batch [70]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.110309,	
2017-07-13 08:29:48,140 Epoch[71] Batch [80]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.109489,	
2017-07-13 08:30:17,010 Epoch[71] Batch [90]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.109525,	
2017-07-13 08:30:41,516 Epoch[71] Batch [100]	Speed: 1.63 samples/sec	Train-FCNLogLoss=0.111937,	
2017-07-13 08:31:11,543 Epoch[71] Batch [110]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.112269,	
2017-07-13 08:31:38,751 Epoch[71] Batch [120]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.112311,	
2017-07-13 08:32:07,134 Epoch[71] Batch [130]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.111848,	
2017-07-13 08:32:36,713 Epoch[71] Batch [140]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.111950,	
2017-07-13 08:33:07,245 Epoch[71] Batch [150]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.111465,	
2017-07-13 08:33:35,786 Epoch[71] Batch [160]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.109915,	
2017-07-13 08:34:01,354 Epoch[71] Batch [170]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.109317,	
2017-07-13 08:34:31,315 Epoch[71] Batch [180]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.108890,	
2017-07-13 08:34:55,069 Epoch[71] Batch [190]	Speed: 1.68 samples/sec	Train-FCNLogLoss=0.108314,	
2017-07-13 08:35:23,834 Epoch[71] Batch [200]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.110453,	
2017-07-13 08:35:51,961 Epoch[71] Batch [210]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.111709,	
2017-07-13 08:36:17,987 Epoch[71] Batch [220]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.112514,	
2017-07-13 08:36:46,224 Epoch[71] Batch [230]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.112363,	
2017-07-13 08:37:12,997 Epoch[71] Batch [240]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.113259,	
2017-07-13 08:37:39,894 Epoch[71] Batch [250]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.113265,	
2017-07-13 08:38:07,343 Epoch[71] Batch [260]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.112953,	
2017-07-13 08:38:33,866 Epoch[71] Batch [270]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.112623,	
2017-07-13 08:38:59,108 Epoch[71] Batch [280]	Speed: 1.58 samples/sec	Train-FCNLogLoss=0.113694,	
2017-07-13 08:39:27,162 Epoch[71] Batch [290]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.114838,	
2017-07-13 08:39:52,196 Epoch[71] Batch [300]	Speed: 1.60 samples/sec	Train-FCNLogLoss=0.115408,	
2017-07-13 08:40:18,795 Epoch[71] Batch [310]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.115921,	
2017-07-13 08:40:45,224 Epoch[71] Batch [320]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.116294,	
2017-07-13 08:41:13,345 Epoch[71] Batch [330]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.115788,	
2017-07-13 08:41:40,246 Epoch[71] Batch [340]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.115818,	
2017-07-13 08:42:07,439 Epoch[71] Batch [350]	Speed: 1.47 samples/sec	Train-FCNLogLoss=0.115705,	
2017-07-13 08:42:36,791 Epoch[71] Batch [360]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.115261,	
2017-07-13 08:43:04,229 Epoch[71] Batch [370]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.114997,	
2017-07-13 08:43:32,219 Epoch[71] Batch [380]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.114919,	
2017-07-13 08:44:02,268 Epoch[71] Batch [390]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.114524,	
2017-07-13 08:44:30,162 Epoch[71] Batch [400]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.114554,	
2017-07-13 08:45:00,115 Epoch[71] Batch [410]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.115485,	
2017-07-13 08:45:28,994 Epoch[71] Batch [420]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.115865,	
2017-07-13 08:45:57,983 Epoch[71] Batch [430]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.115651,	
2017-07-13 08:46:28,794 Epoch[71] Batch [440]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.115553,	
2017-07-13 08:46:56,857 Epoch[71] Batch [450]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.115481,	
2017-07-13 08:47:26,032 Epoch[71] Batch [460]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.115024,	
2017-07-13 08:47:54,938 Epoch[71] Batch [470]	Speed: 1.38 samples/sec	Train-FCNLogLoss=0.114685,	
2017-07-13 08:48:24,941 Epoch[71] Batch [480]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.114354,	
2017-07-13 08:48:55,544 Epoch[71] Batch [490]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.114073,	
2017-07-13 08:49:23,967 Epoch[71] Batch [500]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.113690,	
2017-07-13 08:49:55,330 Epoch[71] Batch [510]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.113359,	
2017-07-13 08:50:24,043 Epoch[71] Batch [520]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.112952,	
2017-07-13 08:50:45,815 Epoch[71] Batch [530]	Speed: 1.84 samples/sec	Train-FCNLogLoss=0.112636,	
2017-07-13 08:50:54,517 Epoch[71] Batch [540]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.112320,	
2017-07-13 08:51:03,054 Epoch[71] Batch [550]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.111993,	
2017-07-13 08:51:11,479 Epoch[71] Batch [560]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.111657,	
2017-07-13 08:51:19,867 Epoch[71] Batch [570]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.111402,	
2017-07-13 08:51:28,648 Epoch[71] Batch [580]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.111038,	
2017-07-13 08:51:37,439 Epoch[71] Batch [590]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.110862,	
2017-07-13 08:51:46,101 Epoch[71] Batch [600]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.110500,	
2017-07-13 08:51:54,838 Epoch[71] Batch [610]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.110276,	
2017-07-13 08:52:03,447 Epoch[71] Batch [620]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.110065,	
2017-07-13 08:52:12,120 Epoch[71] Batch [630]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.109735,	
2017-07-13 08:52:20,908 Epoch[71] Batch [640]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.109566,	
2017-07-13 08:52:29,719 Epoch[71] Batch [650]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.109411,	
2017-07-13 08:52:38,623 Epoch[71] Batch [660]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.109160,	
2017-07-13 08:52:47,270 Epoch[71] Batch [670]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.109211,	
2017-07-13 08:52:55,868 Epoch[71] Batch [680]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.110318,	
2017-07-13 08:53:04,526 Epoch[71] Batch [690]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.110908,	
2017-07-13 08:53:13,186 Epoch[71] Batch [700]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.111107,	
2017-07-13 08:53:21,638 Epoch[71] Batch [710]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.111304,	
2017-07-13 08:53:30,027 Epoch[71] Batch [720]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.111236,	
2017-07-13 08:53:38,714 Epoch[71] Batch [730]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.111347,	
2017-07-13 08:53:47,465 Epoch[71] Batch [740]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.113892,	
2017-07-13 08:53:56,294 Epoch[71] Batch [750]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.114514,	
2017-07-13 08:54:04,916 Epoch[71] Batch [760]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.114941,	
2017-07-13 08:54:13,787 Epoch[71] Batch [770]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.115380,	
2017-07-13 08:54:22,251 Epoch[71] Batch [780]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.115690,	
2017-07-13 08:54:30,892 Epoch[71] Batch [790]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.115864,	
2017-07-13 08:54:39,258 Epoch[71] Batch [800]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.115850,	
2017-07-13 08:54:47,951 Epoch[71] Batch [810]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.115766,	
2017-07-13 08:54:56,595 Epoch[71] Batch [820]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.115572,	
2017-07-13 08:55:05,312 Epoch[71] Batch [830]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.115662,	
2017-07-13 08:55:14,004 Epoch[71] Batch [840]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.115707,	
2017-07-13 08:55:22,374 Epoch[71] Batch [850]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.115646,	
2017-07-13 08:55:31,002 Epoch[71] Batch [860]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.115649,	
2017-07-13 08:55:39,883 Epoch[71] Batch [870]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.115504,	
2017-07-13 08:55:48,527 Epoch[71] Batch [880]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.115210,	
2017-07-13 08:55:57,075 Epoch[71] Batch [890]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.115005,	
2017-07-13 08:56:05,688 Epoch[71] Batch [900]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.114791,	
2017-07-13 08:56:14,323 Epoch[71] Batch [910]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.114610,	
2017-07-13 08:56:22,889 Epoch[71] Batch [920]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.114513,	
2017-07-13 08:56:31,721 Epoch[71] Batch [930]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.114278,	
2017-07-13 08:56:40,177 Epoch[71] Batch [940]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.114041,	
2017-07-13 08:56:48,870 Epoch[71] Batch [950]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.113791,	
2017-07-13 08:56:57,675 Epoch[71] Batch [960]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.113786,	
2017-07-13 08:57:06,551 Epoch[71] Batch [970]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.113731,	
2017-07-13 08:57:15,145 Epoch[71] Batch [980]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.113740,	
2017-07-13 08:57:24,004 Epoch[71] Batch [990]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.113848,	
2017-07-13 08:57:32,652 Epoch[71] Batch [1000]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.113630,	
2017-07-13 08:57:41,450 Epoch[71] Batch [1010]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.113704,	
2017-07-13 08:57:50,397 Epoch[71] Batch [1020]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.113658,	
2017-07-13 08:57:59,305 Epoch[71] Batch [1030]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.113734,	
2017-07-13 08:58:08,123 Epoch[71] Batch [1040]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.113569,	
2017-07-13 08:58:16,942 Epoch[71] Batch [1050]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.113534,	
2017-07-13 08:58:25,420 Epoch[71] Batch [1060]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.113431,	
2017-07-13 08:58:34,041 Epoch[71] Batch [1070]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.113250,	
2017-07-13 08:58:42,694 Epoch[71] Batch [1080]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.113186,	
2017-07-13 08:58:51,548 Epoch[71] Batch [1090]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.113059,	
2017-07-13 08:59:00,168 Epoch[71] Batch [1100]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.112872,	
2017-07-13 08:59:08,974 Epoch[71] Batch [1110]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.112728,	
2017-07-13 08:59:17,955 Epoch[71] Batch [1120]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.112633,	
2017-07-13 08:59:33,095 Epoch[71] Batch [1130]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.112611,	
2017-07-13 09:00:01,756 Epoch[71] Batch [1140]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.112570,	
2017-07-13 09:00:33,393 Epoch[71] Batch [1150]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.112481,	
2017-07-13 09:01:03,210 Epoch[71] Batch [1160]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.112303,	
2017-07-13 09:01:31,625 Epoch[71] Batch [1170]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.112170,	
2017-07-13 09:01:58,584 Epoch[71] Batch [1180]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.112005,	
2017-07-13 09:02:30,299 Epoch[71] Batch [1190]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.111893,	
2017-07-13 09:03:00,601 Epoch[71] Batch [1200]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.111669,	
2017-07-13 09:03:32,943 Epoch[71] Batch [1210]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.111672,	
2017-07-13 09:04:03,613 Epoch[71] Batch [1220]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.111572,	
2017-07-13 09:04:35,025 Epoch[71] Batch [1230]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.111500,	
2017-07-13 09:05:06,442 Epoch[71] Batch [1240]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.111682,	
2017-07-13 09:05:39,607 Epoch[71] Batch [1250]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.111631,	
2017-07-13 09:06:07,915 Epoch[71] Batch [1260]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.111694,	
2017-07-13 09:06:38,513 Epoch[71] Batch [1270]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.111663,	
2017-07-13 09:07:09,540 Epoch[71] Batch [1280]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.111562,	
2017-07-13 09:07:41,507 Epoch[71] Batch [1290]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.111556,	
2017-07-13 09:08:12,059 Epoch[71] Batch [1300]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.111416,	
2017-07-13 09:08:44,733 Epoch[71] Batch [1310]	Speed: 1.22 samples/sec	Train-FCNLogLoss=0.111408,	
2017-07-13 09:09:16,931 Epoch[71] Batch [1320]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.111222,	
2017-07-13 09:09:47,653 Epoch[71] Batch [1330]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.111099,	
2017-07-13 09:10:15,427 Epoch[71] Batch [1340]	Speed: 1.44 samples/sec	Train-FCNLogLoss=0.111076,	
2017-07-13 09:10:47,831 Epoch[71] Batch [1350]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.110861,	
2017-07-13 09:11:16,170 Epoch[71] Batch [1360]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.110917,	
2017-07-13 09:11:48,431 Epoch[71] Batch [1370]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.111041,	
2017-07-13 09:12:16,497 Epoch[71] Batch [1380]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.111147,	
2017-07-13 09:12:44,750 Epoch[71] Batch [1390]	Speed: 1.42 samples/sec	Train-FCNLogLoss=0.111184,	
2017-07-13 09:13:13,305 Epoch[71] Batch [1400]	Speed: 1.40 samples/sec	Train-FCNLogLoss=0.111221,	
2017-07-13 09:13:44,986 Epoch[71] Batch [1410]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.111179,	
2017-07-13 09:14:14,975 Epoch[71] Batch [1420]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.110989,	
2017-07-13 09:14:45,663 Epoch[71] Batch [1430]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.110898,	
2017-07-13 09:15:12,311 Epoch[71] Batch [1440]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.110963,	
2017-07-13 09:15:44,114 Epoch[71] Batch [1450]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.110951,	
2017-07-13 09:16:11,573 Epoch[71] Batch [1460]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.110856,	
2017-07-13 09:16:42,911 Epoch[71] Batch [1470]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.110720,	
2017-07-13 09:17:10,354 Epoch[71] Batch [1480]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.110634,	
2017-07-13 09:17:29,632 Epoch[71] Train-FCNLogLoss=0.110600
2017-07-13 09:17:29,632 Epoch[71] Time cost=3092.107
2017-07-13 09:17:36,768 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0072.params"
2017-07-13 09:18:01,708 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0072.states"
2017-07-13 09:18:35,838 Epoch[72] Batch [10]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.094114,	
2017-07-13 09:19:06,945 Epoch[72] Batch [20]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.092151,	
2017-07-13 09:19:37,565 Epoch[72] Batch [30]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.094127,	
2017-07-13 09:20:11,610 Epoch[72] Batch [40]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.093579,	
2017-07-13 09:20:43,989 Epoch[72] Batch [50]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.094636,	
2017-07-13 09:21:15,738 Epoch[72] Batch [60]	Speed: 1.26 samples/sec	Train-FCNLogLoss=0.093138,	
2017-07-13 09:21:44,980 Epoch[72] Batch [70]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.092601,	
2017-07-13 09:22:15,358 Epoch[72] Batch [80]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.093501,	
2017-07-13 09:22:46,284 Epoch[72] Batch [90]	Speed: 1.29 samples/sec	Train-FCNLogLoss=0.093283,	
2017-07-13 09:23:15,901 Epoch[72] Batch [100]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.092134,	
2017-07-13 09:23:46,175 Epoch[72] Batch [110]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.091919,	
2017-07-13 09:24:16,989 Epoch[72] Batch [120]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.092525,	
2017-07-13 09:24:49,243 Epoch[72] Batch [130]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.094061,	
2017-07-13 09:25:19,279 Epoch[72] Batch [140]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.095630,	
2017-07-13 09:25:48,971 Epoch[72] Batch [150]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.095790,	
2017-07-13 09:26:17,403 Epoch[72] Batch [160]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.095316,	
2017-07-13 09:26:47,766 Epoch[72] Batch [170]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.095511,	
2017-07-13 09:27:13,798 Epoch[72] Batch [180]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.096065,	
2017-07-13 09:27:40,133 Epoch[72] Batch [190]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.095691,	
2017-07-13 09:28:06,579 Epoch[72] Batch [200]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.095355,	
2017-07-13 09:28:33,895 Epoch[72] Batch [210]	Speed: 1.46 samples/sec	Train-FCNLogLoss=0.096165,	
2017-07-13 09:29:01,012 Epoch[72] Batch [220]	Speed: 1.48 samples/sec	Train-FCNLogLoss=0.096455,	
2017-07-13 09:29:30,220 Epoch[72] Batch [230]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.097174,	
2017-07-13 09:29:58,101 Epoch[72] Batch [240]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.097883,	
2017-07-13 09:30:25,719 Epoch[72] Batch [250]	Speed: 1.45 samples/sec	Train-FCNLogLoss=0.098739,	
2017-07-13 09:30:51,928 Epoch[72] Batch [260]	Speed: 1.53 samples/sec	Train-FCNLogLoss=0.099284,	
2017-07-13 09:31:17,095 Epoch[72] Batch [270]	Speed: 1.59 samples/sec	Train-FCNLogLoss=0.098971,	
2017-07-13 09:31:45,042 Epoch[72] Batch [280]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.098545,	
2017-07-13 09:32:11,617 Epoch[72] Batch [290]	Speed: 1.51 samples/sec	Train-FCNLogLoss=0.098236,	
2017-07-13 09:32:37,378 Epoch[72] Batch [300]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.097959,	
2017-07-13 09:33:05,271 Epoch[72] Batch [310]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.097572,	
2017-07-13 09:33:31,598 Epoch[72] Batch [320]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.097261,	
2017-07-13 09:34:02,171 Epoch[72] Batch [330]	Speed: 1.31 samples/sec	Train-FCNLogLoss=0.097004,	
2017-07-13 09:34:30,096 Epoch[72] Batch [340]	Speed: 1.43 samples/sec	Train-FCNLogLoss=0.096679,	
2017-07-13 09:34:56,183 Epoch[72] Batch [350]	Speed: 1.53 samples/sec	Train-FCNLogLoss=0.096356,	
2017-07-13 09:35:29,967 Epoch[72] Batch [360]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.096270,	
2017-07-13 09:36:02,138 Epoch[72] Batch [370]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.096088,	
2017-07-13 09:36:36,013 Epoch[72] Batch [380]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.096197,	
2017-07-13 09:37:09,173 Epoch[72] Batch [390]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.095919,	
2017-07-13 09:37:40,596 Epoch[72] Batch [400]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.095529,	
2017-07-13 09:38:10,307 Epoch[72] Batch [410]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.095592,	
2017-07-13 09:38:42,804 Epoch[72] Batch [420]	Speed: 1.23 samples/sec	Train-FCNLogLoss=0.095701,	
2017-07-13 09:39:13,944 Epoch[72] Batch [430]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.095925,	
2017-07-13 09:39:43,318 Epoch[72] Batch [440]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.095911,	
2017-07-13 09:40:14,146 Epoch[72] Batch [450]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.095656,	
2017-07-13 09:40:40,514 Epoch[72] Batch [460]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.095511,	
2017-07-13 09:41:14,328 Epoch[72] Batch [470]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.095679,	
2017-07-13 09:41:43,561 Epoch[72] Batch [480]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.095781,	
2017-07-13 09:42:13,905 Epoch[72] Batch [490]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.095744,	
2017-07-13 09:42:45,809 Epoch[72] Batch [500]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.095542,	
2017-07-13 09:43:14,988 Epoch[72] Batch [510]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.095962,	
2017-07-13 09:43:44,731 Epoch[72] Batch [520]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.095998,	
2017-07-13 09:44:13,592 Epoch[72] Batch [530]	Speed: 1.39 samples/sec	Train-FCNLogLoss=0.095784,	
2017-07-13 09:44:44,858 Epoch[72] Batch [540]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.095729,	
2017-07-13 09:45:14,668 Epoch[72] Batch [550]	Speed: 1.34 samples/sec	Train-FCNLogLoss=0.095897,	
2017-07-13 09:45:42,944 Epoch[72] Batch [560]	Speed: 1.41 samples/sec	Train-FCNLogLoss=0.095789,	
2017-07-13 09:46:13,084 Epoch[72] Batch [570]	Speed: 1.33 samples/sec	Train-FCNLogLoss=0.095656,	
2017-07-13 09:46:39,694 Epoch[72] Batch [580]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.095512,	
2017-07-13 09:47:11,119 Epoch[72] Batch [590]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.095436,	
2017-07-13 09:47:44,301 Epoch[72] Batch [600]	Speed: 1.21 samples/sec	Train-FCNLogLoss=0.095397,	
2017-07-13 09:48:21,109 Epoch[72] Batch [610]	Speed: 1.09 samples/sec	Train-FCNLogLoss=0.095381,	
2017-07-13 09:48:50,372 Epoch[72] Batch [620]	Speed: 1.37 samples/sec	Train-FCNLogLoss=0.095171,	
2017-07-13 09:49:21,930 Epoch[72] Batch [630]	Speed: 1.27 samples/sec	Train-FCNLogLoss=0.095020,	
2017-07-13 09:49:55,968 Epoch[72] Batch [640]	Speed: 1.18 samples/sec	Train-FCNLogLoss=0.095071,	
2017-07-13 09:50:28,207 Epoch[72] Batch [650]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.094937,	
2017-07-13 09:51:03,612 Epoch[72] Batch [660]	Speed: 1.13 samples/sec	Train-FCNLogLoss=0.094866,	
2017-07-13 09:51:37,206 Epoch[72] Batch [670]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.094729,	
2017-07-13 09:52:06,811 Epoch[72] Batch [680]	Speed: 1.35 samples/sec	Train-FCNLogLoss=0.095061,	
2017-07-13 09:52:38,988 Epoch[72] Batch [690]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.094904,	
2017-07-13 09:53:14,177 Epoch[72] Batch [700]	Speed: 1.14 samples/sec	Train-FCNLogLoss=0.094990,	
2017-07-13 09:53:48,470 Epoch[72] Batch [710]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.095024,	
2017-07-13 09:54:24,860 Epoch[72] Batch [720]	Speed: 1.10 samples/sec	Train-FCNLogLoss=0.095006,	
2017-07-13 09:54:39,926 Epoch[72] Batch [730]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.094909,	
2017-07-13 09:54:48,606 Epoch[72] Batch [740]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.094799,	
2017-07-13 09:54:57,306 Epoch[72] Batch [750]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.094671,	
2017-07-13 09:55:05,861 Epoch[72] Batch [760]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.094553,	
2017-07-13 09:55:14,445 Epoch[72] Batch [770]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.094406,	
2017-07-13 09:55:23,030 Epoch[72] Batch [780]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.094255,	
2017-07-13 09:55:31,622 Epoch[72] Batch [790]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.094107,	
2017-07-13 09:55:40,263 Epoch[72] Batch [800]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.094092,	
2017-07-13 09:55:48,856 Epoch[72] Batch [810]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.093926,	
2017-07-13 09:55:57,002 Epoch[72] Batch [820]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.093872,	
2017-07-13 09:56:05,252 Epoch[72] Batch [830]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.093759,	
2017-07-13 09:56:13,664 Epoch[72] Batch [840]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.093707,	
2017-07-13 09:56:21,912 Epoch[72] Batch [850]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.093576,	
2017-07-13 09:56:30,253 Epoch[72] Batch [860]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.093538,	
2017-07-13 09:56:38,535 Epoch[72] Batch [870]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.093417,	
2017-07-13 09:56:47,003 Epoch[72] Batch [880]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.093291,	
2017-07-13 09:56:55,734 Epoch[72] Batch [890]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.093234,	
2017-07-13 09:57:04,100 Epoch[72] Batch [900]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.093216,	
2017-07-13 09:57:12,710 Epoch[72] Batch [910]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.093101,	
2017-07-13 09:57:21,334 Epoch[72] Batch [920]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.093004,	
2017-07-13 09:57:29,654 Epoch[72] Batch [930]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.093009,	
2017-07-13 09:57:38,026 Epoch[72] Batch [940]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.092983,	
2017-07-13 09:57:46,514 Epoch[72] Batch [950]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.092928,	
2017-07-13 09:57:54,862 Epoch[72] Batch [960]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.092878,	
2017-07-13 09:58:03,307 Epoch[72] Batch [970]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.092852,	
2017-07-13 09:58:11,892 Epoch[72] Batch [980]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.092831,	
2017-07-13 09:58:20,569 Epoch[72] Batch [990]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.092709,	
2017-07-13 09:58:29,052 Epoch[72] Batch [1000]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.092617,	
2017-07-13 09:58:37,741 Epoch[72] Batch [1010]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.092726,	
2017-07-13 09:58:46,222 Epoch[72] Batch [1020]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.092672,	
2017-07-13 09:58:54,791 Epoch[72] Batch [1030]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.092600,	
2017-07-13 09:59:03,386 Epoch[72] Batch [1040]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.092600,	
2017-07-13 09:59:11,706 Epoch[72] Batch [1050]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.092628,	
2017-07-13 09:59:20,234 Epoch[72] Batch [1060]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.092509,	
2017-07-13 09:59:28,747 Epoch[72] Batch [1070]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.092509,	
2017-07-13 09:59:37,131 Epoch[72] Batch [1080]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.092492,	
2017-07-13 09:59:52,707 Epoch[72] Batch [1090]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.092448,	
2017-07-13 10:00:13,863 Epoch[72] Batch [1100]	Speed: 1.89 samples/sec	Train-FCNLogLoss=0.092365,	
2017-07-13 10:00:35,879 Epoch[72] Batch [1110]	Speed: 1.82 samples/sec	Train-FCNLogLoss=0.092337,	
2017-07-13 10:00:58,356 Epoch[72] Batch [1120]	Speed: 1.78 samples/sec	Train-FCNLogLoss=0.092311,	
2017-07-13 10:01:19,799 Epoch[72] Batch [1130]	Speed: 1.87 samples/sec	Train-FCNLogLoss=0.092218,	
2017-07-13 10:01:42,861 Epoch[72] Batch [1140]	Speed: 1.73 samples/sec	Train-FCNLogLoss=0.092120,	
2017-07-13 10:02:04,975 Epoch[72] Batch [1150]	Speed: 1.81 samples/sec	Train-FCNLogLoss=0.092027,	
2017-07-13 10:02:23,561 Epoch[72] Batch [1160]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.091953,	
2017-07-13 10:02:42,493 Epoch[72] Batch [1170]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.091786,	
2017-07-13 10:03:16,097 Epoch[72] Batch [1180]	Speed: 1.19 samples/sec	Train-FCNLogLoss=0.091673,	
2017-07-13 10:03:55,376 Epoch[72] Batch [1190]	Speed: 1.02 samples/sec	Train-FCNLogLoss=0.091664,	
2017-07-13 10:04:27,731 Epoch[72] Batch [1200]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.091624,	
2017-07-13 10:05:00,022 Epoch[72] Batch [1210]	Speed: 1.24 samples/sec	Train-FCNLogLoss=0.091483,	
2017-07-13 10:05:34,193 Epoch[72] Batch [1220]	Speed: 1.17 samples/sec	Train-FCNLogLoss=0.091397,	
2017-07-13 10:05:59,327 Epoch[72] Batch [1230]	Speed: 1.59 samples/sec	Train-FCNLogLoss=0.091358,	
2017-07-13 10:06:22,027 Epoch[72] Batch [1240]	Speed: 1.76 samples/sec	Train-FCNLogLoss=0.091257,	
2017-07-13 10:06:48,694 Epoch[72] Batch [1250]	Speed: 1.50 samples/sec	Train-FCNLogLoss=0.091138,	
2017-07-13 10:07:06,174 Epoch[72] Batch [1260]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.091125,	
2017-07-13 10:07:13,489 Epoch[72] Batch [1270]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.091038,	
2017-07-13 10:07:21,107 Epoch[72] Batch [1280]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.090980,	
2017-07-13 10:07:28,623 Epoch[72] Batch [1290]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.090945,	
2017-07-13 10:07:36,079 Epoch[72] Batch [1300]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.090847,	
2017-07-13 10:07:43,553 Epoch[72] Batch [1310]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.090850,	
2017-07-13 10:07:50,845 Epoch[72] Batch [1320]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.090760,	
2017-07-13 10:07:58,201 Epoch[72] Batch [1330]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.090647,	
2017-07-13 10:08:05,598 Epoch[72] Batch [1340]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.090624,	
2017-07-13 10:08:13,051 Epoch[72] Batch [1350]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.090619,	
2017-07-13 10:08:20,637 Epoch[72] Batch [1360]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.090592,	
2017-07-13 10:08:28,354 Epoch[72] Batch [1370]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.090606,	
2017-07-13 10:08:36,276 Epoch[72] Batch [1380]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.090508,	
2017-07-13 10:08:43,946 Epoch[72] Batch [1390]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.090424,	
2017-07-13 10:08:51,869 Epoch[72] Batch [1400]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.090336,	
2017-07-13 10:08:59,885 Epoch[72] Batch [1410]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.090400,	
2017-07-13 10:09:07,905 Epoch[72] Batch [1420]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.090328,	
2017-07-13 10:09:16,016 Epoch[72] Batch [1430]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.090308,	
2017-07-13 10:09:24,056 Epoch[72] Batch [1440]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.090272,	
2017-07-13 10:09:31,885 Epoch[72] Batch [1450]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.090313,	
2017-07-13 10:09:39,755 Epoch[72] Batch [1460]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.090279,	
2017-07-13 10:09:47,841 Epoch[72] Batch [1470]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.090298,	
2017-07-13 10:09:55,884 Epoch[72] Batch [1480]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.090267,	
2017-07-13 10:10:00,799 Epoch[72] Train-FCNLogLoss=0.090225
2017-07-13 10:10:00,800 Epoch[72] Time cost=3119.091
2017-07-13 10:10:02,033 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0073.params"
2017-07-13 10:10:05,673 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0073.states"
2017-07-13 10:10:14,786 Epoch[73] Batch [10]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.084606,	
2017-07-13 10:10:21,597 Epoch[73] Batch [20]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.085508,	
2017-07-13 10:10:28,587 Epoch[73] Batch [30]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.087259,	
2017-07-13 10:10:35,247 Epoch[73] Batch [40]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.085346,	
2017-07-13 10:10:41,844 Epoch[73] Batch [50]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.084672,	
2017-07-13 10:10:48,909 Epoch[73] Batch [60]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.085139,	
2017-07-13 10:10:55,547 Epoch[73] Batch [70]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.085529,	
2017-07-13 10:11:02,919 Epoch[73] Batch [80]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.084826,	
2017-07-13 10:11:10,783 Epoch[73] Batch [90]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.083645,	
2017-07-13 10:11:18,515 Epoch[73] Batch [100]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.083268,	
2017-07-13 10:11:26,011 Epoch[73] Batch [110]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.083395,	
2017-07-13 10:11:33,359 Epoch[73] Batch [120]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.083494,	
2017-07-13 10:11:41,077 Epoch[73] Batch [130]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.082619,	
2017-07-13 10:11:48,881 Epoch[73] Batch [140]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.083088,	
2017-07-13 10:11:56,357 Epoch[73] Batch [150]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.082424,	
2017-07-13 10:12:03,279 Epoch[73] Batch [160]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.082681,	
2017-07-13 10:12:10,238 Epoch[73] Batch [170]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.083280,	
2017-07-13 10:12:17,496 Epoch[73] Batch [180]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.083620,	
2017-07-13 10:12:24,333 Epoch[73] Batch [190]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.083752,	
2017-07-13 10:12:31,117 Epoch[73] Batch [200]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.084084,	
2017-07-13 10:12:38,143 Epoch[73] Batch [210]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.084322,	
2017-07-13 10:12:45,449 Epoch[73] Batch [220]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.084002,	
2017-07-13 10:12:52,846 Epoch[73] Batch [230]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.083621,	
2017-07-13 10:13:00,192 Epoch[73] Batch [240]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.083874,	
2017-07-13 10:13:07,513 Epoch[73] Batch [250]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.084111,	
2017-07-13 10:13:15,032 Epoch[73] Batch [260]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.084208,	
2017-07-13 10:13:22,962 Epoch[73] Batch [270]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.084395,	
2017-07-13 10:13:30,989 Epoch[73] Batch [280]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.084677,	
2017-07-13 10:13:38,870 Epoch[73] Batch [290]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.084590,	
2017-07-13 10:13:46,839 Epoch[73] Batch [300]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.084407,	
2017-07-13 10:13:54,825 Epoch[73] Batch [310]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.084211,	
2017-07-13 10:14:02,683 Epoch[73] Batch [320]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.084031,	
2017-07-13 10:14:10,598 Epoch[73] Batch [330]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.083984,	
2017-07-13 10:14:18,695 Epoch[73] Batch [340]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.083933,	
2017-07-13 10:14:26,701 Epoch[73] Batch [350]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.083724,	
2017-07-13 10:14:34,771 Epoch[73] Batch [360]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.083532,	
2017-07-13 10:14:42,684 Epoch[73] Batch [370]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.083483,	
2017-07-13 10:14:50,752 Epoch[73] Batch [380]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.083666,	
2017-07-13 10:14:58,822 Epoch[73] Batch [390]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.083799,	
2017-07-13 10:15:06,693 Epoch[73] Batch [400]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.083586,	
2017-07-13 10:15:14,662 Epoch[73] Batch [410]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.083688,	
2017-07-13 10:15:22,694 Epoch[73] Batch [420]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.083479,	
2017-07-13 10:15:30,599 Epoch[73] Batch [430]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.083623,	
2017-07-13 10:15:38,897 Epoch[73] Batch [440]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.083545,	
2017-07-13 10:15:46,947 Epoch[73] Batch [450]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.083667,	
2017-07-13 10:15:55,042 Epoch[73] Batch [460]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.083657,	
2017-07-13 10:16:02,914 Epoch[73] Batch [470]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.083675,	
2017-07-13 10:16:10,817 Epoch[73] Batch [480]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.083698,	
2017-07-13 10:16:18,522 Epoch[73] Batch [490]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.083536,	
2017-07-13 10:16:26,265 Epoch[73] Batch [500]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.083454,	
2017-07-13 10:16:34,133 Epoch[73] Batch [510]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.083256,	
2017-07-13 10:16:42,138 Epoch[73] Batch [520]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.083189,	
2017-07-13 10:16:50,246 Epoch[73] Batch [530]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.083189,	
2017-07-13 10:16:58,363 Epoch[73] Batch [540]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.083265,	
2017-07-13 10:17:06,393 Epoch[73] Batch [550]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.083284,	
2017-07-13 10:17:14,371 Epoch[73] Batch [560]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.083215,	
2017-07-13 10:17:22,321 Epoch[73] Batch [570]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.083297,	
2017-07-13 10:17:30,317 Epoch[73] Batch [580]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.083298,	
2017-07-13 10:17:38,309 Epoch[73] Batch [590]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.083100,	
2017-07-13 10:17:46,399 Epoch[73] Batch [600]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.083045,	
2017-07-13 10:17:54,291 Epoch[73] Batch [610]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.082890,	
2017-07-13 10:18:02,007 Epoch[73] Batch [620]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.082899,	
2017-07-13 10:18:09,759 Epoch[73] Batch [630]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.082803,	
2017-07-13 10:18:17,794 Epoch[73] Batch [640]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.082692,	
2017-07-13 10:18:25,766 Epoch[73] Batch [650]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.082559,	
2017-07-13 10:18:33,794 Epoch[73] Batch [660]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.082483,	
2017-07-13 10:18:41,860 Epoch[73] Batch [670]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.082525,	
2017-07-13 10:18:49,818 Epoch[73] Batch [680]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082502,	
2017-07-13 10:18:57,900 Epoch[73] Batch [690]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.082509,	
2017-07-13 10:19:05,896 Epoch[73] Batch [700]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.082487,	
2017-07-13 10:19:13,899 Epoch[73] Batch [710]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.082521,	
2017-07-13 10:19:21,971 Epoch[73] Batch [720]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.082490,	
2017-07-13 10:19:30,055 Epoch[73] Batch [730]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.082443,	
2017-07-13 10:19:38,431 Epoch[73] Batch [740]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.082516,	
2017-07-13 10:19:46,213 Epoch[73] Batch [750]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.082601,	
2017-07-13 10:19:54,303 Epoch[73] Batch [760]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.082525,	
2017-07-13 10:20:02,379 Epoch[73] Batch [770]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.082590,	
2017-07-13 10:20:10,487 Epoch[73] Batch [780]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.082579,	
2017-07-13 10:20:18,582 Epoch[73] Batch [790]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.082641,	
2017-07-13 10:20:26,674 Epoch[73] Batch [800]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.082657,	
2017-07-13 10:20:34,790 Epoch[73] Batch [810]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.082632,	
2017-07-13 10:20:42,840 Epoch[73] Batch [820]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.082616,	
2017-07-13 10:20:50,845 Epoch[73] Batch [830]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.082556,	
2017-07-13 10:20:58,857 Epoch[73] Batch [840]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.082565,	
2017-07-13 10:21:06,842 Epoch[73] Batch [850]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.082727,	
2017-07-13 10:21:14,797 Epoch[73] Batch [860]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082765,	
2017-07-13 10:21:22,580 Epoch[73] Batch [870]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.082838,	
2017-07-13 10:21:30,466 Epoch[73] Batch [880]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.082834,	
2017-07-13 10:21:38,422 Epoch[73] Batch [890]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082766,	
2017-07-13 10:21:46,357 Epoch[73] Batch [900]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.082797,	
2017-07-13 10:21:54,319 Epoch[73] Batch [910]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.082892,	
2017-07-13 10:22:02,212 Epoch[73] Batch [920]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.082903,	
2017-07-13 10:22:10,132 Epoch[73] Batch [930]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.082932,	
2017-07-13 10:22:18,052 Epoch[73] Batch [940]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.082973,	
2017-07-13 10:22:26,012 Epoch[73] Batch [950]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082981,	
2017-07-13 10:22:33,962 Epoch[73] Batch [960]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082992,	
2017-07-13 10:22:41,969 Epoch[73] Batch [970]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.083055,	
2017-07-13 10:22:50,117 Epoch[73] Batch [980]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.083004,	
2017-07-13 10:22:58,034 Epoch[73] Batch [990]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.083028,	
2017-07-13 10:23:06,205 Epoch[73] Batch [1000]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.082992,	
2017-07-13 10:23:14,092 Epoch[73] Batch [1010]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.083058,	
2017-07-13 10:23:22,177 Epoch[73] Batch [1020]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.083240,	
2017-07-13 10:23:30,345 Epoch[73] Batch [1030]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.083294,	
2017-07-13 10:23:38,601 Epoch[73] Batch [1040]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.083417,	
2017-07-13 10:23:46,684 Epoch[73] Batch [1050]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.083512,	
2017-07-13 10:23:54,571 Epoch[73] Batch [1060]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.083522,	
2017-07-13 10:24:02,491 Epoch[73] Batch [1070]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.083597,	
2017-07-13 10:24:10,581 Epoch[73] Batch [1080]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.083624,	
2017-07-13 10:24:18,990 Epoch[73] Batch [1090]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.083679,	
2017-07-13 10:24:27,128 Epoch[73] Batch [1100]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.083631,	
2017-07-13 10:24:35,071 Epoch[73] Batch [1110]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.083692,	
2017-07-13 10:24:43,089 Epoch[73] Batch [1120]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.083703,	
2017-07-13 10:24:51,158 Epoch[73] Batch [1130]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.083841,	
2017-07-13 10:24:59,140 Epoch[73] Batch [1140]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.083789,	
2017-07-13 10:25:07,218 Epoch[73] Batch [1150]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.083833,	
2017-07-13 10:25:15,133 Epoch[73] Batch [1160]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.083850,	
2017-07-13 10:25:23,110 Epoch[73] Batch [1170]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.083849,	
2017-07-13 10:25:31,171 Epoch[73] Batch [1180]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.083967,	
2017-07-13 10:25:39,062 Epoch[73] Batch [1190]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.084010,	
2017-07-13 10:25:46,924 Epoch[73] Batch [1200]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.083969,	
2017-07-13 10:25:54,764 Epoch[73] Batch [1210]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.083928,	
2017-07-13 10:26:02,592 Epoch[73] Batch [1220]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.083857,	
2017-07-13 10:26:10,382 Epoch[73] Batch [1230]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.083867,	
2017-07-13 10:26:18,390 Epoch[73] Batch [1240]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.083905,	
2017-07-13 10:26:45,157 Epoch[73] Batch [1250]	Speed: 1.49 samples/sec	Train-FCNLogLoss=0.083886,	
2017-07-13 10:27:07,006 Epoch[73] Batch [1260]	Speed: 1.83 samples/sec	Train-FCNLogLoss=0.083860,	
2017-07-13 10:27:14,833 Epoch[73] Batch [1270]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.083836,	
2017-07-13 10:27:22,762 Epoch[73] Batch [1280]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.083827,	
2017-07-13 10:27:30,686 Epoch[73] Batch [1290]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.083798,	
2017-07-13 10:27:39,034 Epoch[73] Batch [1300]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.083781,	
2017-07-13 10:27:47,078 Epoch[73] Batch [1310]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.083775,	
2017-07-13 10:27:55,207 Epoch[73] Batch [1320]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.083769,	
2017-07-13 10:28:03,402 Epoch[73] Batch [1330]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.083727,	
2017-07-13 10:28:11,495 Epoch[73] Batch [1340]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.083730,	
2017-07-13 10:28:19,659 Epoch[73] Batch [1350]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.083692,	
2017-07-13 10:28:27,793 Epoch[73] Batch [1360]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.083715,	
2017-07-13 10:28:36,022 Epoch[73] Batch [1370]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.083658,	
2017-07-13 10:28:43,905 Epoch[73] Batch [1380]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.083743,	
2017-07-13 10:28:51,952 Epoch[73] Batch [1390]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.083747,	
2017-07-13 10:28:59,737 Epoch[73] Batch [1400]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.083702,	
2017-07-13 10:29:07,723 Epoch[73] Batch [1410]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.083681,	
2017-07-13 10:29:15,572 Epoch[73] Batch [1420]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.083669,	
2017-07-13 10:29:23,564 Epoch[73] Batch [1430]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.083675,	
2017-07-13 10:29:31,374 Epoch[73] Batch [1440]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.083704,	
2017-07-13 10:29:39,258 Epoch[73] Batch [1450]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.083695,	
2017-07-13 10:29:47,125 Epoch[73] Batch [1460]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.083699,	
2017-07-13 10:29:55,014 Epoch[73] Batch [1470]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.083724,	
2017-07-13 10:30:03,279 Epoch[73] Batch [1480]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.083739,	
2017-07-13 10:30:08,217 Epoch[73] Train-FCNLogLoss=0.083766
2017-07-13 10:30:08,217 Epoch[73] Time cost=1202.544
2017-07-13 10:30:09,223 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0074.params"
2017-07-13 10:30:13,004 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0074.states"
2017-07-13 10:30:22,142 Epoch[74] Batch [10]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.079702,	
2017-07-13 10:30:30,121 Epoch[74] Batch [20]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.079363,	
2017-07-13 10:30:38,238 Epoch[74] Batch [30]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.081426,	
2017-07-13 10:30:46,147 Epoch[74] Batch [40]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.081068,	
2017-07-13 10:30:54,174 Epoch[74] Batch [50]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.082700,	
2017-07-13 10:31:02,072 Epoch[74] Batch [60]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.081367,	
2017-07-13 10:31:10,149 Epoch[74] Batch [70]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.082394,	
2017-07-13 10:31:18,127 Epoch[74] Batch [80]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.082224,	
2017-07-13 10:31:26,119 Epoch[74] Batch [90]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.084179,	
2017-07-13 10:31:34,100 Epoch[74] Batch [100]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.084020,	
2017-07-13 10:31:42,289 Epoch[74] Batch [110]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.083980,	
2017-07-13 10:31:50,350 Epoch[74] Batch [120]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.083842,	
2017-07-13 10:31:58,375 Epoch[74] Batch [130]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.083222,	
2017-07-13 10:32:06,311 Epoch[74] Batch [140]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.082897,	
2017-07-13 10:32:14,205 Epoch[74] Batch [150]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.083132,	
2017-07-13 10:32:22,213 Epoch[74] Batch [160]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.082792,	
2017-07-13 10:32:30,258 Epoch[74] Batch [170]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.082116,	
2017-07-13 10:32:38,325 Epoch[74] Batch [180]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.082273,	
2017-07-13 10:32:46,310 Epoch[74] Batch [190]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.081926,	
2017-07-13 10:32:54,354 Epoch[74] Batch [200]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.081786,	
2017-07-13 10:33:02,340 Epoch[74] Batch [210]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.081829,	
2017-07-13 10:33:10,116 Epoch[74] Batch [220]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.081865,	
2017-07-13 10:33:18,040 Epoch[74] Batch [230]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.081924,	
2017-07-13 10:33:26,594 Epoch[74] Batch [240]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.081824,	
2017-07-13 10:33:34,459 Epoch[74] Batch [250]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.081807,	
2017-07-13 10:33:42,244 Epoch[74] Batch [260]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.081580,	
2017-07-13 10:33:50,056 Epoch[74] Batch [270]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.081546,	
2017-07-13 10:33:57,999 Epoch[74] Batch [280]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.081444,	
2017-07-13 10:34:05,802 Epoch[74] Batch [290]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.081436,	
2017-07-13 10:34:13,521 Epoch[74] Batch [300]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.081466,	
2017-07-13 10:34:21,452 Epoch[74] Batch [310]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.081465,	
2017-07-13 10:34:29,352 Epoch[74] Batch [320]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.081622,	
2017-07-13 10:34:37,220 Epoch[74] Batch [330]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.081638,	
2017-07-13 10:34:45,246 Epoch[74] Batch [340]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.081631,	
2017-07-13 10:34:53,427 Epoch[74] Batch [350]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.081524,	
2017-07-13 10:35:01,419 Epoch[74] Batch [360]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.081384,	
2017-07-13 10:35:09,411 Epoch[74] Batch [370]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.081324,	
2017-07-13 10:35:17,401 Epoch[74] Batch [380]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.081312,	
2017-07-13 10:35:25,291 Epoch[74] Batch [390]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.081923,	
2017-07-13 10:35:33,220 Epoch[74] Batch [400]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.082090,	
2017-07-13 10:35:41,085 Epoch[74] Batch [410]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.082105,	
2017-07-13 10:35:48,917 Epoch[74] Batch [420]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.082261,	
2017-07-13 10:35:56,693 Epoch[74] Batch [430]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.082152,	
2017-07-13 10:36:04,626 Epoch[74] Batch [440]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.082119,	
2017-07-13 10:36:12,494 Epoch[74] Batch [450]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.082140,	
2017-07-13 10:36:20,332 Epoch[74] Batch [460]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.082088,	
2017-07-13 10:36:28,324 Epoch[74] Batch [470]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.082153,	
2017-07-13 10:36:36,313 Epoch[74] Batch [480]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.082189,	
2017-07-13 10:36:44,122 Epoch[74] Batch [490]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.082084,	
2017-07-13 10:36:52,022 Epoch[74] Batch [500]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.082225,	
2017-07-13 10:36:59,928 Epoch[74] Batch [510]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.082134,	
2017-07-13 10:37:07,860 Epoch[74] Batch [520]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.081960,	
2017-07-13 10:37:15,838 Epoch[74] Batch [530]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.081916,	
2017-07-13 10:37:23,837 Epoch[74] Batch [540]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.081956,	
2017-07-13 10:37:31,913 Epoch[74] Batch [550]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.082070,	
2017-07-13 10:37:39,963 Epoch[74] Batch [560]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.082030,	
2017-07-13 10:37:47,932 Epoch[74] Batch [570]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.082163,	
2017-07-13 10:37:55,855 Epoch[74] Batch [580]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.082152,	
2017-07-13 10:38:03,797 Epoch[74] Batch [590]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.081973,	
2017-07-13 10:38:11,904 Epoch[74] Batch [600]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.081980,	
2017-07-13 10:38:20,035 Epoch[74] Batch [610]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.082108,	
2017-07-13 10:38:27,944 Epoch[74] Batch [620]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.082317,	
2017-07-13 10:38:36,023 Epoch[74] Batch [630]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.082368,	
2017-07-13 10:38:43,954 Epoch[74] Batch [640]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.083195,	
2017-07-13 10:38:52,071 Epoch[74] Batch [650]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089816,	
2017-07-13 10:38:59,763 Epoch[74] Batch [660]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.095315,	
2017-07-13 10:39:07,439 Epoch[74] Batch [670]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.099412,	
2017-07-13 10:39:39,464 Epoch[74] Batch [680]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.101990,	
2017-07-13 10:40:09,870 Epoch[74] Batch [690]	Speed: 1.32 samples/sec	Train-FCNLogLoss=0.104282,	
2017-07-13 10:40:41,070 Epoch[74] Batch [700]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.106561,	
2017-07-13 10:41:10,517 Epoch[74] Batch [710]	Speed: 1.36 samples/sec	Train-FCNLogLoss=0.107991,	
2017-07-13 10:41:36,767 Epoch[74] Batch [720]	Speed: 1.52 samples/sec	Train-FCNLogLoss=0.108869,	
2017-07-13 10:42:08,655 Epoch[74] Batch [730]	Speed: 1.25 samples/sec	Train-FCNLogLoss=0.109895,	
2017-07-13 10:42:39,827 Epoch[74] Batch [740]	Speed: 1.28 samples/sec	Train-FCNLogLoss=0.111036,	
2017-07-13 10:43:10,645 Epoch[74] Batch [750]	Speed: 1.30 samples/sec	Train-FCNLogLoss=0.111817,	
2017-07-13 10:43:33,354 Epoch[74] Batch [760]	Speed: 1.76 samples/sec	Train-FCNLogLoss=0.112461,	
2017-07-13 10:43:41,031 Epoch[74] Batch [770]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.113272,	
2017-07-13 10:43:48,620 Epoch[74] Batch [780]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.115423,	
2017-07-13 10:43:56,220 Epoch[74] Batch [790]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.116219,	
2017-07-13 10:44:03,928 Epoch[74] Batch [800]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.116636,	
2017-07-13 10:44:11,369 Epoch[74] Batch [810]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.116796,	
2017-07-13 10:44:18,919 Epoch[74] Batch [820]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.117267,	
2017-07-13 10:44:26,467 Epoch[74] Batch [830]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.117530,	
2017-07-13 10:44:33,854 Epoch[74] Batch [840]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.118024,	
2017-07-13 10:44:41,741 Epoch[74] Batch [850]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.118596,	
2017-07-13 10:44:49,560 Epoch[74] Batch [860]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.119104,	
2017-07-13 10:44:57,290 Epoch[74] Batch [870]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.119636,	
2017-07-13 10:45:04,726 Epoch[74] Batch [880]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.119801,	
2017-07-13 10:45:12,449 Epoch[74] Batch [890]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.119968,	
2017-07-13 10:45:20,315 Epoch[74] Batch [900]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.120423,	
2017-07-13 10:45:28,363 Epoch[74] Batch [910]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.120779,	
2017-07-13 10:45:36,181 Epoch[74] Batch [920]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.121055,	
2017-07-13 10:45:43,887 Epoch[74] Batch [930]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.121179,	
2017-07-13 10:45:52,157 Epoch[74] Batch [940]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.121232,	
2017-07-13 10:46:00,162 Epoch[74] Batch [950]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.121164,	
2017-07-13 10:46:08,405 Epoch[74] Batch [960]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.121207,	
2017-07-13 10:46:16,522 Epoch[74] Batch [970]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.121364,	
2017-07-13 10:46:25,140 Epoch[74] Batch [980]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.121357,	
2017-07-13 10:46:33,377 Epoch[74] Batch [990]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.121133,	
2017-07-13 10:46:41,135 Epoch[74] Batch [1000]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.121158,	
2017-07-13 10:46:49,229 Epoch[74] Batch [1010]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.121007,	
2017-07-13 10:46:57,265 Epoch[74] Batch [1020]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.121064,	
2017-07-13 10:47:05,460 Epoch[74] Batch [1030]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.120814,	
2017-07-13 10:47:13,429 Epoch[74] Batch [1040]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.120736,	
2017-07-13 10:47:21,312 Epoch[74] Batch [1050]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.120634,	
2017-07-13 10:47:29,369 Epoch[74] Batch [1060]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.120443,	
2017-07-13 10:47:37,323 Epoch[74] Batch [1070]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.120257,	
2017-07-13 10:47:45,180 Epoch[74] Batch [1080]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.120202,	
2017-07-13 10:47:52,930 Epoch[74] Batch [1090]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.120094,	
2017-07-13 10:48:00,833 Epoch[74] Batch [1100]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.119934,	
2017-07-13 10:48:09,009 Epoch[74] Batch [1110]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.119697,	
2017-07-13 10:48:16,899 Epoch[74] Batch [1120]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.119541,	
2017-07-13 10:48:24,718 Epoch[74] Batch [1130]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.119555,	
2017-07-13 10:48:32,496 Epoch[74] Batch [1140]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.119303,	
2017-07-13 10:48:40,607 Epoch[74] Batch [1150]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.119187,	
2017-07-13 10:48:48,481 Epoch[74] Batch [1160]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.118991,	
2017-07-13 10:48:56,626 Epoch[74] Batch [1170]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.118849,	
2017-07-13 10:49:05,178 Epoch[74] Batch [1180]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.118629,	
2017-07-13 10:49:13,811 Epoch[74] Batch [1190]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.118430,	
2017-07-13 10:49:22,163 Epoch[74] Batch [1200]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.118226,	
2017-07-13 10:49:30,362 Epoch[74] Batch [1210]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.118164,	
2017-07-13 10:49:38,134 Epoch[74] Batch [1220]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.118078,	
2017-07-13 10:49:45,921 Epoch[74] Batch [1230]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.117882,	
2017-07-13 10:49:53,802 Epoch[74] Batch [1240]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.117658,	
2017-07-13 10:50:01,481 Epoch[74] Batch [1250]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.117460,	
2017-07-13 10:50:09,522 Epoch[74] Batch [1260]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.117330,	
2017-07-13 10:50:17,282 Epoch[74] Batch [1270]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.117133,	
2017-07-13 10:50:25,261 Epoch[74] Batch [1280]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.116973,	
2017-07-13 10:50:32,968 Epoch[74] Batch [1290]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.116806,	
2017-07-13 10:50:40,798 Epoch[74] Batch [1300]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.116667,	
2017-07-13 10:50:48,142 Epoch[74] Batch [1310]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.116573,	
2017-07-13 10:50:55,962 Epoch[74] Batch [1320]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.116385,	
2017-07-13 10:51:04,068 Epoch[74] Batch [1330]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.116221,	
2017-07-13 10:51:11,918 Epoch[74] Batch [1340]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.116037,	
2017-07-13 10:51:19,833 Epoch[74] Batch [1350]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.115873,	
2017-07-13 10:51:27,734 Epoch[74] Batch [1360]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.115583,	
2017-07-13 10:51:35,818 Epoch[74] Batch [1370]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.115455,	
2017-07-13 10:51:44,040 Epoch[74] Batch [1380]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.115394,	
2017-07-13 10:51:52,074 Epoch[74] Batch [1390]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.115307,	
2017-07-13 10:52:00,164 Epoch[74] Batch [1400]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.115139,	
2017-07-13 10:52:08,336 Epoch[74] Batch [1410]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.114997,	
2017-07-13 10:52:16,316 Epoch[74] Batch [1420]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.114842,	
2017-07-13 10:52:24,404 Epoch[74] Batch [1430]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.114703,	
2017-07-13 10:52:32,706 Epoch[74] Batch [1440]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.114535,	
2017-07-13 10:52:40,759 Epoch[74] Batch [1450]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.114263,	
2017-07-13 10:52:48,951 Epoch[74] Batch [1460]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.114137,	
2017-07-13 10:52:57,353 Epoch[74] Batch [1470]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.113955,	
2017-07-13 10:53:05,336 Epoch[74] Batch [1480]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.113788,	
2017-07-13 10:53:10,078 Epoch[74] Train-FCNLogLoss=0.113702
2017-07-13 10:53:10,078 Epoch[74] Time cost=1377.074
2017-07-13 10:53:11,201 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0075.params"
2017-07-13 10:53:14,980 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0075.states"
2017-07-13 10:53:23,915 Epoch[75] Batch [10]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.090196,	
2017-07-13 10:53:32,120 Epoch[75] Batch [20]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.091365,	
2017-07-13 10:53:40,231 Epoch[75] Batch [30]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.089708,	
2017-07-13 10:53:48,256 Epoch[75] Batch [40]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.092168,	
2017-07-13 10:53:56,159 Epoch[75] Batch [50]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.092284,	
2017-07-13 10:54:04,218 Epoch[75] Batch [60]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.092518,	
2017-07-13 10:54:12,285 Epoch[75] Batch [70]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.091968,	
2017-07-13 10:54:20,621 Epoch[75] Batch [80]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.091688,	
2017-07-13 10:54:28,477 Epoch[75] Batch [90]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.091068,	
2017-07-13 10:54:36,536 Epoch[75] Batch [100]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.091486,	
2017-07-13 10:54:44,383 Epoch[75] Batch [110]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.090901,	
2017-07-13 10:54:52,597 Epoch[75] Batch [120]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.091023,	
2017-07-13 10:55:00,543 Epoch[75] Batch [130]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.091709,	
2017-07-13 10:55:08,564 Epoch[75] Batch [140]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.092008,	
2017-07-13 10:55:16,766 Epoch[75] Batch [150]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.092283,	
2017-07-13 10:55:25,182 Epoch[75] Batch [160]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.091904,	
2017-07-13 10:55:33,606 Epoch[75] Batch [170]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.091514,	
2017-07-13 10:55:41,925 Epoch[75] Batch [180]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.091305,	
2017-07-13 10:55:50,110 Epoch[75] Batch [190]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.091053,	
2017-07-13 10:55:58,038 Epoch[75] Batch [200]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.090728,	
2017-07-13 10:56:05,779 Epoch[75] Batch [210]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.090774,	
2017-07-13 10:56:13,773 Epoch[75] Batch [220]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.090466,	
2017-07-13 10:56:21,787 Epoch[75] Batch [230]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.089702,	
2017-07-13 10:56:29,923 Epoch[75] Batch [240]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.089942,	
2017-07-13 10:56:38,061 Epoch[75] Batch [250]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.089711,	
2017-07-13 10:56:46,249 Epoch[75] Batch [260]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.089373,	
2017-07-13 10:56:54,750 Epoch[75] Batch [270]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.089175,	
2017-07-13 10:57:03,552 Epoch[75] Batch [280]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.089346,	
2017-07-13 10:57:12,116 Epoch[75] Batch [290]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.089087,	
2017-07-13 10:57:20,730 Epoch[75] Batch [300]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.088996,	
2017-07-13 10:57:29,543 Epoch[75] Batch [310]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.088843,	
2017-07-13 10:57:38,567 Epoch[75] Batch [320]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.088473,	
2017-07-13 10:57:47,758 Epoch[75] Batch [330]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.088128,	
2017-07-13 10:57:56,638 Epoch[75] Batch [340]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.087970,	
2017-07-13 10:58:05,453 Epoch[75] Batch [350]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.088164,	
2017-07-13 10:58:14,285 Epoch[75] Batch [360]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.087960,	
2017-07-13 10:58:22,345 Epoch[75] Batch [370]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.087987,	
2017-07-13 10:58:30,215 Epoch[75] Batch [380]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.087753,	
2017-07-13 10:58:38,004 Epoch[75] Batch [390]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.087641,	
2017-07-13 10:58:45,804 Epoch[75] Batch [400]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087564,	
2017-07-13 10:58:54,024 Epoch[75] Batch [410]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.087431,	
2017-07-13 10:59:01,994 Epoch[75] Batch [420]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.087427,	
2017-07-13 10:59:10,251 Epoch[75] Batch [430]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.087373,	
2017-07-13 10:59:18,727 Epoch[75] Batch [440]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.087434,	
2017-07-13 10:59:26,723 Epoch[75] Batch [450]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087467,	
2017-07-13 10:59:34,745 Epoch[75] Batch [460]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.087422,	
2017-07-13 10:59:42,734 Epoch[75] Batch [470]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.087529,	
2017-07-13 10:59:50,785 Epoch[75] Batch [480]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.087987,	
2017-07-13 10:59:58,971 Epoch[75] Batch [490]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.088002,	
2017-07-13 11:00:07,106 Epoch[75] Batch [500]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.087794,	
2017-07-13 11:00:15,233 Epoch[75] Batch [510]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.087692,	
2017-07-13 11:00:22,924 Epoch[75] Batch [520]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.087671,	
2017-07-13 11:00:31,005 Epoch[75] Batch [530]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.087628,	
2017-07-13 11:00:39,210 Epoch[75] Batch [540]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.087601,	
2017-07-13 11:00:47,253 Epoch[75] Batch [550]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.087513,	
2017-07-13 11:00:55,145 Epoch[75] Batch [560]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.087447,	
2017-07-13 11:01:02,999 Epoch[75] Batch [570]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.087407,	
2017-07-13 11:01:10,739 Epoch[75] Batch [580]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.087429,	
2017-07-13 11:01:18,953 Epoch[75] Batch [590]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.087324,	
2017-07-13 11:01:26,881 Epoch[75] Batch [600]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.087171,	
2017-07-13 11:01:34,888 Epoch[75] Batch [610]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087124,	
2017-07-13 11:01:42,803 Epoch[75] Batch [620]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.087106,	
2017-07-13 11:01:50,986 Epoch[75] Batch [630]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.087139,	
2017-07-13 11:01:58,995 Epoch[75] Batch [640]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087212,	
2017-07-13 11:02:06,904 Epoch[75] Batch [650]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087213,	
2017-07-13 11:02:14,809 Epoch[75] Batch [660]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.087133,	
2017-07-13 11:02:22,865 Epoch[75] Batch [670]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.086991,	
2017-07-13 11:02:30,806 Epoch[75] Batch [680]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.086906,	
2017-07-13 11:02:38,797 Epoch[75] Batch [690]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.086850,	
2017-07-13 11:02:46,739 Epoch[75] Batch [700]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.086825,	
2017-07-13 11:02:54,744 Epoch[75] Batch [710]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.086906,	
2017-07-13 11:03:02,728 Epoch[75] Batch [720]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.086842,	
2017-07-13 11:03:10,460 Epoch[75] Batch [730]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.086911,	
2017-07-13 11:03:18,335 Epoch[75] Batch [740]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.087036,	
2017-07-13 11:03:26,409 Epoch[75] Batch [750]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.086962,	
2017-07-13 11:03:34,327 Epoch[75] Batch [760]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.086845,	
2017-07-13 11:03:42,118 Epoch[75] Batch [770]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.086872,	
2017-07-13 11:03:50,073 Epoch[75] Batch [780]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.086763,	
2017-07-13 11:03:57,939 Epoch[75] Batch [790]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.086742,	
2017-07-13 11:04:05,760 Epoch[75] Batch [800]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.086751,	
2017-07-13 11:04:13,609 Epoch[75] Batch [810]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.086851,	
2017-07-13 11:04:21,576 Epoch[75] Batch [820]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.086834,	
2017-07-13 11:04:29,573 Epoch[75] Batch [830]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.086833,	
2017-07-13 11:04:37,524 Epoch[75] Batch [840]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.086890,	
2017-07-13 11:04:45,410 Epoch[75] Batch [850]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.086801,	
2017-07-13 11:04:53,303 Epoch[75] Batch [860]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.086751,	
2017-07-13 11:05:01,216 Epoch[75] Batch [870]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.086610,	
2017-07-13 11:05:09,184 Epoch[75] Batch [880]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.086584,	
2017-07-13 11:05:17,020 Epoch[75] Batch [890]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.086605,	
2017-07-13 11:05:24,997 Epoch[75] Batch [900]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.087762,	
2017-07-13 11:05:32,986 Epoch[75] Batch [910]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.090889,	
2017-07-13 11:05:40,846 Epoch[75] Batch [920]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.092344,	
2017-07-13 11:05:48,812 Epoch[75] Batch [930]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.093491,	
2017-07-13 11:05:57,037 Epoch[75] Batch [940]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.094296,	
2017-07-13 11:06:05,128 Epoch[75] Batch [950]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.095071,	
2017-07-13 11:06:13,210 Epoch[75] Batch [960]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.095437,	
2017-07-13 11:06:21,215 Epoch[75] Batch [970]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.095881,	
2017-07-13 11:06:29,221 Epoch[75] Batch [980]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.096153,	
2017-07-13 11:06:37,251 Epoch[75] Batch [990]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.096604,	
2017-07-13 11:06:45,333 Epoch[75] Batch [1000]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.097322,	
2017-07-13 11:06:53,558 Epoch[75] Batch [1010]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.098011,	
2017-07-13 11:07:01,616 Epoch[75] Batch [1020]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.098397,	
2017-07-13 11:07:09,679 Epoch[75] Batch [1030]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.098893,	
2017-07-13 11:07:17,531 Epoch[75] Batch [1040]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.099317,	
2017-07-13 11:07:25,401 Epoch[75] Batch [1050]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.099539,	
2017-07-13 11:07:33,408 Epoch[75] Batch [1060]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.099696,	
2017-07-13 11:07:41,661 Epoch[75] Batch [1070]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.099680,	
2017-07-13 11:07:49,586 Epoch[75] Batch [1080]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.099855,	
2017-07-13 11:07:57,477 Epoch[75] Batch [1090]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.100045,	
2017-07-13 11:08:05,486 Epoch[75] Batch [1100]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.100374,	
2017-07-13 11:08:13,590 Epoch[75] Batch [1110]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.100560,	
2017-07-13 11:08:21,542 Epoch[75] Batch [1120]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.100679,	
2017-07-13 11:08:29,611 Epoch[75] Batch [1130]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.100690,	
2017-07-13 11:08:37,535 Epoch[75] Batch [1140]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.100814,	
2017-07-13 11:08:45,530 Epoch[75] Batch [1150]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.100860,	
2017-07-13 11:08:53,387 Epoch[75] Batch [1160]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.100886,	
2017-07-13 11:09:01,361 Epoch[75] Batch [1170]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.101047,	
2017-07-13 11:09:09,231 Epoch[75] Batch [1180]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.101227,	
2017-07-13 11:09:17,102 Epoch[75] Batch [1190]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.101514,	
2017-07-13 11:09:25,016 Epoch[75] Batch [1200]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.101753,	
2017-07-13 11:09:32,982 Epoch[75] Batch [1210]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.101904,	
2017-07-13 11:09:40,822 Epoch[75] Batch [1220]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.101921,	
2017-07-13 11:09:48,810 Epoch[75] Batch [1230]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.101997,	
2017-07-13 11:09:56,798 Epoch[75] Batch [1240]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.101966,	
2017-07-13 11:10:04,706 Epoch[75] Batch [1250]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.101908,	
2017-07-13 11:10:12,642 Epoch[75] Batch [1260]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.101903,	
2017-07-13 11:10:20,521 Epoch[75] Batch [1270]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.101823,	
2017-07-13 11:10:28,627 Epoch[75] Batch [1280]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.101748,	
2017-07-13 11:10:36,570 Epoch[75] Batch [1290]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.101850,	
2017-07-13 11:10:44,435 Epoch[75] Batch [1300]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.101737,	
2017-07-13 11:10:52,309 Epoch[75] Batch [1310]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.101679,	
2017-07-13 11:11:00,305 Epoch[75] Batch [1320]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.101735,	
2017-07-13 11:11:08,232 Epoch[75] Batch [1330]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.101748,	
2017-07-13 11:11:16,245 Epoch[75] Batch [1340]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.101749,	
2017-07-13 11:11:24,266 Epoch[75] Batch [1350]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.101694,	
2017-07-13 11:11:32,273 Epoch[75] Batch [1360]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.101748,	
2017-07-13 11:11:40,271 Epoch[75] Batch [1370]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.101701,	
2017-07-13 11:11:48,314 Epoch[75] Batch [1380]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.101621,	
2017-07-13 11:11:56,313 Epoch[75] Batch [1390]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.101601,	
2017-07-13 11:12:04,399 Epoch[75] Batch [1400]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.101484,	
2017-07-13 11:12:12,594 Epoch[75] Batch [1410]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.101383,	
2017-07-13 11:12:20,813 Epoch[75] Batch [1420]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.101258,	
2017-07-13 11:12:28,885 Epoch[75] Batch [1430]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.101171,	
2017-07-13 11:12:37,253 Epoch[75] Batch [1440]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.101224,	
2017-07-13 11:12:45,432 Epoch[75] Batch [1450]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.101322,	
2017-07-13 11:12:53,879 Epoch[75] Batch [1460]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.102217,	
2017-07-13 11:13:02,560 Epoch[75] Batch [1470]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.102531,	
2017-07-13 11:13:11,195 Epoch[75] Batch [1480]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.102801,	
2017-07-13 11:13:16,217 Epoch[75] Train-FCNLogLoss=0.102898
2017-07-13 11:13:16,217 Epoch[75] Time cost=1201.237
2017-07-13 11:13:17,146 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0076.params"
2017-07-13 11:13:20,975 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0076.states"
2017-07-13 11:13:30,753 Epoch[76] Batch [10]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.109350,	
2017-07-13 11:13:39,072 Epoch[76] Batch [20]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.117662,	
2017-07-13 11:13:47,499 Epoch[76] Batch [30]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.111518,	
2017-07-13 11:13:55,377 Epoch[76] Batch [40]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.109593,	
2017-07-13 11:14:03,654 Epoch[76] Batch [50]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.109646,	
2017-07-13 11:14:12,726 Epoch[76] Batch [60]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.109253,	
2017-07-13 11:14:21,950 Epoch[76] Batch [70]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.106617,	
2017-07-13 11:14:31,084 Epoch[76] Batch [80]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.105961,	
2017-07-13 11:14:39,190 Epoch[76] Batch [90]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.105123,	
2017-07-13 11:14:47,006 Epoch[76] Batch [100]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.109410,	
2017-07-13 11:14:55,013 Epoch[76] Batch [110]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.110318,	
2017-07-13 11:15:03,296 Epoch[76] Batch [120]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.111703,	
2017-07-13 11:15:11,208 Epoch[76] Batch [130]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.115609,	
2017-07-13 11:15:19,430 Epoch[76] Batch [140]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.115502,	
2017-07-13 11:15:27,430 Epoch[76] Batch [150]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.114274,	
2017-07-13 11:15:35,507 Epoch[76] Batch [160]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.113713,	
2017-07-13 11:15:43,551 Epoch[76] Batch [170]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.113795,	
2017-07-13 11:15:51,684 Epoch[76] Batch [180]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.113010,	
2017-07-13 11:15:59,934 Epoch[76] Batch [190]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.112358,	
2017-07-13 11:16:07,807 Epoch[76] Batch [200]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.111403,	
2017-07-13 11:16:16,061 Epoch[76] Batch [210]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.110768,	
2017-07-13 11:16:24,377 Epoch[76] Batch [220]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.109650,	
2017-07-13 11:16:34,132 Epoch[76] Batch [230]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.108722,	
2017-07-13 11:16:49,648 Epoch[76] Batch [240]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.108656,	
2017-07-13 11:17:06,440 Epoch[76] Batch [250]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.108424,	
2017-07-13 11:17:22,807 Epoch[76] Batch [260]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.108345,	
2017-07-13 11:17:37,126 Epoch[76] Batch [270]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.107647,	
2017-07-13 11:17:52,690 Epoch[76] Batch [280]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.106849,	
2017-07-13 11:18:07,108 Epoch[76] Batch [290]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.106307,	
2017-07-13 11:18:22,277 Epoch[76] Batch [300]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.105913,	
2017-07-13 11:18:38,024 Epoch[76] Batch [310]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.105528,	
2017-07-13 11:18:54,306 Epoch[76] Batch [320]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.104859,	
2017-07-13 11:19:12,201 Epoch[76] Batch [330]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.104533,	
2017-07-13 11:19:27,786 Epoch[76] Batch [340]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.104231,	
2017-07-13 11:19:42,894 Epoch[76] Batch [350]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.103999,	
2017-07-13 11:20:02,708 Epoch[76] Batch [360]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.103640,	
2017-07-13 11:20:20,141 Epoch[76] Batch [370]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.103584,	
2017-07-13 11:20:36,384 Epoch[76] Batch [380]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.103103,	
2017-07-13 11:20:52,459 Epoch[76] Batch [390]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.102685,	
2017-07-13 11:21:07,861 Epoch[76] Batch [400]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.102285,	
2017-07-13 11:21:25,133 Epoch[76] Batch [410]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.101886,	
2017-07-13 11:21:39,736 Epoch[76] Batch [420]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.101562,	
2017-07-13 11:21:55,914 Epoch[76] Batch [430]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.101226,	
2017-07-13 11:22:10,999 Epoch[76] Batch [440]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.100748,	
2017-07-13 11:22:29,136 Epoch[76] Batch [450]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.100331,	
2017-07-13 11:22:47,899 Epoch[76] Batch [460]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.100877,	
2017-07-13 11:23:08,265 Epoch[76] Batch [470]	Speed: 1.96 samples/sec	Train-FCNLogLoss=0.101916,	
2017-07-13 11:23:25,944 Epoch[76] Batch [480]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.102011,	
2017-07-13 11:23:42,174 Epoch[76] Batch [490]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.102086,	
2017-07-13 11:23:58,188 Epoch[76] Batch [500]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.102244,	
2017-07-13 11:24:13,196 Epoch[76] Batch [510]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.101975,	
2017-07-13 11:24:29,751 Epoch[76] Batch [520]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.101903,	
2017-07-13 11:24:48,629 Epoch[76] Batch [530]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.101970,	
2017-07-13 11:25:05,885 Epoch[76] Batch [540]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.101757,	
2017-07-13 11:25:23,780 Epoch[76] Batch [550]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.101760,	
2017-07-13 11:25:43,527 Epoch[76] Batch [560]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.101489,	
2017-07-13 11:26:02,021 Epoch[76] Batch [570]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.101375,	
2017-07-13 11:26:21,272 Epoch[76] Batch [580]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.101102,	
2017-07-13 11:26:40,109 Epoch[76] Batch [590]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.100990,	
2017-07-13 11:26:54,150 Epoch[76] Batch [600]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.100708,	
2017-07-13 11:27:12,363 Epoch[76] Batch [610]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.100609,	
2017-07-13 11:27:29,270 Epoch[76] Batch [620]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.100410,	
2017-07-13 11:27:47,649 Epoch[76] Batch [630]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.100236,	
2017-07-13 11:28:04,112 Epoch[76] Batch [640]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.100146,	
2017-07-13 11:28:20,088 Epoch[76] Batch [650]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.100034,	
2017-07-13 11:28:35,298 Epoch[76] Batch [660]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.099839,	
2017-07-13 11:28:51,991 Epoch[76] Batch [670]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.099675,	
2017-07-13 11:29:08,371 Epoch[76] Batch [680]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.099587,	
2017-07-13 11:29:25,769 Epoch[76] Batch [690]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.099284,	
2017-07-13 11:29:44,602 Epoch[76] Batch [700]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.099108,	
2017-07-13 11:30:00,636 Epoch[76] Batch [710]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.099101,	
2017-07-13 11:30:21,487 Epoch[76] Batch [720]	Speed: 1.92 samples/sec	Train-FCNLogLoss=0.098949,	
2017-07-13 11:30:41,137 Epoch[76] Batch [730]	Speed: 2.04 samples/sec	Train-FCNLogLoss=0.098795,	
2017-07-13 11:31:00,332 Epoch[76] Batch [740]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.098668,	
2017-07-13 11:31:16,954 Epoch[76] Batch [750]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.098600,	
2017-07-13 11:31:33,787 Epoch[76] Batch [760]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.098455,	
2017-07-13 11:31:51,180 Epoch[76] Batch [770]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.098322,	
2017-07-13 11:32:09,001 Epoch[76] Batch [780]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.098241,	
2017-07-13 11:32:26,877 Epoch[76] Batch [790]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.098006,	
2017-07-13 11:32:44,979 Epoch[76] Batch [800]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.097708,	
2017-07-13 11:33:00,794 Epoch[76] Batch [810]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.097581,	
2017-07-13 11:33:18,301 Epoch[76] Batch [820]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.097579,	
2017-07-13 11:33:38,005 Epoch[76] Batch [830]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.097347,	
2017-07-13 11:33:56,613 Epoch[76] Batch [840]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.098134,	
2017-07-13 11:34:13,891 Epoch[76] Batch [850]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.098476,	
2017-07-13 11:34:29,283 Epoch[76] Batch [860]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.098644,	
2017-07-13 11:34:47,714 Epoch[76] Batch [870]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.098835,	
2017-07-13 11:35:05,462 Epoch[76] Batch [880]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.099090,	
2017-07-13 11:35:23,774 Epoch[76] Batch [890]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.099139,	
2017-07-13 11:35:43,342 Epoch[76] Batch [900]	Speed: 2.04 samples/sec	Train-FCNLogLoss=0.099126,	
2017-07-13 11:36:00,461 Epoch[76] Batch [910]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.099185,	
2017-07-13 11:36:18,597 Epoch[76] Batch [920]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.099094,	
2017-07-13 11:36:34,343 Epoch[76] Batch [930]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.099054,	
2017-07-13 11:36:53,736 Epoch[76] Batch [940]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.099026,	
2017-07-13 11:37:10,635 Epoch[76] Batch [950]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.098950,	
2017-07-13 11:37:26,521 Epoch[76] Batch [960]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.098963,	
2017-07-13 11:37:42,347 Epoch[76] Batch [970]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.098860,	
2017-07-13 11:38:01,282 Epoch[76] Batch [980]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.098829,	
2017-07-13 11:38:17,753 Epoch[76] Batch [990]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.098806,	
2017-07-13 11:38:35,476 Epoch[76] Batch [1000]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.098647,	
2017-07-13 11:38:53,028 Epoch[76] Batch [1010]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.098574,	
2017-07-13 11:39:12,963 Epoch[76] Batch [1020]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.098537,	
2017-07-13 11:39:30,528 Epoch[76] Batch [1030]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.098558,	
2017-07-13 11:39:46,197 Epoch[76] Batch [1040]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.098400,	
2017-07-13 11:40:04,716 Epoch[76] Batch [1050]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.098450,	
2017-07-13 11:40:23,390 Epoch[76] Batch [1060]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.098405,	
2017-07-13 11:40:37,441 Epoch[76] Batch [1070]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.098385,	
2017-07-13 11:40:56,942 Epoch[76] Batch [1080]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.098248,	
2017-07-13 11:41:13,258 Epoch[76] Batch [1090]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.098213,	
2017-07-13 11:41:32,100 Epoch[76] Batch [1100]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.098212,	
2017-07-13 11:41:53,243 Epoch[76] Batch [1110]	Speed: 1.89 samples/sec	Train-FCNLogLoss=0.098100,	
2017-07-13 11:42:11,027 Epoch[76] Batch [1120]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.098072,	
2017-07-13 11:42:28,859 Epoch[76] Batch [1130]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.097979,	
2017-07-13 11:42:47,630 Epoch[76] Batch [1140]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.097955,	
2017-07-13 11:43:07,473 Epoch[76] Batch [1150]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.097909,	
2017-07-13 11:43:24,271 Epoch[76] Batch [1160]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.097803,	
2017-07-13 11:43:41,849 Epoch[76] Batch [1170]	Speed: 2.28 samples/sec	Train-FCNLogLoss=0.097755,	
2017-07-13 11:43:57,321 Epoch[76] Batch [1180]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.097592,	
2017-07-13 11:44:16,092 Epoch[76] Batch [1190]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.097489,	
2017-07-13 11:44:36,136 Epoch[76] Batch [1200]	Speed: 2.00 samples/sec	Train-FCNLogLoss=0.097389,	
2017-07-13 11:44:55,470 Epoch[76] Batch [1210]	Speed: 2.07 samples/sec	Train-FCNLogLoss=0.097338,	
2017-07-13 11:45:14,571 Epoch[76] Batch [1220]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.097164,	
2017-07-13 11:45:31,005 Epoch[76] Batch [1230]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.097131,	
2017-07-13 11:45:47,068 Epoch[76] Batch [1240]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.097095,	
2017-07-13 11:46:04,727 Epoch[76] Batch [1250]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.096936,	
2017-07-13 11:46:23,093 Epoch[76] Batch [1260]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.096848,	
2017-07-13 11:46:42,496 Epoch[76] Batch [1270]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.096764,	
2017-07-13 11:46:58,690 Epoch[76] Batch [1280]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.096657,	
2017-07-13 11:47:18,063 Epoch[76] Batch [1290]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.096507,	
2017-07-13 11:47:33,859 Epoch[76] Batch [1300]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.096368,	
2017-07-13 11:47:52,983 Epoch[76] Batch [1310]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.096277,	
2017-07-13 11:48:12,839 Epoch[76] Batch [1320]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.096099,	
2017-07-13 11:48:30,422 Epoch[76] Batch [1330]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.095990,	
2017-07-13 11:48:46,973 Epoch[76] Batch [1340]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.095892,	
2017-07-13 11:49:03,753 Epoch[76] Batch [1350]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.095831,	
2017-07-13 11:49:21,066 Epoch[76] Batch [1360]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.095729,	
2017-07-13 11:49:39,872 Epoch[76] Batch [1370]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.095650,	
2017-07-13 11:49:58,036 Epoch[76] Batch [1380]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.095664,	
2017-07-13 11:50:15,659 Epoch[76] Batch [1390]	Speed: 2.27 samples/sec	Train-FCNLogLoss=0.095589,	
2017-07-13 11:50:31,093 Epoch[76] Batch [1400]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.095528,	
2017-07-13 11:50:47,217 Epoch[76] Batch [1410]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.095451,	
2017-07-13 11:51:04,125 Epoch[76] Batch [1420]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.095449,	
2017-07-13 11:51:20,725 Epoch[76] Batch [1430]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.095350,	
2017-07-13 11:51:37,700 Epoch[76] Batch [1440]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.095319,	
2017-07-13 11:51:53,869 Epoch[76] Batch [1450]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.095272,	
2017-07-13 11:52:15,133 Epoch[76] Batch [1460]	Speed: 1.88 samples/sec	Train-FCNLogLoss=0.095197,	
2017-07-13 11:52:31,065 Epoch[76] Batch [1470]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.095127,	
2017-07-13 11:52:51,370 Epoch[76] Batch [1480]	Speed: 1.97 samples/sec	Train-FCNLogLoss=0.095026,	
2017-07-13 11:53:02,311 Epoch[76] Train-FCNLogLoss=0.094975
2017-07-13 11:53:02,311 Epoch[76] Time cost=2381.336
2017-07-13 11:53:05,154 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0077.params"
2017-07-13 11:53:25,172 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0077.states"
2017-07-13 11:53:43,330 Epoch[77] Batch [10]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.085969,	
2017-07-13 11:54:01,797 Epoch[77] Batch [20]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.088774,	
2017-07-13 11:54:19,643 Epoch[77] Batch [30]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.086811,	
2017-07-13 11:54:38,692 Epoch[77] Batch [40]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.085450,	
2017-07-13 11:54:55,924 Epoch[77] Batch [50]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.084250,	
2017-07-13 11:55:14,323 Epoch[77] Batch [60]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.084908,	
2017-07-13 11:55:35,209 Epoch[77] Batch [70]	Speed: 1.92 samples/sec	Train-FCNLogLoss=0.084619,	
2017-07-13 11:55:55,333 Epoch[77] Batch [80]	Speed: 1.99 samples/sec	Train-FCNLogLoss=0.084139,	
2017-07-13 11:56:19,159 Epoch[77] Batch [90]	Speed: 1.68 samples/sec	Train-FCNLogLoss=0.084415,	
2017-07-13 11:56:44,949 Epoch[77] Batch [100]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.084454,	
2017-07-13 11:57:09,575 Epoch[77] Batch [110]	Speed: 1.62 samples/sec	Train-FCNLogLoss=0.084175,	
2017-07-13 11:57:33,384 Epoch[77] Batch [120]	Speed: 1.68 samples/sec	Train-FCNLogLoss=0.083929,	
2017-07-13 11:57:56,593 Epoch[77] Batch [130]	Speed: 1.72 samples/sec	Train-FCNLogLoss=0.083944,	
2017-07-13 11:58:21,426 Epoch[77] Batch [140]	Speed: 1.61 samples/sec	Train-FCNLogLoss=0.083621,	
2017-07-13 11:58:46,782 Epoch[77] Batch [150]	Speed: 1.58 samples/sec	Train-FCNLogLoss=0.084099,	
2017-07-13 11:59:08,674 Epoch[77] Batch [160]	Speed: 1.83 samples/sec	Train-FCNLogLoss=0.084759,	
2017-07-13 11:59:29,034 Epoch[77] Batch [170]	Speed: 1.96 samples/sec	Train-FCNLogLoss=0.085828,	
2017-07-13 11:59:54,914 Epoch[77] Batch [180]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.087635,	
2017-07-13 12:00:17,208 Epoch[77] Batch [190]	Speed: 1.79 samples/sec	Train-FCNLogLoss=0.089016,	
2017-07-13 12:00:40,421 Epoch[77] Batch [200]	Speed: 1.72 samples/sec	Train-FCNLogLoss=0.089836,	
2017-07-13 12:01:06,626 Epoch[77] Batch [210]	Speed: 1.53 samples/sec	Train-FCNLogLoss=0.090854,	
2017-07-13 12:01:30,240 Epoch[77] Batch [220]	Speed: 1.69 samples/sec	Train-FCNLogLoss=0.091569,	
2017-07-13 12:01:56,056 Epoch[77] Batch [230]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.092138,	
2017-07-13 12:02:18,322 Epoch[77] Batch [240]	Speed: 1.80 samples/sec	Train-FCNLogLoss=0.092374,	
2017-07-13 12:02:39,834 Epoch[77] Batch [250]	Speed: 1.86 samples/sec	Train-FCNLogLoss=0.092032,	
2017-07-13 12:03:03,066 Epoch[77] Batch [260]	Speed: 1.72 samples/sec	Train-FCNLogLoss=0.092094,	
2017-07-13 12:03:23,803 Epoch[77] Batch [270]	Speed: 1.93 samples/sec	Train-FCNLogLoss=0.092093,	
2017-07-13 12:03:47,818 Epoch[77] Batch [280]	Speed: 1.67 samples/sec	Train-FCNLogLoss=0.092141,	
2017-07-13 12:04:08,653 Epoch[77] Batch [290]	Speed: 1.92 samples/sec	Train-FCNLogLoss=0.092328,	
2017-07-13 12:04:25,492 Epoch[77] Batch [300]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.092448,	
2017-07-13 12:04:43,426 Epoch[77] Batch [310]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.092289,	
2017-07-13 12:05:01,491 Epoch[77] Batch [320]	Speed: 2.21 samples/sec	Train-FCNLogLoss=0.092219,	
2017-07-13 12:05:16,600 Epoch[77] Batch [330]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.091901,	
2017-07-13 12:05:35,754 Epoch[77] Batch [340]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.091853,	
2017-07-13 12:05:54,208 Epoch[77] Batch [350]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.091739,	
2017-07-13 12:06:10,542 Epoch[77] Batch [360]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.091327,	
2017-07-13 12:06:31,455 Epoch[77] Batch [370]	Speed: 1.91 samples/sec	Train-FCNLogLoss=0.091161,	
2017-07-13 12:06:48,627 Epoch[77] Batch [380]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.090924,	
2017-07-13 12:07:04,605 Epoch[77] Batch [390]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.090721,	
2017-07-13 12:07:20,372 Epoch[77] Batch [400]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.090499,	
2017-07-13 12:07:41,287 Epoch[77] Batch [410]	Speed: 1.91 samples/sec	Train-FCNLogLoss=0.090246,	
2017-07-13 12:08:00,013 Epoch[77] Batch [420]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.089935,	
2017-07-13 12:08:16,897 Epoch[77] Batch [430]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.089763,	
2017-07-13 12:08:30,495 Epoch[77] Batch [440]	Speed: 2.94 samples/sec	Train-FCNLogLoss=0.089600,	
2017-07-13 12:08:44,855 Epoch[77] Batch [450]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.089159,	
2017-07-13 12:08:58,832 Epoch[77] Batch [460]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.088993,	
2017-07-13 12:09:14,027 Epoch[77] Batch [470]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.088741,	
2017-07-13 12:09:32,071 Epoch[77] Batch [480]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.088517,	
2017-07-13 12:09:50,433 Epoch[77] Batch [490]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.088538,	
2017-07-13 12:10:07,786 Epoch[77] Batch [500]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.088426,	
2017-07-13 12:10:22,788 Epoch[77] Batch [510]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.088618,	
2017-07-13 12:10:39,332 Epoch[77] Batch [520]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.088549,	
2017-07-13 12:11:00,448 Epoch[77] Batch [530]	Speed: 1.89 samples/sec	Train-FCNLogLoss=0.088327,	
2017-07-13 12:11:20,003 Epoch[77] Batch [540]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.088277,	
2017-07-13 12:11:35,820 Epoch[77] Batch [550]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.088180,	
2017-07-13 12:11:50,984 Epoch[77] Batch [560]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.088156,	
2017-07-13 12:12:07,008 Epoch[77] Batch [570]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.088201,	
2017-07-13 12:12:23,008 Epoch[77] Batch [580]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.088412,	
2017-07-13 12:12:39,175 Epoch[77] Batch [590]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.088451,	
2017-07-13 12:12:55,027 Epoch[77] Batch [600]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.088371,	
2017-07-13 12:13:10,211 Epoch[77] Batch [610]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.088285,	
2017-07-13 12:13:26,954 Epoch[77] Batch [620]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.088398,	
2017-07-13 12:13:43,863 Epoch[77] Batch [630]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.088324,	
2017-07-13 12:13:58,080 Epoch[77] Batch [640]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.088208,	
2017-07-13 12:14:13,637 Epoch[77] Batch [650]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.088082,	
2017-07-13 12:14:28,755 Epoch[77] Batch [660]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.088119,	
2017-07-13 12:14:45,613 Epoch[77] Batch [670]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.088106,	
2017-07-13 12:15:01,707 Epoch[77] Batch [680]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.088011,	
2017-07-13 12:15:18,168 Epoch[77] Batch [690]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.087820,	
2017-07-13 12:15:35,353 Epoch[77] Batch [700]	Speed: 2.33 samples/sec	Train-FCNLogLoss=0.087661,	
2017-07-13 12:15:54,808 Epoch[77] Batch [710]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.087552,	
2017-07-13 12:16:13,177 Epoch[77] Batch [720]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.087452,	
2017-07-13 12:16:31,016 Epoch[77] Batch [730]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.087341,	
2017-07-13 12:16:49,285 Epoch[77] Batch [740]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.087265,	
2017-07-13 12:17:07,862 Epoch[77] Batch [750]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.088053,	
2017-07-13 12:17:27,029 Epoch[77] Batch [760]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.089470,	
2017-07-13 12:17:50,302 Epoch[77] Batch [770]	Speed: 1.72 samples/sec	Train-FCNLogLoss=0.090355,	
2017-07-13 12:18:11,629 Epoch[77] Batch [780]	Speed: 1.88 samples/sec	Train-FCNLogLoss=0.091345,	
2017-07-13 12:18:32,369 Epoch[77] Batch [790]	Speed: 1.93 samples/sec	Train-FCNLogLoss=0.092281,	
2017-07-13 12:18:53,619 Epoch[77] Batch [800]	Speed: 1.88 samples/sec	Train-FCNLogLoss=0.092528,	
2017-07-13 12:19:15,059 Epoch[77] Batch [810]	Speed: 1.87 samples/sec	Train-FCNLogLoss=0.092607,	
2017-07-13 12:19:37,676 Epoch[77] Batch [820]	Speed: 1.77 samples/sec	Train-FCNLogLoss=0.092699,	
2017-07-13 12:19:57,116 Epoch[77] Batch [830]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.092799,	
2017-07-13 12:20:16,435 Epoch[77] Batch [840]	Speed: 2.07 samples/sec	Train-FCNLogLoss=0.092801,	
2017-07-13 12:20:36,407 Epoch[77] Batch [850]	Speed: 2.00 samples/sec	Train-FCNLogLoss=0.092725,	
2017-07-13 12:20:55,668 Epoch[77] Batch [860]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.092723,	
2017-07-13 12:21:13,926 Epoch[77] Batch [870]	Speed: 2.19 samples/sec	Train-FCNLogLoss=0.092679,	
2017-07-13 12:21:30,969 Epoch[77] Batch [880]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.092792,	
2017-07-13 12:21:46,241 Epoch[77] Batch [890]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.092881,	
2017-07-13 12:22:04,233 Epoch[77] Batch [900]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.092920,	
2017-07-13 12:22:24,850 Epoch[77] Batch [910]	Speed: 1.94 samples/sec	Train-FCNLogLoss=0.092945,	
2017-07-13 12:22:44,104 Epoch[77] Batch [920]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.092963,	
2017-07-13 12:23:03,295 Epoch[77] Batch [930]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.092887,	
2017-07-13 12:23:22,550 Epoch[77] Batch [940]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.092972,	
2017-07-13 12:23:42,088 Epoch[77] Batch [950]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.092908,	
2017-07-13 12:23:59,772 Epoch[77] Batch [960]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.092981,	
2017-07-13 12:24:17,717 Epoch[77] Batch [970]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.092898,	
2017-07-13 12:24:33,742 Epoch[77] Batch [980]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.092908,	
2017-07-13 12:24:49,656 Epoch[77] Batch [990]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.092808,	
2017-07-13 12:25:06,559 Epoch[77] Batch [1000]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.092808,	
2017-07-13 12:25:23,636 Epoch[77] Batch [1010]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.092773,	
2017-07-13 12:25:38,163 Epoch[77] Batch [1020]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.092725,	
2017-07-13 12:25:55,162 Epoch[77] Batch [1030]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.092723,	
2017-07-13 12:26:11,941 Epoch[77] Batch [1040]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.093174,	
2017-07-13 12:26:27,042 Epoch[77] Batch [1050]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.093495,	
2017-07-13 12:26:44,011 Epoch[77] Batch [1060]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.093578,	
2017-07-13 12:27:00,879 Epoch[77] Batch [1070]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.093643,	
2017-07-13 12:27:16,431 Epoch[77] Batch [1080]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.093666,	
2017-07-13 12:27:31,218 Epoch[77] Batch [1090]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.093697,	
2017-07-13 12:27:47,709 Epoch[77] Batch [1100]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.093693,	
2017-07-13 12:28:03,613 Epoch[77] Batch [1110]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.093605,	
2017-07-13 12:28:20,145 Epoch[77] Batch [1120]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.093582,	
2017-07-13 12:28:36,836 Epoch[77] Batch [1130]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.093485,	
2017-07-13 12:28:55,807 Epoch[77] Batch [1140]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.093516,	
2017-07-13 12:29:15,540 Epoch[77] Batch [1150]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.093526,	
2017-07-13 12:29:35,123 Epoch[77] Batch [1160]	Speed: 2.04 samples/sec	Train-FCNLogLoss=0.093422,	
2017-07-13 12:29:54,117 Epoch[77] Batch [1170]	Speed: 2.11 samples/sec	Train-FCNLogLoss=0.093334,	
2017-07-13 12:30:11,785 Epoch[77] Batch [1180]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.093213,	
2017-07-13 12:30:29,023 Epoch[77] Batch [1190]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.093143,	
2017-07-13 12:30:46,720 Epoch[77] Batch [1200]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.093123,	
2017-07-13 12:31:05,173 Epoch[77] Batch [1210]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.093066,	
2017-07-13 12:31:23,393 Epoch[77] Batch [1220]	Speed: 2.20 samples/sec	Train-FCNLogLoss=0.092977,	
2017-07-13 12:31:40,404 Epoch[77] Batch [1230]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.092976,	
2017-07-13 12:31:56,628 Epoch[77] Batch [1240]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.092960,	
2017-07-13 12:32:13,581 Epoch[77] Batch [1250]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.092886,	
2017-07-13 12:32:30,621 Epoch[77] Batch [1260]	Speed: 2.35 samples/sec	Train-FCNLogLoss=0.092880,	
2017-07-13 12:32:49,022 Epoch[77] Batch [1270]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.092781,	
2017-07-13 12:33:06,516 Epoch[77] Batch [1280]	Speed: 2.29 samples/sec	Train-FCNLogLoss=0.092691,	
2017-07-13 12:33:20,681 Epoch[77] Batch [1290]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.092578,	
2017-07-13 12:33:30,261 Epoch[77] Batch [1300]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.092507,	
2017-07-13 12:33:38,778 Epoch[77] Batch [1310]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.092409,	
2017-07-13 12:33:46,963 Epoch[77] Batch [1320]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.092349,	
2017-07-13 12:33:55,216 Epoch[77] Batch [1330]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.092336,	
2017-07-13 12:34:03,622 Epoch[77] Batch [1340]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.092333,	
2017-07-13 12:34:11,912 Epoch[77] Batch [1350]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.092258,	
2017-07-13 12:34:20,240 Epoch[77] Batch [1360]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.092244,	
2017-07-13 12:34:28,611 Epoch[77] Batch [1370]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.092258,	
2017-07-13 12:34:36,855 Epoch[77] Batch [1380]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.092197,	
2017-07-13 12:34:45,312 Epoch[77] Batch [1390]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.092127,	
2017-07-13 12:34:53,727 Epoch[77] Batch [1400]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.092037,	
2017-07-13 12:35:02,123 Epoch[77] Batch [1410]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.091999,	
2017-07-13 12:35:10,363 Epoch[77] Batch [1420]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.091992,	
2017-07-13 12:35:18,762 Epoch[77] Batch [1430]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.091980,	
2017-07-13 12:35:27,125 Epoch[77] Batch [1440]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.091924,	
2017-07-13 12:35:35,653 Epoch[77] Batch [1450]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.091847,	
2017-07-13 12:35:43,874 Epoch[77] Batch [1460]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.091802,	
2017-07-13 12:35:52,221 Epoch[77] Batch [1470]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.091721,	
2017-07-13 12:36:00,575 Epoch[77] Batch [1480]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.091753,	
2017-07-13 12:36:05,630 Epoch[77] Train-FCNLogLoss=0.091743
2017-07-13 12:36:05,631 Epoch[77] Time cost=2560.457
2017-07-13 12:36:06,568 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0078.params"
2017-07-13 12:36:10,099 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0078.states"
2017-07-13 12:36:19,599 Epoch[78] Batch [10]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.094668,	
2017-07-13 12:36:27,889 Epoch[78] Batch [20]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.094290,	
2017-07-13 12:36:36,179 Epoch[78] Batch [30]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.092684,	
2017-07-13 12:36:44,490 Epoch[78] Batch [40]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.089895,	
2017-07-13 12:36:52,683 Epoch[78] Batch [50]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.089685,	
2017-07-13 12:37:01,023 Epoch[78] Batch [60]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.088859,	
2017-07-13 12:37:09,345 Epoch[78] Batch [70]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.089126,	
2017-07-13 12:37:17,784 Epoch[78] Batch [80]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.088801,	
2017-07-13 12:37:25,170 Epoch[78] Batch [90]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.088349,	
2017-07-13 12:37:33,047 Epoch[78] Batch [100]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.087214,	
2017-07-13 12:37:40,616 Epoch[78] Batch [110]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.087228,	
2017-07-13 12:37:47,769 Epoch[78] Batch [120]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.087060,	
2017-07-13 12:37:54,766 Epoch[78] Batch [130]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.086826,	
2017-07-13 12:38:01,846 Epoch[78] Batch [140]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.087173,	
2017-07-13 12:38:08,973 Epoch[78] Batch [150]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.086528,	
2017-07-13 12:38:15,837 Epoch[78] Batch [160]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.086130,	
2017-07-13 12:38:22,718 Epoch[78] Batch [170]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.085977,	
2017-07-13 12:38:29,683 Epoch[78] Batch [180]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.085599,	
2017-07-13 12:38:37,084 Epoch[78] Batch [190]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.085289,	
2017-07-13 12:38:44,405 Epoch[78] Batch [200]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.085448,	
2017-07-13 12:38:51,467 Epoch[78] Batch [210]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.085403,	
2017-07-13 12:38:58,655 Epoch[78] Batch [220]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.085194,	
2017-07-13 12:39:06,030 Epoch[78] Batch [230]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.085016,	
2017-07-13 12:39:12,936 Epoch[78] Batch [240]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.084760,	
2017-07-13 12:39:19,655 Epoch[78] Batch [250]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.084922,	
2017-07-13 12:39:26,586 Epoch[78] Batch [260]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.085110,	
2017-07-13 12:39:33,645 Epoch[78] Batch [270]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.085118,	
2017-07-13 12:39:40,960 Epoch[78] Batch [280]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.084720,	
2017-07-13 12:39:47,903 Epoch[78] Batch [290]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.084511,	
2017-07-13 12:39:55,073 Epoch[78] Batch [300]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.084347,	
2017-07-13 12:40:02,299 Epoch[78] Batch [310]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.084030,	
2017-07-13 12:40:09,647 Epoch[78] Batch [320]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.084210,	
2017-07-13 12:40:16,976 Epoch[78] Batch [330]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.084105,	
2017-07-13 12:40:24,408 Epoch[78] Batch [340]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.083981,	
2017-07-13 12:40:32,019 Epoch[78] Batch [350]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.083978,	
2017-07-13 12:40:39,356 Epoch[78] Batch [360]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.084132,	
2017-07-13 12:40:46,718 Epoch[78] Batch [370]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.084177,	
2017-07-13 12:40:54,808 Epoch[78] Batch [380]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.084241,	
2017-07-13 12:41:02,732 Epoch[78] Batch [390]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.084246,	
2017-07-13 12:41:10,766 Epoch[78] Batch [400]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.084140,	
2017-07-13 12:41:18,809 Epoch[78] Batch [410]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.083726,	
2017-07-13 12:41:26,900 Epoch[78] Batch [420]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.083805,	
2017-07-13 12:41:34,828 Epoch[78] Batch [430]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.083494,	
2017-07-13 12:41:42,942 Epoch[78] Batch [440]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.083442,	
2017-07-13 12:41:50,960 Epoch[78] Batch [450]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.083749,	
2017-07-13 12:41:59,162 Epoch[78] Batch [460]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.083577,	
2017-07-13 12:42:07,107 Epoch[78] Batch [470]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.083324,	
2017-07-13 12:42:15,162 Epoch[78] Batch [480]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.083338,	
2017-07-13 12:42:23,128 Epoch[78] Batch [490]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.083208,	
2017-07-13 12:42:31,218 Epoch[78] Batch [500]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.083082,	
2017-07-13 12:42:39,125 Epoch[78] Batch [510]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.083152,	
2017-07-13 12:42:46,913 Epoch[78] Batch [520]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.083048,	
2017-07-13 12:42:55,047 Epoch[78] Batch [530]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.082993,	
2017-07-13 12:43:02,772 Epoch[78] Batch [540]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.082909,	
2017-07-13 12:43:10,424 Epoch[78] Batch [550]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.082825,	
2017-07-13 12:43:18,229 Epoch[78] Batch [560]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.082926,	
2017-07-13 12:43:25,739 Epoch[78] Batch [570]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.083095,	
2017-07-13 12:43:33,511 Epoch[78] Batch [580]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.083113,	
2017-07-13 12:43:41,036 Epoch[78] Batch [590]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.082984,	
2017-07-13 12:43:48,386 Epoch[78] Batch [600]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.082983,	
2017-07-13 12:43:55,696 Epoch[78] Batch [610]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.082987,	
2017-07-13 12:44:03,047 Epoch[78] Batch [620]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.082877,	
2017-07-13 12:44:10,422 Epoch[78] Batch [630]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.083068,	
2017-07-13 12:44:18,075 Epoch[78] Batch [640]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.083148,	
2017-07-13 12:44:25,734 Epoch[78] Batch [650]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.083112,	
2017-07-13 12:44:33,414 Epoch[78] Batch [660]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.083096,	
2017-07-13 12:44:41,016 Epoch[78] Batch [670]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.082939,	
2017-07-13 12:44:48,612 Epoch[78] Batch [680]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.083001,	
2017-07-13 12:44:56,220 Epoch[78] Batch [690]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.083026,	
2017-07-13 12:45:03,964 Epoch[78] Batch [700]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.082976,	
2017-07-13 12:45:11,423 Epoch[78] Batch [710]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.082972,	
2017-07-13 12:45:18,644 Epoch[78] Batch [720]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.082882,	
2017-07-13 12:45:26,340 Epoch[78] Batch [730]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.082881,	
2017-07-13 12:45:34,267 Epoch[78] Batch [740]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.082895,	
2017-07-13 12:45:41,728 Epoch[78] Batch [750]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.082993,	
2017-07-13 12:45:49,207 Epoch[78] Batch [760]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.082916,	
2017-07-13 12:45:57,024 Epoch[78] Batch [770]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.082767,	
2017-07-13 12:46:04,660 Epoch[78] Batch [780]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.082775,	
2017-07-13 12:46:12,212 Epoch[78] Batch [790]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.082818,	
2017-07-13 12:46:19,319 Epoch[78] Batch [800]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.082798,	
2017-07-13 12:46:27,088 Epoch[78] Batch [810]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.082733,	
2017-07-13 12:46:34,724 Epoch[78] Batch [820]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.082721,	
2017-07-13 12:46:42,222 Epoch[78] Batch [830]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.082612,	
2017-07-13 12:46:49,941 Epoch[78] Batch [840]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.082567,	
2017-07-13 12:46:57,848 Epoch[78] Batch [850]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.082568,	
2017-07-13 12:47:05,918 Epoch[78] Batch [860]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.082550,	
2017-07-13 12:47:13,732 Epoch[78] Batch [870]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.082537,	
2017-07-13 12:47:21,303 Epoch[78] Batch [880]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.082510,	
2017-07-13 12:47:28,780 Epoch[78] Batch [890]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.082533,	
2017-07-13 12:47:36,477 Epoch[78] Batch [900]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.082454,	
2017-07-13 12:47:44,536 Epoch[78] Batch [910]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.082483,	
2017-07-13 12:47:52,330 Epoch[78] Batch [920]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.082548,	
2017-07-13 12:48:00,277 Epoch[78] Batch [930]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082493,	
2017-07-13 12:48:08,495 Epoch[78] Batch [940]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.082444,	
2017-07-13 12:48:16,865 Epoch[78] Batch [950]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.082403,	
2017-07-13 12:48:25,083 Epoch[78] Batch [960]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.082339,	
2017-07-13 12:48:33,207 Epoch[78] Batch [970]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.082350,	
2017-07-13 12:48:41,476 Epoch[78] Batch [980]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.082365,	
2017-07-13 12:48:49,716 Epoch[78] Batch [990]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.082349,	
2017-07-13 12:48:58,015 Epoch[78] Batch [1000]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.082254,	
2017-07-13 12:49:06,038 Epoch[78] Batch [1010]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.082248,	
2017-07-13 12:49:14,283 Epoch[78] Batch [1020]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.082249,	
2017-07-13 12:49:22,266 Epoch[78] Batch [1030]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.082185,	
2017-07-13 12:49:30,444 Epoch[78] Batch [1040]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.082182,	
2017-07-13 12:49:38,402 Epoch[78] Batch [1050]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082194,	
2017-07-13 12:49:46,677 Epoch[78] Batch [1060]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.082199,	
2017-07-13 12:49:54,821 Epoch[78] Batch [1070]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.082163,	
2017-07-13 12:50:02,967 Epoch[78] Batch [1080]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.082155,	
2017-07-13 12:50:11,162 Epoch[78] Batch [1090]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.082127,	
2017-07-13 12:50:18,849 Epoch[78] Batch [1100]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.082161,	
2017-07-13 12:50:26,417 Epoch[78] Batch [1110]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.082051,	
2017-07-13 12:50:34,127 Epoch[78] Batch [1120]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.081998,	
2017-07-13 12:50:42,084 Epoch[78] Batch [1130]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082007,	
2017-07-13 12:50:50,014 Epoch[78] Batch [1140]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.082089,	
2017-07-13 12:50:57,857 Epoch[78] Batch [1150]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.082179,	
2017-07-13 12:51:06,709 Epoch[78] Batch [1160]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.082223,	
2017-07-13 12:51:15,229 Epoch[78] Batch [1170]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.082282,	
2017-07-13 12:51:23,662 Epoch[78] Batch [1180]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.082302,	
2017-07-13 12:51:32,602 Epoch[78] Batch [1190]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.082309,	
2017-07-13 12:51:41,440 Epoch[78] Batch [1200]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.082278,	
2017-07-13 12:51:49,269 Epoch[78] Batch [1210]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.082280,	
2017-07-13 12:51:56,951 Epoch[78] Batch [1220]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.082264,	
2017-07-13 12:52:04,711 Epoch[78] Batch [1230]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.082291,	
2017-07-13 12:52:12,084 Epoch[78] Batch [1240]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.082263,	
2017-07-13 12:52:19,609 Epoch[78] Batch [1250]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.082256,	
2017-07-13 12:52:27,699 Epoch[78] Batch [1260]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.082270,	
2017-07-13 12:52:35,357 Epoch[78] Batch [1270]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.082270,	
2017-07-13 12:52:42,529 Epoch[78] Batch [1280]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.082250,	
2017-07-13 12:52:50,659 Epoch[78] Batch [1290]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.082274,	
2017-07-13 12:52:58,676 Epoch[78] Batch [1300]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.082254,	
2017-07-13 12:53:06,687 Epoch[78] Batch [1310]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.082267,	
2017-07-13 12:53:14,656 Epoch[78] Batch [1320]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.082210,	
2017-07-13 12:53:22,770 Epoch[78] Batch [1330]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.082218,	
2017-07-13 12:53:30,867 Epoch[78] Batch [1340]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.082139,	
2017-07-13 12:53:38,894 Epoch[78] Batch [1350]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.082147,	
2017-07-13 12:53:46,809 Epoch[78] Batch [1360]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.082159,	
2017-07-13 12:53:54,934 Epoch[78] Batch [1370]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.082133,	
2017-07-13 12:54:02,985 Epoch[78] Batch [1380]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.082166,	
2017-07-13 12:54:11,350 Epoch[78] Batch [1390]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.082171,	
2017-07-13 12:54:19,298 Epoch[78] Batch [1400]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.082168,	
2017-07-13 12:54:27,228 Epoch[78] Batch [1410]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.082174,	
2017-07-13 12:54:34,995 Epoch[78] Batch [1420]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.082111,	
2017-07-13 12:54:43,113 Epoch[78] Batch [1430]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.082068,	
2017-07-13 12:54:50,998 Epoch[78] Batch [1440]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.082038,	
2017-07-13 12:54:59,103 Epoch[78] Batch [1450]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.082048,	
2017-07-13 12:55:07,141 Epoch[78] Batch [1460]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.082017,	
2017-07-13 12:55:15,166 Epoch[78] Batch [1470]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.082032,	
2017-07-13 12:55:22,484 Epoch[78] Batch [1480]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.081948,	
2017-07-13 12:55:26,943 Epoch[78] Train-FCNLogLoss=0.081962
2017-07-13 12:55:26,943 Epoch[78] Time cost=1156.844
2017-07-13 12:55:27,920 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0079.params"
2017-07-13 12:55:31,469 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0079.states"
2017-07-13 12:55:39,757 Epoch[79] Batch [10]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.072879,	
2017-07-13 12:55:46,932 Epoch[79] Batch [20]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.077441,	
2017-07-13 12:55:54,052 Epoch[79] Batch [30]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.077716,	
2017-07-13 12:56:01,440 Epoch[79] Batch [40]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.077299,	
2017-07-13 12:56:08,998 Epoch[79] Batch [50]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.076968,	
2017-07-13 12:56:16,671 Epoch[79] Batch [60]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.077224,	
2017-07-13 12:56:24,085 Epoch[79] Batch [70]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.078134,	
2017-07-13 12:56:31,638 Epoch[79] Batch [80]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.079306,	
2017-07-13 12:56:39,100 Epoch[79] Batch [90]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.079571,	
2017-07-13 12:56:46,639 Epoch[79] Batch [100]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.079582,	
2017-07-13 12:56:54,230 Epoch[79] Batch [110]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.078669,	
2017-07-13 12:57:01,741 Epoch[79] Batch [120]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.078744,	
2017-07-13 12:57:09,242 Epoch[79] Batch [130]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.078239,	
2017-07-13 12:57:17,053 Epoch[79] Batch [140]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.078972,	
2017-07-13 12:57:24,808 Epoch[79] Batch [150]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.078592,	
2017-07-13 12:57:32,230 Epoch[79] Batch [160]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.078058,	
2017-07-13 12:57:39,964 Epoch[79] Batch [170]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.078150,	
2017-07-13 12:57:47,561 Epoch[79] Batch [180]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.078514,	
2017-07-13 12:57:55,635 Epoch[79] Batch [190]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.078219,	
2017-07-13 12:58:03,550 Epoch[79] Batch [200]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.078104,	
2017-07-13 12:58:11,303 Epoch[79] Batch [210]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.077895,	
2017-07-13 12:58:19,216 Epoch[79] Batch [220]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.078262,	
2017-07-13 12:58:26,931 Epoch[79] Batch [230]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.078154,	
2017-07-13 12:58:34,735 Epoch[79] Batch [240]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.078275,	
2017-07-13 12:58:42,876 Epoch[79] Batch [250]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.078383,	
2017-07-13 12:58:50,673 Epoch[79] Batch [260]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.078295,	
2017-07-13 12:58:58,733 Epoch[79] Batch [270]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.078100,	
2017-07-13 12:59:06,579 Epoch[79] Batch [280]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.078466,	
2017-07-13 12:59:14,555 Epoch[79] Batch [290]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.078427,	
2017-07-13 12:59:22,219 Epoch[79] Batch [300]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.078518,	
2017-07-13 12:59:30,105 Epoch[79] Batch [310]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.078424,	
2017-07-13 12:59:37,914 Epoch[79] Batch [320]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.078680,	
2017-07-13 12:59:46,078 Epoch[79] Batch [330]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.078906,	
2017-07-13 12:59:53,863 Epoch[79] Batch [340]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.078987,	
2017-07-13 13:00:01,714 Epoch[79] Batch [350]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.078995,	
2017-07-13 13:00:09,624 Epoch[79] Batch [360]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.078743,	
2017-07-13 13:00:17,496 Epoch[79] Batch [370]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.078537,	
2017-07-13 13:00:25,182 Epoch[79] Batch [380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.078632,	
2017-07-13 13:00:32,743 Epoch[79] Batch [390]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.078580,	
2017-07-13 13:00:40,375 Epoch[79] Batch [400]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.078672,	
2017-07-13 13:00:48,179 Epoch[79] Batch [410]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.078656,	
2017-07-13 13:00:56,211 Epoch[79] Batch [420]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.078582,	
2017-07-13 13:01:03,893 Epoch[79] Batch [430]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.078516,	
2017-07-13 13:01:11,436 Epoch[79] Batch [440]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.078423,	
2017-07-13 13:01:18,996 Epoch[79] Batch [450]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.078220,	
2017-07-13 13:01:26,869 Epoch[79] Batch [460]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.078155,	
2017-07-13 13:01:34,421 Epoch[79] Batch [470]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.078259,	
2017-07-13 13:01:42,079 Epoch[79] Batch [480]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.078217,	
2017-07-13 13:01:49,612 Epoch[79] Batch [490]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.078209,	
2017-07-13 13:01:57,468 Epoch[79] Batch [500]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.078218,	
2017-07-13 13:02:05,180 Epoch[79] Batch [510]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.078183,	
2017-07-13 13:02:12,951 Epoch[79] Batch [520]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.078106,	
2017-07-13 13:02:20,890 Epoch[79] Batch [530]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.078022,	
2017-07-13 13:02:28,649 Epoch[79] Batch [540]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.078135,	
2017-07-13 13:02:36,489 Epoch[79] Batch [550]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.077973,	
2017-07-13 13:02:44,279 Epoch[79] Batch [560]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.078036,	
2017-07-13 13:02:52,212 Epoch[79] Batch [570]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.078087,	
2017-07-13 13:03:00,089 Epoch[79] Batch [580]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.078001,	
2017-07-13 13:03:07,991 Epoch[79] Batch [590]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.078221,	
2017-07-13 13:03:16,256 Epoch[79] Batch [600]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.078125,	
2017-07-13 13:03:24,130 Epoch[79] Batch [610]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.078129,	
2017-07-13 13:03:32,039 Epoch[79] Batch [620]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.078105,	
2017-07-13 13:03:40,032 Epoch[79] Batch [630]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.078174,	
2017-07-13 13:03:48,045 Epoch[79] Batch [640]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.078221,	
2017-07-13 13:03:56,047 Epoch[79] Batch [650]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.078090,	
2017-07-13 13:04:04,236 Epoch[79] Batch [660]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.078053,	
2017-07-13 13:04:12,191 Epoch[79] Batch [670]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.078068,	
2017-07-13 13:04:20,292 Epoch[79] Batch [680]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.078134,	
2017-07-13 13:04:28,292 Epoch[79] Batch [690]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.078173,	
2017-07-13 13:04:36,401 Epoch[79] Batch [700]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.078314,	
2017-07-13 13:04:44,392 Epoch[79] Batch [710]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.078437,	
2017-07-13 13:04:52,593 Epoch[79] Batch [720]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.078405,	
2017-07-13 13:05:00,627 Epoch[79] Batch [730]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.078442,	
2017-07-13 13:05:08,648 Epoch[79] Batch [740]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.078507,	
2017-07-13 13:05:16,538 Epoch[79] Batch [750]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.078655,	
2017-07-13 13:05:24,396 Epoch[79] Batch [760]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.078697,	
2017-07-13 13:05:31,502 Epoch[79] Batch [770]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.078683,	
2017-07-13 13:05:36,253 Epoch[79] Batch [780]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.078671,	
2017-07-13 13:05:41,140 Epoch[79] Batch [790]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.078728,	
2017-07-13 13:05:46,107 Epoch[79] Batch [800]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.078638,	
2017-07-13 13:05:50,700 Epoch[79] Batch [810]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.078703,	
2017-07-13 13:05:55,441 Epoch[79] Batch [820]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.078744,	
2017-07-13 13:05:59,876 Epoch[79] Batch [830]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.078850,	
2017-07-13 13:06:04,269 Epoch[79] Batch [840]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.078908,	
2017-07-13 13:06:08,934 Epoch[79] Batch [850]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.078870,	
2017-07-13 13:06:13,468 Epoch[79] Batch [860]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.078857,	
2017-07-13 13:06:18,284 Epoch[79] Batch [870]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.078938,	
2017-07-13 13:06:23,121 Epoch[79] Batch [880]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.078979,	
2017-07-13 13:06:28,457 Epoch[79] Batch [890]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.079032,	
2017-07-13 13:06:34,238 Epoch[79] Batch [900]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.079004,	
2017-07-13 13:06:39,590 Epoch[79] Batch [910]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.079029,	
2017-07-13 13:06:44,445 Epoch[79] Batch [920]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.078952,	
2017-07-13 13:06:49,521 Epoch[79] Batch [930]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.078920,	
2017-07-13 13:06:55,147 Epoch[79] Batch [940]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.078923,	
2017-07-13 13:07:00,352 Epoch[79] Batch [950]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.078929,	
2017-07-13 13:07:05,564 Epoch[79] Batch [960]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.078930,	
2017-07-13 13:07:10,505 Epoch[79] Batch [970]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.078972,	
2017-07-13 13:07:15,409 Epoch[79] Batch [980]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.078956,	
2017-07-13 13:07:20,350 Epoch[79] Batch [990]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.078902,	
2017-07-13 13:07:24,804 Epoch[79] Batch [1000]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.078898,	
2017-07-13 13:07:29,269 Epoch[79] Batch [1010]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.078887,	
2017-07-13 13:07:34,613 Epoch[79] Batch [1020]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.078868,	
2017-07-13 13:07:39,848 Epoch[79] Batch [1030]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.078952,	
2017-07-13 13:07:44,947 Epoch[79] Batch [1040]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.079015,	
2017-07-13 13:07:49,807 Epoch[79] Batch [1050]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.079068,	
2017-07-13 13:07:54,580 Epoch[79] Batch [1060]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.079102,	
2017-07-13 13:07:59,383 Epoch[79] Batch [1070]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.079107,	
2017-07-13 13:08:03,973 Epoch[79] Batch [1080]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.079115,	
2017-07-13 13:08:08,451 Epoch[79] Batch [1090]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.079148,	
2017-07-13 13:08:12,803 Epoch[79] Batch [1100]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.079161,	
2017-07-13 13:08:17,217 Epoch[79] Batch [1110]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.079208,	
2017-07-13 13:08:21,683 Epoch[79] Batch [1120]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.079226,	
2017-07-13 13:08:26,079 Epoch[79] Batch [1130]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.079147,	
2017-07-13 13:08:30,695 Epoch[79] Batch [1140]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.079178,	
2017-07-13 13:08:35,293 Epoch[79] Batch [1150]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.079201,	
2017-07-13 13:08:40,204 Epoch[79] Batch [1160]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.079232,	
2017-07-13 13:08:45,035 Epoch[79] Batch [1170]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.079213,	
2017-07-13 13:08:49,505 Epoch[79] Batch [1180]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.079368,	
2017-07-13 13:08:53,957 Epoch[79] Batch [1190]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.079489,	
2017-07-13 13:08:58,474 Epoch[79] Batch [1200]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.079489,	
2017-07-13 13:09:03,243 Epoch[79] Batch [1210]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.079542,	
2017-07-13 13:09:07,950 Epoch[79] Batch [1220]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.079490,	
2017-07-13 13:09:12,862 Epoch[79] Batch [1230]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.079507,	
2017-07-13 13:09:17,388 Epoch[79] Batch [1240]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.079500,	
2017-07-13 13:09:22,193 Epoch[79] Batch [1250]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.079552,	
2017-07-13 13:09:26,759 Epoch[79] Batch [1260]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.079519,	
2017-07-13 13:09:31,350 Epoch[79] Batch [1270]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.079492,	
2017-07-13 13:09:35,828 Epoch[79] Batch [1280]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.079501,	
2017-07-13 13:09:40,472 Epoch[79] Batch [1290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.079527,	
2017-07-13 13:09:45,166 Epoch[79] Batch [1300]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.079589,	
2017-07-13 13:09:50,067 Epoch[79] Batch [1310]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.079600,	
2017-07-13 13:09:55,238 Epoch[79] Batch [1320]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.079536,	
2017-07-13 13:10:00,015 Epoch[79] Batch [1330]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.079566,	
2017-07-13 13:10:04,599 Epoch[79] Batch [1340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.079579,	
2017-07-13 13:10:09,184 Epoch[79] Batch [1350]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.079575,	
2017-07-13 13:10:14,370 Epoch[79] Batch [1360]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.079555,	
2017-07-13 13:10:19,270 Epoch[79] Batch [1370]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.079602,	
2017-07-13 13:10:24,239 Epoch[79] Batch [1380]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.079573,	
2017-07-13 13:10:29,039 Epoch[79] Batch [1390]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.079548,	
2017-07-13 13:10:34,284 Epoch[79] Batch [1400]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.079499,	
2017-07-13 13:10:39,087 Epoch[79] Batch [1410]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.079481,	
2017-07-13 13:10:43,780 Epoch[79] Batch [1420]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.079454,	
2017-07-13 13:10:48,827 Epoch[79] Batch [1430]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.079431,	
2017-07-13 13:10:53,690 Epoch[79] Batch [1440]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.079403,	
2017-07-13 13:10:58,791 Epoch[79] Batch [1450]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.079381,	
2017-07-13 13:11:03,850 Epoch[79] Batch [1460]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.079410,	
2017-07-13 13:11:08,853 Epoch[79] Batch [1470]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.079366,	
2017-07-13 13:11:13,898 Epoch[79] Batch [1480]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.079384,	
2017-07-13 13:11:17,015 Epoch[79] Train-FCNLogLoss=0.079374
2017-07-13 13:11:17,015 Epoch[79] Time cost=945.546
2017-07-13 13:11:17,699 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0080.params"
2017-07-13 13:11:21,048 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0080.states"
2017-07-13 13:11:27,261 Epoch[80] Batch [10]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.070484,	
2017-07-13 13:11:32,623 Epoch[80] Batch [20]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.076631,	
2017-07-13 13:11:37,540 Epoch[80] Batch [30]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.078916,	
2017-07-13 13:11:42,637 Epoch[80] Batch [40]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.079313,	
2017-07-13 13:11:47,614 Epoch[80] Batch [50]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.078058,	
2017-07-13 13:11:52,899 Epoch[80] Batch [60]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.077404,	
2017-07-13 13:11:58,321 Epoch[80] Batch [70]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.077809,	
2017-07-13 13:12:03,591 Epoch[80] Batch [80]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.077338,	
2017-07-13 13:12:08,404 Epoch[80] Batch [90]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.077039,	
2017-07-13 13:12:13,591 Epoch[80] Batch [100]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.076817,	
2017-07-13 13:12:19,475 Epoch[80] Batch [110]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.076904,	
2017-07-13 13:12:24,521 Epoch[80] Batch [120]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.077365,	
2017-07-13 13:12:29,899 Epoch[80] Batch [130]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.076863,	
2017-07-13 13:12:34,976 Epoch[80] Batch [140]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.076574,	
2017-07-13 13:12:40,612 Epoch[80] Batch [150]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.076289,	
2017-07-13 13:12:46,393 Epoch[80] Batch [160]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.076232,	
2017-07-13 13:12:51,757 Epoch[80] Batch [170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.075783,	
2017-07-13 13:12:57,244 Epoch[80] Batch [180]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.075864,	
2017-07-13 13:13:02,578 Epoch[80] Batch [190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.075905,	
2017-07-13 13:13:08,363 Epoch[80] Batch [200]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.075975,	
2017-07-13 13:13:13,944 Epoch[80] Batch [210]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.076081,	
2017-07-13 13:13:19,793 Epoch[80] Batch [220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.076277,	
2017-07-13 13:13:25,047 Epoch[80] Batch [230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.076365,	
2017-07-13 13:13:30,365 Epoch[80] Batch [240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.076344,	
2017-07-13 13:13:36,020 Epoch[80] Batch [250]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.076131,	
2017-07-13 13:13:41,646 Epoch[80] Batch [260]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.076034,	
2017-07-13 13:13:47,447 Epoch[80] Batch [270]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.075981,	
2017-07-13 13:13:52,826 Epoch[80] Batch [280]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.076127,	
2017-07-13 13:13:58,191 Epoch[80] Batch [290]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.076404,	
2017-07-13 13:14:03,609 Epoch[80] Batch [300]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.076410,	
2017-07-13 13:14:09,560 Epoch[80] Batch [310]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.076303,	
2017-07-13 13:14:15,305 Epoch[80] Batch [320]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.076272,	
2017-07-13 13:14:20,763 Epoch[80] Batch [330]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.076352,	
2017-07-13 13:14:26,079 Epoch[80] Batch [340]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.076551,	
2017-07-13 13:14:31,574 Epoch[80] Batch [350]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.076260,	
2017-07-13 13:14:37,680 Epoch[80] Batch [360]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.076124,	
2017-07-13 13:14:44,032 Epoch[80] Batch [370]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.076299,	
2017-07-13 13:14:50,158 Epoch[80] Batch [380]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.076376,	
2017-07-13 13:14:55,617 Epoch[80] Batch [390]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.076314,	
2017-07-13 13:15:01,484 Epoch[80] Batch [400]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.076421,	
2017-07-13 13:15:07,379 Epoch[80] Batch [410]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.076438,	
2017-07-13 13:15:13,981 Epoch[80] Batch [420]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.076290,	
2017-07-13 13:15:20,475 Epoch[80] Batch [430]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.076428,	
2017-07-13 13:15:26,474 Epoch[80] Batch [440]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.076548,	
2017-07-13 13:15:32,033 Epoch[80] Batch [450]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.076641,	
2017-07-13 13:15:39,271 Epoch[80] Batch [460]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.076622,	
2017-07-13 13:15:45,533 Epoch[80] Batch [470]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.076769,	
2017-07-13 13:15:51,719 Epoch[80] Batch [480]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.076771,	
2017-07-13 13:15:57,545 Epoch[80] Batch [490]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.076850,	
2017-07-13 13:16:03,277 Epoch[80] Batch [500]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.077020,	
2017-07-13 13:16:08,927 Epoch[80] Batch [510]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.077045,	
2017-07-13 13:16:13,909 Epoch[80] Batch [520]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.077019,	
2017-07-13 13:16:19,454 Epoch[80] Batch [530]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.076868,	
2017-07-13 13:16:25,399 Epoch[80] Batch [540]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.076872,	
2017-07-13 13:16:30,958 Epoch[80] Batch [550]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.076921,	
2017-07-13 13:16:36,524 Epoch[80] Batch [560]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.076847,	
2017-07-13 13:16:42,350 Epoch[80] Batch [570]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.076749,	
2017-07-13 13:16:47,501 Epoch[80] Batch [580]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.076753,	
2017-07-13 13:16:53,360 Epoch[80] Batch [590]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.076664,	
2017-07-13 13:16:59,730 Epoch[80] Batch [600]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.076737,	
2017-07-13 13:17:05,299 Epoch[80] Batch [610]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.076755,	
2017-07-13 13:17:11,027 Epoch[80] Batch [620]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.076705,	
2017-07-13 13:17:16,679 Epoch[80] Batch [630]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.076612,	
2017-07-13 13:17:22,465 Epoch[80] Batch [640]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.076653,	
2017-07-13 13:17:28,480 Epoch[80] Batch [650]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.076671,	
2017-07-13 13:17:34,023 Epoch[80] Batch [660]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.076724,	
2017-07-13 13:17:39,712 Epoch[80] Batch [670]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.076654,	
2017-07-13 13:17:45,214 Epoch[80] Batch [680]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.076643,	
2017-07-13 13:17:50,301 Epoch[80] Batch [690]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.076597,	
2017-07-13 13:17:56,549 Epoch[80] Batch [700]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.076675,	
2017-07-13 13:18:02,133 Epoch[80] Batch [710]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.076678,	
2017-07-13 13:18:07,966 Epoch[80] Batch [720]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.076763,	
2017-07-13 13:18:13,989 Epoch[80] Batch [730]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.076853,	
2017-07-13 13:18:19,550 Epoch[80] Batch [740]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.077046,	
2017-07-13 13:18:25,312 Epoch[80] Batch [750]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.077126,	
2017-07-13 13:18:31,008 Epoch[80] Batch [760]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.077110,	
2017-07-13 13:18:36,770 Epoch[80] Batch [770]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.077084,	
2017-07-13 13:18:42,402 Epoch[80] Batch [780]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.077065,	
2017-07-13 13:18:47,738 Epoch[80] Batch [790]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.077026,	
2017-07-13 13:18:53,341 Epoch[80] Batch [800]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.077003,	
2017-07-13 13:18:58,907 Epoch[80] Batch [810]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.077042,	
2017-07-13 13:19:04,227 Epoch[80] Batch [820]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.077028,	
2017-07-13 13:19:10,125 Epoch[80] Batch [830]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.077040,	
2017-07-13 13:19:15,790 Epoch[80] Batch [840]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.077085,	
2017-07-13 13:19:21,360 Epoch[80] Batch [850]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.077099,	
2017-07-13 13:19:27,261 Epoch[80] Batch [860]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.077148,	
2017-07-13 13:19:32,552 Epoch[80] Batch [870]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.077100,	
2017-07-13 13:19:37,723 Epoch[80] Batch [880]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.077029,	
2017-07-13 13:19:43,386 Epoch[80] Batch [890]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.077079,	
2017-07-13 13:19:48,734 Epoch[80] Batch [900]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.077022,	
2017-07-13 13:19:54,256 Epoch[80] Batch [910]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.077068,	
2017-07-13 13:19:59,978 Epoch[80] Batch [920]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.077032,	
2017-07-13 13:20:05,956 Epoch[80] Batch [930]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.076935,	
2017-07-13 13:20:12,225 Epoch[80] Batch [940]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.076922,	
2017-07-13 13:20:17,741 Epoch[80] Batch [950]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.076926,	
2017-07-13 13:20:24,048 Epoch[80] Batch [960]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.076993,	
2017-07-13 13:20:29,819 Epoch[80] Batch [970]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.077024,	
2017-07-13 13:20:35,807 Epoch[80] Batch [980]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.077044,	
2017-07-13 13:20:41,874 Epoch[80] Batch [990]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.077005,	
2017-07-13 13:20:46,909 Epoch[80] Batch [1000]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.076986,	
2017-07-13 13:20:52,904 Epoch[80] Batch [1010]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.076951,	
2017-07-13 13:20:58,815 Epoch[80] Batch [1020]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.076862,	
2017-07-13 13:21:04,963 Epoch[80] Batch [1030]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.076837,	
2017-07-13 13:21:10,537 Update[120000]: Change learning rate to 5.00000e-05
2017-07-13 13:21:11,285 Epoch[80] Batch [1040]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.076842,	
2017-07-13 13:21:17,130 Epoch[80] Batch [1050]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.076843,	
2017-07-13 13:21:22,974 Epoch[80] Batch [1060]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.076850,	
2017-07-13 13:21:28,842 Epoch[80] Batch [1070]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.076867,	
2017-07-13 13:21:34,269 Epoch[80] Batch [1080]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.076865,	
2017-07-13 13:21:40,272 Epoch[80] Batch [1090]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.076915,	
2017-07-13 13:21:46,150 Epoch[80] Batch [1100]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.076880,	
2017-07-13 13:21:52,139 Epoch[80] Batch [1110]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.076918,	
2017-07-13 13:21:58,024 Epoch[80] Batch [1120]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.076893,	
2017-07-13 13:22:03,902 Epoch[80] Batch [1130]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.076810,	
2017-07-13 13:22:10,173 Epoch[80] Batch [1140]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.076863,	
2017-07-13 13:22:16,396 Epoch[80] Batch [1150]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.076887,	
2017-07-13 13:22:22,460 Epoch[80] Batch [1160]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.076839,	
2017-07-13 13:22:28,197 Epoch[80] Batch [1170]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.076824,	
2017-07-13 13:22:34,359 Epoch[80] Batch [1180]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.076817,	
2017-07-13 13:22:40,195 Epoch[80] Batch [1190]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.076795,	
2017-07-13 13:22:46,428 Epoch[80] Batch [1200]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.076789,	
2017-07-13 13:22:52,296 Epoch[80] Batch [1210]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.076764,	
2017-07-13 13:22:58,138 Epoch[80] Batch [1220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.076713,	
2017-07-13 13:23:04,192 Epoch[80] Batch [1230]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.076628,	
2017-07-13 13:23:09,760 Epoch[80] Batch [1240]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.076601,	
2017-07-13 13:23:16,394 Epoch[80] Batch [1250]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.076609,	
2017-07-13 13:23:22,580 Epoch[80] Batch [1260]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.076559,	
2017-07-13 13:23:28,743 Epoch[80] Batch [1270]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.076605,	
2017-07-13 13:23:34,852 Epoch[80] Batch [1280]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.076586,	
2017-07-13 13:23:41,019 Epoch[80] Batch [1290]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.076571,	
2017-07-13 13:23:46,459 Epoch[80] Batch [1300]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.076566,	
2017-07-13 13:23:52,271 Epoch[80] Batch [1310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.076565,	
2017-07-13 13:23:58,582 Epoch[80] Batch [1320]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.076581,	
2017-07-13 13:24:04,964 Epoch[80] Batch [1330]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.076574,	
2017-07-13 13:24:11,020 Epoch[80] Batch [1340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.076577,	
2017-07-13 13:24:17,567 Epoch[80] Batch [1350]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.076539,	
2017-07-13 13:24:23,721 Epoch[80] Batch [1360]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.076582,	
2017-07-13 13:24:30,065 Epoch[80] Batch [1370]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.076614,	
2017-07-13 13:24:35,891 Epoch[80] Batch [1380]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.076592,	
2017-07-13 13:24:42,441 Epoch[80] Batch [1390]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.076605,	
2017-07-13 13:24:48,952 Epoch[80] Batch [1400]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.076637,	
2017-07-13 13:24:55,214 Epoch[80] Batch [1410]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.076655,	
2017-07-13 13:25:01,527 Epoch[80] Batch [1420]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.076687,	
2017-07-13 13:25:08,140 Epoch[80] Batch [1430]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.076742,	
2017-07-13 13:25:14,552 Epoch[80] Batch [1440]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.076735,	
2017-07-13 13:25:20,936 Epoch[80] Batch [1450]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.076792,	
2017-07-13 13:25:26,876 Epoch[80] Batch [1460]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.076865,	
2017-07-13 13:25:33,617 Epoch[80] Batch [1470]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.076869,	
2017-07-13 13:25:40,200 Epoch[80] Batch [1480]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.076848,	
2017-07-13 13:25:44,079 Epoch[80] Train-FCNLogLoss=0.076835
2017-07-13 13:25:44,079 Epoch[80] Time cost=863.031
2017-07-13 13:25:45,015 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0081.params"
2017-07-13 13:25:48,345 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0081.states"
2017-07-13 13:25:54,577 Epoch[81] Batch [10]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.083425,	
2017-07-13 13:26:00,290 Epoch[81] Batch [20]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.078301,	
2017-07-13 13:26:06,204 Epoch[81] Batch [30]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.074554,	
2017-07-13 13:26:11,925 Epoch[81] Batch [40]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.075138,	
2017-07-13 13:26:17,544 Epoch[81] Batch [50]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.074308,	
2017-07-13 13:26:22,881 Epoch[81] Batch [60]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.074145,	
2017-07-13 13:26:28,355 Epoch[81] Batch [70]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.073236,	
2017-07-13 13:26:34,342 Epoch[81] Batch [80]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.072878,	
2017-07-13 13:26:40,710 Epoch[81] Batch [90]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.073756,	
2017-07-13 13:26:46,507 Epoch[81] Batch [100]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.073480,	
2017-07-13 13:26:51,971 Epoch[81] Batch [110]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.073638,	
2017-07-13 13:26:57,826 Epoch[81] Batch [120]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.074029,	
2017-07-13 13:27:04,032 Epoch[81] Batch [130]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.073221,	
2017-07-13 13:27:10,279 Epoch[81] Batch [140]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.073475,	
2017-07-13 13:27:16,010 Epoch[81] Batch [150]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.073555,	
2017-07-13 13:27:22,494 Epoch[81] Batch [160]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.073698,	
2017-07-13 13:27:27,882 Epoch[81] Batch [170]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.073483,	
2017-07-13 13:27:33,263 Epoch[81] Batch [180]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.073266,	
2017-07-13 13:27:39,302 Epoch[81] Batch [190]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.073173,	
2017-07-13 13:27:45,333 Epoch[81] Batch [200]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.073234,	
2017-07-13 13:27:51,729 Epoch[81] Batch [210]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.073184,	
2017-07-13 13:27:58,262 Epoch[81] Batch [220]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073678,	
2017-07-13 13:28:04,960 Epoch[81] Batch [230]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073510,	
2017-07-13 13:28:12,180 Epoch[81] Batch [240]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.073309,	
2017-07-13 13:28:19,006 Epoch[81] Batch [250]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073439,	
2017-07-13 13:28:25,879 Epoch[81] Batch [260]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.073506,	
2017-07-13 13:28:32,415 Epoch[81] Batch [270]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073898,	
2017-07-13 13:28:38,609 Epoch[81] Batch [280]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.073991,	
2017-07-13 13:28:44,751 Epoch[81] Batch [290]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.074154,	
2017-07-13 13:28:51,757 Epoch[81] Batch [300]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.073930,	
2017-07-13 13:28:58,054 Epoch[81] Batch [310]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.074125,	
2017-07-13 13:29:04,409 Epoch[81] Batch [320]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.074240,	
2017-07-13 13:29:11,478 Epoch[81] Batch [330]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.074705,	
2017-07-13 13:29:18,296 Epoch[81] Batch [340]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.074535,	
2017-07-13 13:29:25,132 Epoch[81] Batch [350]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.074417,	
2017-07-13 13:29:31,324 Epoch[81] Batch [360]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.074517,	
2017-07-13 13:29:37,382 Epoch[81] Batch [370]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.074492,	
2017-07-13 13:29:43,599 Epoch[81] Batch [380]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.074588,	
2017-07-13 13:29:50,432 Epoch[81] Batch [390]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.074652,	
2017-07-13 13:29:56,991 Epoch[81] Batch [400]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.074547,	
2017-07-13 13:30:03,674 Epoch[81] Batch [410]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.074595,	
2017-07-13 13:30:10,107 Epoch[81] Batch [420]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.074647,	
2017-07-13 13:30:16,453 Epoch[81] Batch [430]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.074707,	
2017-07-13 13:30:23,051 Epoch[81] Batch [440]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.074923,	
2017-07-13 13:30:30,117 Epoch[81] Batch [450]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.074745,	
2017-07-13 13:30:36,816 Epoch[81] Batch [460]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.074634,	
2017-07-13 13:30:43,559 Epoch[81] Batch [470]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.074555,	
2017-07-13 13:30:50,474 Epoch[81] Batch [480]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.074674,	
2017-07-13 13:30:57,084 Epoch[81] Batch [490]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.074807,	
2017-07-13 13:31:04,188 Epoch[81] Batch [500]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.074792,	
2017-07-13 13:31:10,239 Epoch[81] Batch [510]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.074776,	
2017-07-13 13:31:16,933 Epoch[81] Batch [520]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.074817,	
2017-07-13 13:31:23,561 Epoch[81] Batch [530]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.074788,	
2017-07-13 13:31:30,200 Epoch[81] Batch [540]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.074874,	
2017-07-13 13:31:36,939 Epoch[81] Batch [550]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.074941,	
2017-07-13 13:31:43,964 Epoch[81] Batch [560]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.075010,	
2017-07-13 13:31:51,316 Epoch[81] Batch [570]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074935,	
2017-07-13 13:31:58,107 Epoch[81] Batch [580]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.074779,	
2017-07-13 13:32:04,723 Epoch[81] Batch [590]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.074655,	
2017-07-13 13:32:11,436 Epoch[81] Batch [600]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.074626,	
2017-07-13 13:32:18,382 Epoch[81] Batch [610]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.074696,	
2017-07-13 13:32:25,486 Epoch[81] Batch [620]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.074669,	
2017-07-13 13:32:32,530 Epoch[81] Batch [630]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.074684,	
2017-07-13 13:32:39,341 Epoch[81] Batch [640]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.074767,	
2017-07-13 13:32:46,621 Epoch[81] Batch [650]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.074779,	
2017-07-13 13:32:54,637 Epoch[81] Batch [660]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.074690,	
2017-07-13 13:33:02,517 Epoch[81] Batch [670]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.074734,	
2017-07-13 13:33:10,318 Epoch[81] Batch [680]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074837,	
2017-07-13 13:33:18,098 Epoch[81] Batch [690]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074871,	
2017-07-13 13:33:25,808 Epoch[81] Batch [700]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.074951,	
2017-07-13 13:33:33,550 Epoch[81] Batch [710]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.074926,	
2017-07-13 13:33:41,081 Epoch[81] Batch [720]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.074960,	
2017-07-13 13:33:48,854 Epoch[81] Batch [730]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.074854,	
2017-07-13 13:33:56,475 Epoch[81] Batch [740]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.074843,	
2017-07-13 13:34:04,358 Epoch[81] Batch [750]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.074838,	
2017-07-13 13:34:12,133 Epoch[81] Batch [760]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074825,	
2017-07-13 13:34:20,341 Epoch[81] Batch [770]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.074909,	
2017-07-13 13:34:28,436 Epoch[81] Batch [780]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.074905,	
2017-07-13 13:34:36,281 Epoch[81] Batch [790]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.074872,	
2017-07-13 13:34:44,334 Epoch[81] Batch [800]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.074896,	
2017-07-13 13:34:52,131 Epoch[81] Batch [810]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074840,	
2017-07-13 13:34:59,943 Epoch[81] Batch [820]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.074838,	
2017-07-13 13:35:07,741 Epoch[81] Batch [830]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074871,	
2017-07-13 13:35:15,373 Epoch[81] Batch [840]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.074824,	
2017-07-13 13:35:23,070 Epoch[81] Batch [850]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074851,	
2017-07-13 13:35:30,673 Epoch[81] Batch [860]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.074813,	
2017-07-13 13:35:37,893 Epoch[81] Batch [870]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.074812,	
2017-07-13 13:35:45,392 Epoch[81] Batch [880]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.074799,	
2017-07-13 13:35:52,696 Epoch[81] Batch [890]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.074719,	
2017-07-13 13:35:59,896 Epoch[81] Batch [900]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.074734,	
2017-07-13 13:36:07,016 Epoch[81] Batch [910]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.074780,	
2017-07-13 13:36:13,271 Epoch[81] Batch [920]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.074834,	
2017-07-13 13:36:19,711 Epoch[81] Batch [930]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.074940,	
2017-07-13 13:36:26,262 Epoch[81] Batch [940]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.074941,	
2017-07-13 13:36:33,033 Epoch[81] Batch [950]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.074899,	
2017-07-13 13:36:39,649 Epoch[81] Batch [960]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.074918,	
2017-07-13 13:36:46,349 Epoch[81] Batch [970]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.075016,	
2017-07-13 13:36:53,624 Epoch[81] Batch [980]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.075067,	
2017-07-13 13:37:00,789 Epoch[81] Batch [990]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.075000,	
2017-07-13 13:37:07,732 Epoch[81] Batch [1000]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.074991,	
2017-07-13 13:37:14,875 Epoch[81] Batch [1010]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.074972,	
2017-07-13 13:37:21,546 Epoch[81] Batch [1020]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.074940,	
2017-07-13 13:37:28,197 Epoch[81] Batch [1030]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.074939,	
2017-07-13 13:37:35,325 Epoch[81] Batch [1040]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.074869,	
2017-07-13 13:37:42,473 Epoch[81] Batch [1050]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.074881,	
2017-07-13 13:37:49,663 Epoch[81] Batch [1060]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.074871,	
2017-07-13 13:37:57,019 Epoch[81] Batch [1070]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074825,	
2017-07-13 13:38:03,962 Epoch[81] Batch [1080]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.074779,	
2017-07-13 13:38:11,588 Epoch[81] Batch [1090]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.074827,	
2017-07-13 13:38:18,825 Epoch[81] Batch [1100]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.074789,	
2017-07-13 13:38:26,113 Epoch[81] Batch [1110]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.074806,	
2017-07-13 13:38:33,386 Epoch[81] Batch [1120]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.074804,	
2017-07-13 13:38:40,733 Epoch[81] Batch [1130]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074753,	
2017-07-13 13:38:48,312 Epoch[81] Batch [1140]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074701,	
2017-07-13 13:38:55,699 Epoch[81] Batch [1150]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.074665,	
2017-07-13 13:39:03,047 Epoch[81] Batch [1160]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074694,	
2017-07-13 13:39:10,273 Epoch[81] Batch [1170]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.074755,	
2017-07-13 13:39:17,456 Epoch[81] Batch [1180]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.074747,	
2017-07-13 13:39:24,837 Epoch[81] Batch [1190]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.074714,	
2017-07-13 13:39:32,229 Epoch[81] Batch [1200]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.074746,	
2017-07-13 13:39:39,575 Epoch[81] Batch [1210]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.074812,	
2017-07-13 13:39:46,939 Epoch[81] Batch [1220]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.074786,	
2017-07-13 13:39:54,190 Epoch[81] Batch [1230]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.074870,	
2017-07-13 13:40:01,462 Epoch[81] Batch [1240]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.074851,	
2017-07-13 13:40:08,917 Epoch[81] Batch [1250]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.074864,	
2017-07-13 13:40:16,220 Epoch[81] Batch [1260]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.074835,	
2017-07-13 13:40:23,382 Epoch[81] Batch [1270]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.074800,	
2017-07-13 13:40:30,799 Epoch[81] Batch [1280]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.074763,	
2017-07-13 13:40:38,168 Epoch[81] Batch [1290]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.074712,	
2017-07-13 13:40:45,659 Epoch[81] Batch [1300]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.074721,	
2017-07-13 13:40:53,468 Epoch[81] Batch [1310]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.074736,	
2017-07-13 13:41:00,986 Epoch[81] Batch [1320]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.074728,	
2017-07-13 13:41:08,657 Epoch[81] Batch [1330]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.074732,	
2017-07-13 13:41:16,053 Epoch[81] Batch [1340]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.074701,	
2017-07-13 13:41:23,390 Epoch[81] Batch [1350]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.074721,	
2017-07-13 13:41:30,398 Epoch[81] Batch [1360]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.074711,	
2017-07-13 13:41:37,594 Epoch[81] Batch [1370]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.074729,	
2017-07-13 13:41:44,619 Epoch[81] Batch [1380]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.074663,	
2017-07-13 13:41:51,791 Epoch[81] Batch [1390]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.074677,	
2017-07-13 13:41:58,988 Epoch[81] Batch [1400]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.074638,	
2017-07-13 13:42:05,808 Epoch[81] Batch [1410]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.074614,	
2017-07-13 13:42:12,556 Epoch[81] Batch [1420]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.074587,	
2017-07-13 13:42:19,855 Epoch[81] Batch [1430]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.074563,	
2017-07-13 13:42:27,539 Epoch[81] Batch [1440]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.074599,	
2017-07-13 13:42:34,978 Epoch[81] Batch [1450]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.074623,	
2017-07-13 13:42:42,421 Epoch[81] Batch [1460]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.074708,	
2017-07-13 13:42:49,741 Epoch[81] Batch [1470]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.074710,	
2017-07-13 13:42:56,860 Epoch[81] Batch [1480]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.074689,	
2017-07-13 13:43:01,205 Epoch[81] Train-FCNLogLoss=0.074682
2017-07-13 13:43:01,205 Epoch[81] Time cost=1032.860
2017-07-13 13:43:02,065 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0082.params"
2017-07-13 13:43:05,496 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0082.states"
2017-07-13 13:43:14,266 Epoch[82] Batch [10]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.071347,	
2017-07-13 13:43:21,949 Epoch[82] Batch [20]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.073008,	
2017-07-13 13:43:29,817 Epoch[82] Batch [30]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.075963,	
2017-07-13 13:43:37,801 Epoch[82] Batch [40]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.076342,	
2017-07-13 13:43:45,409 Epoch[82] Batch [50]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.074666,	
2017-07-13 13:43:53,005 Epoch[82] Batch [60]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.075304,	
2017-07-13 13:44:00,886 Epoch[82] Batch [70]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.076032,	
2017-07-13 13:44:08,797 Epoch[82] Batch [80]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.075621,	
2017-07-13 13:44:16,706 Epoch[82] Batch [90]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.075757,	
2017-07-13 13:44:24,597 Epoch[82] Batch [100]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.075525,	
2017-07-13 13:44:32,369 Epoch[82] Batch [110]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.074556,	
2017-07-13 13:44:40,306 Epoch[82] Batch [120]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.074043,	
2017-07-13 13:44:48,341 Epoch[82] Batch [130]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.074534,	
2017-07-13 13:44:56,184 Epoch[82] Batch [140]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.074761,	
2017-07-13 13:45:04,193 Epoch[82] Batch [150]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.074960,	
2017-07-13 13:45:11,951 Epoch[82] Batch [160]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.075055,	
2017-07-13 13:45:19,639 Epoch[82] Batch [170]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074817,	
2017-07-13 13:45:27,415 Epoch[82] Batch [180]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.075295,	
2017-07-13 13:45:35,357 Epoch[82] Batch [190]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.075119,	
2017-07-13 13:45:43,047 Epoch[82] Batch [200]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074686,	
2017-07-13 13:45:51,138 Epoch[82] Batch [210]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.074865,	
2017-07-13 13:45:59,056 Epoch[82] Batch [220]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.074499,	
2017-07-13 13:46:07,158 Epoch[82] Batch [230]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.074579,	
2017-07-13 13:46:14,853 Epoch[82] Batch [240]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074238,	
2017-07-13 13:46:22,593 Epoch[82] Batch [250]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.073943,	
2017-07-13 13:46:30,384 Epoch[82] Batch [260]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.073973,	
2017-07-13 13:46:38,396 Epoch[82] Batch [270]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.073888,	
2017-07-13 13:46:46,430 Epoch[82] Batch [280]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.073966,	
2017-07-13 13:46:54,262 Epoch[82] Batch [290]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.074256,	
2017-07-13 13:47:02,158 Epoch[82] Batch [300]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.074234,	
2017-07-13 13:47:10,130 Epoch[82] Batch [310]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.074162,	
2017-07-13 13:47:18,115 Epoch[82] Batch [320]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.074271,	
2017-07-13 13:47:25,975 Epoch[82] Batch [330]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.074347,	
2017-07-13 13:47:33,698 Epoch[82] Batch [340]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.074585,	
2017-07-13 13:47:41,463 Epoch[82] Batch [350]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.074732,	
2017-07-13 13:47:49,387 Epoch[82] Batch [360]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.074719,	
2017-07-13 13:47:57,398 Epoch[82] Batch [370]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.074803,	
2017-07-13 13:48:05,255 Epoch[82] Batch [380]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.074810,	
2017-07-13 13:48:13,077 Epoch[82] Batch [390]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.074828,	
2017-07-13 13:48:20,724 Epoch[82] Batch [400]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.074968,	
2017-07-13 13:48:28,630 Epoch[82] Batch [410]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.075075,	
2017-07-13 13:48:36,385 Epoch[82] Batch [420]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.075133,	
2017-07-13 13:48:43,990 Epoch[82] Batch [430]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.075177,	
2017-07-13 13:48:51,778 Epoch[82] Batch [440]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.075040,	
2017-07-13 13:48:59,670 Epoch[82] Batch [450]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.075199,	
2017-07-13 13:49:07,195 Epoch[82] Batch [460]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.075069,	
2017-07-13 13:49:14,891 Epoch[82] Batch [470]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074889,	
2017-07-13 13:49:22,471 Epoch[82] Batch [480]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.075080,	
2017-07-13 13:49:30,126 Epoch[82] Batch [490]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.075118,	
2017-07-13 13:49:37,819 Epoch[82] Batch [500]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.075236,	
2017-07-13 13:49:45,479 Epoch[82] Batch [510]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.075366,	
2017-07-13 13:49:53,332 Epoch[82] Batch [520]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.075200,	
2017-07-13 13:50:01,271 Epoch[82] Batch [530]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.075213,	
2017-07-13 13:50:09,088 Epoch[82] Batch [540]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.075266,	
2017-07-13 13:50:16,825 Epoch[82] Batch [550]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.075431,	
2017-07-13 13:50:24,664 Epoch[82] Batch [560]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.075484,	
2017-07-13 13:50:32,478 Epoch[82] Batch [570]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.075478,	
2017-07-13 13:50:40,297 Epoch[82] Batch [580]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.075487,	
2017-07-13 13:50:48,061 Epoch[82] Batch [590]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.075378,	
2017-07-13 13:50:55,580 Epoch[82] Batch [600]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.075406,	
2017-07-13 13:51:03,136 Epoch[82] Batch [610]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.075428,	
2017-07-13 13:51:10,679 Epoch[82] Batch [620]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.075359,	
2017-07-13 13:51:17,981 Epoch[82] Batch [630]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.075279,	
2017-07-13 13:51:25,443 Epoch[82] Batch [640]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.075232,	
2017-07-13 13:51:32,936 Epoch[82] Batch [650]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.075253,	
2017-07-13 13:51:40,489 Epoch[82] Batch [660]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.075321,	
2017-07-13 13:51:47,841 Epoch[82] Batch [670]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.075255,	
2017-07-13 13:51:55,457 Epoch[82] Batch [680]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075279,	
2017-07-13 13:52:03,154 Epoch[82] Batch [690]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.075262,	
2017-07-13 13:52:10,788 Epoch[82] Batch [700]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.075291,	
2017-07-13 13:52:18,512 Epoch[82] Batch [710]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.075352,	
2017-07-13 13:52:26,203 Epoch[82] Batch [720]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.075386,	
2017-07-13 13:52:33,973 Epoch[82] Batch [730]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.075356,	
2017-07-13 13:52:41,528 Epoch[82] Batch [740]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.075335,	
2017-07-13 13:52:49,066 Epoch[82] Batch [750]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.075336,	
2017-07-13 13:52:56,844 Epoch[82] Batch [760]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.075431,	
2017-07-13 13:53:04,627 Epoch[82] Batch [770]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.075493,	
2017-07-13 13:53:12,437 Epoch[82] Batch [780]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.075541,	
2017-07-13 13:53:20,156 Epoch[82] Batch [790]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.075611,	
2017-07-13 13:53:27,741 Epoch[82] Batch [800]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.075608,	
2017-07-13 13:53:35,059 Epoch[82] Batch [810]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.075551,	
2017-07-13 13:53:42,558 Epoch[82] Batch [820]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.075610,	
2017-07-13 13:53:50,125 Epoch[82] Batch [830]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.075693,	
2017-07-13 13:53:57,759 Epoch[82] Batch [840]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.075680,	
2017-07-13 13:54:05,463 Epoch[82] Batch [850]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.075747,	
2017-07-13 13:54:13,129 Epoch[82] Batch [860]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.075627,	
2017-07-13 13:54:21,093 Epoch[82] Batch [870]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.075614,	
2017-07-13 13:54:28,799 Epoch[82] Batch [880]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.075625,	
2017-07-13 13:54:36,597 Epoch[82] Batch [890]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.075616,	
2017-07-13 13:54:44,320 Epoch[82] Batch [900]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.075617,	
2017-07-13 13:54:51,989 Epoch[82] Batch [910]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.075586,	
2017-07-13 13:54:59,679 Epoch[82] Batch [920]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.075502,	
2017-07-13 13:55:07,561 Epoch[82] Batch [930]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.075539,	
2017-07-13 13:55:15,286 Epoch[82] Batch [940]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.075518,	
2017-07-13 13:55:22,968 Epoch[82] Batch [950]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.075520,	
2017-07-13 13:55:30,765 Epoch[82] Batch [960]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.075504,	
2017-07-13 13:55:38,645 Epoch[82] Batch [970]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.075472,	
2017-07-13 13:55:46,266 Epoch[82] Batch [980]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075438,	
2017-07-13 13:55:53,842 Epoch[82] Batch [990]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.075443,	
2017-07-13 13:56:01,455 Epoch[82] Batch [1000]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075470,	
2017-07-13 13:56:09,409 Epoch[82] Batch [1010]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.075502,	
2017-07-13 13:56:17,167 Epoch[82] Batch [1020]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.075422,	
2017-07-13 13:56:24,837 Epoch[82] Batch [1030]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.075405,	
2017-07-13 13:56:32,664 Epoch[82] Batch [1040]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.075387,	
2017-07-13 13:56:40,551 Epoch[82] Batch [1050]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.075387,	
2017-07-13 13:56:48,351 Epoch[82] Batch [1060]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.075392,	
2017-07-13 13:56:55,965 Epoch[82] Batch [1070]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075423,	
2017-07-13 13:57:03,736 Epoch[82] Batch [1080]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.075360,	
2017-07-13 13:57:11,370 Epoch[82] Batch [1090]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.075296,	
2017-07-13 13:57:19,060 Epoch[82] Batch [1100]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.075283,	
2017-07-13 13:57:26,709 Epoch[82] Batch [1110]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.075274,	
2017-07-13 13:57:34,693 Epoch[82] Batch [1120]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.075320,	
2017-07-13 13:57:42,478 Epoch[82] Batch [1130]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.075217,	
2017-07-13 13:57:50,091 Epoch[82] Batch [1140]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075179,	
2017-07-13 13:57:57,729 Epoch[82] Batch [1150]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.075169,	
2017-07-13 13:58:05,250 Epoch[82] Batch [1160]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.075194,	
2017-07-13 13:58:13,120 Epoch[82] Batch [1170]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.075221,	
2017-07-13 13:58:21,025 Epoch[82] Batch [1180]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.075191,	
2017-07-13 13:58:28,620 Epoch[82] Batch [1190]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.075221,	
2017-07-13 13:58:36,513 Epoch[82] Batch [1200]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.075147,	
2017-07-13 13:58:44,413 Epoch[82] Batch [1210]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.075089,	
2017-07-13 13:58:52,250 Epoch[82] Batch [1220]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.075113,	
2017-07-13 13:59:00,391 Epoch[82] Batch [1230]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.075033,	
2017-07-13 13:59:08,411 Epoch[82] Batch [1240]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.075004,	
2017-07-13 13:59:16,378 Epoch[82] Batch [1250]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.075018,	
2017-07-13 13:59:24,112 Epoch[82] Batch [1260]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.075019,	
2017-07-13 13:59:32,012 Epoch[82] Batch [1270]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074978,	
2017-07-13 13:59:40,114 Epoch[82] Batch [1280]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.074958,	
2017-07-13 13:59:48,051 Epoch[82] Batch [1290]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.075037,	
2017-07-13 13:59:55,871 Epoch[82] Batch [1300]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.074996,	
2017-07-13 14:00:03,774 Epoch[82] Batch [1310]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074980,	
2017-07-13 14:00:11,676 Epoch[82] Batch [1320]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074947,	
2017-07-13 14:00:19,666 Epoch[82] Batch [1330]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.074914,	
2017-07-13 14:00:27,332 Epoch[82] Batch [1340]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.074899,	
2017-07-13 14:00:35,263 Epoch[82] Batch [1350]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.074898,	
2017-07-13 14:00:43,129 Epoch[82] Batch [1360]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.074907,	
2017-07-13 14:00:50,987 Epoch[82] Batch [1370]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.074931,	
2017-07-13 14:00:58,602 Epoch[82] Batch [1380]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.074900,	
2017-07-13 14:01:06,457 Epoch[82] Batch [1390]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.074913,	
2017-07-13 14:01:14,361 Epoch[82] Batch [1400]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074921,	
2017-07-13 14:01:22,153 Epoch[82] Batch [1410]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074946,	
2017-07-13 14:01:30,183 Epoch[82] Batch [1420]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.074935,	
2017-07-13 14:01:37,930 Epoch[82] Batch [1430]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.074903,	
2017-07-13 14:01:45,921 Epoch[82] Batch [1440]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.074914,	
2017-07-13 14:01:53,651 Epoch[82] Batch [1450]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.074887,	
2017-07-13 14:02:01,551 Epoch[82] Batch [1460]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074867,	
2017-07-13 14:02:09,450 Epoch[82] Batch [1470]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074813,	
2017-07-13 14:02:17,375 Epoch[82] Batch [1480]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.074806,	
2017-07-13 14:02:22,143 Epoch[82] Train-FCNLogLoss=0.074802
2017-07-13 14:02:22,143 Epoch[82] Time cost=1156.647
2017-07-13 14:02:23,144 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0083.params"
2017-07-13 14:02:26,796 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0083.states"
2017-07-13 14:02:35,087 Epoch[83] Batch [10]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.073572,	
2017-07-13 14:02:42,424 Epoch[83] Batch [20]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.074274,	
2017-07-13 14:02:49,788 Epoch[83] Batch [30]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.075392,	
2017-07-13 14:02:57,536 Epoch[83] Batch [40]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.076796,	
2017-07-13 14:03:04,928 Epoch[83] Batch [50]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.075598,	
2017-07-13 14:03:12,251 Epoch[83] Batch [60]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.075286,	
2017-07-13 14:03:19,514 Epoch[83] Batch [70]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.075640,	
2017-07-13 14:03:26,836 Epoch[83] Batch [80]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.075785,	
2017-07-13 14:03:34,514 Epoch[83] Batch [90]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.075549,	
2017-07-13 14:03:42,510 Epoch[83] Batch [100]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.075567,	
2017-07-13 14:03:50,130 Epoch[83] Batch [110]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075270,	
2017-07-13 14:03:58,086 Epoch[83] Batch [120]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.075488,	
2017-07-13 14:04:05,881 Epoch[83] Batch [130]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.075463,	
2017-07-13 14:04:13,496 Epoch[83] Batch [140]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075234,	
2017-07-13 14:04:21,109 Epoch[83] Batch [150]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075108,	
2017-07-13 14:04:28,943 Epoch[83] Batch [160]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.074944,	
2017-07-13 14:04:36,575 Epoch[83] Batch [170]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.074910,	
2017-07-13 14:04:44,472 Epoch[83] Batch [180]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.074849,	
2017-07-13 14:04:52,255 Epoch[83] Batch [190]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074818,	
2017-07-13 14:04:59,652 Epoch[83] Batch [200]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.074939,	
2017-07-13 14:05:07,487 Epoch[83] Batch [210]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.074576,	
2017-07-13 14:05:15,252 Epoch[83] Batch [220]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.074861,	
2017-07-13 14:05:23,255 Epoch[83] Batch [230]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.074668,	
2017-07-13 14:05:30,940 Epoch[83] Batch [240]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.074544,	
2017-07-13 14:05:38,457 Epoch[83] Batch [250]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.074571,	
2017-07-13 14:05:45,980 Epoch[83] Batch [260]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.074583,	
2017-07-13 14:05:53,727 Epoch[83] Batch [270]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.074553,	
2017-07-13 14:06:01,462 Epoch[83] Batch [280]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.074759,	
2017-07-13 14:06:09,183 Epoch[83] Batch [290]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.074977,	
2017-07-13 14:06:16,907 Epoch[83] Batch [300]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.074834,	
2017-07-13 14:06:24,650 Epoch[83] Batch [310]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.074783,	
2017-07-13 14:06:32,389 Epoch[83] Batch [320]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.074784,	
2017-07-13 14:06:40,214 Epoch[83] Batch [330]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.074604,	
2017-07-13 14:06:47,974 Epoch[83] Batch [340]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.074673,	
2017-07-13 14:06:56,108 Epoch[83] Batch [350]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.074784,	
2017-07-13 14:07:03,988 Epoch[83] Batch [360]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.074679,	
2017-07-13 14:07:11,866 Epoch[83] Batch [370]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.074721,	
2017-07-13 14:07:19,781 Epoch[83] Batch [380]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.074949,	
2017-07-13 14:07:27,766 Epoch[83] Batch [390]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.074754,	
2017-07-13 14:07:35,650 Epoch[83] Batch [400]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.074683,	
2017-07-13 14:07:43,446 Epoch[83] Batch [410]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074696,	
2017-07-13 14:07:51,150 Epoch[83] Batch [420]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.074594,	
2017-07-13 14:07:58,979 Epoch[83] Batch [430]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.074615,	
2017-07-13 14:08:06,827 Epoch[83] Batch [440]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.074631,	
2017-07-13 14:08:14,652 Epoch[83] Batch [450]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.074683,	
2017-07-13 14:08:22,450 Epoch[83] Batch [460]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074648,	
2017-07-13 14:08:30,450 Epoch[83] Batch [470]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.074686,	
2017-07-13 14:08:38,394 Epoch[83] Batch [480]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.074654,	
2017-07-13 14:08:46,120 Epoch[83] Batch [490]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.074836,	
2017-07-13 14:08:53,828 Epoch[83] Batch [500]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.074669,	
2017-07-13 14:09:01,716 Epoch[83] Batch [510]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.074714,	
2017-07-13 14:09:09,503 Epoch[83] Batch [520]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074781,	
2017-07-13 14:09:17,563 Epoch[83] Batch [530]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.074788,	
2017-07-13 14:09:25,339 Epoch[83] Batch [540]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074872,	
2017-07-13 14:09:33,185 Epoch[83] Batch [550]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.074875,	
2017-07-13 14:09:41,067 Epoch[83] Batch [560]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.074685,	
2017-07-13 14:09:48,869 Epoch[83] Batch [570]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074754,	
2017-07-13 14:09:56,566 Epoch[83] Batch [580]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074716,	
2017-07-13 14:10:04,282 Epoch[83] Batch [590]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.074558,	
2017-07-13 14:10:12,342 Epoch[83] Batch [600]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.074541,	
2017-07-13 14:10:19,895 Epoch[83] Batch [610]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074337,	
2017-07-13 14:10:27,302 Epoch[83] Batch [620]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.074447,	
2017-07-13 14:10:34,880 Epoch[83] Batch [630]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074601,	
2017-07-13 14:10:42,637 Epoch[83] Batch [640]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.074709,	
2017-07-13 14:10:50,580 Epoch[83] Batch [650]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.074616,	
2017-07-13 14:10:58,634 Epoch[83] Batch [660]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.074574,	
2017-07-13 14:11:06,661 Epoch[83] Batch [670]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.074658,	
2017-07-13 14:11:14,449 Epoch[83] Batch [680]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074693,	
2017-07-13 14:11:21,959 Epoch[83] Batch [690]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.074684,	
2017-07-13 14:11:29,532 Epoch[83] Batch [700]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074831,	
2017-07-13 14:11:37,086 Epoch[83] Batch [710]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074813,	
2017-07-13 14:11:44,757 Epoch[83] Batch [720]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.074850,	
2017-07-13 14:11:52,352 Epoch[83] Batch [730]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.074827,	
2017-07-13 14:11:59,871 Epoch[83] Batch [740]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.074841,	
2017-07-13 14:12:07,596 Epoch[83] Batch [750]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.074979,	
2017-07-13 14:12:15,514 Epoch[83] Batch [760]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.074939,	
2017-07-13 14:12:23,210 Epoch[83] Batch [770]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074875,	
2017-07-13 14:12:30,920 Epoch[83] Batch [780]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.074876,	
2017-07-13 14:12:38,665 Epoch[83] Batch [790]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.074839,	
2017-07-13 14:12:46,174 Epoch[83] Batch [800]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.074749,	
2017-07-13 14:12:53,799 Epoch[83] Batch [810]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.074694,	
2017-07-13 14:13:01,655 Epoch[83] Batch [820]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.074659,	
2017-07-13 14:13:09,441 Epoch[83] Batch [830]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074622,	
2017-07-13 14:13:16,959 Epoch[83] Batch [840]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.074642,	
2017-07-13 14:13:24,615 Epoch[83] Batch [850]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.074534,	
2017-07-13 14:13:32,519 Epoch[83] Batch [860]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074570,	
2017-07-13 14:13:40,085 Epoch[83] Batch [870]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.074578,	
2017-07-13 14:13:47,738 Epoch[83] Batch [880]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.074588,	
2017-07-13 14:13:55,398 Epoch[83] Batch [890]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.074599,	
2017-07-13 14:14:03,037 Epoch[83] Batch [900]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.074669,	
2017-07-13 14:14:10,816 Epoch[83] Batch [910]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074590,	
2017-07-13 14:14:18,337 Epoch[83] Batch [920]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.074570,	
2017-07-13 14:14:26,073 Epoch[83] Batch [930]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.074625,	
2017-07-13 14:14:33,890 Epoch[83] Batch [940]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.074614,	
2017-07-13 14:14:41,487 Epoch[83] Batch [950]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.074637,	
2017-07-13 14:14:49,029 Epoch[83] Batch [960]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074564,	
2017-07-13 14:14:56,616 Epoch[83] Batch [970]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.074499,	
2017-07-13 14:15:04,396 Epoch[83] Batch [980]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.074438,	
2017-07-13 14:15:12,044 Epoch[83] Batch [990]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.074433,	
2017-07-13 14:15:19,246 Epoch[83] Batch [1000]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.074446,	
2017-07-13 14:15:26,329 Epoch[83] Batch [1010]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.074490,	
2017-07-13 14:15:33,295 Epoch[83] Batch [1020]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.074473,	
2017-07-13 14:15:39,449 Epoch[83] Batch [1030]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.074413,	
2017-07-13 14:15:45,638 Epoch[83] Batch [1040]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.074424,	
2017-07-13 14:15:51,967 Epoch[83] Batch [1050]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.074365,	
2017-07-13 14:15:58,132 Epoch[83] Batch [1060]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.074385,	
2017-07-13 14:16:03,833 Epoch[83] Batch [1070]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.074339,	
2017-07-13 14:16:09,908 Epoch[83] Batch [1080]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.074342,	
2017-07-13 14:16:15,921 Epoch[83] Batch [1090]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.074335,	
2017-07-13 14:16:21,800 Epoch[83] Batch [1100]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.074411,	
2017-07-13 14:16:28,015 Epoch[83] Batch [1110]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.074372,	
2017-07-13 14:16:33,620 Epoch[83] Batch [1120]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.074414,	
2017-07-13 14:16:39,770 Epoch[83] Batch [1130]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.074375,	
2017-07-13 14:16:45,999 Epoch[83] Batch [1140]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.074427,	
2017-07-13 14:16:51,934 Epoch[83] Batch [1150]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.074434,	
2017-07-13 14:16:57,729 Epoch[83] Batch [1160]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.074539,	
2017-07-13 14:17:03,645 Epoch[83] Batch [1170]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.074628,	
2017-07-13 14:17:10,017 Epoch[83] Batch [1180]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.074682,	
2017-07-13 14:17:15,863 Epoch[83] Batch [1190]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.074680,	
2017-07-13 14:17:21,980 Epoch[83] Batch [1200]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.074756,	
2017-07-13 14:17:28,129 Epoch[83] Batch [1210]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.074776,	
2017-07-13 14:17:34,564 Epoch[83] Batch [1220]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.074844,	
2017-07-13 14:17:40,658 Epoch[83] Batch [1230]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.074859,	
2017-07-13 14:17:47,063 Epoch[83] Batch [1240]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.074791,	
2017-07-13 14:17:53,243 Epoch[83] Batch [1250]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.074754,	
2017-07-13 14:17:59,297 Epoch[83] Batch [1260]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.074733,	
2017-07-13 14:18:05,515 Epoch[83] Batch [1270]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.074700,	
2017-07-13 14:18:11,284 Epoch[83] Batch [1280]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.074668,	
2017-07-13 14:18:17,146 Epoch[83] Batch [1290]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.074676,	
2017-07-13 14:18:23,014 Epoch[83] Batch [1300]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.074682,	
2017-07-13 14:18:28,617 Epoch[83] Batch [1310]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.074705,	
2017-07-13 14:18:33,977 Epoch[83] Batch [1320]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.074735,	
2017-07-13 14:18:39,562 Epoch[83] Batch [1330]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.074742,	
2017-07-13 14:18:45,251 Epoch[83] Batch [1340]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.074717,	
2017-07-13 14:18:50,248 Epoch[83] Batch [1350]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.074701,	
2017-07-13 14:18:56,376 Epoch[83] Batch [1360]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.074684,	
2017-07-13 14:19:01,955 Epoch[83] Batch [1370]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.074679,	
2017-07-13 14:19:08,132 Epoch[83] Batch [1380]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.074629,	
2017-07-13 14:19:14,111 Epoch[83] Batch [1390]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.074646,	
2017-07-13 14:19:19,174 Epoch[83] Batch [1400]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.074658,	
2017-07-13 14:19:24,654 Epoch[83] Batch [1410]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.074615,	
2017-07-13 14:19:30,146 Epoch[83] Batch [1420]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.074595,	
2017-07-13 14:19:35,674 Epoch[83] Batch [1430]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.074585,	
2017-07-13 14:19:41,213 Epoch[83] Batch [1440]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.074569,	
2017-07-13 14:19:46,612 Epoch[83] Batch [1450]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.074598,	
2017-07-13 14:19:51,699 Epoch[83] Batch [1460]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.074552,	
2017-07-13 14:19:56,823 Epoch[83] Batch [1470]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.074560,	
2017-07-13 14:20:01,687 Epoch[83] Batch [1480]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.074581,	
2017-07-13 14:20:04,805 Epoch[83] Train-FCNLogLoss=0.074564
2017-07-13 14:20:04,806 Epoch[83] Time cost=1058.009
2017-07-13 14:20:05,466 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0084.params"
2017-07-13 14:20:08,744 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0084.states"
2017-07-13 14:20:15,038 Epoch[84] Batch [10]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.071377,	
2017-07-13 14:20:20,342 Epoch[84] Batch [20]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.070152,	
2017-07-13 14:20:25,470 Epoch[84] Batch [30]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.072190,	
2017-07-13 14:20:30,862 Epoch[84] Batch [40]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.072768,	
2017-07-13 14:20:36,429 Epoch[84] Batch [50]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.071311,	
2017-07-13 14:20:41,649 Epoch[84] Batch [60]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.073036,	
2017-07-13 14:20:46,542 Epoch[84] Batch [70]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.072876,	
2017-07-13 14:20:51,157 Epoch[84] Batch [80]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.072781,	
2017-07-13 14:20:55,812 Epoch[84] Batch [90]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.072950,	
2017-07-13 14:21:00,410 Epoch[84] Batch [100]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.073028,	
2017-07-13 14:21:05,018 Epoch[84] Batch [110]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.072695,	
2017-07-13 14:21:09,768 Epoch[84] Batch [120]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.073319,	
2017-07-13 14:21:14,389 Epoch[84] Batch [130]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.073473,	
2017-07-13 14:21:19,141 Epoch[84] Batch [140]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.073941,	
2017-07-13 14:21:23,624 Epoch[84] Batch [150]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.074758,	
2017-07-13 14:21:28,010 Epoch[84] Batch [160]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.074868,	
2017-07-13 14:21:32,377 Epoch[84] Batch [170]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.074851,	
2017-07-13 14:21:36,827 Epoch[84] Batch [180]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.074610,	
2017-07-13 14:21:41,208 Epoch[84] Batch [190]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.074298,	
2017-07-13 14:21:45,662 Epoch[84] Batch [200]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.074369,	
2017-07-13 14:21:49,980 Epoch[84] Batch [210]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.074085,	
2017-07-13 14:21:54,433 Epoch[84] Batch [220]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.074119,	
2017-07-13 14:21:58,931 Epoch[84] Batch [230]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.073980,	
2017-07-13 14:22:03,235 Epoch[84] Batch [240]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.074312,	
2017-07-13 14:22:07,701 Epoch[84] Batch [250]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.074271,	
2017-07-13 14:22:12,163 Epoch[84] Batch [260]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.074718,	
2017-07-13 14:22:16,367 Epoch[84] Batch [270]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.074763,	
2017-07-13 14:22:20,589 Epoch[84] Batch [280]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.074702,	
2017-07-13 14:22:25,142 Epoch[84] Batch [290]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.074646,	
2017-07-13 14:22:29,272 Epoch[84] Batch [300]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.074746,	
2017-07-13 14:22:33,570 Epoch[84] Batch [310]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.074708,	
2017-07-13 14:22:37,693 Epoch[84] Batch [320]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.074621,	
2017-07-13 14:22:42,163 Epoch[84] Batch [330]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.074469,	
2017-07-13 14:22:46,413 Epoch[84] Batch [340]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.074428,	
2017-07-13 14:22:50,690 Epoch[84] Batch [350]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.074335,	
2017-07-13 14:22:55,194 Epoch[84] Batch [360]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.074336,	
2017-07-13 14:22:59,507 Epoch[84] Batch [370]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.074396,	
2017-07-13 14:23:03,884 Epoch[84] Batch [380]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.074330,	
2017-07-13 14:23:08,420 Epoch[84] Batch [390]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.074371,	
2017-07-13 14:23:12,785 Epoch[84] Batch [400]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.074359,	
2017-07-13 14:23:17,062 Epoch[84] Batch [410]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.074189,	
2017-07-13 14:23:21,102 Epoch[84] Batch [420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.074258,	
2017-07-13 14:23:25,382 Epoch[84] Batch [430]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.074273,	
2017-07-13 14:23:29,396 Epoch[84] Batch [440]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.074240,	
2017-07-13 14:23:33,647 Epoch[84] Batch [450]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.074299,	
2017-07-13 14:23:38,016 Epoch[84] Batch [460]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.074533,	
2017-07-13 14:23:42,187 Epoch[84] Batch [470]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.074276,	
2017-07-13 14:23:46,445 Epoch[84] Batch [480]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.074326,	
2017-07-13 14:23:50,826 Epoch[84] Batch [490]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.074292,	
2017-07-13 14:23:55,172 Epoch[84] Batch [500]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.074257,	
2017-07-13 14:23:59,539 Epoch[84] Batch [510]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.074412,	
2017-07-13 14:24:03,914 Epoch[84] Batch [520]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.074364,	
2017-07-13 14:24:08,156 Epoch[84] Batch [530]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.074333,	
2017-07-13 14:24:12,606 Epoch[84] Batch [540]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.074372,	
2017-07-13 14:24:16,956 Epoch[84] Batch [550]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.074303,	
2017-07-13 14:24:20,974 Epoch[84] Batch [560]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.074231,	
2017-07-13 14:24:25,492 Epoch[84] Batch [570]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.074281,	
2017-07-13 14:24:29,642 Epoch[84] Batch [580]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.074292,	
2017-07-13 14:24:33,977 Epoch[84] Batch [590]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.074356,	
2017-07-13 14:24:38,084 Epoch[84] Batch [600]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.074344,	
2017-07-13 14:24:42,530 Epoch[84] Batch [610]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.074478,	
2017-07-13 14:24:46,756 Epoch[84] Batch [620]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.074337,	
2017-07-13 14:24:50,904 Epoch[84] Batch [630]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.074263,	
2017-07-13 14:24:55,050 Epoch[84] Batch [640]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.074286,	
2017-07-13 14:24:58,999 Epoch[84] Batch [650]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.074260,	
2017-07-13 14:25:03,312 Epoch[84] Batch [660]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.074257,	
2017-07-13 14:25:07,509 Epoch[84] Batch [670]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.074403,	
2017-07-13 14:25:11,954 Epoch[84] Batch [680]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.074314,	
2017-07-13 14:25:16,193 Epoch[84] Batch [690]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.074234,	
2017-07-13 14:25:20,428 Epoch[84] Batch [700]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.074313,	
2017-07-13 14:25:24,661 Epoch[84] Batch [710]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.074340,	
2017-07-13 14:25:28,866 Epoch[84] Batch [720]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.074325,	
2017-07-13 14:25:32,957 Epoch[84] Batch [730]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.074302,	
2017-07-13 14:25:37,253 Epoch[84] Batch [740]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.074417,	
2017-07-13 14:25:41,593 Epoch[84] Batch [750]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.074375,	
2017-07-13 14:25:45,988 Epoch[84] Batch [760]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.074340,	
2017-07-13 14:25:50,329 Epoch[84] Batch [770]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.074312,	
2017-07-13 14:25:54,515 Epoch[84] Batch [780]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.074276,	
2017-07-13 14:25:58,885 Epoch[84] Batch [790]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.074299,	
2017-07-13 14:26:03,146 Epoch[84] Batch [800]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.074321,	
2017-07-13 14:26:07,520 Epoch[84] Batch [810]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.074363,	
2017-07-13 14:26:11,892 Epoch[84] Batch [820]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.074280,	
2017-07-13 14:26:16,038 Epoch[84] Batch [830]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.074201,	
2017-07-13 14:26:20,245 Epoch[84] Batch [840]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.074184,	
2017-07-13 14:26:24,666 Epoch[84] Batch [850]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.074307,	
2017-07-13 14:26:28,691 Epoch[84] Batch [860]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.074393,	
2017-07-13 14:26:32,849 Epoch[84] Batch [870]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.074370,	
2017-07-13 14:26:36,963 Epoch[84] Batch [880]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.074287,	
2017-07-13 14:26:41,203 Epoch[84] Batch [890]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.074253,	
2017-07-13 14:26:45,555 Epoch[84] Batch [900]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.074274,	
2017-07-13 14:26:49,781 Epoch[84] Batch [910]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.074262,	
2017-07-13 14:26:53,968 Epoch[84] Batch [920]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.074279,	
2017-07-13 14:26:58,312 Epoch[84] Batch [930]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.074272,	
2017-07-13 14:27:02,543 Epoch[84] Batch [940]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.074227,	
2017-07-13 14:27:06,714 Epoch[84] Batch [950]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.074139,	
2017-07-13 14:27:10,833 Epoch[84] Batch [960]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.074127,	
2017-07-13 14:27:15,052 Epoch[84] Batch [970]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.074144,	
2017-07-13 14:27:19,181 Epoch[84] Batch [980]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.074087,	
2017-07-13 14:27:23,252 Epoch[84] Batch [990]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.074127,	
2017-07-13 14:27:27,526 Epoch[84] Batch [1000]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.074129,	
2017-07-13 14:27:31,495 Epoch[84] Batch [1010]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.074098,	
2017-07-13 14:27:35,756 Epoch[84] Batch [1020]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.074133,	
2017-07-13 14:27:40,159 Epoch[84] Batch [1030]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.074059,	
2017-07-13 14:27:44,166 Epoch[84] Batch [1040]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.073992,	
2017-07-13 14:27:48,381 Epoch[84] Batch [1050]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.074081,	
2017-07-13 14:27:52,504 Epoch[84] Batch [1060]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.074096,	
2017-07-13 14:27:56,679 Epoch[84] Batch [1070]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.074081,	
2017-07-13 14:28:00,775 Epoch[84] Batch [1080]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.074091,	
2017-07-13 14:28:04,942 Epoch[84] Batch [1090]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.074170,	
2017-07-13 14:28:09,165 Epoch[84] Batch [1100]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.074110,	
2017-07-13 14:28:13,123 Epoch[84] Batch [1110]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.074185,	
2017-07-13 14:28:17,207 Epoch[84] Batch [1120]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.074210,	
2017-07-13 14:28:21,242 Epoch[84] Batch [1130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.074224,	
2017-07-13 14:28:25,277 Epoch[84] Batch [1140]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.074334,	
2017-07-13 14:28:29,580 Epoch[84] Batch [1150]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.074315,	
2017-07-13 14:28:33,699 Epoch[84] Batch [1160]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.074299,	
2017-07-13 14:28:37,758 Epoch[84] Batch [1170]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.074338,	
2017-07-13 14:28:42,032 Epoch[84] Batch [1180]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.074409,	
2017-07-13 14:28:46,194 Epoch[84] Batch [1190]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.074456,	
2017-07-13 14:28:50,375 Epoch[84] Batch [1200]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.074440,	
2017-07-13 14:28:54,870 Epoch[84] Batch [1210]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.074403,	
2017-07-13 14:28:58,985 Epoch[84] Batch [1220]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.074433,	
2017-07-13 14:29:02,934 Epoch[84] Batch [1230]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.074434,	
2017-07-13 14:29:07,141 Epoch[84] Batch [1240]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.074432,	
2017-07-13 14:29:11,382 Epoch[84] Batch [1250]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.074502,	
2017-07-13 14:29:15,345 Epoch[84] Batch [1260]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.074553,	
2017-07-13 14:29:19,739 Epoch[84] Batch [1270]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.074522,	
2017-07-13 14:29:24,072 Epoch[84] Batch [1280]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.074603,	
2017-07-13 14:29:28,318 Epoch[84] Batch [1290]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.074674,	
2017-07-13 14:29:32,554 Epoch[84] Batch [1300]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.074660,	
2017-07-13 14:29:36,825 Epoch[84] Batch [1310]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.074707,	
2017-07-13 14:29:40,863 Epoch[84] Batch [1320]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.074652,	
2017-07-13 14:29:44,934 Epoch[84] Batch [1330]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.074612,	
2017-07-13 14:29:49,057 Epoch[84] Batch [1340]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.074610,	
2017-07-13 14:29:53,147 Epoch[84] Batch [1350]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.074597,	
2017-07-13 14:29:57,412 Epoch[84] Batch [1360]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.074579,	
2017-07-13 14:30:01,711 Epoch[84] Batch [1370]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.074532,	
2017-07-13 14:30:05,716 Epoch[84] Batch [1380]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.074541,	
2017-07-13 14:30:10,001 Epoch[84] Batch [1390]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.074562,	
2017-07-13 14:30:13,984 Epoch[84] Batch [1400]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.074544,	
2017-07-13 14:30:18,038 Epoch[84] Batch [1410]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.074647,	
2017-07-13 14:30:22,174 Epoch[84] Batch [1420]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.074625,	
2017-07-13 14:30:26,335 Epoch[84] Batch [1430]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.074637,	
2017-07-13 14:30:30,344 Epoch[84] Batch [1440]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.074585,	
2017-07-13 14:30:34,540 Epoch[84] Batch [1450]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.074620,	
2017-07-13 14:30:38,675 Epoch[84] Batch [1460]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.074640,	
2017-07-13 14:30:42,952 Epoch[84] Batch [1470]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.074646,	
2017-07-13 14:30:47,155 Epoch[84] Batch [1480]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.074633,	
2017-07-13 14:30:49,664 Epoch[84] Train-FCNLogLoss=0.074595
2017-07-13 14:30:49,664 Epoch[84] Time cost=640.919
2017-07-13 14:30:50,314 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0085.params"
2017-07-13 14:30:53,344 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0085.states"
2017-07-13 14:30:58,577 Epoch[85] Batch [10]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.079198,	
2017-07-13 14:31:02,938 Epoch[85] Batch [20]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.076935,	
2017-07-13 14:31:07,346 Epoch[85] Batch [30]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.074758,	
2017-07-13 14:31:11,380 Epoch[85] Batch [40]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.074617,	
2017-07-13 14:31:15,519 Epoch[85] Batch [50]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.073724,	
2017-07-13 14:31:20,000 Epoch[85] Batch [60]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.072536,	
2017-07-13 14:31:24,122 Epoch[85] Batch [70]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.073226,	
2017-07-13 14:31:28,341 Epoch[85] Batch [80]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.073422,	
2017-07-13 14:31:32,450 Epoch[85] Batch [90]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.073880,	
2017-07-13 14:31:36,621 Epoch[85] Batch [100]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.074472,	
2017-07-13 14:31:40,784 Epoch[85] Batch [110]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.075607,	
2017-07-13 14:31:45,098 Epoch[85] Batch [120]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.075748,	
2017-07-13 14:31:49,520 Epoch[85] Batch [130]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075605,	
2017-07-13 14:31:53,960 Epoch[85] Batch [140]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.075514,	
2017-07-13 14:31:58,155 Epoch[85] Batch [150]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.075266,	
2017-07-13 14:32:02,547 Epoch[85] Batch [160]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075288,	
2017-07-13 14:32:06,830 Epoch[85] Batch [170]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.075301,	
2017-07-13 14:32:11,118 Epoch[85] Batch [180]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.075786,	
2017-07-13 14:32:15,364 Epoch[85] Batch [190]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.076092,	
2017-07-13 14:32:19,902 Epoch[85] Batch [200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.076004,	
2017-07-13 14:32:24,207 Epoch[85] Batch [210]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.076081,	
2017-07-13 14:32:28,525 Epoch[85] Batch [220]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.075951,	
2017-07-13 14:32:32,860 Epoch[85] Batch [230]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.075941,	
2017-07-13 14:32:36,985 Epoch[85] Batch [240]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.075860,	
2017-07-13 14:32:41,132 Epoch[85] Batch [250]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.076254,	
2017-07-13 14:32:45,255 Epoch[85] Batch [260]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.076190,	
2017-07-13 14:32:49,405 Epoch[85] Batch [270]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.075798,	
2017-07-13 14:32:53,826 Epoch[85] Batch [280]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075825,	
2017-07-13 14:32:58,209 Epoch[85] Batch [290]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.075757,	
2017-07-13 14:33:02,579 Epoch[85] Batch [300]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.075651,	
2017-07-13 14:33:07,026 Epoch[85] Batch [310]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.075841,	
2017-07-13 14:33:11,435 Epoch[85] Batch [320]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.075846,	
2017-07-13 14:33:15,735 Epoch[85] Batch [330]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.076007,	
2017-07-13 14:33:20,150 Epoch[85] Batch [340]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.076037,	
2017-07-13 14:33:24,342 Epoch[85] Batch [350]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.075988,	
2017-07-13 14:33:28,700 Epoch[85] Batch [360]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.075932,	
2017-07-13 14:33:33,046 Epoch[85] Batch [370]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.075841,	
2017-07-13 14:33:37,355 Epoch[85] Batch [380]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075850,	
2017-07-13 14:33:41,789 Epoch[85] Batch [390]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.075750,	
2017-07-13 14:33:46,008 Epoch[85] Batch [400]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.075841,	
2017-07-13 14:33:50,278 Epoch[85] Batch [410]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.075741,	
2017-07-13 14:33:54,589 Epoch[85] Batch [420]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.075835,	
2017-07-13 14:33:58,796 Epoch[85] Batch [430]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.075776,	
2017-07-13 14:34:03,008 Epoch[85] Batch [440]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.075593,	
2017-07-13 14:34:07,215 Epoch[85] Batch [450]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.075483,	
2017-07-13 14:34:11,731 Epoch[85] Batch [460]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.075467,	
2017-07-13 14:34:15,899 Epoch[85] Batch [470]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.075455,	
2017-07-13 14:34:20,153 Epoch[85] Batch [480]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.075473,	
2017-07-13 14:34:24,262 Epoch[85] Batch [490]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.075277,	
2017-07-13 14:34:28,816 Epoch[85] Batch [500]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.075220,	
2017-07-13 14:34:32,900 Epoch[85] Batch [510]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.075149,	
2017-07-13 14:34:37,075 Epoch[85] Batch [520]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.075161,	
2017-07-13 14:34:41,383 Epoch[85] Batch [530]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.075136,	
2017-07-13 14:34:45,496 Epoch[85] Batch [540]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.075125,	
2017-07-13 14:34:49,771 Epoch[85] Batch [550]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.075045,	
2017-07-13 14:34:54,176 Epoch[85] Batch [560]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.074955,	
2017-07-13 14:34:58,224 Epoch[85] Batch [570]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.074872,	
2017-07-13 14:35:02,429 Epoch[85] Batch [580]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.074897,	
2017-07-13 14:35:06,830 Epoch[85] Batch [590]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.074934,	
2017-07-13 14:35:11,117 Epoch[85] Batch [600]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.074949,	
2017-07-13 14:35:15,356 Epoch[85] Batch [610]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.074970,	
2017-07-13 14:35:19,592 Epoch[85] Batch [620]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.075125,	
2017-07-13 14:35:23,817 Epoch[85] Batch [630]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.075077,	
2017-07-13 14:35:28,027 Epoch[85] Batch [640]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.075019,	
2017-07-13 14:35:32,383 Epoch[85] Batch [650]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.074895,	
2017-07-13 14:35:36,723 Epoch[85] Batch [660]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.075006,	
2017-07-13 14:35:41,112 Epoch[85] Batch [670]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.075019,	
2017-07-13 14:35:45,532 Epoch[85] Batch [680]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.075052,	
2017-07-13 14:35:49,793 Epoch[85] Batch [690]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.075021,	
2017-07-13 14:35:54,191 Epoch[85] Batch [700]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.074994,	
2017-07-13 14:35:58,713 Epoch[85] Batch [710]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.074971,	
2017-07-13 14:36:03,170 Epoch[85] Batch [720]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.074913,	
2017-07-13 14:36:07,615 Epoch[85] Batch [730]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.074948,	
2017-07-13 14:36:11,986 Epoch[85] Batch [740]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.074913,	
2017-07-13 14:36:16,459 Epoch[85] Batch [750]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.074908,	
2017-07-13 14:36:20,981 Epoch[85] Batch [760]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.074935,	
2017-07-13 14:36:25,364 Epoch[85] Batch [770]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.074910,	
2017-07-13 14:36:29,575 Epoch[85] Batch [780]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.074928,	
2017-07-13 14:36:33,947 Epoch[85] Batch [790]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.074954,	
2017-07-13 14:36:38,033 Epoch[85] Batch [800]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.074767,	
2017-07-13 14:36:42,606 Epoch[85] Batch [810]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.074737,	
2017-07-13 14:36:46,894 Epoch[85] Batch [820]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.074661,	
2017-07-13 14:36:51,090 Epoch[85] Batch [830]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.074702,	
2017-07-13 14:36:55,328 Epoch[85] Batch [840]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.074675,	
2017-07-13 14:36:59,619 Epoch[85] Batch [850]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.074738,	
2017-07-13 14:37:03,723 Epoch[85] Batch [860]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.074658,	
2017-07-13 14:37:07,850 Epoch[85] Batch [870]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.074670,	
2017-07-13 14:37:12,069 Epoch[85] Batch [880]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.074665,	
2017-07-13 14:37:16,668 Epoch[85] Batch [890]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.074624,	
2017-07-13 14:37:20,925 Epoch[85] Batch [900]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.074594,	
2017-07-13 14:37:24,912 Epoch[85] Batch [910]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.074579,	
2017-07-13 14:37:29,094 Epoch[85] Batch [920]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.074581,	
2017-07-13 14:37:33,378 Epoch[85] Batch [930]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.074633,	
2017-07-13 14:37:37,790 Epoch[85] Batch [940]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.074623,	
2017-07-13 14:37:41,850 Epoch[85] Batch [950]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.074646,	
2017-07-13 14:37:45,890 Epoch[85] Batch [960]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.074628,	
2017-07-13 14:37:50,058 Epoch[85] Batch [970]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.074577,	
2017-07-13 14:37:54,269 Epoch[85] Batch [980]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.074617,	
2017-07-13 14:37:58,384 Epoch[85] Batch [990]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.074561,	
2017-07-13 14:38:02,521 Epoch[85] Batch [1000]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.074536,	
2017-07-13 14:38:06,848 Epoch[85] Batch [1010]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.074555,	
2017-07-13 14:38:11,193 Epoch[85] Batch [1020]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.074637,	
2017-07-13 14:38:15,345 Epoch[85] Batch [1030]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.074616,	
2017-07-13 14:38:19,810 Epoch[85] Batch [1040]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.074617,	
2017-07-13 14:38:23,839 Epoch[85] Batch [1050]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.074634,	
2017-07-13 14:38:28,229 Epoch[85] Batch [1060]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.074691,	
2017-07-13 14:38:32,511 Epoch[85] Batch [1070]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.074708,	
2017-07-13 14:38:36,657 Epoch[85] Batch [1080]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.074712,	
2017-07-13 14:38:40,959 Epoch[85] Batch [1090]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.074792,	
2017-07-13 14:38:45,372 Epoch[85] Batch [1100]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.074767,	
2017-07-13 14:38:49,475 Epoch[85] Batch [1110]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.074698,	
2017-07-13 14:38:53,678 Epoch[85] Batch [1120]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.074647,	
2017-07-13 14:38:57,737 Epoch[85] Batch [1130]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.074660,	
2017-07-13 14:39:01,925 Epoch[85] Batch [1140]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.074667,	
2017-07-13 14:39:06,023 Epoch[85] Batch [1150]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.074689,	
2017-07-13 14:39:10,207 Epoch[85] Batch [1160]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.074659,	
2017-07-13 14:39:14,500 Epoch[85] Batch [1170]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.074634,	
2017-07-13 14:39:18,855 Epoch[85] Batch [1180]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.074588,	
2017-07-13 14:39:23,066 Epoch[85] Batch [1190]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.074534,	
2017-07-13 14:39:27,354 Epoch[85] Batch [1200]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.074498,	
2017-07-13 14:39:31,737 Epoch[85] Batch [1210]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.074420,	
2017-07-13 14:39:36,051 Epoch[85] Batch [1220]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.074404,	
2017-07-13 14:39:40,589 Epoch[85] Batch [1230]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.074427,	
2017-07-13 14:39:44,997 Epoch[85] Batch [1240]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.074365,	
2017-07-13 14:39:49,479 Epoch[85] Batch [1250]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.074305,	
2017-07-13 14:39:54,211 Epoch[85] Batch [1260]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.074331,	
2017-07-13 14:39:59,053 Epoch[85] Batch [1270]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.074329,	
2017-07-13 14:40:03,568 Epoch[85] Batch [1280]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.074348,	
2017-07-13 14:40:08,216 Epoch[85] Batch [1290]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.074302,	
2017-07-13 14:40:13,059 Epoch[85] Batch [1300]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.074300,	
2017-07-13 14:40:18,028 Epoch[85] Batch [1310]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.074265,	
2017-07-13 14:40:22,762 Epoch[85] Batch [1320]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.074354,	
2017-07-13 14:40:27,627 Epoch[85] Batch [1330]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.074327,	
2017-07-13 14:40:32,198 Epoch[85] Batch [1340]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.074327,	
2017-07-13 14:40:37,019 Epoch[85] Batch [1350]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.074337,	
2017-07-13 14:40:41,811 Epoch[85] Batch [1360]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.074319,	
2017-07-13 14:40:46,606 Epoch[85] Batch [1370]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.074283,	
2017-07-13 14:40:51,425 Epoch[85] Batch [1380]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.074276,	
2017-07-13 14:40:56,476 Epoch[85] Batch [1390]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.074223,	
2017-07-13 14:41:01,463 Epoch[85] Batch [1400]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.074234,	
2017-07-13 14:41:06,054 Epoch[85] Batch [1410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.074251,	
2017-07-13 14:41:10,705 Epoch[85] Batch [1420]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.074199,	
2017-07-13 14:41:15,173 Epoch[85] Batch [1430]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.074206,	
2017-07-13 14:41:19,918 Epoch[85] Batch [1440]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.074281,	
2017-07-13 14:41:24,571 Epoch[85] Batch [1450]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.074206,	
2017-07-13 14:41:29,350 Epoch[85] Batch [1460]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.074270,	
2017-07-13 14:41:33,956 Epoch[85] Batch [1470]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.074234,	
2017-07-13 14:41:38,659 Epoch[85] Batch [1480]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.074235,	
2017-07-13 14:41:41,661 Epoch[85] Train-FCNLogLoss=0.074185
2017-07-13 14:41:41,661 Epoch[85] Time cost=648.317
2017-07-13 14:41:42,340 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0086.params"
2017-07-13 14:41:45,879 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0086.states"
2017-07-13 14:41:51,388 Epoch[86] Batch [10]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.075881,	
2017-07-13 14:41:56,246 Epoch[86] Batch [20]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.075787,	
2017-07-13 14:42:01,307 Epoch[86] Batch [30]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.072740,	
2017-07-13 14:42:06,586 Epoch[86] Batch [40]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.074148,	
2017-07-13 14:42:11,325 Epoch[86] Batch [50]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.074110,	
2017-07-13 14:42:15,933 Epoch[86] Batch [60]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.073692,	
2017-07-13 14:42:20,491 Epoch[86] Batch [70]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.073979,	
2017-07-13 14:42:25,235 Epoch[86] Batch [80]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.073219,	
2017-07-13 14:42:29,787 Epoch[86] Batch [90]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.073891,	
2017-07-13 14:42:34,568 Epoch[86] Batch [100]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.074541,	
2017-07-13 14:42:39,417 Epoch[86] Batch [110]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.074369,	
2017-07-13 14:42:44,019 Epoch[86] Batch [120]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.073839,	
2017-07-13 14:42:48,736 Epoch[86] Batch [130]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.073442,	
2017-07-13 14:42:53,551 Epoch[86] Batch [140]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.073676,	
2017-07-13 14:42:58,300 Epoch[86] Batch [150]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.073576,	
2017-07-13 14:43:03,241 Epoch[86] Batch [160]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.073423,	
2017-07-13 14:43:08,144 Epoch[86] Batch [170]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.073228,	
2017-07-13 14:43:13,283 Epoch[86] Batch [180]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.073316,	
2017-07-13 14:43:18,363 Epoch[86] Batch [190]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.073817,	
2017-07-13 14:43:23,297 Epoch[86] Batch [200]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.073638,	
2017-07-13 14:43:28,176 Epoch[86] Batch [210]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.073526,	
2017-07-13 14:43:33,632 Epoch[86] Batch [220]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.072986,	
2017-07-13 14:43:38,332 Epoch[86] Batch [230]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.073316,	
2017-07-13 14:43:43,721 Epoch[86] Batch [240]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.073016,	
2017-07-13 14:43:48,740 Epoch[86] Batch [250]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.073018,	
2017-07-13 14:43:53,453 Epoch[86] Batch [260]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.072764,	
2017-07-13 14:43:58,218 Epoch[86] Batch [270]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.073030,	
2017-07-13 14:44:03,141 Epoch[86] Batch [280]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.073227,	
2017-07-13 14:44:08,213 Epoch[86] Batch [290]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.073300,	
2017-07-13 14:44:14,274 Epoch[86] Batch [300]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.073160,	
2017-07-13 14:44:19,408 Epoch[86] Batch [310]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.073223,	
2017-07-13 14:44:24,567 Epoch[86] Batch [320]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.073271,	
2017-07-13 14:44:29,593 Epoch[86] Batch [330]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.073132,	
2017-07-13 14:44:35,872 Epoch[86] Batch [340]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.073091,	
2017-07-13 14:44:41,146 Epoch[86] Batch [350]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.073214,	
2017-07-13 14:44:46,242 Epoch[86] Batch [360]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.073352,	
2017-07-13 14:44:51,734 Epoch[86] Batch [370]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.073344,	
2017-07-13 14:44:56,791 Epoch[86] Batch [380]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.073376,	
2017-07-13 14:45:02,321 Epoch[86] Batch [390]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.073341,	
2017-07-13 14:45:08,291 Epoch[86] Batch [400]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.073458,	
2017-07-13 14:45:15,016 Epoch[86] Batch [410]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073702,	
2017-07-13 14:45:20,099 Epoch[86] Batch [420]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.073851,	
2017-07-13 14:45:24,900 Epoch[86] Batch [430]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.073953,	
2017-07-13 14:45:30,387 Epoch[86] Batch [440]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.073950,	
2017-07-13 14:45:35,399 Epoch[86] Batch [450]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.074172,	
2017-07-13 14:45:40,756 Epoch[86] Batch [460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.074228,	
2017-07-13 14:45:45,685 Epoch[86] Batch [470]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.074169,	
2017-07-13 14:45:51,295 Epoch[86] Batch [480]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.074091,	
2017-07-13 14:45:56,376 Epoch[86] Batch [490]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.074175,	
2017-07-13 14:46:01,793 Epoch[86] Batch [500]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.074215,	
2017-07-13 14:46:07,321 Epoch[86] Batch [510]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.074073,	
2017-07-13 14:46:12,791 Epoch[86] Batch [520]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.073981,	
2017-07-13 14:46:17,932 Epoch[86] Batch [530]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.073962,	
2017-07-13 14:46:22,901 Epoch[86] Batch [540]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.073894,	
2017-07-13 14:46:27,839 Epoch[86] Batch [550]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.074138,	
2017-07-13 14:46:33,249 Epoch[86] Batch [560]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.074207,	
2017-07-13 14:46:39,035 Epoch[86] Batch [570]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.074266,	
2017-07-13 14:46:44,632 Epoch[86] Batch [580]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.074353,	
2017-07-13 14:46:50,327 Epoch[86] Batch [590]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.074448,	
2017-07-13 14:46:56,112 Epoch[86] Batch [600]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.074332,	
2017-07-13 14:47:01,356 Epoch[86] Batch [610]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.074421,	
2017-07-13 14:47:06,322 Epoch[86] Batch [620]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.074436,	
2017-07-13 14:47:11,326 Epoch[86] Batch [630]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.074468,	
2017-07-13 14:47:16,569 Epoch[86] Batch [640]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.074513,	
2017-07-13 14:47:21,910 Epoch[86] Batch [650]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.074434,	
2017-07-13 14:47:27,304 Epoch[86] Batch [660]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.074398,	
2017-07-13 14:47:32,717 Epoch[86] Batch [670]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.074334,	
2017-07-13 14:47:38,063 Epoch[86] Batch [680]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.074347,	
2017-07-13 14:47:43,268 Epoch[86] Batch [690]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.074318,	
2017-07-13 14:47:48,438 Epoch[86] Batch [700]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.074334,	
2017-07-13 14:47:53,454 Epoch[86] Batch [710]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.074402,	
2017-07-13 14:47:58,552 Epoch[86] Batch [720]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.074418,	
2017-07-13 14:48:04,102 Epoch[86] Batch [730]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.074388,	
2017-07-13 14:48:09,951 Epoch[86] Batch [740]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.074388,	
2017-07-13 14:48:15,628 Epoch[86] Batch [750]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.074380,	
2017-07-13 14:48:21,579 Epoch[86] Batch [760]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.074412,	
2017-07-13 14:48:26,708 Epoch[86] Batch [770]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.074395,	
2017-07-13 14:48:32,544 Epoch[86] Batch [780]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.074293,	
2017-07-13 14:48:38,400 Epoch[86] Batch [790]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.074274,	
2017-07-13 14:48:43,668 Epoch[86] Batch [800]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.074272,	
2017-07-13 14:48:49,247 Epoch[86] Batch [810]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.074239,	
2017-07-13 14:48:54,538 Epoch[86] Batch [820]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.074196,	
2017-07-13 14:48:59,981 Epoch[86] Batch [830]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.074143,	
2017-07-13 14:49:05,472 Epoch[86] Batch [840]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.074219,	
2017-07-13 14:49:11,060 Epoch[86] Batch [850]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.074131,	
2017-07-13 14:49:16,256 Epoch[86] Batch [860]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.074112,	
2017-07-13 14:49:21,438 Epoch[86] Batch [870]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.074031,	
2017-07-13 14:49:26,942 Epoch[86] Batch [880]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.073967,	
2017-07-13 14:49:32,038 Epoch[86] Batch [890]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.073964,	
2017-07-13 14:49:36,992 Epoch[86] Batch [900]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.073945,	
2017-07-13 14:49:42,623 Epoch[86] Batch [910]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.073936,	
2017-07-13 14:49:47,996 Epoch[86] Batch [920]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.073910,	
2017-07-13 14:49:53,486 Epoch[86] Batch [930]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.073948,	
2017-07-13 14:49:58,567 Epoch[86] Batch [940]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.073876,	
2017-07-13 14:50:03,730 Epoch[86] Batch [950]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.073907,	
2017-07-13 14:50:08,885 Epoch[86] Batch [960]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.073870,	
2017-07-13 14:50:14,181 Epoch[86] Batch [970]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.073820,	
2017-07-13 14:50:19,425 Epoch[86] Batch [980]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.073875,	
2017-07-13 14:50:25,656 Epoch[86] Batch [990]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.073897,	
2017-07-13 14:50:31,428 Epoch[86] Batch [1000]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.073925,	
2017-07-13 14:50:36,781 Epoch[86] Batch [1010]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.073908,	
2017-07-13 14:50:42,666 Epoch[86] Batch [1020]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.073864,	
2017-07-13 14:50:48,326 Epoch[86] Batch [1030]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.073911,	
2017-07-13 14:50:54,326 Epoch[86] Batch [1040]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.073939,	
2017-07-13 14:51:00,506 Epoch[86] Batch [1050]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.073949,	
2017-07-13 14:51:06,646 Epoch[86] Batch [1060]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.073970,	
2017-07-13 14:51:12,596 Epoch[86] Batch [1070]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.073965,	
2017-07-13 14:51:18,352 Epoch[86] Batch [1080]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.073970,	
2017-07-13 14:51:24,481 Epoch[86] Batch [1090]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.073992,	
2017-07-13 14:51:30,391 Epoch[86] Batch [1100]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.074007,	
2017-07-13 14:51:36,685 Epoch[86] Batch [1110]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.073960,	
2017-07-13 14:51:42,345 Epoch[86] Batch [1120]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.073943,	
2017-07-13 14:51:47,821 Epoch[86] Batch [1130]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.073969,	
2017-07-13 14:51:53,780 Epoch[86] Batch [1140]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.074060,	
2017-07-13 14:51:59,786 Epoch[86] Batch [1150]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.074060,	
2017-07-13 14:52:05,731 Epoch[86] Batch [1160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.074062,	
2017-07-13 14:52:11,917 Epoch[86] Batch [1170]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.074096,	
2017-07-13 14:52:17,750 Epoch[86] Batch [1180]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.074033,	
2017-07-13 14:52:23,205 Epoch[86] Batch [1190]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.074049,	
2017-07-13 14:52:29,090 Epoch[86] Batch [1200]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.073975,	
2017-07-13 14:52:35,107 Epoch[86] Batch [1210]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.074096,	
2017-07-13 14:52:41,448 Epoch[86] Batch [1220]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.074090,	
2017-07-13 14:52:46,857 Epoch[86] Batch [1230]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.074106,	
2017-07-13 14:52:52,952 Epoch[86] Batch [1240]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.074119,	
2017-07-13 14:52:59,454 Epoch[86] Batch [1250]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.074156,	
2017-07-13 14:53:05,547 Epoch[86] Batch [1260]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.074131,	
2017-07-13 14:53:11,548 Epoch[86] Batch [1270]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.074068,	
2017-07-13 14:53:17,944 Epoch[86] Batch [1280]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.073975,	
2017-07-13 14:53:23,578 Epoch[86] Batch [1290]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.074002,	
2017-07-13 14:53:29,481 Epoch[86] Batch [1300]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.073979,	
2017-07-13 14:53:35,535 Epoch[86] Batch [1310]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.074027,	
2017-07-13 14:53:41,570 Epoch[86] Batch [1320]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.074077,	
2017-07-13 14:53:47,772 Epoch[86] Batch [1330]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.074109,	
2017-07-13 14:53:53,730 Epoch[86] Batch [1340]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.074183,	
2017-07-13 14:53:59,464 Epoch[86] Batch [1350]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.074191,	
2017-07-13 14:54:05,499 Epoch[86] Batch [1360]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.074172,	
2017-07-13 14:54:12,053 Epoch[86] Batch [1370]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.074189,	
2017-07-13 14:54:18,325 Epoch[86] Batch [1380]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.074136,	
2017-07-13 14:54:23,919 Epoch[86] Batch [1390]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.074140,	
2017-07-13 14:54:29,250 Epoch[86] Batch [1400]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.074124,	
2017-07-13 14:54:34,954 Epoch[86] Batch [1410]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.074188,	
2017-07-13 14:54:40,301 Epoch[86] Batch [1420]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.074192,	
2017-07-13 14:54:46,387 Epoch[86] Batch [1430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.074176,	
2017-07-13 14:54:52,041 Epoch[86] Batch [1440]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.074145,	
2017-07-13 14:54:57,720 Epoch[86] Batch [1450]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.074124,	
2017-07-13 14:55:03,777 Epoch[86] Batch [1460]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.074184,	
2017-07-13 14:55:10,037 Epoch[86] Batch [1470]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.074194,	
2017-07-13 14:55:16,200 Epoch[86] Batch [1480]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.074180,	
2017-07-13 14:55:19,901 Epoch[86] Train-FCNLogLoss=0.074146
2017-07-13 14:55:19,901 Epoch[86] Time cost=814.021
2017-07-13 14:55:20,964 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0087.params"
2017-07-13 14:55:24,403 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0087.states"
2017-07-13 14:55:30,676 Epoch[87] Batch [10]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.070780,	
2017-07-13 14:55:36,251 Epoch[87] Batch [20]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.072534,	
2017-07-13 14:55:42,285 Epoch[87] Batch [30]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.075940,	
2017-07-13 14:55:47,958 Epoch[87] Batch [40]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.075058,	
2017-07-13 14:55:53,136 Epoch[87] Batch [50]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.073911,	
2017-07-13 14:55:59,124 Epoch[87] Batch [60]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.074305,	
2017-07-13 14:56:05,054 Epoch[87] Batch [70]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.074229,	
2017-07-13 14:56:11,110 Epoch[87] Batch [80]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.074146,	
2017-07-13 14:56:16,782 Epoch[87] Batch [90]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.073938,	
2017-07-13 14:56:22,530 Epoch[87] Batch [100]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.074247,	
2017-07-13 14:56:27,919 Epoch[87] Batch [110]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.074098,	
2017-07-13 14:56:33,896 Epoch[87] Batch [120]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.074514,	
2017-07-13 14:56:40,253 Epoch[87] Batch [130]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.074245,	
2017-07-13 14:56:46,712 Epoch[87] Batch [140]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.073885,	
2017-07-13 14:56:52,541 Epoch[87] Batch [150]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.074052,	
2017-07-13 14:56:58,706 Epoch[87] Batch [160]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.074121,	
2017-07-13 14:57:04,747 Epoch[87] Batch [170]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.074150,	
2017-07-13 14:57:11,151 Epoch[87] Batch [180]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.074149,	
2017-07-13 14:57:17,671 Epoch[87] Batch [190]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.074293,	
2017-07-13 14:57:24,091 Epoch[87] Batch [200]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.074363,	
2017-07-13 14:57:30,308 Epoch[87] Batch [210]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.074226,	
2017-07-13 14:57:36,306 Epoch[87] Batch [220]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.074361,	
2017-07-13 14:57:42,624 Epoch[87] Batch [230]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.074442,	
2017-07-13 14:57:48,829 Epoch[87] Batch [240]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.074432,	
2017-07-13 14:57:55,526 Epoch[87] Batch [250]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.074407,	
2017-07-13 14:58:01,841 Epoch[87] Batch [260]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.074276,	
2017-07-13 14:58:07,714 Epoch[87] Batch [270]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.074109,	
2017-07-13 14:58:14,325 Epoch[87] Batch [280]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.073903,	
2017-07-13 14:58:20,901 Epoch[87] Batch [290]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.073816,	
2017-07-13 14:58:27,074 Epoch[87] Batch [300]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.073758,	
2017-07-13 14:58:33,496 Epoch[87] Batch [310]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.073689,	
2017-07-13 14:58:39,922 Epoch[87] Batch [320]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.073586,	
2017-07-13 14:58:46,193 Epoch[87] Batch [330]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.073689,	
2017-07-13 14:58:52,234 Epoch[87] Batch [340]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.073656,	
2017-07-13 14:58:58,287 Epoch[87] Batch [350]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.073777,	
2017-07-13 14:59:04,534 Epoch[87] Batch [360]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.073859,	
2017-07-13 14:59:10,913 Epoch[87] Batch [370]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.073976,	
2017-07-13 14:59:17,054 Epoch[87] Batch [380]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.073857,	
2017-07-13 14:59:23,002 Epoch[87] Batch [390]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.073825,	
2017-07-13 14:59:28,664 Epoch[87] Batch [400]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.073875,	
2017-07-13 14:59:35,081 Epoch[87] Batch [410]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.073879,	
2017-07-13 14:59:41,365 Epoch[87] Batch [420]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.073889,	
2017-07-13 14:59:48,034 Epoch[87] Batch [430]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073968,	
2017-07-13 14:59:54,393 Epoch[87] Batch [440]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.074054,	
2017-07-13 15:00:00,589 Epoch[87] Batch [450]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.074246,	
2017-07-13 15:00:06,465 Epoch[87] Batch [460]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.074399,	
2017-07-13 15:00:12,869 Epoch[87] Batch [470]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.074332,	
2017-07-13 15:00:19,004 Epoch[87] Batch [480]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.074360,	
2017-07-13 15:00:25,391 Epoch[87] Batch [490]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.074295,	
2017-07-13 15:00:31,413 Epoch[87] Batch [500]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.074164,	
2017-07-13 15:00:37,515 Epoch[87] Batch [510]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.074234,	
2017-07-13 15:00:43,908 Epoch[87] Batch [520]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.074289,	
2017-07-13 15:00:50,501 Epoch[87] Batch [530]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.074270,	
2017-07-13 15:00:56,715 Epoch[87] Batch [540]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.074219,	
2017-07-13 15:01:03,109 Epoch[87] Batch [550]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.074267,	
2017-07-13 15:01:09,156 Epoch[87] Batch [560]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.074040,	
2017-07-13 15:01:15,550 Epoch[87] Batch [570]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073962,	
2017-07-13 15:01:21,734 Epoch[87] Batch [580]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.073891,	
2017-07-13 15:01:28,058 Epoch[87] Batch [590]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.073967,	
2017-07-13 15:01:34,640 Epoch[87] Batch [600]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.074011,	
2017-07-13 15:01:41,070 Epoch[87] Batch [610]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.073956,	
2017-07-13 15:01:47,815 Epoch[87] Batch [620]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073969,	
2017-07-13 15:01:54,309 Epoch[87] Batch [630]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.073948,	
2017-07-13 15:02:00,623 Epoch[87] Batch [640]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.073986,	
2017-07-13 15:02:07,281 Epoch[87] Batch [650]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073975,	
2017-07-13 15:02:13,710 Epoch[87] Batch [660]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.073913,	
2017-07-13 15:02:19,943 Epoch[87] Batch [670]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.073960,	
2017-07-13 15:02:26,130 Epoch[87] Batch [680]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.073892,	
2017-07-13 15:02:32,576 Epoch[87] Batch [690]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.073928,	
2017-07-13 15:02:39,029 Epoch[87] Batch [700]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.074036,	
2017-07-13 15:02:45,520 Epoch[87] Batch [710]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.074084,	
2017-07-13 15:02:51,796 Epoch[87] Batch [720]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.073974,	
2017-07-13 15:02:57,614 Epoch[87] Batch [730]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.073992,	
2017-07-13 15:03:03,330 Epoch[87] Batch [740]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.073931,	
2017-07-13 15:03:09,386 Epoch[87] Batch [750]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.073955,	
2017-07-13 15:03:15,475 Epoch[87] Batch [760]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.074041,	
2017-07-13 15:03:21,840 Epoch[87] Batch [770]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.074014,	
2017-07-13 15:03:27,966 Epoch[87] Batch [780]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.074037,	
2017-07-13 15:03:33,984 Epoch[87] Batch [790]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.074095,	
2017-07-13 15:03:40,277 Epoch[87] Batch [800]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.074210,	
2017-07-13 15:03:46,954 Epoch[87] Batch [810]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.074288,	
2017-07-13 15:03:52,880 Epoch[87] Batch [820]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.074364,	
2017-07-13 15:03:59,004 Epoch[87] Batch [830]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.074382,	
2017-07-13 15:04:05,319 Epoch[87] Batch [840]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.074446,	
2017-07-13 15:04:11,871 Epoch[87] Batch [850]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.074420,	
2017-07-13 15:04:18,105 Epoch[87] Batch [860]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.074474,	
2017-07-13 15:04:24,762 Epoch[87] Batch [870]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.074377,	
2017-07-13 15:04:31,289 Epoch[87] Batch [880]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.074422,	
2017-07-13 15:04:37,818 Epoch[87] Batch [890]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.074469,	
2017-07-13 15:04:43,475 Epoch[87] Batch [900]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.074411,	
2017-07-13 15:04:50,711 Epoch[87] Batch [910]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.074384,	
2017-07-13 15:04:58,589 Epoch[87] Batch [920]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.074325,	
2017-07-13 15:05:07,444 Epoch[87] Batch [930]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.074323,	
2017-07-13 15:05:15,895 Epoch[87] Batch [940]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.074298,	
2017-07-13 15:05:22,908 Epoch[87] Batch [950]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.074293,	
2017-07-13 15:05:29,927 Epoch[87] Batch [960]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.074320,	
2017-07-13 15:05:38,599 Epoch[87] Batch [970]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.074290,	
2017-07-13 15:05:44,684 Epoch[87] Batch [980]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.074320,	
2017-07-13 15:05:50,577 Epoch[87] Batch [990]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.074345,	
2017-07-13 15:05:57,017 Epoch[87] Batch [1000]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.074281,	
2017-07-13 15:06:03,639 Epoch[87] Batch [1010]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.074206,	
2017-07-13 15:06:10,661 Epoch[87] Batch [1020]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.074266,	
2017-07-13 15:06:17,913 Epoch[87] Batch [1030]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.074191,	
2017-07-13 15:06:26,994 Epoch[87] Batch [1040]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.074217,	
2017-07-13 15:06:35,901 Epoch[87] Batch [1050]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.074253,	
2017-07-13 15:06:43,599 Epoch[87] Batch [1060]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074235,	
2017-07-13 15:06:49,907 Epoch[87] Batch [1070]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.074237,	
2017-07-13 15:06:57,645 Epoch[87] Batch [1080]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.074155,	
2017-07-13 15:07:06,133 Epoch[87] Batch [1090]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.074143,	
2017-07-13 15:07:13,807 Epoch[87] Batch [1100]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.074114,	
2017-07-13 15:07:22,569 Epoch[87] Batch [1110]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.074085,	
2017-07-13 15:07:29,131 Epoch[87] Batch [1120]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.074136,	
2017-07-13 15:07:36,946 Epoch[87] Batch [1130]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.074130,	
2017-07-13 15:07:43,921 Epoch[87] Batch [1140]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.074071,	
2017-07-13 15:07:50,074 Epoch[87] Batch [1150]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.074067,	
2017-07-13 15:07:57,507 Epoch[87] Batch [1160]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.074023,	
2017-07-13 15:08:04,750 Epoch[87] Batch [1170]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.074062,	
2017-07-13 15:08:12,195 Epoch[87] Batch [1180]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.074116,	
2017-07-13 15:08:18,623 Epoch[87] Batch [1190]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.074126,	
2017-07-13 15:08:25,793 Epoch[87] Batch [1200]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.074163,	
2017-07-13 15:08:33,832 Epoch[87] Batch [1210]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.074196,	
2017-07-13 15:08:42,110 Epoch[87] Batch [1220]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.074190,	
2017-07-13 15:08:50,000 Epoch[87] Batch [1230]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.074158,	
2017-07-13 15:08:56,631 Epoch[87] Batch [1240]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.074096,	
2017-07-13 15:09:06,959 Epoch[87] Batch [1250]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.074064,	
2017-07-13 15:09:14,192 Epoch[87] Batch [1260]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.074085,	
2017-07-13 15:09:22,503 Epoch[87] Batch [1270]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.074110,	
2017-07-13 15:09:29,660 Epoch[87] Batch [1280]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.074154,	
2017-07-13 15:09:36,500 Epoch[87] Batch [1290]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.074157,	
2017-07-13 15:09:43,862 Epoch[87] Batch [1300]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.074094,	
2017-07-13 15:09:52,273 Epoch[87] Batch [1310]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.074099,	
2017-07-13 15:09:58,028 Epoch[87] Batch [1320]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.074112,	
2017-07-13 15:10:05,629 Epoch[87] Batch [1330]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.074088,	
2017-07-13 15:10:12,230 Epoch[87] Batch [1340]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.074011,	
2017-07-13 15:10:21,025 Epoch[87] Batch [1350]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.073979,	
2017-07-13 15:10:30,399 Epoch[87] Batch [1360]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.073941,	
2017-07-13 15:10:37,619 Epoch[87] Batch [1370]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.073888,	
2017-07-13 15:10:45,733 Epoch[87] Batch [1380]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.073843,	
2017-07-13 15:10:56,263 Epoch[87] Batch [1390]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.073786,	
2017-07-13 15:11:03,810 Epoch[87] Batch [1400]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.073837,	
2017-07-13 15:11:11,685 Epoch[87] Batch [1410]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.073870,	
2017-07-13 15:11:20,143 Epoch[87] Batch [1420]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.073889,	
2017-07-13 15:11:26,857 Epoch[87] Batch [1430]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073919,	
2017-07-13 15:11:32,987 Epoch[87] Batch [1440]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.073895,	
2017-07-13 15:11:39,557 Epoch[87] Batch [1450]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.073944,	
2017-07-13 15:11:47,896 Epoch[87] Batch [1460]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.073969,	
2017-07-13 15:11:56,380 Epoch[87] Batch [1470]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.073991,	
2017-07-13 15:12:04,422 Epoch[87] Batch [1480]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.073979,	
2017-07-13 15:12:09,677 Epoch[87] Train-FCNLogLoss=0.073974
2017-07-13 15:12:09,678 Epoch[87] Time cost=1005.274
2017-07-13 15:12:10,338 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0088.params"
2017-07-13 15:12:13,656 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0088.states"
2017-07-13 15:12:22,390 Epoch[88] Batch [10]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.072183,	
2017-07-13 15:12:31,142 Epoch[88] Batch [20]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.073984,	
2017-07-13 15:12:40,063 Epoch[88] Batch [30]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.073987,	
2017-07-13 15:12:50,373 Epoch[88] Batch [40]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.074986,	
2017-07-13 15:12:57,831 Epoch[88] Batch [50]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.075272,	
2017-07-13 15:13:05,546 Epoch[88] Batch [60]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.074240,	
2017-07-13 15:13:15,783 Epoch[88] Batch [70]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.074415,	
2017-07-13 15:13:22,804 Epoch[88] Batch [80]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.074853,	
2017-07-13 15:13:30,482 Epoch[88] Batch [90]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.074333,	
2017-07-13 15:13:39,246 Epoch[88] Batch [100]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.074075,	
2017-07-13 15:13:46,294 Epoch[88] Batch [110]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.073569,	
2017-07-13 15:13:54,094 Epoch[88] Batch [120]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074007,	
2017-07-13 15:14:01,137 Epoch[88] Batch [130]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.074276,	
2017-07-13 15:14:08,135 Epoch[88] Batch [140]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.073785,	
2017-07-13 15:14:16,917 Epoch[88] Batch [150]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.073645,	
2017-07-13 15:14:25,031 Epoch[88] Batch [160]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.073476,	
2017-07-13 15:14:34,970 Epoch[88] Batch [170]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.073363,	
2017-07-13 15:14:42,766 Epoch[88] Batch [180]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.073344,	
2017-07-13 15:14:51,332 Epoch[88] Batch [190]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.073254,	
2017-07-13 15:14:58,278 Epoch[88] Batch [200]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.073466,	
2017-07-13 15:15:05,147 Epoch[88] Batch [210]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.073332,	
2017-07-13 15:15:11,695 Epoch[88] Batch [220]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.073743,	
2017-07-13 15:15:18,127 Epoch[88] Batch [230]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.073774,	
2017-07-13 15:15:24,928 Epoch[88] Batch [240]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073873,	
2017-07-13 15:15:31,987 Epoch[88] Batch [250]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.074371,	
2017-07-13 15:15:39,201 Epoch[88] Batch [260]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.074368,	
2017-07-13 15:15:46,604 Epoch[88] Batch [270]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.074697,	
2017-07-13 15:15:53,744 Epoch[88] Batch [280]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.074649,	
2017-07-13 15:16:00,666 Epoch[88] Batch [290]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.074657,	
2017-07-13 15:16:08,085 Epoch[88] Batch [300]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.074892,	
2017-07-13 15:16:15,031 Epoch[88] Batch [310]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.075023,	
2017-07-13 15:16:21,959 Epoch[88] Batch [320]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.074824,	
2017-07-13 15:16:28,894 Epoch[88] Batch [330]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.074987,	
2017-07-13 15:16:35,969 Epoch[88] Batch [340]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.074869,	
2017-07-13 15:16:43,070 Epoch[88] Batch [350]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.074987,	
2017-07-13 15:16:50,595 Epoch[88] Batch [360]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.075087,	
2017-07-13 15:16:57,729 Epoch[88] Batch [370]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.074829,	
2017-07-13 15:17:04,726 Epoch[88] Batch [380]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.075012,	
2017-07-13 15:17:11,767 Epoch[88] Batch [390]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.074865,	
2017-07-13 15:17:19,124 Epoch[88] Batch [400]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074853,	
2017-07-13 15:17:26,344 Epoch[88] Batch [410]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.074935,	
2017-07-13 15:17:33,598 Epoch[88] Batch [420]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.074946,	
2017-07-13 15:17:41,134 Epoch[88] Batch [430]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.074950,	
2017-07-13 15:17:49,955 Epoch[88] Batch [440]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.074889,	
2017-07-13 15:17:57,655 Epoch[88] Batch [450]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074644,	
2017-07-13 15:18:06,130 Epoch[88] Batch [460]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.074745,	
2017-07-13 15:18:14,824 Epoch[88] Batch [470]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.074790,	
2017-07-13 15:18:22,809 Epoch[88] Batch [480]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.074737,	
2017-07-13 15:18:30,491 Epoch[88] Batch [490]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.074698,	
2017-07-13 15:18:38,343 Epoch[88] Batch [500]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.074407,	
2017-07-13 15:18:45,851 Epoch[88] Batch [510]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.074477,	
2017-07-13 15:18:53,159 Epoch[88] Batch [520]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.074503,	
2017-07-13 15:19:00,464 Epoch[88] Batch [530]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.074540,	
2017-07-13 15:19:07,904 Epoch[88] Batch [540]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.074449,	
2017-07-13 15:19:15,452 Epoch[88] Batch [550]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074396,	
2017-07-13 15:19:22,811 Epoch[88] Batch [560]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074295,	
2017-07-13 15:19:30,290 Epoch[88] Batch [570]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.074248,	
2017-07-13 15:19:37,681 Epoch[88] Batch [580]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.074290,	
2017-07-13 15:19:44,762 Epoch[88] Batch [590]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.074281,	
2017-07-13 15:19:52,304 Epoch[88] Batch [600]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074160,	
2017-07-13 15:19:59,845 Epoch[88] Batch [610]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074299,	
2017-07-13 15:20:07,070 Epoch[88] Batch [620]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.074359,	
2017-07-13 15:20:13,692 Epoch[88] Batch [630]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.074267,	
2017-07-13 15:20:21,010 Epoch[88] Batch [640]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.074210,	
2017-07-13 15:20:27,931 Epoch[88] Batch [650]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.074276,	
2017-07-13 15:20:34,799 Epoch[88] Batch [660]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.074255,	
2017-07-13 15:20:41,919 Epoch[88] Batch [670]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.074189,	
2017-07-13 15:20:49,179 Epoch[88] Batch [680]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.074290,	
2017-07-13 15:20:56,311 Epoch[88] Batch [690]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.074322,	
2017-07-13 15:21:03,612 Epoch[88] Batch [700]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.074495,	
2017-07-13 15:21:10,605 Epoch[88] Batch [710]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.074503,	
2017-07-13 15:21:17,579 Epoch[88] Batch [720]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.074486,	
2017-07-13 15:21:24,590 Epoch[88] Batch [730]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.074500,	
2017-07-13 15:21:31,849 Epoch[88] Batch [740]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.074437,	
2017-07-13 15:21:38,735 Epoch[88] Batch [750]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.074455,	
2017-07-13 15:21:45,971 Epoch[88] Batch [760]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.074298,	
2017-07-13 15:21:52,794 Epoch[88] Batch [770]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.074438,	
2017-07-13 15:21:59,789 Epoch[88] Batch [780]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.074396,	
2017-07-13 15:22:06,852 Epoch[88] Batch [790]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.074376,	
2017-07-13 15:22:13,842 Epoch[88] Batch [800]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.074439,	
2017-07-13 15:22:20,916 Epoch[88] Batch [810]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.074419,	
2017-07-13 15:22:28,412 Epoch[88] Batch [820]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.074468,	
2017-07-13 15:22:35,671 Epoch[88] Batch [830]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.074480,	
2017-07-13 15:22:44,667 Epoch[88] Batch [840]	Speed: 4.45 samples/sec	Train-FCNLogLoss=0.074521,	
2017-07-13 15:22:52,578 Epoch[88] Batch [850]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074517,	
2017-07-13 15:23:01,729 Epoch[88] Batch [860]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.074538,	
2017-07-13 15:23:09,666 Epoch[88] Batch [870]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.074631,	
2017-07-13 15:23:16,942 Epoch[88] Batch [880]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.074635,	
2017-07-13 15:23:24,849 Epoch[88] Batch [890]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074629,	
2017-07-13 15:23:31,651 Epoch[88] Batch [900]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.074528,	
2017-07-13 15:23:38,680 Epoch[88] Batch [910]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.074470,	
2017-07-13 15:23:46,206 Epoch[88] Batch [920]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.074432,	
2017-07-13 15:23:53,357 Epoch[88] Batch [930]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.074406,	
2017-07-13 15:24:00,359 Epoch[88] Batch [940]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.074464,	
2017-07-13 15:24:07,788 Epoch[88] Batch [950]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.074492,	
2017-07-13 15:24:15,024 Epoch[88] Batch [960]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.074481,	
2017-07-13 15:24:22,238 Epoch[88] Batch [970]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.074477,	
2017-07-13 15:24:29,766 Epoch[88] Batch [980]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.074417,	
2017-07-13 15:24:37,164 Epoch[88] Batch [990]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.074447,	
2017-07-13 15:24:44,568 Epoch[88] Batch [1000]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.074458,	
2017-07-13 15:24:51,736 Epoch[88] Batch [1010]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.074405,	
2017-07-13 15:24:59,129 Epoch[88] Batch [1020]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.074429,	
2017-07-13 15:25:06,306 Epoch[88] Batch [1030]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.074352,	
2017-07-13 15:25:13,633 Epoch[88] Batch [1040]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.074273,	
2017-07-13 15:25:20,727 Epoch[88] Batch [1050]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.074274,	
2017-07-13 15:25:27,842 Epoch[88] Batch [1060]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.074276,	
2017-07-13 15:25:35,044 Epoch[88] Batch [1070]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.074332,	
2017-07-13 15:25:42,313 Epoch[88] Batch [1080]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.074271,	
2017-07-13 15:25:49,578 Epoch[88] Batch [1090]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.074300,	
2017-07-13 15:25:56,877 Epoch[88] Batch [1100]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.074311,	
2017-07-13 15:26:04,316 Epoch[88] Batch [1110]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.074330,	
2017-07-13 15:26:11,610 Epoch[88] Batch [1120]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.074307,	
2017-07-13 15:26:18,653 Epoch[88] Batch [1130]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.074298,	
2017-07-13 15:26:26,199 Epoch[88] Batch [1140]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074329,	
2017-07-13 15:26:33,669 Epoch[88] Batch [1150]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.074273,	
2017-07-13 15:26:41,363 Epoch[88] Batch [1160]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074246,	
2017-07-13 15:26:48,911 Epoch[88] Batch [1170]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074222,	
2017-07-13 15:26:56,559 Epoch[88] Batch [1180]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.074208,	
2017-07-13 15:27:03,914 Epoch[88] Batch [1190]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074210,	
2017-07-13 15:27:11,656 Epoch[88] Batch [1200]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.074205,	
2017-07-13 15:27:19,454 Epoch[88] Batch [1210]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074217,	
2017-07-13 15:27:27,004 Epoch[88] Batch [1220]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074141,	
2017-07-13 15:27:34,676 Epoch[88] Batch [1230]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.074168,	
2017-07-13 15:27:41,961 Epoch[88] Batch [1240]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.074175,	
2017-07-13 15:27:49,445 Epoch[88] Batch [1250]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.074150,	
2017-07-13 15:27:57,543 Epoch[88] Batch [1260]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.074127,	
2017-07-13 15:28:05,450 Epoch[88] Batch [1270]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074122,	
2017-07-13 15:28:13,330 Epoch[88] Batch [1280]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.074081,	
2017-07-13 15:28:21,440 Epoch[88] Batch [1290]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.074093,	
2017-07-13 15:28:29,467 Epoch[88] Batch [1300]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.074099,	
2017-07-13 15:28:37,164 Epoch[88] Batch [1310]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074082,	
2017-07-13 15:28:45,188 Epoch[88] Batch [1320]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.074049,	
2017-07-13 15:28:53,078 Epoch[88] Batch [1330]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.073992,	
2017-07-13 15:29:00,864 Epoch[88] Batch [1340]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.073919,	
2017-07-13 15:29:08,841 Epoch[88] Batch [1350]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.073958,	
2017-07-13 15:29:16,895 Epoch[88] Batch [1360]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.074007,	
2017-07-13 15:29:24,843 Epoch[88] Batch [1370]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.074047,	
2017-07-13 15:29:32,931 Epoch[88] Batch [1380]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.074113,	
2017-07-13 15:29:41,158 Epoch[88] Batch [1390]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.074081,	
2017-07-13 15:29:49,339 Epoch[88] Batch [1400]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.074076,	
2017-07-13 15:29:57,200 Epoch[88] Batch [1410]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.074032,	
2017-07-13 15:30:05,053 Epoch[88] Batch [1420]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.074067,	
2017-07-13 15:30:12,977 Epoch[88] Batch [1430]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.074088,	
2017-07-13 15:30:20,919 Epoch[88] Batch [1440]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.074051,	
2017-07-13 15:30:28,732 Epoch[88] Batch [1450]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.073986,	
2017-07-13 15:30:36,447 Epoch[88] Batch [1460]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.073960,	
2017-07-13 15:30:43,915 Epoch[88] Batch [1470]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.073940,	
2017-07-13 15:30:51,444 Epoch[88] Batch [1480]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.073932,	
2017-07-13 15:30:56,187 Epoch[88] Train-FCNLogLoss=0.073892
2017-07-13 15:30:56,187 Epoch[88] Time cost=1122.531
2017-07-13 15:30:57,430 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0089.params"
2017-07-13 15:31:00,811 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0089.states"
2017-07-13 15:31:08,615 Epoch[89] Batch [10]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.068097,	
2017-07-13 15:31:15,205 Epoch[89] Batch [20]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.071745,	
2017-07-13 15:31:22,012 Epoch[89] Batch [30]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.075075,	
2017-07-13 15:31:29,223 Epoch[89] Batch [40]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.074370,	
2017-07-13 15:31:36,328 Epoch[89] Batch [50]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.072293,	
2017-07-13 15:31:43,551 Epoch[89] Batch [60]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.072238,	
2017-07-13 15:31:50,301 Epoch[89] Batch [70]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.071996,	
2017-07-13 15:31:57,236 Epoch[89] Batch [80]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.073127,	
2017-07-13 15:32:03,589 Epoch[89] Batch [90]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.073410,	
2017-07-13 15:32:09,954 Epoch[89] Batch [100]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.073730,	
2017-07-13 15:32:17,097 Epoch[89] Batch [110]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.073745,	
2017-07-13 15:32:24,311 Epoch[89] Batch [120]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.073407,	
2017-07-13 15:32:30,972 Epoch[89] Batch [130]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.074057,	
2017-07-13 15:32:37,747 Epoch[89] Batch [140]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.074000,	
2017-07-13 15:32:44,445 Epoch[89] Batch [150]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.074013,	
2017-07-13 15:32:51,447 Epoch[89] Batch [160]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.073583,	
2017-07-13 15:32:58,567 Epoch[89] Batch [170]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.073846,	
2017-07-13 15:33:05,532 Epoch[89] Batch [180]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.073279,	
2017-07-13 15:33:12,261 Epoch[89] Batch [190]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073119,	
2017-07-13 15:33:19,640 Epoch[89] Batch [200]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.073313,	
2017-07-13 15:33:26,394 Epoch[89] Batch [210]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073169,	
2017-07-13 15:33:33,274 Epoch[89] Batch [220]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.073082,	
2017-07-13 15:33:40,308 Epoch[89] Batch [230]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.073184,	
2017-07-13 15:33:47,325 Epoch[89] Batch [240]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.073109,	
2017-07-13 15:33:54,477 Epoch[89] Batch [250]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.073023,	
2017-07-13 15:34:01,597 Epoch[89] Batch [260]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.072901,	
2017-07-13 15:34:09,049 Epoch[89] Batch [270]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.072988,	
2017-07-13 15:34:16,269 Epoch[89] Batch [280]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.072887,	
2017-07-13 15:34:23,454 Epoch[89] Batch [290]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.072877,	
2017-07-13 15:34:30,793 Epoch[89] Batch [300]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.072730,	
2017-07-13 15:34:38,038 Epoch[89] Batch [310]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.072657,	
2017-07-13 15:34:45,065 Epoch[89] Batch [320]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.072665,	
2017-07-13 15:34:52,435 Epoch[89] Batch [330]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.072583,	
2017-07-13 15:34:59,900 Epoch[89] Batch [340]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.072731,	
2017-07-13 15:35:07,002 Epoch[89] Batch [350]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.072601,	
2017-07-13 15:35:14,029 Epoch[89] Batch [360]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.072685,	
2017-07-13 15:35:21,155 Epoch[89] Batch [370]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.072804,	
2017-07-13 15:35:28,088 Epoch[89] Batch [380]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.072794,	
2017-07-13 15:35:34,888 Epoch[89] Batch [390]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.072703,	
2017-07-13 15:35:41,812 Epoch[89] Batch [400]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.072897,	
2017-07-13 15:35:48,805 Epoch[89] Batch [410]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.072749,	
2017-07-13 15:35:55,976 Epoch[89] Batch [420]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.072961,	
2017-07-13 15:36:02,217 Epoch[89] Batch [430]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.073015,	
2017-07-13 15:36:07,951 Epoch[89] Batch [440]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.073167,	
2017-07-13 15:36:14,859 Epoch[89] Batch [450]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.073182,	
2017-07-13 15:36:21,896 Epoch[89] Batch [460]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.073191,	
2017-07-13 15:36:28,370 Epoch[89] Batch [470]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.073115,	
2017-07-13 15:36:35,344 Epoch[89] Batch [480]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.073014,	
2017-07-13 15:36:42,161 Epoch[89] Batch [490]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073035,	
2017-07-13 15:36:48,388 Epoch[89] Batch [500]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.073069,	
2017-07-13 15:36:54,172 Epoch[89] Batch [510]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.073046,	
2017-07-13 15:37:00,148 Epoch[89] Batch [520]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.073077,	
2017-07-13 15:37:05,716 Epoch[89] Batch [530]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.073000,	
2017-07-13 15:37:11,615 Epoch[89] Batch [540]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.073072,	
2017-07-13 15:37:17,335 Epoch[89] Batch [550]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.073032,	
2017-07-13 15:37:23,170 Epoch[89] Batch [560]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.072912,	
2017-07-13 15:37:28,442 Epoch[89] Batch [570]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.072966,	
2017-07-13 15:37:34,853 Epoch[89] Batch [580]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.072901,	
2017-07-13 15:37:41,131 Epoch[89] Batch [590]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.072928,	
2017-07-13 15:37:47,375 Epoch[89] Batch [600]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.072888,	
2017-07-13 15:37:53,168 Epoch[89] Batch [610]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.072949,	
2017-07-13 15:37:59,298 Epoch[89] Batch [620]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.072995,	
2017-07-13 15:38:05,777 Epoch[89] Batch [630]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.073108,	
2017-07-13 15:38:12,562 Epoch[89] Batch [640]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073208,	
2017-07-13 15:38:19,208 Epoch[89] Batch [650]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073267,	
2017-07-13 15:38:25,732 Epoch[89] Batch [660]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.073273,	
2017-07-13 15:38:32,243 Epoch[89] Batch [670]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073258,	
2017-07-13 15:38:38,488 Epoch[89] Batch [680]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.073254,	
2017-07-13 15:38:44,883 Epoch[89] Batch [690]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073207,	
2017-07-13 15:38:51,048 Epoch[89] Batch [700]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.073168,	
2017-07-13 15:38:56,952 Epoch[89] Batch [710]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.073177,	
2017-07-13 15:39:02,910 Epoch[89] Batch [720]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.073250,	
2017-07-13 15:39:08,469 Epoch[89] Batch [730]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.073204,	
2017-07-13 15:39:14,541 Epoch[89] Batch [740]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.073104,	
2017-07-13 15:39:20,227 Epoch[89] Batch [750]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.073096,	
2017-07-13 15:39:25,965 Epoch[89] Batch [760]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.073026,	
2017-07-13 15:39:31,474 Epoch[89] Batch [770]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.073042,	
2017-07-13 15:39:37,391 Epoch[89] Batch [780]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.073024,	
2017-07-13 15:39:43,125 Epoch[89] Batch [790]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.073001,	
2017-07-13 15:39:47,932 Epoch[89] Batch [800]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.073090,	
2017-07-13 15:39:53,413 Epoch[89] Batch [810]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.073162,	
2017-07-13 15:39:59,033 Epoch[89] Batch [820]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.073058,	
2017-07-13 15:40:04,756 Epoch[89] Batch [830]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.073043,	
2017-07-13 15:40:09,743 Epoch[89] Batch [840]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.073019,	
2017-07-13 15:40:14,635 Epoch[89] Batch [850]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.073093,	
2017-07-13 15:40:19,536 Epoch[89] Batch [860]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.073126,	
2017-07-13 15:40:24,725 Epoch[89] Batch [870]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.073125,	
2017-07-13 15:40:29,762 Epoch[89] Batch [880]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.073116,	
2017-07-13 15:40:34,797 Epoch[89] Batch [890]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.073159,	
2017-07-13 15:40:39,733 Epoch[89] Batch [900]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.073080,	
2017-07-13 15:40:44,592 Epoch[89] Batch [910]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.073119,	
2017-07-13 15:40:49,805 Epoch[89] Batch [920]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.073102,	
2017-07-13 15:40:54,754 Epoch[89] Batch [930]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.073129,	
2017-07-13 15:40:59,575 Epoch[89] Batch [940]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.073086,	
2017-07-13 15:41:04,314 Epoch[89] Batch [950]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.073221,	
2017-07-13 15:41:09,312 Epoch[89] Batch [960]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.073227,	
2017-07-13 15:41:14,246 Epoch[89] Batch [970]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.073194,	
2017-07-13 15:41:19,238 Epoch[89] Batch [980]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.073220,	
2017-07-13 15:41:24,326 Epoch[89] Batch [990]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.073214,	
2017-07-13 15:41:29,080 Epoch[89] Batch [1000]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.073285,	
2017-07-13 15:41:33,792 Epoch[89] Batch [1010]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.073304,	
2017-07-13 15:41:38,385 Epoch[89] Batch [1020]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.073344,	
2017-07-13 15:41:43,263 Epoch[89] Batch [1030]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.073332,	
2017-07-13 15:41:47,837 Epoch[89] Batch [1040]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.073360,	
2017-07-13 15:41:52,818 Epoch[89] Batch [1050]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.073303,	
2017-07-13 15:41:57,704 Epoch[89] Batch [1060]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.073301,	
2017-07-13 15:42:02,687 Epoch[89] Batch [1070]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.073299,	
2017-07-13 15:42:07,568 Epoch[89] Batch [1080]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.073294,	
2017-07-13 15:42:12,420 Epoch[89] Batch [1090]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.073238,	
2017-07-13 15:42:17,526 Epoch[89] Batch [1100]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.073261,	
2017-07-13 15:42:22,462 Epoch[89] Batch [1110]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.073286,	
2017-07-13 15:42:27,725 Epoch[89] Batch [1120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.073353,	
2017-07-13 15:42:32,679 Epoch[89] Batch [1130]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.073281,	
2017-07-13 15:42:37,671 Epoch[89] Batch [1140]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.073292,	
2017-07-13 15:42:42,711 Epoch[89] Batch [1150]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.073305,	
2017-07-13 15:42:47,937 Epoch[89] Batch [1160]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.073389,	
2017-07-13 15:42:52,933 Epoch[89] Batch [1170]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.073443,	
2017-07-13 15:42:57,855 Epoch[89] Batch [1180]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.073467,	
2017-07-13 15:43:02,727 Epoch[89] Batch [1190]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.073456,	
2017-07-13 15:43:07,631 Epoch[89] Batch [1200]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.073463,	
2017-07-13 15:43:12,531 Epoch[89] Batch [1210]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.073461,	
2017-07-13 15:43:17,341 Epoch[89] Batch [1220]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.073415,	
2017-07-13 15:43:22,250 Epoch[89] Batch [1230]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.073394,	
2017-07-13 15:43:27,122 Epoch[89] Batch [1240]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.073429,	
2017-07-13 15:43:31,941 Epoch[89] Batch [1250]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.073477,	
2017-07-13 15:43:37,093 Epoch[89] Batch [1260]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.073476,	
2017-07-13 15:43:42,524 Epoch[89] Batch [1270]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.073546,	
2017-07-13 15:43:47,600 Epoch[89] Batch [1280]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.073530,	
2017-07-13 15:43:52,600 Epoch[89] Batch [1290]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.073532,	
2017-07-13 15:43:57,741 Epoch[89] Batch [1300]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.073578,	
2017-07-13 15:44:02,542 Epoch[89] Batch [1310]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.073569,	
2017-07-13 15:44:07,180 Epoch[89] Batch [1320]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.073582,	
2017-07-13 15:44:11,874 Epoch[89] Batch [1330]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.073554,	
2017-07-13 15:44:16,538 Epoch[89] Batch [1340]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.073566,	
2017-07-13 15:44:21,447 Epoch[89] Batch [1350]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.073551,	
2017-07-13 15:44:25,947 Epoch[89] Batch [1360]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.073548,	
2017-07-13 15:44:30,659 Epoch[89] Batch [1370]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.073540,	
2017-07-13 15:44:35,325 Epoch[89] Batch [1380]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.073519,	
2017-07-13 15:44:39,754 Epoch[89] Batch [1390]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.073484,	
2017-07-13 15:44:44,164 Epoch[89] Batch [1400]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.073500,	
2017-07-13 15:44:48,753 Epoch[89] Batch [1410]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.073525,	
2017-07-13 15:44:53,417 Epoch[89] Batch [1420]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.073522,	
2017-07-13 15:44:58,006 Epoch[89] Batch [1430]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.073509,	
2017-07-13 15:45:02,525 Epoch[89] Batch [1440]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.073514,	
2017-07-13 15:45:07,220 Epoch[89] Batch [1450]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.073486,	
2017-07-13 15:45:11,872 Epoch[89] Batch [1460]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.073491,	
2017-07-13 15:45:16,800 Epoch[89] Batch [1470]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.073475,	
2017-07-13 15:45:21,558 Epoch[89] Batch [1480]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.073492,	
2017-07-13 15:45:24,345 Epoch[89] Train-FCNLogLoss=0.073511
2017-07-13 15:45:24,345 Epoch[89] Time cost=863.533
2017-07-13 15:45:24,994 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0090.params"
2017-07-13 15:45:28,279 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0090.states"
2017-07-13 15:45:33,682 Epoch[90] Batch [10]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.072043,	
2017-07-13 15:45:38,698 Epoch[90] Batch [20]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.076328,	
2017-07-13 15:45:43,529 Epoch[90] Batch [30]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.075688,	
2017-07-13 15:45:48,274 Epoch[90] Batch [40]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.074822,	
2017-07-13 15:45:53,078 Epoch[90] Batch [50]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.073414,	
2017-07-13 15:45:57,928 Epoch[90] Batch [60]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.074475,	
2017-07-13 15:46:02,554 Epoch[90] Batch [70]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.075003,	
2017-07-13 15:46:07,571 Epoch[90] Batch [80]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.075140,	
2017-07-13 15:46:12,211 Epoch[90] Batch [90]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.074538,	
2017-07-13 15:46:17,120 Epoch[90] Batch [100]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.074031,	
2017-07-13 15:46:21,802 Epoch[90] Batch [110]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.074495,	
2017-07-13 15:46:26,641 Epoch[90] Batch [120]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.074486,	
2017-07-13 15:46:31,616 Epoch[90] Batch [130]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.074634,	
2017-07-13 15:46:36,882 Epoch[90] Batch [140]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.075045,	
2017-07-13 15:46:41,956 Epoch[90] Batch [150]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.074727,	
2017-07-13 15:46:46,704 Epoch[90] Batch [160]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.074717,	
2017-07-13 15:46:51,734 Epoch[90] Batch [170]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.074197,	
2017-07-13 15:46:57,071 Epoch[90] Batch [180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.074133,	
2017-07-13 15:47:02,658 Epoch[90] Batch [190]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.074482,	
2017-07-13 15:47:07,464 Epoch[90] Batch [200]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.074436,	
2017-07-13 15:47:12,330 Epoch[90] Batch [210]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.074345,	
2017-07-13 15:47:17,341 Epoch[90] Batch [220]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.074187,	
2017-07-13 15:47:22,154 Epoch[90] Batch [230]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.074187,	
2017-07-13 15:47:27,265 Epoch[90] Batch [240]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.074254,	
2017-07-13 15:47:32,103 Epoch[90] Batch [250]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.074400,	
2017-07-13 15:47:37,122 Epoch[90] Batch [260]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.074308,	
2017-07-13 15:47:41,924 Epoch[90] Batch [270]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.074311,	
2017-07-13 15:47:47,123 Epoch[90] Batch [280]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.074461,	
2017-07-13 15:47:52,710 Epoch[90] Batch [290]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.074293,	
2017-07-13 15:47:57,833 Epoch[90] Batch [300]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.074371,	
2017-07-13 15:48:02,682 Epoch[90] Batch [310]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.074447,	
2017-07-13 15:48:07,644 Epoch[90] Batch [320]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.074337,	
2017-07-13 15:48:12,697 Epoch[90] Batch [330]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.074276,	
2017-07-13 15:48:17,586 Epoch[90] Batch [340]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.074261,	
2017-07-13 15:48:22,428 Epoch[90] Batch [350]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.074233,	
2017-07-13 15:48:27,322 Epoch[90] Batch [360]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.074209,	
2017-07-13 15:48:33,037 Epoch[90] Batch [370]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.074165,	
2017-07-13 15:48:38,938 Epoch[90] Batch [380]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.073954,	
2017-07-13 15:48:44,420 Epoch[90] Batch [390]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.073879,	
2017-07-13 15:48:49,332 Epoch[90] Batch [400]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.074012,	
2017-07-13 15:48:55,003 Epoch[90] Batch [410]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.074007,	
2017-07-13 15:49:00,034 Epoch[90] Batch [420]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.074062,	
2017-07-13 15:49:05,179 Epoch[90] Batch [430]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.074087,	
2017-07-13 15:49:10,515 Epoch[90] Batch [440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.074073,	
2017-07-13 15:49:16,021 Epoch[90] Batch [450]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.073934,	
2017-07-13 15:49:21,228 Epoch[90] Batch [460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.073977,	
2017-07-13 15:49:26,361 Epoch[90] Batch [470]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.073919,	
2017-07-13 15:49:31,206 Epoch[90] Batch [480]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.073921,	
2017-07-13 15:49:36,878 Epoch[90] Batch [490]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.073934,	
2017-07-13 15:49:42,475 Epoch[90] Batch [500]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.074025,	
2017-07-13 15:49:47,487 Epoch[90] Batch [510]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.074139,	
2017-07-13 15:49:52,288 Epoch[90] Batch [520]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.074172,	
2017-07-13 15:49:58,127 Epoch[90] Batch [530]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.074179,	
2017-07-13 15:50:03,362 Epoch[90] Batch [540]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.074119,	
2017-07-13 15:50:09,017 Epoch[90] Batch [550]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.074213,	
2017-07-13 15:50:14,652 Epoch[90] Batch [560]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.074146,	
2017-07-13 15:50:19,533 Epoch[90] Batch [570]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.074190,	
2017-07-13 15:50:24,470 Epoch[90] Batch [580]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.074098,	
2017-07-13 15:50:29,551 Epoch[90] Batch [590]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.074028,	
2017-07-13 15:50:34,740 Epoch[90] Batch [600]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.073986,	
2017-07-13 15:50:39,906 Epoch[90] Batch [610]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.074041,	
2017-07-13 15:50:44,882 Epoch[90] Batch [620]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.074029,	
2017-07-13 15:50:50,223 Epoch[90] Batch [630]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.074138,	
2017-07-13 15:50:55,563 Epoch[90] Batch [640]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.074030,	
2017-07-13 15:51:00,179 Epoch[90] Batch [650]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.073973,	
2017-07-13 15:51:05,115 Epoch[90] Batch [660]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.073924,	
2017-07-13 15:51:10,148 Epoch[90] Batch [670]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.073927,	
2017-07-13 15:51:15,019 Epoch[90] Batch [680]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.073944,	
2017-07-13 15:51:20,367 Epoch[90] Batch [690]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.073854,	
2017-07-13 15:51:26,266 Epoch[90] Batch [700]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.073806,	
2017-07-13 15:51:31,264 Epoch[90] Batch [710]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.073854,	
2017-07-13 15:51:36,245 Epoch[90] Batch [720]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.073979,	
2017-07-13 15:51:41,337 Epoch[90] Batch [730]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.073961,	
2017-07-13 15:51:46,036 Epoch[90] Batch [740]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.073933,	
2017-07-13 15:51:51,069 Epoch[90] Batch [750]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.073860,	
2017-07-13 15:51:55,827 Epoch[90] Batch [760]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.073872,	
2017-07-13 15:52:01,221 Epoch[90] Batch [770]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.073886,	
2017-07-13 15:52:06,554 Epoch[90] Batch [780]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.073946,	
2017-07-13 15:52:12,074 Epoch[90] Batch [790]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.073934,	
2017-07-13 15:52:17,141 Epoch[90] Batch [800]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.074011,	
2017-07-13 15:52:22,082 Epoch[90] Batch [810]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.074116,	
2017-07-13 15:52:27,040 Epoch[90] Batch [820]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.074103,	
2017-07-13 15:52:31,904 Epoch[90] Batch [830]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.074134,	
2017-07-13 15:52:37,165 Epoch[90] Batch [840]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.074146,	
2017-07-13 15:52:42,826 Epoch[90] Batch [850]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.074149,	
2017-07-13 15:52:48,601 Epoch[90] Batch [860]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.074069,	
2017-07-13 15:52:54,356 Epoch[90] Batch [870]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.074081,	
2017-07-13 15:53:00,201 Epoch[90] Batch [880]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.074048,	
2017-07-13 15:53:05,585 Epoch[90] Batch [890]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.074045,	
2017-07-13 15:53:10,960 Epoch[90] Batch [900]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.074134,	
2017-07-13 15:53:16,052 Epoch[90] Batch [910]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.074193,	
2017-07-13 15:53:22,095 Epoch[90] Batch [920]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.074109,	
2017-07-13 15:53:28,210 Epoch[90] Batch [930]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.074110,	
2017-07-13 15:53:33,796 Epoch[90] Batch [940]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.074046,	
2017-07-13 15:53:38,991 Epoch[90] Batch [950]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.073941,	
2017-07-13 15:53:44,661 Epoch[90] Batch [960]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.073971,	
2017-07-13 15:53:51,000 Epoch[90] Batch [970]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.073958,	
2017-07-13 15:53:56,522 Epoch[90] Batch [980]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.073972,	
2017-07-13 15:54:02,707 Epoch[90] Batch [990]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.074009,	
2017-07-13 15:54:08,757 Epoch[90] Batch [1000]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.073992,	
2017-07-13 15:54:14,826 Epoch[90] Batch [1010]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.074134,	
2017-07-13 15:54:21,251 Epoch[90] Batch [1020]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.074053,	
2017-07-13 15:54:27,424 Epoch[90] Batch [1030]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.074040,	
2017-07-13 15:54:33,360 Epoch[90] Batch [1040]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.074085,	
2017-07-13 15:54:39,211 Epoch[90] Batch [1050]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.074040,	
2017-07-13 15:54:44,965 Epoch[90] Batch [1060]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.074116,	
2017-07-13 15:54:51,094 Epoch[90] Batch [1070]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.074148,	
2017-07-13 15:54:56,842 Epoch[90] Batch [1080]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.074140,	
2017-07-13 15:55:03,054 Epoch[90] Batch [1090]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.074093,	
2017-07-13 15:55:08,955 Epoch[90] Batch [1100]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.074126,	
2017-07-13 15:55:13,750 Epoch[90] Batch [1110]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.074074,	
2017-07-13 15:55:19,010 Epoch[90] Batch [1120]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.074094,	
2017-07-13 15:55:23,978 Epoch[90] Batch [1130]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.074125,	
2017-07-13 15:55:29,224 Epoch[90] Batch [1140]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.074004,	
2017-07-13 15:55:34,479 Epoch[90] Batch [1150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.074033,	
2017-07-13 15:55:40,055 Epoch[90] Batch [1160]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.074008,	
2017-07-13 15:55:45,532 Epoch[90] Batch [1170]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.073996,	
2017-07-13 15:55:50,554 Epoch[90] Batch [1180]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.073971,	
2017-07-13 15:55:55,223 Epoch[90] Batch [1190]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.073973,	
2017-07-13 15:56:00,131 Epoch[90] Batch [1200]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.073954,	
2017-07-13 15:56:05,221 Epoch[90] Batch [1210]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.073942,	
2017-07-13 15:56:10,196 Epoch[90] Batch [1220]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.073990,	
2017-07-13 15:56:15,175 Epoch[90] Batch [1230]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.073985,	
2017-07-13 15:56:19,909 Epoch[90] Batch [1240]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.074057,	
2017-07-13 15:56:24,851 Epoch[90] Batch [1250]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.074072,	
2017-07-13 15:56:30,413 Epoch[90] Batch [1260]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.074088,	
2017-07-13 15:56:35,774 Epoch[90] Batch [1270]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.074068,	
2017-07-13 15:56:41,267 Epoch[90] Batch [1280]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.074078,	
2017-07-13 15:56:46,920 Epoch[90] Batch [1290]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.074061,	
2017-07-13 15:56:52,540 Epoch[90] Batch [1300]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.074093,	
2017-07-13 15:56:57,608 Epoch[90] Batch [1310]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.074073,	
2017-07-13 15:57:03,305 Epoch[90] Batch [1320]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.074052,	
2017-07-13 15:57:08,299 Epoch[90] Batch [1330]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.074056,	
2017-07-13 15:57:13,326 Epoch[90] Batch [1340]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.074032,	
2017-07-13 15:57:18,283 Epoch[90] Batch [1350]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.074034,	
2017-07-13 15:57:24,161 Epoch[90] Batch [1360]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.074066,	
2017-07-13 15:57:29,178 Epoch[90] Batch [1370]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.074093,	
2017-07-13 15:57:34,655 Epoch[90] Batch [1380]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.074100,	
2017-07-13 15:57:39,559 Epoch[90] Batch [1390]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.074105,	
2017-07-13 15:57:44,348 Epoch[90] Batch [1400]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.074074,	
2017-07-13 15:57:49,146 Epoch[90] Batch [1410]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.074064,	
2017-07-13 15:57:53,880 Epoch[90] Batch [1420]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.074072,	
2017-07-13 15:57:58,944 Epoch[90] Batch [1430]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.074065,	
2017-07-13 15:58:03,836 Epoch[90] Batch [1440]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.074095,	
2017-07-13 15:58:08,697 Epoch[90] Batch [1450]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.074123,	
2017-07-13 15:58:13,776 Epoch[90] Batch [1460]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.074095,	
2017-07-13 15:58:18,759 Epoch[90] Batch [1470]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.074125,	
2017-07-13 15:58:23,767 Epoch[90] Batch [1480]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.074123,	
2017-07-13 15:58:26,772 Epoch[90] Train-FCNLogLoss=0.074125
2017-07-13 15:58:26,772 Epoch[90] Time cost=778.493
2017-07-13 15:58:27,504 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0091.params"
2017-07-13 15:58:31,102 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0091.states"
2017-07-13 15:58:36,671 Epoch[91] Batch [10]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.070699,	
2017-07-13 15:58:41,587 Epoch[91] Batch [20]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.069602,	
2017-07-13 15:58:46,828 Epoch[91] Batch [30]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.071385,	
2017-07-13 15:58:51,837 Epoch[91] Batch [40]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.072262,	
2017-07-13 15:58:56,757 Epoch[91] Batch [50]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.071848,	
2017-07-13 15:59:01,664 Epoch[91] Batch [60]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.072525,	
2017-07-13 15:59:07,090 Epoch[91] Batch [70]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.072485,	
2017-07-13 15:59:12,211 Epoch[91] Batch [80]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.072484,	
2017-07-13 15:59:17,369 Epoch[91] Batch [90]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.072892,	
2017-07-13 15:59:22,803 Epoch[91] Batch [100]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.073139,	
2017-07-13 15:59:28,520 Epoch[91] Batch [110]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.073006,	
2017-07-13 15:59:34,379 Epoch[91] Batch [120]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.073249,	
2017-07-13 15:59:39,530 Epoch[91] Batch [130]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.073320,	
2017-07-13 15:59:45,344 Epoch[91] Batch [140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.072979,	
2017-07-13 15:59:51,101 Epoch[91] Batch [150]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.073337,	
2017-07-13 15:59:57,128 Epoch[91] Batch [160]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.073020,	
2017-07-13 16:00:03,137 Epoch[91] Batch [170]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.073090,	
2017-07-13 16:00:09,339 Epoch[91] Batch [180]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.073200,	
2017-07-13 16:00:14,964 Epoch[91] Batch [190]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.073096,	
2017-07-13 16:00:20,569 Epoch[91] Batch [200]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.073451,	
2017-07-13 16:00:26,252 Epoch[91] Batch [210]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.073207,	
2017-07-13 16:00:31,366 Epoch[91] Batch [220]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.073102,	
2017-07-13 16:00:36,867 Epoch[91] Batch [230]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.073140,	
2017-07-13 16:00:43,069 Epoch[91] Batch [240]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.073088,	
2017-07-13 16:00:48,646 Epoch[91] Batch [250]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.072906,	
2017-07-13 16:00:54,245 Epoch[91] Batch [260]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.073175,	
2017-07-13 16:00:59,513 Epoch[91] Batch [270]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.073445,	
2017-07-13 16:01:04,857 Epoch[91] Batch [280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.073897,	
2017-07-13 16:01:11,006 Epoch[91] Batch [290]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.073746,	
2017-07-13 16:01:16,890 Epoch[91] Batch [300]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.073611,	
2017-07-13 16:01:23,280 Epoch[91] Batch [310]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073356,	
2017-07-13 16:01:29,107 Epoch[91] Batch [320]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.073292,	
2017-07-13 16:01:35,109 Epoch[91] Batch [330]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.073346,	
2017-07-13 16:01:41,100 Epoch[91] Batch [340]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.073386,	
2017-07-13 16:01:46,945 Epoch[91] Batch [350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.073498,	
2017-07-13 16:01:52,483 Epoch[91] Batch [360]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.073420,	
2017-07-13 16:01:58,510 Epoch[91] Batch [370]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.073620,	
2017-07-13 16:02:04,930 Epoch[91] Batch [380]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.073437,	
2017-07-13 16:02:10,950 Epoch[91] Batch [390]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.073478,	
2017-07-13 16:02:16,410 Epoch[91] Batch [400]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.073453,	
2017-07-13 16:02:22,662 Epoch[91] Batch [410]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.073544,	
2017-07-13 16:02:28,267 Epoch[91] Batch [420]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.073590,	
2017-07-13 16:02:34,077 Epoch[91] Batch [430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.073344,	
2017-07-13 16:02:39,366 Epoch[91] Batch [440]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.073278,	
2017-07-13 16:02:44,884 Epoch[91] Batch [450]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.073341,	
2017-07-13 16:02:49,587 Epoch[91] Batch [460]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.073327,	
2017-07-13 16:02:54,428 Epoch[91] Batch [470]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.073369,	
2017-07-13 16:02:59,398 Epoch[91] Batch [480]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.073186,	
2017-07-13 16:03:04,232 Epoch[91] Batch [490]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.072930,	
2017-07-13 16:03:09,159 Epoch[91] Batch [500]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.072814,	
2017-07-13 16:03:14,297 Epoch[91] Batch [510]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.072800,	
2017-07-13 16:03:19,322 Epoch[91] Batch [520]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.072819,	
2017-07-13 16:03:25,087 Epoch[91] Batch [530]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.072831,	
2017-07-13 16:03:30,302 Epoch[91] Batch [540]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.072773,	
2017-07-13 16:03:35,456 Epoch[91] Batch [550]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.072774,	
2017-07-13 16:03:41,003 Epoch[91] Batch [560]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.072695,	
2017-07-13 16:03:46,442 Epoch[91] Batch [570]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.072700,	
2017-07-13 16:03:51,951 Epoch[91] Batch [580]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.072638,	
2017-07-13 16:03:57,327 Epoch[91] Batch [590]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.072749,	
2017-07-13 16:04:03,049 Epoch[91] Batch [600]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.072749,	
2017-07-13 16:04:08,962 Epoch[91] Batch [610]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.072745,	
2017-07-13 16:04:15,061 Epoch[91] Batch [620]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.072721,	
2017-07-13 16:04:20,929 Epoch[91] Batch [630]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.072767,	
2017-07-13 16:04:26,698 Epoch[91] Batch [640]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.072708,	
2017-07-13 16:04:33,178 Epoch[91] Batch [650]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.072696,	
2017-07-13 16:04:38,941 Epoch[91] Batch [660]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.072696,	
2017-07-13 16:04:44,918 Epoch[91] Batch [670]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.072583,	
2017-07-13 16:04:51,162 Epoch[91] Batch [680]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.072655,	
2017-07-13 16:04:57,084 Epoch[91] Batch [690]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.072757,	
2017-07-13 16:05:02,518 Epoch[91] Batch [700]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.072763,	
2017-07-13 16:05:08,789 Epoch[91] Batch [710]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.072858,	
2017-07-13 16:05:14,570 Epoch[91] Batch [720]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.072899,	
2017-07-13 16:05:21,106 Epoch[91] Batch [730]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.072995,	
2017-07-13 16:05:27,498 Epoch[91] Batch [740]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073122,	
2017-07-13 16:05:32,785 Epoch[91] Batch [750]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.073157,	
2017-07-13 16:05:39,058 Epoch[91] Batch [760]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.073144,	
2017-07-13 16:05:45,247 Epoch[91] Batch [770]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.073167,	
2017-07-13 16:05:52,025 Epoch[91] Batch [780]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073192,	
2017-07-13 16:05:58,626 Epoch[91] Batch [790]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.073267,	
2017-07-13 16:06:05,158 Epoch[91] Batch [800]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073353,	
2017-07-13 16:06:11,673 Epoch[91] Batch [810]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073378,	
2017-07-13 16:06:17,936 Epoch[91] Batch [820]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.073417,	
2017-07-13 16:06:24,491 Epoch[91] Batch [830]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.073344,	
2017-07-13 16:06:30,556 Epoch[91] Batch [840]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.073365,	
2017-07-13 16:06:36,799 Epoch[91] Batch [850]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.073413,	
2017-07-13 16:06:42,958 Epoch[91] Batch [860]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.073457,	
2017-07-13 16:06:49,490 Epoch[91] Batch [870]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073415,	
2017-07-13 16:06:55,925 Epoch[91] Batch [880]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.073409,	
2017-07-13 16:07:02,488 Epoch[91] Batch [890]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.073423,	
2017-07-13 16:07:09,027 Epoch[91] Batch [900]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073451,	
2017-07-13 16:07:15,463 Epoch[91] Batch [910]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.073405,	
2017-07-13 16:07:21,623 Epoch[91] Batch [920]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.073407,	
2017-07-13 16:07:27,984 Epoch[91] Batch [930]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.073330,	
2017-07-13 16:07:33,003 Epoch[91] Batch [940]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.073326,	
2017-07-13 16:07:39,267 Epoch[91] Batch [950]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.073413,	
2017-07-13 16:07:45,628 Epoch[91] Batch [960]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.073435,	
2017-07-13 16:07:51,863 Epoch[91] Batch [970]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.073507,	
2017-07-13 16:07:58,187 Epoch[91] Batch [980]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.073535,	
2017-07-13 16:08:04,132 Epoch[91] Batch [990]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.073536,	
2017-07-13 16:08:09,824 Epoch[91] Batch [1000]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.073540,	
2017-07-13 16:08:15,455 Epoch[91] Batch [1010]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.073517,	
2017-07-13 16:08:21,227 Epoch[91] Batch [1020]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.073508,	
2017-07-13 16:08:26,797 Epoch[91] Batch [1030]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.073524,	
2017-07-13 16:08:32,581 Epoch[91] Batch [1040]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.073495,	
2017-07-13 16:08:39,075 Epoch[91] Batch [1050]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.073492,	
2017-07-13 16:08:44,939 Epoch[91] Batch [1060]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.073486,	
2017-07-13 16:08:50,973 Epoch[91] Batch [1070]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.073476,	
2017-07-13 16:08:57,103 Epoch[91] Batch [1080]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.073452,	
2017-07-13 16:09:03,051 Epoch[91] Batch [1090]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.073414,	
2017-07-13 16:09:09,172 Epoch[91] Batch [1100]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.073401,	
2017-07-13 16:09:15,005 Epoch[91] Batch [1110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.073427,	
2017-07-13 16:09:21,214 Epoch[91] Batch [1120]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.073438,	
2017-07-13 16:09:27,049 Epoch[91] Batch [1130]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.073437,	
2017-07-13 16:09:33,209 Epoch[91] Batch [1140]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.073368,	
2017-07-13 16:09:39,564 Epoch[91] Batch [1150]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.073297,	
2017-07-13 16:09:45,618 Epoch[91] Batch [1160]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.073367,	
2017-07-13 16:09:52,214 Epoch[91] Batch [1170]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.073312,	
2017-07-13 16:09:58,350 Epoch[91] Batch [1180]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.073321,	
2017-07-13 16:10:04,833 Epoch[91] Batch [1190]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.073375,	
2017-07-13 16:10:11,165 Epoch[91] Batch [1200]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.073413,	
2017-07-13 16:10:17,676 Epoch[91] Batch [1210]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073417,	
2017-07-13 16:10:23,977 Epoch[91] Batch [1220]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.073466,	
2017-07-13 16:10:30,270 Epoch[91] Batch [1230]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.073512,	
2017-07-13 16:10:37,200 Epoch[91] Batch [1240]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.073495,	
2017-07-13 16:10:43,597 Epoch[91] Batch [1250]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.073442,	
2017-07-13 16:10:50,156 Epoch[91] Batch [1260]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.073461,	
2017-07-13 16:10:56,426 Epoch[91] Batch [1270]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.073506,	
2017-07-13 16:11:02,784 Epoch[91] Batch [1280]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.073513,	
2017-07-13 16:11:09,521 Epoch[91] Batch [1290]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073433,	
2017-07-13 16:11:15,907 Epoch[91] Batch [1300]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073436,	
2017-07-13 16:11:22,776 Epoch[91] Batch [1310]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.073492,	
2017-07-13 16:11:29,460 Epoch[91] Batch [1320]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073538,	
2017-07-13 16:11:35,983 Epoch[91] Batch [1330]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.073527,	
2017-07-13 16:11:42,279 Epoch[91] Batch [1340]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.073531,	
2017-07-13 16:11:48,446 Epoch[91] Batch [1350]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.073462,	
2017-07-13 16:11:54,641 Epoch[91] Batch [1360]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.073467,	
2017-07-13 16:12:00,906 Epoch[91] Batch [1370]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.073409,	
2017-07-13 16:12:07,248 Epoch[91] Batch [1380]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.073411,	
2017-07-13 16:12:13,502 Epoch[91] Batch [1390]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.073428,	
2017-07-13 16:12:19,902 Epoch[91] Batch [1400]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.073464,	
2017-07-13 16:12:25,804 Epoch[91] Batch [1410]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.073416,	
2017-07-13 16:12:31,480 Epoch[91] Batch [1420]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.073460,	
2017-07-13 16:12:37,737 Epoch[91] Batch [1430]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.073487,	
2017-07-13 16:12:43,017 Epoch[91] Batch [1440]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.073519,	
2017-07-13 16:12:48,367 Epoch[91] Batch [1450]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.073485,	
2017-07-13 16:12:54,302 Epoch[91] Batch [1460]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.073495,	
2017-07-13 16:13:00,175 Epoch[91] Batch [1470]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.073490,	
2017-07-13 16:13:05,632 Epoch[91] Batch [1480]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.073486,	
2017-07-13 16:13:08,850 Epoch[91] Train-FCNLogLoss=0.073482
2017-07-13 16:13:08,850 Epoch[91] Time cost=877.747
2017-07-13 16:13:09,629 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0092.params"
2017-07-13 16:13:13,186 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0092.states"
2017-07-13 16:13:20,462 Epoch[92] Batch [10]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.064108,	
2017-07-13 16:13:27,206 Epoch[92] Batch [20]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.067044,	
2017-07-13 16:13:33,302 Epoch[92] Batch [30]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.065719,	
2017-07-13 16:13:39,101 Epoch[92] Batch [40]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.069628,	
2017-07-13 16:13:45,424 Epoch[92] Batch [50]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.072312,	
2017-07-13 16:13:51,503 Epoch[92] Batch [60]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.071697,	
2017-07-13 16:13:57,799 Epoch[92] Batch [70]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.071158,	
2017-07-13 16:14:03,942 Epoch[92] Batch [80]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.071050,	
2017-07-13 16:14:10,155 Epoch[92] Batch [90]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.072305,	
2017-07-13 16:14:16,449 Epoch[92] Batch [100]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.072506,	
2017-07-13 16:14:22,557 Epoch[92] Batch [110]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.072391,	
2017-07-13 16:14:27,879 Epoch[92] Batch [120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.072231,	
2017-07-13 16:14:33,471 Epoch[92] Batch [130]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.072890,	
2017-07-13 16:14:39,389 Epoch[92] Batch [140]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.072795,	
2017-07-13 16:14:44,759 Epoch[92] Batch [150]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.072843,	
2017-07-13 16:14:49,991 Epoch[92] Batch [160]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.072737,	
2017-07-13 16:14:55,678 Epoch[92] Batch [170]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.072752,	
2017-07-13 16:15:01,852 Epoch[92] Batch [180]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.072939,	
2017-07-13 16:15:07,880 Epoch[92] Batch [190]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.073101,	
2017-07-13 16:15:14,115 Epoch[92] Batch [200]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.072937,	
2017-07-13 16:15:20,484 Epoch[92] Batch [210]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.072792,	
2017-07-13 16:15:27,123 Epoch[92] Batch [220]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072887,	
2017-07-13 16:15:34,038 Epoch[92] Batch [230]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.073212,	
2017-07-13 16:15:41,097 Epoch[92] Batch [240]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.073230,	
2017-07-13 16:15:48,547 Epoch[92] Batch [250]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.073360,	
2017-07-13 16:15:55,831 Epoch[92] Batch [260]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.073058,	
2017-07-13 16:16:02,732 Epoch[92] Batch [270]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.073386,	
2017-07-13 16:16:09,973 Epoch[92] Batch [280]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.073213,	
2017-07-13 16:16:17,143 Epoch[92] Batch [290]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.073369,	
2017-07-13 16:16:24,650 Epoch[92] Batch [300]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.073433,	
2017-07-13 16:16:32,300 Epoch[92] Batch [310]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.073547,	
2017-07-13 16:16:39,963 Epoch[92] Batch [320]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.073522,	
2017-07-13 16:16:47,555 Epoch[92] Batch [330]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.073571,	
2017-07-13 16:16:54,870 Epoch[92] Batch [340]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.073513,	
2017-07-13 16:17:02,633 Epoch[92] Batch [350]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.073592,	
2017-07-13 16:17:10,010 Epoch[92] Batch [360]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.073584,	
2017-07-13 16:17:17,377 Epoch[92] Batch [370]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.073338,	
2017-07-13 16:17:24,475 Epoch[92] Batch [380]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.073252,	
2017-07-13 16:17:31,741 Epoch[92] Batch [390]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.073301,	
2017-07-13 16:17:38,655 Epoch[92] Batch [400]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.073316,	
2017-07-13 16:17:45,344 Epoch[92] Batch [410]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073360,	
2017-07-13 16:17:52,150 Epoch[92] Batch [420]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073205,	
2017-07-13 16:17:58,805 Epoch[92] Batch [430]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073234,	
2017-07-13 16:18:05,179 Epoch[92] Batch [440]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.073313,	
2017-07-13 16:18:11,355 Epoch[92] Batch [450]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.073388,	
2017-07-13 16:18:17,474 Epoch[92] Batch [460]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.073352,	
2017-07-13 16:18:23,240 Epoch[92] Batch [470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.073395,	
2017-07-13 16:18:29,334 Epoch[92] Batch [480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.073321,	
2017-07-13 16:18:35,081 Epoch[92] Batch [490]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.073397,	
2017-07-13 16:18:40,819 Epoch[92] Batch [500]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.073271,	
2017-07-13 16:18:46,107 Epoch[92] Batch [510]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.073391,	
2017-07-13 16:18:51,613 Epoch[92] Batch [520]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.073567,	
2017-07-13 16:18:57,187 Epoch[92] Batch [530]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.073550,	
2017-07-13 16:19:03,076 Epoch[92] Batch [540]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.073525,	
2017-07-13 16:19:08,870 Epoch[92] Batch [550]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.073518,	
2017-07-13 16:19:14,924 Epoch[92] Batch [560]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.073537,	
2017-07-13 16:19:20,909 Epoch[92] Batch [570]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.073601,	
2017-07-13 16:19:26,733 Epoch[92] Batch [580]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.073518,	
2017-07-13 16:19:32,866 Epoch[92] Batch [590]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.073619,	
2017-07-13 16:19:39,029 Epoch[92] Batch [600]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.073523,	
2017-07-13 16:19:45,416 Epoch[92] Batch [610]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073539,	
2017-07-13 16:19:51,740 Epoch[92] Batch [620]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.073403,	
2017-07-13 16:19:58,300 Epoch[92] Batch [630]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.073406,	
2017-07-13 16:20:03,578 Epoch[92] Batch [640]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.073328,	
2017-07-13 16:20:09,286 Epoch[92] Batch [650]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.073270,	
2017-07-13 16:20:15,586 Epoch[92] Batch [660]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.073185,	
2017-07-13 16:20:21,532 Epoch[92] Batch [670]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.073259,	
2017-07-13 16:20:27,335 Epoch[92] Batch [680]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.073189,	
2017-07-13 16:20:33,748 Epoch[92] Batch [690]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.073194,	
2017-07-13 16:20:39,381 Epoch[92] Batch [700]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.073191,	
2017-07-13 16:20:45,265 Epoch[92] Batch [710]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.073124,	
2017-07-13 16:20:51,458 Epoch[92] Batch [720]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.073092,	
2017-07-13 16:20:57,757 Epoch[92] Batch [730]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.073130,	
2017-07-13 16:21:03,676 Epoch[92] Batch [740]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.073105,	
2017-07-13 16:21:09,597 Epoch[92] Batch [750]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.073220,	
2017-07-13 16:21:15,613 Epoch[92] Batch [760]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.073158,	
2017-07-13 16:21:21,668 Epoch[92] Batch [770]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.073209,	
2017-07-13 16:21:27,607 Epoch[92] Batch [780]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.073227,	
2017-07-13 16:21:34,220 Epoch[92] Batch [790]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.073363,	
2017-07-13 16:21:39,712 Epoch[92] Batch [800]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.073324,	
2017-07-13 16:21:45,916 Epoch[92] Batch [810]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.073297,	
2017-07-13 16:21:51,770 Epoch[92] Batch [820]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.073278,	
2017-07-13 16:21:57,587 Epoch[92] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.073322,	
2017-07-13 16:22:03,643 Epoch[92] Batch [840]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.073328,	
2017-07-13 16:22:09,685 Epoch[92] Batch [850]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.073379,	
2017-07-13 16:22:15,961 Epoch[92] Batch [860]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.073412,	
2017-07-13 16:22:22,216 Epoch[92] Batch [870]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.073469,	
2017-07-13 16:22:28,268 Epoch[92] Batch [880]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.073428,	
2017-07-13 16:22:34,566 Epoch[92] Batch [890]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.073461,	
2017-07-13 16:22:40,907 Epoch[92] Batch [900]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.073448,	
2017-07-13 16:22:47,483 Epoch[92] Batch [910]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.073501,	
2017-07-13 16:22:53,887 Epoch[92] Batch [920]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.073562,	
2017-07-13 16:23:00,127 Epoch[92] Batch [930]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.073555,	
2017-07-13 16:23:06,605 Epoch[92] Batch [940]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.073539,	
2017-07-13 16:23:12,757 Epoch[92] Batch [950]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.073527,	
2017-07-13 16:23:19,047 Epoch[92] Batch [960]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.073532,	
2017-07-13 16:23:25,357 Epoch[92] Batch [970]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.073563,	
2017-07-13 16:23:31,706 Epoch[92] Batch [980]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.073645,	
2017-07-13 16:23:38,160 Epoch[92] Batch [990]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.073596,	
2017-07-13 16:23:44,309 Epoch[92] Batch [1000]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.073588,	
2017-07-13 16:23:50,323 Epoch[92] Batch [1010]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.073620,	
2017-07-13 16:23:57,104 Epoch[92] Batch [1020]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073683,	
2017-07-13 16:24:03,185 Epoch[92] Batch [1030]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.073651,	
2017-07-13 16:24:09,222 Epoch[92] Batch [1040]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.073558,	
2017-07-13 16:24:15,654 Epoch[92] Batch [1050]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.073534,	
2017-07-13 16:24:21,924 Epoch[92] Batch [1060]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.073520,	
2017-07-13 16:24:28,013 Epoch[92] Batch [1070]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.073565,	
2017-07-13 16:24:35,096 Epoch[92] Batch [1080]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.073534,	
2017-07-13 16:24:41,844 Epoch[92] Batch [1090]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073548,	
2017-07-13 16:24:48,344 Epoch[92] Batch [1100]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.073523,	
2017-07-13 16:24:54,534 Epoch[92] Batch [1110]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.073552,	
2017-07-13 16:25:01,492 Epoch[92] Batch [1120]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.073531,	
2017-07-13 16:25:07,738 Epoch[92] Batch [1130]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.073494,	
2017-07-13 16:25:13,937 Epoch[92] Batch [1140]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.073512,	
2017-07-13 16:25:20,663 Epoch[92] Batch [1150]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073547,	
2017-07-13 16:25:27,069 Epoch[92] Batch [1160]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.073564,	
2017-07-13 16:25:33,738 Epoch[92] Batch [1170]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073527,	
2017-07-13 16:25:40,234 Epoch[92] Batch [1180]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.073578,	
2017-07-13 16:25:46,645 Epoch[92] Batch [1190]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.073570,	
2017-07-13 16:25:53,197 Epoch[92] Batch [1200]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.073519,	
2017-07-13 16:26:00,121 Epoch[92] Batch [1210]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.073520,	
2017-07-13 16:26:06,772 Epoch[92] Batch [1220]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073551,	
2017-07-13 16:26:13,405 Epoch[92] Batch [1230]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073638,	
2017-07-13 16:26:20,266 Epoch[92] Batch [1240]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.073664,	
2017-07-13 16:26:27,039 Epoch[92] Batch [1250]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073662,	
2017-07-13 16:26:34,027 Epoch[92] Batch [1260]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.073674,	
2017-07-13 16:26:41,120 Epoch[92] Batch [1270]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.073692,	
2017-07-13 16:26:47,976 Epoch[92] Batch [1280]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.073695,	
2017-07-13 16:26:55,253 Epoch[92] Batch [1290]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.073677,	
2017-07-13 16:27:02,500 Epoch[92] Batch [1300]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.073651,	
2017-07-13 16:27:09,651 Epoch[92] Batch [1310]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.073687,	
2017-07-13 16:27:16,993 Epoch[92] Batch [1320]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.073685,	
2017-07-13 16:27:24,045 Epoch[92] Batch [1330]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.073694,	
2017-07-13 16:27:30,193 Epoch[92] Batch [1340]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.073688,	
2017-07-13 16:27:36,648 Epoch[92] Batch [1350]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.073680,	
2017-07-13 16:27:42,903 Epoch[92] Batch [1360]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.073729,	
2017-07-13 16:27:50,116 Epoch[92] Batch [1370]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.073735,	
2017-07-13 16:27:56,727 Epoch[92] Batch [1380]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.073680,	
2017-07-13 16:28:03,160 Epoch[92] Batch [1390]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.073662,	
2017-07-13 16:28:09,348 Epoch[92] Batch [1400]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.073627,	
2017-07-13 16:28:15,742 Epoch[92] Batch [1410]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073629,	
2017-07-13 16:28:21,770 Epoch[92] Batch [1420]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.073581,	
2017-07-13 16:28:27,699 Epoch[92] Batch [1430]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.073558,	
2017-07-13 16:28:33,853 Epoch[92] Batch [1440]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.073575,	
2017-07-13 16:28:40,030 Epoch[92] Batch [1450]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.073594,	
2017-07-13 16:28:46,769 Epoch[92] Batch [1460]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073623,	
2017-07-13 16:28:53,776 Epoch[92] Batch [1470]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.073629,	
2017-07-13 16:29:00,187 Epoch[92] Batch [1480]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.073591,	
2017-07-13 16:29:03,687 Epoch[92] Train-FCNLogLoss=0.073586
2017-07-13 16:29:03,687 Epoch[92] Time cost=950.501
2017-07-13 16:29:04,787 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0093.params"
2017-07-13 16:29:08,244 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0093.states"
2017-07-13 16:29:15,344 Epoch[93] Batch [10]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.072233,	
2017-07-13 16:29:21,694 Epoch[93] Batch [20]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.075536,	
2017-07-13 16:29:27,872 Epoch[93] Batch [30]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.075405,	
2017-07-13 16:29:34,217 Epoch[93] Batch [40]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.075453,	
2017-07-13 16:29:40,656 Epoch[93] Batch [50]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.075247,	
2017-07-13 16:29:47,482 Epoch[93] Batch [60]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.075236,	
2017-07-13 16:29:53,820 Epoch[93] Batch [70]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.074063,	
2017-07-13 16:30:01,044 Epoch[93] Batch [80]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.073941,	
2017-07-13 16:30:08,417 Epoch[93] Batch [90]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.074715,	
2017-07-13 16:30:15,928 Epoch[93] Batch [100]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.075809,	
2017-07-13 16:30:23,014 Epoch[93] Batch [110]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.075913,	
2017-07-13 16:30:30,214 Epoch[93] Batch [120]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.075522,	
2017-07-13 16:30:37,371 Epoch[93] Batch [130]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.075283,	
2017-07-13 16:30:43,922 Epoch[93] Batch [140]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.076114,	
2017-07-13 16:30:50,990 Epoch[93] Batch [150]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.075952,	
2017-07-13 16:30:57,551 Epoch[93] Batch [160]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.075568,	
2017-07-13 16:31:04,232 Epoch[93] Batch [170]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.075937,	
2017-07-13 16:31:11,307 Epoch[93] Batch [180]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.075884,	
2017-07-13 16:31:18,326 Epoch[93] Batch [190]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.076202,	
2017-07-13 16:31:25,889 Epoch[93] Batch [200]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.075852,	
2017-07-13 16:31:32,924 Epoch[93] Batch [210]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.075943,	
2017-07-13 16:31:40,208 Epoch[93] Batch [220]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.076023,	
2017-07-13 16:31:47,823 Epoch[93] Batch [230]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.075775,	
2017-07-13 16:31:55,637 Epoch[93] Batch [240]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.075720,	
2017-07-13 16:32:02,995 Epoch[93] Batch [250]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.075759,	
2017-07-13 16:32:10,379 Epoch[93] Batch [260]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.075678,	
2017-07-13 16:32:17,924 Epoch[93] Batch [270]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.075377,	
2017-07-13 16:32:25,566 Epoch[93] Batch [280]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.075564,	
2017-07-13 16:32:33,494 Epoch[93] Batch [290]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.075371,	
2017-07-13 16:32:41,387 Epoch[93] Batch [300]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.075462,	
2017-07-13 16:32:49,235 Epoch[93] Batch [310]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.075495,	
2017-07-13 16:32:56,891 Epoch[93] Batch [320]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.075486,	
2017-07-13 16:33:04,896 Epoch[93] Batch [330]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.075331,	
2017-07-13 16:33:12,625 Epoch[93] Batch [340]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.075178,	
2017-07-13 16:33:20,473 Epoch[93] Batch [350]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.075026,	
2017-07-13 16:33:28,351 Epoch[93] Batch [360]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.075078,	
2017-07-13 16:33:36,069 Epoch[93] Batch [370]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.075129,	
2017-07-13 16:33:43,519 Epoch[93] Batch [380]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.075154,	
2017-07-13 16:33:50,663 Epoch[93] Batch [390]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.074997,	
2017-07-13 16:33:57,989 Epoch[93] Batch [400]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.074847,	
2017-07-13 16:34:05,153 Epoch[93] Batch [410]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.074809,	
2017-07-13 16:34:12,514 Epoch[93] Batch [420]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.074735,	
2017-07-13 16:34:19,370 Epoch[93] Batch [430]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.074752,	
2017-07-13 16:34:26,137 Epoch[93] Batch [440]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.074712,	
2017-07-13 16:34:33,182 Epoch[93] Batch [450]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.074731,	
2017-07-13 16:34:40,278 Epoch[93] Batch [460]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.074720,	
2017-07-13 16:34:47,461 Epoch[93] Batch [470]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.074655,	
2017-07-13 16:34:54,549 Epoch[93] Batch [480]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.074563,	
2017-07-13 16:35:02,128 Epoch[93] Batch [490]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074509,	
2017-07-13 16:35:09,476 Epoch[93] Batch [500]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074490,	
2017-07-13 16:35:17,382 Epoch[93] Batch [510]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074466,	
2017-07-13 16:35:25,106 Epoch[93] Batch [520]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.074378,	
2017-07-13 16:35:33,494 Epoch[93] Batch [530]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.074504,	
2017-07-13 16:35:41,703 Epoch[93] Batch [540]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.074445,	
2017-07-13 16:35:49,967 Epoch[93] Batch [550]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.074414,	
2017-07-13 16:35:58,555 Epoch[93] Batch [560]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.074397,	
2017-07-13 16:36:07,128 Epoch[93] Batch [570]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.074428,	
2017-07-13 16:36:15,977 Epoch[93] Batch [580]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.074322,	
2017-07-13 16:36:25,258 Epoch[93] Batch [590]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.074305,	
2017-07-13 16:36:34,913 Epoch[93] Batch [600]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.074363,	
2017-07-13 16:36:44,275 Epoch[93] Batch [610]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.074349,	
2017-07-13 16:36:54,429 Epoch[93] Batch [620]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.074261,	
2017-07-13 16:37:03,386 Epoch[93] Batch [630]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.074287,	
2017-07-13 16:37:12,422 Epoch[93] Batch [640]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.074331,	
2017-07-13 16:37:21,678 Epoch[93] Batch [650]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.074258,	
2017-07-13 16:37:31,158 Epoch[93] Batch [660]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.074192,	
2017-07-13 16:37:39,798 Epoch[93] Batch [670]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.074161,	
2017-07-13 16:37:47,179 Epoch[93] Batch [680]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.074050,	
2017-07-13 16:37:54,735 Epoch[93] Batch [690]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.073958,	
2017-07-13 16:38:02,135 Epoch[93] Batch [700]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.073960,	
2017-07-13 16:38:09,991 Epoch[93] Batch [710]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.073987,	
2017-07-13 16:38:17,437 Epoch[93] Batch [720]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.074053,	
2017-07-13 16:38:24,791 Epoch[93] Batch [730]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.074047,	
2017-07-13 16:38:31,986 Epoch[93] Batch [740]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.073908,	
2017-07-13 16:38:39,555 Epoch[93] Batch [750]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.073830,	
2017-07-13 16:38:46,882 Epoch[93] Batch [760]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.073863,	
2017-07-13 16:38:54,134 Epoch[93] Batch [770]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.073810,	
2017-07-13 16:39:01,011 Epoch[93] Batch [780]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.073797,	
2017-07-13 16:39:07,842 Epoch[93] Batch [790]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073806,	
2017-07-13 16:39:15,451 Epoch[93] Batch [800]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.073756,	
2017-07-13 16:39:22,946 Epoch[93] Batch [810]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.073729,	
2017-07-13 16:39:30,218 Epoch[93] Batch [820]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.073754,	
2017-07-13 16:39:37,242 Epoch[93] Batch [830]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.073705,	
2017-07-13 16:39:44,607 Epoch[93] Batch [840]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.073801,	
2017-07-13 16:39:51,277 Epoch[93] Batch [850]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073719,	
2017-07-13 16:39:57,506 Epoch[93] Batch [860]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.073671,	
2017-07-13 16:40:03,589 Epoch[93] Batch [870]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.073720,	
2017-07-13 16:40:09,467 Epoch[93] Batch [880]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.073675,	
2017-07-13 16:40:15,544 Epoch[93] Batch [890]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.073648,	
2017-07-13 16:40:21,296 Epoch[93] Batch [900]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.073621,	
2017-07-13 16:40:27,174 Epoch[93] Batch [910]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.073675,	
2017-07-13 16:40:32,937 Epoch[93] Batch [920]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.073666,	
2017-07-13 16:40:39,327 Epoch[93] Batch [930]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073710,	
2017-07-13 16:40:45,531 Epoch[93] Batch [940]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.073683,	
2017-07-13 16:40:52,182 Epoch[93] Batch [950]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073675,	
2017-07-13 16:40:58,702 Epoch[93] Batch [960]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073671,	
2017-07-13 16:41:05,177 Epoch[93] Batch [970]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.073667,	
2017-07-13 16:41:11,676 Epoch[93] Batch [980]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.073605,	
2017-07-13 16:41:17,869 Epoch[93] Batch [990]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.073593,	
2017-07-13 16:41:24,163 Epoch[93] Batch [1000]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.073575,	
2017-07-13 16:41:30,053 Epoch[93] Batch [1010]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.073582,	
2017-07-13 16:41:36,190 Epoch[93] Batch [1020]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.073641,	
2017-07-13 16:41:43,262 Epoch[93] Batch [1030]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.073665,	
2017-07-13 16:41:49,787 Epoch[93] Batch [1040]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.073669,	
2017-07-13 16:41:56,315 Epoch[93] Batch [1050]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.073683,	
2017-07-13 16:42:02,675 Epoch[93] Batch [1060]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.073659,	
2017-07-13 16:42:08,947 Epoch[93] Batch [1070]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.073739,	
2017-07-13 16:42:15,429 Epoch[93] Batch [1080]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.073697,	
2017-07-13 16:42:22,013 Epoch[93] Batch [1090]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.073655,	
2017-07-13 16:42:28,570 Epoch[93] Batch [1100]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.073609,	
2017-07-13 16:42:35,034 Epoch[93] Batch [1110]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.073610,	
2017-07-13 16:42:41,686 Epoch[93] Batch [1120]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073562,	
2017-07-13 16:42:48,339 Epoch[93] Batch [1130]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073557,	
2017-07-13 16:42:54,848 Epoch[93] Batch [1140]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.073587,	
2017-07-13 16:43:01,111 Epoch[93] Batch [1150]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.073610,	
2017-07-13 16:43:07,755 Epoch[93] Batch [1160]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073609,	
2017-07-13 16:43:14,463 Epoch[93] Batch [1170]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073651,	
2017-07-13 16:43:21,188 Epoch[93] Batch [1180]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073680,	
2017-07-13 16:43:28,543 Epoch[93] Batch [1190]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.073711,	
2017-07-13 16:43:35,350 Epoch[93] Batch [1200]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073738,	
2017-07-13 16:43:42,246 Epoch[93] Batch [1210]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.073699,	
2017-07-13 16:43:49,541 Epoch[93] Batch [1220]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.073707,	
2017-07-13 16:43:56,755 Epoch[93] Batch [1230]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.073635,	
2017-07-13 16:44:04,077 Epoch[93] Batch [1240]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.073629,	
2017-07-13 16:44:11,540 Epoch[93] Batch [1250]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.073629,	
2017-07-13 16:44:19,035 Epoch[93] Batch [1260]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.073642,	
2017-07-13 16:44:26,462 Epoch[93] Batch [1270]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.073660,	
2017-07-13 16:44:33,850 Epoch[93] Batch [1280]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.073646,	
2017-07-13 16:44:41,655 Epoch[93] Batch [1290]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.073607,	
2017-07-13 16:44:49,343 Epoch[93] Batch [1300]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.073605,	
2017-07-13 16:44:56,900 Epoch[93] Batch [1310]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.073600,	
2017-07-13 16:45:04,364 Epoch[93] Batch [1320]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.073598,	
2017-07-13 16:45:11,625 Epoch[93] Batch [1330]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.073591,	
2017-07-13 16:45:19,000 Epoch[93] Batch [1340]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.073600,	
2017-07-13 16:45:26,443 Epoch[93] Batch [1350]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.073573,	
2017-07-13 16:45:33,931 Epoch[93] Batch [1360]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.073581,	
2017-07-13 16:45:41,269 Epoch[93] Batch [1370]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.073571,	
2017-07-13 16:45:48,548 Epoch[93] Batch [1380]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.073577,	
2017-07-13 16:45:56,126 Epoch[93] Batch [1390]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.073586,	
2017-07-13 16:46:03,599 Epoch[93] Batch [1400]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.073552,	
2017-07-13 16:46:10,840 Epoch[93] Batch [1410]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.073546,	
2017-07-13 16:46:18,097 Epoch[93] Batch [1420]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.073578,	
2017-07-13 16:46:25,584 Epoch[93] Batch [1430]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.073583,	
2017-07-13 16:46:32,772 Epoch[93] Batch [1440]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.073548,	
2017-07-13 16:46:40,128 Epoch[93] Batch [1450]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.073555,	
2017-07-13 16:46:47,459 Epoch[93] Batch [1460]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.073529,	
2017-07-13 16:46:54,472 Epoch[93] Batch [1470]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.073575,	
2017-07-13 16:47:01,875 Epoch[93] Batch [1480]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.073542,	
2017-07-13 16:47:06,506 Epoch[93] Train-FCNLogLoss=0.073569
2017-07-13 16:47:06,507 Epoch[93] Time cost=1078.262
2017-07-13 16:47:07,694 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0094.params"
2017-07-13 16:47:11,546 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0094.states"
2017-07-13 16:47:20,246 Epoch[94] Batch [10]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.069715,	
2017-07-13 16:47:27,790 Epoch[94] Batch [20]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.073260,	
2017-07-13 16:47:35,443 Epoch[94] Batch [30]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.072715,	
2017-07-13 16:47:42,996 Epoch[94] Batch [40]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.073878,	
2017-07-13 16:47:50,394 Epoch[94] Batch [50]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.075604,	
2017-07-13 16:47:57,987 Epoch[94] Batch [60]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.075213,	
2017-07-13 16:48:05,427 Epoch[94] Batch [70]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.075802,	
2017-07-13 16:48:12,925 Epoch[94] Batch [80]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.075807,	
2017-07-13 16:48:20,415 Epoch[94] Batch [90]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.075752,	
2017-07-13 16:48:27,967 Epoch[94] Batch [100]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074843,	
2017-07-13 16:48:35,381 Epoch[94] Batch [110]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.074764,	
2017-07-13 16:48:42,848 Epoch[94] Batch [120]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.074771,	
2017-07-13 16:48:50,363 Epoch[94] Batch [130]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.074752,	
2017-07-13 16:48:57,832 Epoch[94] Batch [140]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.074894,	
2017-07-13 16:49:05,312 Epoch[94] Batch [150]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.074949,	
2017-07-13 16:49:12,793 Epoch[94] Batch [160]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.074874,	
2017-07-13 16:49:20,295 Epoch[94] Batch [170]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.074527,	
2017-07-13 16:49:27,758 Epoch[94] Batch [180]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.074460,	
2017-07-13 16:49:35,330 Epoch[94] Batch [190]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074442,	
2017-07-13 16:49:43,019 Epoch[94] Batch [200]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.074365,	
2017-07-13 16:49:50,592 Epoch[94] Batch [210]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074411,	
2017-07-13 16:49:58,053 Epoch[94] Batch [220]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.074375,	
2017-07-13 16:50:05,537 Epoch[94] Batch [230]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.074434,	
2017-07-13 16:50:13,059 Epoch[94] Batch [240]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.074242,	
2017-07-13 16:50:31,386 Epoch[94] Batch [250]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.074310,	
2017-07-13 16:50:52,545 Epoch[94] Batch [260]	Speed: 1.89 samples/sec	Train-FCNLogLoss=0.074348,	
2017-07-13 16:51:12,775 Epoch[94] Batch [270]	Speed: 1.98 samples/sec	Train-FCNLogLoss=0.074311,	
2017-07-13 16:51:35,106 Epoch[94] Batch [280]	Speed: 1.79 samples/sec	Train-FCNLogLoss=0.074242,	
2017-07-13 16:51:58,527 Epoch[94] Batch [290]	Speed: 1.71 samples/sec	Train-FCNLogLoss=0.074327,	
2017-07-13 16:52:21,284 Epoch[94] Batch [300]	Speed: 1.76 samples/sec	Train-FCNLogLoss=0.074358,	
2017-07-13 16:52:45,444 Epoch[94] Batch [310]	Speed: 1.66 samples/sec	Train-FCNLogLoss=0.074160,	
2017-07-13 16:53:10,575 Epoch[94] Batch [320]	Speed: 1.59 samples/sec	Train-FCNLogLoss=0.074208,	
2017-07-13 16:53:36,634 Epoch[94] Batch [330]	Speed: 1.54 samples/sec	Train-FCNLogLoss=0.074176,	
2017-07-13 16:54:00,469 Epoch[94] Batch [340]	Speed: 1.68 samples/sec	Train-FCNLogLoss=0.074237,	
2017-07-13 16:54:26,102 Epoch[94] Batch [350]	Speed: 1.56 samples/sec	Train-FCNLogLoss=0.074247,	
2017-07-13 16:54:49,503 Epoch[94] Batch [360]	Speed: 1.71 samples/sec	Train-FCNLogLoss=0.074156,	
2017-07-13 16:55:13,193 Epoch[94] Batch [370]	Speed: 1.69 samples/sec	Train-FCNLogLoss=0.074286,	
2017-07-13 16:55:37,081 Epoch[94] Batch [380]	Speed: 1.67 samples/sec	Train-FCNLogLoss=0.074329,	
2017-07-13 16:56:01,276 Epoch[94] Batch [390]	Speed: 1.65 samples/sec	Train-FCNLogLoss=0.074328,	
2017-07-13 16:56:23,020 Epoch[94] Batch [400]	Speed: 1.84 samples/sec	Train-FCNLogLoss=0.074490,	
2017-07-13 16:56:46,464 Epoch[94] Batch [410]	Speed: 1.71 samples/sec	Train-FCNLogLoss=0.074463,	
2017-07-13 16:57:09,189 Epoch[94] Batch [420]	Speed: 1.76 samples/sec	Train-FCNLogLoss=0.074405,	
2017-07-13 16:57:32,951 Epoch[94] Batch [430]	Speed: 1.68 samples/sec	Train-FCNLogLoss=0.074438,	
2017-07-13 16:57:54,473 Epoch[94] Batch [440]	Speed: 1.86 samples/sec	Train-FCNLogLoss=0.074521,	
2017-07-13 16:58:05,070 Epoch[94] Batch [450]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.074503,	
2017-07-13 16:58:12,484 Epoch[94] Batch [460]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.074525,	
2017-07-13 16:58:20,040 Epoch[94] Batch [470]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.074476,	
2017-07-13 16:58:27,569 Epoch[94] Batch [480]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.074350,	
2017-07-13 16:58:35,097 Epoch[94] Batch [490]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.074518,	
2017-07-13 16:58:42,541 Epoch[94] Batch [500]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.074351,	
2017-07-13 16:58:50,102 Epoch[94] Batch [510]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.074443,	
2017-07-13 16:58:57,649 Epoch[94] Batch [520]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.074297,	
2017-07-13 16:59:05,134 Epoch[94] Batch [530]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.074255,	
2017-07-13 16:59:12,710 Epoch[94] Batch [540]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074352,	
2017-07-13 16:59:20,207 Epoch[94] Batch [550]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.074334,	
2017-07-13 16:59:27,842 Epoch[94] Batch [560]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.074294,	
2017-07-13 16:59:35,242 Epoch[94] Batch [570]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.074170,	
2017-07-13 16:59:42,805 Epoch[94] Batch [580]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.074267,	
2017-07-13 16:59:50,248 Epoch[94] Batch [590]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.074360,	
2017-07-13 16:59:57,826 Epoch[94] Batch [600]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074176,	
2017-07-13 17:00:05,428 Epoch[94] Batch [610]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.074051,	
2017-07-13 17:00:13,007 Epoch[94] Batch [620]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.074018,	
2017-07-13 17:00:20,650 Epoch[94] Batch [630]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.074055,	
2017-07-13 17:00:28,263 Epoch[94] Batch [640]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.073922,	
2017-07-13 17:00:35,795 Epoch[94] Batch [650]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.073837,	
2017-07-13 17:00:43,387 Epoch[94] Batch [660]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.073853,	
2017-07-13 17:00:50,819 Epoch[94] Batch [670]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.073894,	
2017-07-13 17:00:58,326 Epoch[94] Batch [680]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.073846,	
2017-07-13 17:01:05,886 Epoch[94] Batch [690]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.073880,	
2017-07-13 17:01:13,364 Epoch[94] Batch [700]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.073938,	
2017-07-13 17:01:20,785 Epoch[94] Batch [710]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.073916,	
2017-07-13 17:01:28,457 Epoch[94] Batch [720]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.073903,	
2017-07-13 17:01:35,984 Epoch[94] Batch [730]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.073943,	
2017-07-13 17:01:43,605 Epoch[94] Batch [740]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.073910,	
2017-07-13 17:01:51,265 Epoch[94] Batch [750]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.073873,	
2017-07-13 17:01:58,860 Epoch[94] Batch [760]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.073976,	
2017-07-13 17:02:06,373 Epoch[94] Batch [770]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.073892,	
2017-07-13 17:02:13,933 Epoch[94] Batch [780]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.073914,	
2017-07-13 17:02:21,369 Epoch[94] Batch [790]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.073887,	
2017-07-13 17:02:28,883 Epoch[94] Batch [800]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.073902,	
2017-07-13 17:02:36,398 Epoch[94] Batch [810]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.073941,	
2017-07-13 17:02:43,895 Epoch[94] Batch [820]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.073906,	
2017-07-13 17:02:51,421 Epoch[94] Batch [830]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.073948,	
2017-07-13 17:02:58,986 Epoch[94] Batch [840]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.073993,	
2017-07-13 17:03:08,885 Epoch[94] Batch [850]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.073999,	
2017-07-13 17:03:29,416 Epoch[94] Batch [860]	Speed: 1.95 samples/sec	Train-FCNLogLoss=0.073990,	
2017-07-13 17:03:52,283 Epoch[94] Batch [870]	Speed: 1.75 samples/sec	Train-FCNLogLoss=0.073986,	
2017-07-13 17:04:16,118 Epoch[94] Batch [880]	Speed: 1.68 samples/sec	Train-FCNLogLoss=0.073959,	
2017-07-13 17:04:39,409 Epoch[94] Batch [890]	Speed: 1.72 samples/sec	Train-FCNLogLoss=0.073826,	
2017-07-13 17:05:03,100 Epoch[94] Batch [900]	Speed: 1.69 samples/sec	Train-FCNLogLoss=0.073885,	
2017-07-13 17:05:27,665 Epoch[94] Batch [910]	Speed: 1.63 samples/sec	Train-FCNLogLoss=0.073834,	
2017-07-13 17:05:52,378 Epoch[94] Batch [920]	Speed: 1.62 samples/sec	Train-FCNLogLoss=0.073870,	
2017-07-13 17:06:14,497 Epoch[94] Batch [930]	Speed: 1.81 samples/sec	Train-FCNLogLoss=0.073880,	
2017-07-13 17:06:37,351 Epoch[94] Batch [940]	Speed: 1.75 samples/sec	Train-FCNLogLoss=0.073899,	
2017-07-13 17:07:00,645 Epoch[94] Batch [950]	Speed: 1.72 samples/sec	Train-FCNLogLoss=0.073864,	
2017-07-13 17:07:20,303 Epoch[94] Batch [960]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.073842,	
2017-07-13 17:07:39,773 Epoch[94] Batch [970]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.073854,	
2017-07-13 17:07:55,546 Epoch[94] Batch [980]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.073838,	
2017-07-13 17:08:03,078 Epoch[94] Batch [990]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.073862,	
2017-07-13 17:08:11,053 Epoch[94] Batch [1000]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.073875,	
2017-07-13 17:08:18,996 Epoch[94] Batch [1010]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.073887,	
2017-07-13 17:08:26,936 Epoch[94] Batch [1020]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.073845,	
2017-07-13 17:08:34,793 Epoch[94] Batch [1030]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.073903,	
2017-07-13 17:08:42,725 Epoch[94] Batch [1040]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.073882,	
2017-07-13 17:08:50,651 Epoch[94] Batch [1050]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.073909,	
2017-07-13 17:08:58,615 Epoch[94] Batch [1060]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.073916,	
2017-07-13 17:09:06,776 Epoch[94] Batch [1070]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073973,	
2017-07-13 17:09:14,947 Epoch[94] Batch [1080]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073999,	
2017-07-13 17:09:22,964 Epoch[94] Batch [1090]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.073952,	
2017-07-13 17:09:30,683 Epoch[94] Batch [1100]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.073898,	
2017-07-13 17:09:38,608 Epoch[94] Batch [1110]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.073919,	
2017-07-13 17:09:46,709 Epoch[94] Batch [1120]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.073929,	
2017-07-13 17:09:54,515 Epoch[94] Batch [1130]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.073934,	
2017-07-13 17:10:02,447 Epoch[94] Batch [1140]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.073950,	
2017-07-13 17:10:10,363 Epoch[94] Batch [1150]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.073950,	
2017-07-13 17:10:18,200 Epoch[94] Batch [1160]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.073981,	
2017-07-13 17:10:26,220 Epoch[94] Batch [1170]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.074029,	
2017-07-13 17:10:34,114 Epoch[94] Batch [1180]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.074044,	
2017-07-13 17:10:42,079 Epoch[94] Batch [1190]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.074010,	
2017-07-13 17:10:50,021 Epoch[94] Batch [1200]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.073938,	
2017-07-13 17:10:58,080 Epoch[94] Batch [1210]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.073975,	
2017-07-13 17:11:05,973 Epoch[94] Batch [1220]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.074003,	
2017-07-13 17:11:13,772 Epoch[94] Batch [1230]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.074005,	
2017-07-13 17:11:21,748 Epoch[94] Batch [1240]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.073947,	
2017-07-13 17:11:29,594 Epoch[94] Batch [1250]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.073943,	
2017-07-13 17:11:38,228 Epoch[94] Batch [1260]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.073941,	
2017-07-13 17:11:46,271 Epoch[94] Batch [1270]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.073897,	
2017-07-13 17:11:54,119 Epoch[94] Batch [1280]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.073903,	
2017-07-13 17:12:02,163 Epoch[94] Batch [1290]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.073863,	
2017-07-13 17:12:10,312 Epoch[94] Batch [1300]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.073845,	
2017-07-13 17:12:18,712 Epoch[94] Batch [1310]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.073868,	
2017-07-13 17:12:26,704 Epoch[94] Batch [1320]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.073804,	
2017-07-13 17:12:34,820 Epoch[94] Batch [1330]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.073816,	
2017-07-13 17:12:43,003 Epoch[94] Batch [1340]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.073755,	
2017-07-13 17:12:51,458 Epoch[94] Batch [1350]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.073740,	
2017-07-13 17:12:59,590 Epoch[94] Batch [1360]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.073775,	
2017-07-13 17:13:07,795 Epoch[94] Batch [1370]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.073760,	
2017-07-13 17:13:15,686 Epoch[94] Batch [1380]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.073759,	
2017-07-13 17:13:23,644 Epoch[94] Batch [1390]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.073723,	
2017-07-13 17:13:31,701 Epoch[94] Batch [1400]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.073740,	
2017-07-13 17:13:39,992 Epoch[94] Batch [1410]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.073715,	
2017-07-13 17:13:48,040 Epoch[94] Batch [1420]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.073650,	
2017-07-13 17:13:56,539 Epoch[94] Batch [1430]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.073631,	
2017-07-13 17:14:04,891 Epoch[94] Batch [1440]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.073639,	
2017-07-13 17:14:13,160 Epoch[94] Batch [1450]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.073575,	
2017-07-13 17:14:21,172 Epoch[94] Batch [1460]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.073521,	
2017-07-13 17:14:29,181 Epoch[94] Batch [1470]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.073555,	
2017-07-13 17:14:37,198 Epoch[94] Batch [1480]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.073597,	
2017-07-13 17:14:42,121 Epoch[94] Train-FCNLogLoss=0.073587
2017-07-13 17:14:42,121 Epoch[94] Time cost=1650.575
2017-07-13 17:14:43,265 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0095.params"
2017-07-13 17:14:47,229 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0095.states"
2017-07-13 17:14:56,714 Epoch[95] Batch [10]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.071146,	
2017-07-13 17:15:04,886 Epoch[95] Batch [20]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.074497,	
2017-07-13 17:15:13,081 Epoch[95] Batch [30]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.070608,	
2017-07-13 17:15:21,079 Epoch[95] Batch [40]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.073113,	
2017-07-13 17:15:29,058 Epoch[95] Batch [50]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.074200,	
2017-07-13 17:15:37,064 Epoch[95] Batch [60]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.074017,	
2017-07-13 17:15:44,966 Epoch[95] Batch [70]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.074421,	
2017-07-13 17:15:53,019 Epoch[95] Batch [80]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.073779,	
2017-07-13 17:16:00,891 Epoch[95] Batch [90]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.073594,	
2017-07-13 17:16:09,045 Epoch[95] Batch [100]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.072725,	
2017-07-13 17:16:17,128 Epoch[95] Batch [110]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.072910,	
2017-07-13 17:16:24,990 Epoch[95] Batch [120]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.072510,	
2017-07-13 17:16:32,986 Epoch[95] Batch [130]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.072853,	
2017-07-13 17:16:41,069 Epoch[95] Batch [140]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.072968,	
2017-07-13 17:16:48,910 Epoch[95] Batch [150]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.072996,	
2017-07-13 17:16:56,939 Epoch[95] Batch [160]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.072762,	
2017-07-13 17:17:04,889 Epoch[95] Batch [170]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.072930,	
2017-07-13 17:17:12,999 Epoch[95] Batch [180]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.072939,	
2017-07-13 17:17:20,735 Epoch[95] Batch [190]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.072893,	
2017-07-13 17:17:28,929 Epoch[95] Batch [200]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.072505,	
2017-07-13 17:17:36,716 Epoch[95] Batch [210]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.072648,	
2017-07-13 17:17:44,696 Epoch[95] Batch [220]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.072730,	
2017-07-13 17:17:52,532 Epoch[95] Batch [230]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.072473,	
2017-07-13 17:18:00,645 Epoch[95] Batch [240]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.072565,	
2017-07-13 17:18:09,564 Epoch[95] Batch [250]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.072735,	
2017-07-13 17:18:23,721 Epoch[95] Batch [260]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.072947,	
2017-07-13 17:18:39,023 Epoch[95] Batch [270]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.073163,	
2017-07-13 17:18:53,870 Epoch[95] Batch [280]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.073191,	
2017-07-13 17:19:09,151 Epoch[95] Batch [290]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.073231,	
2017-07-13 17:19:24,647 Epoch[95] Batch [300]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.073242,	
2017-07-13 17:19:40,066 Epoch[95] Batch [310]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.073196,	
2017-07-13 17:19:55,174 Epoch[95] Batch [320]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.073682,	
2017-07-13 17:20:11,310 Epoch[95] Batch [330]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.073565,	
2017-07-13 17:20:25,504 Epoch[95] Batch [340]	Speed: 2.82 samples/sec	Train-FCNLogLoss=0.073628,	
2017-07-13 17:20:40,562 Epoch[95] Batch [350]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.073540,	
2017-07-13 17:20:55,634 Epoch[95] Batch [360]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.073477,	
2017-07-13 17:21:12,578 Epoch[95] Batch [370]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.073449,	
2017-07-13 17:21:28,113 Epoch[95] Batch [380]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.073504,	
2017-07-13 17:21:43,959 Epoch[95] Batch [390]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.073550,	
2017-07-13 17:21:59,843 Epoch[95] Batch [400]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.073581,	
2017-07-13 17:22:15,233 Epoch[95] Batch [410]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073913,	
2017-07-13 17:22:31,006 Epoch[95] Batch [420]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.073838,	
2017-07-13 17:22:45,491 Epoch[95] Batch [430]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.073731,	
2017-07-13 17:23:01,281 Epoch[95] Batch [440]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.073675,	
2017-07-13 17:23:17,195 Epoch[95] Batch [450]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.073593,	
2017-07-13 17:23:32,891 Epoch[95] Batch [460]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.073532,	
2017-07-13 17:23:48,324 Epoch[95] Batch [470]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.073606,	
2017-07-13 17:24:04,136 Epoch[95] Batch [480]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.073582,	
2017-07-13 17:24:20,256 Epoch[95] Batch [490]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.073578,	
2017-07-13 17:24:37,030 Epoch[95] Batch [500]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.073606,	
2017-07-13 17:24:53,247 Epoch[95] Batch [510]	Speed: 2.47 samples/sec	Train-FCNLogLoss=0.073679,	
2017-07-13 17:25:09,217 Epoch[95] Batch [520]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.073625,	
2017-07-13 17:25:24,075 Epoch[95] Batch [530]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.073689,	
2017-07-13 17:25:40,032 Epoch[95] Batch [540]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.073623,	
2017-07-13 17:25:55,443 Epoch[95] Batch [550]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073524,	
2017-07-13 17:26:10,957 Epoch[95] Batch [560]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.073563,	
2017-07-13 17:26:26,355 Epoch[95] Batch [570]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073581,	
2017-07-13 17:26:41,746 Epoch[95] Batch [580]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073501,	
2017-07-13 17:26:56,246 Epoch[95] Batch [590]	Speed: 2.76 samples/sec	Train-FCNLogLoss=0.073395,	
2017-07-13 17:27:11,616 Epoch[95] Batch [600]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073485,	
2017-07-13 17:27:26,745 Epoch[95] Batch [610]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.073494,	
2017-07-13 17:27:42,670 Epoch[95] Batch [620]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.073579,	
2017-07-13 17:27:58,371 Epoch[95] Batch [630]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.073618,	
2017-07-13 17:28:14,399 Epoch[95] Batch [640]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.073684,	
2017-07-13 17:28:30,183 Epoch[95] Batch [650]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.073743,	
2017-07-13 17:28:44,991 Epoch[95] Batch [660]	Speed: 2.70 samples/sec	Train-FCNLogLoss=0.073763,	
2017-07-13 17:28:58,816 Epoch[95] Batch [670]	Speed: 2.89 samples/sec	Train-FCNLogLoss=0.073791,	
2017-07-13 17:29:13,070 Epoch[95] Batch [680]	Speed: 2.81 samples/sec	Train-FCNLogLoss=0.073775,	
2017-07-13 17:29:29,468 Epoch[95] Batch [690]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.073801,	
2017-07-13 17:29:45,113 Epoch[95] Batch [700]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.073653,	
2017-07-13 17:29:59,864 Epoch[95] Batch [710]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.073698,	
2017-07-13 17:30:13,987 Epoch[95] Batch [720]	Speed: 2.83 samples/sec	Train-FCNLogLoss=0.073539,	
2017-07-13 17:30:26,826 Epoch[95] Batch [730]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.073520,	
2017-07-13 17:30:41,399 Epoch[95] Batch [740]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.073496,	
2017-07-13 17:30:56,470 Epoch[95] Batch [750]	Speed: 2.65 samples/sec	Train-FCNLogLoss=0.073524,	
2017-07-13 17:31:11,197 Epoch[95] Batch [760]	Speed: 2.72 samples/sec	Train-FCNLogLoss=0.073594,	
2017-07-13 17:31:26,580 Epoch[95] Batch [770]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073554,	
2017-07-13 17:31:41,335 Epoch[95] Batch [780]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.073556,	
2017-07-13 17:31:54,982 Epoch[95] Batch [790]	Speed: 2.93 samples/sec	Train-FCNLogLoss=0.073482,	
2017-07-13 17:32:10,436 Epoch[95] Batch [800]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.073447,	
2017-07-13 17:32:26,125 Epoch[95] Batch [810]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.073500,	
2017-07-13 17:32:41,548 Epoch[95] Batch [820]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.073549,	
2017-07-13 17:32:56,911 Epoch[95] Batch [830]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073499,	
2017-07-13 17:33:12,396 Epoch[95] Batch [840]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.073527,	
2017-07-13 17:33:26,472 Epoch[95] Batch [850]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.073476,	
2017-07-13 17:33:41,669 Epoch[95] Batch [860]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.073464,	
2017-07-13 17:33:56,925 Epoch[95] Batch [870]	Speed: 2.62 samples/sec	Train-FCNLogLoss=0.073525,	
2017-07-13 17:34:12,279 Epoch[95] Batch [880]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.073446,	
2017-07-13 17:34:26,828 Epoch[95] Batch [890]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.073430,	
2017-07-13 17:34:42,202 Epoch[95] Batch [900]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073460,	
2017-07-13 17:34:55,872 Epoch[95] Batch [910]	Speed: 2.93 samples/sec	Train-FCNLogLoss=0.073454,	
2017-07-13 17:35:10,484 Epoch[95] Batch [920]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.073522,	
2017-07-13 17:35:25,643 Epoch[95] Batch [930]	Speed: 2.64 samples/sec	Train-FCNLogLoss=0.073541,	
2017-07-13 17:35:41,154 Epoch[95] Batch [940]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.073574,	
2017-07-13 17:35:56,334 Epoch[95] Batch [950]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.073538,	
2017-07-13 17:36:11,879 Epoch[95] Batch [960]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.073527,	
2017-07-13 17:36:27,347 Epoch[95] Batch [970]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.073471,	
2017-07-13 17:36:42,227 Epoch[95] Batch [980]	Speed: 2.69 samples/sec	Train-FCNLogLoss=0.073451,	
2017-07-13 17:36:56,985 Epoch[95] Batch [990]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.073429,	
2017-07-13 17:37:11,942 Epoch[95] Batch [1000]	Speed: 2.67 samples/sec	Train-FCNLogLoss=0.073458,	
2017-07-13 17:37:28,440 Epoch[95] Batch [1010]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.073448,	
2017-07-13 17:37:44,052 Epoch[95] Batch [1020]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.073423,	
2017-07-13 17:38:00,404 Epoch[95] Batch [1030]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.073430,	
2017-07-13 17:38:16,247 Epoch[95] Batch [1040]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.073492,	
2017-07-13 17:38:32,822 Epoch[95] Batch [1050]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.073386,	
2017-07-13 17:38:49,268 Epoch[95] Batch [1060]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.073374,	
2017-07-13 17:39:05,173 Epoch[95] Batch [1070]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.073347,	
2017-07-13 17:39:21,122 Epoch[95] Batch [1080]	Speed: 2.51 samples/sec	Train-FCNLogLoss=0.073359,	
2017-07-13 17:39:37,599 Epoch[95] Batch [1090]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.073303,	
2017-07-13 17:39:52,994 Epoch[95] Batch [1100]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.073325,	
2017-07-13 17:40:09,275 Epoch[95] Batch [1110]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.073400,	
2017-07-13 17:40:24,508 Epoch[95] Batch [1120]	Speed: 2.63 samples/sec	Train-FCNLogLoss=0.073366,	
2017-07-13 17:40:39,981 Epoch[95] Batch [1130]	Speed: 2.59 samples/sec	Train-FCNLogLoss=0.073329,	
2017-07-13 17:40:55,812 Epoch[95] Batch [1140]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.073294,	
2017-07-13 17:41:10,547 Epoch[95] Batch [1150]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.073330,	
2017-07-13 17:41:24,989 Epoch[95] Batch [1160]	Speed: 2.77 samples/sec	Train-FCNLogLoss=0.073357,	
2017-07-13 17:41:40,497 Epoch[95] Batch [1170]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.073393,	
2017-07-13 17:41:57,060 Epoch[95] Batch [1180]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.073448,	
2017-07-13 17:42:12,696 Epoch[95] Batch [1190]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.073464,	
2017-07-13 17:42:27,457 Epoch[95] Batch [1200]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.073474,	
2017-07-13 17:42:43,581 Epoch[95] Batch [1210]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.073479,	
2017-07-13 17:42:58,619 Epoch[95] Batch [1220]	Speed: 2.66 samples/sec	Train-FCNLogLoss=0.073515,	
2017-07-13 17:43:14,383 Epoch[95] Batch [1230]	Speed: 2.54 samples/sec	Train-FCNLogLoss=0.073478,	
2017-07-13 17:43:29,858 Epoch[95] Batch [1240]	Speed: 2.58 samples/sec	Train-FCNLogLoss=0.073508,	
2017-07-13 17:43:46,920 Epoch[95] Batch [1250]	Speed: 2.34 samples/sec	Train-FCNLogLoss=0.073527,	
2017-07-13 17:44:02,575 Epoch[95] Batch [1260]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.073570,	
2017-07-13 17:44:18,719 Epoch[95] Batch [1270]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.073552,	
2017-07-13 17:44:33,344 Epoch[95] Batch [1280]	Speed: 2.74 samples/sec	Train-FCNLogLoss=0.073460,	
2017-07-13 17:44:49,738 Epoch[95] Batch [1290]	Speed: 2.44 samples/sec	Train-FCNLogLoss=0.073473,	
2017-07-13 17:45:05,823 Epoch[95] Batch [1300]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.073457,	
2017-07-13 17:45:22,161 Epoch[95] Batch [1310]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.073536,	
2017-07-13 17:45:38,278 Epoch[95] Batch [1320]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.073535,	
2017-07-13 17:45:53,628 Epoch[95] Batch [1330]	Speed: 2.61 samples/sec	Train-FCNLogLoss=0.073531,	
2017-07-13 17:46:09,251 Epoch[95] Batch [1340]	Speed: 2.56 samples/sec	Train-FCNLogLoss=0.073508,	
2017-07-13 17:46:25,284 Epoch[95] Batch [1350]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.073559,	
2017-07-13 17:46:42,257 Epoch[95] Batch [1360]	Speed: 2.36 samples/sec	Train-FCNLogLoss=0.073545,	
2017-07-13 17:46:58,096 Epoch[95] Batch [1370]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.073610,	
2017-07-13 17:47:13,631 Epoch[95] Batch [1380]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.073592,	
2017-07-13 17:47:30,267 Epoch[95] Batch [1390]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.073603,	
2017-07-13 17:47:46,948 Epoch[95] Batch [1400]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.073585,	
2017-07-13 17:48:03,442 Epoch[95] Batch [1410]	Speed: 2.43 samples/sec	Train-FCNLogLoss=0.073522,	
2017-07-13 17:48:19,544 Epoch[95] Batch [1420]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.073475,	
2017-07-13 17:48:30,849 Epoch[95] Batch [1430]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.073477,	
2017-07-13 17:48:42,019 Epoch[95] Batch [1440]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.073503,	
2017-07-13 17:48:54,560 Epoch[95] Batch [1450]	Speed: 3.19 samples/sec	Train-FCNLogLoss=0.073509,	
2017-07-13 17:49:07,689 Epoch[95] Batch [1460]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.073462,	
2017-07-13 17:49:23,687 Epoch[95] Batch [1470]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.073468,	
2017-07-13 17:49:39,766 Epoch[95] Batch [1480]	Speed: 2.49 samples/sec	Train-FCNLogLoss=0.073464,	
2017-07-13 17:49:49,158 Epoch[95] Train-FCNLogLoss=0.073437
2017-07-13 17:49:49,158 Epoch[95] Time cost=2101.928
2017-07-13 17:49:53,238 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0096.params"
2017-07-13 17:50:07,962 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0096.states"
2017-07-13 17:50:28,389 Epoch[96] Batch [10]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.078938,	
2017-07-13 17:50:46,273 Epoch[96] Batch [20]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.082311,	
2017-07-13 17:51:05,150 Epoch[96] Batch [30]	Speed: 2.12 samples/sec	Train-FCNLogLoss=0.080052,	
2017-07-13 17:51:23,823 Epoch[96] Batch [40]	Speed: 2.14 samples/sec	Train-FCNLogLoss=0.078932,	
2017-07-13 17:51:43,422 Epoch[96] Batch [50]	Speed: 2.04 samples/sec	Train-FCNLogLoss=0.077807,	
2017-07-13 17:52:01,890 Epoch[96] Batch [60]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.077829,	
2017-07-13 17:52:19,236 Epoch[96] Batch [70]	Speed: 2.31 samples/sec	Train-FCNLogLoss=0.076785,	
2017-07-13 17:52:38,963 Epoch[96] Batch [80]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.076649,	
2017-07-13 17:52:57,360 Epoch[96] Batch [90]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.075532,	
2017-07-13 17:53:15,833 Epoch[96] Batch [100]	Speed: 2.17 samples/sec	Train-FCNLogLoss=0.075245,	
2017-07-13 17:53:33,772 Epoch[96] Batch [110]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.074879,	
2017-07-13 17:53:51,692 Epoch[96] Batch [120]	Speed: 2.23 samples/sec	Train-FCNLogLoss=0.075210,	
2017-07-13 17:54:07,691 Epoch[96] Batch [130]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.074463,	
2017-07-13 17:54:24,952 Epoch[96] Batch [140]	Speed: 2.32 samples/sec	Train-FCNLogLoss=0.074747,	
2017-07-13 17:54:43,958 Epoch[96] Batch [150]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.074417,	
2017-07-13 17:55:09,798 Epoch[96] Batch [160]	Speed: 1.55 samples/sec	Train-FCNLogLoss=0.074269,	
2017-07-13 17:55:29,791 Epoch[96] Batch [170]	Speed: 2.00 samples/sec	Train-FCNLogLoss=0.074164,	
2017-07-13 17:55:51,054 Epoch[96] Batch [180]	Speed: 1.88 samples/sec	Train-FCNLogLoss=0.074120,	
2017-07-13 17:56:10,897 Epoch[96] Batch [190]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.074333,	
2017-07-13 17:56:30,929 Epoch[96] Batch [200]	Speed: 2.00 samples/sec	Train-FCNLogLoss=0.074562,	
2017-07-13 17:56:49,461 Epoch[96] Batch [210]	Speed: 2.16 samples/sec	Train-FCNLogLoss=0.074404,	
2017-07-13 17:57:08,978 Epoch[96] Batch [220]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.074143,	
2017-07-13 17:57:26,957 Epoch[96] Batch [230]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.073896,	
2017-07-13 17:57:46,227 Epoch[96] Batch [240]	Speed: 2.08 samples/sec	Train-FCNLogLoss=0.073796,	
2017-07-13 17:58:05,411 Epoch[96] Batch [250]	Speed: 2.09 samples/sec	Train-FCNLogLoss=0.073766,	
2017-07-13 17:58:24,859 Epoch[96] Batch [260]	Speed: 2.06 samples/sec	Train-FCNLogLoss=0.073641,	
2017-07-13 17:58:44,381 Epoch[96] Batch [270]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.073428,	
2017-07-13 17:59:04,290 Epoch[96] Batch [280]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.073324,	
2017-07-13 17:59:22,090 Epoch[96] Batch [290]	Speed: 2.25 samples/sec	Train-FCNLogLoss=0.073300,	
2017-07-13 17:59:40,661 Epoch[96] Batch [300]	Speed: 2.15 samples/sec	Train-FCNLogLoss=0.073509,	
2017-07-13 18:00:00,928 Epoch[96] Batch [310]	Speed: 1.97 samples/sec	Train-FCNLogLoss=0.073648,	
2017-07-13 18:00:20,840 Epoch[96] Batch [320]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.073794,	
2017-07-13 18:00:38,849 Epoch[96] Batch [330]	Speed: 2.22 samples/sec	Train-FCNLogLoss=0.073819,	
2017-07-13 18:00:59,221 Epoch[96] Batch [340]	Speed: 1.96 samples/sec	Train-FCNLogLoss=0.073684,	
2017-07-13 18:01:18,905 Epoch[96] Batch [350]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.073446,	
2017-07-13 18:01:37,970 Epoch[96] Batch [360]	Speed: 2.10 samples/sec	Train-FCNLogLoss=0.073337,	
2017-07-13 18:01:57,886 Epoch[96] Batch [370]	Speed: 2.01 samples/sec	Train-FCNLogLoss=0.073332,	
2017-07-13 18:02:16,208 Epoch[96] Batch [380]	Speed: 2.18 samples/sec	Train-FCNLogLoss=0.073308,	
2017-07-13 18:02:35,766 Epoch[96] Batch [390]	Speed: 2.05 samples/sec	Train-FCNLogLoss=0.073505,	
2017-07-13 18:02:55,494 Epoch[96] Batch [400]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.073624,	
2017-07-13 18:03:15,686 Epoch[96] Batch [410]	Speed: 1.98 samples/sec	Train-FCNLogLoss=0.073530,	
2017-07-13 18:03:35,501 Epoch[96] Batch [420]	Speed: 2.02 samples/sec	Train-FCNLogLoss=0.073483,	
2017-07-13 18:03:55,893 Epoch[96] Batch [430]	Speed: 1.96 samples/sec	Train-FCNLogLoss=0.073532,	
2017-07-13 18:04:16,005 Epoch[96] Batch [440]	Speed: 1.99 samples/sec	Train-FCNLogLoss=0.073466,	
2017-07-13 18:04:30,681 Epoch[96] Batch [450]	Speed: 2.73 samples/sec	Train-FCNLogLoss=0.073354,	
2017-07-13 18:04:38,760 Epoch[96] Batch [460]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.073445,	
2017-07-13 18:04:47,286 Epoch[96] Batch [470]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.073495,	
2017-07-13 18:04:55,184 Epoch[96] Batch [480]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.073469,	
2017-07-13 18:05:03,093 Epoch[96] Batch [490]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.073410,	
2017-07-13 18:05:10,842 Epoch[96] Batch [500]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.073464,	
2017-07-13 18:05:18,918 Epoch[96] Batch [510]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.073317,	
2017-07-13 18:05:27,150 Epoch[96] Batch [520]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.073448,	
2017-07-13 18:05:35,076 Epoch[96] Batch [530]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.073460,	
2017-07-13 18:05:42,935 Epoch[96] Batch [540]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.073548,	
2017-07-13 18:05:51,034 Epoch[96] Batch [550]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.073488,	
2017-07-13 18:05:59,286 Epoch[96] Batch [560]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.073450,	
2017-07-13 18:06:07,432 Epoch[96] Batch [570]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.073438,	
2017-07-13 18:06:15,779 Epoch[96] Batch [580]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.073453,	
2017-07-13 18:06:24,375 Epoch[96] Batch [590]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.073541,	
2017-07-13 18:06:32,239 Epoch[96] Batch [600]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.073541,	
2017-07-13 18:06:40,152 Epoch[96] Batch [610]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.073547,	
2017-07-13 18:06:48,254 Epoch[96] Batch [620]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.073570,	
2017-07-13 18:06:57,040 Epoch[96] Batch [630]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.073377,	
2017-07-13 18:07:04,996 Epoch[96] Batch [640]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.073386,	
2017-07-13 18:07:13,074 Epoch[96] Batch [650]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.073257,	
2017-07-13 18:07:20,952 Epoch[96] Batch [660]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.073152,	
2017-07-13 18:07:28,992 Epoch[96] Batch [670]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.073079,	
2017-07-13 18:07:36,853 Epoch[96] Batch [680]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.073104,	
2017-07-13 18:07:45,049 Epoch[96] Batch [690]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.073144,	
2017-07-13 18:07:53,958 Epoch[96] Batch [700]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.073220,	
2017-07-13 18:08:10,201 Epoch[96] Batch [710]	Speed: 2.46 samples/sec	Train-FCNLogLoss=0.073272,	
2017-07-13 18:08:26,531 Epoch[96] Batch [720]	Speed: 2.45 samples/sec	Train-FCNLogLoss=0.073321,	
2017-07-13 18:08:42,660 Epoch[96] Batch [730]	Speed: 2.48 samples/sec	Train-FCNLogLoss=0.073297,	
2017-07-13 18:09:00,360 Epoch[96] Batch [740]	Speed: 2.26 samples/sec	Train-FCNLogLoss=0.073288,	
2017-07-13 18:09:16,986 Epoch[96] Batch [750]	Speed: 2.41 samples/sec	Train-FCNLogLoss=0.073292,	
2017-07-13 18:09:31,042 Epoch[96] Batch [760]	Speed: 2.85 samples/sec	Train-FCNLogLoss=0.073235,	
2017-07-13 18:09:47,050 Epoch[96] Batch [770]	Speed: 2.50 samples/sec	Train-FCNLogLoss=0.073235,	
2017-07-13 18:10:03,708 Epoch[96] Batch [780]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.073300,	
2017-07-13 18:10:20,357 Epoch[96] Batch [790]	Speed: 2.40 samples/sec	Train-FCNLogLoss=0.073293,	
2017-07-13 18:10:37,750 Epoch[96] Batch [800]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.073260,	
2017-07-13 18:10:55,164 Epoch[96] Batch [810]	Speed: 2.30 samples/sec	Train-FCNLogLoss=0.073218,	
2017-07-13 18:11:12,001 Epoch[96] Batch [820]	Speed: 2.38 samples/sec	Train-FCNLogLoss=0.073193,	
2017-07-13 18:11:27,672 Epoch[96] Batch [830]	Speed: 2.55 samples/sec	Train-FCNLogLoss=0.073252,	
2017-07-13 18:11:44,559 Epoch[96] Batch [840]	Speed: 2.37 samples/sec	Train-FCNLogLoss=0.073219,	
2017-07-13 18:12:00,137 Epoch[96] Batch [850]	Speed: 2.57 samples/sec	Train-FCNLogLoss=0.073129,	
2017-07-13 18:12:16,670 Epoch[96] Batch [860]	Speed: 2.42 samples/sec	Train-FCNLogLoss=0.073151,	
2017-07-13 18:12:33,405 Epoch[96] Batch [870]	Speed: 2.39 samples/sec	Train-FCNLogLoss=0.073201,	
2017-07-13 18:12:49,265 Epoch[96] Batch [880]	Speed: 2.52 samples/sec	Train-FCNLogLoss=0.073138,	
2017-07-13 18:13:02,846 Epoch[96] Batch [890]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.073108,	
2017-07-13 18:13:10,997 Epoch[96] Batch [900]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.073162,	
2017-07-13 18:13:18,935 Epoch[96] Batch [910]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.073163,	
2017-07-13 18:13:27,102 Epoch[96] Batch [920]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073077,	
2017-07-13 18:13:35,171 Epoch[96] Batch [930]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.073145,	
2017-07-13 18:13:43,470 Epoch[96] Batch [940]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.073262,	
2017-07-13 18:13:51,631 Epoch[96] Batch [950]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073257,	
2017-07-13 18:13:59,908 Epoch[96] Batch [960]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.073338,	
2017-07-13 18:14:08,211 Epoch[96] Batch [970]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.073338,	
2017-07-13 18:14:16,487 Epoch[96] Batch [980]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.073306,	
2017-07-13 18:14:24,656 Epoch[96] Batch [990]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073263,	
2017-07-13 18:14:32,732 Epoch[96] Batch [1000]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.073254,	
2017-07-13 18:14:40,763 Epoch[96] Batch [1010]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.073198,	
2017-07-13 18:14:49,077 Epoch[96] Batch [1020]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.073169,	
2017-07-13 18:14:57,176 Epoch[96] Batch [1030]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.073152,	
2017-07-13 18:15:05,518 Epoch[96] Batch [1040]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.073157,	
2017-07-13 18:15:13,740 Epoch[96] Batch [1050]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.073115,	
2017-07-13 18:15:21,836 Epoch[96] Batch [1060]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.073136,	
2017-07-13 18:15:30,061 Epoch[96] Batch [1070]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.073228,	
2017-07-13 18:15:38,089 Epoch[96] Batch [1080]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.073233,	
2017-07-13 18:15:46,359 Epoch[96] Batch [1090]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.073249,	
2017-07-13 18:15:54,907 Epoch[96] Batch [1100]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.073156,	
2017-07-13 18:16:02,984 Epoch[96] Batch [1110]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.073167,	
2017-07-13 18:16:10,955 Epoch[96] Batch [1120]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.073201,	
2017-07-13 18:16:19,104 Epoch[96] Batch [1130]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.073272,	
2017-07-13 18:16:27,195 Epoch[96] Batch [1140]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.073299,	
2017-07-13 18:16:35,376 Epoch[96] Batch [1150]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.073274,	
2017-07-13 18:16:43,458 Epoch[96] Batch [1160]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.073278,	
2017-07-13 18:16:51,622 Epoch[96] Batch [1170]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073292,	
2017-07-13 18:16:59,789 Epoch[96] Batch [1180]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073329,	
2017-07-13 18:17:07,852 Epoch[96] Batch [1190]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.073293,	
2017-07-13 18:17:15,727 Epoch[96] Batch [1200]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.073288,	
2017-07-13 18:17:23,941 Epoch[96] Batch [1210]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.073357,	
2017-07-13 18:17:32,022 Epoch[96] Batch [1220]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.073391,	
2017-07-13 18:17:40,236 Epoch[96] Batch [1230]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.073406,	
2017-07-13 18:17:48,551 Epoch[96] Batch [1240]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.073402,	
2017-07-13 18:17:56,569 Epoch[96] Batch [1250]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.073403,	
2017-07-13 18:18:04,768 Epoch[96] Batch [1260]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.073346,	
2017-07-13 18:18:12,830 Epoch[96] Batch [1270]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.073368,	
2017-07-13 18:18:21,164 Epoch[96] Batch [1280]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.073345,	
2017-07-13 18:18:29,131 Epoch[96] Batch [1290]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.073285,	
2017-07-13 18:18:37,528 Epoch[96] Batch [1300]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.073278,	
2017-07-13 18:18:45,588 Epoch[96] Batch [1310]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.073272,	
2017-07-13 18:18:53,470 Epoch[96] Batch [1320]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.073218,	
2017-07-13 18:19:01,859 Epoch[96] Batch [1330]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.073238,	
2017-07-13 18:19:09,848 Epoch[96] Batch [1340]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.073240,	
2017-07-13 18:19:18,080 Epoch[96] Batch [1350]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.073313,	
2017-07-13 18:19:26,233 Epoch[96] Batch [1360]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.073393,	
2017-07-13 18:19:34,465 Epoch[96] Batch [1370]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.073370,	
2017-07-13 18:19:42,624 Epoch[96] Batch [1380]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073374,	
2017-07-13 18:19:50,781 Epoch[96] Batch [1390]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.073367,	
2017-07-13 18:19:59,097 Epoch[96] Batch [1400]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.073314,	
2017-07-13 18:20:07,472 Epoch[96] Batch [1410]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.073265,	
2017-07-13 18:20:15,917 Epoch[96] Batch [1420]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.073328,	
2017-07-13 18:20:24,268 Epoch[96] Batch [1430]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.073318,	
2017-07-13 18:20:32,738 Epoch[96] Batch [1440]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.073258,	
2017-07-13 18:20:41,267 Epoch[96] Batch [1450]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.073279,	
2017-07-13 18:20:54,378 Epoch[96] Batch [1460]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.073286,	
2017-07-13 18:21:02,617 Epoch[96] Batch [1470]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.073336,	
2017-07-13 18:21:10,894 Epoch[96] Batch [1480]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.073329,	
2017-07-13 18:21:15,996 Epoch[96] Train-FCNLogLoss=0.073331
2017-07-13 18:21:15,996 Epoch[96] Time cost=1868.033
2017-07-13 18:21:17,143 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0097.params"
2017-07-13 18:21:21,557 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0097.states"
2017-07-13 18:21:32,227 Epoch[97] Batch [10]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.073451,	
2017-07-13 18:21:41,669 Epoch[97] Batch [20]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.076926,	
2017-07-13 18:21:51,245 Epoch[97] Batch [30]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.072960,	
2017-07-13 18:22:00,471 Epoch[97] Batch [40]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.074865,	
2017-07-13 18:22:10,024 Epoch[97] Batch [50]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.074971,	
2017-07-13 18:22:19,394 Epoch[97] Batch [60]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.073588,	
2017-07-13 18:22:28,935 Epoch[97] Batch [70]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.073457,	
2017-07-13 18:22:38,592 Epoch[97] Batch [80]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.074171,	
2017-07-13 18:22:48,212 Epoch[97] Batch [90]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.073673,	
2017-07-13 18:22:57,780 Epoch[97] Batch [100]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.073400,	
2017-07-13 18:23:07,288 Epoch[97] Batch [110]	Speed: 4.21 samples/sec	Train-FCNLogLoss=0.072462,	
2017-07-13 18:23:16,637 Epoch[97] Batch [120]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.072879,	
2017-07-13 18:23:24,880 Epoch[97] Batch [130]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.072708,	
2017-07-13 18:23:31,592 Epoch[97] Batch [140]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072484,	
2017-07-13 18:23:37,390 Epoch[97] Batch [150]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.072912,	
2017-07-13 18:23:43,495 Epoch[97] Batch [160]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.072704,	
2017-07-13 18:23:50,223 Epoch[97] Batch [170]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073004,	
2017-07-13 18:23:56,855 Epoch[97] Batch [180]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072771,	
2017-07-13 18:24:03,484 Epoch[97] Batch [190]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072840,	
2017-07-13 18:24:10,159 Epoch[97] Batch [200]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072732,	
2017-07-13 18:24:16,895 Epoch[97] Batch [210]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072606,	
2017-07-13 18:24:23,606 Epoch[97] Batch [220]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072362,	
2017-07-13 18:24:30,362 Epoch[97] Batch [230]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072625,	
2017-07-13 18:24:37,067 Epoch[97] Batch [240]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072616,	
2017-07-13 18:24:43,816 Epoch[97] Batch [250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072768,	
2017-07-13 18:24:50,542 Epoch[97] Batch [260]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072593,	
2017-07-13 18:24:57,273 Epoch[97] Batch [270]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072566,	
2017-07-13 18:25:04,003 Epoch[97] Batch [280]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072667,	
2017-07-13 18:25:10,719 Epoch[97] Batch [290]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072573,	
2017-07-13 18:25:17,466 Epoch[97] Batch [300]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072793,	
2017-07-13 18:25:24,305 Epoch[97] Batch [310]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.072925,	
2017-07-13 18:25:31,195 Epoch[97] Batch [320]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.072807,	
2017-07-13 18:25:37,979 Epoch[97] Batch [330]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072985,	
2017-07-13 18:25:44,742 Epoch[97] Batch [340]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073187,	
2017-07-13 18:25:51,503 Epoch[97] Batch [350]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073412,	
2017-07-13 18:25:58,273 Epoch[97] Batch [360]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073430,	
2017-07-13 18:26:04,971 Epoch[97] Batch [370]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073474,	
2017-07-13 18:26:11,689 Epoch[97] Batch [380]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073371,	
2017-07-13 18:26:18,520 Epoch[97] Batch [390]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073351,	
2017-07-13 18:26:25,231 Epoch[97] Batch [400]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073409,	
2017-07-13 18:26:31,960 Epoch[97] Batch [410]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073327,	
2017-07-13 18:26:38,665 Epoch[97] Batch [420]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073384,	
2017-07-13 18:26:45,394 Epoch[97] Batch [430]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073355,	
2017-07-13 18:26:52,098 Epoch[97] Batch [440]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073277,	
2017-07-13 18:26:58,855 Epoch[97] Batch [450]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073277,	
2017-07-13 18:27:05,586 Epoch[97] Batch [460]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073226,	
2017-07-13 18:27:12,284 Epoch[97] Batch [470]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072966,	
2017-07-13 18:27:19,000 Epoch[97] Batch [480]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072806,	
2017-07-13 18:27:25,743 Epoch[97] Batch [490]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072793,	
2017-07-13 18:27:32,534 Epoch[97] Batch [500]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072796,	
2017-07-13 18:27:39,079 Epoch[97] Batch [510]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.072786,	
2017-07-13 18:27:45,821 Epoch[97] Batch [520]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072868,	
2017-07-13 18:27:52,545 Epoch[97] Batch [530]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072889,	
2017-07-13 18:27:59,306 Epoch[97] Batch [540]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072912,	
2017-07-13 18:28:06,045 Epoch[97] Batch [550]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072886,	
2017-07-13 18:28:12,768 Epoch[97] Batch [560]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072941,	
2017-07-13 18:28:19,542 Epoch[97] Batch [570]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073032,	
2017-07-13 18:28:26,253 Epoch[97] Batch [580]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073050,	
2017-07-13 18:28:33,105 Epoch[97] Batch [590]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.073097,	
2017-07-13 18:28:39,929 Epoch[97] Batch [600]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073085,	
2017-07-13 18:28:46,644 Epoch[97] Batch [610]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073051,	
2017-07-13 18:28:53,374 Epoch[97] Batch [620]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073039,	
2017-07-13 18:29:00,138 Epoch[97] Batch [630]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073039,	
2017-07-13 18:29:06,839 Epoch[97] Batch [640]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073013,	
2017-07-13 18:29:13,579 Epoch[97] Batch [650]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073131,	
2017-07-13 18:29:20,347 Epoch[97] Batch [660]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073125,	
2017-07-13 18:29:27,048 Epoch[97] Batch [670]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073037,	
2017-07-13 18:29:33,821 Epoch[97] Batch [680]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072977,	
2017-07-13 18:29:40,522 Epoch[97] Batch [690]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072994,	
2017-07-13 18:29:47,261 Epoch[97] Batch [700]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072976,	
2017-07-13 18:29:54,011 Epoch[97] Batch [710]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073072,	
2017-07-13 18:30:00,751 Epoch[97] Batch [720]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073050,	
2017-07-13 18:30:07,484 Epoch[97] Batch [730]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073122,	
2017-07-13 18:30:14,239 Epoch[97] Batch [740]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073177,	
2017-07-13 18:30:20,981 Epoch[97] Batch [750]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073153,	
2017-07-13 18:30:27,730 Epoch[97] Batch [760]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073156,	
2017-07-13 18:30:34,428 Epoch[97] Batch [770]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073047,	
2017-07-13 18:30:41,173 Epoch[97] Batch [780]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072916,	
2017-07-13 18:30:47,897 Epoch[97] Batch [790]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072911,	
2017-07-13 18:30:54,646 Epoch[97] Batch [800]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072957,	
2017-07-13 18:31:01,362 Epoch[97] Batch [810]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072982,	
2017-07-13 18:31:08,079 Epoch[97] Batch [820]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073027,	
2017-07-13 18:31:14,763 Epoch[97] Batch [830]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073068,	
2017-07-13 18:31:21,544 Epoch[97] Batch [840]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073067,	
2017-07-13 18:31:28,271 Epoch[97] Batch [850]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073068,	
2017-07-13 18:31:35,018 Epoch[97] Batch [860]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073158,	
2017-07-13 18:31:41,747 Epoch[97] Batch [870]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073199,	
2017-07-13 18:31:48,477 Epoch[97] Batch [880]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073245,	
2017-07-13 18:31:55,147 Epoch[97] Batch [890]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073217,	
2017-07-13 18:32:01,903 Epoch[97] Batch [900]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073202,	
2017-07-13 18:32:08,623 Epoch[97] Batch [910]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073193,	
2017-07-13 18:32:15,343 Epoch[97] Batch [920]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073153,	
2017-07-13 18:32:22,025 Epoch[97] Batch [930]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073041,	
2017-07-13 18:32:28,839 Epoch[97] Batch [940]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073041,	
2017-07-13 18:32:35,613 Epoch[97] Batch [950]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072958,	
2017-07-13 18:32:42,231 Epoch[97] Batch [960]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.072952,	
2017-07-13 18:32:48,918 Epoch[97] Batch [970]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072857,	
2017-07-13 18:32:55,635 Epoch[97] Batch [980]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072819,	
2017-07-13 18:33:02,390 Epoch[97] Batch [990]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072931,	
2017-07-13 18:33:09,043 Epoch[97] Batch [1000]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072952,	
2017-07-13 18:33:15,740 Epoch[97] Batch [1010]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072958,	
2017-07-13 18:33:22,503 Epoch[97] Batch [1020]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072997,	
2017-07-13 18:33:29,198 Epoch[97] Batch [1030]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073046,	
2017-07-13 18:33:35,894 Epoch[97] Batch [1040]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072995,	
2017-07-13 18:33:42,625 Epoch[97] Batch [1050]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073010,	
2017-07-13 18:33:49,333 Epoch[97] Batch [1060]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073016,	
2017-07-13 18:33:56,001 Epoch[97] Batch [1070]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073047,	
2017-07-13 18:34:02,704 Epoch[97] Batch [1080]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073064,	
2017-07-13 18:34:09,440 Epoch[97] Batch [1090]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073070,	
2017-07-13 18:34:16,194 Epoch[97] Batch [1100]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073109,	
2017-07-13 18:34:22,899 Epoch[97] Batch [1110]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073237,	
2017-07-13 18:34:29,656 Epoch[97] Batch [1120]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073168,	
2017-07-13 18:34:36,368 Epoch[97] Batch [1130]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073127,	
2017-07-13 18:34:43,121 Epoch[97] Batch [1140]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073168,	
2017-07-13 18:34:49,875 Epoch[97] Batch [1150]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073207,	
2017-07-13 18:34:56,596 Epoch[97] Batch [1160]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073190,	
2017-07-13 18:35:03,357 Epoch[97] Batch [1170]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073144,	
2017-07-13 18:35:10,073 Epoch[97] Batch [1180]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073144,	
2017-07-13 18:35:16,819 Epoch[97] Batch [1190]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073179,	
2017-07-13 18:35:23,525 Epoch[97] Batch [1200]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073197,	
2017-07-13 18:35:30,211 Epoch[97] Batch [1210]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073245,	
2017-07-13 18:35:36,952 Epoch[97] Batch [1220]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073277,	
2017-07-13 18:35:43,761 Epoch[97] Batch [1230]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073257,	
2017-07-13 18:35:50,476 Epoch[97] Batch [1240]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073247,	
2017-07-13 18:35:57,195 Epoch[97] Batch [1250]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073180,	
2017-07-13 18:36:03,915 Epoch[97] Batch [1260]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073194,	
2017-07-13 18:36:10,606 Epoch[97] Batch [1270]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073192,	
2017-07-13 18:36:17,327 Epoch[97] Batch [1280]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073160,	
2017-07-13 18:36:24,055 Epoch[97] Batch [1290]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073131,	
2017-07-13 18:36:30,779 Epoch[97] Batch [1300]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073107,	
2017-07-13 18:36:37,506 Epoch[97] Batch [1310]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073076,	
2017-07-13 18:36:44,247 Epoch[97] Batch [1320]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073057,	
2017-07-13 18:36:50,974 Epoch[97] Batch [1330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073027,	
2017-07-13 18:36:57,663 Epoch[97] Batch [1340]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073022,	
2017-07-13 18:37:04,398 Epoch[97] Batch [1350]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073036,	
2017-07-13 18:37:11,157 Epoch[97] Batch [1360]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073005,	
2017-07-13 18:37:17,922 Epoch[97] Batch [1370]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073095,	
2017-07-13 18:37:24,841 Epoch[97] Batch [1380]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.073122,	
2017-07-13 18:37:31,632 Epoch[97] Batch [1390]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073138,	
2017-07-13 18:37:38,300 Epoch[97] Batch [1400]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073231,	
2017-07-13 18:37:45,059 Epoch[97] Batch [1410]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073247,	
2017-07-13 18:37:51,775 Epoch[97] Batch [1420]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073298,	
2017-07-13 18:37:58,533 Epoch[97] Batch [1430]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073282,	
2017-07-13 18:38:05,327 Epoch[97] Batch [1440]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073291,	
2017-07-13 18:38:12,087 Epoch[97] Batch [1450]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073268,	
2017-07-13 18:38:18,800 Epoch[97] Batch [1460]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073267,	
2017-07-13 18:38:25,567 Epoch[97] Batch [1470]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073279,	
2017-07-13 18:38:32,277 Epoch[97] Batch [1480]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073277,	
2017-07-13 18:38:36,362 Epoch[97] Train-FCNLogLoss=0.073276
2017-07-13 18:38:36,363 Epoch[97] Time cost=1034.806
2017-07-13 18:38:37,131 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0098.params"
2017-07-13 18:38:41,509 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0098.states"
2017-07-13 18:38:49,175 Epoch[98] Batch [10]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.070757,	
2017-07-13 18:38:55,827 Epoch[98] Batch [20]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.071622,	
2017-07-13 18:39:02,518 Epoch[98] Batch [30]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.070497,	
2017-07-13 18:39:09,308 Epoch[98] Batch [40]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072288,	
2017-07-13 18:39:16,025 Epoch[98] Batch [50]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073201,	
2017-07-13 18:39:22,803 Epoch[98] Batch [60]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073015,	
2017-07-13 18:39:29,585 Epoch[98] Batch [70]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072314,	
2017-07-13 18:39:36,537 Epoch[98] Batch [80]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.071341,	
2017-07-13 18:39:43,258 Epoch[98] Batch [90]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072251,	
2017-07-13 18:39:49,993 Epoch[98] Batch [100]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.071989,	
2017-07-13 18:39:56,686 Epoch[98] Batch [110]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072631,	
2017-07-13 18:40:03,435 Epoch[98] Batch [120]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073024,	
2017-07-13 18:40:10,187 Epoch[98] Batch [130]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072827,	
2017-07-13 18:40:16,904 Epoch[98] Batch [140]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073422,	
2017-07-13 18:40:22,725 Epoch[98] Batch [150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.073607,	
2017-07-13 18:40:29,245 Epoch[98] Batch [160]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073667,	
2017-07-13 18:40:35,895 Epoch[98] Batch [170]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073541,	
2017-07-13 18:40:42,646 Epoch[98] Batch [180]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073779,	
2017-07-13 18:40:49,366 Epoch[98] Batch [190]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.074190,	
2017-07-13 18:40:56,103 Epoch[98] Batch [200]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073967,	
2017-07-13 18:41:02,848 Epoch[98] Batch [210]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073905,	
2017-07-13 18:41:09,571 Epoch[98] Batch [220]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.074153,	
2017-07-13 18:41:16,270 Epoch[98] Batch [230]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.074364,	
2017-07-13 18:41:23,032 Epoch[98] Batch [240]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.074333,	
2017-07-13 18:41:29,783 Epoch[98] Batch [250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.074342,	
2017-07-13 18:41:36,532 Epoch[98] Batch [260]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.074090,	
2017-07-13 18:41:43,281 Epoch[98] Batch [270]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.074196,	
2017-07-13 18:41:50,023 Epoch[98] Batch [280]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.074033,	
2017-07-13 18:41:56,728 Epoch[98] Batch [290]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073918,	
2017-07-13 18:42:03,478 Epoch[98] Batch [300]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073839,	
2017-07-13 18:42:10,234 Epoch[98] Batch [310]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073623,	
2017-07-13 18:42:17,012 Epoch[98] Batch [320]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073449,	
2017-07-13 18:42:23,732 Epoch[98] Batch [330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073372,	
2017-07-13 18:42:30,518 Epoch[98] Batch [340]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073392,	
2017-07-13 18:42:37,273 Epoch[98] Batch [350]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073569,	
2017-07-13 18:42:43,998 Epoch[98] Batch [360]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073531,	
2017-07-13 18:42:50,690 Epoch[98] Batch [370]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073629,	
2017-07-13 18:42:57,536 Epoch[98] Batch [380]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.073459,	
2017-07-13 18:43:04,506 Epoch[98] Batch [390]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.073479,	
2017-07-13 18:43:11,383 Epoch[98] Batch [400]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.073420,	
2017-07-13 18:43:18,112 Epoch[98] Batch [410]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073381,	
2017-07-13 18:43:24,817 Epoch[98] Batch [420]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073553,	
2017-07-13 18:43:31,567 Epoch[98] Batch [430]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073594,	
2017-07-13 18:43:38,310 Epoch[98] Batch [440]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073515,	
2017-07-13 18:43:45,112 Epoch[98] Batch [450]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073544,	
2017-07-13 18:43:51,757 Epoch[98] Batch [460]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073586,	
2017-07-13 18:43:58,561 Epoch[98] Batch [470]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073746,	
2017-07-13 18:44:05,280 Epoch[98] Batch [480]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073699,	
2017-07-13 18:44:12,006 Epoch[98] Batch [490]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073567,	
2017-07-13 18:44:18,732 Epoch[98] Batch [500]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073614,	
2017-07-13 18:44:25,448 Epoch[98] Batch [510]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073510,	
2017-07-13 18:44:32,272 Epoch[98] Batch [520]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073543,	
2017-07-13 18:44:39,003 Epoch[98] Batch [530]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073574,	
2017-07-13 18:44:45,933 Epoch[98] Batch [540]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.073658,	
2017-07-13 18:44:52,656 Epoch[98] Batch [550]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073637,	
2017-07-13 18:44:59,331 Epoch[98] Batch [560]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073519,	
2017-07-13 18:45:06,073 Epoch[98] Batch [570]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073419,	
2017-07-13 18:45:12,827 Epoch[98] Batch [580]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073222,	
2017-07-13 18:45:19,541 Epoch[98] Batch [590]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073349,	
2017-07-13 18:45:26,333 Epoch[98] Batch [600]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073372,	
2017-07-13 18:45:33,155 Epoch[98] Batch [610]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073333,	
2017-07-13 18:45:39,898 Epoch[98] Batch [620]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073375,	
2017-07-13 18:45:46,537 Epoch[98] Batch [630]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073406,	
2017-07-13 18:45:53,258 Epoch[98] Batch [640]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073473,	
2017-07-13 18:46:00,020 Epoch[98] Batch [650]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073418,	
2017-07-13 18:46:06,745 Epoch[98] Batch [660]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073396,	
2017-07-13 18:46:13,523 Epoch[98] Batch [670]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073247,	
2017-07-13 18:46:20,204 Epoch[98] Batch [680]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073305,	
2017-07-13 18:46:26,970 Epoch[98] Batch [690]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073341,	
2017-07-13 18:46:33,716 Epoch[98] Batch [700]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073224,	
2017-07-13 18:46:40,544 Epoch[98] Batch [710]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073177,	
2017-07-13 18:46:47,221 Epoch[98] Batch [720]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073179,	
2017-07-13 18:46:53,963 Epoch[98] Batch [730]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073093,	
2017-07-13 18:47:00,651 Epoch[98] Batch [740]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073149,	
2017-07-13 18:47:07,375 Epoch[98] Batch [750]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073119,	
2017-07-13 18:47:14,144 Epoch[98] Batch [760]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073078,	
2017-07-13 18:47:20,866 Epoch[98] Batch [770]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072995,	
2017-07-13 18:47:27,599 Epoch[98] Batch [780]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072912,	
2017-07-13 18:47:34,324 Epoch[98] Batch [790]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072787,	
2017-07-13 18:47:41,133 Epoch[98] Batch [800]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072814,	
2017-07-13 18:47:47,883 Epoch[98] Batch [810]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072803,	
2017-07-13 18:47:54,630 Epoch[98] Batch [820]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072842,	
2017-07-13 18:48:01,424 Epoch[98] Batch [830]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072837,	
2017-07-13 18:48:08,109 Epoch[98] Batch [840]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072872,	
2017-07-13 18:48:14,858 Epoch[98] Batch [850]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072921,	
2017-07-13 18:48:21,639 Epoch[98] Batch [860]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072916,	
2017-07-13 18:48:28,300 Epoch[98] Batch [870]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072944,	
2017-07-13 18:48:35,093 Epoch[98] Batch [880]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072883,	
2017-07-13 18:48:41,792 Epoch[98] Batch [890]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072924,	
2017-07-13 18:48:48,480 Epoch[98] Batch [900]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072902,	
2017-07-13 18:48:55,041 Epoch[98] Batch [910]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.072967,	
2017-07-13 18:49:01,813 Epoch[98] Batch [920]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073068,	
2017-07-13 18:49:08,603 Epoch[98] Batch [930]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073022,	
2017-07-13 18:49:15,345 Epoch[98] Batch [940]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073074,	
2017-07-13 18:49:22,352 Epoch[98] Batch [950]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.073111,	
2017-07-13 18:49:29,142 Epoch[98] Batch [960]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073095,	
2017-07-13 18:49:35,872 Epoch[98] Batch [970]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073159,	
2017-07-13 18:49:42,583 Epoch[98] Batch [980]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073202,	
2017-07-13 18:49:49,293 Epoch[98] Batch [990]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073230,	
2017-07-13 18:49:56,083 Epoch[98] Batch [1000]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073192,	
2017-07-13 18:50:02,753 Epoch[98] Batch [1010]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073240,	
2017-07-13 18:50:09,492 Epoch[98] Batch [1020]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073236,	
2017-07-13 18:50:16,226 Epoch[98] Batch [1030]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073237,	
2017-07-13 18:50:22,852 Epoch[98] Batch [1040]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.073227,	
2017-07-13 18:50:29,566 Epoch[98] Batch [1050]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073202,	
2017-07-13 18:50:36,287 Epoch[98] Batch [1060]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073174,	
2017-07-13 18:50:43,051 Epoch[98] Batch [1070]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073258,	
2017-07-13 18:50:49,781 Epoch[98] Batch [1080]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073334,	
2017-07-13 18:50:56,558 Epoch[98] Batch [1090]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073339,	
2017-07-13 18:51:03,338 Epoch[98] Batch [1100]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073324,	
2017-07-13 18:51:10,117 Epoch[98] Batch [1110]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073301,	
2017-07-13 18:51:17,022 Epoch[98] Batch [1120]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.073281,	
2017-07-13 18:51:24,000 Epoch[98] Batch [1130]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.073293,	
2017-07-13 18:51:30,630 Epoch[98] Batch [1140]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073305,	
2017-07-13 18:51:37,352 Epoch[98] Batch [1150]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073271,	
2017-07-13 18:51:44,112 Epoch[98] Batch [1160]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073218,	
2017-07-13 18:51:50,864 Epoch[98] Batch [1170]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073175,	
2017-07-13 18:51:57,581 Epoch[98] Batch [1180]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073124,	
2017-07-13 18:52:04,493 Epoch[98] Batch [1190]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.073058,	
2017-07-13 18:52:11,042 Epoch[98] Batch [1200]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.073117,	
2017-07-13 18:52:17,792 Epoch[98] Batch [1210]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073148,	
2017-07-13 18:52:24,482 Epoch[98] Batch [1220]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073141,	
2017-07-13 18:52:31,215 Epoch[98] Batch [1230]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073116,	
2017-07-13 18:52:37,967 Epoch[98] Batch [1240]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073093,	
2017-07-13 18:52:44,714 Epoch[98] Batch [1250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073081,	
2017-07-13 18:52:51,399 Epoch[98] Batch [1260]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073094,	
2017-07-13 18:52:58,242 Epoch[98] Batch [1270]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.073104,	
2017-07-13 18:53:04,780 Epoch[98] Batch [1280]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073092,	
2017-07-13 18:53:11,543 Epoch[98] Batch [1290]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073116,	
2017-07-13 18:53:18,301 Epoch[98] Batch [1300]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073069,	
2017-07-13 18:53:25,061 Epoch[98] Batch [1310]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073068,	
2017-07-13 18:53:31,714 Epoch[98] Batch [1320]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073123,	
2017-07-13 18:53:38,489 Epoch[98] Batch [1330]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073133,	
2017-07-13 18:53:45,279 Epoch[98] Batch [1340]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073107,	
2017-07-13 18:53:52,023 Epoch[98] Batch [1350]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073094,	
2017-07-13 18:53:58,795 Epoch[98] Batch [1360]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073112,	
2017-07-13 18:54:05,528 Epoch[98] Batch [1370]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073146,	
2017-07-13 18:54:12,324 Epoch[98] Batch [1380]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073118,	
2017-07-13 18:54:19,046 Epoch[98] Batch [1390]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073130,	
2017-07-13 18:54:25,766 Epoch[98] Batch [1400]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073159,	
2017-07-13 18:54:32,573 Epoch[98] Batch [1410]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073164,	
2017-07-13 18:54:39,277 Epoch[98] Batch [1420]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073158,	
2017-07-13 18:54:45,946 Epoch[98] Batch [1430]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073160,	
2017-07-13 18:54:52,718 Epoch[98] Batch [1440]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073160,	
2017-07-13 18:54:59,409 Epoch[98] Batch [1450]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073114,	
2017-07-13 18:55:05,977 Epoch[98] Batch [1460]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.073185,	
2017-07-13 18:55:12,717 Epoch[98] Batch [1470]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073144,	
2017-07-13 18:55:19,457 Epoch[98] Batch [1480]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073164,	
2017-07-13 18:55:23,569 Epoch[98] Train-FCNLogLoss=0.073140
2017-07-13 18:55:23,569 Epoch[98] Time cost=1002.059
2017-07-13 18:55:24,471 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0099.params"
2017-07-13 18:55:29,062 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0099.states"
2017-07-13 18:55:36,801 Epoch[99] Batch [10]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.067172,	
2017-07-13 18:55:43,400 Epoch[99] Batch [20]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.069229,	
2017-07-13 18:55:50,152 Epoch[99] Batch [30]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.070220,	
2017-07-13 18:55:56,917 Epoch[99] Batch [40]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.070096,	
2017-07-13 18:56:03,640 Epoch[99] Batch [50]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.070529,	
2017-07-13 18:56:10,351 Epoch[99] Batch [60]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.071248,	
2017-07-13 18:56:17,071 Epoch[99] Batch [70]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.071918,	
2017-07-13 18:56:23,782 Epoch[99] Batch [80]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072220,	
2017-07-13 18:56:30,499 Epoch[99] Batch [90]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072212,	
2017-07-13 18:56:37,197 Epoch[99] Batch [100]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072340,	
2017-07-13 18:56:43,967 Epoch[99] Batch [110]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072838,	
2017-07-13 18:56:50,697 Epoch[99] Batch [120]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072508,	
2017-07-13 18:56:57,425 Epoch[99] Batch [130]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072567,	
2017-07-13 18:57:04,184 Epoch[99] Batch [140]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072941,	
2017-07-13 18:57:10,403 Epoch[99] Batch [150]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.073098,	
2017-07-13 18:57:17,247 Epoch[99] Batch [160]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.073530,	
2017-07-13 18:57:23,967 Epoch[99] Batch [170]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073403,	
2017-07-13 18:57:30,739 Epoch[99] Batch [180]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073195,	
2017-07-13 18:57:37,469 Epoch[99] Batch [190]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073430,	
2017-07-13 18:57:44,237 Epoch[99] Batch [200]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073604,	
2017-07-13 18:57:50,998 Epoch[99] Batch [210]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073488,	
2017-07-13 18:57:57,730 Epoch[99] Batch [220]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073539,	
2017-07-13 18:58:04,458 Epoch[99] Batch [230]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073561,	
2017-07-13 18:58:11,181 Epoch[99] Batch [240]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.074058,	
2017-07-13 18:58:17,842 Epoch[99] Batch [250]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.074322,	
2017-07-13 18:58:24,479 Epoch[99] Batch [260]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.074129,	
2017-07-13 18:58:31,161 Epoch[99] Batch [270]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073884,	
2017-07-13 18:58:37,857 Epoch[99] Batch [280]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073728,	
2017-07-13 18:58:44,647 Epoch[99] Batch [290]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073865,	
2017-07-13 18:58:51,314 Epoch[99] Batch [300]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.074113,	
2017-07-13 18:58:58,010 Epoch[99] Batch [310]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073869,	
2017-07-13 18:59:05,279 Epoch[99] Batch [320]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.073804,	
2017-07-13 18:59:12,092 Epoch[99] Batch [330]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073834,	
2017-07-13 18:59:18,854 Epoch[99] Batch [340]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073616,	
2017-07-13 18:59:25,653 Epoch[99] Batch [350]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073480,	
2017-07-13 18:59:32,338 Epoch[99] Batch [360]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073447,	
2017-07-13 18:59:39,024 Epoch[99] Batch [370]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073392,	
2017-07-13 18:59:45,810 Epoch[99] Batch [380]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073484,	
2017-07-13 18:59:52,508 Epoch[99] Batch [390]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073458,	
2017-07-13 18:59:59,277 Epoch[99] Batch [400]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073307,	
2017-07-13 19:00:05,981 Epoch[99] Batch [410]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073347,	
2017-07-13 19:00:12,712 Epoch[99] Batch [420]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073384,	
2017-07-13 19:00:19,479 Epoch[99] Batch [430]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073470,	
2017-07-13 19:00:26,200 Epoch[99] Batch [440]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073394,	
2017-07-13 19:00:32,920 Epoch[99] Batch [450]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073518,	
2017-07-13 19:00:39,680 Epoch[99] Batch [460]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073366,	
2017-07-13 19:00:46,398 Epoch[99] Batch [470]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073438,	
2017-07-13 19:00:53,129 Epoch[99] Batch [480]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073340,	
2017-07-13 19:00:59,843 Epoch[99] Batch [490]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073341,	
2017-07-13 19:01:06,617 Epoch[99] Batch [500]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073185,	
2017-07-13 19:01:13,342 Epoch[99] Batch [510]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073169,	
2017-07-13 19:01:20,041 Epoch[99] Batch [520]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073227,	
2017-07-13 19:01:26,889 Epoch[99] Batch [530]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.073210,	
2017-07-13 19:01:33,591 Epoch[99] Batch [540]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073239,	
2017-07-13 19:01:40,380 Epoch[99] Batch [550]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073204,	
2017-07-13 19:01:47,262 Epoch[99] Batch [560]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.073228,	
2017-07-13 19:01:54,065 Epoch[99] Batch [570]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073044,	
2017-07-13 19:02:00,999 Epoch[99] Batch [580]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.073043,	
2017-07-13 19:02:07,650 Epoch[99] Batch [590]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073100,	
2017-07-13 19:02:14,483 Epoch[99] Batch [600]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.073148,	
2017-07-13 19:02:21,198 Epoch[99] Batch [610]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073106,	
2017-07-13 19:02:27,968 Epoch[99] Batch [620]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073171,	
2017-07-13 19:02:34,723 Epoch[99] Batch [630]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073236,	
2017-07-13 19:02:41,523 Epoch[99] Batch [640]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073272,	
2017-07-13 19:02:48,247 Epoch[99] Batch [650]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073299,	
2017-07-13 19:02:54,895 Epoch[99] Batch [660]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073235,	
2017-07-13 19:03:01,707 Epoch[99] Batch [670]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073273,	
2017-07-13 19:03:08,408 Epoch[99] Batch [680]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073267,	
2017-07-13 19:03:15,046 Epoch[99] Batch [690]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073321,	
2017-07-13 19:03:21,816 Epoch[99] Batch [700]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073345,	
2017-07-13 19:03:28,893 Epoch[99] Batch [710]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.073440,	
2017-07-13 19:03:36,026 Epoch[99] Batch [720]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.073331,	
2017-07-13 19:03:42,777 Epoch[99] Batch [730]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073341,	
2017-07-13 19:03:50,002 Epoch[99] Batch [740]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.073315,	
2017-07-13 19:03:57,070 Epoch[99] Batch [750]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.073311,	
2017-07-13 19:04:04,167 Epoch[99] Batch [760]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.073345,	
2017-07-13 19:04:10,963 Epoch[99] Batch [770]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073300,	
2017-07-13 19:04:18,393 Epoch[99] Batch [780]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.073330,	
2017-07-13 19:04:25,935 Epoch[99] Batch [790]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.073320,	
2017-07-13 19:04:32,870 Epoch[99] Batch [800]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.073312,	
2017-07-13 19:04:39,623 Epoch[99] Batch [810]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073348,	
2017-07-13 19:04:46,383 Epoch[99] Batch [820]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073311,	
2017-07-13 19:04:53,511 Epoch[99] Batch [830]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.073263,	
2017-07-13 19:05:00,160 Epoch[99] Batch [840]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073256,	
2017-07-13 19:05:06,928 Epoch[99] Batch [850]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073199,	
2017-07-13 19:05:13,665 Epoch[99] Batch [860]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073168,	
2017-07-13 19:05:20,594 Epoch[99] Batch [870]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.073047,	
2017-07-13 19:05:27,536 Epoch[99] Batch [880]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.073010,	
2017-07-13 19:05:34,311 Epoch[99] Batch [890]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072974,	
2017-07-13 19:05:40,970 Epoch[99] Batch [900]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072993,	
2017-07-13 19:05:47,744 Epoch[99] Batch [910]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073019,	
2017-07-13 19:05:54,390 Epoch[99] Batch [920]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073056,	
2017-07-13 19:06:01,270 Epoch[99] Batch [930]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.072985,	
2017-07-13 19:06:07,940 Epoch[99] Batch [940]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072877,	
2017-07-13 19:06:14,628 Epoch[99] Batch [950]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072908,	
2017-07-13 19:06:21,334 Epoch[99] Batch [960]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072921,	
2017-07-13 19:06:28,270 Epoch[99] Batch [970]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.072874,	
2017-07-13 19:06:34,940 Epoch[99] Batch [980]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072926,	
2017-07-13 19:06:41,598 Epoch[99] Batch [990]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072864,	
2017-07-13 19:06:48,317 Epoch[99] Batch [1000]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072836,	
2017-07-13 19:06:55,471 Epoch[99] Batch [1010]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.072859,	
2017-07-13 19:07:02,691 Epoch[99] Batch [1020]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.072844,	
2017-07-13 19:07:09,597 Epoch[99] Batch [1030]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.072804,	
2017-07-13 19:07:16,342 Epoch[99] Batch [1040]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072885,	
2017-07-13 19:07:23,279 Epoch[99] Batch [1050]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.072880,	
2017-07-13 19:07:30,156 Epoch[99] Batch [1060]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.072810,	
2017-07-13 19:07:37,092 Epoch[99] Batch [1070]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.072806,	
2017-07-13 19:07:43,881 Epoch[99] Batch [1080]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072758,	
2017-07-13 19:07:51,113 Epoch[99] Batch [1090]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.072717,	
2017-07-13 19:07:58,396 Epoch[99] Batch [1100]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.072713,	
2017-07-13 19:08:06,046 Epoch[99] Batch [1110]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.072740,	
2017-07-13 19:08:13,597 Epoch[99] Batch [1120]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.072698,	
2017-07-13 19:08:21,270 Epoch[99] Batch [1130]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.072710,	
2017-07-13 19:08:29,770 Epoch[99] Batch [1140]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.072691,	
2017-07-13 19:08:37,522 Epoch[99] Batch [1150]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.072643,	
2017-07-13 19:08:45,797 Epoch[99] Batch [1160]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.072610,	
2017-07-13 19:08:53,627 Epoch[99] Batch [1170]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.072668,	
2017-07-13 19:09:01,927 Epoch[99] Batch [1180]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.072633,	
2017-07-13 19:09:10,244 Epoch[99] Batch [1190]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.072672,	
2017-07-13 19:09:18,474 Epoch[99] Batch [1200]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.072682,	
2017-07-13 19:09:27,031 Epoch[99] Batch [1210]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.072785,	
2017-07-13 19:09:34,644 Epoch[99] Batch [1220]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.072770,	
2017-07-13 19:09:42,898 Epoch[99] Batch [1230]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.072727,	
2017-07-13 19:09:50,752 Epoch[99] Batch [1240]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.072740,	
2017-07-13 19:09:59,401 Epoch[99] Batch [1250]	Speed: 4.63 samples/sec	Train-FCNLogLoss=0.072691,	
2017-07-13 19:10:07,781 Epoch[99] Batch [1260]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.072738,	
2017-07-13 19:10:16,365 Epoch[99] Batch [1270]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.072637,	
2017-07-13 19:10:25,688 Epoch[99] Batch [1280]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.072635,	
2017-07-13 19:10:33,154 Epoch[99] Batch [1290]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.072714,	
2017-07-13 19:10:40,759 Epoch[99] Batch [1300]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.072692,	
2017-07-13 19:10:48,259 Epoch[99] Batch [1310]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.072693,	
2017-07-13 19:10:55,660 Epoch[99] Batch [1320]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.072738,	
2017-07-13 19:11:02,712 Epoch[99] Batch [1330]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.072784,	
2017-07-13 19:11:10,279 Epoch[99] Batch [1340]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.072767,	
2017-07-13 19:11:17,836 Epoch[99] Batch [1350]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.072761,	
2017-07-13 19:11:25,789 Epoch[99] Batch [1360]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.072761,	
2017-07-13 19:11:33,763 Epoch[99] Batch [1370]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.072762,	
2017-07-13 19:11:41,171 Epoch[99] Batch [1380]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.072751,	
2017-07-13 19:11:49,411 Epoch[99] Batch [1390]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.072753,	
2017-07-13 19:11:57,752 Epoch[99] Batch [1400]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.072705,	
2017-07-13 19:12:05,854 Epoch[99] Batch [1410]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.072760,	
2017-07-13 19:12:14,252 Epoch[99] Batch [1420]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.072753,	
2017-07-13 19:12:22,742 Epoch[99] Batch [1430]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.072737,	
2017-07-13 19:12:30,973 Epoch[99] Batch [1440]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.072797,	
2017-07-13 19:12:39,440 Epoch[99] Batch [1450]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.072807,	
2017-07-13 19:12:47,505 Epoch[99] Batch [1460]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.072808,	
2017-07-13 19:12:56,403 Epoch[99] Batch [1470]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.072813,	
2017-07-13 19:13:04,515 Epoch[99] Batch [1480]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.072793,	
2017-07-13 19:13:09,696 Epoch[99] Train-FCNLogLoss=0.072788
2017-07-13 19:13:09,696 Epoch[99] Time cost=1060.634
2017-07-13 19:13:10,701 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0100.params"
2017-07-13 19:13:15,192 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0100.states"
2017-07-13 19:13:23,334 Epoch[100] Batch [10]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.071730,	
2017-07-13 19:13:31,125 Epoch[100] Batch [20]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.069959,	
2017-07-13 19:13:38,874 Epoch[100] Batch [30]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.068137,	
2017-07-13 19:13:46,036 Epoch[100] Batch [40]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.067968,	
2017-07-13 19:13:53,185 Epoch[100] Batch [50]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.069072,	
2017-07-13 19:13:59,890 Epoch[100] Batch [60]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.070037,	
2017-07-13 19:14:06,724 Epoch[100] Batch [70]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.069877,	
2017-07-13 19:14:13,486 Epoch[100] Batch [80]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.071052,	
2017-07-13 19:14:19,900 Epoch[100] Batch [90]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.071587,	
2017-07-13 19:14:26,905 Epoch[100] Batch [100]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.071254,	
2017-07-13 19:14:33,520 Epoch[100] Batch [110]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072043,	
2017-07-13 19:14:40,251 Epoch[100] Batch [120]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072481,	
2017-07-13 19:14:46,948 Epoch[100] Batch [130]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072383,	
2017-07-13 19:14:53,695 Epoch[100] Batch [140]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.071921,	
2017-07-13 19:15:00,707 Epoch[100] Batch [150]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.072232,	
2017-07-13 19:15:07,401 Epoch[100] Batch [160]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072425,	
2017-07-13 19:15:14,246 Epoch[100] Batch [170]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.072950,	
2017-07-13 19:15:20,970 Epoch[100] Batch [180]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073092,	
2017-07-13 19:15:27,746 Epoch[100] Batch [190]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073009,	
2017-07-13 19:15:34,496 Epoch[100] Batch [200]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073088,	
2017-07-13 19:15:41,243 Epoch[100] Batch [210]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073574,	
2017-07-13 19:15:48,240 Epoch[100] Batch [220]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.073350,	
2017-07-13 19:15:54,801 Epoch[100] Batch [230]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.073034,	
2017-07-13 19:16:01,546 Epoch[100] Batch [240]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073003,	
2017-07-13 19:16:08,316 Epoch[100] Batch [250]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072916,	
2017-07-13 19:16:15,048 Epoch[100] Batch [260]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072883,	
2017-07-13 19:16:21,782 Epoch[100] Batch [270]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072789,	
2017-07-13 19:16:28,552 Epoch[100] Batch [280]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072950,	
2017-07-13 19:16:35,296 Epoch[100] Batch [290]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073001,	
2017-07-13 19:16:42,073 Epoch[100] Batch [300]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072852,	
2017-07-13 19:16:48,806 Epoch[100] Batch [310]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072710,	
2017-07-13 19:16:55,565 Epoch[100] Batch [320]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072687,	
2017-07-13 19:17:02,270 Epoch[100] Batch [330]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072971,	
2017-07-13 19:17:09,024 Epoch[100] Batch [340]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072806,	
2017-07-13 19:17:15,749 Epoch[100] Batch [350]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072965,	
2017-07-13 19:17:22,526 Epoch[100] Batch [360]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073078,	
2017-07-13 19:17:29,216 Epoch[100] Batch [370]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073026,	
2017-07-13 19:17:35,974 Epoch[100] Batch [380]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073078,	
2017-07-13 19:17:42,728 Epoch[100] Batch [390]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072996,	
2017-07-13 19:17:49,431 Epoch[100] Batch [400]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073031,	
2017-07-13 19:17:56,182 Epoch[100] Batch [410]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073009,	
2017-07-13 19:18:02,934 Epoch[100] Batch [420]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072900,	
2017-07-13 19:18:09,646 Epoch[100] Batch [430]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072931,	
2017-07-13 19:18:16,420 Epoch[100] Batch [440]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072966,	
2017-07-13 19:18:23,114 Epoch[100] Batch [450]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072979,	
2017-07-13 19:18:29,776 Epoch[100] Batch [460]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072979,	
2017-07-13 19:18:36,517 Epoch[100] Batch [470]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073097,	
2017-07-13 19:18:43,292 Epoch[100] Batch [480]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072911,	
2017-07-13 19:18:49,986 Epoch[100] Batch [490]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072811,	
2017-07-13 19:18:56,814 Epoch[100] Batch [500]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072813,	
2017-07-13 19:19:03,473 Epoch[100] Batch [510]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072831,	
2017-07-13 19:19:10,199 Epoch[100] Batch [520]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072785,	
2017-07-13 19:19:16,921 Epoch[100] Batch [530]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072822,	
2017-07-13 19:19:23,678 Epoch[100] Batch [540]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072850,	
2017-07-13 19:19:30,449 Epoch[100] Batch [550]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072713,	
2017-07-13 19:19:37,158 Epoch[100] Batch [560]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072755,	
2017-07-13 19:19:43,910 Epoch[100] Batch [570]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072901,	
2017-07-13 19:19:50,662 Epoch[100] Batch [580]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072919,	
2017-07-13 19:19:57,447 Epoch[100] Batch [590]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072952,	
2017-07-13 19:20:04,339 Epoch[100] Batch [600]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.072917,	
2017-07-13 19:20:11,053 Epoch[100] Batch [610]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072810,	
2017-07-13 19:20:17,835 Epoch[100] Batch [620]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072613,	
2017-07-13 19:20:24,502 Epoch[100] Batch [630]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072519,	
2017-07-13 19:20:31,233 Epoch[100] Batch [640]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072539,	
2017-07-13 19:20:37,948 Epoch[100] Batch [650]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072489,	
2017-07-13 19:20:44,648 Epoch[100] Batch [660]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072521,	
2017-07-13 19:20:51,382 Epoch[100] Batch [670]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072613,	
2017-07-13 19:20:58,088 Epoch[100] Batch [680]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072531,	
2017-07-13 19:21:04,754 Epoch[100] Batch [690]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072489,	
2017-07-13 19:21:11,578 Epoch[100] Batch [700]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072430,	
2017-07-13 19:21:18,419 Epoch[100] Batch [710]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.072355,	
2017-07-13 19:21:25,121 Epoch[100] Batch [720]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072340,	
2017-07-13 19:21:31,893 Epoch[100] Batch [730]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072368,	
2017-07-13 19:21:38,645 Epoch[100] Batch [740]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072426,	
2017-07-13 19:21:45,339 Epoch[100] Batch [750]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072366,	
2017-07-13 19:21:51,976 Epoch[100] Batch [760]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072306,	
2017-07-13 19:21:58,820 Epoch[100] Batch [770]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.072360,	
2017-07-13 19:22:05,460 Epoch[100] Batch [780]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.072379,	
2017-07-13 19:22:12,219 Epoch[100] Batch [790]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072364,	
2017-07-13 19:22:18,896 Epoch[100] Batch [800]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072415,	
2017-07-13 19:22:25,626 Epoch[100] Batch [810]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072344,	
2017-07-13 19:22:32,327 Epoch[100] Batch [820]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072343,	
2017-07-13 19:22:39,076 Epoch[100] Batch [830]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072315,	
2017-07-13 19:22:45,798 Epoch[100] Batch [840]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072280,	
2017-07-13 19:22:52,532 Epoch[100] Batch [850]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072387,	
2017-07-13 19:22:59,240 Epoch[100] Batch [860]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072381,	
2017-07-13 19:23:05,976 Epoch[100] Batch [870]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072390,	
2017-07-13 19:23:12,643 Epoch[100] Batch [880]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072375,	
2017-07-13 19:23:19,351 Epoch[100] Batch [890]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072428,	
2017-07-13 19:23:26,057 Epoch[100] Batch [900]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072451,	
2017-07-13 19:23:32,806 Epoch[100] Batch [910]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072425,	
2017-07-13 19:23:39,503 Epoch[100] Batch [920]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072435,	
2017-07-13 19:23:46,293 Epoch[100] Batch [930]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072459,	
2017-07-13 19:23:52,955 Epoch[100] Batch [940]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072585,	
2017-07-13 19:23:59,639 Epoch[100] Batch [950]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072629,	
2017-07-13 19:24:06,367 Epoch[100] Batch [960]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072635,	
2017-07-13 19:24:13,100 Epoch[100] Batch [970]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072631,	
2017-07-13 19:24:19,843 Epoch[100] Batch [980]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072670,	
2017-07-13 19:24:26,592 Epoch[100] Batch [990]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072727,	
2017-07-13 19:24:33,251 Epoch[100] Batch [1000]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072768,	
2017-07-13 19:24:40,033 Epoch[100] Batch [1010]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072722,	
2017-07-13 19:24:46,697 Epoch[100] Batch [1020]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072823,	
2017-07-13 19:24:53,404 Epoch[100] Batch [1030]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072803,	
2017-07-13 19:25:00,122 Epoch[100] Batch [1040]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072800,	
2017-07-13 19:25:06,879 Epoch[100] Batch [1050]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072746,	
2017-07-13 19:25:13,580 Epoch[100] Batch [1060]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072736,	
2017-07-13 19:25:20,380 Epoch[100] Batch [1070]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.072658,	
2017-07-13 19:25:27,091 Epoch[100] Batch [1080]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072648,	
2017-07-13 19:25:33,824 Epoch[100] Batch [1090]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072634,	
2017-07-13 19:25:40,491 Epoch[100] Batch [1100]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072593,	
2017-07-13 19:25:47,142 Epoch[100] Batch [1110]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072557,	
2017-07-13 19:25:53,884 Epoch[100] Batch [1120]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072637,	
2017-07-13 19:26:00,563 Epoch[100] Batch [1130]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072713,	
2017-07-13 19:26:07,300 Epoch[100] Batch [1140]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072759,	
2017-07-13 19:26:14,019 Epoch[100] Batch [1150]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072793,	
2017-07-13 19:26:20,762 Epoch[100] Batch [1160]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072793,	
2017-07-13 19:26:27,473 Epoch[100] Batch [1170]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072798,	
2017-07-13 19:26:34,181 Epoch[100] Batch [1180]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072824,	
2017-07-13 19:26:40,871 Epoch[100] Batch [1190]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072790,	
2017-07-13 19:26:47,587 Epoch[100] Batch [1200]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072749,	
2017-07-13 19:26:54,314 Epoch[100] Batch [1210]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072700,	
2017-07-13 19:27:01,045 Epoch[100] Batch [1220]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072693,	
2017-07-13 19:27:07,792 Epoch[100] Batch [1230]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072646,	
2017-07-13 19:27:14,499 Epoch[100] Batch [1240]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072660,	
2017-07-13 19:27:21,247 Epoch[100] Batch [1250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072661,	
2017-07-13 19:27:28,016 Epoch[100] Batch [1260]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072676,	
2017-07-13 19:27:34,693 Epoch[100] Batch [1270]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072682,	
2017-07-13 19:27:41,385 Epoch[100] Batch [1280]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072718,	
2017-07-13 19:27:48,012 Epoch[100] Batch [1290]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.072702,	
2017-07-13 19:27:54,685 Epoch[100] Batch [1300]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072677,	
2017-07-13 19:28:01,392 Epoch[100] Batch [1310]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072684,	
2017-07-13 19:28:08,131 Epoch[100] Batch [1320]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072702,	
2017-07-13 19:28:14,823 Epoch[100] Batch [1330]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072705,	
2017-07-13 19:28:21,545 Epoch[100] Batch [1340]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072726,	
2017-07-13 19:28:28,252 Epoch[100] Batch [1350]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072685,	
2017-07-13 19:28:35,006 Epoch[100] Batch [1360]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072632,	
2017-07-13 19:28:41,712 Epoch[100] Batch [1370]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072614,	
2017-07-13 19:28:48,475 Epoch[100] Batch [1380]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072646,	
2017-07-13 19:28:55,151 Epoch[100] Batch [1390]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072587,	
2017-07-13 19:29:01,908 Epoch[100] Batch [1400]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072626,	
2017-07-13 19:29:08,617 Epoch[100] Batch [1410]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072653,	
2017-07-13 19:29:15,311 Epoch[100] Batch [1420]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072680,	
2017-07-13 19:29:22,084 Epoch[100] Batch [1430]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072664,	
2017-07-13 19:29:28,737 Epoch[100] Batch [1440]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072578,	
2017-07-13 19:29:35,289 Epoch[100] Batch [1450]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.072589,	
2017-07-13 19:29:42,062 Epoch[100] Batch [1460]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072588,	
2017-07-13 19:29:48,598 Epoch[100] Batch [1470]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.072621,	
2017-07-13 19:29:55,257 Epoch[100] Batch [1480]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072645,	
2017-07-13 19:29:59,248 Epoch[100] Train-FCNLogLoss=0.072657
2017-07-13 19:29:59,248 Epoch[100] Time cost=1004.056
2017-07-13 19:30:00,047 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0101.params"
2017-07-13 19:30:04,009 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0101.states"
2017-07-13 19:30:11,523 Epoch[101] Batch [10]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.076213,	
2017-07-13 19:30:18,177 Epoch[101] Batch [20]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.074885,	
2017-07-13 19:30:25,015 Epoch[101] Batch [30]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.074349,	
2017-07-13 19:30:31,739 Epoch[101] Batch [40]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073535,	
2017-07-13 19:30:38,359 Epoch[101] Batch [50]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.074937,	
2017-07-13 19:30:45,007 Epoch[101] Batch [60]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.074280,	
2017-07-13 19:30:51,724 Epoch[101] Batch [70]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073317,	
2017-07-13 19:30:58,445 Epoch[101] Batch [80]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073462,	
2017-07-13 19:31:04,102 Epoch[101] Batch [90]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.073042,	
2017-07-13 19:31:10,748 Epoch[101] Batch [100]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.072789,	
2017-07-13 19:31:17,404 Epoch[101] Batch [110]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073137,	
2017-07-13 19:31:24,136 Epoch[101] Batch [120]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073093,	
2017-07-13 19:31:30,842 Epoch[101] Batch [130]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073283,	
2017-07-13 19:31:37,564 Epoch[101] Batch [140]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073766,	
2017-07-13 19:31:44,313 Epoch[101] Batch [150]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073580,	
2017-07-13 19:31:51,045 Epoch[101] Batch [160]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073430,	
2017-07-13 19:31:57,659 Epoch[101] Batch [170]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.073215,	
2017-07-13 19:32:04,277 Epoch[101] Batch [180]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.073209,	
2017-07-13 19:32:10,948 Epoch[101] Batch [190]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073431,	
2017-07-13 19:32:17,684 Epoch[101] Batch [200]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073597,	
2017-07-13 19:32:24,441 Epoch[101] Batch [210]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073855,	
2017-07-13 19:32:31,172 Epoch[101] Batch [220]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.074086,	
2017-07-13 19:32:37,854 Epoch[101] Batch [230]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073900,	
2017-07-13 19:32:44,577 Epoch[101] Batch [240]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073935,	
2017-07-13 19:32:51,262 Epoch[101] Batch [250]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.074011,	
2017-07-13 19:32:58,014 Epoch[101] Batch [260]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.074025,	
2017-07-13 19:33:04,759 Epoch[101] Batch [270]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073795,	
2017-07-13 19:33:11,583 Epoch[101] Batch [280]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.074051,	
2017-07-13 19:33:18,179 Epoch[101] Batch [290]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.073937,	
2017-07-13 19:33:24,911 Epoch[101] Batch [300]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073895,	
2017-07-13 19:33:31,593 Epoch[101] Batch [310]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073997,	
2017-07-13 19:33:38,329 Epoch[101] Batch [320]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073925,	
2017-07-13 19:33:45,023 Epoch[101] Batch [330]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.074179,	
2017-07-13 19:33:51,518 Epoch[101] Batch [340]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.074094,	
2017-07-13 19:33:58,212 Epoch[101] Batch [350]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073931,	
2017-07-13 19:34:04,939 Epoch[101] Batch [360]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073965,	
2017-07-13 19:34:11,663 Epoch[101] Batch [370]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.074198,	
2017-07-13 19:34:18,387 Epoch[101] Batch [380]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.074183,	
2017-07-13 19:34:25,062 Epoch[101] Batch [390]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.074154,	
2017-07-13 19:34:31,891 Epoch[101] Batch [400]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.074049,	
2017-07-13 19:34:38,524 Epoch[101] Batch [410]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073890,	
2017-07-13 19:34:45,216 Epoch[101] Batch [420]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073910,	
2017-07-13 19:34:51,819 Epoch[101] Batch [430]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.073931,	
2017-07-13 19:34:58,573 Epoch[101] Batch [440]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.074030,	
2017-07-13 19:35:05,284 Epoch[101] Batch [450]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073901,	
2017-07-13 19:35:11,821 Epoch[101] Batch [460]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073716,	
2017-07-13 19:35:18,415 Epoch[101] Batch [470]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.073791,	
2017-07-13 19:35:25,227 Epoch[101] Batch [480]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073620,	
2017-07-13 19:35:31,617 Epoch[101] Batch [490]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.073713,	
2017-07-13 19:35:38,288 Epoch[101] Batch [500]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073741,	
2017-07-13 19:35:44,967 Epoch[101] Batch [510]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073671,	
2017-07-13 19:35:51,767 Epoch[101] Batch [520]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073600,	
2017-07-13 19:35:58,428 Epoch[101] Batch [530]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073605,	
2017-07-13 19:36:05,181 Epoch[101] Batch [540]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073516,	
2017-07-13 19:36:11,882 Epoch[101] Batch [550]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073641,	
2017-07-13 19:36:18,409 Epoch[101] Batch [560]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.073639,	
2017-07-13 19:36:25,113 Epoch[101] Batch [570]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073581,	
2017-07-13 19:36:31,772 Epoch[101] Batch [580]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073643,	
2017-07-13 19:36:38,515 Epoch[101] Batch [590]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073615,	
2017-07-13 19:36:45,242 Epoch[101] Batch [600]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073655,	
2017-07-13 19:36:52,002 Epoch[101] Batch [610]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073710,	
2017-07-13 19:36:58,718 Epoch[101] Batch [620]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073691,	
2017-07-13 19:37:05,402 Epoch[101] Batch [630]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073618,	
2017-07-13 19:37:12,194 Epoch[101] Batch [640]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073528,	
2017-07-13 19:37:18,844 Epoch[101] Batch [650]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073527,	
2017-07-13 19:37:25,546 Epoch[101] Batch [660]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073519,	
2017-07-13 19:37:32,269 Epoch[101] Batch [670]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073575,	
2017-07-13 19:37:38,974 Epoch[101] Batch [680]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073562,	
2017-07-13 19:37:45,711 Epoch[101] Batch [690]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073544,	
2017-07-13 19:37:52,387 Epoch[101] Batch [700]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073508,	
2017-07-13 19:37:59,042 Epoch[101] Batch [710]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.073578,	
2017-07-13 19:38:05,810 Epoch[101] Batch [720]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073579,	
2017-07-13 19:38:12,443 Epoch[101] Batch [730]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073657,	
2017-07-13 19:38:19,119 Epoch[101] Batch [740]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073554,	
2017-07-13 19:38:25,943 Epoch[101] Batch [750]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073539,	
2017-07-13 19:38:32,579 Epoch[101] Batch [760]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073469,	
2017-07-13 19:38:39,328 Epoch[101] Batch [770]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073388,	
2017-07-13 19:38:45,984 Epoch[101] Batch [780]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073394,	
2017-07-13 19:38:52,746 Epoch[101] Batch [790]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073476,	
2017-07-13 19:38:59,507 Epoch[101] Batch [800]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073459,	
2017-07-13 19:39:06,256 Epoch[101] Batch [810]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073413,	
2017-07-13 19:39:12,987 Epoch[101] Batch [820]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073491,	
2017-07-13 19:39:19,721 Epoch[101] Batch [830]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073478,	
2017-07-13 19:39:26,433 Epoch[101] Batch [840]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073456,	
2017-07-13 19:39:33,180 Epoch[101] Batch [850]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073532,	
2017-07-13 19:39:39,962 Epoch[101] Batch [860]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073488,	
2017-07-13 19:39:46,709 Epoch[101] Batch [870]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073505,	
2017-07-13 19:39:53,394 Epoch[101] Batch [880]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073457,	
2017-07-13 19:40:00,088 Epoch[101] Batch [890]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073434,	
2017-07-13 19:40:06,864 Epoch[101] Batch [900]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073488,	
2017-07-13 19:40:13,583 Epoch[101] Batch [910]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073495,	
2017-07-13 19:40:20,233 Epoch[101] Batch [920]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073510,	
2017-07-13 19:40:26,925 Epoch[101] Batch [930]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073654,	
2017-07-13 19:40:33,151 Epoch[101] Batch [940]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.073647,	
2017-07-13 19:40:39,373 Epoch[101] Batch [950]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.073579,	
2017-07-13 19:40:46,050 Epoch[101] Batch [960]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073547,	
2017-07-13 19:40:52,484 Epoch[101] Batch [970]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.073488,	
2017-07-13 19:40:59,163 Epoch[101] Batch [980]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073468,	
2017-07-13 19:41:05,734 Epoch[101] Batch [990]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.073484,	
2017-07-13 19:41:12,464 Epoch[101] Batch [1000]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073501,	
2017-07-13 19:41:19,032 Epoch[101] Batch [1010]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.073401,	
2017-07-13 19:41:25,768 Epoch[101] Batch [1020]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073312,	
2017-07-13 19:41:32,225 Epoch[101] Batch [1030]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.073252,	
2017-07-13 19:41:38,722 Epoch[101] Batch [1040]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.073213,	
2017-07-13 19:41:45,239 Epoch[101] Batch [1050]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073254,	
2017-07-13 19:41:51,851 Epoch[101] Batch [1060]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.073318,	
2017-07-13 19:41:58,500 Epoch[101] Batch [1070]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073295,	
2017-07-13 19:42:05,236 Epoch[101] Batch [1080]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073358,	
2017-07-13 19:42:11,974 Epoch[101] Batch [1090]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073319,	
2017-07-13 19:42:18,705 Epoch[101] Batch [1100]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073262,	
2017-07-13 19:42:25,337 Epoch[101] Batch [1110]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073271,	
2017-07-13 19:42:31,797 Epoch[101] Batch [1120]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.073261,	
2017-07-13 19:42:38,702 Epoch[101] Batch [1130]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.073232,	
2017-07-13 19:42:45,674 Epoch[101] Batch [1140]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.073246,	
2017-07-13 19:42:52,395 Epoch[101] Batch [1150]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073229,	
2017-07-13 19:42:59,030 Epoch[101] Batch [1160]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073211,	
2017-07-13 19:43:05,915 Epoch[101] Batch [1170]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.073225,	
2017-07-13 19:43:12,677 Epoch[101] Batch [1180]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073208,	
2017-07-13 19:43:19,673 Epoch[101] Batch [1190]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.073210,	
2017-07-13 19:43:26,348 Epoch[101] Batch [1200]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073268,	
2017-07-13 19:43:33,055 Epoch[101] Batch [1210]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073281,	
2017-07-13 19:43:39,953 Epoch[101] Batch [1220]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.073248,	
2017-07-13 19:43:46,573 Epoch[101] Batch [1230]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.073247,	
2017-07-13 19:43:53,062 Epoch[101] Batch [1240]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.073210,	
2017-07-13 19:43:59,807 Epoch[101] Batch [1250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073171,	
2017-07-13 19:44:06,507 Epoch[101] Batch [1260]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073211,	
2017-07-13 19:44:13,146 Epoch[101] Batch [1270]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073220,	
2017-07-13 19:44:19,872 Epoch[101] Batch [1280]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073269,	
2017-07-13 19:44:26,416 Epoch[101] Batch [1290]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.073234,	
2017-07-13 19:44:32,742 Epoch[101] Batch [1300]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.073294,	
2017-07-13 19:44:39,358 Epoch[101] Batch [1310]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.073293,	
2017-07-13 19:44:46,091 Epoch[101] Batch [1320]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073263,	
2017-07-13 19:44:52,653 Epoch[101] Batch [1330]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.073263,	
2017-07-13 19:44:59,176 Epoch[101] Batch [1340]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.073283,	
2017-07-13 19:45:05,900 Epoch[101] Batch [1350]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073243,	
2017-07-13 19:45:12,592 Epoch[101] Batch [1360]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.073252,	
2017-07-13 19:45:19,370 Epoch[101] Batch [1370]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073258,	
2017-07-13 19:45:26,372 Epoch[101] Batch [1380]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.073200,	
2017-07-13 19:45:32,790 Epoch[101] Batch [1390]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.073196,	
2017-07-13 19:45:39,387 Epoch[101] Batch [1400]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.073195,	
2017-07-13 19:45:46,313 Epoch[101] Batch [1410]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.073181,	
2017-07-13 19:45:53,422 Epoch[101] Batch [1420]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.073144,	
2017-07-13 19:46:00,118 Epoch[101] Batch [1430]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073172,	
2017-07-13 19:46:07,280 Epoch[101] Batch [1440]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.073161,	
2017-07-13 19:46:14,218 Epoch[101] Batch [1450]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.073174,	
2017-07-13 19:46:21,069 Epoch[101] Batch [1460]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.073188,	
2017-07-13 19:46:27,515 Epoch[101] Batch [1470]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.073117,	
2017-07-13 19:46:34,227 Epoch[101] Batch [1480]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073065,	
2017-07-13 19:46:38,253 Epoch[101] Train-FCNLogLoss=0.073064
2017-07-13 19:46:38,254 Epoch[101] Time cost=994.244
2017-07-13 19:46:39,081 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0102.params"
2017-07-13 19:46:43,038 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0102.states"
2017-07-13 19:46:51,016 Epoch[102] Batch [10]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.072736,	
2017-07-13 19:46:57,755 Epoch[102] Batch [20]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073437,	
2017-07-13 19:47:04,754 Epoch[102] Batch [30]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.072514,	
2017-07-13 19:47:11,566 Epoch[102] Batch [40]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072400,	
2017-07-13 19:47:18,219 Epoch[102] Batch [50]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072902,	
2017-07-13 19:47:24,630 Epoch[102] Batch [60]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.072333,	
2017-07-13 19:47:31,188 Epoch[102] Batch [70]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.072117,	
2017-07-13 19:47:37,766 Epoch[102] Batch [80]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.073074,	
2017-07-13 19:47:44,567 Epoch[102] Batch [90]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073773,	
2017-07-13 19:47:51,485 Epoch[102] Batch [100]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.072954,	
2017-07-13 19:47:58,066 Epoch[102] Batch [110]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.072934,	
2017-07-13 19:48:04,566 Epoch[102] Batch [120]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.073090,	
2017-07-13 19:48:11,526 Epoch[102] Batch [130]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.073209,	
2017-07-13 19:48:18,268 Epoch[102] Batch [140]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073160,	
2017-07-13 19:48:24,932 Epoch[102] Batch [150]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073243,	
2017-07-13 19:48:31,615 Epoch[102] Batch [160]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072672,	
2017-07-13 19:48:38,416 Epoch[102] Batch [170]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.072510,	
2017-07-13 19:48:45,172 Epoch[102] Batch [180]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072113,	
2017-07-13 19:48:51,925 Epoch[102] Batch [190]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.071972,	
2017-07-13 19:48:58,632 Epoch[102] Batch [200]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.071976,	
2017-07-13 19:49:05,427 Epoch[102] Batch [210]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072026,	
2017-07-13 19:49:12,305 Epoch[102] Batch [220]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.071767,	
2017-07-13 19:49:19,031 Epoch[102] Batch [230]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.071689,	
2017-07-13 19:49:25,538 Epoch[102] Batch [240]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.071630,	
2017-07-13 19:49:31,991 Epoch[102] Batch [250]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.071890,	
2017-07-13 19:49:38,501 Epoch[102] Batch [260]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.072105,	
2017-07-13 19:49:45,239 Epoch[102] Batch [270]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072336,	
2017-07-13 19:49:51,912 Epoch[102] Batch [280]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072053,	
2017-07-13 19:49:58,339 Epoch[102] Batch [290]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.072360,	
2017-07-13 19:50:04,746 Epoch[102] Batch [300]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.072359,	
2017-07-13 19:50:11,424 Epoch[102] Batch [310]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072435,	
2017-07-13 19:50:18,127 Epoch[102] Batch [320]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072535,	
2017-07-13 19:50:24,824 Epoch[102] Batch [330]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072444,	
2017-07-13 19:50:31,380 Epoch[102] Batch [340]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.072457,	
2017-07-13 19:50:37,820 Epoch[102] Batch [350]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.072464,	
2017-07-13 19:50:44,233 Epoch[102] Batch [360]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.072456,	
2017-07-13 19:50:50,889 Epoch[102] Batch [370]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072441,	
2017-07-13 19:50:57,542 Epoch[102] Batch [380]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072559,	
2017-07-13 19:51:03,978 Epoch[102] Batch [390]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.072742,	
2017-07-13 19:51:10,746 Epoch[102] Batch [400]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072722,	
2017-07-13 19:51:17,222 Epoch[102] Batch [410]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.072794,	
2017-07-13 19:51:23,573 Epoch[102] Batch [420]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.073044,	
2017-07-13 19:51:30,048 Epoch[102] Batch [430]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.072875,	
2017-07-13 19:51:36,500 Epoch[102] Batch [440]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.072953,	
2017-07-13 19:51:43,164 Epoch[102] Batch [450]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072873,	
2017-07-13 19:51:49,735 Epoch[102] Batch [460]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.072969,	
2017-07-13 19:51:56,408 Epoch[102] Batch [470]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072996,	
2017-07-13 19:52:03,162 Epoch[102] Batch [480]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073031,	
2017-07-13 19:52:09,536 Epoch[102] Batch [490]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.073042,	
2017-07-13 19:52:15,954 Epoch[102] Batch [500]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.073061,	
2017-07-13 19:52:22,451 Epoch[102] Batch [510]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.073006,	
2017-07-13 19:52:28,948 Epoch[102] Batch [520]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.072986,	
2017-07-13 19:52:35,577 Epoch[102] Batch [530]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072882,	
2017-07-13 19:52:42,152 Epoch[102] Batch [540]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.072813,	
2017-07-13 19:52:48,815 Epoch[102] Batch [550]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072825,	
2017-07-13 19:52:55,242 Epoch[102] Batch [560]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.072781,	
2017-07-13 19:53:01,766 Epoch[102] Batch [570]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.072783,	
2017-07-13 19:53:08,242 Epoch[102] Batch [580]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.072863,	
2017-07-13 19:53:15,331 Epoch[102] Batch [590]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.072913,	
2017-07-13 19:53:22,534 Epoch[102] Batch [600]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.073040,	
2017-07-13 19:53:29,258 Epoch[102] Batch [610]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073060,	
2017-07-13 19:53:35,791 Epoch[102] Batch [620]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073128,	
2017-07-13 19:53:42,419 Epoch[102] Batch [630]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.073172,	
2017-07-13 19:53:49,432 Epoch[102] Batch [640]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.073220,	
2017-07-13 19:53:56,026 Epoch[102] Batch [650]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.073248,	
2017-07-13 19:54:02,222 Epoch[102] Batch [660]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.073206,	
2017-07-13 19:54:08,966 Epoch[102] Batch [670]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073243,	
2017-07-13 19:54:15,728 Epoch[102] Batch [680]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073279,	
2017-07-13 19:54:22,085 Epoch[102] Batch [690]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.073248,	
2017-07-13 19:54:29,183 Epoch[102] Batch [700]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.073258,	
2017-07-13 19:54:35,815 Epoch[102] Batch [710]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073250,	
2017-07-13 19:54:42,575 Epoch[102] Batch [720]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073068,	
2017-07-13 19:54:49,400 Epoch[102] Batch [730]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073036,	
2017-07-13 19:54:55,925 Epoch[102] Batch [740]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.072997,	
2017-07-13 19:55:02,587 Epoch[102] Batch [750]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073118,	
2017-07-13 19:55:09,400 Epoch[102] Batch [760]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073035,	
2017-07-13 19:55:16,136 Epoch[102] Batch [770]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072981,	
2017-07-13 19:55:22,587 Epoch[102] Batch [780]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.072892,	
2017-07-13 19:55:29,012 Epoch[102] Batch [790]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.072910,	
2017-07-13 19:55:35,607 Epoch[102] Batch [800]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.072809,	
2017-07-13 19:55:42,279 Epoch[102] Batch [810]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072655,	
2017-07-13 19:55:48,782 Epoch[102] Batch [820]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.072708,	
2017-07-13 19:55:55,292 Epoch[102] Batch [830]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.072680,	
2017-07-13 19:56:02,174 Epoch[102] Batch [840]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.072633,	
2017-07-13 19:56:08,966 Epoch[102] Batch [850]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072577,	
2017-07-13 19:56:16,238 Epoch[102] Batch [860]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.072527,	
2017-07-13 19:56:22,741 Epoch[102] Batch [870]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.072518,	
2017-07-13 19:56:29,701 Epoch[102] Batch [880]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.072540,	
2017-07-13 19:56:36,373 Epoch[102] Batch [890]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072506,	
2017-07-13 19:56:43,402 Epoch[102] Batch [900]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.072593,	
2017-07-13 19:56:50,001 Epoch[102] Batch [910]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072618,	
2017-07-13 19:56:56,720 Epoch[102] Batch [920]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072640,	
2017-07-13 19:57:03,461 Epoch[102] Batch [930]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072590,	
2017-07-13 19:57:10,068 Epoch[102] Batch [940]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072532,	
2017-07-13 19:57:16,668 Epoch[102] Batch [950]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072550,	
2017-07-13 19:57:23,444 Epoch[102] Batch [960]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072513,	
2017-07-13 19:57:30,073 Epoch[102] Batch [970]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072556,	
2017-07-13 19:57:36,833 Epoch[102] Batch [980]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072632,	
2017-07-13 19:57:43,552 Epoch[102] Batch [990]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072676,	
2017-07-13 19:57:50,054 Epoch[102] Batch [1000]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.072683,	
2017-07-13 19:57:56,722 Epoch[102] Batch [1010]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072676,	
2017-07-13 19:58:03,588 Epoch[102] Batch [1020]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.072671,	
2017-07-13 19:58:10,294 Epoch[102] Batch [1030]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072687,	
2017-07-13 19:58:17,086 Epoch[102] Batch [1040]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072678,	
2017-07-13 19:58:23,687 Epoch[102] Batch [1050]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072715,	
2017-07-13 19:58:30,607 Epoch[102] Batch [1060]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.072733,	
2017-07-13 19:58:37,711 Epoch[102] Batch [1070]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.072726,	
2017-07-13 19:58:45,215 Epoch[102] Batch [1080]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.072739,	
2017-07-13 19:58:52,330 Epoch[102] Batch [1090]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.072738,	
2017-07-13 19:58:59,355 Epoch[102] Batch [1100]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.072714,	
2017-07-13 19:59:06,103 Epoch[102] Batch [1110]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072662,	
2017-07-13 19:59:13,034 Epoch[102] Batch [1120]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.072648,	
2017-07-13 19:59:20,375 Epoch[102] Batch [1130]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.072537,	
2017-07-13 19:59:27,443 Epoch[102] Batch [1140]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.072476,	
2017-07-13 19:59:34,290 Epoch[102] Batch [1150]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.072530,	
2017-07-13 19:59:41,118 Epoch[102] Batch [1160]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072500,	
2017-07-13 19:59:48,158 Epoch[102] Batch [1170]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.072489,	
2017-07-13 19:59:55,112 Epoch[102] Batch [1180]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.072565,	
2017-07-13 20:00:02,462 Epoch[102] Batch [1190]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.072604,	
2017-07-13 20:00:09,312 Epoch[102] Batch [1200]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.072667,	
2017-07-13 20:00:16,604 Epoch[102] Batch [1210]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.072638,	
2017-07-13 20:00:23,481 Epoch[102] Batch [1220]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.072647,	
2017-07-13 20:00:31,200 Epoch[102] Batch [1230]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.072679,	
2017-07-13 20:00:38,205 Epoch[102] Batch [1240]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.072752,	
2017-07-13 20:00:45,079 Epoch[102] Batch [1250]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.072763,	
2017-07-13 20:00:52,455 Epoch[102] Batch [1260]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.072774,	
2017-07-13 20:00:59,463 Epoch[102] Batch [1270]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.072754,	
2017-07-13 20:01:06,601 Epoch[102] Batch [1280]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.072726,	
2017-07-13 20:01:13,656 Epoch[102] Batch [1290]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.072696,	
2017-07-13 20:01:20,561 Epoch[102] Batch [1300]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.072648,	
2017-07-13 20:01:27,880 Epoch[102] Batch [1310]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.072657,	
2017-07-13 20:01:34,680 Epoch[102] Batch [1320]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.072654,	
2017-07-13 20:01:41,991 Epoch[102] Batch [1330]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.072609,	
2017-07-13 20:01:48,743 Epoch[102] Batch [1340]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072628,	
2017-07-13 20:01:55,352 Epoch[102] Batch [1350]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072612,	
2017-07-13 20:02:02,278 Epoch[102] Batch [1360]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.072612,	
2017-07-13 20:02:08,763 Epoch[102] Batch [1370]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.072661,	
2017-07-13 20:02:15,747 Epoch[102] Batch [1380]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.072699,	
2017-07-13 20:02:22,554 Epoch[102] Batch [1390]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.072673,	
2017-07-13 20:02:29,578 Epoch[102] Batch [1400]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.072686,	
2017-07-13 20:02:36,749 Epoch[102] Batch [1410]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.072696,	
2017-07-13 20:02:43,995 Epoch[102] Batch [1420]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.072706,	
2017-07-13 20:02:50,964 Epoch[102] Batch [1430]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.072715,	
2017-07-13 20:02:57,432 Epoch[102] Batch [1440]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.072733,	
2017-07-13 20:03:04,314 Epoch[102] Batch [1450]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.072740,	
2017-07-13 20:03:11,124 Epoch[102] Batch [1460]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072754,	
2017-07-13 20:03:17,836 Epoch[102] Batch [1470]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072799,	
2017-07-13 20:03:24,765 Epoch[102] Batch [1480]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.072757,	
2017-07-13 20:03:28,801 Epoch[102] Train-FCNLogLoss=0.072749
2017-07-13 20:03:28,801 Epoch[102] Time cost=1005.763
2017-07-13 20:03:29,802 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0103.params"
2017-07-13 20:03:33,759 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0103.states"
2017-07-13 20:03:42,006 Epoch[103] Batch [10]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.067958,	
2017-07-13 20:03:49,753 Epoch[103] Batch [20]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.074941,	
2017-07-13 20:03:56,700 Epoch[103] Batch [30]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.072858,	
2017-07-13 20:04:03,210 Epoch[103] Batch [40]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.073479,	
2017-07-13 20:04:09,769 Epoch[103] Batch [50]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.073974,	
2017-07-13 20:04:16,419 Epoch[103] Batch [60]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073954,	
2017-07-13 20:04:23,326 Epoch[103] Batch [70]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.074740,	
2017-07-13 20:04:30,081 Epoch[103] Batch [80]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.074070,	
2017-07-13 20:04:36,673 Epoch[103] Batch [90]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.074149,	
2017-07-13 20:04:43,236 Epoch[103] Batch [100]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.074837,	
2017-07-13 20:04:49,819 Epoch[103] Batch [110]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.073539,	
2017-07-13 20:04:56,336 Epoch[103] Batch [120]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073956,	
2017-07-13 20:05:03,483 Epoch[103] Batch [130]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.073759,	
2017-07-13 20:05:10,162 Epoch[103] Batch [140]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073768,	
2017-07-13 20:05:16,974 Epoch[103] Batch [150]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073792,	
2017-07-13 20:05:24,222 Epoch[103] Batch [160]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.073422,	
2017-07-13 20:05:30,972 Epoch[103] Batch [170]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073766,	
2017-07-13 20:05:37,704 Epoch[103] Batch [180]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073968,	
2017-07-13 20:05:44,469 Epoch[103] Batch [190]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073751,	
2017-07-13 20:05:51,559 Epoch[103] Batch [200]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.073443,	
2017-07-13 20:05:58,354 Epoch[103] Batch [210]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.073483,	
2017-07-13 20:06:05,310 Epoch[103] Batch [220]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.073204,	
2017-07-13 20:06:12,238 Epoch[103] Batch [230]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.073122,	
2017-07-13 20:06:19,246 Epoch[103] Batch [240]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.073111,	
2017-07-13 20:06:25,954 Epoch[103] Batch [250]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073091,	
2017-07-13 20:06:32,666 Epoch[103] Batch [260]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072880,	
2017-07-13 20:06:39,259 Epoch[103] Batch [270]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.072826,	
2017-07-13 20:06:46,048 Epoch[103] Batch [280]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072791,	
2017-07-13 20:06:52,689 Epoch[103] Batch [290]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073008,	
2017-07-13 20:06:59,346 Epoch[103] Batch [300]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.073037,	
2017-07-13 20:07:06,058 Epoch[103] Batch [310]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073242,	
2017-07-13 20:07:12,638 Epoch[103] Batch [320]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.073160,	
2017-07-13 20:07:19,133 Epoch[103] Batch [330]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.073123,	
2017-07-13 20:07:25,777 Epoch[103] Batch [340]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073008,	
2017-07-13 20:07:32,560 Epoch[103] Batch [350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072960,	
2017-07-13 20:07:39,255 Epoch[103] Batch [360]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072835,	
2017-07-13 20:07:46,033 Epoch[103] Batch [370]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072688,	
2017-07-13 20:07:52,778 Epoch[103] Batch [380]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072634,	
2017-07-13 20:07:59,588 Epoch[103] Batch [390]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072693,	
2017-07-13 20:08:06,165 Epoch[103] Batch [400]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.072567,	
2017-07-13 20:08:12,786 Epoch[103] Batch [410]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.072526,	
2017-07-13 20:08:19,477 Epoch[103] Batch [420]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072464,	
2017-07-13 20:08:26,186 Epoch[103] Batch [430]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072448,	
2017-07-13 20:08:32,913 Epoch[103] Batch [440]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072383,	
2017-07-13 20:08:39,616 Epoch[103] Batch [450]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072251,	
2017-07-13 20:08:46,256 Epoch[103] Batch [460]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.072217,	
2017-07-13 20:08:52,812 Epoch[103] Batch [470]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.072271,	
2017-07-13 20:08:59,820 Epoch[103] Batch [480]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.072339,	
2017-07-13 20:09:06,413 Epoch[103] Batch [490]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.072302,	
2017-07-13 20:09:13,181 Epoch[103] Batch [500]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072278,	
2017-07-13 20:09:20,056 Epoch[103] Batch [510]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.072215,	
2017-07-13 20:09:26,545 Epoch[103] Batch [520]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.072273,	
2017-07-13 20:09:33,372 Epoch[103] Batch [530]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072268,	
2017-07-13 20:09:40,132 Epoch[103] Batch [540]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072347,	
2017-07-13 20:09:47,298 Epoch[103] Batch [550]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.072215,	
2017-07-13 20:09:54,430 Epoch[103] Batch [560]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.072257,	
2017-07-13 20:10:01,738 Epoch[103] Batch [570]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.072214,	
2017-07-13 20:10:09,244 Epoch[103] Batch [580]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.072176,	
2017-07-13 20:10:16,351 Epoch[103] Batch [590]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.072083,	
2017-07-13 20:10:23,698 Epoch[103] Batch [600]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.072136,	
2017-07-13 20:10:30,772 Epoch[103] Batch [610]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.072220,	
2017-07-13 20:10:37,511 Epoch[103] Batch [620]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072154,	
2017-07-13 20:10:44,132 Epoch[103] Batch [630]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.072255,	
2017-07-13 20:10:50,737 Epoch[103] Batch [640]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072268,	
2017-07-13 20:10:57,476 Epoch[103] Batch [650]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072277,	
2017-07-13 20:11:03,998 Epoch[103] Batch [660]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.072228,	
2017-07-13 20:11:10,657 Epoch[103] Batch [670]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072444,	
2017-07-13 20:11:17,615 Epoch[103] Batch [680]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.072405,	
2017-07-13 20:11:24,431 Epoch[103] Batch [690]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072430,	
2017-07-13 20:11:30,596 Epoch[103] Batch [700]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.072516,	
2017-07-13 20:11:37,149 Epoch[103] Batch [710]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.072603,	
2017-07-13 20:11:43,603 Epoch[103] Batch [720]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.072621,	
2017-07-13 20:11:50,185 Epoch[103] Batch [730]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.072532,	
2017-07-13 20:11:56,707 Epoch[103] Batch [740]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.072559,	
2017-07-13 20:12:03,317 Epoch[103] Batch [750]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072494,	
2017-07-13 20:12:10,048 Epoch[103] Batch [760]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072477,	
2017-07-13 20:12:16,529 Epoch[103] Batch [770]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.072581,	
2017-07-13 20:12:23,258 Epoch[103] Batch [780]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072532,	
2017-07-13 20:12:29,935 Epoch[103] Batch [790]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072392,	
2017-07-13 20:12:36,642 Epoch[103] Batch [800]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072473,	
2017-07-13 20:12:43,256 Epoch[103] Batch [810]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072467,	
2017-07-13 20:12:49,910 Epoch[103] Batch [820]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072488,	
2017-07-13 20:12:56,594 Epoch[103] Batch [830]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072478,	
2017-07-13 20:13:03,048 Epoch[103] Batch [840]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.072449,	
2017-07-13 20:13:09,739 Epoch[103] Batch [850]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072491,	
2017-07-13 20:13:16,464 Epoch[103] Batch [860]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072402,	
2017-07-13 20:13:23,168 Epoch[103] Batch [870]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072338,	
2017-07-13 20:13:29,810 Epoch[103] Batch [880]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.072307,	
2017-07-13 20:13:36,382 Epoch[103] Batch [890]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.072263,	
2017-07-13 20:13:42,897 Epoch[103] Batch [900]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.072360,	
2017-07-13 20:13:50,071 Epoch[103] Batch [910]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.072367,	
2017-07-13 20:13:56,619 Epoch[103] Batch [920]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.072318,	
2017-07-13 20:14:03,069 Epoch[103] Batch [930]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.072265,	
2017-07-13 20:14:09,965 Epoch[103] Batch [940]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.072267,	
2017-07-13 20:14:16,907 Epoch[103] Batch [950]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.072205,	
2017-07-13 20:14:23,787 Epoch[103] Batch [960]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.072318,	
2017-07-13 20:14:30,449 Epoch[103] Batch [970]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072295,	
2017-07-13 20:14:37,265 Epoch[103] Batch [980]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072349,	
2017-07-13 20:14:44,536 Epoch[103] Batch [990]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.072355,	
2017-07-13 20:14:51,161 Epoch[103] Batch [1000]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.072405,	
2017-07-13 20:14:58,035 Epoch[103] Batch [1010]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.072293,	
2017-07-13 20:15:04,635 Epoch[103] Batch [1020]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072255,	
2017-07-13 20:15:11,278 Epoch[103] Batch [1030]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.072216,	
2017-07-13 20:15:18,029 Epoch[103] Batch [1040]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072195,	
2017-07-13 20:15:24,838 Epoch[103] Batch [1050]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072235,	
2017-07-13 20:15:31,857 Epoch[103] Batch [1060]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.072259,	
2017-07-13 20:15:38,864 Epoch[103] Batch [1070]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.072303,	
2017-07-13 20:15:45,465 Epoch[103] Batch [1080]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072266,	
2017-07-13 20:15:52,479 Epoch[103] Batch [1090]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.072288,	
2017-07-13 20:15:58,936 Epoch[103] Batch [1100]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.072317,	
2017-07-13 20:16:05,804 Epoch[103] Batch [1110]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.072408,	
2017-07-13 20:16:12,517 Epoch[103] Batch [1120]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072417,	
2017-07-13 20:16:19,347 Epoch[103] Batch [1130]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072409,	
2017-07-13 20:16:26,522 Epoch[103] Batch [1140]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.072398,	
2017-07-13 20:16:33,295 Epoch[103] Batch [1150]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072397,	
2017-07-13 20:16:40,383 Epoch[103] Batch [1160]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.072449,	
2017-07-13 20:16:47,358 Epoch[103] Batch [1170]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.072464,	
2017-07-13 20:16:54,058 Epoch[103] Batch [1180]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072495,	
2017-07-13 20:17:00,899 Epoch[103] Batch [1190]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.072487,	
2017-07-13 20:17:07,765 Epoch[103] Batch [1200]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.072445,	
2017-07-13 20:17:14,297 Epoch[103] Batch [1210]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.072430,	
2017-07-13 20:17:20,948 Epoch[103] Batch [1220]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072431,	
2017-07-13 20:17:28,106 Epoch[103] Batch [1230]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.072478,	
2017-07-13 20:17:35,037 Epoch[103] Batch [1240]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.072476,	
2017-07-13 20:17:41,480 Epoch[103] Batch [1250]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.072422,	
2017-07-13 20:17:48,302 Epoch[103] Batch [1260]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072384,	
2017-07-13 20:17:55,127 Epoch[103] Batch [1270]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072395,	
2017-07-13 20:18:02,330 Epoch[103] Batch [1280]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.072431,	
2017-07-13 20:18:09,378 Epoch[103] Batch [1290]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.072380,	
2017-07-13 20:18:16,142 Epoch[103] Batch [1300]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072381,	
2017-07-13 20:18:22,883 Epoch[103] Batch [1310]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072344,	
2017-07-13 20:18:29,642 Epoch[103] Batch [1320]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072332,	
2017-07-13 20:18:36,210 Epoch[103] Batch [1330]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.072357,	
2017-07-13 20:18:42,894 Epoch[103] Batch [1340]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072363,	
2017-07-13 20:18:49,567 Epoch[103] Batch [1350]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072384,	
2017-07-13 20:18:56,345 Epoch[103] Batch [1360]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072397,	
2017-07-13 20:19:03,064 Epoch[103] Batch [1370]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072415,	
2017-07-13 20:19:09,772 Epoch[103] Batch [1380]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072490,	
2017-07-13 20:19:16,492 Epoch[103] Batch [1390]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072483,	
2017-07-13 20:19:23,189 Epoch[103] Batch [1400]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072466,	
2017-07-13 20:19:29,906 Epoch[103] Batch [1410]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072495,	
2017-07-13 20:19:36,660 Epoch[103] Batch [1420]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072513,	
2017-07-13 20:19:43,363 Epoch[103] Batch [1430]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072471,	
2017-07-13 20:19:50,097 Epoch[103] Batch [1440]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072488,	
2017-07-13 20:19:56,806 Epoch[103] Batch [1450]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072446,	
2017-07-13 20:20:03,581 Epoch[103] Batch [1460]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072486,	
2017-07-13 20:20:10,281 Epoch[103] Batch [1470]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072464,	
2017-07-13 20:20:17,062 Epoch[103] Batch [1480]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072478,	
2017-07-13 20:20:21,045 Epoch[103] Train-FCNLogLoss=0.072485
2017-07-13 20:20:21,045 Epoch[103] Time cost=1007.286
2017-07-13 20:20:21,918 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0104.params"
2017-07-13 20:20:25,807 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0104.states"
2017-07-13 20:20:33,405 Epoch[104] Batch [10]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.082374,	
2017-07-13 20:20:39,997 Epoch[104] Batch [20]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.078276,	
2017-07-13 20:20:46,584 Epoch[104] Batch [30]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.073184,	
2017-07-13 20:20:53,216 Epoch[104] Batch [40]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.075125,	
2017-07-13 20:20:59,908 Epoch[104] Batch [50]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.075166,	
2017-07-13 20:21:06,679 Epoch[104] Batch [60]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.074284,	
2017-07-13 20:21:13,360 Epoch[104] Batch [70]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.074296,	
2017-07-13 20:21:20,084 Epoch[104] Batch [80]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073243,	
2017-07-13 20:21:26,904 Epoch[104] Batch [90]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072873,	
2017-07-13 20:21:33,651 Epoch[104] Batch [100]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073813,	
2017-07-13 20:21:40,367 Epoch[104] Batch [110]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.074013,	
2017-07-13 20:21:47,096 Epoch[104] Batch [120]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.074143,	
2017-07-13 20:21:53,843 Epoch[104] Batch [130]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.074049,	
2017-07-13 20:22:00,644 Epoch[104] Batch [140]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073733,	
2017-07-13 20:22:07,404 Epoch[104] Batch [150]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073469,	
2017-07-13 20:22:14,074 Epoch[104] Batch [160]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073208,	
2017-07-13 20:22:20,791 Epoch[104] Batch [170]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.073403,	
2017-07-13 20:22:27,385 Epoch[104] Batch [180]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.073002,	
2017-07-13 20:22:34,106 Epoch[104] Batch [190]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072842,	
2017-07-13 20:22:40,949 Epoch[104] Batch [200]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.072816,	
2017-07-13 20:22:47,640 Epoch[104] Batch [210]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072894,	
2017-07-13 20:22:54,317 Epoch[104] Batch [220]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072945,	
2017-07-13 20:23:00,541 Epoch[104] Batch [230]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.073043,	
2017-07-13 20:23:07,339 Epoch[104] Batch [240]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073023,	
2017-07-13 20:23:14,080 Epoch[104] Batch [250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073062,	
2017-07-13 20:23:20,793 Epoch[104] Batch [260]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072815,	
2017-07-13 20:23:27,565 Epoch[104] Batch [270]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073100,	
2017-07-13 20:23:34,310 Epoch[104] Batch [280]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.073083,	
2017-07-13 20:23:41,137 Epoch[104] Batch [290]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073081,	
2017-07-13 20:23:47,760 Epoch[104] Batch [300]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.072863,	
2017-07-13 20:23:54,505 Epoch[104] Batch [310]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072848,	
2017-07-13 20:24:01,078 Epoch[104] Batch [320]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.072663,	
2017-07-13 20:24:07,771 Epoch[104] Batch [330]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072650,	
2017-07-13 20:24:14,489 Epoch[104] Batch [340]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072533,	
2017-07-13 20:24:21,182 Epoch[104] Batch [350]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072482,	
2017-07-13 20:24:27,835 Epoch[104] Batch [360]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072311,	
2017-07-13 20:24:34,660 Epoch[104] Batch [370]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072338,	
2017-07-13 20:24:41,378 Epoch[104] Batch [380]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072382,	
2017-07-13 20:24:48,076 Epoch[104] Batch [390]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072197,	
2017-07-13 20:24:54,791 Epoch[104] Batch [400]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072292,	
2017-07-13 20:25:01,483 Epoch[104] Batch [410]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072231,	
2017-07-13 20:25:08,247 Epoch[104] Batch [420]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072378,	
2017-07-13 20:25:14,981 Epoch[104] Batch [430]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072482,	
2017-07-13 20:25:21,714 Epoch[104] Batch [440]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072284,	
2017-07-13 20:25:28,430 Epoch[104] Batch [450]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072341,	
2017-07-13 20:25:35,102 Epoch[104] Batch [460]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072526,	
2017-07-13 20:25:41,788 Epoch[104] Batch [470]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072587,	
2017-07-13 20:25:48,563 Epoch[104] Batch [480]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072672,	
2017-07-13 20:25:55,202 Epoch[104] Batch [490]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072617,	
2017-07-13 20:26:01,889 Epoch[104] Batch [500]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072652,	
2017-07-13 20:26:08,555 Epoch[104] Batch [510]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072633,	
2017-07-13 20:26:15,316 Epoch[104] Batch [520]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072608,	
2017-07-13 20:26:22,028 Epoch[104] Batch [530]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072575,	
2017-07-13 20:26:28,712 Epoch[104] Batch [540]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072567,	
2017-07-13 20:26:35,204 Epoch[104] Batch [550]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.072480,	
2017-07-13 20:26:41,904 Epoch[104] Batch [560]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072528,	
2017-07-13 20:26:48,575 Epoch[104] Batch [570]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072589,	
2017-07-13 20:26:55,416 Epoch[104] Batch [580]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.072612,	
2017-07-13 20:27:01,731 Epoch[104] Batch [590]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.072701,	
2017-07-13 20:27:08,160 Epoch[104] Batch [600]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.072753,	
2017-07-13 20:27:14,774 Epoch[104] Batch [610]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072730,	
2017-07-13 20:27:21,092 Epoch[104] Batch [620]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.072667,	
2017-07-13 20:27:27,622 Epoch[104] Batch [630]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.072679,	
2017-07-13 20:27:34,028 Epoch[104] Batch [640]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.072734,	
2017-07-13 20:27:40,664 Epoch[104] Batch [650]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072630,	
2017-07-13 20:27:47,093 Epoch[104] Batch [660]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.072531,	
2017-07-13 20:27:53,939 Epoch[104] Batch [670]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.072661,	
2017-07-13 20:28:00,364 Epoch[104] Batch [680]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.072642,	
2017-07-13 20:28:06,847 Epoch[104] Batch [690]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.072760,	
2017-07-13 20:28:13,185 Epoch[104] Batch [700]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.072779,	
2017-07-13 20:28:19,660 Epoch[104] Batch [710]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.072769,	
2017-07-13 20:28:26,147 Epoch[104] Batch [720]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.072800,	
2017-07-13 20:28:32,503 Epoch[104] Batch [730]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.072952,	
2017-07-13 20:28:39,165 Epoch[104] Batch [740]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073003,	
2017-07-13 20:28:46,110 Epoch[104] Batch [750]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.073013,	
2017-07-13 20:28:53,105 Epoch[104] Batch [760]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.073036,	
2017-07-13 20:28:59,921 Epoch[104] Batch [770]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073078,	
2017-07-13 20:29:06,683 Epoch[104] Batch [780]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072977,	
2017-07-13 20:29:13,556 Epoch[104] Batch [790]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.073017,	
2017-07-13 20:29:20,378 Epoch[104] Batch [800]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072995,	
2017-07-13 20:29:27,095 Epoch[104] Batch [810]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072951,	
2017-07-13 20:29:33,791 Epoch[104] Batch [820]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072934,	
2017-07-13 20:29:40,388 Epoch[104] Batch [830]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072887,	
2017-07-13 20:29:46,578 Epoch[104] Batch [840]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.072836,	
2017-07-13 20:29:52,950 Epoch[104] Batch [850]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.072838,	
2017-07-13 20:29:59,480 Epoch[104] Batch [860]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.072848,	
2017-07-13 20:30:06,236 Epoch[104] Batch [870]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072870,	
2017-07-13 20:30:12,656 Epoch[104] Batch [880]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.072863,	
2017-07-13 20:30:19,259 Epoch[104] Batch [890]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072909,	
2017-07-13 20:30:25,807 Epoch[104] Batch [900]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.072928,	
2017-07-13 20:30:32,505 Epoch[104] Batch [910]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072937,	
2017-07-13 20:30:39,169 Epoch[104] Batch [920]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072987,	
2017-07-13 20:30:45,731 Epoch[104] Batch [930]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.072956,	
2017-07-13 20:30:52,202 Epoch[104] Batch [940]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.072925,	
2017-07-13 20:30:58,954 Epoch[104] Batch [950]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072994,	
2017-07-13 20:31:05,301 Epoch[104] Batch [960]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.073079,	
2017-07-13 20:31:12,110 Epoch[104] Batch [970]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073121,	
2017-07-13 20:31:18,973 Epoch[104] Batch [980]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.073045,	
2017-07-13 20:31:25,758 Epoch[104] Batch [990]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.073011,	
2017-07-13 20:31:32,653 Epoch[104] Batch [1000]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.072978,	
2017-07-13 20:31:39,437 Epoch[104] Batch [1010]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072949,	
2017-07-13 20:31:45,853 Epoch[104] Batch [1020]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.073017,	
2017-07-13 20:31:52,674 Epoch[104] Batch [1030]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073029,	
2017-07-13 20:31:59,161 Epoch[104] Batch [1040]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.073024,	
2017-07-13 20:32:05,894 Epoch[104] Batch [1050]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073047,	
2017-07-13 20:32:12,575 Epoch[104] Batch [1060]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073052,	
2017-07-13 20:32:19,274 Epoch[104] Batch [1070]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073042,	
2017-07-13 20:32:25,892 Epoch[104] Batch [1080]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.073072,	
2017-07-13 20:32:32,627 Epoch[104] Batch [1090]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073061,	
2017-07-13 20:32:39,131 Epoch[104] Batch [1100]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.073073,	
2017-07-13 20:32:45,472 Epoch[104] Batch [1110]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.073030,	
2017-07-13 20:32:51,927 Epoch[104] Batch [1120]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.073022,	
2017-07-13 20:32:58,445 Epoch[104] Batch [1130]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073018,	
2017-07-13 20:33:05,251 Epoch[104] Batch [1140]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.073046,	
2017-07-13 20:33:12,283 Epoch[104] Batch [1150]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.073056,	
2017-07-13 20:33:19,369 Epoch[104] Batch [1160]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.073037,	
2017-07-13 20:33:26,282 Epoch[104] Batch [1170]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.073025,	
2017-07-13 20:33:32,655 Epoch[104] Batch [1180]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.072996,	
2017-07-13 20:33:39,691 Epoch[104] Batch [1190]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.072953,	
2017-07-13 20:33:46,821 Epoch[104] Batch [1200]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.072912,	
2017-07-13 20:33:53,745 Epoch[104] Batch [1210]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.072925,	
2017-07-13 20:34:01,257 Epoch[104] Batch [1220]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.072890,	
2017-07-13 20:34:08,295 Epoch[104] Batch [1230]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.072842,	
2017-07-13 20:34:15,045 Epoch[104] Batch [1240]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072827,	
2017-07-13 20:34:21,792 Epoch[104] Batch [1250]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072873,	
2017-07-13 20:34:28,735 Epoch[104] Batch [1260]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.072847,	
2017-07-13 20:34:35,513 Epoch[104] Batch [1270]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072887,	
2017-07-13 20:34:41,752 Epoch[104] Batch [1280]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.072879,	
2017-07-13 20:34:48,438 Epoch[104] Batch [1290]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072863,	
2017-07-13 20:34:54,937 Epoch[104] Batch [1300]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.072857,	
2017-07-13 20:35:01,558 Epoch[104] Batch [1310]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.072796,	
2017-07-13 20:35:08,010 Epoch[104] Batch [1320]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.072783,	
2017-07-13 20:35:14,408 Epoch[104] Batch [1330]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.072811,	
2017-07-13 20:35:20,820 Epoch[104] Batch [1340]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.072827,	
2017-07-13 20:35:27,135 Epoch[104] Batch [1350]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.072820,	
2017-07-13 20:35:33,817 Epoch[104] Batch [1360]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072808,	
2017-07-13 20:35:40,325 Epoch[104] Batch [1370]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.072866,	
2017-07-13 20:35:47,036 Epoch[104] Batch [1380]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072898,	
2017-07-13 20:35:53,597 Epoch[104] Batch [1390]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.072904,	
2017-07-13 20:36:00,149 Epoch[104] Batch [1400]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.072962,	
2017-07-13 20:36:06,576 Epoch[104] Batch [1410]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.072957,	
2017-07-13 20:36:13,349 Epoch[104] Batch [1420]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072933,	
2017-07-13 20:36:19,952 Epoch[104] Batch [1430]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072865,	
2017-07-13 20:36:26,521 Epoch[104] Batch [1440]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.072866,	
2017-07-13 20:36:33,356 Epoch[104] Batch [1450]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.072849,	
2017-07-13 20:36:40,371 Epoch[104] Batch [1460]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.072855,	
2017-07-13 20:36:46,860 Epoch[104] Batch [1470]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.072843,	
2017-07-13 20:36:53,651 Epoch[104] Batch [1480]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072899,	
2017-07-13 20:36:57,661 Epoch[104] Train-FCNLogLoss=0.072864
2017-07-13 20:36:57,661 Epoch[104] Time cost=991.854
2017-07-13 20:36:58,835 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0105.params"
2017-07-13 20:37:03,379 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0105.states"
2017-07-13 20:37:11,111 Epoch[105] Batch [10]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.078718,	
2017-07-13 20:37:17,952 Epoch[105] Batch [20]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.077291,	
2017-07-13 20:37:24,475 Epoch[105] Batch [30]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.074229,	
2017-07-13 20:37:30,850 Epoch[105] Batch [40]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.073510,	
2017-07-13 20:37:37,949 Epoch[105] Batch [50]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.073084,	
2017-07-13 20:37:44,815 Epoch[105] Batch [60]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.072899,	
2017-07-13 20:37:51,726 Epoch[105] Batch [70]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.072986,	
2017-07-13 20:37:58,367 Epoch[105] Batch [80]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.073579,	
2017-07-13 20:38:04,884 Epoch[105] Batch [90]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.073481,	
2017-07-13 20:38:11,712 Epoch[105] Batch [100]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.073892,	
2017-07-13 20:38:18,415 Epoch[105] Batch [110]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073651,	
2017-07-13 20:38:25,123 Epoch[105] Batch [120]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.073330,	
2017-07-13 20:38:31,901 Epoch[105] Batch [130]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072903,	
2017-07-13 20:38:38,571 Epoch[105] Batch [140]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.073325,	
2017-07-13 20:38:45,207 Epoch[105] Batch [150]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.073222,	
2017-07-13 20:38:51,740 Epoch[105] Batch [160]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073013,	
2017-07-13 20:38:58,352 Epoch[105] Batch [170]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072745,	
2017-07-13 20:39:04,889 Epoch[105] Batch [180]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.073069,	
2017-07-13 20:39:11,709 Epoch[105] Batch [190]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.073032,	
2017-07-13 20:39:18,761 Epoch[105] Batch [200]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.073056,	
2017-07-13 20:39:25,499 Epoch[105] Batch [210]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.073175,	
2017-07-13 20:39:32,258 Epoch[105] Batch [220]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.073064,	
2017-07-13 20:39:38,747 Epoch[105] Batch [230]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.073184,	
2017-07-13 20:39:45,512 Epoch[105] Batch [240]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.073233,	
2017-07-13 20:39:52,217 Epoch[105] Batch [250]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.073071,	
2017-07-13 20:39:59,092 Epoch[105] Batch [260]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.073026,	
2017-07-13 20:40:05,882 Epoch[105] Batch [270]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.072930,	
2017-07-13 20:40:12,457 Epoch[105] Batch [280]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.072603,	
2017-07-13 20:40:19,158 Epoch[105] Batch [290]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072562,	
2017-07-13 20:40:25,763 Epoch[105] Batch [300]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072375,	
2017-07-13 20:40:32,378 Epoch[105] Batch [310]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072331,	
2017-07-13 20:40:39,136 Epoch[105] Batch [320]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072467,	
2017-07-13 20:40:45,379 Epoch[105] Batch [330]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.072434,	
2017-07-13 20:40:51,873 Epoch[105] Batch [340]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.072415,	
2017-07-13 20:40:58,679 Epoch[105] Batch [350]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.072377,	
2017-07-13 20:41:05,378 Epoch[105] Batch [360]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072420,	
2017-07-13 20:41:12,070 Epoch[105] Batch [370]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072518,	
2017-07-13 20:41:18,827 Epoch[105] Batch [380]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072558,	
2017-07-13 20:41:25,639 Epoch[105] Batch [390]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072588,	
2017-07-13 20:41:32,241 Epoch[105] Batch [400]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.072691,	
2017-07-13 20:41:38,920 Epoch[105] Batch [410]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072639,	
2017-07-13 20:41:45,636 Epoch[105] Batch [420]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072696,	
2017-07-13 20:41:52,382 Epoch[105] Batch [430]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072772,	
2017-07-13 20:41:59,119 Epoch[105] Batch [440]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072926,	
2017-07-13 20:42:05,801 Epoch[105] Batch [450]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.073020,	
2017-07-13 20:42:12,557 Epoch[105] Batch [460]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072884,	
2017-07-13 20:42:19,133 Epoch[105] Batch [470]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.072901,	
2017-07-13 20:42:25,887 Epoch[105] Batch [480]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072890,	
2017-07-13 20:42:32,417 Epoch[105] Batch [490]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.072811,	
2017-07-13 20:42:39,536 Epoch[105] Batch [500]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.072730,	
2017-07-13 20:42:46,321 Epoch[105] Batch [510]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072620,	
2017-07-13 20:42:53,040 Epoch[105] Batch [520]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072447,	
2017-07-13 20:42:59,749 Epoch[105] Batch [530]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072524,	
2017-07-13 20:43:06,566 Epoch[105] Batch [540]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072536,	
2017-07-13 20:43:13,234 Epoch[105] Batch [550]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072558,	
2017-07-13 20:43:19,939 Epoch[105] Batch [560]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072636,	
2017-07-13 20:43:26,710 Epoch[105] Batch [570]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072625,	
2017-07-13 20:43:33,420 Epoch[105] Batch [580]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072669,	
2017-07-13 20:43:40,127 Epoch[105] Batch [590]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072548,	
2017-07-13 20:43:46,884 Epoch[105] Batch [600]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072548,	
2017-07-13 20:43:53,575 Epoch[105] Batch [610]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072408,	
2017-07-13 20:44:00,283 Epoch[105] Batch [620]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072355,	
2017-07-13 20:44:07,068 Epoch[105] Batch [630]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072431,	
2017-07-13 20:44:13,794 Epoch[105] Batch [640]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072423,	
2017-07-13 20:44:20,491 Epoch[105] Batch [650]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072436,	
2017-07-13 20:44:27,296 Epoch[105] Batch [660]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.072558,	
2017-07-13 20:44:33,992 Epoch[105] Batch [670]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072557,	
2017-07-13 20:44:40,696 Epoch[105] Batch [680]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072563,	
2017-07-13 20:44:47,470 Epoch[105] Batch [690]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072576,	
2017-07-13 20:44:54,169 Epoch[105] Batch [700]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072610,	
2017-07-13 20:45:00,922 Epoch[105] Batch [710]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072655,	
2017-07-13 20:45:07,641 Epoch[105] Batch [720]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072619,	
2017-07-13 20:45:14,397 Epoch[105] Batch [730]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072672,	
2017-07-13 20:45:21,128 Epoch[105] Batch [740]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072591,	
2017-07-13 20:45:27,849 Epoch[105] Batch [750]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072502,	
2017-07-13 20:45:34,632 Epoch[105] Batch [760]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072480,	
2017-07-13 20:45:41,349 Epoch[105] Batch [770]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072497,	
2017-07-13 20:45:48,051 Epoch[105] Batch [780]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072478,	
2017-07-13 20:45:54,713 Epoch[105] Batch [790]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072535,	
2017-07-13 20:46:01,374 Epoch[105] Batch [800]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.072467,	
2017-07-13 20:46:08,067 Epoch[105] Batch [810]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072456,	
2017-07-13 20:46:14,708 Epoch[105] Batch [820]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.072451,	
2017-07-13 20:46:21,532 Epoch[105] Batch [830]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.072462,	
2017-07-13 20:46:28,220 Epoch[105] Batch [840]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072469,	
2017-07-13 20:46:34,889 Epoch[105] Batch [850]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072482,	
2017-07-13 20:46:41,628 Epoch[105] Batch [860]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072524,	
2017-07-13 20:46:48,320 Epoch[105] Batch [870]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072567,	
2017-07-13 20:46:55,092 Epoch[105] Batch [880]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072688,	
2017-07-13 20:47:01,875 Epoch[105] Batch [890]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072579,	
2017-07-13 20:47:08,458 Epoch[105] Batch [900]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.072542,	
2017-07-13 20:47:15,275 Epoch[105] Batch [910]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.072478,	
2017-07-13 20:47:22,108 Epoch[105] Batch [920]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.072566,	
2017-07-13 20:47:28,820 Epoch[105] Batch [930]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072573,	
2017-07-13 20:47:35,486 Epoch[105] Batch [940]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072661,	
2017-07-13 20:47:42,216 Epoch[105] Batch [950]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072603,	
2017-07-13 20:47:48,907 Epoch[105] Batch [960]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072597,	
2017-07-13 20:47:55,682 Epoch[105] Batch [970]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072573,	
2017-07-13 20:48:02,416 Epoch[105] Batch [980]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072683,	
2017-07-13 20:48:09,142 Epoch[105] Batch [990]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072690,	
2017-07-13 20:48:15,845 Epoch[105] Batch [1000]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072654,	
2017-07-13 20:48:22,558 Epoch[105] Batch [1010]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072630,	
2017-07-13 20:48:29,335 Epoch[105] Batch [1020]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072652,	
2017-07-13 20:48:36,029 Epoch[105] Batch [1030]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072674,	
2017-07-13 20:48:42,744 Epoch[105] Batch [1040]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072754,	
2017-07-13 20:48:49,451 Epoch[105] Batch [1050]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072775,	
2017-07-13 20:48:56,206 Epoch[105] Batch [1060]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072745,	
2017-07-13 20:49:02,872 Epoch[105] Batch [1070]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072725,	
2017-07-13 20:49:09,653 Epoch[105] Batch [1080]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072757,	
2017-07-13 20:49:16,343 Epoch[105] Batch [1090]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072776,	
2017-07-13 20:49:23,098 Epoch[105] Batch [1100]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072735,	
2017-07-13 20:49:29,964 Epoch[105] Batch [1110]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.072722,	
2017-07-13 20:49:36,527 Epoch[105] Batch [1120]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.072664,	
2017-07-13 20:49:43,310 Epoch[105] Batch [1130]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072635,	
2017-07-13 20:49:50,088 Epoch[105] Batch [1140]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.072633,	
2017-07-13 20:49:56,794 Epoch[105] Batch [1150]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072605,	
2017-07-13 20:50:03,526 Epoch[105] Batch [1160]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072608,	
2017-07-13 20:50:10,160 Epoch[105] Batch [1170]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072557,	
2017-07-13 20:50:16,927 Epoch[105] Batch [1180]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.072512,	
2017-07-13 20:50:23,680 Epoch[105] Batch [1190]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072519,	
2017-07-13 20:50:30,316 Epoch[105] Batch [1200]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.072491,	
2017-07-13 20:50:37,047 Epoch[105] Batch [1210]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072477,	
2017-07-13 20:50:43,717 Epoch[105] Batch [1220]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072473,	
2017-07-13 20:50:50,427 Epoch[105] Batch [1230]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072435,	
2017-07-13 20:50:57,146 Epoch[105] Batch [1240]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072507,	
2017-07-13 20:51:03,828 Epoch[105] Batch [1250]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072509,	
2017-07-13 20:51:10,587 Epoch[105] Batch [1260]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072538,	
2017-07-13 20:51:17,281 Epoch[105] Batch [1270]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072519,	
2017-07-13 20:51:24,002 Epoch[105] Batch [1280]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.072484,	
2017-07-13 20:51:30,535 Epoch[105] Batch [1290]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.072481,	
2017-07-13 20:51:37,118 Epoch[105] Batch [1300]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.072454,	
2017-07-13 20:51:43,870 Epoch[105] Batch [1310]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072432,	
2017-07-13 20:51:50,584 Epoch[105] Batch [1320]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.072452,	
2017-07-13 20:51:57,287 Epoch[105] Batch [1330]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072468,	
2017-07-13 20:52:03,966 Epoch[105] Batch [1340]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072508,	
2017-07-13 20:52:10,886 Epoch[105] Batch [1350]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.072461,	
2017-07-13 20:52:18,089 Epoch[105] Batch [1360]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.072499,	
2017-07-13 20:52:24,790 Epoch[105] Batch [1370]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072527,	
2017-07-13 20:52:31,399 Epoch[105] Batch [1380]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.072503,	
2017-07-13 20:52:38,142 Epoch[105] Batch [1390]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072527,	
2017-07-13 20:52:44,808 Epoch[105] Batch [1400]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.072472,	
2017-07-13 20:52:51,546 Epoch[105] Batch [1410]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.072472,	
2017-07-13 20:52:58,232 Epoch[105] Batch [1420]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.072437,	
2017-07-13 20:53:05,106 Epoch[105] Batch [1430]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.072455,	
2017-07-13 20:53:11,783 Epoch[105] Batch [1440]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.072489,	
2017-07-13 20:53:18,426 Epoch[105] Batch [1450]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.072488,	
2017-07-13 20:53:25,182 Epoch[105] Batch [1460]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.072541,	
2017-07-13 20:53:31,879 Epoch[105] Batch [1470]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.072557,	
2017-07-13 20:53:38,623 Epoch[105] Batch [1480]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.072546,	
2017-07-13 20:53:42,667 Epoch[105] Train-FCNLogLoss=0.072563
2017-07-13 20:53:42,667 Epoch[105] Time cost=999.287
2017-07-13 20:53:43,555 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0106.params"
2017-07-13 20:53:47,512 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106-0106.states"
2017-07-13 20:53:47,522 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 106,
           'lr': 0.0005,
           'lr_step': '80.672',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_dcn_epoch106',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dcn'}

2017-07-13 20:53:58,436 testing 4/500 data 1.4343s net 0.3625s post 0.0061s
2017-07-13 20:53:59,750 testing 8/500 data 1.2012s net 0.3480s post 0.0090s
2017-07-13 20:54:01,069 testing 12/500 data 1.1301s net 0.3406s post 0.0079s
2017-07-13 20:54:02,432 testing 16/500 data 1.1057s net 0.3366s post 0.0075s
2017-07-13 20:54:03,688 testing 20/500 data 1.0714s net 0.3323s post 0.0073s
2017-07-13 20:54:04,991 testing 24/500 data 1.0479s net 0.3380s post 0.0070s
2017-07-13 20:54:06,230 testing 28/500 data 1.0270s net 0.3370s post 0.0069s
2017-07-13 20:54:07,542 testing 32/500 data 1.0215s net 0.3352s post 0.0069s
2017-07-13 20:54:08,837 testing 36/500 data 1.0153s net 0.3339s post 0.0067s
2017-07-13 20:54:10,126 testing 40/500 data 1.0110s net 0.3317s post 0.0066s
2017-07-13 20:54:11,453 testing 44/500 data 1.0065s net 0.3342s post 0.0065s
2017-07-13 20:54:12,819 testing 48/500 data 1.0005s net 0.3418s post 0.0065s
2017-07-13 20:54:14,075 testing 52/500 data 0.9943s net 0.3409s post 0.0065s
2017-07-13 20:54:15,480 testing 56/500 data 1.0002s net 0.3396s post 0.0064s
2017-07-13 20:54:16,759 testing 60/500 data 0.9963s net 0.3390s post 0.0064s
2017-07-13 20:54:18,007 testing 64/500 data 0.9915s net 0.3380s post 0.0064s
2017-07-13 20:54:19,261 testing 68/500 data 0.9888s net 0.3359s post 0.0063s
2017-07-13 20:54:20,579 testing 72/500 data 0.9889s net 0.3351s post 0.0063s
2017-07-13 20:54:21,911 testing 76/500 data 0.9874s net 0.3367s post 0.0063s
2017-07-13 20:54:23,231 testing 80/500 data 0.9820s net 0.3416s post 0.0063s
2017-07-13 20:54:24,607 testing 84/500 data 0.9794s net 0.3464s post 0.0063s
2017-07-13 20:54:25,781 testing 88/500 data 0.9729s net 0.3457s post 0.0063s
2017-07-13 20:54:27,070 testing 92/500 data 0.9723s net 0.3447s post 0.0063s
2017-07-13 20:54:28,346 testing 96/500 data 0.9720s net 0.3431s post 0.0063s
2017-07-13 20:54:29,626 testing 100/500 data 0.9706s net 0.3429s post 0.0063s
2017-07-13 20:54:30,973 testing 104/500 data 0.9694s net 0.3451s post 0.0063s
2017-07-13 20:54:32,161 testing 108/500 data 0.9654s net 0.3442s post 0.0063s
2017-07-13 20:54:33,479 testing 112/500 data 0.9659s net 0.3438s post 0.0063s
2017-07-13 20:54:34,759 testing 116/500 data 0.9653s net 0.3430s post 0.0063s
2017-07-13 20:54:36,019 testing 120/500 data 0.9644s net 0.3421s post 0.0063s
2017-07-13 20:54:37,350 testing 124/500 data 0.9645s net 0.3426s post 0.0063s
2017-07-13 20:54:38,687 testing 128/500 data 0.9628s net 0.3451s post 0.0063s
2017-07-13 20:54:39,978 testing 132/500 data 0.9606s net 0.3465s post 0.0063s
2017-07-13 20:54:41,230 testing 136/500 data 0.9594s net 0.3460s post 0.0063s
2017-07-13 20:54:42,546 testing 140/500 data 0.9602s net 0.3453s post 0.0063s
2017-07-13 20:54:43,830 testing 144/500 data 0.9592s net 0.3456s post 0.0063s
2017-07-13 20:54:45,213 testing 148/500 data 0.9593s net 0.3474s post 0.0063s
2017-07-13 20:54:46,604 testing 152/500 data 0.9602s net 0.3485s post 0.0063s
2017-07-13 20:54:47,971 testing 156/500 data 0.9605s net 0.3495s post 0.0063s
2017-07-13 20:54:49,275 testing 160/500 data 0.9606s net 0.3491s post 0.0063s
2017-07-13 20:54:50,588 testing 164/500 data 0.9611s net 0.3486s post 0.0063s
2017-07-13 20:54:51,910 testing 168/500 data 0.9620s net 0.3478s post 0.0063s
2017-07-13 20:54:53,176 testing 172/500 data 0.9618s net 0.3468s post 0.0064s
2017-07-13 20:54:54,478 testing 176/500 data 0.9612s net 0.3471s post 0.0064s
2017-07-13 20:54:55,826 testing 180/500 data 0.9601s net 0.3489s post 0.0064s
2017-07-13 20:54:56,994 testing 184/500 data 0.9575s net 0.3483s post 0.0064s
2017-07-13 20:54:58,264 testing 188/500 data 0.9572s net 0.3477s post 0.0064s
2017-07-13 20:54:59,494 testing 192/500 data 0.9561s net 0.3471s post 0.0064s
2017-07-13 20:55:00,832 testing 196/500 data 0.9558s net 0.3480s post 0.0064s
2017-07-13 20:55:02,085 testing 200/500 data 0.9551s net 0.3476s post 0.0064s
2017-07-13 20:55:03,445 testing 204/500 data 0.9564s net 0.3473s post 0.0064s
2017-07-13 20:55:04,748 testing 208/500 data 0.9567s net 0.3468s post 0.0064s
2017-07-13 20:55:06,057 testing 212/500 data 0.9574s net 0.3459s post 0.0066s
2017-07-13 20:55:07,410 testing 216/500 data 0.9578s net 0.3463s post 0.0066s
2017-07-13 20:55:08,744 testing 220/500 data 0.9567s net 0.3478s post 0.0066s
2017-07-13 20:55:09,926 testing 224/500 data 0.9548s net 0.3474s post 0.0066s
2017-07-13 20:55:11,231 testing 228/500 data 0.9550s net 0.3471s post 0.0066s
2017-07-13 20:55:12,533 testing 232/500 data 0.9553s net 0.3466s post 0.0067s
2017-07-13 20:55:13,802 testing 236/500 data 0.9554s net 0.3459s post 0.0067s
2017-07-13 20:55:15,117 testing 240/500 data 0.9559s net 0.3455s post 0.0066s
2017-07-13 20:55:16,431 testing 244/500 data 0.9557s net 0.3458s post 0.0066s
2017-07-13 20:55:17,784 testing 248/500 data 0.9557s net 0.3466s post 0.0066s
2017-07-13 20:55:19,150 testing 252/500 data 0.9553s net 0.3479s post 0.0066s
2017-07-13 20:55:20,397 testing 256/500 data 0.9543s net 0.3479s post 0.0066s
2017-07-13 20:55:21,668 testing 260/500 data 0.9541s net 0.3475s post 0.0066s
2017-07-13 20:55:22,909 testing 264/500 data 0.9536s net 0.3470s post 0.0066s
2017-07-13 20:55:24,212 testing 268/500 data 0.9535s net 0.3471s post 0.0066s
2017-07-13 20:55:25,553 testing 272/500 data 0.9533s net 0.3478s post 0.0066s
2017-07-13 20:55:26,935 testing 276/500 data 0.9529s net 0.3492s post 0.0066s
2017-07-13 20:55:28,058 testing 280/500 data 0.9505s net 0.3489s post 0.0066s
2017-07-13 20:55:29,295 testing 284/500 data 0.9501s net 0.3484s post 0.0066s
2017-07-13 20:55:30,612 testing 288/500 data 0.9504s net 0.3483s post 0.0066s
2017-07-13 20:55:31,943 testing 292/500 data 0.9504s net 0.3487s post 0.0066s
2017-07-13 20:55:33,278 testing 296/500 data 0.9497s net 0.3497s post 0.0066s
2017-07-13 20:55:34,487 testing 300/500 data 0.9488s net 0.3493s post 0.0066s
2017-07-13 20:55:35,750 testing 304/500 data 0.9486s net 0.3490s post 0.0066s
2017-07-13 20:55:37,087 testing 308/500 data 0.9493s net 0.3488s post 0.0066s
2017-07-13 20:55:38,405 testing 312/500 data 0.9497s net 0.3485s post 0.0066s
2017-07-13 20:55:39,742 testing 316/500 data 0.9503s net 0.3483s post 0.0066s
2017-07-13 20:55:40,994 testing 320/500 data 0.9499s net 0.3480s post 0.0065s
2017-07-13 20:55:42,392 testing 324/500 data 0.9510s net 0.3481s post 0.0065s
2017-07-13 20:55:43,779 testing 328/500 data 0.9517s net 0.3484s post 0.0065s
2017-07-13 20:55:45,117 testing 332/500 data 0.9511s net 0.3494s post 0.0065s
2017-07-13 20:55:46,544 testing 336/500 data 0.9517s net 0.3502s post 0.0065s
2017-07-13 20:55:47,784 testing 340/500 data 0.9513s net 0.3499s post 0.0065s
2017-07-13 20:55:49,187 testing 344/500 data 0.9526s net 0.3496s post 0.0065s
2017-07-13 20:55:50,540 testing 348/500 data 0.9533s net 0.3494s post 0.0065s
2017-07-13 20:55:51,933 testing 352/500 data 0.9545s net 0.3492s post 0.0065s
2017-07-13 20:55:53,342 testing 356/500 data 0.9559s net 0.3490s post 0.0065s
2017-07-13 20:55:54,823 testing 360/500 data 0.9575s net 0.3492s post 0.0065s
2017-07-13 20:55:56,147 testing 364/500 data 0.9577s net 0.3491s post 0.0065s
2017-07-13 20:55:57,697 testing 368/500 data 0.9594s net 0.3500s post 0.0065s
2017-07-13 20:55:59,006 testing 372/500 data 0.9584s net 0.3509s post 0.0065s
2017-07-13 20:56:00,415 testing 376/500 data 0.9588s net 0.3515s post 0.0065s
2017-07-13 20:56:01,369 testing 380/500 data 0.9554s net 0.3511s post 0.0065s
2017-07-13 20:56:03,038 testing 384/500 data 0.9592s net 0.3511s post 0.0065s
2017-07-13 20:56:04,570 testing 388/500 data 0.9606s net 0.3518s post 0.0065s
2017-07-13 20:56:05,959 testing 392/500 data 0.9606s net 0.3526s post 0.0065s
2017-07-13 20:56:07,276 testing 396/500 data 0.9609s net 0.3523s post 0.0065s
2017-07-13 20:56:08,805 testing 400/500 data 0.9624s net 0.3529s post 0.0065s
2017-07-13 20:56:10,136 testing 404/500 data 0.9628s net 0.3525s post 0.0065s
2017-07-13 20:56:11,715 testing 408/500 data 0.9645s net 0.3534s post 0.0065s
2017-07-13 20:56:13,155 testing 412/500 data 0.9648s net 0.3541s post 0.0065s
2017-07-13 20:56:14,654 testing 416/500 data 0.9661s net 0.3545s post 0.0065s
2017-07-13 20:56:15,945 testing 420/500 data 0.9650s net 0.3553s post 0.0065s
2017-07-13 20:56:17,422 testing 424/500 data 0.9657s net 0.3560s post 0.0065s
2017-07-13 20:56:18,635 testing 428/500 data 0.9650s net 0.3557s post 0.0065s
2017-07-13 20:56:20,193 testing 432/500 data 0.9673s net 0.3555s post 0.0065s
2017-07-13 20:56:21,375 testing 436/500 data 0.9663s net 0.3552s post 0.0065s
2017-07-13 20:56:22,895 testing 440/500 data 0.9682s net 0.3549s post 0.0065s
2017-07-13 20:56:24,337 testing 444/500 data 0.9694s net 0.3547s post 0.0065s
2017-07-13 20:56:25,682 testing 448/500 data 0.9699s net 0.3544s post 0.0065s
2017-07-13 20:56:27,142 testing 452/500 data 0.9712s net 0.3542s post 0.0065s
2017-07-13 20:56:28,530 testing 456/500 data 0.9720s net 0.3539s post 0.0065s
2017-07-13 20:56:29,818 testing 460/500 data 0.9719s net 0.3536s post 0.0065s
2017-07-13 20:56:31,075 testing 464/500 data 0.9718s net 0.3531s post 0.0065s
2017-07-13 20:56:32,466 testing 468/500 data 0.9726s net 0.3528s post 0.0065s
2017-07-13 20:56:33,836 testing 472/500 data 0.9731s net 0.3526s post 0.0065s
2017-07-13 20:56:35,169 testing 476/500 data 0.9728s net 0.3529s post 0.0065s
2017-07-13 20:56:36,565 testing 480/500 data 0.9733s net 0.3529s post 0.0065s
2017-07-13 20:56:37,927 testing 484/500 data 0.9736s net 0.3529s post 0.0065s
2017-07-13 20:56:39,279 testing 488/500 data 0.9735s net 0.3532s post 0.0065s
2017-07-13 20:56:40,642 testing 492/500 data 0.9730s net 0.3539s post 0.0065s
2017-07-13 20:56:41,941 testing 496/500 data 0.9728s net 0.3538s post 0.0065s
2017-07-13 20:56:43,315 testing 500/500 data 0.9734s net 0.3536s post 0.0065s
2017-07-13 20:58:44,736 evaluate segmentation: 

2017-07-13 20:58:44,736 IU_array:

2017-07-13 20:58:44,736 0.98010
2017-07-13 20:58:44,736 0.83719
2017-07-13 20:58:44,736 0.91361
2017-07-13 20:58:44,736 0.57212
2017-07-13 20:58:44,736 0.54977
2017-07-13 20:58:44,736 0.53899
2017-07-13 20:58:44,736 0.63974
2017-07-13 20:58:44,736 0.73554
2017-07-13 20:58:44,736 0.91339
2017-07-13 20:58:44,737 0.62755
2017-07-13 20:58:44,737 0.93635
2017-07-13 20:58:44,737 0.78660
2017-07-13 20:58:44,737 0.59978
2017-07-13 20:58:44,737 0.93823
2017-07-13 20:58:44,737 0.65613
2017-07-13 20:58:44,737 0.86810
2017-07-13 20:58:44,737 0.75501
2017-07-13 20:58:44,737 0.61670
2017-07-13 20:58:44,737 0.74431
2017-07-13 20:58:44,737 meanIU:0.74785

2017-06-27 15:22:54,261 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate9x9'}

2017-06-27 15:24:32,007 Epoch[0] Batch [10]	Speed: 8.94 samples/sec	Train-FCNLogLoss=2.891400,	
2017-06-27 15:24:36,371 Epoch[0] Batch [20]	Speed: 9.17 samples/sec	Train-FCNLogLoss=2.774611,	
2017-06-27 15:24:40,803 Epoch[0] Batch [30]	Speed: 9.03 samples/sec	Train-FCNLogLoss=2.533022,	
2017-06-27 15:24:45,321 Epoch[0] Batch [40]	Speed: 8.85 samples/sec	Train-FCNLogLoss=2.304353,	
2017-06-27 15:24:49,756 Epoch[0] Batch [50]	Speed: 9.02 samples/sec	Train-FCNLogLoss=2.079999,	
2017-06-27 15:24:54,237 Epoch[0] Batch [60]	Speed: 8.93 samples/sec	Train-FCNLogLoss=1.919088,	
2017-06-27 15:24:58,641 Epoch[0] Batch [70]	Speed: 9.08 samples/sec	Train-FCNLogLoss=1.774328,	
2017-06-27 15:25:03,176 Epoch[0] Batch [80]	Speed: 8.82 samples/sec	Train-FCNLogLoss=1.659732,	
2017-06-27 15:25:07,563 Epoch[0] Batch [90]	Speed: 9.12 samples/sec	Train-FCNLogLoss=1.559312,	
2017-06-27 15:25:12,053 Epoch[0] Batch [100]	Speed: 8.91 samples/sec	Train-FCNLogLoss=1.475712,	
2017-06-27 15:25:16,471 Epoch[0] Batch [110]	Speed: 9.05 samples/sec	Train-FCNLogLoss=1.402792,	
2017-06-27 15:25:20,943 Epoch[0] Batch [120]	Speed: 8.95 samples/sec	Train-FCNLogLoss=1.348218,	
2017-06-27 15:25:25,505 Epoch[0] Batch [130]	Speed: 8.77 samples/sec	Train-FCNLogLoss=1.289147,	
2017-06-27 15:25:29,905 Epoch[0] Batch [140]	Speed: 9.09 samples/sec	Train-FCNLogLoss=1.245451,	
2017-06-27 15:25:34,210 Epoch[0] Batch [150]	Speed: 9.29 samples/sec	Train-FCNLogLoss=1.203819,	
2017-06-27 15:25:38,493 Epoch[0] Batch [160]	Speed: 9.34 samples/sec	Train-FCNLogLoss=1.172213,	
2017-06-27 15:25:42,801 Epoch[0] Batch [170]	Speed: 9.29 samples/sec	Train-FCNLogLoss=1.136097,	
2017-06-27 15:25:47,050 Epoch[0] Batch [180]	Speed: 9.41 samples/sec	Train-FCNLogLoss=1.105537,	
2017-06-27 15:25:51,352 Epoch[0] Batch [190]	Speed: 9.30 samples/sec	Train-FCNLogLoss=1.081622,	
2017-06-27 15:25:55,667 Epoch[0] Batch [200]	Speed: 9.27 samples/sec	Train-FCNLogLoss=1.054053,	
2017-06-27 15:26:00,002 Epoch[0] Batch [210]	Speed: 9.23 samples/sec	Train-FCNLogLoss=1.030881,	
2017-06-27 15:26:04,254 Epoch[0] Batch [220]	Speed: 9.41 samples/sec	Train-FCNLogLoss=1.004315,	
2017-06-27 15:26:08,592 Epoch[0] Batch [230]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.988076,	
2017-06-27 15:26:12,846 Epoch[0] Batch [240]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.966229,	
2017-06-27 15:26:17,242 Epoch[0] Batch [250]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.946197,	
2017-06-27 15:26:21,528 Epoch[0] Batch [260]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.930974,	
2017-06-27 15:26:25,851 Epoch[0] Batch [270]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.919485,	
2017-06-27 15:26:30,050 Epoch[0] Batch [280]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.903906,	
2017-06-27 15:26:34,391 Epoch[0] Batch [290]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.889077,	
2017-06-27 15:26:38,691 Epoch[0] Batch [300]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.874024,	
2017-06-27 15:26:42,997 Epoch[0] Batch [310]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.864286,	
2017-06-27 15:26:47,362 Epoch[0] Batch [320]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.851601,	
2017-06-27 15:26:51,688 Epoch[0] Batch [330]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.838284,	
2017-06-27 15:26:55,921 Epoch[0] Batch [340]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.826479,	
2017-06-27 15:27:00,213 Epoch[0] Batch [350]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.815100,	
2017-06-27 15:27:04,433 Epoch[0] Batch [360]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.806704,	
2017-06-27 15:27:08,727 Epoch[0] Batch [370]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.796582,	
2017-06-27 15:27:12,943 Epoch[0] Batch [380]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.787507,	
2017-06-27 15:27:17,142 Epoch[0] Batch [390]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.778825,	
2017-06-27 15:27:21,490 Epoch[0] Batch [400]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.769301,	
2017-06-27 15:27:25,676 Epoch[0] Batch [410]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.761457,	
2017-06-27 15:27:29,911 Epoch[0] Batch [420]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.753046,	
2017-06-27 15:27:34,104 Epoch[0] Batch [430]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.744497,	
2017-06-27 15:27:38,463 Epoch[0] Batch [440]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.735969,	
2017-06-27 15:27:42,787 Epoch[0] Batch [450]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.728747,	
2017-06-27 15:27:47,106 Epoch[0] Batch [460]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.722810,	
2017-06-27 15:27:51,363 Epoch[0] Batch [470]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.716288,	
2017-06-27 15:27:55,616 Epoch[0] Batch [480]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.709690,	
2017-06-27 15:27:59,880 Epoch[0] Batch [490]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.702266,	
2017-06-27 15:28:04,114 Epoch[0] Batch [500]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.697278,	
2017-06-27 15:28:08,409 Epoch[0] Batch [510]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.690505,	
2017-06-27 15:28:12,687 Epoch[0] Batch [520]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.686416,	
2017-06-27 15:28:16,942 Epoch[0] Batch [530]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.681513,	
2017-06-27 15:28:21,168 Epoch[0] Batch [540]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.676417,	
2017-06-27 15:28:25,480 Epoch[0] Batch [550]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.670355,	
2017-06-27 15:28:29,562 Epoch[0] Batch [560]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.665645,	
2017-06-27 15:28:34,042 Epoch[0] Batch [570]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.660437,	
2017-06-27 15:28:38,407 Epoch[0] Batch [580]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.655135,	
2017-06-27 15:28:42,757 Epoch[0] Batch [590]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.650417,	
2017-06-27 15:28:47,062 Epoch[0] Batch [600]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.645413,	
2017-06-27 15:28:51,403 Epoch[0] Batch [610]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.641082,	
2017-06-27 15:28:55,687 Epoch[0] Batch [620]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.636439,	
2017-06-27 15:29:00,038 Epoch[0] Batch [630]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.633962,	
2017-06-27 15:29:04,262 Epoch[0] Batch [640]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.630179,	
2017-06-27 15:29:08,607 Epoch[0] Batch [650]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.626304,	
2017-06-27 15:29:12,855 Epoch[0] Batch [660]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.621748,	
2017-06-27 15:29:17,119 Epoch[0] Batch [670]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.618711,	
2017-06-27 15:29:21,477 Epoch[0] Batch [680]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.615315,	
2017-06-27 15:29:25,681 Epoch[0] Batch [690]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.611427,	
2017-06-27 15:29:30,039 Epoch[0] Batch [700]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.608305,	
2017-06-27 15:29:34,306 Epoch[0] Batch [710]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.604178,	
2017-06-27 15:29:38,591 Epoch[0] Batch [720]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.600535,	
2017-06-27 15:29:42,800 Epoch[0] Batch [730]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.596637,	
2017-06-27 15:29:47,015 Epoch[0] Batch [740]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.593351,	
2017-06-27 15:29:51,369 Epoch[0] Batch [750]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.589765,	
2017-06-27 15:29:55,636 Epoch[0] Batch [760]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.587410,	
2017-06-27 15:29:59,898 Epoch[0] Batch [770]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.584068,	
2017-06-27 15:30:04,152 Epoch[0] Batch [780]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.581249,	
2017-06-27 15:30:08,323 Epoch[0] Batch [790]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.578416,	
2017-06-27 15:30:12,603 Epoch[0] Batch [800]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.575979,	
2017-06-27 15:30:16,842 Epoch[0] Batch [810]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.573714,	
2017-06-27 15:30:21,215 Epoch[0] Batch [820]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.570559,	
2017-06-27 15:30:25,532 Epoch[0] Batch [830]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.567774,	
2017-06-27 15:30:29,787 Epoch[0] Batch [840]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.565063,	
2017-06-27 15:30:34,203 Epoch[0] Batch [850]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.562418,	
2017-06-27 15:30:38,422 Epoch[0] Batch [860]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.559723,	
2017-06-27 15:30:42,617 Epoch[0] Batch [870]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.556659,	
2017-06-27 15:30:46,893 Epoch[0] Batch [880]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.553599,	
2017-06-27 15:30:51,252 Epoch[0] Batch [890]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.550942,	
2017-06-27 15:30:55,513 Epoch[0] Batch [900]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.548661,	
2017-06-27 15:30:59,726 Epoch[0] Batch [910]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.545957,	
2017-06-27 15:31:03,933 Epoch[0] Batch [920]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.543291,	
2017-06-27 15:31:08,140 Epoch[0] Batch [930]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.540989,	
2017-06-27 15:31:12,578 Epoch[0] Batch [940]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.539242,	
2017-06-27 15:31:16,878 Epoch[0] Batch [950]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.537059,	
2017-06-27 15:31:21,210 Epoch[0] Batch [960]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.534539,	
2017-06-27 15:31:25,434 Epoch[0] Batch [970]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.532251,	
2017-06-27 15:31:29,726 Epoch[0] Batch [980]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.530602,	
2017-06-27 15:31:34,003 Epoch[0] Batch [990]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.528327,	
2017-06-27 15:31:38,354 Epoch[0] Batch [1000]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.526114,	
2017-06-27 15:31:42,625 Epoch[0] Batch [1010]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.524836,	
2017-06-27 15:31:46,963 Epoch[0] Batch [1020]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.524782,	
2017-06-27 15:31:51,366 Epoch[0] Batch [1030]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.535854,	
2017-06-27 15:31:55,704 Epoch[0] Batch [1040]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.544953,	
2017-06-27 15:31:59,883 Epoch[0] Batch [1050]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.549079,	
2017-06-27 15:32:04,135 Epoch[0] Batch [1060]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.550780,	
2017-06-27 15:32:08,423 Epoch[0] Batch [1070]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.551205,	
2017-06-27 15:32:12,688 Epoch[0] Batch [1080]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.551523,	
2017-06-27 15:32:17,058 Epoch[0] Batch [1090]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.551794,	
2017-06-27 15:32:21,356 Epoch[0] Batch [1100]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.550802,	
2017-06-27 15:32:25,586 Epoch[0] Batch [1110]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.550489,	
2017-06-27 15:32:29,805 Epoch[0] Batch [1120]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.549922,	
2017-06-27 15:32:34,067 Epoch[0] Batch [1130]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.549381,	
2017-06-27 15:32:38,401 Epoch[0] Batch [1140]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.548675,	
2017-06-27 15:32:42,593 Epoch[0] Batch [1150]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.547702,	
2017-06-27 15:32:46,868 Epoch[0] Batch [1160]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.545802,	
2017-06-27 15:32:51,096 Epoch[0] Batch [1170]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.544430,	
2017-06-27 15:32:55,295 Epoch[0] Batch [1180]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.543318,	
2017-06-27 15:32:59,560 Epoch[0] Batch [1190]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.542050,	
2017-06-27 15:33:03,780 Epoch[0] Batch [1200]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.540620,	
2017-06-27 15:33:07,974 Epoch[0] Batch [1210]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.539096,	
2017-06-27 15:33:12,309 Epoch[0] Batch [1220]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.537783,	
2017-06-27 15:33:16,502 Epoch[0] Batch [1230]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.537274,	
2017-06-27 15:33:20,784 Epoch[0] Batch [1240]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.536123,	
2017-06-27 15:33:25,073 Epoch[0] Batch [1250]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.535063,	
2017-06-27 15:33:29,454 Epoch[0] Batch [1260]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.533810,	
2017-06-27 15:33:33,723 Epoch[0] Batch [1270]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.532099,	
2017-06-27 15:33:38,095 Epoch[0] Batch [1280]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.530763,	
2017-06-27 15:33:42,432 Epoch[0] Batch [1290]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.530519,	
2017-06-27 15:33:46,628 Epoch[0] Batch [1300]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.529506,	
2017-06-27 15:33:50,913 Epoch[0] Batch [1310]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.528573,	
2017-06-27 15:33:55,257 Epoch[0] Batch [1320]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.527160,	
2017-06-27 15:33:59,577 Epoch[0] Batch [1330]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.526176,	
2017-06-27 15:34:03,817 Epoch[0] Batch [1340]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.525345,	
2017-06-27 15:34:08,069 Epoch[0] Batch [1350]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.524011,	
2017-06-27 15:34:12,369 Epoch[0] Batch [1360]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.522765,	
2017-06-27 15:34:16,764 Epoch[0] Batch [1370]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.521795,	
2017-06-27 15:34:21,121 Epoch[0] Batch [1380]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.520825,	
2017-06-27 15:34:25,331 Epoch[0] Batch [1390]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.519294,	
2017-06-27 15:34:29,543 Epoch[0] Batch [1400]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.518158,	
2017-06-27 15:34:33,989 Epoch[0] Batch [1410]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.517009,	
2017-06-27 15:34:38,219 Epoch[0] Batch [1420]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.515638,	
2017-06-27 15:34:42,390 Epoch[0] Batch [1430]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.514440,	
2017-06-27 15:34:46,634 Epoch[0] Batch [1440]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.513024,	
2017-06-27 15:34:50,818 Epoch[0] Batch [1450]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.511554,	
2017-06-27 15:34:55,080 Epoch[0] Batch [1460]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.510403,	
2017-06-27 15:34:59,322 Epoch[0] Batch [1470]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.508824,	
2017-06-27 15:35:03,550 Epoch[0] Batch [1480]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.507951,	
2017-06-27 15:35:06,106 Epoch[0] Train-FCNLogLoss=0.507200
2017-06-27 15:35:06,106 Epoch[0] Time cost=655.216
2017-06-27 15:35:06,946 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0001.params"
2017-06-27 15:35:08,692 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0001.states"
2017-06-27 15:35:13,649 Epoch[1] Batch [10]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.308966,	
2017-06-27 15:35:17,795 Epoch[1] Batch [20]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.330482,	
2017-06-27 15:35:21,965 Epoch[1] Batch [30]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.329549,	
2017-06-27 15:35:26,141 Epoch[1] Batch [40]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.334089,	
2017-06-27 15:35:30,365 Epoch[1] Batch [50]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.333773,	
2017-06-27 15:35:34,557 Epoch[1] Batch [60]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.323768,	
2017-06-27 15:35:38,657 Epoch[1] Batch [70]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.324776,	
2017-06-27 15:35:42,824 Epoch[1] Batch [80]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.323096,	
2017-06-27 15:35:47,003 Epoch[1] Batch [90]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.321626,	
2017-06-27 15:35:51,088 Epoch[1] Batch [100]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.320596,	
2017-06-27 15:35:55,279 Epoch[1] Batch [110]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.317484,	
2017-06-27 15:35:59,674 Epoch[1] Batch [120]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.312141,	
2017-06-27 15:36:03,919 Epoch[1] Batch [130]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.310228,	
2017-06-27 15:36:08,175 Epoch[1] Batch [140]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.304265,	
2017-06-27 15:36:12,489 Epoch[1] Batch [150]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.304437,	
2017-06-27 15:36:16,656 Epoch[1] Batch [160]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.305252,	
2017-06-27 15:36:20,822 Epoch[1] Batch [170]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.305676,	
2017-06-27 15:36:24,978 Epoch[1] Batch [180]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.305920,	
2017-06-27 15:36:29,200 Epoch[1] Batch [190]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.306232,	
2017-06-27 15:36:33,489 Epoch[1] Batch [200]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.307717,	
2017-06-27 15:36:37,647 Epoch[1] Batch [210]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.305104,	
2017-06-27 15:36:41,818 Epoch[1] Batch [220]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.304376,	
2017-06-27 15:36:46,138 Epoch[1] Batch [230]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.306901,	
2017-06-27 15:36:50,377 Epoch[1] Batch [240]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.308803,	
2017-06-27 15:36:54,690 Epoch[1] Batch [250]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.312940,	
2017-06-27 15:36:58,997 Epoch[1] Batch [260]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.314083,	
2017-06-27 15:37:03,246 Epoch[1] Batch [270]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.315075,	
2017-06-27 15:37:07,542 Epoch[1] Batch [280]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.313777,	
2017-06-27 15:37:11,743 Epoch[1] Batch [290]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.313336,	
2017-06-27 15:37:16,066 Epoch[1] Batch [300]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.311636,	
2017-06-27 15:37:20,398 Epoch[1] Batch [310]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.310586,	
2017-06-27 15:37:24,695 Epoch[1] Batch [320]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.310454,	
2017-06-27 15:37:29,021 Epoch[1] Batch [330]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.308589,	
2017-06-27 15:37:33,372 Epoch[1] Batch [340]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.307332,	
2017-06-27 15:37:37,723 Epoch[1] Batch [350]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.306759,	
2017-06-27 15:37:42,077 Epoch[1] Batch [360]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.304066,	
2017-06-27 15:37:46,351 Epoch[1] Batch [370]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.302942,	
2017-06-27 15:37:50,677 Epoch[1] Batch [380]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.302701,	
2017-06-27 15:37:54,962 Epoch[1] Batch [390]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.302619,	
2017-06-27 15:37:59,365 Epoch[1] Batch [400]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.301801,	
2017-06-27 15:38:03,542 Epoch[1] Batch [410]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.300091,	
2017-06-27 15:38:07,923 Epoch[1] Batch [420]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.299102,	
2017-06-27 15:38:12,151 Epoch[1] Batch [430]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.299174,	
2017-06-27 15:38:16,488 Epoch[1] Batch [440]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.298786,	
2017-06-27 15:38:20,817 Epoch[1] Batch [450]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.298051,	
2017-06-27 15:38:25,058 Epoch[1] Batch [460]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.296438,	
2017-06-27 15:38:29,272 Epoch[1] Batch [470]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.294703,	
2017-06-27 15:38:33,569 Epoch[1] Batch [480]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.293487,	
2017-06-27 15:38:37,999 Epoch[1] Batch [490]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.293658,	
2017-06-27 15:38:42,379 Epoch[1] Batch [500]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.293902,	
2017-06-27 15:38:46,662 Epoch[1] Batch [510]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.293399,	
2017-06-27 15:38:51,186 Epoch[1] Batch [520]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.291572,	
2017-06-27 15:38:55,500 Epoch[1] Batch [530]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.290444,	
2017-06-27 15:38:59,720 Epoch[1] Batch [540]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.290008,	
2017-06-27 15:39:03,929 Epoch[1] Batch [550]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.289695,	
2017-06-27 15:39:08,176 Epoch[1] Batch [560]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.288260,	
2017-06-27 15:39:12,434 Epoch[1] Batch [570]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.287326,	
2017-06-27 15:39:16,652 Epoch[1] Batch [580]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.287088,	
2017-06-27 15:39:20,968 Epoch[1] Batch [590]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.286602,	
2017-06-27 15:39:25,189 Epoch[1] Batch [600]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.285960,	
2017-06-27 15:39:29,334 Epoch[1] Batch [610]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.285792,	
2017-06-27 15:39:33,494 Epoch[1] Batch [620]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.285415,	
2017-06-27 15:39:37,677 Epoch[1] Batch [630]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.284912,	
2017-06-27 15:39:41,941 Epoch[1] Batch [640]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.284240,	
2017-06-27 15:39:46,194 Epoch[1] Batch [650]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.284487,	
2017-06-27 15:39:50,414 Epoch[1] Batch [660]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.285164,	
2017-06-27 15:39:54,600 Epoch[1] Batch [670]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.284923,	
2017-06-27 15:39:58,715 Epoch[1] Batch [680]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.284293,	
2017-06-27 15:40:02,961 Epoch[1] Batch [690]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.283937,	
2017-06-27 15:40:07,036 Epoch[1] Batch [700]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.282953,	
2017-06-27 15:40:11,237 Epoch[1] Batch [710]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.282437,	
2017-06-27 15:40:15,424 Epoch[1] Batch [720]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.282597,	
2017-06-27 15:40:19,741 Epoch[1] Batch [730]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.282141,	
2017-06-27 15:40:24,095 Epoch[1] Batch [740]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.281317,	
2017-06-27 15:40:28,422 Epoch[1] Batch [750]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.280698,	
2017-06-27 15:40:32,829 Epoch[1] Batch [760]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.280713,	
2017-06-27 15:40:37,002 Epoch[1] Batch [770]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.280246,	
2017-06-27 15:40:41,379 Epoch[1] Batch [780]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.279760,	
2017-06-27 15:40:45,732 Epoch[1] Batch [790]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.279365,	
2017-06-27 15:40:49,984 Epoch[1] Batch [800]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.279352,	
2017-06-27 15:40:54,331 Epoch[1] Batch [810]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.280232,	
2017-06-27 15:40:58,671 Epoch[1] Batch [820]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.280150,	
2017-06-27 15:41:02,871 Epoch[1] Batch [830]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.280030,	
2017-06-27 15:41:07,216 Epoch[1] Batch [840]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.279476,	
2017-06-27 15:41:11,448 Epoch[1] Batch [850]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.279400,	
2017-06-27 15:41:15,671 Epoch[1] Batch [860]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.279634,	
2017-06-27 15:41:19,947 Epoch[1] Batch [870]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.279822,	
2017-06-27 15:41:24,214 Epoch[1] Batch [880]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.279211,	
2017-06-27 15:41:28,533 Epoch[1] Batch [890]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.278750,	
2017-06-27 15:41:32,795 Epoch[1] Batch [900]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.278722,	
2017-06-27 15:41:37,042 Epoch[1] Batch [910]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.278293,	
2017-06-27 15:41:41,383 Epoch[1] Batch [920]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.278105,	
2017-06-27 15:41:45,697 Epoch[1] Batch [930]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.279575,	
2017-06-27 15:41:50,006 Epoch[1] Batch [940]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.279805,	
2017-06-27 15:41:54,222 Epoch[1] Batch [950]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.280104,	
2017-06-27 15:41:58,431 Epoch[1] Batch [960]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.279701,	
2017-06-27 15:42:02,713 Epoch[1] Batch [970]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.279547,	
2017-06-27 15:42:07,161 Epoch[1] Batch [980]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.279262,	
2017-06-27 15:42:11,428 Epoch[1] Batch [990]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.279077,	
2017-06-27 15:42:15,850 Epoch[1] Batch [1000]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.278975,	
2017-06-27 15:42:20,198 Epoch[1] Batch [1010]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.278688,	
2017-06-27 15:42:24,469 Epoch[1] Batch [1020]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.278384,	
2017-06-27 15:42:28,679 Epoch[1] Batch [1030]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.278048,	
2017-06-27 15:42:33,019 Epoch[1] Batch [1040]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.277441,	
2017-06-27 15:42:37,283 Epoch[1] Batch [1050]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.277400,	
2017-06-27 15:42:41,683 Epoch[1] Batch [1060]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.276906,	
2017-06-27 15:42:45,938 Epoch[1] Batch [1070]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.276525,	
2017-06-27 15:42:50,090 Epoch[1] Batch [1080]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.276059,	
2017-06-27 15:42:54,283 Epoch[1] Batch [1090]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.275503,	
2017-06-27 15:42:58,437 Epoch[1] Batch [1100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.275516,	
2017-06-27 15:43:02,649 Epoch[1] Batch [1110]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.275025,	
2017-06-27 15:43:06,830 Epoch[1] Batch [1120]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.274958,	
2017-06-27 15:43:10,919 Epoch[1] Batch [1130]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.274700,	
2017-06-27 15:43:15,109 Epoch[1] Batch [1140]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.274278,	
2017-06-27 15:43:19,282 Epoch[1] Batch [1150]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.274208,	
2017-06-27 15:43:23,518 Epoch[1] Batch [1160]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.273820,	
2017-06-27 15:43:27,749 Epoch[1] Batch [1170]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.273686,	
2017-06-27 15:43:31,957 Epoch[1] Batch [1180]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.273380,	
2017-06-27 15:43:36,166 Epoch[1] Batch [1190]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.272846,	
2017-06-27 15:43:40,502 Epoch[1] Batch [1200]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.272553,	
2017-06-27 15:43:44,724 Epoch[1] Batch [1210]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.272250,	
2017-06-27 15:43:49,071 Epoch[1] Batch [1220]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.271822,	
2017-06-27 15:43:53,149 Epoch[1] Batch [1230]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.271379,	
2017-06-27 15:43:57,367 Epoch[1] Batch [1240]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.270901,	
2017-06-27 15:44:01,608 Epoch[1] Batch [1250]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.270318,	
2017-06-27 15:44:05,806 Epoch[1] Batch [1260]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.270425,	
2017-06-27 15:44:10,095 Epoch[1] Batch [1270]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.270327,	
2017-06-27 15:44:14,380 Epoch[1] Batch [1280]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.270325,	
2017-06-27 15:44:18,714 Epoch[1] Batch [1290]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.270133,	
2017-06-27 15:44:23,276 Epoch[1] Batch [1300]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.270111,	
2017-06-27 15:44:27,629 Epoch[1] Batch [1310]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.269830,	
2017-06-27 15:44:32,064 Epoch[1] Batch [1320]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.269793,	
2017-06-27 15:44:36,381 Epoch[1] Batch [1330]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.269745,	
2017-06-27 15:44:40,575 Epoch[1] Batch [1340]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.269370,	
2017-06-27 15:44:44,924 Epoch[1] Batch [1350]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.268691,	
2017-06-27 15:44:49,273 Epoch[1] Batch [1360]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.268360,	
2017-06-27 15:44:53,530 Epoch[1] Batch [1370]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.268195,	
2017-06-27 15:44:57,994 Epoch[1] Batch [1380]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.267795,	
2017-06-27 15:45:02,254 Epoch[1] Batch [1390]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.267461,	
2017-06-27 15:45:06,502 Epoch[1] Batch [1400]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.267064,	
2017-06-27 15:45:10,770 Epoch[1] Batch [1410]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.266717,	
2017-06-27 15:45:15,083 Epoch[1] Batch [1420]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.266284,	
2017-06-27 15:45:19,372 Epoch[1] Batch [1430]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.265977,	
2017-06-27 15:45:23,683 Epoch[1] Batch [1440]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.265892,	
2017-06-27 15:45:28,030 Epoch[1] Batch [1450]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.265742,	
2017-06-27 15:45:32,286 Epoch[1] Batch [1460]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.265424,	
2017-06-27 15:45:36,524 Epoch[1] Batch [1470]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.265313,	
2017-06-27 15:45:40,767 Epoch[1] Batch [1480]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.264917,	
2017-06-27 15:45:43,353 Epoch[1] Train-FCNLogLoss=0.264788
2017-06-27 15:45:43,353 Epoch[1] Time cost=634.660
2017-06-27 15:45:44,141 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0002.params"
2017-06-27 15:45:45,825 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0002.states"
2017-06-27 15:45:50,736 Epoch[2] Batch [10]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.234441,	
2017-06-27 15:45:54,967 Epoch[2] Batch [20]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.246689,	
2017-06-27 15:45:59,206 Epoch[2] Batch [30]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.234815,	
2017-06-27 15:46:03,374 Epoch[2] Batch [40]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.221997,	
2017-06-27 15:46:07,725 Epoch[2] Batch [50]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.220585,	
2017-06-27 15:46:11,937 Epoch[2] Batch [60]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.223845,	
2017-06-27 15:46:16,140 Epoch[2] Batch [70]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.221591,	
2017-06-27 15:46:20,353 Epoch[2] Batch [80]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.224319,	
2017-06-27 15:46:24,547 Epoch[2] Batch [90]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.223718,	
2017-06-27 15:46:28,764 Epoch[2] Batch [100]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.220167,	
2017-06-27 15:46:33,025 Epoch[2] Batch [110]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.218978,	
2017-06-27 15:46:37,276 Epoch[2] Batch [120]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.221040,	
2017-06-27 15:46:41,547 Epoch[2] Batch [130]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.221232,	
2017-06-27 15:46:45,771 Epoch[2] Batch [140]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.220282,	
2017-06-27 15:46:50,015 Epoch[2] Batch [150]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.220737,	
2017-06-27 15:46:54,325 Epoch[2] Batch [160]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.220280,	
2017-06-27 15:46:58,618 Epoch[2] Batch [170]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.221064,	
2017-06-27 15:47:02,978 Epoch[2] Batch [180]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.221940,	
2017-06-27 15:47:07,240 Epoch[2] Batch [190]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.220899,	
2017-06-27 15:47:11,448 Epoch[2] Batch [200]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.220447,	
2017-06-27 15:47:15,666 Epoch[2] Batch [210]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.221206,	
2017-06-27 15:47:19,982 Epoch[2] Batch [220]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.223340,	
2017-06-27 15:47:24,262 Epoch[2] Batch [230]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.222697,	
2017-06-27 15:47:28,527 Epoch[2] Batch [240]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.222330,	
2017-06-27 15:47:32,807 Epoch[2] Batch [250]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.220784,	
2017-06-27 15:47:37,168 Epoch[2] Batch [260]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.219923,	
2017-06-27 15:47:41,344 Epoch[2] Batch [270]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.218971,	
2017-06-27 15:47:45,591 Epoch[2] Batch [280]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.217981,	
2017-06-27 15:47:49,786 Epoch[2] Batch [290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.218122,	
2017-06-27 15:47:53,973 Epoch[2] Batch [300]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.218015,	
2017-06-27 15:47:58,167 Epoch[2] Batch [310]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.216806,	
2017-06-27 15:48:02,348 Epoch[2] Batch [320]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.215856,	
2017-06-27 15:48:06,534 Epoch[2] Batch [330]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.216038,	
2017-06-27 15:48:10,794 Epoch[2] Batch [340]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.217916,	
2017-06-27 15:48:14,957 Epoch[2] Batch [350]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.217713,	
2017-06-27 15:48:19,167 Epoch[2] Batch [360]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.217503,	
2017-06-27 15:48:23,326 Epoch[2] Batch [370]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.217769,	
2017-06-27 15:48:27,478 Epoch[2] Batch [380]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.217483,	
2017-06-27 15:48:31,874 Epoch[2] Batch [390]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.216846,	
2017-06-27 15:48:36,033 Epoch[2] Batch [400]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.217068,	
2017-06-27 15:48:40,314 Epoch[2] Batch [410]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.218437,	
2017-06-27 15:48:44,546 Epoch[2] Batch [420]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.218041,	
2017-06-27 15:48:48,876 Epoch[2] Batch [430]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.218576,	
2017-06-27 15:48:53,143 Epoch[2] Batch [440]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.218864,	
2017-06-27 15:48:57,406 Epoch[2] Batch [450]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.219070,	
2017-06-27 15:49:01,600 Epoch[2] Batch [460]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.219944,	
2017-06-27 15:49:05,827 Epoch[2] Batch [470]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.219372,	
2017-06-27 15:49:10,239 Epoch[2] Batch [480]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.218885,	
2017-06-27 15:49:14,679 Epoch[2] Batch [490]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.218156,	
2017-06-27 15:49:19,041 Epoch[2] Batch [500]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.217441,	
2017-06-27 15:49:23,309 Epoch[2] Batch [510]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.217425,	
2017-06-27 15:49:27,764 Epoch[2] Batch [520]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.217711,	
2017-06-27 15:49:31,955 Epoch[2] Batch [530]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.217890,	
2017-06-27 15:49:36,277 Epoch[2] Batch [540]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.217344,	
2017-06-27 15:49:40,494 Epoch[2] Batch [550]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.218062,	
2017-06-27 15:49:44,753 Epoch[2] Batch [560]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.218286,	
2017-06-27 15:49:48,964 Epoch[2] Batch [570]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.219430,	
2017-06-27 15:49:53,232 Epoch[2] Batch [580]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.221169,	
2017-06-27 15:49:57,387 Epoch[2] Batch [590]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.222372,	
2017-06-27 15:50:01,570 Epoch[2] Batch [600]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.222390,	
2017-06-27 15:50:05,824 Epoch[2] Batch [610]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.222361,	
2017-06-27 15:50:10,070 Epoch[2] Batch [620]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.222139,	
2017-06-27 15:50:14,339 Epoch[2] Batch [630]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.221831,	
2017-06-27 15:50:18,573 Epoch[2] Batch [640]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.221607,	
2017-06-27 15:50:22,839 Epoch[2] Batch [650]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.221079,	
2017-06-27 15:50:27,143 Epoch[2] Batch [660]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.220989,	
2017-06-27 15:50:31,374 Epoch[2] Batch [670]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.221222,	
2017-06-27 15:50:35,550 Epoch[2] Batch [680]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.221185,	
2017-06-27 15:50:39,783 Epoch[2] Batch [690]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.221600,	
2017-06-27 15:50:44,785 Epoch[2] Batch [700]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.221574,	
2017-06-27 15:50:53,171 Epoch[2] Batch [710]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.221373,	
2017-06-27 15:51:01,996 Epoch[2] Batch [720]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.221045,	
2017-06-27 15:51:10,442 Epoch[2] Batch [730]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.220903,	
2017-06-27 15:51:19,598 Epoch[2] Batch [740]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.221271,	
2017-06-27 15:51:27,913 Epoch[2] Batch [750]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.221202,	
2017-06-27 15:51:37,316 Epoch[2] Batch [760]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.220944,	
2017-06-27 15:51:45,497 Epoch[2] Batch [770]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.221196,	
2017-06-27 15:51:53,661 Epoch[2] Batch [780]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.220893,	
2017-06-27 15:52:02,083 Epoch[2] Batch [790]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.221103,	
2017-06-27 15:52:10,210 Epoch[2] Batch [800]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.220745,	
2017-06-27 15:52:18,466 Epoch[2] Batch [810]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.220277,	
2017-06-27 15:52:26,908 Epoch[2] Batch [820]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.219908,	
2017-06-27 15:52:35,430 Epoch[2] Batch [830]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.219377,	
2017-06-27 15:52:43,851 Epoch[2] Batch [840]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.219565,	
2017-06-27 15:52:51,862 Epoch[2] Batch [850]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.219406,	
2017-06-27 15:52:59,985 Epoch[2] Batch [860]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.219067,	
2017-06-27 15:53:08,106 Epoch[2] Batch [870]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.219080,	
2017-06-27 15:53:16,395 Epoch[2] Batch [880]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.219512,	
2017-06-27 15:53:24,210 Epoch[2] Batch [890]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.219496,	
2017-06-27 15:53:32,154 Epoch[2] Batch [900]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.219706,	
2017-06-27 15:53:41,035 Epoch[2] Batch [910]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.220123,	
2017-06-27 15:53:49,371 Epoch[2] Batch [920]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.219812,	
2017-06-27 15:53:57,554 Epoch[2] Batch [930]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.219497,	
2017-06-27 15:54:06,121 Epoch[2] Batch [940]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.219516,	
2017-06-27 15:54:14,890 Epoch[2] Batch [950]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.219249,	
2017-06-27 15:54:22,956 Epoch[2] Batch [960]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.218688,	
2017-06-27 15:54:31,162 Epoch[2] Batch [970]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.218735,	
2017-06-27 15:54:39,281 Epoch[2] Batch [980]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.218409,	
2017-06-27 15:54:47,952 Epoch[2] Batch [990]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.218314,	
2017-06-27 15:54:56,050 Epoch[2] Batch [1000]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.218150,	
2017-06-27 15:55:04,221 Epoch[2] Batch [1010]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.217665,	
2017-06-27 15:55:11,874 Epoch[2] Batch [1020]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.217578,	
2017-06-27 15:55:19,593 Epoch[2] Batch [1030]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.217400,	
2017-06-27 15:55:26,801 Epoch[2] Batch [1040]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.217428,	
2017-06-27 15:55:33,444 Epoch[2] Batch [1050]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.217651,	
2017-06-27 15:55:39,554 Epoch[2] Batch [1060]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.217916,	
2017-06-27 15:55:44,936 Epoch[2] Batch [1070]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.217821,	
2017-06-27 15:55:50,309 Epoch[2] Batch [1080]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.218212,	
2017-06-27 15:55:55,293 Epoch[2] Batch [1090]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.218727,	
2017-06-27 15:56:00,199 Epoch[2] Batch [1100]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.219021,	
2017-06-27 15:56:05,024 Epoch[2] Batch [1110]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.219177,	
2017-06-27 15:56:09,904 Epoch[2] Batch [1120]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.218978,	
2017-06-27 15:56:14,636 Epoch[2] Batch [1130]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.218551,	
2017-06-27 15:56:19,233 Epoch[2] Batch [1140]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.218604,	
2017-06-27 15:56:24,050 Epoch[2] Batch [1150]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.218406,	
2017-06-27 15:56:28,860 Epoch[2] Batch [1160]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.217993,	
2017-06-27 15:56:33,600 Epoch[2] Batch [1170]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.217990,	
2017-06-27 15:56:38,444 Epoch[2] Batch [1180]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.217865,	
2017-06-27 15:56:43,362 Epoch[2] Batch [1190]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.217926,	
2017-06-27 15:56:48,222 Epoch[2] Batch [1200]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.217817,	
2017-06-27 15:56:53,020 Epoch[2] Batch [1210]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.217671,	
2017-06-27 15:56:57,636 Epoch[2] Batch [1220]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.217407,	
2017-06-27 15:57:02,379 Epoch[2] Batch [1230]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.217156,	
2017-06-27 15:57:07,000 Epoch[2] Batch [1240]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.217043,	
2017-06-27 15:57:11,449 Epoch[2] Batch [1250]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.216917,	
2017-06-27 15:57:15,900 Epoch[2] Batch [1260]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.216673,	
2017-06-27 15:57:20,341 Epoch[2] Batch [1270]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.216704,	
2017-06-27 15:57:24,952 Epoch[2] Batch [1280]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.216817,	
2017-06-27 15:57:29,468 Epoch[2] Batch [1290]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.216752,	
2017-06-27 15:57:34,100 Epoch[2] Batch [1300]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.216765,	
2017-06-27 15:57:38,689 Epoch[2] Batch [1310]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.217036,	
2017-06-27 15:57:43,180 Epoch[2] Batch [1320]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.217039,	
2017-06-27 15:57:47,792 Epoch[2] Batch [1330]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.216913,	
2017-06-27 15:57:52,332 Epoch[2] Batch [1340]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.216756,	
2017-06-27 15:57:56,809 Epoch[2] Batch [1350]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.216765,	
2017-06-27 15:58:01,597 Epoch[2] Batch [1360]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.216631,	
2017-06-27 15:58:06,095 Epoch[2] Batch [1370]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.216363,	
2017-06-27 15:58:10,901 Epoch[2] Batch [1380]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.216535,	
2017-06-27 15:58:15,332 Epoch[2] Batch [1390]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.216531,	
2017-06-27 15:58:19,850 Epoch[2] Batch [1400]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.216484,	
2017-06-27 15:58:24,287 Epoch[2] Batch [1410]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.216365,	
2017-06-27 15:58:28,814 Epoch[2] Batch [1420]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.216187,	
2017-06-27 15:58:33,333 Epoch[2] Batch [1430]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.216132,	
2017-06-27 15:58:37,871 Epoch[2] Batch [1440]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.216291,	
2017-06-27 15:58:42,312 Epoch[2] Batch [1450]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.216650,	
2017-06-27 15:58:46,732 Epoch[2] Batch [1460]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.216562,	
2017-06-27 15:58:51,177 Epoch[2] Batch [1470]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.216538,	
2017-06-27 15:58:55,488 Epoch[2] Batch [1480]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.216477,	
2017-06-27 15:58:58,090 Epoch[2] Train-FCNLogLoss=0.216475
2017-06-27 15:58:58,090 Epoch[2] Time cost=792.264
2017-06-27 15:58:58,933 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0003.params"
2017-06-27 15:59:00,592 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0003.states"
2017-06-27 15:59:05,562 Epoch[3] Batch [10]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.211879,	
2017-06-27 15:59:10,100 Epoch[3] Batch [20]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.210771,	
2017-06-27 15:59:14,481 Epoch[3] Batch [30]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.211099,	
2017-06-27 15:59:19,012 Epoch[3] Batch [40]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.205503,	
2017-06-27 15:59:23,422 Epoch[3] Batch [50]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.201084,	
2017-06-27 15:59:27,895 Epoch[3] Batch [60]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.201010,	
2017-06-27 15:59:32,444 Epoch[3] Batch [70]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.203213,	
2017-06-27 15:59:36,792 Epoch[3] Batch [80]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.205662,	
2017-06-27 15:59:41,148 Epoch[3] Batch [90]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.209529,	
2017-06-27 15:59:45,524 Epoch[3] Batch [100]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.209370,	
2017-06-27 15:59:50,030 Epoch[3] Batch [110]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.207100,	
2017-06-27 15:59:54,426 Epoch[3] Batch [120]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.205504,	
2017-06-27 15:59:58,808 Epoch[3] Batch [130]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.205361,	
2017-06-27 16:00:03,292 Epoch[3] Batch [140]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.203456,	
2017-06-27 16:00:07,851 Epoch[3] Batch [150]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.202057,	
2017-06-27 16:00:11,998 Epoch[3] Batch [160]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.199308,	
2017-06-27 16:00:16,305 Epoch[3] Batch [170]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.198439,	
2017-06-27 16:00:20,576 Epoch[3] Batch [180]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.198270,	
2017-06-27 16:00:24,832 Epoch[3] Batch [190]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.199005,	
2017-06-27 16:00:29,077 Epoch[3] Batch [200]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.198904,	
2017-06-27 16:00:33,341 Epoch[3] Batch [210]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.198382,	
2017-06-27 16:00:37,787 Epoch[3] Batch [220]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.197901,	
2017-06-27 16:00:42,171 Epoch[3] Batch [230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.197061,	
2017-06-27 16:00:46,487 Epoch[3] Batch [240]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.197206,	
2017-06-27 16:00:50,836 Epoch[3] Batch [250]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.196175,	
2017-06-27 16:00:55,310 Epoch[3] Batch [260]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.195336,	
2017-06-27 16:00:59,898 Epoch[3] Batch [270]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.195692,	
2017-06-27 16:01:04,661 Epoch[3] Batch [280]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.195776,	
2017-06-27 16:01:09,154 Epoch[3] Batch [290]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.195093,	
2017-06-27 16:01:13,954 Epoch[3] Batch [300]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.194570,	
2017-06-27 16:01:18,527 Epoch[3] Batch [310]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.193270,	
2017-06-27 16:01:23,068 Epoch[3] Batch [320]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.192381,	
2017-06-27 16:01:27,775 Epoch[3] Batch [330]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.191884,	
2017-06-27 16:01:32,620 Epoch[3] Batch [340]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.191016,	
2017-06-27 16:01:37,794 Epoch[3] Batch [350]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.190817,	
2017-06-27 16:01:42,974 Epoch[3] Batch [360]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.190428,	
2017-06-27 16:01:47,969 Epoch[3] Batch [370]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.190275,	
2017-06-27 16:01:52,915 Epoch[3] Batch [380]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.190743,	
2017-06-27 16:01:57,539 Epoch[3] Batch [390]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.190643,	
2017-06-27 16:02:02,457 Epoch[3] Batch [400]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.190855,	
2017-06-27 16:02:07,164 Epoch[3] Batch [410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.190424,	
2017-06-27 16:02:12,161 Epoch[3] Batch [420]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.189913,	
2017-06-27 16:02:17,018 Epoch[3] Batch [430]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.189844,	
2017-06-27 16:02:22,037 Epoch[3] Batch [440]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.190400,	
2017-06-27 16:02:26,910 Epoch[3] Batch [450]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.190850,	
2017-06-27 16:02:32,453 Epoch[3] Batch [460]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.190740,	
2017-06-27 16:02:38,098 Epoch[3] Batch [470]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.191013,	
2017-06-27 16:02:43,926 Epoch[3] Batch [480]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.190775,	
2017-06-27 16:02:49,555 Epoch[3] Batch [490]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.190482,	
2017-06-27 16:02:55,247 Epoch[3] Batch [500]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.190276,	
2017-06-27 16:03:01,051 Epoch[3] Batch [510]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.190670,	
2017-06-27 16:03:06,939 Epoch[3] Batch [520]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.190956,	
2017-06-27 16:03:12,979 Epoch[3] Batch [530]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.190985,	
2017-06-27 16:03:18,411 Epoch[3] Batch [540]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.191112,	
2017-06-27 16:03:24,376 Epoch[3] Batch [550]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.190819,	
2017-06-27 16:03:30,419 Epoch[3] Batch [560]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.191176,	
2017-06-27 16:03:36,540 Epoch[3] Batch [570]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.191649,	
2017-06-27 16:03:42,085 Epoch[3] Batch [580]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.191734,	
2017-06-27 16:03:48,073 Epoch[3] Batch [590]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.191569,	
2017-06-27 16:03:54,091 Epoch[3] Batch [600]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.191739,	
2017-06-27 16:03:59,789 Epoch[3] Batch [610]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.191689,	
2017-06-27 16:04:05,714 Epoch[3] Batch [620]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.191573,	
2017-06-27 16:04:11,909 Epoch[3] Batch [630]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.192293,	
2017-06-27 16:04:18,093 Epoch[3] Batch [640]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.192540,	
2017-06-27 16:04:24,302 Epoch[3] Batch [650]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.193913,	
2017-06-27 16:04:30,247 Epoch[3] Batch [660]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.194092,	
2017-06-27 16:04:36,102 Epoch[3] Batch [670]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.194594,	
2017-06-27 16:04:42,605 Epoch[3] Batch [680]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.194599,	
2017-06-27 16:04:48,955 Epoch[3] Batch [690]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.194528,	
2017-06-27 16:04:55,628 Epoch[3] Batch [700]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.194540,	
2017-06-27 16:05:02,082 Epoch[3] Batch [710]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.194511,	
2017-06-27 16:05:08,785 Epoch[3] Batch [720]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.194364,	
2017-06-27 16:05:14,965 Epoch[3] Batch [730]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.194197,	
2017-06-27 16:05:21,002 Epoch[3] Batch [740]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.194089,	
2017-06-27 16:05:27,423 Epoch[3] Batch [750]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.193668,	
2017-06-27 16:05:34,017 Epoch[3] Batch [760]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.193262,	
2017-06-27 16:05:40,905 Epoch[3] Batch [770]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.193146,	
2017-06-27 16:05:47,348 Epoch[3] Batch [780]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.193466,	
2017-06-27 16:05:53,486 Epoch[3] Batch [790]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.193813,	
2017-06-27 16:05:59,327 Epoch[3] Batch [800]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.193542,	
2017-06-27 16:06:05,201 Epoch[3] Batch [810]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.193546,	
2017-06-27 16:06:11,645 Epoch[3] Batch [820]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.193121,	
2017-06-27 16:06:18,022 Epoch[3] Batch [830]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.193180,	
2017-06-27 16:06:24,411 Epoch[3] Batch [840]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.193061,	
2017-06-27 16:06:31,149 Epoch[3] Batch [850]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.193010,	
2017-06-27 16:06:37,102 Epoch[3] Batch [860]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.192866,	
2017-06-27 16:06:43,923 Epoch[3] Batch [870]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.192895,	
2017-06-27 16:06:50,375 Epoch[3] Batch [880]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.192844,	
2017-06-27 16:06:56,983 Epoch[3] Batch [890]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.192819,	
2017-06-27 16:07:03,714 Epoch[3] Batch [900]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.192844,	
2017-06-27 16:07:10,000 Epoch[3] Batch [910]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.192659,	
2017-06-27 16:07:16,252 Epoch[3] Batch [920]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.192348,	
2017-06-27 16:07:22,362 Epoch[3] Batch [930]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.192242,	
2017-06-27 16:07:28,343 Epoch[3] Batch [940]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.192215,	
2017-06-27 16:07:34,453 Epoch[3] Batch [950]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.191999,	
2017-06-27 16:07:40,789 Epoch[3] Batch [960]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.191929,	
2017-06-27 16:07:47,142 Epoch[3] Batch [970]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.191814,	
2017-06-27 16:07:53,424 Epoch[3] Batch [980]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.192883,	
2017-06-27 16:08:00,025 Epoch[3] Batch [990]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.193528,	
2017-06-27 16:08:06,705 Epoch[3] Batch [1000]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.193714,	
2017-06-27 16:08:13,562 Epoch[3] Batch [1010]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.193957,	
2017-06-27 16:08:20,589 Epoch[3] Batch [1020]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.193937,	
2017-06-27 16:08:28,024 Epoch[3] Batch [1030]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.194075,	
2017-06-27 16:08:35,200 Epoch[3] Batch [1040]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.194540,	
2017-06-27 16:08:42,714 Epoch[3] Batch [1050]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.194420,	
2017-06-27 16:08:50,370 Epoch[3] Batch [1060]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.194674,	
2017-06-27 16:08:57,757 Epoch[3] Batch [1070]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.194746,	
2017-06-27 16:09:05,148 Epoch[3] Batch [1080]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.194629,	
2017-06-27 16:09:12,962 Epoch[3] Batch [1090]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.194422,	
2017-06-27 16:09:20,562 Epoch[3] Batch [1100]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.194413,	
2017-06-27 16:09:28,272 Epoch[3] Batch [1110]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.194186,	
2017-06-27 16:09:36,125 Epoch[3] Batch [1120]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.194122,	
2017-06-27 16:09:43,934 Epoch[3] Batch [1130]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.193854,	
2017-06-27 16:09:51,687 Epoch[3] Batch [1140]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.193730,	
2017-06-27 16:09:59,608 Epoch[3] Batch [1150]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.193781,	
2017-06-27 16:10:07,571 Epoch[3] Batch [1160]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.193922,	
2017-06-27 16:10:15,281 Epoch[3] Batch [1170]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.194254,	
2017-06-27 16:10:23,160 Epoch[3] Batch [1180]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.194163,	
2017-06-27 16:10:31,051 Epoch[3] Batch [1190]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.194199,	
2017-06-27 16:10:38,847 Epoch[3] Batch [1200]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.194405,	
2017-06-27 16:10:46,770 Epoch[3] Batch [1210]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.194431,	
2017-06-27 16:10:54,583 Epoch[3] Batch [1220]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.194456,	
2017-06-27 16:11:02,462 Epoch[3] Batch [1230]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.194352,	
2017-06-27 16:11:10,228 Epoch[3] Batch [1240]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.194170,	
2017-06-27 16:11:18,068 Epoch[3] Batch [1250]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.194000,	
2017-06-27 16:11:25,947 Epoch[3] Batch [1260]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.194043,	
2017-06-27 16:11:34,071 Epoch[3] Batch [1270]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.194008,	
2017-06-27 16:11:42,028 Epoch[3] Batch [1280]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.193863,	
2017-06-27 16:11:50,019 Epoch[3] Batch [1290]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.193703,	
2017-06-27 16:11:58,200 Epoch[3] Batch [1300]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.193762,	
2017-06-27 16:12:06,580 Epoch[3] Batch [1310]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.193832,	
2017-06-27 16:12:14,714 Epoch[3] Batch [1320]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.193925,	
2017-06-27 16:12:22,981 Epoch[3] Batch [1330]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.194059,	
2017-06-27 16:12:31,048 Epoch[3] Batch [1340]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.194074,	
2017-06-27 16:12:38,983 Epoch[3] Batch [1350]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.194202,	
2017-06-27 16:12:47,190 Epoch[3] Batch [1360]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.194444,	
2017-06-27 16:12:54,994 Epoch[3] Batch [1370]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.194002,	
2017-06-27 16:13:02,765 Epoch[3] Batch [1380]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.193964,	
2017-06-27 16:13:10,908 Epoch[3] Batch [1390]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.193864,	
2017-06-27 16:13:19,082 Epoch[3] Batch [1400]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.193652,	
2017-06-27 16:13:27,103 Epoch[3] Batch [1410]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.193636,	
2017-06-27 16:13:34,890 Epoch[3] Batch [1420]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.193727,	
2017-06-27 16:13:42,818 Epoch[3] Batch [1430]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.193579,	
2017-06-27 16:13:49,717 Epoch[3] Batch [1440]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.193521,	
2017-06-27 16:13:58,253 Epoch[3] Batch [1450]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.193456,	
2017-06-27 16:14:06,766 Epoch[3] Batch [1460]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.193474,	
2017-06-27 16:14:15,387 Epoch[3] Batch [1470]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.193605,	
2017-06-27 16:14:24,147 Epoch[3] Batch [1480]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.193903,	
2017-06-27 16:14:29,216 Epoch[3] Train-FCNLogLoss=0.193889
2017-06-27 16:14:29,217 Epoch[3] Time cost=928.624
2017-06-27 16:14:30,363 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0004.params"
2017-06-27 16:14:34,149 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0004.states"
2017-06-27 16:14:43,816 Epoch[4] Batch [10]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.179340,	
2017-06-27 16:14:52,757 Epoch[4] Batch [20]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.185074,	
2017-06-27 16:15:01,485 Epoch[4] Batch [30]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.180819,	
2017-06-27 16:15:09,965 Epoch[4] Batch [40]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.176696,	
2017-06-27 16:15:22,800 Epoch[4] Batch [50]	Speed: 3.12 samples/sec	Train-FCNLogLoss=0.176696,	
2017-06-27 16:15:33,246 Epoch[4] Batch [60]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.177509,	
2017-06-27 16:15:43,289 Epoch[4] Batch [70]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.181998,	
2017-06-27 16:15:53,382 Epoch[4] Batch [80]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.183016,	
2017-06-27 16:16:03,231 Epoch[4] Batch [90]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.182738,	
2017-06-27 16:16:13,191 Epoch[4] Batch [100]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.180153,	
2017-06-27 16:16:23,277 Epoch[4] Batch [110]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.179380,	
2017-06-27 16:16:33,890 Epoch[4] Batch [120]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.179237,	
2017-06-27 16:16:43,864 Epoch[4] Batch [130]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.179714,	
2017-06-27 16:16:54,019 Epoch[4] Batch [140]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.179370,	
2017-06-27 16:17:02,940 Epoch[4] Batch [150]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.178803,	
2017-06-27 16:17:12,130 Epoch[4] Batch [160]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.178563,	
2017-06-27 16:17:21,711 Epoch[4] Batch [170]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.178933,	
2017-06-27 16:17:31,653 Epoch[4] Batch [180]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.179204,	
2017-06-27 16:17:41,826 Epoch[4] Batch [190]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.178880,	
2017-06-27 16:17:51,532 Epoch[4] Batch [200]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.178579,	
2017-06-27 16:18:00,350 Epoch[4] Batch [210]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.177979,	
2017-06-27 16:18:09,535 Epoch[4] Batch [220]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.177488,	
2017-06-27 16:18:19,400 Epoch[4] Batch [230]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.178802,	
2017-06-27 16:18:29,042 Epoch[4] Batch [240]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.179261,	
2017-06-27 16:18:37,837 Epoch[4] Batch [250]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.179731,	
2017-06-27 16:18:47,277 Epoch[4] Batch [260]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.180418,	
2017-06-27 16:18:56,615 Epoch[4] Batch [270]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.180968,	
2017-06-27 16:19:05,349 Epoch[4] Batch [280]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.180218,	
2017-06-27 16:19:14,746 Epoch[4] Batch [290]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.179737,	
2017-06-27 16:19:23,799 Epoch[4] Batch [300]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.179005,	
2017-06-27 16:19:32,853 Epoch[4] Batch [310]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.179144,	
2017-06-27 16:19:41,767 Epoch[4] Batch [320]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.179820,	
2017-06-27 16:19:50,786 Epoch[4] Batch [330]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.180538,	
2017-06-27 16:19:59,310 Epoch[4] Batch [340]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.181894,	
2017-06-27 16:20:08,524 Epoch[4] Batch [350]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.181286,	
2017-06-27 16:20:15,923 Epoch[4] Batch [360]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.181244,	
2017-06-27 16:20:23,315 Epoch[4] Batch [370]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.180635,	
2017-06-27 16:20:30,215 Epoch[4] Batch [380]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.179709,	
2017-06-27 16:20:36,451 Epoch[4] Batch [390]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.179296,	
2017-06-27 16:20:42,376 Epoch[4] Batch [400]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.179208,	
2017-06-27 16:20:48,231 Epoch[4] Batch [410]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.179373,	
2017-06-27 16:20:54,501 Epoch[4] Batch [420]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.179857,	
2017-06-27 16:21:00,797 Epoch[4] Batch [430]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.179941,	
2017-06-27 16:21:06,415 Epoch[4] Batch [440]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.179197,	
2017-06-27 16:21:12,788 Epoch[4] Batch [450]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.178997,	
2017-06-27 16:21:18,436 Epoch[4] Batch [460]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.179192,	
2017-06-27 16:21:24,507 Epoch[4] Batch [470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.178935,	
2017-06-27 16:21:30,614 Epoch[4] Batch [480]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.179460,	
2017-06-27 16:21:36,380 Epoch[4] Batch [490]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.179612,	
2017-06-27 16:21:42,892 Epoch[4] Batch [500]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.180027,	
2017-06-27 16:21:49,249 Epoch[4] Batch [510]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.180086,	
2017-06-27 16:21:55,393 Epoch[4] Batch [520]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.179973,	
2017-06-27 16:22:01,435 Epoch[4] Batch [530]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.180205,	
2017-06-27 16:22:06,790 Epoch[4] Batch [540]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.180515,	
2017-06-27 16:22:12,864 Epoch[4] Batch [550]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.180117,	
2017-06-27 16:22:18,524 Epoch[4] Batch [560]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.180086,	
2017-06-27 16:22:24,475 Epoch[4] Batch [570]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.180087,	
2017-06-27 16:22:30,268 Epoch[4] Batch [580]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.180362,	
2017-06-27 16:22:36,317 Epoch[4] Batch [590]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.179763,	
2017-06-27 16:22:41,942 Epoch[4] Batch [600]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.179666,	
2017-06-27 16:22:47,557 Epoch[4] Batch [610]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.179394,	
2017-06-27 16:22:53,544 Epoch[4] Batch [620]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.179414,	
2017-06-27 16:22:59,172 Epoch[4] Batch [630]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.180051,	
2017-06-27 16:23:04,779 Epoch[4] Batch [640]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.180169,	
2017-06-27 16:23:10,907 Epoch[4] Batch [650]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.180353,	
2017-06-27 16:23:17,202 Epoch[4] Batch [660]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.179859,	
2017-06-27 16:23:24,473 Epoch[4] Batch [670]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.180164,	
2017-06-27 16:23:31,383 Epoch[4] Batch [680]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.180016,	
2017-06-27 16:23:38,295 Epoch[4] Batch [690]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.180008,	
2017-06-27 16:23:46,099 Epoch[4] Batch [700]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.179851,	
2017-06-27 16:23:53,463 Epoch[4] Batch [710]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.179541,	
2017-06-27 16:24:01,434 Epoch[4] Batch [720]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.180670,	
2017-06-27 16:24:09,223 Epoch[4] Batch [730]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.180728,	
2017-06-27 16:24:17,094 Epoch[4] Batch [740]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.180699,	
2017-06-27 16:24:24,891 Epoch[4] Batch [750]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.180794,	
2017-06-27 16:24:32,756 Epoch[4] Batch [760]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.181045,	
2017-06-27 16:24:40,576 Epoch[4] Batch [770]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.181118,	
2017-06-27 16:24:48,626 Epoch[4] Batch [780]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.181316,	
2017-06-27 16:24:56,652 Epoch[4] Batch [790]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.181166,	
2017-06-27 16:25:04,657 Epoch[4] Batch [800]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.181271,	
2017-06-27 16:25:12,607 Epoch[4] Batch [810]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.180970,	
2017-06-27 16:25:20,489 Epoch[4] Batch [820]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.181051,	
2017-06-27 16:25:28,133 Epoch[4] Batch [830]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.180876,	
2017-06-27 16:25:35,956 Epoch[4] Batch [840]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.180604,	
2017-06-27 16:25:43,618 Epoch[4] Batch [850]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.180695,	
2017-06-27 16:25:52,002 Epoch[4] Batch [860]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.180700,	
2017-06-27 16:25:59,796 Epoch[4] Batch [870]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.180811,	
2017-06-27 16:26:07,668 Epoch[4] Batch [880]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.180541,	
2017-06-27 16:26:15,627 Epoch[4] Batch [890]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.180664,	
2017-06-27 16:26:23,312 Epoch[4] Batch [900]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.180645,	
2017-06-27 16:26:30,881 Epoch[4] Batch [910]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.180610,	
2017-06-27 16:26:38,898 Epoch[4] Batch [920]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.180943,	
2017-06-27 16:26:46,743 Epoch[4] Batch [930]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.180772,	
2017-06-27 16:26:54,596 Epoch[4] Batch [940]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.180690,	
2017-06-27 16:27:02,529 Epoch[4] Batch [950]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.180945,	
2017-06-27 16:27:10,560 Epoch[4] Batch [960]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.180982,	
2017-06-27 16:27:18,958 Epoch[4] Batch [970]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.181172,	
2017-06-27 16:27:27,129 Epoch[4] Batch [980]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.180984,	
2017-06-27 16:27:35,051 Epoch[4] Batch [990]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.181012,	
2017-06-27 16:27:42,756 Epoch[4] Batch [1000]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.180973,	
2017-06-27 16:27:50,832 Epoch[4] Batch [1010]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.180610,	
2017-06-27 16:27:59,118 Epoch[4] Batch [1020]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.180525,	
2017-06-27 16:28:07,338 Epoch[4] Batch [1030]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.180667,	
2017-06-27 16:28:15,548 Epoch[4] Batch [1040]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.180865,	
2017-06-27 16:28:23,507 Epoch[4] Batch [1050]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.180707,	
2017-06-27 16:28:31,439 Epoch[4] Batch [1060]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.180707,	
2017-06-27 16:28:39,155 Epoch[4] Batch [1070]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.180796,	
2017-06-27 16:28:46,972 Epoch[4] Batch [1080]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.180566,	
2017-06-27 16:28:54,722 Epoch[4] Batch [1090]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.180283,	
2017-06-27 16:29:02,641 Epoch[4] Batch [1100]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.180195,	
2017-06-27 16:29:10,694 Epoch[4] Batch [1110]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.180220,	
2017-06-27 16:29:18,816 Epoch[4] Batch [1120]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.179901,	
2017-06-27 16:29:26,882 Epoch[4] Batch [1130]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.180280,	
2017-06-27 16:29:35,120 Epoch[4] Batch [1140]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.180392,	
2017-06-27 16:29:43,100 Epoch[4] Batch [1150]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.180484,	
2017-06-27 16:29:51,296 Epoch[4] Batch [1160]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.180799,	
2017-06-27 16:29:59,387 Epoch[4] Batch [1170]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.180841,	
2017-06-27 16:30:07,611 Epoch[4] Batch [1180]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.180820,	
2017-06-27 16:30:15,767 Epoch[4] Batch [1190]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.180787,	
2017-06-27 16:30:23,698 Epoch[4] Batch [1200]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.180783,	
2017-06-27 16:30:31,425 Epoch[4] Batch [1210]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.180907,	
2017-06-27 16:30:39,448 Epoch[4] Batch [1220]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.180959,	
2017-06-27 16:30:47,398 Epoch[4] Batch [1230]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.180969,	
2017-06-27 16:30:55,214 Epoch[4] Batch [1240]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.180949,	
2017-06-27 16:31:03,315 Epoch[4] Batch [1250]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.180915,	
2017-06-27 16:31:11,126 Epoch[4] Batch [1260]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.180735,	
2017-06-27 16:31:18,988 Epoch[4] Batch [1270]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.180604,	
2017-06-27 16:31:27,341 Epoch[4] Batch [1280]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.180617,	
2017-06-27 16:31:35,535 Epoch[4] Batch [1290]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.180530,	
2017-06-27 16:31:43,882 Epoch[4] Batch [1300]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.180403,	
2017-06-27 16:31:51,854 Epoch[4] Batch [1310]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.180189,	
2017-06-27 16:32:00,023 Epoch[4] Batch [1320]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.180035,	
2017-06-27 16:32:08,159 Epoch[4] Batch [1330]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.179940,	
2017-06-27 16:32:16,196 Epoch[4] Batch [1340]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.179845,	
2017-06-27 16:32:24,394 Epoch[4] Batch [1350]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.179784,	
2017-06-27 16:32:32,744 Epoch[4] Batch [1360]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.179786,	
2017-06-27 16:32:41,068 Epoch[4] Batch [1370]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.179771,	
2017-06-27 16:32:49,467 Epoch[4] Batch [1380]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.179656,	
2017-06-27 16:32:57,420 Epoch[4] Batch [1390]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.179756,	
2017-06-27 16:33:05,395 Epoch[4] Batch [1400]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.179708,	
2017-06-27 16:33:13,346 Epoch[4] Batch [1410]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.179603,	
2017-06-27 16:33:21,098 Epoch[4] Batch [1420]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.179526,	
2017-06-27 16:33:29,464 Epoch[4] Batch [1430]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.179358,	
2017-06-27 16:33:37,603 Epoch[4] Batch [1440]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.179116,	
2017-06-27 16:33:45,909 Epoch[4] Batch [1450]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.178979,	
2017-06-27 16:33:52,276 Epoch[4] Batch [1460]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.179215,	
2017-06-27 16:33:58,797 Epoch[4] Batch [1470]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.179036,	
2017-06-27 16:34:05,205 Epoch[4] Batch [1480]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.178996,	
2017-06-27 16:34:09,085 Epoch[4] Train-FCNLogLoss=0.178870
2017-06-27 16:34:09,085 Epoch[4] Time cost=1174.935
2017-06-27 16:34:10,018 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0005.params"
2017-06-27 16:34:11,997 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0005.states"
2017-06-27 16:34:19,032 Epoch[5] Batch [10]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.173051,	
2017-06-27 16:34:25,593 Epoch[5] Batch [20]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.188465,	
2017-06-27 16:34:32,035 Epoch[5] Batch [30]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.186226,	
2017-06-27 16:34:38,500 Epoch[5] Batch [40]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.188032,	
2017-06-27 16:34:44,869 Epoch[5] Batch [50]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.179065,	
2017-06-27 16:34:51,188 Epoch[5] Batch [60]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.181573,	
2017-06-27 16:34:57,425 Epoch[5] Batch [70]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.181040,	
2017-06-27 16:35:03,730 Epoch[5] Batch [80]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.181065,	
2017-06-27 16:35:10,483 Epoch[5] Batch [90]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.182654,	
2017-06-27 16:35:16,895 Epoch[5] Batch [100]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.184531,	
2017-06-27 16:35:23,254 Epoch[5] Batch [110]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.183329,	
2017-06-27 16:35:29,570 Epoch[5] Batch [120]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.182746,	
2017-06-27 16:35:36,382 Epoch[5] Batch [130]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.180774,	
2017-06-27 16:35:43,173 Epoch[5] Batch [140]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.179955,	
2017-06-27 16:35:49,699 Epoch[5] Batch [150]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.180000,	
2017-06-27 16:35:56,248 Epoch[5] Batch [160]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.179317,	
2017-06-27 16:36:02,812 Epoch[5] Batch [170]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.178593,	
2017-06-27 16:36:09,498 Epoch[5] Batch [180]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.178347,	
2017-06-27 16:36:15,832 Epoch[5] Batch [190]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.177745,	
2017-06-27 16:36:22,147 Epoch[5] Batch [200]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.177339,	
2017-06-27 16:36:28,607 Epoch[5] Batch [210]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.177765,	
2017-06-27 16:36:34,979 Epoch[5] Batch [220]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.176636,	
2017-06-27 16:36:41,526 Epoch[5] Batch [230]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.176356,	
2017-06-27 16:36:47,770 Epoch[5] Batch [240]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.175568,	
2017-06-27 16:36:54,142 Epoch[5] Batch [250]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.174522,	
2017-06-27 16:37:00,348 Epoch[5] Batch [260]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.173865,	
2017-06-27 16:37:06,699 Epoch[5] Batch [270]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.174234,	
2017-06-27 16:37:13,030 Epoch[5] Batch [280]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.174859,	
2017-06-27 16:37:19,608 Epoch[5] Batch [290]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.174496,	
2017-06-27 16:37:26,916 Epoch[5] Batch [300]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.175505,	
2017-06-27 16:37:33,456 Epoch[5] Batch [310]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.175432,	
2017-06-27 16:37:39,667 Epoch[5] Batch [320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.174830,	
2017-06-27 16:37:45,869 Epoch[5] Batch [330]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.174629,	
2017-06-27 16:37:52,565 Epoch[5] Batch [340]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.174370,	
2017-06-27 16:37:59,585 Epoch[5] Batch [350]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.174528,	
2017-06-27 16:38:06,726 Epoch[5] Batch [360]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.174749,	
2017-06-27 16:38:12,880 Epoch[5] Batch [370]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.174647,	
2017-06-27 16:38:19,514 Epoch[5] Batch [380]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.174389,	
2017-06-27 16:38:26,147 Epoch[5] Batch [390]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.174259,	
2017-06-27 16:38:32,642 Epoch[5] Batch [400]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.174532,	
2017-06-27 16:38:39,284 Epoch[5] Batch [410]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.174424,	
2017-06-27 16:38:45,352 Epoch[5] Batch [420]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.173735,	
2017-06-27 16:38:51,529 Epoch[5] Batch [430]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.173719,	
2017-06-27 16:38:57,406 Epoch[5] Batch [440]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.173454,	
2017-06-27 16:39:03,285 Epoch[5] Batch [450]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.173389,	
2017-06-27 16:39:09,447 Epoch[5] Batch [460]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.173038,	
2017-06-27 16:39:15,316 Epoch[5] Batch [470]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.172717,	
2017-06-27 16:39:21,067 Epoch[5] Batch [480]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.172537,	
2017-06-27 16:39:26,729 Epoch[5] Batch [490]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.172205,	
2017-06-27 16:39:32,231 Epoch[5] Batch [500]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.172163,	
2017-06-27 16:39:37,393 Epoch[5] Batch [510]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.172605,	
2017-06-27 16:39:43,150 Epoch[5] Batch [520]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.172037,	
2017-06-27 16:39:48,622 Epoch[5] Batch [530]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.172540,	
2017-06-27 16:39:54,349 Epoch[5] Batch [540]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.172798,	
2017-06-27 16:39:59,951 Epoch[5] Batch [550]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.174252,	
2017-06-27 16:40:05,634 Epoch[5] Batch [560]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.175649,	
2017-06-27 16:40:11,019 Epoch[5] Batch [570]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.176787,	
2017-06-27 16:40:16,825 Epoch[5] Batch [580]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.176688,	
2017-06-27 16:40:22,621 Epoch[5] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.176350,	
2017-06-27 16:40:28,925 Epoch[5] Batch [600]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.176462,	
2017-06-27 16:40:35,624 Epoch[5] Batch [610]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.176236,	
2017-06-27 16:40:42,664 Epoch[5] Batch [620]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.175854,	
2017-06-27 16:40:50,228 Epoch[5] Batch [630]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.175498,	
2017-06-27 16:40:57,975 Epoch[5] Batch [640]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.175412,	
2017-06-27 16:41:05,963 Epoch[5] Batch [650]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.175013,	
2017-06-27 16:41:14,343 Epoch[5] Batch [660]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.174943,	
2017-06-27 16:41:23,185 Epoch[5] Batch [670]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.174981,	
2017-06-27 16:41:32,048 Epoch[5] Batch [680]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.174929,	
2017-06-27 16:41:41,264 Epoch[5] Batch [690]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.175454,	
2017-06-27 16:41:50,236 Epoch[5] Batch [700]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.175432,	
2017-06-27 16:41:59,308 Epoch[5] Batch [710]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.175546,	
2017-06-27 16:42:08,244 Epoch[5] Batch [720]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.175496,	
2017-06-27 16:42:16,959 Epoch[5] Batch [730]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.175316,	
2017-06-27 16:42:25,742 Epoch[5] Batch [740]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.175124,	
2017-06-27 16:42:34,820 Epoch[5] Batch [750]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.174634,	
2017-06-27 16:42:44,095 Epoch[5] Batch [760]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.174434,	
2017-06-27 16:42:52,913 Epoch[5] Batch [770]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.175109,	
2017-06-27 16:43:01,841 Epoch[5] Batch [780]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.175277,	
2017-06-27 16:43:09,643 Epoch[5] Batch [790]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.175078,	
2017-06-27 16:43:17,477 Epoch[5] Batch [800]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.174920,	
2017-06-27 16:43:25,556 Epoch[5] Batch [810]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.174824,	
2017-06-27 16:43:33,785 Epoch[5] Batch [820]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.174882,	
2017-06-27 16:43:41,971 Epoch[5] Batch [830]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.174864,	
2017-06-27 16:43:49,990 Epoch[5] Batch [840]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.174842,	
2017-06-27 16:43:58,172 Epoch[5] Batch [850]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.174750,	
2017-06-27 16:44:06,523 Epoch[5] Batch [860]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.174736,	
2017-06-27 16:44:14,830 Epoch[5] Batch [870]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.174666,	
2017-06-27 16:44:23,852 Epoch[5] Batch [880]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.174463,	
2017-06-27 16:44:32,376 Epoch[5] Batch [890]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.174261,	
2017-06-27 16:44:41,639 Epoch[5] Batch [900]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.174308,	
2017-06-27 16:44:50,424 Epoch[5] Batch [910]	Speed: 4.55 samples/sec	Train-FCNLogLoss=0.174210,	
2017-06-27 16:44:59,183 Epoch[5] Batch [920]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.173983,	
2017-06-27 16:45:07,988 Epoch[5] Batch [930]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.173942,	
2017-06-27 16:45:16,550 Epoch[5] Batch [940]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.173872,	
2017-06-27 16:45:25,005 Epoch[5] Batch [950]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.173934,	
2017-06-27 16:45:33,768 Epoch[5] Batch [960]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.173728,	
2017-06-27 16:45:42,259 Epoch[5] Batch [970]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.173568,	
2017-06-27 16:45:50,514 Epoch[5] Batch [980]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.173335,	
2017-06-27 16:45:59,340 Epoch[5] Batch [990]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.173569,	
2017-06-27 16:46:08,401 Epoch[5] Batch [1000]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.173623,	
2017-06-27 16:46:16,739 Epoch[5] Batch [1010]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.173419,	
2017-06-27 16:46:25,904 Epoch[5] Batch [1020]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.173280,	
2017-06-27 16:46:34,279 Epoch[5] Batch [1030]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.173202,	
2017-06-27 16:46:43,017 Epoch[5] Batch [1040]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.173293,	
2017-06-27 16:46:51,680 Epoch[5] Batch [1050]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.173378,	
2017-06-27 16:47:00,493 Epoch[5] Batch [1060]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.173516,	
2017-06-27 16:47:08,766 Epoch[5] Batch [1070]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.173454,	
2017-06-27 16:47:17,016 Epoch[5] Batch [1080]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.173287,	
2017-06-27 16:47:25,269 Epoch[5] Batch [1090]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.173106,	
2017-06-27 16:47:33,508 Epoch[5] Batch [1100]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.173245,	
2017-06-27 16:47:42,175 Epoch[5] Batch [1110]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.173051,	
2017-06-27 16:47:50,512 Epoch[5] Batch [1120]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.173072,	
2017-06-27 16:47:58,815 Epoch[5] Batch [1130]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.173009,	
2017-06-27 16:48:07,301 Epoch[5] Batch [1140]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.172803,	
2017-06-27 16:48:15,919 Epoch[5] Batch [1150]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.172680,	
2017-06-27 16:48:23,906 Epoch[5] Batch [1160]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.172527,	
2017-06-27 16:48:33,093 Epoch[5] Batch [1170]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.172400,	
2017-06-27 16:48:41,137 Epoch[5] Batch [1180]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.172288,	
2017-06-27 16:48:49,126 Epoch[5] Batch [1190]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.172267,	
2017-06-27 16:48:57,615 Epoch[5] Batch [1200]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.172306,	
2017-06-27 16:49:06,245 Epoch[5] Batch [1210]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.172283,	
2017-06-27 16:49:15,208 Epoch[5] Batch [1220]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.172162,	
2017-06-27 16:49:23,980 Epoch[5] Batch [1230]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.172058,	
2017-06-27 16:49:32,812 Epoch[5] Batch [1240]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.172053,	
2017-06-27 16:49:41,665 Epoch[5] Batch [1250]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.171906,	
2017-06-27 16:49:50,341 Epoch[5] Batch [1260]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.171807,	
2017-06-27 16:49:59,379 Epoch[5] Batch [1270]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.171736,	
2017-06-27 16:50:08,055 Epoch[5] Batch [1280]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.171519,	
2017-06-27 16:50:16,786 Epoch[5] Batch [1290]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.171351,	
2017-06-27 16:50:25,505 Epoch[5] Batch [1300]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.171104,	
2017-06-27 16:50:34,637 Epoch[5] Batch [1310]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.171171,	
2017-06-27 16:50:43,754 Epoch[5] Batch [1320]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.171235,	
2017-06-27 16:50:53,613 Epoch[5] Batch [1330]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.171173,	
2017-06-27 16:51:02,074 Epoch[5] Batch [1340]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.171219,	
2017-06-27 16:51:11,266 Epoch[5] Batch [1350]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.171208,	
2017-06-27 16:51:20,005 Epoch[5] Batch [1360]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.171114,	
2017-06-27 16:51:28,869 Epoch[5] Batch [1370]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.170904,	
2017-06-27 16:51:37,921 Epoch[5] Batch [1380]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.170760,	
2017-06-27 16:51:46,793 Epoch[5] Batch [1390]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.170743,	
2017-06-27 16:51:55,603 Epoch[5] Batch [1400]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.170554,	
2017-06-27 16:52:04,900 Epoch[5] Batch [1410]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.170545,	
2017-06-27 16:52:13,556 Epoch[5] Batch [1420]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.170588,	
2017-06-27 16:52:22,473 Epoch[5] Batch [1430]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.170708,	
2017-06-27 16:52:31,186 Epoch[5] Batch [1440]	Speed: 4.59 samples/sec	Train-FCNLogLoss=0.170464,	
2017-06-27 16:52:40,666 Epoch[5] Batch [1450]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.170442,	
2017-06-27 16:52:49,741 Epoch[5] Batch [1460]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.170439,	
2017-06-27 16:52:58,715 Epoch[5] Batch [1470]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.170511,	
2017-06-27 16:53:07,496 Epoch[5] Batch [1480]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.170343,	
2017-06-27 16:53:12,811 Epoch[5] Train-FCNLogLoss=0.170243
2017-06-27 16:53:12,812 Epoch[5] Time cost=1140.814
2017-06-27 16:53:13,966 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0006.params"
2017-06-27 16:53:17,892 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0006.states"
2017-06-27 16:53:27,565 Epoch[6] Batch [10]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.147778,	
2017-06-27 16:53:35,576 Epoch[6] Batch [20]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.150572,	
2017-06-27 16:53:43,659 Epoch[6] Batch [30]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.161339,	
2017-06-27 16:53:51,533 Epoch[6] Batch [40]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.155447,	
2017-06-27 16:53:59,579 Epoch[6] Batch [50]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.153344,	
2017-06-27 16:54:07,596 Epoch[6] Batch [60]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.152216,	
2017-06-27 16:54:15,502 Epoch[6] Batch [70]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.150330,	
2017-06-27 16:54:23,926 Epoch[6] Batch [80]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.150298,	
2017-06-27 16:54:32,337 Epoch[6] Batch [90]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.154116,	
2017-06-27 16:54:40,191 Epoch[6] Batch [100]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.153618,	
2017-06-27 16:54:48,162 Epoch[6] Batch [110]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.153134,	
2017-06-27 16:54:56,312 Epoch[6] Batch [120]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.152006,	
2017-06-27 16:55:04,507 Epoch[6] Batch [130]	Speed: 4.88 samples/sec	Train-FCNLogLoss=0.152312,	
2017-06-27 16:55:12,770 Epoch[6] Batch [140]	Speed: 4.84 samples/sec	Train-FCNLogLoss=0.152645,	
2017-06-27 16:55:20,824 Epoch[6] Batch [150]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.152752,	
2017-06-27 16:55:29,236 Epoch[6] Batch [160]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.152829,	
2017-06-27 16:55:37,644 Epoch[6] Batch [170]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.152545,	
2017-06-27 16:55:45,720 Epoch[6] Batch [180]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.153091,	
2017-06-27 16:55:54,251 Epoch[6] Batch [190]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.153395,	
2017-06-27 16:56:03,070 Epoch[6] Batch [200]	Speed: 4.54 samples/sec	Train-FCNLogLoss=0.152583,	
2017-06-27 16:56:12,210 Epoch[6] Batch [210]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.151814,	
2017-06-27 16:56:21,244 Epoch[6] Batch [220]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.152587,	
2017-06-27 16:56:30,411 Epoch[6] Batch [230]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.154663,	
2017-06-27 16:56:39,979 Epoch[6] Batch [240]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.155125,	
2017-06-27 16:56:49,665 Epoch[6] Batch [250]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.155362,	
2017-06-27 16:56:59,275 Epoch[6] Batch [260]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.155607,	
2017-06-27 16:57:08,989 Epoch[6] Batch [270]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.155688,	
2017-06-27 16:57:17,883 Epoch[6] Batch [280]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.156812,	
2017-06-27 16:57:27,066 Epoch[6] Batch [290]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.156903,	
2017-06-27 16:57:36,424 Epoch[6] Batch [300]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.156957,	
2017-06-27 16:57:45,003 Epoch[6] Batch [310]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.156630,	
2017-06-27 16:57:53,373 Epoch[6] Batch [320]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.156279,	
2017-06-27 16:58:01,588 Epoch[6] Batch [330]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.156632,	
2017-06-27 16:58:10,161 Epoch[6] Batch [340]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.157232,	
2017-06-27 16:58:18,859 Epoch[6] Batch [350]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.157589,	
2017-06-27 16:58:27,832 Epoch[6] Batch [360]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.157361,	
2017-06-27 16:58:36,596 Epoch[6] Batch [370]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.156982,	
2017-06-27 16:58:46,827 Epoch[6] Batch [380]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.157161,	
2017-06-27 16:58:55,667 Epoch[6] Batch [390]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.157299,	
2017-06-27 16:59:05,289 Epoch[6] Batch [400]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.157812,	
2017-06-27 16:59:14,480 Epoch[6] Batch [410]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.157924,	
2017-06-27 16:59:22,598 Epoch[6] Batch [420]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.157678,	
2017-06-27 16:59:32,680 Epoch[6] Batch [430]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.157610,	
2017-06-27 16:59:41,011 Epoch[6] Batch [440]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.157694,	
2017-06-27 16:59:50,259 Epoch[6] Batch [450]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.157177,	
2017-06-27 16:59:59,390 Epoch[6] Batch [460]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.157134,	
2017-06-27 17:00:08,294 Epoch[6] Batch [470]	Speed: 4.49 samples/sec	Train-FCNLogLoss=0.157370,	
2017-06-27 17:00:17,655 Epoch[6] Batch [480]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.157333,	
2017-06-27 17:00:27,331 Epoch[6] Batch [490]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.157203,	
2017-06-27 17:00:36,972 Epoch[6] Batch [500]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.157032,	
2017-06-27 17:00:46,710 Epoch[6] Batch [510]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.156930,	
2017-06-27 17:00:56,817 Epoch[6] Batch [520]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.156613,	
2017-06-27 17:01:06,387 Epoch[6] Batch [530]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.157071,	
2017-06-27 17:01:15,720 Epoch[6] Batch [540]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.156914,	
2017-06-27 17:01:26,003 Epoch[6] Batch [550]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.156845,	
2017-06-27 17:01:36,008 Epoch[6] Batch [560]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.157319,	
2017-06-27 17:01:46,182 Epoch[6] Batch [570]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.157422,	
2017-06-27 17:01:56,867 Epoch[6] Batch [580]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.157224,	
2017-06-27 17:02:06,559 Epoch[6] Batch [590]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.157473,	
2017-06-27 17:02:16,507 Epoch[6] Batch [600]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.157325,	
2017-06-27 17:02:25,872 Epoch[6] Batch [610]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.157195,	
2017-06-27 17:02:35,861 Epoch[6] Batch [620]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.157224,	
2017-06-27 17:02:45,385 Epoch[6] Batch [630]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.157405,	
2017-06-27 17:02:55,916 Epoch[6] Batch [640]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.157549,	
2017-06-27 17:03:05,535 Epoch[6] Batch [650]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.157365,	
2017-06-27 17:03:15,647 Epoch[6] Batch [660]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.157263,	
2017-06-27 17:03:25,459 Epoch[6] Batch [670]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.157024,	
2017-06-27 17:03:35,844 Epoch[6] Batch [680]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.156979,	
2017-06-27 17:03:46,869 Epoch[6] Batch [690]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.157073,	
2017-06-27 17:03:57,103 Epoch[6] Batch [700]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.157142,	
2017-06-27 17:04:07,179 Epoch[6] Batch [710]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.157063,	
2017-06-27 17:04:17,061 Epoch[6] Batch [720]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.157294,	
2017-06-27 17:04:27,591 Epoch[6] Batch [730]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.157291,	
2017-06-27 17:04:36,882 Epoch[6] Batch [740]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.157235,	
2017-06-27 17:04:46,570 Epoch[6] Batch [750]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.157010,	
2017-06-27 17:04:56,778 Epoch[6] Batch [760]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.156716,	
2017-06-27 17:05:07,278 Epoch[6] Batch [770]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.156606,	
2017-06-27 17:05:17,313 Epoch[6] Batch [780]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.156487,	
2017-06-27 17:05:27,826 Epoch[6] Batch [790]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.156408,	
2017-06-27 17:05:38,196 Epoch[6] Batch [800]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.156625,	
2017-06-27 17:05:49,645 Epoch[6] Batch [810]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.156549,	
2017-06-27 17:06:00,770 Epoch[6] Batch [820]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.156502,	
2017-06-27 17:06:11,105 Epoch[6] Batch [830]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.156429,	
2017-06-27 17:06:22,305 Epoch[6] Batch [840]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.156180,	
2017-06-27 17:06:34,318 Epoch[6] Batch [850]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.156075,	
2017-06-27 17:06:45,255 Epoch[6] Batch [860]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.156588,	
2017-06-27 17:06:56,213 Epoch[6] Batch [870]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.156768,	
2017-06-27 17:07:06,988 Epoch[6] Batch [880]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.157098,	
2017-06-27 17:07:19,005 Epoch[6] Batch [890]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.157686,	
2017-06-27 17:07:29,334 Epoch[6] Batch [900]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.158213,	
2017-06-27 17:07:39,376 Epoch[6] Batch [910]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.158301,	
2017-06-27 17:07:49,893 Epoch[6] Batch [920]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.158536,	
2017-06-27 17:08:01,142 Epoch[6] Batch [930]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.158643,	
2017-06-27 17:08:12,819 Epoch[6] Batch [940]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.158845,	
2017-06-27 17:08:23,327 Epoch[6] Batch [950]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.159100,	
2017-06-27 17:08:35,154 Epoch[6] Batch [960]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.159229,	
2017-06-27 17:08:45,802 Epoch[6] Batch [970]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.159452,	
2017-06-27 17:08:56,889 Epoch[6] Batch [980]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.159477,	
2017-06-27 17:09:07,613 Epoch[6] Batch [990]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.159498,	
2017-06-27 17:09:18,941 Epoch[6] Batch [1000]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.159214,	
2017-06-27 17:09:30,167 Epoch[6] Batch [1010]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.158994,	
2017-06-27 17:09:40,996 Epoch[6] Batch [1020]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.158978,	
2017-06-27 17:09:52,086 Epoch[6] Batch [1030]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.158779,	
2017-06-27 17:10:02,614 Epoch[6] Batch [1040]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.158823,	
2017-06-27 17:10:14,002 Epoch[6] Batch [1050]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.158687,	
2017-06-27 17:10:24,970 Epoch[6] Batch [1060]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.158552,	
2017-06-27 17:10:35,179 Epoch[6] Batch [1070]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.158487,	
2017-06-27 17:10:46,280 Epoch[6] Batch [1080]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.158394,	
2017-06-27 17:10:57,743 Epoch[6] Batch [1090]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.158554,	
2017-06-27 17:11:08,827 Epoch[6] Batch [1100]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.158458,	
2017-06-27 17:11:19,925 Epoch[6] Batch [1110]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.158234,	
2017-06-27 17:11:30,687 Epoch[6] Batch [1120]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.158241,	
2017-06-27 17:11:41,639 Epoch[6] Batch [1130]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.158217,	
2017-06-27 17:11:52,729 Epoch[6] Batch [1140]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.158059,	
2017-06-27 17:12:04,317 Epoch[6] Batch [1150]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.157901,	
2017-06-27 17:12:15,719 Epoch[6] Batch [1160]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.157746,	
2017-06-27 17:12:27,033 Epoch[6] Batch [1170]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.157811,	
2017-06-27 17:12:37,889 Epoch[6] Batch [1180]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.157801,	
2017-06-27 17:12:48,324 Epoch[6] Batch [1190]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.157774,	
2017-06-27 17:12:59,099 Epoch[6] Batch [1200]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.157623,	
2017-06-27 17:13:10,413 Epoch[6] Batch [1210]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.157660,	
2017-06-27 17:13:22,644 Epoch[6] Batch [1220]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.157831,	
2017-06-27 17:13:34,368 Epoch[6] Batch [1230]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.157706,	
2017-06-27 17:13:45,247 Epoch[6] Batch [1240]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.157761,	
2017-06-27 17:13:56,273 Epoch[6] Batch [1250]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.157676,	
2017-06-27 17:14:06,922 Epoch[6] Batch [1260]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.157686,	
2017-06-27 17:14:17,666 Epoch[6] Batch [1270]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.157850,	
2017-06-27 17:14:29,036 Epoch[6] Batch [1280]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.157926,	
2017-06-27 17:14:39,800 Epoch[6] Batch [1290]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.157917,	
2017-06-27 17:14:50,508 Epoch[6] Batch [1300]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.157926,	
2017-06-27 17:15:01,758 Epoch[6] Batch [1310]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.157934,	
2017-06-27 17:15:13,270 Epoch[6] Batch [1320]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.158051,	
2017-06-27 17:15:23,653 Epoch[6] Batch [1330]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.158122,	
2017-06-27 17:15:34,766 Epoch[6] Batch [1340]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.158040,	
2017-06-27 17:15:44,338 Epoch[6] Batch [1350]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.158036,	
2017-06-27 17:15:54,820 Epoch[6] Batch [1360]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.158038,	
2017-06-27 17:16:04,990 Epoch[6] Batch [1370]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.157995,	
2017-06-27 17:16:16,274 Epoch[6] Batch [1380]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.158112,	
2017-06-27 17:16:28,130 Epoch[6] Batch [1390]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.158021,	
2017-06-27 17:16:39,485 Epoch[6] Batch [1400]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.158329,	
2017-06-27 17:16:50,086 Epoch[6] Batch [1410]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.158671,	
2017-06-27 17:17:01,914 Epoch[6] Batch [1420]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.158693,	
2017-06-27 17:17:13,162 Epoch[6] Batch [1430]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.158596,	
2017-06-27 17:17:23,575 Epoch[6] Batch [1440]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.158687,	
2017-06-27 17:17:33,688 Epoch[6] Batch [1450]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.158548,	
2017-06-27 17:17:43,613 Epoch[6] Batch [1460]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.158492,	
2017-06-27 17:17:54,682 Epoch[6] Batch [1470]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.158503,	
2017-06-27 17:18:04,590 Epoch[6] Batch [1480]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.158476,	
2017-06-27 17:18:10,743 Epoch[6] Train-FCNLogLoss=0.158465
2017-06-27 17:18:10,743 Epoch[6] Time cost=1492.851
2017-06-27 17:18:25,675 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0007.params"
2017-06-27 17:18:31,740 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0007.states"
2017-06-27 17:18:43,685 Epoch[7] Batch [10]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.152004,	
2017-06-27 17:18:53,858 Epoch[7] Batch [20]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.156009,	
2017-06-27 17:19:03,914 Epoch[7] Batch [30]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.163122,	
2017-06-27 17:19:14,330 Epoch[7] Batch [40]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.162781,	
2017-06-27 17:19:25,457 Epoch[7] Batch [50]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.162147,	
2017-06-27 17:19:36,511 Epoch[7] Batch [60]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.157792,	
2017-06-27 17:19:47,186 Epoch[7] Batch [70]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.154420,	
2017-06-27 17:19:57,389 Epoch[7] Batch [80]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.150590,	
2017-06-27 17:20:08,104 Epoch[7] Batch [90]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.149337,	
2017-06-27 17:20:18,319 Epoch[7] Batch [100]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.147987,	
2017-06-27 17:20:28,563 Epoch[7] Batch [110]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.146720,	
2017-06-27 17:20:39,055 Epoch[7] Batch [120]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.146182,	
2017-06-27 17:20:50,193 Epoch[7] Batch [130]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.150382,	
2017-06-27 17:21:01,086 Epoch[7] Batch [140]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.151318,	
2017-06-27 17:21:12,082 Epoch[7] Batch [150]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.151396,	
2017-06-27 17:21:23,502 Epoch[7] Batch [160]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.152395,	
2017-06-27 17:21:34,014 Epoch[7] Batch [170]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.151883,	
2017-06-27 17:21:44,087 Epoch[7] Batch [180]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.151076,	
2017-06-27 17:21:55,057 Epoch[7] Batch [190]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.151100,	
2017-06-27 17:22:05,912 Epoch[7] Batch [200]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.151818,	
2017-06-27 17:22:16,058 Epoch[7] Batch [210]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.151479,	
2017-06-27 17:22:26,262 Epoch[7] Batch [220]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.152428,	
2017-06-27 17:22:35,751 Epoch[7] Batch [230]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.154725,	
2017-06-27 17:22:45,500 Epoch[7] Batch [240]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.154256,	
2017-06-27 17:22:55,161 Epoch[7] Batch [250]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.154421,	
2017-06-27 17:23:05,351 Epoch[7] Batch [260]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.153781,	
2017-06-27 17:23:16,285 Epoch[7] Batch [270]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.152699,	
2017-06-27 17:23:27,072 Epoch[7] Batch [280]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.152897,	
2017-06-27 17:23:37,431 Epoch[7] Batch [290]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.152856,	
2017-06-27 17:23:47,550 Epoch[7] Batch [300]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.151884,	
2017-06-27 17:23:58,716 Epoch[7] Batch [310]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.152083,	
2017-06-27 17:24:09,739 Epoch[7] Batch [320]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.151741,	
2017-06-27 17:24:20,145 Epoch[7] Batch [330]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.151717,	
2017-06-27 17:24:31,371 Epoch[7] Batch [340]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.152871,	
2017-06-27 17:24:41,840 Epoch[7] Batch [350]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.152381,	
2017-06-27 17:24:52,976 Epoch[7] Batch [360]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.152536,	
2017-06-27 17:25:03,212 Epoch[7] Batch [370]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.152247,	
2017-06-27 17:25:13,629 Epoch[7] Batch [380]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.152189,	
2017-06-27 17:25:24,648 Epoch[7] Batch [390]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.152400,	
2017-06-27 17:25:36,411 Epoch[7] Batch [400]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.152904,	
2017-06-27 17:25:47,051 Epoch[7] Batch [410]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.152829,	
2017-06-27 17:25:58,831 Epoch[7] Batch [420]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.153381,	
2017-06-27 17:26:10,019 Epoch[7] Batch [430]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.153241,	
2017-06-27 17:26:21,823 Epoch[7] Batch [440]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.153878,	
2017-06-27 17:26:32,630 Epoch[7] Batch [450]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.154410,	
2017-06-27 17:26:43,263 Epoch[7] Batch [460]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.154469,	
2017-06-27 17:26:54,260 Epoch[7] Batch [470]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.154343,	
2017-06-27 17:27:04,678 Epoch[7] Batch [480]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.154655,	
2017-06-27 17:27:15,508 Epoch[7] Batch [490]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.154601,	
2017-06-27 17:27:25,940 Epoch[7] Batch [500]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.154178,	
2017-06-27 17:27:36,805 Epoch[7] Batch [510]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.153961,	
2017-06-27 17:27:46,822 Epoch[7] Batch [520]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.153948,	
2017-06-27 17:27:56,918 Epoch[7] Batch [530]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.154542,	
2017-06-27 17:28:07,388 Epoch[7] Batch [540]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.154642,	
2017-06-27 17:28:17,761 Epoch[7] Batch [550]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.154497,	
2017-06-27 17:28:29,225 Epoch[7] Batch [560]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.154630,	
2017-06-27 17:28:40,915 Epoch[7] Batch [570]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.154453,	
2017-06-27 17:28:51,439 Epoch[7] Batch [580]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.154204,	
2017-06-27 17:29:03,208 Epoch[7] Batch [590]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.154145,	
2017-06-27 17:29:15,365 Epoch[7] Batch [600]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.154344,	
2017-06-27 17:29:27,485 Epoch[7] Batch [610]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.154220,	
2017-06-27 17:29:38,894 Epoch[7] Batch [620]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.154659,	
2017-06-27 17:29:49,760 Epoch[7] Batch [630]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.154921,	
2017-06-27 17:30:01,866 Epoch[7] Batch [640]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.154774,	
2017-06-27 17:30:13,493 Epoch[7] Batch [650]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.154972,	
2017-06-27 17:30:23,934 Epoch[7] Batch [660]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.155169,	
2017-06-27 17:30:35,552 Epoch[7] Batch [670]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.155207,	
2017-06-27 17:30:47,074 Epoch[7] Batch [680]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.155016,	
2017-06-27 17:30:58,000 Epoch[7] Batch [690]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.155064,	
2017-06-27 17:31:08,813 Epoch[7] Batch [700]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.155082,	
2017-06-27 17:31:20,467 Epoch[7] Batch [710]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.154896,	
2017-06-27 17:31:30,983 Epoch[7] Batch [720]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.155048,	
2017-06-27 17:31:42,025 Epoch[7] Batch [730]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.155101,	
2017-06-27 17:31:53,452 Epoch[7] Batch [740]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.154977,	
2017-06-27 17:32:03,365 Epoch[7] Batch [750]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.154988,	
2017-06-27 17:32:15,837 Epoch[7] Batch [760]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.154852,	
2017-06-27 17:32:26,685 Epoch[7] Batch [770]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.154933,	
2017-06-27 17:32:37,115 Epoch[7] Batch [780]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.155048,	
2017-06-27 17:32:47,792 Epoch[7] Batch [790]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.154896,	
2017-06-27 17:32:59,143 Epoch[7] Batch [800]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.154989,	
2017-06-27 17:33:09,609 Epoch[7] Batch [810]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.154922,	
2017-06-27 17:33:20,829 Epoch[7] Batch [820]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.154763,	
2017-06-27 17:33:30,992 Epoch[7] Batch [830]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.154623,	
2017-06-27 17:33:41,550 Epoch[7] Batch [840]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.154506,	
2017-06-27 17:33:52,987 Epoch[7] Batch [850]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.154440,	
2017-06-27 17:34:03,382 Epoch[7] Batch [860]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.154359,	
2017-06-27 17:34:15,616 Epoch[7] Batch [870]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.154166,	
2017-06-27 17:34:26,548 Epoch[7] Batch [880]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.153973,	
2017-06-27 17:34:37,419 Epoch[7] Batch [890]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.153918,	
2017-06-27 17:34:49,463 Epoch[7] Batch [900]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.153751,	
2017-06-27 17:35:01,165 Epoch[7] Batch [910]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.153684,	
2017-06-27 17:35:12,688 Epoch[7] Batch [920]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.153468,	
2017-06-27 17:35:22,810 Epoch[7] Batch [930]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.153395,	
2017-06-27 17:35:34,471 Epoch[7] Batch [940]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.153494,	
2017-06-27 17:35:45,387 Epoch[7] Batch [950]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.153528,	
2017-06-27 17:35:56,550 Epoch[7] Batch [960]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.153742,	
2017-06-27 17:36:06,519 Epoch[7] Batch [970]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.153788,	
2017-06-27 17:36:17,699 Epoch[7] Batch [980]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.153867,	
2017-06-27 17:36:27,917 Epoch[7] Batch [990]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.153889,	
2017-06-27 17:36:38,755 Epoch[7] Batch [1000]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.153920,	
2017-06-27 17:36:50,097 Epoch[7] Batch [1010]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.153912,	
2017-06-27 17:37:01,359 Epoch[7] Batch [1020]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.153961,	
2017-06-27 17:37:12,686 Epoch[7] Batch [1030]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.154051,	
2017-06-27 17:37:23,508 Epoch[7] Batch [1040]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.153975,	
2017-06-27 17:37:33,668 Epoch[7] Batch [1050]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.154021,	
2017-06-27 17:37:44,825 Epoch[7] Batch [1060]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.153982,	
2017-06-27 17:37:55,566 Epoch[7] Batch [1070]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.153796,	
2017-06-27 17:38:07,541 Epoch[7] Batch [1080]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.153953,	
2017-06-27 17:38:18,285 Epoch[7] Batch [1090]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.153874,	
2017-06-27 17:38:29,462 Epoch[7] Batch [1100]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.154232,	
2017-06-27 17:38:40,223 Epoch[7] Batch [1110]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.154171,	
2017-06-27 17:38:51,343 Epoch[7] Batch [1120]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.154315,	
2017-06-27 17:39:01,695 Epoch[7] Batch [1130]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.154392,	
2017-06-27 17:39:12,631 Epoch[7] Batch [1140]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.154264,	
2017-06-27 17:39:24,051 Epoch[7] Batch [1150]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.154278,	
2017-06-27 17:39:35,273 Epoch[7] Batch [1160]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.154203,	
2017-06-27 17:39:47,959 Epoch[7] Batch [1170]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.154081,	
2017-06-27 17:39:58,888 Epoch[7] Batch [1180]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.153853,	
2017-06-27 17:40:10,045 Epoch[7] Batch [1190]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.153736,	
2017-06-27 17:40:20,606 Epoch[7] Batch [1200]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.153660,	
2017-06-27 17:40:31,458 Epoch[7] Batch [1210]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.153558,	
2017-06-27 17:40:42,514 Epoch[7] Batch [1220]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.153474,	
2017-06-27 17:40:54,176 Epoch[7] Batch [1230]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.153443,	
2017-06-27 17:41:05,234 Epoch[7] Batch [1240]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.153368,	
2017-06-27 17:41:15,439 Epoch[7] Batch [1250]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.153279,	
2017-06-27 17:41:26,388 Epoch[7] Batch [1260]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.153095,	
2017-06-27 17:41:37,062 Epoch[7] Batch [1270]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.153182,	
2017-06-27 17:41:47,197 Epoch[7] Batch [1280]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.153181,	
2017-06-27 17:41:58,123 Epoch[7] Batch [1290]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.153405,	
2017-06-27 17:42:08,950 Epoch[7] Batch [1300]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.153442,	
2017-06-27 17:42:20,272 Epoch[7] Batch [1310]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.153377,	
2017-06-27 17:42:30,498 Epoch[7] Batch [1320]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.153419,	
2017-06-27 17:42:41,140 Epoch[7] Batch [1330]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.153110,	
2017-06-27 17:42:53,046 Epoch[7] Batch [1340]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.152995,	
2017-06-27 17:43:04,837 Epoch[7] Batch [1350]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.152902,	
2017-06-27 17:43:15,463 Epoch[7] Batch [1360]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.152868,	
2017-06-27 17:43:26,479 Epoch[7] Batch [1370]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.152850,	
2017-06-27 17:43:37,535 Epoch[7] Batch [1380]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.152919,	
2017-06-27 17:43:48,777 Epoch[7] Batch [1390]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.152818,	
2017-06-27 17:43:59,995 Epoch[7] Batch [1400]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.152899,	
2017-06-27 17:44:11,909 Epoch[7] Batch [1410]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.152708,	
2017-06-27 17:44:23,836 Epoch[7] Batch [1420]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.152931,	
2017-06-27 17:44:35,105 Epoch[7] Batch [1430]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.153050,	
2017-06-27 17:44:46,121 Epoch[7] Batch [1440]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.152984,	
2017-06-27 17:44:58,389 Epoch[7] Batch [1450]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.152936,	
2017-06-27 17:45:09,642 Epoch[7] Batch [1460]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.152816,	
2017-06-27 17:45:20,659 Epoch[7] Batch [1470]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.152747,	
2017-06-27 17:45:31,894 Epoch[7] Batch [1480]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.152792,	
2017-06-27 17:45:39,131 Epoch[7] Train-FCNLogLoss=0.152681
2017-06-27 17:45:39,131 Epoch[7] Time cost=1627.127
2017-06-27 17:45:45,765 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0008.params"
2017-06-27 17:45:50,182 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0008.states"
2017-06-27 17:46:02,619 Epoch[8] Batch [10]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.155427,	
2017-06-27 17:46:13,547 Epoch[8] Batch [20]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.160514,	
2017-06-27 17:46:24,602 Epoch[8] Batch [30]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.157653,	
2017-06-27 17:46:35,169 Epoch[8] Batch [40]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.158038,	
2017-06-27 17:46:45,425 Epoch[8] Batch [50]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.164647,	
2017-06-27 17:46:55,756 Epoch[8] Batch [60]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.159812,	
2017-06-27 17:47:07,733 Epoch[8] Batch [70]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.159039,	
2017-06-27 17:47:18,698 Epoch[8] Batch [80]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.158251,	
2017-06-27 17:47:29,361 Epoch[8] Batch [90]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.156000,	
2017-06-27 17:47:40,003 Epoch[8] Batch [100]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.155358,	
2017-06-27 17:47:51,365 Epoch[8] Batch [110]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.156236,	
2017-06-27 17:48:01,874 Epoch[8] Batch [120]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.158046,	
2017-06-27 17:48:12,378 Epoch[8] Batch [130]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.157843,	
2017-06-27 17:48:23,573 Epoch[8] Batch [140]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.155832,	
2017-06-27 17:48:34,797 Epoch[8] Batch [150]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.158921,	
2017-06-27 17:48:44,716 Epoch[8] Batch [160]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.159840,	
2017-06-27 17:48:55,705 Epoch[8] Batch [170]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.159879,	
2017-06-27 17:49:06,514 Epoch[8] Batch [180]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.160550,	
2017-06-27 17:49:16,814 Epoch[8] Batch [190]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.159789,	
2017-06-27 17:49:27,315 Epoch[8] Batch [200]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.159978,	
2017-06-27 17:49:38,804 Epoch[8] Batch [210]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.160016,	
2017-06-27 17:49:49,642 Epoch[8] Batch [220]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.159646,	
2017-06-27 17:49:59,602 Epoch[8] Batch [230]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.159873,	
2017-06-27 17:50:10,491 Epoch[8] Batch [240]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.159930,	
2017-06-27 17:50:20,791 Epoch[8] Batch [250]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.159731,	
2017-06-27 17:50:31,387 Epoch[8] Batch [260]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.158981,	
2017-06-27 17:50:42,111 Epoch[8] Batch [270]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.158498,	
2017-06-27 17:50:52,294 Epoch[8] Batch [280]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.158238,	
2017-06-27 17:51:04,146 Epoch[8] Batch [290]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.157861,	
2017-06-27 17:51:14,547 Epoch[8] Batch [300]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.156730,	
2017-06-27 17:51:25,687 Epoch[8] Batch [310]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.155943,	
2017-06-27 17:51:36,737 Epoch[8] Batch [320]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.155434,	
2017-06-27 17:51:47,787 Epoch[8] Batch [330]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.154931,	
2017-06-27 17:51:58,517 Epoch[8] Batch [340]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.154561,	
2017-06-27 17:52:09,306 Epoch[8] Batch [350]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.154674,	
2017-06-27 17:52:20,834 Epoch[8] Batch [360]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.154304,	
2017-06-27 17:52:32,312 Epoch[8] Batch [370]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.154279,	
2017-06-27 17:52:43,567 Epoch[8] Batch [380]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.153772,	
2017-06-27 17:52:53,126 Epoch[8] Batch [390]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.153516,	
2017-06-27 17:53:03,960 Epoch[8] Batch [400]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.153006,	
2017-06-27 17:53:13,542 Epoch[8] Batch [410]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.152565,	
2017-06-27 17:53:24,339 Epoch[8] Batch [420]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.152232,	
2017-06-27 17:53:35,354 Epoch[8] Batch [430]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.151839,	
2017-06-27 17:53:45,480 Epoch[8] Batch [440]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.151835,	
2017-06-27 17:53:55,873 Epoch[8] Batch [450]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.151627,	
2017-06-27 17:54:07,263 Epoch[8] Batch [460]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.151408,	
2017-06-27 17:54:17,375 Epoch[8] Batch [470]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.151319,	
2017-06-27 17:54:27,625 Epoch[8] Batch [480]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.150859,	
2017-06-27 17:54:38,013 Epoch[8] Batch [490]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.150689,	
2017-06-27 17:54:47,683 Epoch[8] Batch [500]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.150989,	
2017-06-27 17:54:58,594 Epoch[8] Batch [510]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.150679,	
2017-06-27 17:55:09,184 Epoch[8] Batch [520]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.150747,	
2017-06-27 17:55:18,926 Epoch[8] Batch [530]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.151065,	
2017-06-27 17:55:29,658 Epoch[8] Batch [540]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.151045,	
2017-06-27 17:55:40,551 Epoch[8] Batch [550]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.151542,	
2017-06-27 17:55:51,173 Epoch[8] Batch [560]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.151898,	
2017-06-27 17:56:01,343 Epoch[8] Batch [570]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.151932,	
2017-06-27 17:56:11,035 Epoch[8] Batch [580]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.151616,	
2017-06-27 17:56:21,256 Epoch[8] Batch [590]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.151917,	
2017-06-27 17:56:32,367 Epoch[8] Batch [600]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.152239,	
2017-06-27 17:56:43,045 Epoch[8] Batch [610]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.152323,	
2017-06-27 17:56:53,319 Epoch[8] Batch [620]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.152214,	
2017-06-27 17:57:02,805 Epoch[8] Batch [630]	Speed: 4.22 samples/sec	Train-FCNLogLoss=0.152137,	
2017-06-27 17:57:13,363 Epoch[8] Batch [640]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.152096,	
2017-06-27 17:57:24,997 Epoch[8] Batch [650]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.151968,	
2017-06-27 17:57:35,391 Epoch[8] Batch [660]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.151958,	
2017-06-27 17:57:45,627 Epoch[8] Batch [670]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.152044,	
2017-06-27 17:57:56,438 Epoch[8] Batch [680]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.152100,	
2017-06-27 17:58:06,774 Epoch[8] Batch [690]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.152309,	
2017-06-27 17:58:17,305 Epoch[8] Batch [700]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.152251,	
2017-06-27 17:58:29,408 Epoch[8] Batch [710]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.152214,	
2017-06-27 17:58:40,961 Epoch[8] Batch [720]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.151925,	
2017-06-27 17:58:51,372 Epoch[8] Batch [730]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.151651,	
2017-06-27 17:59:01,744 Epoch[8] Batch [740]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.151340,	
2017-06-27 17:59:11,972 Epoch[8] Batch [750]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.151015,	
2017-06-27 17:59:22,679 Epoch[8] Batch [760]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.150824,	
2017-06-27 17:59:33,440 Epoch[8] Batch [770]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.150738,	
2017-06-27 17:59:44,657 Epoch[8] Batch [780]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.150477,	
2017-06-27 17:59:55,529 Epoch[8] Batch [790]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.150438,	
2017-06-27 18:00:06,856 Epoch[8] Batch [800]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.150616,	
2017-06-27 18:00:17,367 Epoch[8] Batch [810]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.150779,	
2017-06-27 18:00:28,432 Epoch[8] Batch [820]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.150621,	
2017-06-27 18:00:38,882 Epoch[8] Batch [830]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.150504,	
2017-06-27 18:00:50,969 Epoch[8] Batch [840]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.150281,	
2017-06-27 18:01:02,765 Epoch[8] Batch [850]	Speed: 3.39 samples/sec	Train-FCNLogLoss=0.150426,	
2017-06-27 18:01:13,268 Epoch[8] Batch [860]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.150604,	
2017-06-27 18:01:23,769 Epoch[8] Batch [870]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.150520,	
2017-06-27 18:01:34,365 Epoch[8] Batch [880]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.150466,	
2017-06-27 18:01:45,382 Epoch[8] Batch [890]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.150448,	
2017-06-27 18:01:57,148 Epoch[8] Batch [900]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.150290,	
2017-06-27 18:02:07,942 Epoch[8] Batch [910]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.150503,	
2017-06-27 18:02:18,845 Epoch[8] Batch [920]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.150319,	
2017-06-27 18:02:31,166 Epoch[8] Batch [930]	Speed: 3.25 samples/sec	Train-FCNLogLoss=0.150179,	
2017-06-27 18:02:42,098 Epoch[8] Batch [940]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.150145,	
2017-06-27 18:02:54,572 Epoch[8] Batch [950]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.149948,	
2017-06-27 18:03:04,670 Epoch[8] Batch [960]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.149723,	
2017-06-27 18:03:15,116 Epoch[8] Batch [970]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.149606,	
2017-06-27 18:03:25,638 Epoch[8] Batch [980]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.149375,	
2017-06-27 18:03:36,356 Epoch[8] Batch [990]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.149476,	
2017-06-27 18:03:47,500 Epoch[8] Batch [1000]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.149400,	
2017-06-27 18:03:59,032 Epoch[8] Batch [1010]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.149402,	
2017-06-27 18:04:10,783 Epoch[8] Batch [1020]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.149439,	
2017-06-27 18:04:21,862 Epoch[8] Batch [1030]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.149210,	
2017-06-27 18:04:33,068 Epoch[8] Batch [1040]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.149309,	
2017-06-27 18:04:45,217 Epoch[8] Batch [1050]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.149306,	
2017-06-27 18:04:55,845 Epoch[8] Batch [1060]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.149182,	
2017-06-27 18:05:07,351 Epoch[8] Batch [1070]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.149283,	
2017-06-27 18:05:17,818 Epoch[8] Batch [1080]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.149575,	
2017-06-27 18:05:29,983 Epoch[8] Batch [1090]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.149715,	
2017-06-27 18:05:41,135 Epoch[8] Batch [1100]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.149762,	
2017-06-27 18:05:53,312 Epoch[8] Batch [1110]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.149969,	
2017-06-27 18:06:04,591 Epoch[8] Batch [1120]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.149898,	
2017-06-27 18:06:15,342 Epoch[8] Batch [1130]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.149898,	
2017-06-27 18:06:25,500 Epoch[8] Batch [1140]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.149888,	
2017-06-27 18:06:36,295 Epoch[8] Batch [1150]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.149819,	
2017-06-27 18:06:47,658 Epoch[8] Batch [1160]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.149800,	
2017-06-27 18:06:59,119 Epoch[8] Batch [1170]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.149849,	
2017-06-27 18:07:10,026 Epoch[8] Batch [1180]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.149962,	
2017-06-27 18:07:20,461 Epoch[8] Batch [1190]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.149870,	
2017-06-27 18:07:30,915 Epoch[8] Batch [1200]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.150057,	
2017-06-27 18:07:41,241 Epoch[8] Batch [1210]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.149987,	
2017-06-27 18:07:53,193 Epoch[8] Batch [1220]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.149987,	
2017-06-27 18:08:03,251 Epoch[8] Batch [1230]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.149912,	
2017-06-27 18:08:13,701 Epoch[8] Batch [1240]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.149743,	
2017-06-27 18:08:24,303 Epoch[8] Batch [1250]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.149562,	
2017-06-27 18:08:34,917 Epoch[8] Batch [1260]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.149388,	
2017-06-27 18:08:45,530 Epoch[8] Batch [1270]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.149236,	
2017-06-27 18:08:56,603 Epoch[8] Batch [1280]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.149177,	
2017-06-27 18:09:06,326 Epoch[8] Batch [1290]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.149267,	
2017-06-27 18:09:16,055 Epoch[8] Batch [1300]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.149646,	
2017-06-27 18:09:26,498 Epoch[8] Batch [1310]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.149757,	
2017-06-27 18:09:37,983 Epoch[8] Batch [1320]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.149897,	
2017-06-27 18:09:47,611 Epoch[8] Batch [1330]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.149891,	
2017-06-27 18:09:57,918 Epoch[8] Batch [1340]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.150006,	
2017-06-27 18:10:08,413 Epoch[8] Batch [1350]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.150049,	
2017-06-27 18:10:19,014 Epoch[8] Batch [1360]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.149990,	
2017-06-27 18:10:29,097 Epoch[8] Batch [1370]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.150097,	
2017-06-27 18:10:38,855 Epoch[8] Batch [1380]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.150063,	
2017-06-27 18:10:49,291 Epoch[8] Batch [1390]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.150056,	
2017-06-27 18:11:00,453 Epoch[8] Batch [1400]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.149970,	
2017-06-27 18:11:10,767 Epoch[8] Batch [1410]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.149832,	
2017-06-27 18:11:21,536 Epoch[8] Batch [1420]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.149699,	
2017-06-27 18:11:31,556 Epoch[8] Batch [1430]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.149589,	
2017-06-27 18:11:41,494 Epoch[8] Batch [1440]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.149727,	
2017-06-27 18:11:51,251 Epoch[8] Batch [1450]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.149747,	
2017-06-27 18:12:01,701 Epoch[8] Batch [1460]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.149807,	
2017-06-27 18:12:11,622 Epoch[8] Batch [1470]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.149663,	
2017-06-27 18:12:21,890 Epoch[8] Batch [1480]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.149535,	
2017-06-27 18:12:28,282 Epoch[8] Train-FCNLogLoss=0.149447
2017-06-27 18:12:28,282 Epoch[8] Time cost=1597.773
2017-06-27 18:12:32,306 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0009.params"
2017-06-27 18:12:36,687 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0009.states"
2017-06-27 18:12:48,687 Epoch[9] Batch [10]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.146009,	
2017-06-27 18:12:59,182 Epoch[9] Batch [20]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.142064,	
2017-06-27 18:13:09,472 Epoch[9] Batch [30]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.140677,	
2017-06-27 18:13:20,291 Epoch[9] Batch [40]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.146915,	
2017-06-27 18:13:31,119 Epoch[9] Batch [50]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.145375,	
2017-06-27 18:13:41,638 Epoch[9] Batch [60]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.143830,	
2017-06-27 18:13:51,877 Epoch[9] Batch [70]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.145808,	
2017-06-27 18:14:02,736 Epoch[9] Batch [80]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.145052,	
2017-06-27 18:14:12,649 Epoch[9] Batch [90]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.144120,	
2017-06-27 18:14:23,110 Epoch[9] Batch [100]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.141851,	
2017-06-27 18:14:32,962 Epoch[9] Batch [110]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.145529,	
2017-06-27 18:14:43,102 Epoch[9] Batch [120]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.146848,	
2017-06-27 18:14:53,128 Epoch[9] Batch [130]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.147058,	
2017-06-27 18:15:03,610 Epoch[9] Batch [140]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.147016,	
2017-06-27 18:15:13,950 Epoch[9] Batch [150]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.147127,	
2017-06-27 18:15:23,860 Epoch[9] Batch [160]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.149532,	
2017-06-27 18:15:33,275 Epoch[9] Batch [170]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.149971,	
2017-06-27 18:15:43,425 Epoch[9] Batch [180]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.149382,	
2017-06-27 18:15:53,391 Epoch[9] Batch [190]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.149331,	
2017-06-27 18:16:03,764 Epoch[9] Batch [200]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.149182,	
2017-06-27 18:16:13,944 Epoch[9] Batch [210]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.148631,	
2017-06-27 18:16:25,152 Epoch[9] Batch [220]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.149468,	
2017-06-27 18:16:35,233 Epoch[9] Batch [230]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.149395,	
2017-06-27 18:16:45,255 Epoch[9] Batch [240]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.149245,	
2017-06-27 18:16:56,694 Epoch[9] Batch [250]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.149129,	
2017-06-27 18:17:07,163 Epoch[9] Batch [260]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.149004,	
2017-06-27 18:17:17,318 Epoch[9] Batch [270]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.148632,	
2017-06-27 18:17:27,634 Epoch[9] Batch [280]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.148163,	
2017-06-27 18:17:37,969 Epoch[9] Batch [290]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.147719,	
2017-06-27 18:17:48,904 Epoch[9] Batch [300]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.147332,	
2017-06-27 18:17:59,678 Epoch[9] Batch [310]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.147689,	
2017-06-27 18:18:10,743 Epoch[9] Batch [320]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.147124,	
2017-06-27 18:18:21,891 Epoch[9] Batch [330]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.146448,	
2017-06-27 18:18:32,450 Epoch[9] Batch [340]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.147062,	
2017-06-27 18:18:42,719 Epoch[9] Batch [350]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.147334,	
2017-06-27 18:18:52,635 Epoch[9] Batch [360]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.147082,	
2017-06-27 18:19:02,822 Epoch[9] Batch [370]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.146783,	
2017-06-27 18:19:13,190 Epoch[9] Batch [380]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.146626,	
2017-06-27 18:19:23,776 Epoch[9] Batch [390]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.146288,	
2017-06-27 18:19:33,560 Epoch[9] Batch [400]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.145958,	
2017-06-27 18:19:43,961 Epoch[9] Batch [410]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.146398,	
2017-06-27 18:19:54,500 Epoch[9] Batch [420]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.146619,	
2017-06-27 18:20:05,201 Epoch[9] Batch [430]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.146576,	
2017-06-27 18:20:15,382 Epoch[9] Batch [440]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.146313,	
2017-06-27 18:20:25,334 Epoch[9] Batch [450]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.146053,	
2017-06-27 18:20:36,833 Epoch[9] Batch [460]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.145729,	
2017-06-27 18:20:47,380 Epoch[9] Batch [470]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.145755,	
2017-06-27 18:20:57,330 Epoch[9] Batch [480]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.145938,	
2017-06-27 18:21:08,532 Epoch[9] Batch [490]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.146061,	
2017-06-27 18:21:18,396 Epoch[9] Batch [500]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.146077,	
2017-06-27 18:21:28,963 Epoch[9] Batch [510]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.146024,	
2017-06-27 18:21:39,340 Epoch[9] Batch [520]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.146430,	
2017-06-27 18:21:49,760 Epoch[9] Batch [530]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.146110,	
2017-06-27 18:22:01,046 Epoch[9] Batch [540]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.145816,	
2017-06-27 18:22:11,263 Epoch[9] Batch [550]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.146093,	
2017-06-27 18:22:21,876 Epoch[9] Batch [560]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.146450,	
2017-06-27 18:22:31,995 Epoch[9] Batch [570]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.146238,	
2017-06-27 18:22:43,437 Epoch[9] Batch [580]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.146828,	
2017-06-27 18:22:53,576 Epoch[9] Batch [590]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.147008,	
2017-06-27 18:23:05,642 Epoch[9] Batch [600]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.146845,	
2017-06-27 18:23:16,139 Epoch[9] Batch [610]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.146864,	
2017-06-27 18:23:26,926 Epoch[9] Batch [620]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.146832,	
2017-06-27 18:23:38,143 Epoch[9] Batch [630]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.146917,	
2017-06-27 18:23:49,395 Epoch[9] Batch [640]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.146740,	
2017-06-27 18:23:59,305 Epoch[9] Batch [650]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.146759,	
2017-06-27 18:24:09,760 Epoch[9] Batch [660]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.146636,	
2017-06-27 18:24:20,253 Epoch[9] Batch [670]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.146618,	
2017-06-27 18:24:31,119 Epoch[9] Batch [680]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.146393,	
2017-06-27 18:24:41,484 Epoch[9] Batch [690]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.146040,	
2017-06-27 18:24:51,972 Epoch[9] Batch [700]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.145995,	
2017-06-27 18:25:01,721 Epoch[9] Batch [710]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.145815,	
2017-06-27 18:25:11,768 Epoch[9] Batch [720]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.145758,	
2017-06-27 18:25:21,657 Epoch[9] Batch [730]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.145983,	
2017-06-27 18:25:32,560 Epoch[9] Batch [740]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.145824,	
2017-06-27 18:25:43,766 Epoch[9] Batch [750]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.145680,	
2017-06-27 18:25:54,557 Epoch[9] Batch [760]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.145552,	
2017-06-27 18:26:05,022 Epoch[9] Batch [770]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.145321,	
2017-06-27 18:26:15,895 Epoch[9] Batch [780]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.145183,	
2017-06-27 18:26:26,238 Epoch[9] Batch [790]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.144908,	
2017-06-27 18:26:36,987 Epoch[9] Batch [800]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.144661,	
2017-06-27 18:26:47,780 Epoch[9] Batch [810]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.144332,	
2017-06-27 18:26:57,997 Epoch[9] Batch [820]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.144216,	
2017-06-27 18:27:08,497 Epoch[9] Batch [830]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.144247,	
2017-06-27 18:27:19,066 Epoch[9] Batch [840]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.144181,	
2017-06-27 18:27:29,649 Epoch[9] Batch [850]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.144298,	
2017-06-27 18:27:40,494 Epoch[9] Batch [860]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.144062,	
2017-06-27 18:27:51,600 Epoch[9] Batch [870]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.143992,	
2017-06-27 18:28:02,683 Epoch[9] Batch [880]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.144181,	
2017-06-27 18:28:14,024 Epoch[9] Batch [890]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.144048,	
2017-06-27 18:28:25,222 Epoch[9] Batch [900]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.144001,	
2017-06-27 18:28:36,261 Epoch[9] Batch [910]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.144026,	
2017-06-27 18:28:47,992 Epoch[9] Batch [920]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.144000,	
2017-06-27 18:28:58,865 Epoch[9] Batch [930]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.144138,	
2017-06-27 18:29:10,023 Epoch[9] Batch [940]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.144405,	
2017-06-27 18:29:20,680 Epoch[9] Batch [950]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.144337,	
2017-06-27 18:29:30,960 Epoch[9] Batch [960]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.144393,	
2017-06-27 18:29:42,168 Epoch[9] Batch [970]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.144684,	
2017-06-27 18:29:56,497 Epoch[9] Batch [980]	Speed: 2.79 samples/sec	Train-FCNLogLoss=0.144516,	
2017-06-27 18:30:08,389 Epoch[9] Batch [990]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.144604,	
2017-06-27 18:30:19,139 Epoch[9] Batch [1000]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.144626,	
2017-06-27 18:30:29,747 Epoch[9] Batch [1010]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.144511,	
2017-06-27 18:30:41,749 Epoch[9] Batch [1020]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.144404,	
2017-06-27 18:30:53,169 Epoch[9] Batch [1030]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.144878,	
2017-06-27 18:31:04,283 Epoch[9] Batch [1040]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.144787,	
2017-06-27 18:31:15,196 Epoch[9] Batch [1050]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.144713,	
2017-06-27 18:31:25,869 Epoch[9] Batch [1060]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.144690,	
2017-06-27 18:31:38,135 Epoch[9] Batch [1070]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.144617,	
2017-06-27 18:31:50,177 Epoch[9] Batch [1080]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.144609,	
2017-06-27 18:32:01,554 Epoch[9] Batch [1090]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.144400,	
2017-06-27 18:32:12,000 Epoch[9] Batch [1100]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.144376,	
2017-06-27 18:32:23,160 Epoch[9] Batch [1110]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.144427,	
2017-06-27 18:32:34,036 Epoch[9] Batch [1120]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.144700,	
2017-06-27 18:32:45,684 Epoch[9] Batch [1130]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.144832,	
2017-06-27 18:32:56,155 Epoch[9] Batch [1140]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.144906,	
2017-06-27 18:33:06,787 Epoch[9] Batch [1150]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.144746,	
2017-06-27 18:33:16,933 Epoch[9] Batch [1160]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.144512,	
2017-06-27 18:33:27,870 Epoch[9] Batch [1170]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.144276,	
2017-06-27 18:33:40,892 Epoch[9] Batch [1180]	Speed: 3.07 samples/sec	Train-FCNLogLoss=0.144141,	
2017-06-27 18:33:53,142 Epoch[9] Batch [1190]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.144069,	
2017-06-27 18:34:04,394 Epoch[9] Batch [1200]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.143916,	
2017-06-27 18:34:15,112 Epoch[9] Batch [1210]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.143830,	
2017-06-27 18:34:26,554 Epoch[9] Batch [1220]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.143639,	
2017-06-27 18:34:37,814 Epoch[9] Batch [1230]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.143541,	
2017-06-27 18:34:48,930 Epoch[9] Batch [1240]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.143588,	
2017-06-27 18:34:59,688 Epoch[9] Batch [1250]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.143684,	
2017-06-27 18:35:11,098 Epoch[9] Batch [1260]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.143778,	
2017-06-27 18:35:21,803 Epoch[9] Batch [1270]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.143696,	
2017-06-27 18:35:33,396 Epoch[9] Batch [1280]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.143580,	
2017-06-27 18:35:45,159 Epoch[9] Batch [1290]	Speed: 3.40 samples/sec	Train-FCNLogLoss=0.143686,	
2017-06-27 18:35:56,298 Epoch[9] Batch [1300]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.143749,	
2017-06-27 18:36:07,611 Epoch[9] Batch [1310]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.143759,	
2017-06-27 18:36:20,345 Epoch[9] Batch [1320]	Speed: 3.14 samples/sec	Train-FCNLogLoss=0.143871,	
2017-06-27 18:36:30,729 Epoch[9] Batch [1330]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.144118,	
2017-06-27 18:36:42,052 Epoch[9] Batch [1340]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.144203,	
2017-06-27 18:36:54,729 Epoch[9] Batch [1350]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.144215,	
2017-06-27 18:37:05,345 Epoch[9] Batch [1360]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.144376,	
2017-06-27 18:37:15,986 Epoch[9] Batch [1370]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.144384,	
2017-06-27 18:37:26,509 Epoch[9] Batch [1380]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.144345,	
2017-06-27 18:37:38,589 Epoch[9] Batch [1390]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.144313,	
2017-06-27 18:37:50,132 Epoch[9] Batch [1400]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.144262,	
2017-06-27 18:38:02,414 Epoch[9] Batch [1410]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.144189,	
2017-06-27 18:38:13,010 Epoch[9] Batch [1420]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.144154,	
2017-06-27 18:38:24,961 Epoch[9] Batch [1430]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.144199,	
2017-06-27 18:38:38,502 Epoch[9] Batch [1440]	Speed: 2.95 samples/sec	Train-FCNLogLoss=0.144384,	
2017-06-27 18:38:53,895 Epoch[9] Batch [1450]	Speed: 2.60 samples/sec	Train-FCNLogLoss=0.144351,	
2017-06-27 18:39:06,267 Epoch[9] Batch [1460]	Speed: 3.23 samples/sec	Train-FCNLogLoss=0.144294,	
2017-06-27 18:39:18,243 Epoch[9] Batch [1470]	Speed: 3.34 samples/sec	Train-FCNLogLoss=0.144557,	
2017-06-27 18:39:29,788 Epoch[9] Batch [1480]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.144697,	
2017-06-27 18:39:35,940 Epoch[9] Train-FCNLogLoss=0.144709
2017-06-27 18:39:35,944 Epoch[9] Time cost=1618.998
2017-06-27 18:39:41,600 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0010.params"
2017-06-27 18:39:47,664 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0010.states"
2017-06-27 18:40:00,100 Epoch[10] Batch [10]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.136372,	
2017-06-27 18:40:10,986 Epoch[10] Batch [20]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.128833,	
2017-06-27 18:40:22,260 Epoch[10] Batch [30]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.134112,	
2017-06-27 18:40:33,009 Epoch[10] Batch [40]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.137769,	
2017-06-27 18:40:44,216 Epoch[10] Batch [50]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.137252,	
2017-06-27 18:40:55,469 Epoch[10] Batch [60]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.136620,	
2017-06-27 18:41:07,333 Epoch[10] Batch [70]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.138963,	
2017-06-27 18:41:18,941 Epoch[10] Batch [80]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.139247,	
2017-06-27 18:41:30,400 Epoch[10] Batch [90]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.139734,	
2017-06-27 18:41:41,747 Epoch[10] Batch [100]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.139790,	
2017-06-27 18:41:52,951 Epoch[10] Batch [110]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.138621,	
2017-06-27 18:42:03,563 Epoch[10] Batch [120]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.138301,	
2017-06-27 18:42:14,811 Epoch[10] Batch [130]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.139538,	
2017-06-27 18:42:26,373 Epoch[10] Batch [140]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.138947,	
2017-06-27 18:42:37,619 Epoch[10] Batch [150]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.138858,	
2017-06-27 18:42:48,755 Epoch[10] Batch [160]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.139413,	
2017-06-27 18:43:00,621 Epoch[10] Batch [170]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.139383,	
2017-06-27 18:43:13,758 Epoch[10] Batch [180]	Speed: 3.05 samples/sec	Train-FCNLogLoss=0.140269,	
2017-06-27 18:43:24,989 Epoch[10] Batch [190]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.140374,	
2017-06-27 18:43:36,551 Epoch[10] Batch [200]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.140521,	
2017-06-27 18:43:48,047 Epoch[10] Batch [210]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.140316,	
2017-06-27 18:43:58,997 Epoch[10] Batch [220]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.142161,	
2017-06-27 18:44:09,456 Epoch[10] Batch [230]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.142610,	
2017-06-27 18:44:21,311 Epoch[10] Batch [240]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.142865,	
2017-06-27 18:44:32,561 Epoch[10] Batch [250]	Speed: 3.56 samples/sec	Train-FCNLogLoss=0.142504,	
2017-06-27 18:44:44,014 Epoch[10] Batch [260]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.142875,	
2017-06-27 18:44:54,910 Epoch[10] Batch [270]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.142920,	
2017-06-27 18:45:06,367 Epoch[10] Batch [280]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.142972,	
2017-06-27 18:45:16,533 Epoch[10] Batch [290]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.142164,	
2017-06-27 18:45:28,125 Epoch[10] Batch [300]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.142234,	
2017-06-27 18:45:37,855 Epoch[10] Batch [310]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.142404,	
2017-06-27 18:45:48,705 Epoch[10] Batch [320]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.143302,	
2017-06-27 18:46:00,081 Epoch[10] Batch [330]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.143719,	
2017-06-27 18:46:10,692 Epoch[10] Batch [340]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.143568,	
2017-06-27 18:46:22,240 Epoch[10] Batch [350]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.143306,	
2017-06-27 18:46:33,369 Epoch[10] Batch [360]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.143380,	
2017-06-27 18:46:43,471 Epoch[10] Batch [370]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.143266,	
2017-06-27 18:46:54,526 Epoch[10] Batch [380]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.143186,	
2017-06-27 18:47:06,383 Epoch[10] Batch [390]	Speed: 3.37 samples/sec	Train-FCNLogLoss=0.142784,	
2017-06-27 18:47:18,640 Epoch[10] Batch [400]	Speed: 3.26 samples/sec	Train-FCNLogLoss=0.142340,	
2017-06-27 18:47:29,411 Epoch[10] Batch [410]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.142223,	
2017-06-27 18:47:39,909 Epoch[10] Batch [420]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.142304,	
2017-06-27 18:47:51,630 Epoch[10] Batch [430]	Speed: 3.41 samples/sec	Train-FCNLogLoss=0.142413,	
2017-06-27 18:48:02,150 Epoch[10] Batch [440]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.142213,	
2017-06-27 18:48:13,655 Epoch[10] Batch [450]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.142209,	
2017-06-27 18:48:25,061 Epoch[10] Batch [460]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.142417,	
2017-06-27 18:48:37,635 Epoch[10] Batch [470]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.141954,	
2017-06-27 18:48:49,543 Epoch[10] Batch [480]	Speed: 3.36 samples/sec	Train-FCNLogLoss=0.141840,	
2017-06-27 18:49:01,235 Epoch[10] Batch [490]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.141659,	
2017-06-27 18:49:12,826 Epoch[10] Batch [500]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.141304,	
2017-06-27 18:49:23,813 Epoch[10] Batch [510]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.141662,	
2017-06-27 18:49:37,639 Epoch[10] Batch [520]	Speed: 2.90 samples/sec	Train-FCNLogLoss=0.141648,	
2017-06-27 18:49:47,637 Epoch[10] Batch [530]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.141272,	
2017-06-27 18:49:57,867 Epoch[10] Batch [540]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.141062,	
2017-06-27 18:50:08,818 Epoch[10] Batch [550]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.140953,	
2017-06-27 18:50:20,348 Epoch[10] Batch [560]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.140792,	
2017-06-27 18:50:32,796 Epoch[10] Batch [570]	Speed: 3.21 samples/sec	Train-FCNLogLoss=0.141263,	
2017-06-27 18:50:43,897 Epoch[10] Batch [580]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.141301,	
2017-06-27 18:50:55,445 Epoch[10] Batch [590]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.141434,	
2017-06-27 18:51:08,160 Epoch[10] Batch [600]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.141218,	
2017-06-27 18:51:19,836 Epoch[10] Batch [610]	Speed: 3.43 samples/sec	Train-FCNLogLoss=0.141276,	
2017-06-27 18:51:30,276 Epoch[10] Batch [620]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.141104,	
2017-06-27 18:51:40,834 Epoch[10] Batch [630]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.141005,	
2017-06-27 18:51:51,720 Epoch[10] Batch [640]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.141227,	
2017-06-27 18:52:03,433 Epoch[10] Batch [650]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.140963,	
2017-06-27 18:52:13,026 Epoch[10] Batch [660]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.141084,	
2017-06-27 18:52:23,777 Epoch[10] Batch [670]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.140962,	
2017-06-27 18:52:42,550 Epoch[10] Batch [680]	Speed: 2.13 samples/sec	Train-FCNLogLoss=0.141044,	
2017-06-27 18:52:52,458 Epoch[10] Batch [690]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.141207,	
2017-06-27 18:53:02,196 Epoch[10] Batch [700]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.141020,	
2017-06-27 18:53:11,201 Epoch[10] Batch [710]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.140928,	
2017-06-27 18:53:19,687 Epoch[10] Batch [720]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.140800,	
2017-06-27 18:53:31,521 Epoch[10] Batch [730]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.140634,	
2017-06-27 18:53:42,812 Epoch[10] Batch [740]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.140476,	
2017-06-27 18:53:52,707 Epoch[10] Batch [750]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.140371,	
2017-06-27 18:54:03,435 Epoch[10] Batch [760]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.140280,	
2017-06-27 18:54:13,917 Epoch[10] Batch [770]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.140111,	
2017-06-27 18:54:25,185 Epoch[10] Batch [780]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.140121,	
2017-06-27 18:54:35,151 Epoch[10] Batch [790]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.140129,	
2017-06-27 18:54:45,416 Epoch[10] Batch [800]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.139991,	
2017-06-27 18:54:55,634 Epoch[10] Batch [810]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.140171,	
2017-06-27 18:55:05,812 Epoch[10] Batch [820]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.139988,	
2017-06-27 18:55:16,772 Epoch[10] Batch [830]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.139849,	
2017-06-27 18:55:27,137 Epoch[10] Batch [840]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.139521,	
2017-06-27 18:55:37,056 Epoch[10] Batch [850]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.139408,	
2017-06-27 18:55:48,525 Epoch[10] Batch [860]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.139332,	
2017-06-27 18:55:59,855 Epoch[10] Batch [870]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.139173,	
2017-06-27 18:56:09,974 Epoch[10] Batch [880]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.139410,	
2017-06-27 18:56:20,941 Epoch[10] Batch [890]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.139814,	
2017-06-27 18:56:31,818 Epoch[10] Batch [900]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.140216,	
2017-06-27 18:56:41,234 Epoch[10] Batch [910]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.140594,	
2017-06-27 18:56:50,267 Epoch[10] Batch [920]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.140513,	
2017-06-27 18:57:00,038 Epoch[10] Batch [930]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.140416,	
2017-06-27 18:57:10,088 Epoch[10] Batch [940]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.140324,	
2017-06-27 18:57:20,551 Epoch[10] Batch [950]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.140248,	
2017-06-27 18:57:30,434 Epoch[10] Batch [960]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.140292,	
2017-06-27 18:57:43,812 Epoch[10] Batch [970]	Speed: 2.99 samples/sec	Train-FCNLogLoss=0.140630,	
2017-06-27 18:57:53,136 Epoch[10] Batch [980]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.140621,	
2017-06-27 18:58:02,355 Epoch[10] Batch [990]	Speed: 4.34 samples/sec	Train-FCNLogLoss=0.140618,	
2017-06-27 18:58:12,896 Epoch[10] Batch [1000]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.140632,	
2017-06-27 18:58:23,285 Epoch[10] Batch [1010]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.140839,	
2017-06-27 18:58:33,878 Epoch[10] Batch [1020]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.140883,	
2017-06-27 18:58:44,213 Epoch[10] Batch [1030]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.140746,	
2017-06-27 18:58:54,943 Epoch[10] Batch [1040]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.140618,	
2017-06-27 18:59:14,657 Epoch[10] Batch [1050]	Speed: 2.03 samples/sec	Train-FCNLogLoss=0.140673,	
2017-06-27 18:59:24,953 Epoch[10] Batch [1060]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.140739,	
2017-06-27 18:59:34,741 Epoch[10] Batch [1070]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.140563,	
2017-06-27 18:59:44,621 Epoch[10] Batch [1080]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.140420,	
2017-06-27 18:59:54,364 Epoch[10] Batch [1090]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.140445,	
2017-06-27 19:00:04,316 Epoch[10] Batch [1100]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.140640,	
2017-06-27 19:00:20,105 Epoch[10] Batch [1110]	Speed: 2.53 samples/sec	Train-FCNLogLoss=0.140525,	
2017-06-27 19:00:29,668 Epoch[10] Batch [1120]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.140628,	
2017-06-27 19:00:40,147 Epoch[10] Batch [1130]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.140783,	
2017-06-27 19:00:50,393 Epoch[10] Batch [1140]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.140863,	
2017-06-27 19:01:00,438 Epoch[10] Batch [1150]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.140885,	
2017-06-27 19:01:10,109 Epoch[10] Batch [1160]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.140822,	
2017-06-27 19:01:20,639 Epoch[10] Batch [1170]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.140885,	
2017-06-27 19:01:31,573 Epoch[10] Batch [1180]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.140886,	
2017-06-27 19:01:42,980 Epoch[10] Batch [1190]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.140805,	
2017-06-27 19:01:53,057 Epoch[10] Batch [1200]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.140747,	
2017-06-27 19:02:03,806 Epoch[10] Batch [1210]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.140704,	
2017-06-27 19:02:14,307 Epoch[10] Batch [1220]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.140572,	
2017-06-27 19:02:24,611 Epoch[10] Batch [1230]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.140534,	
2017-06-27 19:02:34,789 Epoch[10] Batch [1240]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.140549,	
2017-06-27 19:02:44,847 Epoch[10] Batch [1250]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.140621,	
2017-06-27 19:02:55,171 Epoch[10] Batch [1260]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.140759,	
2017-06-27 19:03:05,320 Epoch[10] Batch [1270]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.140841,	
2017-06-27 19:03:15,937 Epoch[10] Batch [1280]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.140782,	
2017-06-27 19:03:25,337 Epoch[10] Batch [1290]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.140702,	
2017-06-27 19:03:35,296 Epoch[10] Batch [1300]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.140516,	
2017-06-27 19:03:44,378 Epoch[10] Batch [1310]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.140402,	
2017-06-27 19:03:54,673 Epoch[10] Batch [1320]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.140387,	
2017-06-27 19:04:07,460 Epoch[10] Batch [1330]	Speed: 3.13 samples/sec	Train-FCNLogLoss=0.140294,	
2017-06-27 19:04:17,578 Epoch[10] Batch [1340]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.140336,	
2017-06-27 19:04:26,622 Epoch[10] Batch [1350]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.140259,	
2017-06-27 19:04:36,755 Epoch[10] Batch [1360]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.140179,	
2017-06-27 19:04:47,589 Epoch[10] Batch [1370]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.140223,	
2017-06-27 19:04:57,718 Epoch[10] Batch [1380]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.140258,	
2017-06-27 19:05:08,865 Epoch[10] Batch [1390]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.140279,	
2017-06-27 19:05:19,715 Epoch[10] Batch [1400]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.140375,	
2017-06-27 19:05:30,143 Epoch[10] Batch [1410]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.140295,	
2017-06-27 19:05:39,470 Epoch[10] Batch [1420]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.140229,	
2017-06-27 19:05:49,811 Epoch[10] Batch [1430]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.140253,	
2017-06-27 19:06:00,132 Epoch[10] Batch [1440]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.140294,	
2017-06-27 19:06:10,233 Epoch[10] Batch [1450]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.140548,	
2017-06-27 19:06:20,695 Epoch[10] Batch [1460]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.140522,	
2017-06-27 19:06:30,437 Epoch[10] Batch [1470]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.140454,	
2017-06-27 19:06:41,725 Epoch[10] Batch [1480]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.140315,	
2017-06-27 19:06:47,359 Epoch[10] Train-FCNLogLoss=0.140212
2017-06-27 19:06:47,360 Epoch[10] Time cost=1619.340
2017-06-27 19:06:58,927 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0011.params"
2017-06-27 19:07:10,361 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0011.states"
2017-06-27 19:07:22,861 Epoch[11] Batch [10]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.121415,	
2017-06-27 19:07:32,857 Epoch[11] Batch [20]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.125655,	
2017-06-27 19:07:42,933 Epoch[11] Batch [30]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.137850,	
2017-06-27 19:07:53,518 Epoch[11] Batch [40]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.139430,	
2017-06-27 19:08:03,613 Epoch[11] Batch [50]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.139294,	
2017-06-27 19:08:14,182 Epoch[11] Batch [60]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.136898,	
2017-06-27 19:08:24,131 Epoch[11] Batch [70]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.136790,	
2017-06-27 19:08:34,652 Epoch[11] Batch [80]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.134773,	
2017-06-27 19:08:45,643 Epoch[11] Batch [90]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.134944,	
2017-06-27 19:08:57,983 Epoch[11] Batch [100]	Speed: 3.24 samples/sec	Train-FCNLogLoss=0.134985,	
2017-06-27 19:09:07,879 Epoch[11] Batch [110]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.135987,	
2017-06-27 19:09:18,797 Epoch[11] Batch [120]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.135730,	
2017-06-27 19:09:28,785 Epoch[11] Batch [130]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.135730,	
2017-06-27 19:09:39,720 Epoch[11] Batch [140]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.136440,	
2017-06-27 19:09:48,768 Epoch[11] Batch [150]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.136332,	
2017-06-27 19:09:58,509 Epoch[11] Batch [160]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.136534,	
2017-06-27 19:10:08,307 Epoch[11] Batch [170]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.137130,	
2017-06-27 19:10:18,716 Epoch[11] Batch [180]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.139204,	
2017-06-27 19:10:28,750 Epoch[11] Batch [190]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.139313,	
2017-06-27 19:10:38,480 Epoch[11] Batch [200]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.139531,	
2017-06-27 19:10:48,286 Epoch[11] Batch [210]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.139233,	
2017-06-27 19:10:58,258 Epoch[11] Batch [220]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.139471,	
2017-06-27 19:11:08,255 Epoch[11] Batch [230]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.139778,	
2017-06-27 19:11:18,552 Epoch[11] Batch [240]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.141400,	
2017-06-27 19:11:28,285 Epoch[11] Batch [250]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.141853,	
2017-06-27 19:11:38,598 Epoch[11] Batch [260]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.141114,	
2017-06-27 19:11:48,469 Epoch[11] Batch [270]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.140594,	
2017-06-27 19:11:58,046 Epoch[11] Batch [280]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.140256,	
2017-06-27 19:12:07,938 Epoch[11] Batch [290]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.140057,	
2017-06-27 19:12:18,562 Epoch[11] Batch [300]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.139775,	
2017-06-27 19:12:29,493 Epoch[11] Batch [310]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.139168,	
2017-06-27 19:12:43,559 Epoch[11] Batch [320]	Speed: 2.84 samples/sec	Train-FCNLogLoss=0.139518,	
2017-06-27 19:12:53,352 Epoch[11] Batch [330]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.139276,	
2017-06-27 19:13:03,319 Epoch[11] Batch [340]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.139266,	
2017-06-27 19:13:12,773 Epoch[11] Batch [350]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.139358,	
2017-06-27 19:13:23,200 Epoch[11] Batch [360]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.139012,	
2017-06-27 19:13:34,342 Epoch[11] Batch [370]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.138770,	
2017-06-27 19:13:44,967 Epoch[11] Batch [380]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.138435,	
2017-06-27 19:13:56,902 Epoch[11] Batch [390]	Speed: 3.35 samples/sec	Train-FCNLogLoss=0.138248,	
2017-06-27 19:14:06,474 Epoch[11] Batch [400]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.138151,	
2017-06-27 19:14:16,306 Epoch[11] Batch [410]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.138315,	
2017-06-27 19:14:27,832 Epoch[11] Batch [420]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.137964,	
2017-06-27 19:14:38,811 Epoch[11] Batch [430]	Speed: 3.64 samples/sec	Train-FCNLogLoss=0.138106,	
2017-06-27 19:14:48,495 Epoch[11] Batch [440]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.138374,	
2017-06-27 19:14:58,382 Epoch[11] Batch [450]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.138295,	
2017-06-27 19:15:08,497 Epoch[11] Batch [460]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.138365,	
2017-06-27 19:15:18,552 Epoch[11] Batch [470]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.138298,	
2017-06-27 19:15:29,144 Epoch[11] Batch [480]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.138928,	
2017-06-27 19:15:39,160 Epoch[11] Batch [490]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.138699,	
2017-06-27 19:15:49,371 Epoch[11] Batch [500]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.138207,	
2017-06-27 19:15:59,116 Epoch[11] Batch [510]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.138097,	
2017-06-27 19:16:10,082 Epoch[11] Batch [520]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.138015,	
2017-06-27 19:16:19,463 Epoch[11] Batch [530]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.138187,	
2017-06-27 19:16:29,705 Epoch[11] Batch [540]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.138018,	
2017-06-27 19:16:39,939 Epoch[11] Batch [550]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.138391,	
2017-06-27 19:16:51,000 Epoch[11] Batch [560]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.138299,	
2017-06-27 19:17:01,524 Epoch[11] Batch [570]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.138021,	
2017-06-27 19:17:11,837 Epoch[11] Batch [580]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.137943,	
2017-06-27 19:17:21,843 Epoch[11] Batch [590]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.137756,	
2017-06-27 19:17:32,103 Epoch[11] Batch [600]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.137633,	
2017-06-27 19:17:42,273 Epoch[11] Batch [610]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.137432,	
2017-06-27 19:17:52,548 Epoch[11] Batch [620]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.137624,	
2017-06-27 19:18:02,402 Epoch[11] Batch [630]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.137384,	
2017-06-27 19:18:12,915 Epoch[11] Batch [640]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.137500,	
2017-06-27 19:18:23,217 Epoch[11] Batch [650]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.137295,	
2017-06-27 19:18:33,402 Epoch[11] Batch [660]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.137374,	
2017-06-27 19:18:43,826 Epoch[11] Batch [670]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.137096,	
2017-06-27 19:18:53,655 Epoch[11] Batch [680]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.136904,	
2017-06-27 19:19:04,910 Epoch[11] Batch [690]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.136832,	
2017-06-27 19:19:16,054 Epoch[11] Batch [700]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.137018,	
2017-06-27 19:19:26,050 Epoch[11] Batch [710]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.136733,	
2017-06-27 19:19:36,269 Epoch[11] Batch [720]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.136926,	
2017-06-27 19:19:47,218 Epoch[11] Batch [730]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.136708,	
2017-06-27 19:19:57,304 Epoch[11] Batch [740]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.136974,	
2017-06-27 19:20:07,917 Epoch[11] Batch [750]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.137165,	
2017-06-27 19:20:18,474 Epoch[11] Batch [760]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.137201,	
2017-06-27 19:20:29,124 Epoch[11] Batch [770]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.137193,	
2017-06-27 19:20:39,142 Epoch[11] Batch [780]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.137141,	
2017-06-27 19:20:49,256 Epoch[11] Batch [790]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.137152,	
2017-06-27 19:20:59,237 Epoch[11] Batch [800]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.137072,	
2017-06-27 19:21:10,164 Epoch[11] Batch [810]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.137250,	
2017-06-27 19:21:20,583 Epoch[11] Batch [820]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.137178,	
2017-06-27 19:21:30,202 Epoch[11] Batch [830]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.137046,	
2017-06-27 19:21:41,229 Epoch[11] Batch [840]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.136841,	
2017-06-27 19:21:53,948 Epoch[11] Batch [850]	Speed: 3.15 samples/sec	Train-FCNLogLoss=0.136750,	
2017-06-27 19:22:03,955 Epoch[11] Batch [860]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.136572,	
2017-06-27 19:22:13,274 Epoch[11] Batch [870]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.136660,	
2017-06-27 19:22:22,975 Epoch[11] Batch [880]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.136660,	
2017-06-27 19:22:33,166 Epoch[11] Batch [890]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.136528,	
2017-06-27 19:22:42,868 Epoch[11] Batch [900]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.136428,	
2017-06-27 19:22:53,035 Epoch[11] Batch [910]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.136253,	
2017-06-27 19:23:04,334 Epoch[11] Batch [920]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.136278,	
2017-06-27 19:23:14,264 Epoch[11] Batch [930]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.136286,	
2017-06-27 19:23:24,080 Epoch[11] Batch [940]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.136481,	
2017-06-27 19:23:34,761 Epoch[11] Batch [950]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.136573,	
2017-06-27 19:23:44,639 Epoch[11] Batch [960]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.136475,	
2017-06-27 19:23:54,389 Epoch[11] Batch [970]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.136393,	
2017-06-27 19:24:05,101 Epoch[11] Batch [980]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.136467,	
2017-06-27 19:24:15,723 Epoch[11] Batch [990]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.136273,	
2017-06-27 19:24:25,665 Epoch[11] Batch [1000]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.136365,	
2017-06-27 19:24:36,168 Epoch[11] Batch [1010]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.136464,	
2017-06-27 19:24:46,144 Epoch[11] Batch [1020]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.136459,	
2017-06-27 19:24:56,266 Epoch[11] Batch [1030]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.136550,	
2017-06-27 19:25:05,999 Epoch[11] Batch [1040]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.136627,	
2017-06-27 19:25:16,255 Epoch[11] Batch [1050]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.136548,	
2017-06-27 19:25:27,347 Epoch[11] Batch [1060]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.136422,	
2017-06-27 19:25:38,310 Epoch[11] Batch [1070]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.136531,	
2017-06-27 19:25:48,739 Epoch[11] Batch [1080]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.136588,	
2017-06-27 19:25:58,347 Epoch[11] Batch [1090]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.136448,	
2017-06-27 19:26:08,629 Epoch[11] Batch [1100]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.136507,	
2017-06-27 19:26:20,340 Epoch[11] Batch [1110]	Speed: 3.42 samples/sec	Train-FCNLogLoss=0.136533,	
2017-06-27 19:26:30,764 Epoch[11] Batch [1120]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.136536,	
2017-06-27 19:26:42,180 Epoch[11] Batch [1130]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.136567,	
2017-06-27 19:26:52,865 Epoch[11] Batch [1140]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.136716,	
2017-06-27 19:27:05,006 Epoch[11] Batch [1150]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.136716,	
2017-06-27 19:27:22,830 Epoch[11] Batch [1160]	Speed: 2.24 samples/sec	Train-FCNLogLoss=0.136554,	
2017-06-27 19:27:33,066 Epoch[11] Batch [1170]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.136475,	
2017-06-27 19:27:43,270 Epoch[11] Batch [1180]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.136439,	
2017-06-27 19:27:52,823 Epoch[11] Batch [1190]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.136589,	
2017-06-27 19:28:02,676 Epoch[11] Batch [1200]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.136576,	
2017-06-27 19:28:13,435 Epoch[11] Batch [1210]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.136714,	
2017-06-27 19:28:23,920 Epoch[11] Batch [1220]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.136696,	
2017-06-27 19:28:34,144 Epoch[11] Batch [1230]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.136719,	
2017-06-27 19:28:44,206 Epoch[11] Batch [1240]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.136599,	
2017-06-27 19:28:54,576 Epoch[11] Batch [1250]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.136463,	
2017-06-27 19:29:05,624 Epoch[11] Batch [1260]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.136491,	
2017-06-27 19:29:15,264 Epoch[11] Batch [1270]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.136434,	
2017-06-27 19:29:25,348 Epoch[11] Batch [1280]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.136409,	
2017-06-27 19:29:36,055 Epoch[11] Batch [1290]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.136394,	
2017-06-27 19:29:46,029 Epoch[11] Batch [1300]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.136343,	
2017-06-27 19:29:56,557 Epoch[11] Batch [1310]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.136454,	
2017-06-27 19:30:07,676 Epoch[11] Batch [1320]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.136534,	
2017-06-27 19:30:18,529 Epoch[11] Batch [1330]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.136820,	
2017-06-27 19:30:30,677 Epoch[11] Batch [1340]	Speed: 3.29 samples/sec	Train-FCNLogLoss=0.136880,	
2017-06-27 19:30:41,075 Epoch[11] Batch [1350]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.136905,	
2017-06-27 19:30:51,959 Epoch[11] Batch [1360]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.136921,	
2017-06-27 19:31:02,993 Epoch[11] Batch [1370]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.137094,	
2017-06-27 19:31:13,491 Epoch[11] Batch [1380]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.137133,	
2017-06-27 19:31:23,504 Epoch[11] Batch [1390]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.137067,	
2017-06-27 19:31:35,046 Epoch[11] Batch [1400]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.136984,	
2017-06-27 19:31:45,193 Epoch[11] Batch [1410]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.137112,	
2017-06-27 19:31:56,080 Epoch[11] Batch [1420]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.137219,	
2017-06-27 19:32:08,214 Epoch[11] Batch [1430]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.137307,	
2017-06-27 19:32:19,474 Epoch[11] Batch [1440]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.137231,	
2017-06-27 19:32:29,687 Epoch[11] Batch [1450]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.137236,	
2017-06-27 19:32:39,758 Epoch[11] Batch [1460]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.137356,	
2017-06-27 19:32:49,715 Epoch[11] Batch [1470]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.137202,	
2017-06-27 19:32:59,919 Epoch[11] Batch [1480]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.137156,	
2017-06-27 19:33:06,816 Epoch[11] Train-FCNLogLoss=0.137135
2017-06-27 19:33:06,816 Epoch[11] Time cost=1556.368
2017-06-27 19:33:14,299 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0012.params"
2017-06-27 19:33:23,017 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0012.states"
2017-06-27 19:33:34,864 Epoch[12] Batch [10]	Speed: 3.94 samples/sec	Train-FCNLogLoss=0.128753,	
2017-06-27 19:33:43,732 Epoch[12] Batch [20]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.130495,	
2017-06-27 19:33:53,305 Epoch[12] Batch [30]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.134521,	
2017-06-27 19:34:03,013 Epoch[12] Batch [40]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.132444,	
2017-06-27 19:34:14,596 Epoch[12] Batch [50]	Speed: 3.45 samples/sec	Train-FCNLogLoss=0.129474,	
2017-06-27 19:34:24,874 Epoch[12] Batch [60]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.126553,	
2017-06-27 19:34:36,308 Epoch[12] Batch [70]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.124826,	
2017-06-27 19:34:46,364 Epoch[12] Batch [80]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.127070,	
2017-06-27 19:34:57,273 Epoch[12] Batch [90]	Speed: 3.67 samples/sec	Train-FCNLogLoss=0.130712,	
2017-06-27 19:35:07,785 Epoch[12] Batch [100]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.131097,	
2017-06-27 19:35:18,242 Epoch[12] Batch [110]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.133166,	
2017-06-27 19:35:28,285 Epoch[12] Batch [120]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.134279,	
2017-06-27 19:35:38,391 Epoch[12] Batch [130]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.134334,	
2017-06-27 19:35:48,971 Epoch[12] Batch [140]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.134538,	
2017-06-27 19:36:00,443 Epoch[12] Batch [150]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.134425,	
2017-06-27 19:36:10,462 Epoch[12] Batch [160]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.134069,	
2017-06-27 19:36:21,100 Epoch[12] Batch [170]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.133788,	
2017-06-27 19:36:31,023 Epoch[12] Batch [180]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.133943,	
2017-06-27 19:36:42,124 Epoch[12] Batch [190]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.134186,	
2017-06-27 19:36:52,415 Epoch[12] Batch [200]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.134131,	
2017-06-27 19:37:02,086 Epoch[12] Batch [210]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.134194,	
2017-06-27 19:37:13,358 Epoch[12] Batch [220]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.134271,	
2017-06-27 19:37:24,415 Epoch[12] Batch [230]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.133784,	
2017-06-27 19:37:35,957 Epoch[12] Batch [240]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.134790,	
2017-06-27 19:37:46,691 Epoch[12] Batch [250]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.134265,	
2017-06-27 19:37:57,431 Epoch[12] Batch [260]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.134503,	
2017-06-27 19:38:08,605 Epoch[12] Batch [270]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.134854,	
2017-06-27 19:38:19,679 Epoch[12] Batch [280]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.135396,	
2017-06-27 19:38:30,257 Epoch[12] Batch [290]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.135728,	
2017-06-27 19:38:39,843 Epoch[12] Batch [300]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.135357,	
2017-06-27 19:38:50,332 Epoch[12] Batch [310]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.135626,	
2017-06-27 19:39:01,399 Epoch[12] Batch [320]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.135817,	
2017-06-27 19:39:12,322 Epoch[12] Batch [330]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.135442,	
2017-06-27 19:39:23,214 Epoch[12] Batch [340]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.134971,	
2017-06-27 19:39:33,117 Epoch[12] Batch [350]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.134632,	
2017-06-27 19:39:43,745 Epoch[12] Batch [360]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.134771,	
2017-06-27 19:39:54,317 Epoch[12] Batch [370]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.134897,	
2017-06-27 19:40:05,756 Epoch[12] Batch [380]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.135092,	
2017-06-27 19:40:15,547 Epoch[12] Batch [390]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.135197,	
2017-06-27 19:40:25,762 Epoch[12] Batch [400]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.134892,	
2017-06-27 19:40:35,598 Epoch[12] Batch [410]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.134931,	
2017-06-27 19:40:45,681 Epoch[12] Batch [420]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.134864,	
2017-06-27 19:40:56,241 Epoch[12] Batch [430]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.135013,	
2017-06-27 19:41:05,952 Epoch[12] Batch [440]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.134731,	
2017-06-27 19:41:16,548 Epoch[12] Batch [450]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.134430,	
2017-06-27 19:41:26,605 Epoch[12] Batch [460]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.134427,	
2017-06-27 19:41:36,750 Epoch[12] Batch [470]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.134506,	
2017-06-27 19:41:46,857 Epoch[12] Batch [480]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.134856,	
2017-06-27 19:41:57,646 Epoch[12] Batch [490]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.134569,	
2017-06-27 19:42:07,438 Epoch[12] Batch [500]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.134678,	
2017-06-27 19:42:18,466 Epoch[12] Batch [510]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.134751,	
2017-06-27 19:42:28,894 Epoch[12] Batch [520]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.135142,	
2017-06-27 19:42:39,822 Epoch[12] Batch [530]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.134988,	
2017-06-27 19:42:49,577 Epoch[12] Batch [540]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.134842,	
2017-06-27 19:42:59,924 Epoch[12] Batch [550]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.134750,	
2017-06-27 19:43:10,347 Epoch[12] Batch [560]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.134642,	
2017-06-27 19:43:20,851 Epoch[12] Batch [570]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.134760,	
2017-06-27 19:43:32,217 Epoch[12] Batch [580]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.134619,	
2017-06-27 19:43:43,169 Epoch[12] Batch [590]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.134797,	
2017-06-27 19:43:53,995 Epoch[12] Batch [600]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.135321,	
2017-06-27 19:44:04,031 Epoch[12] Batch [610]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.135208,	
2017-06-27 19:44:14,088 Epoch[12] Batch [620]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.135116,	
2017-06-27 19:44:24,199 Epoch[12] Batch [630]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.134749,	
2017-06-27 19:44:34,508 Epoch[12] Batch [640]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.134643,	
2017-06-27 19:44:44,851 Epoch[12] Batch [650]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.134505,	
2017-06-27 19:44:55,614 Epoch[12] Batch [660]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.134578,	
2017-06-27 19:45:06,415 Epoch[12] Batch [670]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.134438,	
2017-06-27 19:45:16,176 Epoch[12] Batch [680]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.134376,	
2017-06-27 19:45:26,744 Epoch[12] Batch [690]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.134449,	
2017-06-27 19:45:37,334 Epoch[12] Batch [700]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.134508,	
2017-06-27 19:45:49,346 Epoch[12] Batch [710]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.134702,	
2017-06-27 19:46:00,084 Epoch[12] Batch [720]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.134382,	
2017-06-27 19:46:10,847 Epoch[12] Batch [730]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.134217,	
2017-06-27 19:46:21,918 Epoch[12] Batch [740]	Speed: 3.61 samples/sec	Train-FCNLogLoss=0.134166,	
2017-06-27 19:46:32,558 Epoch[12] Batch [750]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.134350,	
2017-06-27 19:46:43,749 Epoch[12] Batch [760]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.134306,	
2017-06-27 19:46:53,984 Epoch[12] Batch [770]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.134179,	
2017-06-27 19:47:04,334 Epoch[12] Batch [780]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.134253,	
2017-06-27 19:47:15,294 Epoch[12] Batch [790]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.134157,	
2017-06-27 19:47:25,988 Epoch[12] Batch [800]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.134004,	
2017-06-27 19:47:37,197 Epoch[12] Batch [810]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.133951,	
2017-06-27 19:47:48,743 Epoch[12] Batch [820]	Speed: 3.46 samples/sec	Train-FCNLogLoss=0.133828,	
2017-06-27 19:47:58,518 Epoch[12] Batch [830]	Speed: 4.09 samples/sec	Train-FCNLogLoss=0.133742,	
2017-06-27 19:48:08,952 Epoch[12] Batch [840]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.133618,	
2017-06-27 19:48:19,584 Epoch[12] Batch [850]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.134078,	
2017-06-27 19:48:29,837 Epoch[12] Batch [860]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.134088,	
2017-06-27 19:48:40,656 Epoch[12] Batch [870]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.134124,	
2017-06-27 19:48:50,914 Epoch[12] Batch [880]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.134438,	
2017-06-27 19:49:00,498 Epoch[12] Batch [890]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.134504,	
2017-06-27 19:49:11,529 Epoch[12] Batch [900]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.134383,	
2017-06-27 19:49:21,766 Epoch[12] Batch [910]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.134366,	
2017-06-27 19:49:31,995 Epoch[12] Batch [920]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.134318,	
2017-06-27 19:49:42,191 Epoch[12] Batch [930]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.134200,	
2017-06-27 19:49:53,671 Epoch[12] Batch [940]	Speed: 3.48 samples/sec	Train-FCNLogLoss=0.134151,	
2017-06-27 19:50:03,779 Epoch[12] Batch [950]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.134043,	
2017-06-27 19:50:13,621 Epoch[12] Batch [960]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.134098,	
2017-06-27 19:50:24,388 Epoch[12] Batch [970]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.134329,	
2017-06-27 19:50:35,791 Epoch[12] Batch [980]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.134410,	
2017-06-27 19:50:45,529 Epoch[12] Batch [990]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.134330,	
2017-06-27 19:50:55,975 Epoch[12] Batch [1000]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.134380,	
2017-06-27 19:51:07,124 Epoch[12] Batch [1010]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.134413,	
2017-06-27 19:51:17,320 Epoch[12] Batch [1020]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.134546,	
2017-06-27 19:51:27,508 Epoch[12] Batch [1030]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.134525,	
2017-06-27 19:51:37,917 Epoch[12] Batch [1040]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.134650,	
2017-06-27 19:51:49,765 Epoch[12] Batch [1050]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.134722,	
2017-06-27 19:52:00,371 Epoch[12] Batch [1060]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.134703,	
2017-06-27 19:52:10,423 Epoch[12] Batch [1070]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.134515,	
2017-06-27 19:52:22,480 Epoch[12] Batch [1080]	Speed: 3.32 samples/sec	Train-FCNLogLoss=0.134495,	
2017-06-27 19:52:33,593 Epoch[12] Batch [1090]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.134485,	
2017-06-27 19:52:44,362 Epoch[12] Batch [1100]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.134533,	
2017-06-27 19:52:54,533 Epoch[12] Batch [1110]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.134661,	
2017-06-27 19:53:05,342 Epoch[12] Batch [1120]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.134565,	
2017-06-27 19:53:15,508 Epoch[12] Batch [1130]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.134671,	
2017-06-27 19:53:25,514 Epoch[12] Batch [1140]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.134735,	
2017-06-27 19:53:35,982 Epoch[12] Batch [1150]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.134779,	
2017-06-27 19:53:47,295 Epoch[12] Batch [1160]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.134702,	
2017-06-27 19:53:58,394 Epoch[12] Batch [1170]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.134797,	
2017-06-27 19:54:09,031 Epoch[12] Batch [1180]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.134721,	
2017-06-27 19:54:20,216 Epoch[12] Batch [1190]	Speed: 3.58 samples/sec	Train-FCNLogLoss=0.134635,	
2017-06-27 19:54:30,597 Epoch[12] Batch [1200]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.134476,	
2017-06-27 19:54:41,043 Epoch[12] Batch [1210]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.134354,	
2017-06-27 19:54:55,038 Epoch[12] Batch [1220]	Speed: 2.86 samples/sec	Train-FCNLogLoss=0.134290,	
2017-06-27 19:55:05,005 Epoch[12] Batch [1230]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.134375,	
2017-06-27 19:55:15,234 Epoch[12] Batch [1240]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.134422,	
2017-06-27 19:55:25,136 Epoch[12] Batch [1250]	Speed: 4.04 samples/sec	Train-FCNLogLoss=0.134295,	
2017-06-27 19:55:35,749 Epoch[12] Batch [1260]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.134369,	
2017-06-27 19:55:45,737 Epoch[12] Batch [1270]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.134376,	
2017-06-27 19:55:56,557 Epoch[12] Batch [1280]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.134345,	
2017-06-27 19:56:07,144 Epoch[12] Batch [1290]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.134267,	
2017-06-27 19:56:17,712 Epoch[12] Batch [1300]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.134260,	
2017-06-27 19:56:28,122 Epoch[12] Batch [1310]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.134216,	
2017-06-27 19:56:39,572 Epoch[12] Batch [1320]	Speed: 3.49 samples/sec	Train-FCNLogLoss=0.134216,	
2017-06-27 19:56:50,371 Epoch[12] Batch [1330]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.134034,	
2017-06-27 19:57:03,022 Epoch[12] Batch [1340]	Speed: 3.16 samples/sec	Train-FCNLogLoss=0.133946,	
2017-06-27 19:57:14,239 Epoch[12] Batch [1350]	Speed: 3.57 samples/sec	Train-FCNLogLoss=0.133816,	
2017-06-27 19:57:24,979 Epoch[12] Batch [1360]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.133753,	
2017-06-27 19:57:37,000 Epoch[12] Batch [1370]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.133782,	
2017-06-27 19:57:47,366 Epoch[12] Batch [1380]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.133787,	
2017-06-27 19:57:58,036 Epoch[12] Batch [1390]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.133785,	
2017-06-27 19:58:09,165 Epoch[12] Batch [1400]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.133737,	
2017-06-27 19:58:20,092 Epoch[12] Batch [1410]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.133649,	
2017-06-27 19:58:30,482 Epoch[12] Batch [1420]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.133633,	
2017-06-27 19:58:42,556 Epoch[12] Batch [1430]	Speed: 3.31 samples/sec	Train-FCNLogLoss=0.133646,	
2017-06-27 19:58:53,262 Epoch[12] Batch [1440]	Speed: 3.74 samples/sec	Train-FCNLogLoss=0.133669,	
2017-06-27 19:59:04,308 Epoch[12] Batch [1450]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.133595,	
2017-06-27 19:59:14,354 Epoch[12] Batch [1460]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.133686,	
2017-06-27 19:59:24,645 Epoch[12] Batch [1470]	Speed: 3.89 samples/sec	Train-FCNLogLoss=0.133641,	
2017-06-27 19:59:35,316 Epoch[12] Batch [1480]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.133584,	
2017-06-27 19:59:42,312 Epoch[12] Train-FCNLogLoss=0.133651
2017-06-27 19:59:42,312 Epoch[12] Time cost=1579.176
2017-06-27 19:59:49,571 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0013.params"
2017-06-27 19:59:56,748 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0013.states"
2017-06-27 20:00:08,262 Epoch[13] Batch [10]	Speed: 4.10 samples/sec	Train-FCNLogLoss=0.126590,	
2017-06-27 20:00:17,450 Epoch[13] Batch [20]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.120251,	
2017-06-27 20:00:27,959 Epoch[13] Batch [30]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.127644,	
2017-06-27 20:00:39,016 Epoch[13] Batch [40]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.127320,	
2017-06-27 20:00:48,834 Epoch[13] Batch [50]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.125831,	
2017-06-27 20:00:58,781 Epoch[13] Batch [60]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.124768,	
2017-06-27 20:01:09,153 Epoch[13] Batch [70]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.125623,	
2017-06-27 20:01:19,753 Epoch[13] Batch [80]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.127743,	
2017-06-27 20:01:30,549 Epoch[13] Batch [90]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.126803,	
2017-06-27 20:01:40,846 Epoch[13] Batch [100]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.127282,	
2017-06-27 20:01:51,954 Epoch[13] Batch [110]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.126724,	
2017-06-27 20:02:02,929 Epoch[13] Batch [120]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.126284,	
2017-06-27 20:02:13,012 Epoch[13] Batch [130]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.126243,	
2017-06-27 20:02:23,317 Epoch[13] Batch [140]	Speed: 3.88 samples/sec	Train-FCNLogLoss=0.127260,	
2017-06-27 20:02:33,666 Epoch[13] Batch [150]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.128109,	
2017-06-27 20:02:44,955 Epoch[13] Batch [160]	Speed: 3.54 samples/sec	Train-FCNLogLoss=0.129135,	
2017-06-27 20:02:55,633 Epoch[13] Batch [170]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.129709,	
2017-06-27 20:03:07,485 Epoch[13] Batch [180]	Speed: 3.38 samples/sec	Train-FCNLogLoss=0.128886,	
2017-06-27 20:03:18,548 Epoch[13] Batch [190]	Speed: 3.62 samples/sec	Train-FCNLogLoss=0.129382,	
2017-06-27 20:03:29,057 Epoch[13] Batch [200]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.130383,	
2017-06-27 20:03:41,285 Epoch[13] Batch [210]	Speed: 3.27 samples/sec	Train-FCNLogLoss=0.130815,	
2017-06-27 20:03:51,521 Epoch[13] Batch [220]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.131499,	
2017-06-27 20:04:02,168 Epoch[13] Batch [230]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.132658,	
2017-06-27 20:04:14,287 Epoch[13] Batch [240]	Speed: 3.30 samples/sec	Train-FCNLogLoss=0.132492,	
2017-06-27 20:04:25,658 Epoch[13] Batch [250]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.132452,	
2017-06-27 20:04:36,577 Epoch[13] Batch [260]	Speed: 3.66 samples/sec	Train-FCNLogLoss=0.131865,	
2017-06-27 20:04:46,744 Epoch[13] Batch [270]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.131279,	
2017-06-27 20:04:57,124 Epoch[13] Batch [280]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.130832,	
2017-06-27 20:05:07,389 Epoch[13] Batch [290]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.130363,	
2017-06-27 20:05:17,766 Epoch[13] Batch [300]	Speed: 3.85 samples/sec	Train-FCNLogLoss=0.129702,	
2017-06-27 20:05:28,534 Epoch[13] Batch [310]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.129298,	
2017-06-27 20:05:38,557 Epoch[13] Batch [320]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.129423,	
2017-06-27 20:05:50,190 Epoch[13] Batch [330]	Speed: 3.44 samples/sec	Train-FCNLogLoss=0.129190,	
2017-06-27 20:06:00,033 Epoch[13] Batch [340]	Speed: 4.06 samples/sec	Train-FCNLogLoss=0.129295,	
2017-06-27 20:06:10,855 Epoch[13] Batch [350]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.128812,	
2017-06-27 20:06:20,982 Epoch[13] Batch [360]	Speed: 3.95 samples/sec	Train-FCNLogLoss=0.128511,	
2017-06-27 20:06:31,217 Epoch[13] Batch [370]	Speed: 3.91 samples/sec	Train-FCNLogLoss=0.128620,	
2017-06-27 20:06:42,354 Epoch[13] Batch [380]	Speed: 3.59 samples/sec	Train-FCNLogLoss=0.128631,	
2017-06-27 20:06:53,098 Epoch[13] Batch [390]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.128391,	
2017-06-27 20:07:03,509 Epoch[13] Batch [400]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.127896,	
2017-06-27 20:07:14,374 Epoch[13] Batch [410]	Speed: 3.68 samples/sec	Train-FCNLogLoss=0.127825,	
2017-06-27 20:07:26,963 Epoch[13] Batch [420]	Speed: 3.18 samples/sec	Train-FCNLogLoss=0.127873,	
2017-06-27 20:07:37,554 Epoch[13] Batch [430]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.128085,	
2017-06-27 20:07:48,958 Epoch[13] Batch [440]	Speed: 3.51 samples/sec	Train-FCNLogLoss=0.128261,	
2017-06-27 20:07:59,578 Epoch[13] Batch [450]	Speed: 3.77 samples/sec	Train-FCNLogLoss=0.128179,	
2017-06-27 20:08:09,396 Epoch[13] Batch [460]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.128249,	
2017-06-27 20:08:20,931 Epoch[13] Batch [470]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.127958,	
2017-06-27 20:08:31,421 Epoch[13] Batch [480]	Speed: 3.81 samples/sec	Train-FCNLogLoss=0.127730,	
2017-06-27 20:08:41,501 Epoch[13] Batch [490]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.127713,	
2017-06-27 20:08:51,051 Epoch[13] Batch [500]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.127759,	
2017-06-27 20:09:01,087 Epoch[13] Batch [510]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.127676,	
2017-06-27 20:09:12,052 Epoch[13] Batch [520]	Speed: 3.65 samples/sec	Train-FCNLogLoss=0.127957,	
2017-06-27 20:09:21,869 Epoch[13] Batch [530]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.128497,	
2017-06-27 20:09:32,591 Epoch[13] Batch [540]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.129170,	
2017-06-27 20:09:43,599 Epoch[13] Batch [550]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.129411,	
2017-06-27 20:09:53,655 Epoch[13] Batch [560]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.129262,	
2017-06-27 20:10:04,133 Epoch[13] Batch [570]	Speed: 3.82 samples/sec	Train-FCNLogLoss=0.129437,	
2017-06-27 20:10:14,494 Epoch[13] Batch [580]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.129265,	
2017-06-27 20:10:26,037 Epoch[13] Batch [590]	Speed: 3.47 samples/sec	Train-FCNLogLoss=0.129254,	
2017-06-27 20:10:36,367 Epoch[13] Batch [600]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.129286,	
2017-06-27 20:10:47,202 Epoch[13] Batch [610]	Speed: 3.69 samples/sec	Train-FCNLogLoss=0.129100,	
2017-06-27 20:10:57,451 Epoch[13] Batch [620]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.129194,	
2017-06-27 20:11:07,875 Epoch[13] Batch [630]	Speed: 3.84 samples/sec	Train-FCNLogLoss=0.129438,	
2017-06-27 20:11:18,132 Epoch[13] Batch [640]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.129657,	
2017-06-27 20:11:28,179 Epoch[13] Batch [650]	Speed: 3.98 samples/sec	Train-FCNLogLoss=0.129725,	
2017-06-27 20:11:38,634 Epoch[13] Batch [660]	Speed: 3.83 samples/sec	Train-FCNLogLoss=0.129703,	
2017-06-27 20:11:50,064 Epoch[13] Batch [670]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.129776,	
2017-06-27 20:11:59,719 Epoch[13] Batch [680]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.129961,	
2017-06-27 20:12:10,279 Epoch[13] Batch [690]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.130156,	
2017-06-27 20:12:20,151 Epoch[13] Batch [700]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.129952,	
2017-06-27 20:12:30,973 Epoch[13] Batch [710]	Speed: 3.70 samples/sec	Train-FCNLogLoss=0.129992,	
2017-06-27 20:12:42,345 Epoch[13] Batch [720]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.129802,	
2017-06-27 20:12:53,065 Epoch[13] Batch [730]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.129609,	
2017-06-27 20:13:03,644 Epoch[13] Batch [740]	Speed: 3.78 samples/sec	Train-FCNLogLoss=0.129632,	
2017-06-27 20:13:13,740 Epoch[13] Batch [750]	Speed: 3.96 samples/sec	Train-FCNLogLoss=0.129493,	
2017-06-27 20:13:24,285 Epoch[13] Batch [760]	Speed: 3.79 samples/sec	Train-FCNLogLoss=0.129478,	
2017-06-27 20:13:35,546 Epoch[13] Batch [770]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.129322,	
2017-06-27 20:13:45,530 Epoch[13] Batch [780]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.129136,	
2017-06-27 20:13:56,068 Epoch[13] Batch [790]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.129216,	
2017-06-27 20:14:07,335 Epoch[13] Batch [800]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.129255,	
2017-06-27 20:14:18,066 Epoch[13] Batch [810]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.129226,	
2017-06-27 20:14:30,254 Epoch[13] Batch [820]	Speed: 3.28 samples/sec	Train-FCNLogLoss=0.129195,	
2017-06-27 20:14:41,592 Epoch[13] Batch [830]	Speed: 3.53 samples/sec	Train-FCNLogLoss=0.129221,	
2017-06-27 20:14:52,711 Epoch[13] Batch [840]	Speed: 3.60 samples/sec	Train-FCNLogLoss=0.129164,	
2017-06-27 20:15:03,464 Epoch[13] Batch [850]	Speed: 3.72 samples/sec	Train-FCNLogLoss=0.129084,	
2017-06-27 20:15:14,828 Epoch[13] Batch [860]	Speed: 3.52 samples/sec	Train-FCNLogLoss=0.128935,	
2017-06-27 20:15:26,835 Epoch[13] Batch [870]	Speed: 3.33 samples/sec	Train-FCNLogLoss=0.129007,	
2017-06-27 20:15:37,559 Epoch[13] Batch [880]	Speed: 3.73 samples/sec	Train-FCNLogLoss=0.129053,	
2017-06-27 20:15:47,568 Epoch[13] Batch [890]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.129304,	
2017-06-27 20:15:57,826 Epoch[13] Batch [900]	Speed: 3.90 samples/sec	Train-FCNLogLoss=0.129337,	
2017-06-27 20:16:09,109 Epoch[13] Batch [910]	Speed: 3.55 samples/sec	Train-FCNLogLoss=0.129281,	
2017-06-27 20:16:19,744 Epoch[13] Batch [920]	Speed: 3.76 samples/sec	Train-FCNLogLoss=0.129221,	
2017-06-27 20:16:29,913 Epoch[13] Batch [930]	Speed: 3.93 samples/sec	Train-FCNLogLoss=0.129289,	
2017-06-27 20:16:40,438 Epoch[13] Batch [940]	Speed: 3.80 samples/sec	Train-FCNLogLoss=0.129307,	
2017-06-27 20:16:50,798 Epoch[13] Batch [950]	Speed: 3.86 samples/sec	Train-FCNLogLoss=0.129375,	
2017-06-27 20:17:02,219 Epoch[13] Batch [960]	Speed: 3.50 samples/sec	Train-FCNLogLoss=0.129423,	
2017-06-27 20:17:12,882 Epoch[13] Batch [970]	Speed: 3.75 samples/sec	Train-FCNLogLoss=0.129390,	
2017-06-27 20:17:23,679 Epoch[13] Batch [980]	Speed: 3.71 samples/sec	Train-FCNLogLoss=0.129432,	
2017-06-27 20:17:38,453 Epoch[13] Batch [990]	Speed: 2.71 samples/sec	Train-FCNLogLoss=0.129156,	
2017-06-27 20:17:46,850 Epoch[13] Batch [1000]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.129145,	
2017-06-27 20:17:55,793 Epoch[13] Batch [1010]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.128994,	
2017-06-27 20:18:04,281 Epoch[13] Batch [1020]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.129129,	
2017-06-27 20:18:13,519 Epoch[13] Batch [1030]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.129306,	
2017-06-27 20:18:21,953 Epoch[13] Batch [1040]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.129182,	
2017-06-27 20:18:30,341 Epoch[13] Batch [1050]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.129025,	
2017-06-27 20:18:37,620 Epoch[13] Batch [1060]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.128911,	
2017-06-27 20:18:46,011 Epoch[13] Batch [1070]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.129027,	
2017-06-27 20:18:53,821 Epoch[13] Batch [1080]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.128924,	
2017-06-27 20:19:01,749 Epoch[13] Batch [1090]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.128892,	
2017-06-27 20:19:09,113 Epoch[13] Batch [1100]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.128985,	
2017-06-27 20:19:16,448 Epoch[13] Batch [1110]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.128842,	
2017-06-27 20:19:24,722 Epoch[13] Batch [1120]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.128729,	
2017-06-27 20:19:32,138 Epoch[13] Batch [1130]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.128647,	
2017-06-27 20:19:40,517 Epoch[13] Batch [1140]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.128665,	
2017-06-27 20:19:47,172 Epoch[13] Batch [1150]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.128578,	
2017-06-27 20:19:53,823 Epoch[13] Batch [1160]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.128549,	
2017-06-27 20:20:01,411 Epoch[13] Batch [1170]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.128502,	
2017-06-27 20:20:08,479 Epoch[13] Batch [1180]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.128661,	
2017-06-27 20:20:15,480 Epoch[13] Batch [1190]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.128625,	
2017-06-27 20:20:22,216 Epoch[13] Batch [1200]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.128687,	
2017-06-27 20:20:28,593 Epoch[13] Batch [1210]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.128528,	
2017-06-27 20:20:36,036 Epoch[13] Batch [1220]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.128440,	
2017-06-27 20:20:42,674 Epoch[13] Batch [1230]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.128317,	
2017-06-27 20:20:48,993 Epoch[13] Batch [1240]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.128254,	
2017-06-27 20:20:55,316 Epoch[13] Batch [1250]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.128260,	
2017-06-27 20:21:01,315 Epoch[13] Batch [1260]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.128155,	
2017-06-27 20:21:06,808 Epoch[13] Batch [1270]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.128074,	
2017-06-27 20:21:13,269 Epoch[13] Batch [1280]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.128032,	
2017-06-27 20:21:19,382 Epoch[13] Batch [1290]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.128095,	
2017-06-27 20:21:25,699 Epoch[13] Batch [1300]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.128035,	
2017-06-27 20:21:32,260 Epoch[13] Batch [1310]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.128179,	
2017-06-27 20:21:38,648 Epoch[13] Batch [1320]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.128347,	
2017-06-27 20:21:45,456 Epoch[13] Batch [1330]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.128314,	
2017-06-27 20:21:51,355 Epoch[13] Batch [1340]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.128368,	
2017-06-27 20:21:56,823 Epoch[13] Batch [1350]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.128386,	
2017-06-27 20:22:02,477 Epoch[13] Batch [1360]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.128386,	
2017-06-27 20:22:08,665 Epoch[13] Batch [1370]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.128453,	
2017-06-27 20:22:14,200 Epoch[13] Batch [1380]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.128527,	
2017-06-27 20:22:19,891 Epoch[13] Batch [1390]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.128586,	
2017-06-27 20:22:25,865 Epoch[13] Batch [1400]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.128572,	
2017-06-27 20:22:30,572 Epoch[13] Batch [1410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.128541,	
2017-06-27 20:22:35,778 Epoch[13] Batch [1420]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.128552,	
2017-06-27 20:22:41,598 Epoch[13] Batch [1430]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.128465,	
2017-06-27 20:22:46,829 Epoch[13] Batch [1440]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.128586,	
2017-06-27 20:22:52,141 Epoch[13] Batch [1450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.128726,	
2017-06-27 20:22:57,720 Epoch[13] Batch [1460]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.128838,	
2017-06-27 20:23:03,469 Epoch[13] Batch [1470]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.128908,	
2017-06-27 20:23:08,115 Epoch[13] Batch [1480]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.128960,	
2017-06-27 20:23:11,230 Epoch[13] Train-FCNLogLoss=0.128964
2017-06-27 20:23:11,230 Epoch[13] Time cost=1394.219
2017-06-27 20:23:12,927 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0014.params"
2017-06-27 20:23:15,150 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0014.states"
2017-06-27 20:23:20,633 Epoch[14] Batch [10]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.113975,	
2017-06-27 20:23:25,162 Epoch[14] Batch [20]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.120325,	
2017-06-27 20:23:29,698 Epoch[14] Batch [30]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.118393,	
2017-06-27 20:23:34,278 Epoch[14] Batch [40]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.117359,	
2017-06-27 20:23:38,639 Epoch[14] Batch [50]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.119163,	
2017-06-27 20:23:42,865 Epoch[14] Batch [60]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.118628,	
2017-06-27 20:23:47,319 Epoch[14] Batch [70]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.118414,	
2017-06-27 20:23:51,731 Epoch[14] Batch [80]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.118638,	
2017-06-27 20:23:56,010 Epoch[14] Batch [90]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.119104,	
2017-06-27 20:24:00,633 Epoch[14] Batch [100]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.118575,	
2017-06-27 20:24:05,231 Epoch[14] Batch [110]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.118731,	
2017-06-27 20:24:09,516 Epoch[14] Batch [120]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.118362,	
2017-06-27 20:24:13,837 Epoch[14] Batch [130]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.118255,	
2017-06-27 20:24:18,092 Epoch[14] Batch [140]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.117463,	
2017-06-27 20:24:22,714 Epoch[14] Batch [150]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.117449,	
2017-06-27 20:24:26,947 Epoch[14] Batch [160]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.117915,	
2017-06-27 20:24:31,212 Epoch[14] Batch [170]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.118790,	
2017-06-27 20:24:35,700 Epoch[14] Batch [180]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.119440,	
2017-06-27 20:24:39,945 Epoch[14] Batch [190]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.119886,	
2017-06-27 20:24:44,380 Epoch[14] Batch [200]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.120620,	
2017-06-27 20:24:48,554 Epoch[14] Batch [210]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.120285,	
2017-06-27 20:24:52,695 Epoch[14] Batch [220]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.120209,	
2017-06-27 20:24:56,918 Epoch[14] Batch [230]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.120696,	
2017-06-27 20:25:01,105 Epoch[14] Batch [240]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.120670,	
2017-06-27 20:25:05,200 Epoch[14] Batch [250]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.121040,	
2017-06-27 20:25:09,470 Epoch[14] Batch [260]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.120929,	
2017-06-27 20:25:13,718 Epoch[14] Batch [270]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.120983,	
2017-06-27 20:25:17,965 Epoch[14] Batch [280]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.121120,	
2017-06-27 20:25:22,118 Epoch[14] Batch [290]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.120985,	
2017-06-27 20:25:26,340 Epoch[14] Batch [300]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.120756,	
2017-06-27 20:25:30,544 Epoch[14] Batch [310]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.120483,	
2017-06-27 20:25:34,710 Epoch[14] Batch [320]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.121059,	
2017-06-27 20:25:38,857 Epoch[14] Batch [330]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.121533,	
2017-06-27 20:25:43,066 Epoch[14] Batch [340]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.121767,	
2017-06-27 20:25:47,211 Epoch[14] Batch [350]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.121699,	
2017-06-27 20:25:51,348 Epoch[14] Batch [360]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.121948,	
2017-06-27 20:25:55,678 Epoch[14] Batch [370]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.122381,	
2017-06-27 20:25:59,882 Epoch[14] Batch [380]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.122561,	
2017-06-27 20:26:04,192 Epoch[14] Batch [390]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.122778,	
2017-06-27 20:26:08,358 Epoch[14] Batch [400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.123338,	
2017-06-27 20:26:12,668 Epoch[14] Batch [410]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.123266,	
2017-06-27 20:26:16,790 Epoch[14] Batch [420]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.123340,	
2017-06-27 20:26:21,013 Epoch[14] Batch [430]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.122836,	
2017-06-27 20:26:25,217 Epoch[14] Batch [440]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.123221,	
2017-06-27 20:26:29,409 Epoch[14] Batch [450]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.123430,	
2017-06-27 20:26:33,680 Epoch[14] Batch [460]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.123493,	
2017-06-27 20:26:37,841 Epoch[14] Batch [470]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.123755,	
2017-06-27 20:26:42,028 Epoch[14] Batch [480]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.123762,	
2017-06-27 20:26:46,290 Epoch[14] Batch [490]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.123717,	
2017-06-27 20:26:50,514 Epoch[14] Batch [500]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.123986,	
2017-06-27 20:26:54,704 Epoch[14] Batch [510]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.123901,	
2017-06-27 20:26:58,849 Epoch[14] Batch [520]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.123602,	
2017-06-27 20:27:02,959 Epoch[14] Batch [530]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.123730,	
2017-06-27 20:27:07,096 Epoch[14] Batch [540]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.123865,	
2017-06-27 20:27:11,216 Epoch[14] Batch [550]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.123866,	
2017-06-27 20:27:15,357 Epoch[14] Batch [560]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.123919,	
2017-06-27 20:27:19,514 Epoch[14] Batch [570]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.124208,	
2017-06-27 20:27:23,732 Epoch[14] Batch [580]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.124555,	
2017-06-27 20:27:27,851 Epoch[14] Batch [590]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.124763,	
2017-06-27 20:27:31,913 Epoch[14] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.124787,	
2017-06-27 20:27:36,028 Epoch[14] Batch [610]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.125104,	
2017-06-27 20:27:40,095 Epoch[14] Batch [620]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.125135,	
2017-06-27 20:27:44,222 Epoch[14] Batch [630]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.125149,	
2017-06-27 20:27:48,324 Epoch[14] Batch [640]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.125140,	
2017-06-27 20:27:52,419 Epoch[14] Batch [650]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.125208,	
2017-06-27 20:27:56,578 Epoch[14] Batch [660]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.125174,	
2017-06-27 20:28:00,613 Epoch[14] Batch [670]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.125344,	
2017-06-27 20:28:04,705 Epoch[14] Batch [680]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.125671,	
2017-06-27 20:28:08,782 Epoch[14] Batch [690]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.126051,	
2017-06-27 20:28:12,935 Epoch[14] Batch [700]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.126466,	
2017-06-27 20:28:17,016 Epoch[14] Batch [710]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.126560,	
2017-06-27 20:28:21,119 Epoch[14] Batch [720]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.126582,	
2017-06-27 20:28:25,305 Epoch[14] Batch [730]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.126639,	
2017-06-27 20:28:29,456 Epoch[14] Batch [740]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.126635,	
2017-06-27 20:28:33,525 Epoch[14] Batch [750]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.127066,	
2017-06-27 20:28:37,669 Epoch[14] Batch [760]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.128060,	
2017-06-27 20:28:41,699 Epoch[14] Batch [770]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.128884,	
2017-06-27 20:28:45,814 Epoch[14] Batch [780]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.129240,	
2017-06-27 20:28:49,897 Epoch[14] Batch [790]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.130165,	
2017-06-27 20:28:53,970 Epoch[14] Batch [800]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.132506,	
2017-06-27 20:28:58,105 Epoch[14] Batch [810]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.133613,	
2017-06-27 20:29:02,261 Epoch[14] Batch [820]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.134565,	
2017-06-27 20:29:06,418 Epoch[14] Batch [830]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.135561,	
2017-06-27 20:29:10,588 Epoch[14] Batch [840]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.135815,	
2017-06-27 20:29:14,670 Epoch[14] Batch [850]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.136150,	
2017-06-27 20:29:18,813 Epoch[14] Batch [860]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.136118,	
2017-06-27 20:29:22,965 Epoch[14] Batch [870]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.136490,	
2017-06-27 20:29:27,103 Epoch[14] Batch [880]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.136815,	
2017-06-27 20:29:31,289 Epoch[14] Batch [890]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.137127,	
2017-06-27 20:29:35,528 Epoch[14] Batch [900]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.137401,	
2017-06-27 20:29:39,654 Epoch[14] Batch [910]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.137362,	
2017-06-27 20:29:43,724 Epoch[14] Batch [920]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.137393,	
2017-06-27 20:29:47,864 Epoch[14] Batch [930]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.137456,	
2017-06-27 20:29:52,049 Epoch[14] Batch [940]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.137313,	
2017-06-27 20:29:56,070 Epoch[14] Batch [950]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.137308,	
2017-06-27 20:30:00,231 Epoch[14] Batch [960]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.137330,	
2017-06-27 20:30:04,325 Epoch[14] Batch [970]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.137574,	
2017-06-27 20:30:08,443 Epoch[14] Batch [980]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.137652,	
2017-06-27 20:30:12,653 Epoch[14] Batch [990]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.137675,	
2017-06-27 20:30:16,799 Epoch[14] Batch [1000]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.137581,	
2017-06-27 20:30:21,038 Epoch[14] Batch [1010]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.137500,	
2017-06-27 20:30:25,087 Epoch[14] Batch [1020]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.137682,	
2017-06-27 20:30:29,204 Epoch[14] Batch [1030]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.137754,	
2017-06-27 20:30:33,383 Epoch[14] Batch [1040]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.137695,	
2017-06-27 20:30:37,490 Epoch[14] Batch [1050]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.137650,	
2017-06-27 20:30:41,500 Epoch[14] Batch [1060]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.137570,	
2017-06-27 20:30:45,621 Epoch[14] Batch [1070]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.137577,	
2017-06-27 20:30:49,744 Epoch[14] Batch [1080]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.137424,	
2017-06-27 20:30:53,876 Epoch[14] Batch [1090]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.137332,	
2017-06-27 20:30:57,973 Epoch[14] Batch [1100]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.137221,	
2017-06-27 20:31:02,045 Epoch[14] Batch [1110]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.137179,	
2017-06-27 20:31:06,056 Epoch[14] Batch [1120]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.137263,	
2017-06-27 20:31:10,163 Epoch[14] Batch [1130]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.137046,	
2017-06-27 20:31:14,311 Epoch[14] Batch [1140]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.136967,	
2017-06-27 20:31:18,428 Epoch[14] Batch [1150]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.136940,	
2017-06-27 20:31:22,537 Epoch[14] Batch [1160]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136854,	
2017-06-27 20:31:26,582 Epoch[14] Batch [1170]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.136773,	
2017-06-27 20:31:30,722 Epoch[14] Batch [1180]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.136776,	
2017-06-27 20:31:34,870 Epoch[14] Batch [1190]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.136660,	
2017-06-27 20:31:39,049 Epoch[14] Batch [1200]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.136662,	
2017-06-27 20:31:43,084 Epoch[14] Batch [1210]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.136639,	
2017-06-27 20:31:47,311 Epoch[14] Batch [1220]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.136656,	
2017-06-27 20:31:51,443 Epoch[14] Batch [1230]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.136512,	
2017-06-27 20:31:55,487 Epoch[14] Batch [1240]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.136388,	
2017-06-27 20:31:59,586 Epoch[14] Batch [1250]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.136343,	
2017-06-27 20:32:03,571 Epoch[14] Batch [1260]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.136308,	
2017-06-27 20:32:07,847 Epoch[14] Batch [1270]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.136213,	
2017-06-27 20:32:11,941 Epoch[14] Batch [1280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.136383,	
2017-06-27 20:32:15,985 Epoch[14] Batch [1290]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.136562,	
2017-06-27 20:32:20,075 Epoch[14] Batch [1300]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.136784,	
2017-06-27 20:32:24,210 Epoch[14] Batch [1310]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.136762,	
2017-06-27 20:32:28,436 Epoch[14] Batch [1320]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.136627,	
2017-06-27 20:32:32,507 Epoch[14] Batch [1330]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.136625,	
2017-06-27 20:32:36,605 Epoch[14] Batch [1340]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.136571,	
2017-06-27 20:32:40,705 Epoch[14] Batch [1350]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.136470,	
2017-06-27 20:32:44,753 Epoch[14] Batch [1360]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.136408,	
2017-06-27 20:32:49,027 Epoch[14] Batch [1370]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.136213,	
2017-06-27 20:32:53,088 Epoch[14] Batch [1380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.136511,	
2017-06-27 20:32:57,185 Epoch[14] Batch [1390]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.136563,	
2017-06-27 20:33:01,249 Epoch[14] Batch [1400]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.136697,	
2017-06-27 20:33:05,387 Epoch[14] Batch [1410]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.136772,	
2017-06-27 20:33:09,557 Epoch[14] Batch [1420]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.136651,	
2017-06-27 20:33:13,546 Epoch[14] Batch [1430]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.136699,	
2017-06-27 20:33:17,693 Epoch[14] Batch [1440]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136778,	
2017-06-27 20:33:21,732 Epoch[14] Batch [1450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.136746,	
2017-06-27 20:33:25,723 Epoch[14] Batch [1460]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.136727,	
2017-06-27 20:33:29,756 Epoch[14] Batch [1470]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.136826,	
2017-06-27 20:33:33,832 Epoch[14] Batch [1480]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.136801,	
2017-06-27 20:33:36,276 Epoch[14] Train-FCNLogLoss=0.136753
2017-06-27 20:33:36,276 Epoch[14] Time cost=621.125
2017-06-27 20:33:37,119 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0015.params"
2017-06-27 20:33:38,758 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0015.states"
2017-06-27 20:33:43,537 Epoch[15] Batch [10]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.144808,	
2017-06-27 20:33:47,553 Epoch[15] Batch [20]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.133085,	
2017-06-27 20:33:51,672 Epoch[15] Batch [30]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.124646,	
2017-06-27 20:33:55,694 Epoch[15] Batch [40]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.123754,	
2017-06-27 20:33:59,804 Epoch[15] Batch [50]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.124554,	
2017-06-27 20:34:03,915 Epoch[15] Batch [60]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.122848,	
2017-06-27 20:34:08,056 Epoch[15] Batch [70]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.123833,	
2017-06-27 20:34:12,136 Epoch[15] Batch [80]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.123176,	
2017-06-27 20:34:16,320 Epoch[15] Batch [90]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.124237,	
2017-06-27 20:34:20,349 Epoch[15] Batch [100]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.124697,	
2017-06-27 20:34:24,374 Epoch[15] Batch [110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.125960,	
2017-06-27 20:34:28,547 Epoch[15] Batch [120]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.126451,	
2017-06-27 20:34:32,580 Epoch[15] Batch [130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.128512,	
2017-06-27 20:34:36,656 Epoch[15] Batch [140]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.132987,	
2017-06-27 20:34:40,791 Epoch[15] Batch [150]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.135045,	
2017-06-27 20:34:44,935 Epoch[15] Batch [160]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136414,	
2017-06-27 20:34:49,039 Epoch[15] Batch [170]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.137207,	
2017-06-27 20:34:53,139 Epoch[15] Batch [180]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.137247,	
2017-06-27 20:34:57,282 Epoch[15] Batch [190]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.136600,	
2017-06-27 20:35:01,394 Epoch[15] Batch [200]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.136396,	
2017-06-27 20:35:05,548 Epoch[15] Batch [210]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.136334,	
2017-06-27 20:35:09,664 Epoch[15] Batch [220]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.136308,	
2017-06-27 20:35:13,785 Epoch[15] Batch [230]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.135869,	
2017-06-27 20:35:17,989 Epoch[15] Batch [240]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.136331,	
2017-06-27 20:35:22,039 Epoch[15] Batch [250]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.136702,	
2017-06-27 20:35:26,106 Epoch[15] Batch [260]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.136821,	
2017-06-27 20:35:30,374 Epoch[15] Batch [270]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.136597,	
2017-06-27 20:35:34,556 Epoch[15] Batch [280]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.136224,	
2017-06-27 20:35:38,723 Epoch[15] Batch [290]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.135711,	
2017-06-27 20:35:42,797 Epoch[15] Batch [300]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.135800,	
2017-06-27 20:35:47,065 Epoch[15] Batch [310]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.135492,	
2017-06-27 20:35:51,190 Epoch[15] Batch [320]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.135169,	
2017-06-27 20:35:55,292 Epoch[15] Batch [330]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.134717,	
2017-06-27 20:35:59,486 Epoch[15] Batch [340]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.135140,	
2017-06-27 20:36:03,677 Epoch[15] Batch [350]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.135157,	
2017-06-27 20:36:07,689 Epoch[15] Batch [360]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.135779,	
2017-06-27 20:36:11,682 Epoch[15] Batch [370]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.135853,	
2017-06-27 20:36:15,683 Epoch[15] Batch [380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.136196,	
2017-06-27 20:36:19,864 Epoch[15] Batch [390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.135626,	
2017-06-27 20:36:23,977 Epoch[15] Batch [400]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.135291,	
2017-06-27 20:36:28,010 Epoch[15] Batch [410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.134983,	
2017-06-27 20:36:32,108 Epoch[15] Batch [420]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.135216,	
2017-06-27 20:36:36,240 Epoch[15] Batch [430]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.134879,	
2017-06-27 20:36:40,350 Epoch[15] Batch [440]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134874,	
2017-06-27 20:36:44,475 Epoch[15] Batch [450]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.134579,	
2017-06-27 20:36:48,659 Epoch[15] Batch [460]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.134776,	
2017-06-27 20:36:52,754 Epoch[15] Batch [470]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.134498,	
2017-06-27 20:36:56,837 Epoch[15] Batch [480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.134137,	
2017-06-27 20:37:00,929 Epoch[15] Batch [490]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.133822,	
2017-06-27 20:37:05,059 Epoch[15] Batch [500]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.133651,	
2017-06-27 20:37:09,148 Epoch[15] Batch [510]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.133862,	
2017-06-27 20:37:13,312 Epoch[15] Batch [520]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.133874,	
2017-06-27 20:37:17,371 Epoch[15] Batch [530]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.133693,	
2017-06-27 20:37:21,465 Epoch[15] Batch [540]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.133438,	
2017-06-27 20:37:25,489 Epoch[15] Batch [550]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.133277,	
2017-06-27 20:37:29,589 Epoch[15] Batch [560]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.133110,	
2017-06-27 20:37:33,733 Epoch[15] Batch [570]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.133154,	
2017-06-27 20:37:37,891 Epoch[15] Batch [580]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.132757,	
2017-06-27 20:37:41,958 Epoch[15] Batch [590]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.132421,	
2017-06-27 20:37:46,057 Epoch[15] Batch [600]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.132037,	
2017-06-27 20:37:50,116 Epoch[15] Batch [610]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.131803,	
2017-06-27 20:37:54,191 Epoch[15] Batch [620]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.131579,	
2017-06-27 20:37:58,282 Epoch[15] Batch [630]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.131591,	
2017-06-27 20:38:02,423 Epoch[15] Batch [640]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.131757,	
2017-06-27 20:38:06,512 Epoch[15] Batch [650]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.131531,	
2017-06-27 20:38:10,501 Epoch[15] Batch [660]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.131250,	
2017-06-27 20:38:14,604 Epoch[15] Batch [670]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.131127,	
2017-06-27 20:38:18,786 Epoch[15] Batch [680]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.130847,	
2017-06-27 20:38:22,913 Epoch[15] Batch [690]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.130744,	
2017-06-27 20:38:26,964 Epoch[15] Batch [700]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.130587,	
2017-06-27 20:38:31,092 Epoch[15] Batch [710]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.130627,	
2017-06-27 20:38:35,172 Epoch[15] Batch [720]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.130467,	
2017-06-27 20:38:39,300 Epoch[15] Batch [730]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.130419,	
2017-06-27 20:38:43,489 Epoch[15] Batch [740]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.130227,	
2017-06-27 20:38:47,595 Epoch[15] Batch [750]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.130175,	
2017-06-27 20:38:51,784 Epoch[15] Batch [760]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.130146,	
2017-06-27 20:38:55,888 Epoch[15] Batch [770]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.130473,	
2017-06-27 20:38:59,954 Epoch[15] Batch [780]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.130502,	
2017-06-27 20:39:04,121 Epoch[15] Batch [790]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.130490,	
2017-06-27 20:39:08,214 Epoch[15] Batch [800]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.130335,	
2017-06-27 20:39:12,220 Epoch[15] Batch [810]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.130362,	
2017-06-27 20:39:16,267 Epoch[15] Batch [820]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.130397,	
2017-06-27 20:39:20,395 Epoch[15] Batch [830]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.130544,	
2017-06-27 20:39:24,534 Epoch[15] Batch [840]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.130447,	
2017-06-27 20:39:28,720 Epoch[15] Batch [850]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.130294,	
2017-06-27 20:39:32,763 Epoch[15] Batch [860]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.130358,	
2017-06-27 20:39:36,812 Epoch[15] Batch [870]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.130291,	
2017-06-27 20:39:40,844 Epoch[15] Batch [880]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.130189,	
2017-06-27 20:39:44,936 Epoch[15] Batch [890]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.130122,	
2017-06-27 20:39:49,033 Epoch[15] Batch [900]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.129991,	
2017-06-27 20:39:53,123 Epoch[15] Batch [910]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.129994,	
2017-06-27 20:39:57,319 Epoch[15] Batch [920]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.130085,	
2017-06-27 20:40:01,492 Epoch[15] Batch [930]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.130065,	
2017-06-27 20:40:05,644 Epoch[15] Batch [940]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.130639,	
2017-06-27 20:40:09,733 Epoch[15] Batch [950]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.133017,	
2017-06-27 20:40:13,770 Epoch[15] Batch [960]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.135558,	
2017-06-27 20:40:17,970 Epoch[15] Batch [970]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.136244,	
2017-06-27 20:40:22,142 Epoch[15] Batch [980]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.136909,	
2017-06-27 20:40:26,208 Epoch[15] Batch [990]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.137666,	
2017-06-27 20:40:30,373 Epoch[15] Batch [1000]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.137761,	
2017-06-27 20:40:34,433 Epoch[15] Batch [1010]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.137838,	
2017-06-27 20:40:38,545 Epoch[15] Batch [1020]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.138211,	
2017-06-27 20:40:42,652 Epoch[15] Batch [1030]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.138736,	
2017-06-27 20:40:46,776 Epoch[15] Batch [1040]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.139122,	
2017-06-27 20:40:50,823 Epoch[15] Batch [1050]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.139178,	
2017-06-27 20:40:54,938 Epoch[15] Batch [1060]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.139508,	
2017-06-27 20:40:58,967 Epoch[15] Batch [1070]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.139848,	
2017-06-27 20:41:03,101 Epoch[15] Batch [1080]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.139932,	
2017-06-27 20:41:07,162 Epoch[15] Batch [1090]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.140022,	
2017-06-27 20:41:11,276 Epoch[15] Batch [1100]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.140061,	
2017-06-27 20:41:15,446 Epoch[15] Batch [1110]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.140206,	
2017-06-27 20:41:19,553 Epoch[15] Batch [1120]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.140087,	
2017-06-27 20:41:23,657 Epoch[15] Batch [1130]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.140204,	
2017-06-27 20:41:27,771 Epoch[15] Batch [1140]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.140032,	
2017-06-27 20:41:31,845 Epoch[15] Batch [1150]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.140048,	
2017-06-27 20:41:36,022 Epoch[15] Batch [1160]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.139888,	
2017-06-27 20:41:40,141 Epoch[15] Batch [1170]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.139758,	
2017-06-27 20:41:44,317 Epoch[15] Batch [1180]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.139823,	
2017-06-27 20:41:48,381 Epoch[15] Batch [1190]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.139682,	
2017-06-27 20:41:52,519 Epoch[15] Batch [1200]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.139533,	
2017-06-27 20:41:56,652 Epoch[15] Batch [1210]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.139665,	
2017-06-27 20:42:00,815 Epoch[15] Batch [1220]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.139660,	
2017-06-27 20:42:05,050 Epoch[15] Batch [1230]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.139542,	
2017-06-27 20:42:09,272 Epoch[15] Batch [1240]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.139614,	
2017-06-27 20:42:13,392 Epoch[15] Batch [1250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.139476,	
2017-06-27 20:42:17,591 Epoch[15] Batch [1260]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.139437,	
2017-06-27 20:42:21,702 Epoch[15] Batch [1270]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.139472,	
2017-06-27 20:42:25,842 Epoch[15] Batch [1280]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.139391,	
2017-06-27 20:42:29,933 Epoch[15] Batch [1290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.139408,	
2017-06-27 20:42:33,994 Epoch[15] Batch [1300]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.139493,	
2017-06-27 20:42:38,143 Epoch[15] Batch [1310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.139574,	
2017-06-27 20:42:42,219 Epoch[15] Batch [1320]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.139504,	
2017-06-27 20:42:46,353 Epoch[15] Batch [1330]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.139310,	
2017-06-27 20:42:50,491 Epoch[15] Batch [1340]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.139363,	
2017-06-27 20:42:54,553 Epoch[15] Batch [1350]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.139314,	
2017-06-27 20:42:58,726 Epoch[15] Batch [1360]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.139231,	
2017-06-27 20:43:02,782 Epoch[15] Batch [1370]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.139277,	
2017-06-27 20:43:06,917 Epoch[15] Batch [1380]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.139229,	
2017-06-27 20:43:11,058 Epoch[15] Batch [1390]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.139428,	
2017-06-27 20:43:15,218 Epoch[15] Batch [1400]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.139353,	
2017-06-27 20:43:19,396 Epoch[15] Batch [1410]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.139254,	
2017-06-27 20:43:23,545 Epoch[15] Batch [1420]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.139193,	
2017-06-27 20:43:27,671 Epoch[15] Batch [1430]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.139009,	
2017-06-27 20:43:31,751 Epoch[15] Batch [1440]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.138932,	
2017-06-27 20:43:35,847 Epoch[15] Batch [1450]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.138792,	
2017-06-27 20:43:39,999 Epoch[15] Batch [1460]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.138654,	
2017-06-27 20:43:44,125 Epoch[15] Batch [1470]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.138593,	
2017-06-27 20:43:48,190 Epoch[15] Batch [1480]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.138638,	
2017-06-27 20:43:50,636 Epoch[15] Train-FCNLogLoss=0.138673
2017-06-27 20:43:50,637 Epoch[15] Time cost=611.879
2017-06-27 20:43:51,412 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0016.params"
2017-06-27 20:43:53,086 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0016.states"
2017-06-27 20:43:57,911 Epoch[16] Batch [10]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.148243,	
2017-06-27 20:44:02,059 Epoch[16] Batch [20]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.130088,	
2017-06-27 20:44:06,103 Epoch[16] Batch [30]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.130023,	
2017-06-27 20:44:10,269 Epoch[16] Batch [40]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.126769,	
2017-06-27 20:44:14,374 Epoch[16] Batch [50]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.130562,	
2017-06-27 20:44:18,482 Epoch[16] Batch [60]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.131542,	
2017-06-27 20:44:22,548 Epoch[16] Batch [70]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.132001,	
2017-06-27 20:44:26,795 Epoch[16] Batch [80]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.131277,	
2017-06-27 20:44:30,896 Epoch[16] Batch [90]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.131229,	
2017-06-27 20:44:35,132 Epoch[16] Batch [100]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.130287,	
2017-06-27 20:44:39,193 Epoch[16] Batch [110]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.130706,	
2017-06-27 20:44:43,362 Epoch[16] Batch [120]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.130396,	
2017-06-27 20:44:47,482 Epoch[16] Batch [130]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.130070,	
2017-06-27 20:44:51,625 Epoch[16] Batch [140]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.130537,	
2017-06-27 20:44:55,730 Epoch[16] Batch [150]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.131014,	
2017-06-27 20:44:59,808 Epoch[16] Batch [160]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.134128,	
2017-06-27 20:45:04,130 Epoch[16] Batch [170]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.134676,	
2017-06-27 20:45:08,187 Epoch[16] Batch [180]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.134357,	
2017-06-27 20:45:12,217 Epoch[16] Batch [190]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.134004,	
2017-06-27 20:45:16,508 Epoch[16] Batch [200]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.134651,	
2017-06-27 20:45:20,636 Epoch[16] Batch [210]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.134600,	
2017-06-27 20:45:24,727 Epoch[16] Batch [220]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.134062,	
2017-06-27 20:45:28,904 Epoch[16] Batch [230]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.133785,	
2017-06-27 20:45:33,157 Epoch[16] Batch [240]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.133223,	
2017-06-27 20:45:37,307 Epoch[16] Batch [250]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.132991,	
2017-06-27 20:45:41,401 Epoch[16] Batch [260]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.132393,	
2017-06-27 20:45:45,619 Epoch[16] Batch [270]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.132121,	
2017-06-27 20:45:49,859 Epoch[16] Batch [280]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.131807,	
2017-06-27 20:45:54,057 Epoch[16] Batch [290]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.131531,	
2017-06-27 20:45:58,309 Epoch[16] Batch [300]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.130807,	
2017-06-27 20:46:02,428 Epoch[16] Batch [310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.130902,	
2017-06-27 20:46:06,558 Epoch[16] Batch [320]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.131220,	
2017-06-27 20:46:10,764 Epoch[16] Batch [330]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.131186,	
2017-06-27 20:46:14,900 Epoch[16] Batch [340]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.131368,	
2017-06-27 20:46:19,028 Epoch[16] Batch [350]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.131090,	
2017-06-27 20:46:23,139 Epoch[16] Batch [360]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.130680,	
2017-06-27 20:46:27,277 Epoch[16] Batch [370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.130388,	
2017-06-27 20:46:31,422 Epoch[16] Batch [380]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.130298,	
2017-06-27 20:46:35,524 Epoch[16] Batch [390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.130296,	
2017-06-27 20:46:39,562 Epoch[16] Batch [400]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.130588,	
2017-06-27 20:46:43,706 Epoch[16] Batch [410]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.130511,	
2017-06-27 20:46:47,914 Epoch[16] Batch [420]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.130632,	
2017-06-27 20:46:52,076 Epoch[16] Batch [430]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.130408,	
2017-06-27 20:46:56,143 Epoch[16] Batch [440]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.130502,	
2017-06-27 20:47:00,223 Epoch[16] Batch [450]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.130307,	
2017-06-27 20:47:04,395 Epoch[16] Batch [460]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.130007,	
2017-06-27 20:47:08,575 Epoch[16] Batch [470]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.129942,	
2017-06-27 20:47:12,655 Epoch[16] Batch [480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.129686,	
2017-06-27 20:47:16,792 Epoch[16] Batch [490]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.129780,	
2017-06-27 20:47:20,909 Epoch[16] Batch [500]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.129712,	
2017-06-27 20:47:25,170 Epoch[16] Batch [510]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.129601,	
2017-06-27 20:47:29,274 Epoch[16] Batch [520]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.129435,	
2017-06-27 20:47:33,411 Epoch[16] Batch [530]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.129203,	
2017-06-27 20:47:37,475 Epoch[16] Batch [540]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.128968,	
2017-06-27 20:47:41,502 Epoch[16] Batch [550]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.128907,	
2017-06-27 20:47:45,500 Epoch[16] Batch [560]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.128703,	
2017-06-27 20:47:49,595 Epoch[16] Batch [570]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.128559,	
2017-06-27 20:47:53,684 Epoch[16] Batch [580]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.128318,	
2017-06-27 20:47:57,792 Epoch[16] Batch [590]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.128366,	
2017-06-27 20:48:01,869 Epoch[16] Batch [600]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.128146,	
2017-06-27 20:48:05,986 Epoch[16] Batch [610]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.128165,	
2017-06-27 20:48:10,132 Epoch[16] Batch [620]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.128266,	
2017-06-27 20:48:14,218 Epoch[16] Batch [630]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.128414,	
2017-06-27 20:48:18,388 Epoch[16] Batch [640]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.128860,	
2017-06-27 20:48:22,475 Epoch[16] Batch [650]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.128811,	
2017-06-27 20:48:26,661 Epoch[16] Batch [660]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.128671,	
2017-06-27 20:48:30,903 Epoch[16] Batch [670]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.128831,	
2017-06-27 20:48:35,001 Epoch[16] Batch [680]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.128771,	
2017-06-27 20:48:39,065 Epoch[16] Batch [690]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.128715,	
2017-06-27 20:48:43,227 Epoch[16] Batch [700]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.128800,	
2017-06-27 20:48:47,301 Epoch[16] Batch [710]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.128813,	
2017-06-27 20:48:51,387 Epoch[16] Batch [720]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.128606,	
2017-06-27 20:48:55,618 Epoch[16] Batch [730]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.128724,	
2017-06-27 20:48:59,693 Epoch[16] Batch [740]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.128644,	
2017-06-27 20:49:03,838 Epoch[16] Batch [750]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.128624,	
2017-06-27 20:49:08,023 Epoch[16] Batch [760]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.128507,	
2017-06-27 20:49:12,122 Epoch[16] Batch [770]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.128253,	
2017-06-27 20:49:16,303 Epoch[16] Batch [780]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.128112,	
2017-06-27 20:49:20,332 Epoch[16] Batch [790]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.128025,	
2017-06-27 20:49:24,516 Epoch[16] Batch [800]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.127876,	
2017-06-27 20:49:28,600 Epoch[16] Batch [810]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.127730,	
2017-06-27 20:49:32,662 Epoch[16] Batch [820]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.127527,	
2017-06-27 20:49:36,695 Epoch[16] Batch [830]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.127389,	
2017-06-27 20:49:40,824 Epoch[16] Batch [840]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.127312,	
2017-06-27 20:49:44,988 Epoch[16] Batch [850]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.127404,	
2017-06-27 20:49:49,199 Epoch[16] Batch [860]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.127305,	
2017-06-27 20:49:53,306 Epoch[16] Batch [870]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.127206,	
2017-06-27 20:49:57,462 Epoch[16] Batch [880]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.127014,	
2017-06-27 20:50:01,508 Epoch[16] Batch [890]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.127030,	
2017-06-27 20:50:05,534 Epoch[16] Batch [900]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.127036,	
2017-06-27 20:50:09,642 Epoch[16] Batch [910]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.127021,	
2017-06-27 20:50:13,712 Epoch[16] Batch [920]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.127112,	
2017-06-27 20:50:17,827 Epoch[16] Batch [930]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.126959,	
2017-06-27 20:50:21,889 Epoch[16] Batch [940]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.127001,	
2017-06-27 20:50:26,034 Epoch[16] Batch [950]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.127141,	
2017-06-27 20:50:30,118 Epoch[16] Batch [960]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.127068,	
2017-06-27 20:50:34,276 Epoch[16] Batch [970]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.126895,	
2017-06-27 20:50:38,421 Epoch[16] Batch [980]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.126777,	
2017-06-27 20:50:42,539 Epoch[16] Batch [990]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.126828,	
2017-06-27 20:50:46,630 Epoch[16] Batch [1000]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.126725,	
2017-06-27 20:50:50,727 Epoch[16] Batch [1010]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.126559,	
2017-06-27 20:50:54,861 Epoch[16] Batch [1020]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.126398,	
2017-06-27 20:50:59,041 Epoch[16] Batch [1030]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.126499,	
2017-06-27 20:51:03,187 Epoch[16] Batch [1040]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.126540,	
2017-06-27 20:51:07,225 Epoch[16] Batch [1050]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.126535,	
2017-06-27 20:51:11,259 Epoch[16] Batch [1060]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.126330,	
2017-06-27 20:51:15,383 Epoch[16] Batch [1070]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.126379,	
2017-06-27 20:51:19,440 Epoch[16] Batch [1080]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.126301,	
2017-06-27 20:51:23,636 Epoch[16] Batch [1090]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.126348,	
2017-06-27 20:51:27,847 Epoch[16] Batch [1100]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.126358,	
2017-06-27 20:51:31,981 Epoch[16] Batch [1110]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.126470,	
2017-06-27 20:51:36,118 Epoch[16] Batch [1120]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.126491,	
2017-06-27 20:51:40,144 Epoch[16] Batch [1130]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126416,	
2017-06-27 20:51:44,247 Epoch[16] Batch [1140]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.126492,	
2017-06-27 20:51:48,413 Epoch[16] Batch [1150]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.126470,	
2017-06-27 20:51:52,568 Epoch[16] Batch [1160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.126478,	
2017-06-27 20:51:56,613 Epoch[16] Batch [1170]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.126379,	
2017-06-27 20:52:00,772 Epoch[16] Batch [1180]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.126313,	
2017-06-27 20:52:04,887 Epoch[16] Batch [1190]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.126288,	
2017-06-27 20:52:09,040 Epoch[16] Batch [1200]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.126357,	
2017-06-27 20:52:13,256 Epoch[16] Batch [1210]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.126432,	
2017-06-27 20:52:17,268 Epoch[16] Batch [1220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.126367,	
2017-06-27 20:52:21,391 Epoch[16] Batch [1230]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.126385,	
2017-06-27 20:52:25,582 Epoch[16] Batch [1240]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.126323,	
2017-06-27 20:52:29,723 Epoch[16] Batch [1250]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.126349,	
2017-06-27 20:52:33,902 Epoch[16] Batch [1260]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.126567,	
2017-06-27 20:52:38,011 Epoch[16] Batch [1270]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.126694,	
2017-06-27 20:52:42,268 Epoch[16] Batch [1280]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.126752,	
2017-06-27 20:52:46,369 Epoch[16] Batch [1290]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.126744,	
2017-06-27 20:52:50,523 Epoch[16] Batch [1300]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.126781,	
2017-06-27 20:52:54,644 Epoch[16] Batch [1310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.126603,	
2017-06-27 20:52:58,794 Epoch[16] Batch [1320]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.126601,	
2017-06-27 20:53:02,856 Epoch[16] Batch [1330]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.126629,	
2017-06-27 20:53:07,093 Epoch[16] Batch [1340]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.126593,	
2017-06-27 20:53:11,234 Epoch[16] Batch [1350]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.126640,	
2017-06-27 20:53:15,397 Epoch[16] Batch [1360]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.126686,	
2017-06-27 20:53:19,449 Epoch[16] Batch [1370]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.126591,	
2017-06-27 20:53:23,531 Epoch[16] Batch [1380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.126499,	
2017-06-27 20:53:27,551 Epoch[16] Batch [1390]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.126434,	
2017-06-27 20:53:31,632 Epoch[16] Batch [1400]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.126540,	
2017-06-27 20:53:35,746 Epoch[16] Batch [1410]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.126584,	
2017-06-27 20:53:39,838 Epoch[16] Batch [1420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.126526,	
2017-06-27 20:53:43,997 Epoch[16] Batch [1430]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.126789,	
2017-06-27 20:53:48,101 Epoch[16] Batch [1440]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.126715,	
2017-06-27 20:53:52,120 Epoch[16] Batch [1450]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.126711,	
2017-06-27 20:53:56,246 Epoch[16] Batch [1460]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.126723,	
2017-06-27 20:54:00,288 Epoch[16] Batch [1470]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.126784,	
2017-06-27 20:54:04,410 Epoch[16] Batch [1480]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.126806,	
2017-06-27 20:54:06,929 Epoch[16] Train-FCNLogLoss=0.126728
2017-06-27 20:54:06,929 Epoch[16] Time cost=613.843
2017-06-27 20:54:07,663 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0017.params"
2017-06-27 20:54:09,323 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0017.states"
2017-06-27 20:54:14,069 Epoch[17] Batch [10]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.120141,	
2017-06-27 20:54:18,250 Epoch[17] Batch [20]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.117608,	
2017-06-27 20:54:22,349 Epoch[17] Batch [30]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.120442,	
2017-06-27 20:54:26,393 Epoch[17] Batch [40]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.118086,	
2017-06-27 20:54:30,495 Epoch[17] Batch [50]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.116033,	
2017-06-27 20:54:34,702 Epoch[17] Batch [60]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.119254,	
2017-06-27 20:54:38,871 Epoch[17] Batch [70]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.120048,	
2017-06-27 20:54:43,021 Epoch[17] Batch [80]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.118950,	
2017-06-27 20:54:47,159 Epoch[17] Batch [90]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.120673,	
2017-06-27 20:54:51,277 Epoch[17] Batch [100]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.121519,	
2017-06-27 20:54:55,421 Epoch[17] Batch [110]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.121420,	
2017-06-27 20:54:59,624 Epoch[17] Batch [120]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.121363,	
2017-06-27 20:55:03,747 Epoch[17] Batch [130]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.121834,	
2017-06-27 20:55:07,830 Epoch[17] Batch [140]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.121426,	
2017-06-27 20:55:11,965 Epoch[17] Batch [150]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.121882,	
2017-06-27 20:55:16,107 Epoch[17] Batch [160]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.121656,	
2017-06-27 20:55:20,256 Epoch[17] Batch [170]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.121333,	
2017-06-27 20:55:24,446 Epoch[17] Batch [180]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.122146,	
2017-06-27 20:55:28,578 Epoch[17] Batch [190]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.121649,	
2017-06-27 20:55:32,725 Epoch[17] Batch [200]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.122096,	
2017-06-27 20:55:36,909 Epoch[17] Batch [210]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.122022,	
2017-06-27 20:55:40,991 Epoch[17] Batch [220]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.122315,	
2017-06-27 20:55:45,139 Epoch[17] Batch [230]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.121817,	
2017-06-27 20:55:49,245 Epoch[17] Batch [240]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.121553,	
2017-06-27 20:55:53,402 Epoch[17] Batch [250]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.122129,	
2017-06-27 20:55:57,537 Epoch[17] Batch [260]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.122352,	
2017-06-27 20:56:01,641 Epoch[17] Batch [270]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.122429,	
2017-06-27 20:56:05,682 Epoch[17] Batch [280]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.122095,	
2017-06-27 20:56:09,769 Epoch[17] Batch [290]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.122360,	
2017-06-27 20:56:13,922 Epoch[17] Batch [300]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.122085,	
2017-06-27 20:56:18,027 Epoch[17] Batch [310]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.122077,	
2017-06-27 20:56:22,120 Epoch[17] Batch [320]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.121479,	
2017-06-27 20:56:26,328 Epoch[17] Batch [330]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.121920,	
2017-06-27 20:56:30,404 Epoch[17] Batch [340]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.121793,	
2017-06-27 20:56:34,528 Epoch[17] Batch [350]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.122467,	
2017-06-27 20:56:38,687 Epoch[17] Batch [360]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.122217,	
2017-06-27 20:56:42,745 Epoch[17] Batch [370]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.121996,	
2017-06-27 20:56:46,892 Epoch[17] Batch [380]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.122232,	
2017-06-27 20:56:51,004 Epoch[17] Batch [390]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.122209,	
2017-06-27 20:56:55,185 Epoch[17] Batch [400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.122111,	
2017-06-27 20:56:59,336 Epoch[17] Batch [410]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.122310,	
2017-06-27 20:57:03,607 Epoch[17] Batch [420]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.122266,	
2017-06-27 20:57:07,678 Epoch[17] Batch [430]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.122202,	
2017-06-27 20:57:11,904 Epoch[17] Batch [440]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.122330,	
2017-06-27 20:57:16,098 Epoch[17] Batch [450]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.122557,	
2017-06-27 20:57:20,287 Epoch[17] Batch [460]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.122559,	
2017-06-27 20:57:24,437 Epoch[17] Batch [470]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.122624,	
2017-06-27 20:57:28,500 Epoch[17] Batch [480]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.122757,	
2017-06-27 20:57:32,649 Epoch[17] Batch [490]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.122726,	
2017-06-27 20:57:36,770 Epoch[17] Batch [500]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.122954,	
2017-06-27 20:57:40,869 Epoch[17] Batch [510]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.122825,	
2017-06-27 20:57:44,962 Epoch[17] Batch [520]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.122873,	
2017-06-27 20:57:49,091 Epoch[17] Batch [530]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.122955,	
2017-06-27 20:57:53,327 Epoch[17] Batch [540]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.122925,	
2017-06-27 20:57:57,485 Epoch[17] Batch [550]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.123062,	
2017-06-27 20:58:01,563 Epoch[17] Batch [560]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.122981,	
2017-06-27 20:58:05,608 Epoch[17] Batch [570]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.123076,	
2017-06-27 20:58:09,826 Epoch[17] Batch [580]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.122903,	
2017-06-27 20:58:13,897 Epoch[17] Batch [590]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.122987,	
2017-06-27 20:58:18,068 Epoch[17] Batch [600]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.122939,	
2017-06-27 20:58:22,219 Epoch[17] Batch [610]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.122889,	
2017-06-27 20:58:26,444 Epoch[17] Batch [620]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.122741,	
2017-06-27 20:58:30,503 Epoch[17] Batch [630]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.122865,	
2017-06-27 20:58:34,641 Epoch[17] Batch [640]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.122801,	
2017-06-27 20:58:38,810 Epoch[17] Batch [650]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.122556,	
2017-06-27 20:58:42,931 Epoch[17] Batch [660]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.122459,	
2017-06-27 20:58:47,000 Epoch[17] Batch [670]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.122173,	
2017-06-27 20:58:51,149 Epoch[17] Batch [680]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.121989,	
2017-06-27 20:58:55,305 Epoch[17] Batch [690]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.122061,	
2017-06-27 20:58:59,498 Epoch[17] Batch [700]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.121942,	
2017-06-27 20:59:03,626 Epoch[17] Batch [710]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.122040,	
2017-06-27 20:59:07,856 Epoch[17] Batch [720]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.122138,	
2017-06-27 20:59:11,959 Epoch[17] Batch [730]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.122149,	
2017-06-27 20:59:16,098 Epoch[17] Batch [740]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.122178,	
2017-06-27 20:59:20,213 Epoch[17] Batch [750]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.122082,	
2017-06-27 20:59:24,162 Epoch[17] Batch [760]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.122123,	
2017-06-27 20:59:28,305 Epoch[17] Batch [770]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.122037,	
2017-06-27 20:59:32,348 Epoch[17] Batch [780]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.121848,	
2017-06-27 20:59:36,380 Epoch[17] Batch [790]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.121837,	
2017-06-27 20:59:40,513 Epoch[17] Batch [800]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.122036,	
2017-06-27 20:59:44,568 Epoch[17] Batch [810]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.122057,	
2017-06-27 20:59:48,611 Epoch[17] Batch [820]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.122177,	
2017-06-27 20:59:52,809 Epoch[17] Batch [830]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.122622,	
2017-06-27 20:59:56,934 Epoch[17] Batch [840]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.122638,	
2017-06-27 21:00:01,077 Epoch[17] Batch [850]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.122677,	
2017-06-27 21:00:05,278 Epoch[17] Batch [860]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.122918,	
2017-06-27 21:00:09,470 Epoch[17] Batch [870]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.123069,	
2017-06-27 21:00:13,703 Epoch[17] Batch [880]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.123006,	
2017-06-27 21:00:17,790 Epoch[17] Batch [890]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.123079,	
2017-06-27 21:00:21,885 Epoch[17] Batch [900]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.123059,	
2017-06-27 21:00:26,007 Epoch[17] Batch [910]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.123012,	
2017-06-27 21:00:30,106 Epoch[17] Batch [920]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.122889,	
2017-06-27 21:00:34,198 Epoch[17] Batch [930]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.122759,	
2017-06-27 21:00:38,362 Epoch[17] Batch [940]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.122832,	
2017-06-27 21:00:42,497 Epoch[17] Batch [950]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.122813,	
2017-06-27 21:00:46,574 Epoch[17] Batch [960]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.122741,	
2017-06-27 21:00:50,648 Epoch[17] Batch [970]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.122638,	
2017-06-27 21:00:54,745 Epoch[17] Batch [980]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.122687,	
2017-06-27 21:00:58,799 Epoch[17] Batch [990]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.122818,	
2017-06-27 21:01:02,906 Epoch[17] Batch [1000]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.123011,	
2017-06-27 21:01:07,008 Epoch[17] Batch [1010]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.123127,	
2017-06-27 21:01:11,059 Epoch[17] Batch [1020]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.123086,	
2017-06-27 21:01:15,213 Epoch[17] Batch [1030]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.122971,	
2017-06-27 21:01:19,351 Epoch[17] Batch [1040]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.122864,	
2017-06-27 21:01:23,329 Epoch[17] Batch [1050]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.122873,	
2017-06-27 21:01:27,321 Epoch[17] Batch [1060]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.123001,	
2017-06-27 21:01:31,410 Epoch[17] Batch [1070]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.123089,	
2017-06-27 21:01:35,488 Epoch[17] Batch [1080]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.123189,	
2017-06-27 21:01:39,586 Epoch[17] Batch [1090]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.123360,	
2017-06-27 21:01:43,572 Epoch[17] Batch [1100]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.123466,	
2017-06-27 21:01:47,645 Epoch[17] Batch [1110]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.123525,	
2017-06-27 21:01:51,758 Epoch[17] Batch [1120]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.123829,	
2017-06-27 21:01:55,933 Epoch[17] Batch [1130]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.123805,	
2017-06-27 21:02:00,124 Epoch[17] Batch [1140]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.123737,	
2017-06-27 21:02:04,133 Epoch[17] Batch [1150]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.123802,	
2017-06-27 21:02:08,316 Epoch[17] Batch [1160]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.123929,	
2017-06-27 21:02:12,412 Epoch[17] Batch [1170]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.123966,	
2017-06-27 21:02:16,541 Epoch[17] Batch [1180]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.124035,	
2017-06-27 21:02:20,511 Epoch[17] Batch [1190]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.124109,	
2017-06-27 21:02:24,703 Epoch[17] Batch [1200]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.124269,	
2017-06-27 21:02:28,857 Epoch[17] Batch [1210]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.124297,	
2017-06-27 21:02:32,910 Epoch[17] Batch [1220]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.124284,	
2017-06-27 21:02:36,950 Epoch[17] Batch [1230]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.124190,	
2017-06-27 21:02:41,031 Epoch[17] Batch [1240]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.124082,	
2017-06-27 21:02:45,086 Epoch[17] Batch [1250]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.124038,	
2017-06-27 21:02:49,026 Epoch[17] Batch [1260]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.124131,	
2017-06-27 21:02:53,121 Epoch[17] Batch [1270]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.124048,	
2017-06-27 21:02:57,167 Epoch[17] Batch [1280]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.123857,	
2017-06-27 21:03:01,244 Epoch[17] Batch [1290]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.123801,	
2017-06-27 21:03:05,227 Epoch[17] Batch [1300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.123636,	
2017-06-27 21:03:09,322 Epoch[17] Batch [1310]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.123543,	
2017-06-27 21:03:13,364 Epoch[17] Batch [1320]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.123605,	
2017-06-27 21:03:17,519 Epoch[17] Batch [1330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.123603,	
2017-06-27 21:03:21,566 Epoch[17] Batch [1340]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.123536,	
2017-06-27 21:03:25,671 Epoch[17] Batch [1350]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.123437,	
2017-06-27 21:03:29,750 Epoch[17] Batch [1360]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.123357,	
2017-06-27 21:03:33,823 Epoch[17] Batch [1370]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.123278,	
2017-06-27 21:03:37,905 Epoch[17] Batch [1380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.123205,	
2017-06-27 21:03:41,971 Epoch[17] Batch [1390]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.123214,	
2017-06-27 21:03:46,032 Epoch[17] Batch [1400]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.123220,	
2017-06-27 21:03:50,044 Epoch[17] Batch [1410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.123236,	
2017-06-27 21:03:54,170 Epoch[17] Batch [1420]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.123106,	
2017-06-27 21:03:58,230 Epoch[17] Batch [1430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.123104,	
2017-06-27 21:04:02,370 Epoch[17] Batch [1440]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.123140,	
2017-06-27 21:04:06,504 Epoch[17] Batch [1450]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.123080,	
2017-06-27 21:04:10,606 Epoch[17] Batch [1460]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.122964,	
2017-06-27 21:04:14,679 Epoch[17] Batch [1470]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.122906,	
2017-06-27 21:04:18,844 Epoch[17] Batch [1480]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.122883,	
2017-06-27 21:04:21,309 Epoch[17] Train-FCNLogLoss=0.122808
2017-06-27 21:04:21,309 Epoch[17] Time cost=611.986
2017-06-27 21:04:22,097 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0018.params"
2017-06-27 21:04:23,713 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0018.states"
2017-06-27 21:04:28,578 Epoch[18] Batch [10]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.120119,	
2017-06-27 21:04:32,735 Epoch[18] Batch [20]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.117515,	
2017-06-27 21:04:36,650 Epoch[18] Batch [30]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.116405,	
2017-06-27 21:04:40,671 Epoch[18] Batch [40]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.123202,	
2017-06-27 21:04:44,736 Epoch[18] Batch [50]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.119522,	
2017-06-27 21:04:48,884 Epoch[18] Batch [60]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.120930,	
2017-06-27 21:04:53,121 Epoch[18] Batch [70]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.123044,	
2017-06-27 21:04:57,168 Epoch[18] Batch [80]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.121882,	
2017-06-27 21:05:01,173 Epoch[18] Batch [90]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.120923,	
2017-06-27 21:05:05,378 Epoch[18] Batch [100]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.121742,	
2017-06-27 21:05:09,406 Epoch[18] Batch [110]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.122041,	
2017-06-27 21:05:13,414 Epoch[18] Batch [120]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.121630,	
2017-06-27 21:05:17,529 Epoch[18] Batch [130]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.120245,	
2017-06-27 21:05:21,584 Epoch[18] Batch [140]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.121255,	
2017-06-27 21:05:25,710 Epoch[18] Batch [150]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.121508,	
2017-06-27 21:05:29,846 Epoch[18] Batch [160]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.120610,	
2017-06-27 21:05:33,944 Epoch[18] Batch [170]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.120540,	
2017-06-27 21:05:38,027 Epoch[18] Batch [180]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.120569,	
2017-06-27 21:05:42,222 Epoch[18] Batch [190]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.120754,	
2017-06-27 21:05:46,309 Epoch[18] Batch [200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.120671,	
2017-06-27 21:05:50,508 Epoch[18] Batch [210]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.120926,	
2017-06-27 21:05:54,637 Epoch[18] Batch [220]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.121244,	
2017-06-27 21:05:58,784 Epoch[18] Batch [230]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.120817,	
2017-06-27 21:06:02,813 Epoch[18] Batch [240]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.120535,	
2017-06-27 21:06:06,966 Epoch[18] Batch [250]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.120694,	
2017-06-27 21:06:11,008 Epoch[18] Batch [260]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.120165,	
2017-06-27 21:06:15,081 Epoch[18] Batch [270]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.120429,	
2017-06-27 21:06:19,122 Epoch[18] Batch [280]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.119839,	
2017-06-27 21:06:23,138 Epoch[18] Batch [290]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.119872,	
2017-06-27 21:06:27,259 Epoch[18] Batch [300]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.119878,	
2017-06-27 21:06:31,422 Epoch[18] Batch [310]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.120348,	
2017-06-27 21:06:35,474 Epoch[18] Batch [320]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.120127,	
2017-06-27 21:06:39,605 Epoch[18] Batch [330]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.120555,	
2017-06-27 21:06:43,698 Epoch[18] Batch [340]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.120232,	
2017-06-27 21:06:47,786 Epoch[18] Batch [350]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.120178,	
2017-06-27 21:06:51,802 Epoch[18] Batch [360]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.119977,	
2017-06-27 21:06:55,843 Epoch[18] Batch [370]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.119879,	
2017-06-27 21:06:59,936 Epoch[18] Batch [380]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.119892,	
2017-06-27 21:07:04,089 Epoch[18] Batch [390]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.119866,	
2017-06-27 21:07:08,141 Epoch[18] Batch [400]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.119875,	
2017-06-27 21:07:12,100 Epoch[18] Batch [410]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.119981,	
2017-06-27 21:07:16,149 Epoch[18] Batch [420]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.120023,	
2017-06-27 21:07:20,202 Epoch[18] Batch [430]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.119931,	
2017-06-27 21:07:24,346 Epoch[18] Batch [440]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.119651,	
2017-06-27 21:07:28,337 Epoch[18] Batch [450]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.119682,	
2017-06-27 21:07:32,516 Epoch[18] Batch [460]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.119477,	
2017-06-27 21:07:36,593 Epoch[18] Batch [470]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.119518,	
2017-06-27 21:07:40,748 Epoch[18] Batch [480]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.119336,	
2017-06-27 21:07:44,830 Epoch[18] Batch [490]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.119181,	
2017-06-27 21:07:48,893 Epoch[18] Batch [500]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.119103,	
2017-06-27 21:07:52,978 Epoch[18] Batch [510]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.118830,	
2017-06-27 21:07:57,077 Epoch[18] Batch [520]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118836,	
2017-06-27 21:08:01,178 Epoch[18] Batch [530]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118731,	
2017-06-27 21:08:05,258 Epoch[18] Batch [540]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118843,	
2017-06-27 21:08:09,267 Epoch[18] Batch [550]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.119131,	
2017-06-27 21:08:13,402 Epoch[18] Batch [560]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.119521,	
2017-06-27 21:08:17,509 Epoch[18] Batch [570]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.119746,	
2017-06-27 21:08:21,550 Epoch[18] Batch [580]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.119541,	
2017-06-27 21:08:25,593 Epoch[18] Batch [590]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.119790,	
2017-06-27 21:08:29,700 Epoch[18] Batch [600]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.119703,	
2017-06-27 21:08:33,878 Epoch[18] Batch [610]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.119653,	
2017-06-27 21:08:37,982 Epoch[18] Batch [620]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.119936,	
2017-06-27 21:08:42,120 Epoch[18] Batch [630]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.119929,	
2017-06-27 21:08:46,223 Epoch[18] Batch [640]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.120089,	
2017-06-27 21:08:50,355 Epoch[18] Batch [650]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.120112,	
2017-06-27 21:08:54,390 Epoch[18] Batch [660]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.120069,	
2017-06-27 21:08:58,574 Epoch[18] Batch [670]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.119944,	
2017-06-27 21:09:02,722 Epoch[18] Batch [680]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.119778,	
2017-06-27 21:09:06,815 Epoch[18] Batch [690]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.119649,	
2017-06-27 21:09:10,882 Epoch[18] Batch [700]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.119355,	
2017-06-27 21:09:15,044 Epoch[18] Batch [710]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.119720,	
2017-06-27 21:09:19,135 Epoch[18] Batch [720]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.119748,	
2017-06-27 21:09:23,267 Epoch[18] Batch [730]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.119667,	
2017-06-27 21:09:27,365 Epoch[18] Batch [740]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.119772,	
2017-06-27 21:09:31,482 Epoch[18] Batch [750]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.119727,	
2017-06-27 21:09:35,654 Epoch[18] Batch [760]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.119741,	
2017-06-27 21:09:39,800 Epoch[18] Batch [770]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.120059,	
2017-06-27 21:09:43,936 Epoch[18] Batch [780]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.119995,	
2017-06-27 21:09:48,085 Epoch[18] Batch [790]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.120367,	
2017-06-27 21:09:52,119 Epoch[18] Batch [800]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.120416,	
2017-06-27 21:09:56,375 Epoch[18] Batch [810]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.120460,	
2017-06-27 21:10:00,477 Epoch[18] Batch [820]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.120427,	
2017-06-27 21:10:04,613 Epoch[18] Batch [830]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.120362,	
2017-06-27 21:10:08,762 Epoch[18] Batch [840]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.120452,	
2017-06-27 21:10:12,881 Epoch[18] Batch [850]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.120456,	
2017-06-27 21:10:17,040 Epoch[18] Batch [860]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.120292,	
2017-06-27 21:10:21,126 Epoch[18] Batch [870]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.120265,	
2017-06-27 21:10:25,261 Epoch[18] Batch [880]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.120586,	
2017-06-27 21:10:29,346 Epoch[18] Batch [890]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.120608,	
2017-06-27 21:10:33,413 Epoch[18] Batch [900]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.120604,	
2017-06-27 21:10:37,579 Epoch[18] Batch [910]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.120690,	
2017-06-27 21:10:41,817 Epoch[18] Batch [920]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.120607,	
2017-06-27 21:10:46,029 Epoch[18] Batch [930]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.120526,	
2017-06-27 21:10:50,118 Epoch[18] Batch [940]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.120380,	
2017-06-27 21:10:54,230 Epoch[18] Batch [950]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.120347,	
2017-06-27 21:10:58,456 Epoch[18] Batch [960]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.120272,	
2017-06-27 21:11:02,602 Epoch[18] Batch [970]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.120373,	
2017-06-27 21:11:06,731 Epoch[18] Batch [980]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.120365,	
2017-06-27 21:11:10,887 Epoch[18] Batch [990]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.120288,	
2017-06-27 21:11:15,054 Epoch[18] Batch [1000]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.120437,	
2017-06-27 21:11:19,116 Epoch[18] Batch [1010]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.120382,	
2017-06-27 21:11:23,143 Epoch[18] Batch [1020]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.120293,	
2017-06-27 21:11:27,258 Epoch[18] Batch [1030]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.120251,	
2017-06-27 21:11:31,349 Epoch[18] Batch [1040]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.120207,	
2017-06-27 21:11:35,497 Epoch[18] Batch [1050]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.120139,	
2017-06-27 21:11:39,624 Epoch[18] Batch [1060]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.120019,	
2017-06-27 21:11:43,667 Epoch[18] Batch [1070]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.119959,	
2017-06-27 21:11:47,714 Epoch[18] Batch [1080]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.119964,	
2017-06-27 21:11:51,850 Epoch[18] Batch [1090]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.120172,	
2017-06-27 21:11:55,921 Epoch[18] Batch [1100]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.120055,	
2017-06-27 21:11:59,949 Epoch[18] Batch [1110]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.120033,	
2017-06-27 21:12:04,070 Epoch[18] Batch [1120]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.119953,	
2017-06-27 21:12:08,128 Epoch[18] Batch [1130]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.120033,	
2017-06-27 21:12:12,236 Epoch[18] Batch [1140]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.119992,	
2017-06-27 21:12:16,260 Epoch[18] Batch [1150]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.119878,	
2017-06-27 21:12:20,367 Epoch[18] Batch [1160]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.119779,	
2017-06-27 21:12:24,351 Epoch[18] Batch [1170]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.119676,	
2017-06-27 21:12:28,411 Epoch[18] Batch [1180]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.119557,	
2017-06-27 21:12:32,502 Epoch[18] Batch [1190]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.119488,	
2017-06-27 21:12:36,530 Epoch[18] Batch [1200]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.119355,	
2017-06-27 21:12:40,567 Epoch[18] Batch [1210]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.119283,	
2017-06-27 21:12:44,671 Epoch[18] Batch [1220]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.119212,	
2017-06-27 21:12:48,772 Epoch[18] Batch [1230]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.119300,	
2017-06-27 21:12:52,877 Epoch[18] Batch [1240]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.119305,	
2017-06-27 21:12:56,917 Epoch[18] Batch [1250]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.119253,	
2017-06-27 21:13:00,977 Epoch[18] Batch [1260]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.119277,	
2017-06-27 21:13:04,984 Epoch[18] Batch [1270]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.119108,	
2017-06-27 21:13:09,104 Epoch[18] Batch [1280]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.119017,	
2017-06-27 21:13:13,195 Epoch[18] Batch [1290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.118998,	
2017-06-27 21:13:17,303 Epoch[18] Batch [1300]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.119068,	
2017-06-27 21:13:21,393 Epoch[18] Batch [1310]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.119047,	
2017-06-27 21:13:25,487 Epoch[18] Batch [1320]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.119008,	
2017-06-27 21:13:29,600 Epoch[18] Batch [1330]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.118951,	
2017-06-27 21:13:33,758 Epoch[18] Batch [1340]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.119068,	
2017-06-27 21:13:37,875 Epoch[18] Batch [1350]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.119034,	
2017-06-27 21:13:41,959 Epoch[18] Batch [1360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118990,	
2017-06-27 21:13:46,021 Epoch[18] Batch [1370]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.118906,	
2017-06-27 21:13:50,096 Epoch[18] Batch [1380]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.118869,	
2017-06-27 21:13:54,207 Epoch[18] Batch [1390]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.119098,	
2017-06-27 21:13:58,240 Epoch[18] Batch [1400]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.119004,	
2017-06-27 21:14:02,324 Epoch[18] Batch [1410]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118943,	
2017-06-27 21:14:06,478 Epoch[18] Batch [1420]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.119047,	
2017-06-27 21:14:10,555 Epoch[18] Batch [1430]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.119044,	
2017-06-27 21:14:14,676 Epoch[18] Batch [1440]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.119033,	
2017-06-27 21:14:18,702 Epoch[18] Batch [1450]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.119215,	
2017-06-27 21:14:22,845 Epoch[18] Batch [1460]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.119190,	
2017-06-27 21:14:27,008 Epoch[18] Batch [1470]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.119190,	
2017-06-27 21:14:31,092 Epoch[18] Batch [1480]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.119100,	
2017-06-27 21:14:33,540 Epoch[18] Train-FCNLogLoss=0.119063
2017-06-27 21:14:33,540 Epoch[18] Time cost=609.826
2017-06-27 21:14:34,350 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0019.params"
2017-06-27 21:14:35,991 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0019.states"
2017-06-27 21:14:40,811 Epoch[19] Batch [10]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.122857,	
2017-06-27 21:14:44,879 Epoch[19] Batch [20]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116345,	
2017-06-27 21:14:48,987 Epoch[19] Batch [30]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.118171,	
2017-06-27 21:14:53,177 Epoch[19] Batch [40]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.119355,	
2017-06-27 21:14:57,264 Epoch[19] Batch [50]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.118405,	
2017-06-27 21:15:01,401 Epoch[19] Batch [60]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.117363,	
2017-06-27 21:15:05,534 Epoch[19] Batch [70]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.117549,	
2017-06-27 21:15:09,707 Epoch[19] Batch [80]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.116618,	
2017-06-27 21:15:13,764 Epoch[19] Batch [90]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.115102,	
2017-06-27 21:15:17,850 Epoch[19] Batch [100]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116649,	
2017-06-27 21:15:21,975 Epoch[19] Batch [110]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.116087,	
2017-06-27 21:15:26,240 Epoch[19] Batch [120]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.117131,	
2017-06-27 21:15:30,316 Epoch[19] Batch [130]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116677,	
2017-06-27 21:15:34,460 Epoch[19] Batch [140]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.116759,	
2017-06-27 21:15:38,614 Epoch[19] Batch [150]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.117230,	
2017-06-27 21:15:42,767 Epoch[19] Batch [160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.116519,	
2017-06-27 21:15:46,852 Epoch[19] Batch [170]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116401,	
2017-06-27 21:15:50,930 Epoch[19] Batch [180]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116305,	
2017-06-27 21:15:54,988 Epoch[19] Batch [190]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.115598,	
2017-06-27 21:15:59,110 Epoch[19] Batch [200]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.115656,	
2017-06-27 21:16:03,245 Epoch[19] Batch [210]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.115476,	
2017-06-27 21:16:07,385 Epoch[19] Batch [220]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115181,	
2017-06-27 21:16:11,499 Epoch[19] Batch [230]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.114952,	
2017-06-27 21:16:15,653 Epoch[19] Batch [240]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.114900,	
2017-06-27 21:16:19,795 Epoch[19] Batch [250]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115031,	
2017-06-27 21:16:23,990 Epoch[19] Batch [260]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.115029,	
2017-06-27 21:16:28,089 Epoch[19] Batch [270]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.114824,	
2017-06-27 21:16:32,163 Epoch[19] Batch [280]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115000,	
2017-06-27 21:16:36,397 Epoch[19] Batch [290]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.115158,	
2017-06-27 21:16:40,517 Epoch[19] Batch [300]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.116034,	
2017-06-27 21:16:44,823 Epoch[19] Batch [310]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.116362,	
2017-06-27 21:16:48,980 Epoch[19] Batch [320]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.116080,	
2017-06-27 21:16:53,140 Epoch[19] Batch [330]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.116468,	
2017-06-27 21:16:57,359 Epoch[19] Batch [340]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.116912,	
2017-06-27 21:17:01,545 Epoch[19] Batch [350]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.117370,	
2017-06-27 21:17:05,696 Epoch[19] Batch [360]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.117896,	
2017-06-27 21:17:09,899 Epoch[19] Batch [370]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.117788,	
2017-06-27 21:17:13,992 Epoch[19] Batch [380]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117550,	
2017-06-27 21:17:18,223 Epoch[19] Batch [390]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.117659,	
2017-06-27 21:17:22,252 Epoch[19] Batch [400]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117684,	
2017-06-27 21:17:26,354 Epoch[19] Batch [410]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.117914,	
2017-06-27 21:17:30,447 Epoch[19] Batch [420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.118017,	
2017-06-27 21:17:34,589 Epoch[19] Batch [430]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.118109,	
2017-06-27 21:17:38,768 Epoch[19] Batch [440]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.118095,	
2017-06-27 21:17:42,915 Epoch[19] Batch [450]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.117957,	
2017-06-27 21:17:46,990 Epoch[19] Batch [460]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117962,	
2017-06-27 21:17:51,120 Epoch[19] Batch [470]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.117766,	
2017-06-27 21:17:55,222 Epoch[19] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.117884,	
2017-06-27 21:17:59,393 Epoch[19] Batch [490]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.117835,	
2017-06-27 21:18:03,493 Epoch[19] Batch [500]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118087,	
2017-06-27 21:18:07,647 Epoch[19] Batch [510]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.118259,	
2017-06-27 21:18:11,801 Epoch[19] Batch [520]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.118540,	
2017-06-27 21:18:15,797 Epoch[19] Batch [530]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118681,	
2017-06-27 21:18:19,867 Epoch[19] Batch [540]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.119017,	
2017-06-27 21:18:23,906 Epoch[19] Batch [550]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.119370,	
2017-06-27 21:18:27,958 Epoch[19] Batch [560]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.119091,	
2017-06-27 21:18:32,084 Epoch[19] Batch [570]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.119108,	
2017-06-27 21:18:36,066 Epoch[19] Batch [580]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.118665,	
2017-06-27 21:18:40,041 Epoch[19] Batch [590]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.118544,	
2017-06-27 21:18:44,161 Epoch[19] Batch [600]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.118520,	
2017-06-27 21:18:48,368 Epoch[19] Batch [610]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.118271,	
2017-06-27 21:18:52,495 Epoch[19] Batch [620]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.118147,	
2017-06-27 21:18:56,659 Epoch[19] Batch [630]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.118048,	
2017-06-27 21:19:00,732 Epoch[19] Batch [640]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.118115,	
2017-06-27 21:19:04,855 Epoch[19] Batch [650]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117849,	
2017-06-27 21:19:09,195 Epoch[19] Batch [660]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.117831,	
2017-06-27 21:19:13,319 Epoch[19] Batch [670]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117778,	
2017-06-27 21:19:17,505 Epoch[19] Batch [680]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.117759,	
2017-06-27 21:19:21,596 Epoch[19] Batch [690]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.117583,	
2017-06-27 21:19:25,705 Epoch[19] Batch [700]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117663,	
2017-06-27 21:19:29,741 Epoch[19] Batch [710]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117454,	
2017-06-27 21:19:33,897 Epoch[19] Batch [720]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.117420,	
2017-06-27 21:19:37,913 Epoch[19] Batch [730]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117504,	
2017-06-27 21:19:42,010 Epoch[19] Batch [740]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117613,	
2017-06-27 21:19:46,127 Epoch[19] Batch [750]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117507,	
2017-06-27 21:19:50,248 Epoch[19] Batch [760]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117646,	
2017-06-27 21:19:54,333 Epoch[19] Batch [770]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117544,	
2017-06-27 21:19:58,418 Epoch[19] Batch [780]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117667,	
2017-06-27 21:20:02,489 Epoch[19] Batch [790]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117529,	
2017-06-27 21:20:06,686 Epoch[19] Batch [800]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.117625,	
2017-06-27 21:20:10,663 Epoch[19] Batch [810]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.117525,	
2017-06-27 21:20:14,798 Epoch[19] Batch [820]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.117367,	
2017-06-27 21:20:18,999 Epoch[19] Batch [830]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.117264,	
2017-06-27 21:20:23,117 Epoch[19] Batch [840]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117240,	
2017-06-27 21:20:27,246 Epoch[19] Batch [850]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.117316,	
2017-06-27 21:20:31,283 Epoch[19] Batch [860]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117382,	
2017-06-27 21:20:35,378 Epoch[19] Batch [870]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117411,	
2017-06-27 21:20:39,590 Epoch[19] Batch [880]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.117308,	
2017-06-27 21:20:43,773 Epoch[19] Batch [890]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.117283,	
2017-06-27 21:20:47,894 Epoch[19] Batch [900]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117256,	
2017-06-27 21:20:52,140 Epoch[19] Batch [910]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.117241,	
2017-06-27 21:20:56,221 Epoch[19] Batch [920]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117404,	
2017-06-27 21:21:00,392 Epoch[19] Batch [930]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.117315,	
2017-06-27 21:21:04,514 Epoch[19] Batch [940]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117357,	
2017-06-27 21:21:08,649 Epoch[19] Batch [950]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.117208,	
2017-06-27 21:21:12,727 Epoch[19] Batch [960]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117123,	
2017-06-27 21:21:16,926 Epoch[19] Batch [970]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.117101,	
2017-06-27 21:21:21,091 Epoch[19] Batch [980]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.116985,	
2017-06-27 21:21:25,221 Epoch[19] Batch [990]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.116957,	
2017-06-27 21:21:29,419 Epoch[19] Batch [1000]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.117065,	
2017-06-27 21:21:33,583 Epoch[19] Batch [1010]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.117022,	
2017-06-27 21:21:37,680 Epoch[19] Batch [1020]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117018,	
2017-06-27 21:21:41,757 Epoch[19] Batch [1030]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117022,	
2017-06-27 21:21:45,866 Epoch[19] Batch [1040]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.116863,	
2017-06-27 21:21:50,105 Epoch[19] Batch [1050]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.116874,	
2017-06-27 21:21:54,120 Epoch[19] Batch [1060]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116917,	
2017-06-27 21:21:58,261 Epoch[19] Batch [1070]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116900,	
2017-06-27 21:22:02,331 Epoch[19] Batch [1080]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116835,	
2017-06-27 21:22:06,403 Epoch[19] Batch [1090]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.116746,	
2017-06-27 21:22:10,492 Epoch[19] Batch [1100]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116793,	
2017-06-27 21:22:14,552 Epoch[19] Batch [1110]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116701,	
2017-06-27 21:22:18,692 Epoch[19] Batch [1120]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116652,	
2017-06-27 21:22:22,705 Epoch[19] Batch [1130]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116590,	
2017-06-27 21:22:26,723 Epoch[19] Batch [1140]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116487,	
2017-06-27 21:22:30,877 Epoch[19] Batch [1150]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.116490,	
2017-06-27 21:22:34,914 Epoch[19] Batch [1160]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.116535,	
2017-06-27 21:22:38,983 Epoch[19] Batch [1170]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116536,	
2017-06-27 21:22:43,093 Epoch[19] Batch [1180]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116587,	
2017-06-27 21:22:47,266 Epoch[19] Batch [1190]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.116632,	
2017-06-27 21:22:51,328 Epoch[19] Batch [1200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116733,	
2017-06-27 21:22:55,470 Epoch[19] Batch [1210]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.117045,	
2017-06-27 21:22:59,512 Epoch[19] Batch [1220]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.117022,	
2017-06-27 21:23:03,506 Epoch[19] Batch [1230]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.117091,	
2017-06-27 21:23:07,625 Epoch[19] Batch [1240]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117194,	
2017-06-27 21:23:11,778 Epoch[19] Batch [1250]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.117046,	
2017-06-27 21:23:15,938 Epoch[19] Batch [1260]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.117698,	
2017-06-27 21:23:20,018 Epoch[19] Batch [1270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118135,	
2017-06-27 21:23:24,083 Epoch[19] Batch [1280]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.118365,	
2017-06-27 21:23:28,204 Epoch[19] Batch [1290]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.118540,	
2017-06-27 21:23:32,322 Epoch[19] Batch [1300]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.118690,	
2017-06-27 21:23:36,493 Epoch[19] Batch [1310]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.118808,	
2017-06-27 21:23:40,583 Epoch[19] Batch [1320]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.118935,	
2017-06-27 21:23:44,729 Epoch[19] Batch [1330]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.118956,	
2017-06-27 21:23:48,850 Epoch[19] Batch [1340]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.118964,	
2017-06-27 21:23:53,000 Epoch[19] Batch [1350]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.118944,	
2017-06-27 21:23:57,154 Epoch[19] Batch [1360]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.118900,	
2017-06-27 21:24:01,235 Epoch[19] Batch [1370]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118922,	
2017-06-27 21:24:05,376 Epoch[19] Batch [1380]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.119020,	
2017-06-27 21:24:09,579 Epoch[19] Batch [1390]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.119129,	
2017-06-27 21:24:13,652 Epoch[19] Batch [1400]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.119165,	
2017-06-27 21:24:17,751 Epoch[19] Batch [1410]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.119265,	
2017-06-27 21:24:21,806 Epoch[19] Batch [1420]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.119226,	
2017-06-27 21:24:25,880 Epoch[19] Batch [1430]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.119334,	
2017-06-27 21:24:30,018 Epoch[19] Batch [1440]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.119267,	
2017-06-27 21:24:34,145 Epoch[19] Batch [1450]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.119286,	
2017-06-27 21:24:38,203 Epoch[19] Batch [1460]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.119292,	
2017-06-27 21:24:42,259 Epoch[19] Batch [1470]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.119276,	
2017-06-27 21:24:46,488 Epoch[19] Batch [1480]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.119284,	
2017-06-27 21:24:48,877 Epoch[19] Train-FCNLogLoss=0.119290
2017-06-27 21:24:48,877 Epoch[19] Time cost=612.885
2017-06-27 21:24:49,591 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0020.params"
2017-06-27 21:24:51,192 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0020.states"
2017-06-27 21:24:55,985 Epoch[20] Batch [10]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.119031,	
2017-06-27 21:25:00,053 Epoch[20] Batch [20]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.113556,	
2017-06-27 21:25:04,133 Epoch[20] Batch [30]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116419,	
2017-06-27 21:25:08,111 Epoch[20] Batch [40]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.118385,	
2017-06-27 21:25:12,130 Epoch[20] Batch [50]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.117495,	
2017-06-27 21:25:16,204 Epoch[20] Batch [60]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.116455,	
2017-06-27 21:25:20,336 Epoch[20] Batch [70]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.116590,	
2017-06-27 21:25:24,342 Epoch[20] Batch [80]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.116253,	
2017-06-27 21:25:28,564 Epoch[20] Batch [90]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.116258,	
2017-06-27 21:25:32,703 Epoch[20] Batch [100]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115660,	
2017-06-27 21:25:36,768 Epoch[20] Batch [110]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115394,	
2017-06-27 21:25:40,920 Epoch[20] Batch [120]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.114733,	
2017-06-27 21:25:44,995 Epoch[20] Batch [130]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114227,	
2017-06-27 21:25:49,102 Epoch[20] Batch [140]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113543,	
2017-06-27 21:25:53,214 Epoch[20] Batch [150]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.113665,	
2017-06-27 21:25:57,339 Epoch[20] Batch [160]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113904,	
2017-06-27 21:26:01,434 Epoch[20] Batch [170]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113854,	
2017-06-27 21:26:05,533 Epoch[20] Batch [180]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113758,	
2017-06-27 21:26:09,713 Epoch[20] Batch [190]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.113727,	
2017-06-27 21:26:13,826 Epoch[20] Batch [200]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.114559,	
2017-06-27 21:26:17,939 Epoch[20] Batch [210]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.114271,	
2017-06-27 21:26:22,057 Epoch[20] Batch [220]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.114310,	
2017-06-27 21:26:26,104 Epoch[20] Batch [230]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.114051,	
2017-06-27 21:26:30,284 Epoch[20] Batch [240]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.114089,	
2017-06-27 21:26:34,360 Epoch[20] Batch [250]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113950,	
2017-06-27 21:26:38,584 Epoch[20] Batch [260]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113718,	
2017-06-27 21:26:42,670 Epoch[20] Batch [270]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.113686,	
2017-06-27 21:26:46,767 Epoch[20] Batch [280]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113380,	
2017-06-27 21:26:50,839 Epoch[20] Batch [290]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113756,	
2017-06-27 21:26:54,903 Epoch[20] Batch [300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113639,	
2017-06-27 21:26:58,921 Epoch[20] Batch [310]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113920,	
2017-06-27 21:27:03,017 Epoch[20] Batch [320]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.114317,	
2017-06-27 21:27:07,043 Epoch[20] Batch [330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114188,	
2017-06-27 21:27:11,190 Epoch[20] Batch [340]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.114268,	
2017-06-27 21:27:15,191 Epoch[20] Batch [350]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.114466,	
2017-06-27 21:27:19,425 Epoch[20] Batch [360]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.114383,	
2017-06-27 21:27:23,506 Epoch[20] Batch [370]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114187,	
2017-06-27 21:27:27,630 Epoch[20] Batch [380]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.114156,	
2017-06-27 21:27:31,844 Epoch[20] Batch [390]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.113962,	
2017-06-27 21:27:35,936 Epoch[20] Batch [400]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.113909,	
2017-06-27 21:27:40,071 Epoch[20] Batch [410]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.114106,	
2017-06-27 21:27:44,201 Epoch[20] Batch [420]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.114623,	
2017-06-27 21:27:48,299 Epoch[20] Batch [430]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.114937,	
2017-06-27 21:27:52,343 Epoch[20] Batch [440]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.115037,	
2017-06-27 21:27:56,434 Epoch[20] Batch [450]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.115113,	
2017-06-27 21:28:00,506 Epoch[20] Batch [460]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114906,	
2017-06-27 21:28:04,552 Epoch[20] Batch [470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.115025,	
2017-06-27 21:28:08,635 Epoch[20] Batch [480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.115081,	
2017-06-27 21:28:12,704 Epoch[20] Batch [490]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.115111,	
2017-06-27 21:28:16,848 Epoch[20] Batch [500]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.115268,	
2017-06-27 21:28:21,088 Epoch[20] Batch [510]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.115368,	
2017-06-27 21:28:25,195 Epoch[20] Batch [520]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115263,	
2017-06-27 21:28:29,343 Epoch[20] Batch [530]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.115537,	
2017-06-27 21:28:33,383 Epoch[20] Batch [540]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.115644,	
2017-06-27 21:28:37,500 Epoch[20] Batch [550]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.115661,	
2017-06-27 21:28:41,559 Epoch[20] Batch [560]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.115619,	
2017-06-27 21:28:45,755 Epoch[20] Batch [570]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.115778,	
2017-06-27 21:28:49,923 Epoch[20] Batch [580]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.115814,	
2017-06-27 21:28:53,974 Epoch[20] Batch [590]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.115758,	
2017-06-27 21:28:58,064 Epoch[20] Batch [600]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.115582,	
2017-06-27 21:29:02,179 Epoch[20] Batch [610]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.115530,	
2017-06-27 21:29:06,254 Epoch[20] Batch [620]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115459,	
2017-06-27 21:29:10,315 Epoch[20] Batch [630]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.115375,	
2017-06-27 21:29:14,380 Epoch[20] Batch [640]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115307,	
2017-06-27 21:29:18,464 Epoch[20] Batch [650]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115457,	
2017-06-27 21:29:22,648 Epoch[20] Batch [660]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.115624,	
2017-06-27 21:29:26,817 Epoch[20] Batch [670]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.115973,	
2017-06-27 21:29:30,894 Epoch[20] Batch [680]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115906,	
2017-06-27 21:29:35,109 Epoch[20] Batch [690]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.116080,	
2017-06-27 21:29:39,239 Epoch[20] Batch [700]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.116113,	
2017-06-27 21:29:43,366 Epoch[20] Batch [710]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.116077,	
2017-06-27 21:29:47,472 Epoch[20] Batch [720]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115938,	
2017-06-27 21:29:51,647 Epoch[20] Batch [730]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.115949,	
2017-06-27 21:29:55,803 Epoch[20] Batch [740]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.116128,	
2017-06-27 21:29:59,931 Epoch[20] Batch [750]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.116267,	
2017-06-27 21:30:04,084 Epoch[20] Batch [760]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.116285,	
2017-06-27 21:30:08,210 Epoch[20] Batch [770]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.116122,	
2017-06-27 21:30:12,258 Epoch[20] Batch [780]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.116127,	
2017-06-27 21:30:16,445 Epoch[20] Batch [790]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.116215,	
2017-06-27 21:30:20,562 Epoch[20] Batch [800]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.116376,	
2017-06-27 21:30:24,667 Epoch[20] Batch [810]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.116482,	
2017-06-27 21:30:28,784 Epoch[20] Batch [820]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.116471,	
2017-06-27 21:30:32,854 Epoch[20] Batch [830]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116310,	
2017-06-27 21:30:36,908 Epoch[20] Batch [840]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.116169,	
2017-06-27 21:30:41,006 Epoch[20] Batch [850]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.116024,	
2017-06-27 21:30:45,155 Epoch[20] Batch [860]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.115968,	
2017-06-27 21:30:49,361 Epoch[20] Batch [870]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.115982,	
2017-06-27 21:30:53,571 Epoch[20] Batch [880]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.115814,	
2017-06-27 21:30:57,701 Epoch[20] Batch [890]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.115696,	
2017-06-27 21:31:01,757 Epoch[20] Batch [900]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.115725,	
2017-06-27 21:31:05,924 Epoch[20] Batch [910]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.115680,	
2017-06-27 21:31:10,164 Epoch[20] Batch [920]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.115800,	
2017-06-27 21:31:14,307 Epoch[20] Batch [930]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.115775,	
2017-06-27 21:31:18,326 Epoch[20] Batch [940]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115898,	
2017-06-27 21:31:22,364 Epoch[20] Batch [950]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.115876,	
2017-06-27 21:31:26,446 Epoch[20] Batch [960]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.115833,	
2017-06-27 21:31:30,480 Epoch[20] Batch [970]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115870,	
2017-06-27 21:31:34,583 Epoch[20] Batch [980]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.115950,	
2017-06-27 21:31:38,729 Epoch[20] Batch [990]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.115953,	
2017-06-27 21:31:42,788 Epoch[20] Batch [1000]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116318,	
2017-06-27 21:31:47,021 Epoch[20] Batch [1010]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.116457,	
2017-06-27 21:31:51,074 Epoch[20] Batch [1020]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.116511,	
2017-06-27 21:31:55,212 Epoch[20] Batch [1030]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.116495,	
2017-06-27 21:31:59,147 Epoch[20] Batch [1040]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.116647,	
2017-06-27 21:32:03,229 Epoch[20] Batch [1050]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116748,	
2017-06-27 21:32:07,487 Epoch[20] Batch [1060]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.116741,	
2017-06-27 21:32:11,586 Epoch[20] Batch [1070]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.116714,	
2017-06-27 21:32:15,693 Epoch[20] Batch [1080]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.116671,	
2017-06-27 21:32:19,733 Epoch[20] Batch [1090]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.116727,	
2017-06-27 21:32:23,892 Epoch[20] Batch [1100]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.116516,	
2017-06-27 21:32:28,068 Epoch[20] Batch [1110]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.116472,	
2017-06-27 21:32:32,187 Epoch[20] Batch [1120]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.116378,	
2017-06-27 21:32:36,298 Epoch[20] Batch [1130]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116470,	
2017-06-27 21:32:40,481 Epoch[20] Batch [1140]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.116480,	
2017-06-27 21:32:44,533 Epoch[20] Batch [1150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.116404,	
2017-06-27 21:32:48,723 Epoch[20] Batch [1160]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.116341,	
2017-06-27 21:32:52,955 Epoch[20] Batch [1170]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.116341,	
2017-06-27 21:32:57,098 Epoch[20] Batch [1180]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116299,	
2017-06-27 21:33:01,171 Epoch[20] Batch [1190]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.116235,	
2017-06-27 21:33:05,243 Epoch[20] Batch [1200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.116156,	
2017-06-27 21:33:09,515 Epoch[20] Batch [1210]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.116136,	
2017-06-27 21:33:13,531 Epoch[20] Batch [1220]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116086,	
2017-06-27 21:33:17,690 Epoch[20] Batch [1230]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.115972,	
2017-06-27 21:33:21,846 Epoch[20] Batch [1240]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.115963,	
2017-06-27 21:33:25,979 Epoch[20] Batch [1250]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.115891,	
2017-06-27 21:33:30,077 Epoch[20] Batch [1260]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.115885,	
2017-06-27 21:33:34,251 Epoch[20] Batch [1270]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.115952,	
2017-06-27 21:33:38,321 Epoch[20] Batch [1280]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116015,	
2017-06-27 21:33:42,530 Epoch[20] Batch [1290]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.116048,	
2017-06-27 21:33:46,676 Epoch[20] Batch [1300]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.116037,	
2017-06-27 21:33:50,825 Epoch[20] Batch [1310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.116110,	
2017-06-27 21:33:54,917 Epoch[20] Batch [1320]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116041,	
2017-06-27 21:33:58,924 Epoch[20] Batch [1330]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.116152,	
2017-06-27 21:34:02,980 Epoch[20] Batch [1340]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116160,	
2017-06-27 21:34:07,044 Epoch[20] Batch [1350]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116173,	
2017-06-27 21:34:11,221 Epoch[20] Batch [1360]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.116272,	
2017-06-27 21:34:15,389 Epoch[20] Batch [1370]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.116211,	
2017-06-27 21:34:19,484 Epoch[20] Batch [1380]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116168,	
2017-06-27 21:34:23,663 Epoch[20] Batch [1390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.116086,	
2017-06-27 21:34:27,723 Epoch[20] Batch [1400]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116012,	
2017-06-27 21:34:31,745 Epoch[20] Batch [1410]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115966,	
2017-06-27 21:34:35,840 Epoch[20] Batch [1420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.115976,	
2017-06-27 21:34:39,997 Epoch[20] Batch [1430]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.116071,	
2017-06-27 21:34:44,130 Epoch[20] Batch [1440]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.116085,	
2017-06-27 21:34:48,282 Epoch[20] Batch [1450]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.116086,	
2017-06-27 21:34:52,477 Epoch[20] Batch [1460]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.116101,	
2017-06-27 21:34:56,595 Epoch[20] Batch [1470]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.116098,	
2017-06-27 21:35:00,760 Epoch[20] Batch [1480]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.116079,	
2017-06-27 21:35:03,206 Epoch[20] Train-FCNLogLoss=0.116105
2017-06-27 21:35:03,206 Epoch[20] Time cost=612.013
2017-06-27 21:35:03,921 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0021.params"
2017-06-27 21:35:05,571 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0021.states"
2017-06-27 21:35:10,319 Epoch[21] Batch [10]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116925,	
2017-06-27 21:35:14,430 Epoch[21] Batch [20]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.111462,	
2017-06-27 21:35:18,503 Epoch[21] Batch [30]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.111985,	
2017-06-27 21:35:22,681 Epoch[21] Batch [40]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.113277,	
2017-06-27 21:35:26,890 Epoch[21] Batch [50]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.116062,	
2017-06-27 21:35:30,941 Epoch[21] Batch [60]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.115675,	
2017-06-27 21:35:35,102 Epoch[21] Batch [70]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.118639,	
2017-06-27 21:35:39,204 Epoch[21] Batch [80]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.118737,	
2017-06-27 21:35:43,335 Epoch[21] Batch [90]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.117385,	
2017-06-27 21:35:47,565 Epoch[21] Batch [100]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.118566,	
2017-06-27 21:35:51,786 Epoch[21] Batch [110]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.117591,	
2017-06-27 21:35:55,966 Epoch[21] Batch [120]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.117670,	
2017-06-27 21:36:00,076 Epoch[21] Batch [130]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.117707,	
2017-06-27 21:36:04,249 Epoch[21] Batch [140]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.116715,	
2017-06-27 21:36:08,359 Epoch[21] Batch [150]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.116156,	
2017-06-27 21:36:12,537 Epoch[21] Batch [160]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.116012,	
2017-06-27 21:36:16,652 Epoch[21] Batch [170]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.116802,	
2017-06-27 21:36:20,768 Epoch[21] Batch [180]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.116038,	
2017-06-27 21:36:24,866 Epoch[21] Batch [190]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.115329,	
2017-06-27 21:36:28,918 Epoch[21] Batch [200]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.115680,	
2017-06-27 21:36:33,045 Epoch[21] Batch [210]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.115158,	
2017-06-27 21:36:37,188 Epoch[21] Batch [220]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.114805,	
2017-06-27 21:36:41,239 Epoch[21] Batch [230]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.114661,	
2017-06-27 21:36:45,463 Epoch[21] Batch [240]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.114792,	
2017-06-27 21:36:49,594 Epoch[21] Batch [250]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.114970,	
2017-06-27 21:36:53,799 Epoch[21] Batch [260]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.114991,	
2017-06-27 21:36:57,906 Epoch[21] Batch [270]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.114582,	
2017-06-27 21:37:02,000 Epoch[21] Batch [280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.114060,	
2017-06-27 21:37:06,151 Epoch[21] Batch [290]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.113850,	
2017-06-27 21:37:10,314 Epoch[21] Batch [300]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.113571,	
2017-06-27 21:37:14,433 Epoch[21] Batch [310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.113708,	
2017-06-27 21:37:18,436 Epoch[21] Batch [320]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.113676,	
2017-06-27 21:37:22,679 Epoch[21] Batch [330]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.113688,	
2017-06-27 21:37:26,703 Epoch[21] Batch [340]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.113620,	
2017-06-27 21:37:30,855 Epoch[21] Batch [350]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.113476,	
2017-06-27 21:37:34,991 Epoch[21] Batch [360]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113634,	
2017-06-27 21:37:39,040 Epoch[21] Batch [370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113837,	
2017-06-27 21:37:43,120 Epoch[21] Batch [380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.113841,	
2017-06-27 21:37:47,220 Epoch[21] Batch [390]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113870,	
2017-06-27 21:37:51,319 Epoch[21] Batch [400]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113716,	
2017-06-27 21:37:55,356 Epoch[21] Batch [410]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113545,	
2017-06-27 21:37:59,585 Epoch[21] Batch [420]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.113633,	
2017-06-27 21:38:03,698 Epoch[21] Batch [430]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.113855,	
2017-06-27 21:38:07,807 Epoch[21] Batch [440]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.114037,	
2017-06-27 21:38:11,876 Epoch[21] Batch [450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.113934,	
2017-06-27 21:38:16,025 Epoch[21] Batch [460]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.114044,	
2017-06-27 21:38:20,075 Epoch[21] Batch [470]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113940,	
2017-06-27 21:38:24,184 Epoch[21] Batch [480]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.114201,	
2017-06-27 21:38:28,301 Epoch[21] Batch [490]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.114402,	
2017-06-27 21:38:32,571 Epoch[21] Batch [500]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.114483,	
2017-06-27 21:38:36,744 Epoch[21] Batch [510]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.114553,	
2017-06-27 21:38:40,920 Epoch[21] Batch [520]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.114455,	
2017-06-27 21:38:45,099 Epoch[21] Batch [530]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.114114,	
2017-06-27 21:38:49,191 Epoch[21] Batch [540]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.114127,	
2017-06-27 21:38:53,292 Epoch[21] Batch [550]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.113734,	
2017-06-27 21:38:57,387 Epoch[21] Batch [560]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113725,	
2017-06-27 21:39:01,530 Epoch[21] Batch [570]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113966,	
2017-06-27 21:39:05,606 Epoch[21] Batch [580]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113708,	
2017-06-27 21:39:09,753 Epoch[21] Batch [590]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113604,	
2017-06-27 21:39:13,912 Epoch[21] Batch [600]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.113497,	
2017-06-27 21:39:18,052 Epoch[21] Batch [610]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.113153,	
2017-06-27 21:39:22,085 Epoch[21] Batch [620]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112910,	
2017-06-27 21:39:26,224 Epoch[21] Batch [630]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.112889,	
2017-06-27 21:39:30,278 Epoch[21] Batch [640]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112862,	
2017-06-27 21:39:34,200 Epoch[21] Batch [650]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112941,	
2017-06-27 21:39:38,248 Epoch[21] Batch [660]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112965,	
2017-06-27 21:39:42,318 Epoch[21] Batch [670]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.112885,	
2017-06-27 21:39:46,427 Epoch[21] Batch [680]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112887,	
2017-06-27 21:39:50,512 Epoch[21] Batch [690]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112873,	
2017-06-27 21:39:54,566 Epoch[21] Batch [700]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112865,	
2017-06-27 21:39:58,615 Epoch[21] Batch [710]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112948,	
2017-06-27 21:40:02,609 Epoch[21] Batch [720]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.113137,	
2017-06-27 21:40:06,751 Epoch[21] Batch [730]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.113219,	
2017-06-27 21:40:10,791 Epoch[21] Batch [740]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113315,	
2017-06-27 21:40:14,848 Epoch[21] Batch [750]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.113226,	
2017-06-27 21:40:18,880 Epoch[21] Batch [760]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.113309,	
2017-06-27 21:40:22,909 Epoch[21] Batch [770]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113362,	
2017-06-27 21:40:26,873 Epoch[21] Batch [780]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.113394,	
2017-06-27 21:40:30,903 Epoch[21] Batch [790]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113660,	
2017-06-27 21:40:34,983 Epoch[21] Batch [800]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.113678,	
2017-06-27 21:40:39,077 Epoch[21] Batch [810]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113710,	
2017-06-27 21:40:43,088 Epoch[21] Batch [820]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.113649,	
2017-06-27 21:40:47,178 Epoch[21] Batch [830]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.113608,	
2017-06-27 21:40:51,166 Epoch[21] Batch [840]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.113572,	
2017-06-27 21:40:55,292 Epoch[21] Batch [850]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113503,	
2017-06-27 21:40:59,340 Epoch[21] Batch [860]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113570,	
2017-06-27 21:41:03,315 Epoch[21] Batch [870]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.113517,	
2017-06-27 21:41:07,341 Epoch[21] Batch [880]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.113370,	
2017-06-27 21:41:11,432 Epoch[21] Batch [890]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.113335,	
2017-06-27 21:41:15,482 Epoch[21] Batch [900]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113479,	
2017-06-27 21:41:19,574 Epoch[21] Batch [910]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.113516,	
2017-06-27 21:41:23,708 Epoch[21] Batch [920]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113513,	
2017-06-27 21:41:27,775 Epoch[21] Batch [930]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113528,	
2017-06-27 21:41:31,878 Epoch[21] Batch [940]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.113438,	
2017-06-27 21:41:35,945 Epoch[21] Batch [950]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113475,	
2017-06-27 21:41:39,995 Epoch[21] Batch [960]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113456,	
2017-06-27 21:41:43,971 Epoch[21] Batch [970]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.113334,	
2017-06-27 21:41:48,130 Epoch[21] Batch [980]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.113207,	
2017-06-27 21:41:52,214 Epoch[21] Batch [990]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.113274,	
2017-06-27 21:41:56,323 Epoch[21] Batch [1000]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113268,	
2017-06-27 21:42:00,422 Epoch[21] Batch [1010]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113405,	
2017-06-27 21:42:04,431 Epoch[21] Batch [1020]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113580,	
2017-06-27 21:42:08,545 Epoch[21] Batch [1030]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.113716,	
2017-06-27 21:42:12,606 Epoch[21] Batch [1040]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113754,	
2017-06-27 21:42:16,719 Epoch[21] Batch [1050]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.113816,	
2017-06-27 21:42:20,713 Epoch[21] Batch [1060]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.113888,	
2017-06-27 21:42:24,805 Epoch[21] Batch [1070]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.113741,	
2017-06-27 21:42:28,791 Epoch[21] Batch [1080]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.113781,	
2017-06-27 21:42:32,826 Epoch[21] Batch [1090]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113709,	
2017-06-27 21:42:36,824 Epoch[21] Batch [1100]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.113655,	
2017-06-27 21:42:40,793 Epoch[21] Batch [1110]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.113608,	
2017-06-27 21:42:44,883 Epoch[21] Batch [1120]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.113586,	
2017-06-27 21:42:48,962 Epoch[21] Batch [1130]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113637,	
2017-06-27 21:42:53,061 Epoch[21] Batch [1140]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113682,	
2017-06-27 21:42:57,093 Epoch[21] Batch [1150]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.113641,	
2017-06-27 21:43:01,140 Epoch[21] Batch [1160]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.113649,	
2017-06-27 21:43:05,260 Epoch[21] Batch [1170]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.113654,	
2017-06-27 21:43:09,274 Epoch[21] Batch [1180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.113590,	
2017-06-27 21:43:13,328 Epoch[21] Batch [1190]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113667,	
2017-06-27 21:43:17,364 Epoch[21] Batch [1200]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113610,	
2017-06-27 21:43:21,426 Epoch[21] Batch [1210]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113641,	
2017-06-27 21:43:25,421 Epoch[21] Batch [1220]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.113565,	
2017-06-27 21:43:29,431 Epoch[21] Batch [1230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113624,	
2017-06-27 21:43:33,524 Epoch[21] Batch [1240]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113598,	
2017-06-27 21:43:37,570 Epoch[21] Batch [1250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.113673,	
2017-06-27 21:43:41,617 Epoch[21] Batch [1260]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113725,	
2017-06-27 21:43:45,638 Epoch[21] Batch [1270]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113685,	
2017-06-27 21:43:49,658 Epoch[21] Batch [1280]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113705,	
2017-06-27 21:43:53,740 Epoch[21] Batch [1290]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.113795,	
2017-06-27 21:43:57,683 Epoch[21] Batch [1300]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.113827,	
2017-06-27 21:44:01,775 Epoch[21] Batch [1310]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114092,	
2017-06-27 21:44:05,951 Epoch[21] Batch [1320]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.114270,	
2017-06-27 21:44:10,022 Epoch[21] Batch [1330]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.114296,	
2017-06-27 21:44:14,069 Epoch[21] Batch [1340]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.114352,	
2017-06-27 21:44:18,116 Epoch[21] Batch [1350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.114295,	
2017-06-27 21:44:22,135 Epoch[21] Batch [1360]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.114198,	
2017-06-27 21:44:26,279 Epoch[21] Batch [1370]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.114159,	
2017-06-27 21:44:30,322 Epoch[21] Batch [1380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.114232,	
2017-06-27 21:44:34,309 Epoch[21] Batch [1390]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.114217,	
2017-06-27 21:44:38,358 Epoch[21] Batch [1400]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.114156,	
2017-06-27 21:44:42,499 Epoch[21] Batch [1410]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.114066,	
2017-06-27 21:44:46,616 Epoch[21] Batch [1420]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.114050,	
2017-06-27 21:44:50,561 Epoch[21] Batch [1430]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.113986,	
2017-06-27 21:44:54,594 Epoch[21] Batch [1440]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.114019,	
2017-06-27 21:44:58,656 Epoch[21] Batch [1450]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113989,	
2017-06-27 21:45:02,697 Epoch[21] Batch [1460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113908,	
2017-06-27 21:45:06,824 Epoch[21] Batch [1470]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.113951,	
2017-06-27 21:45:10,840 Epoch[21] Batch [1480]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113937,	
2017-06-27 21:45:13,208 Epoch[21] Train-FCNLogLoss=0.113934
2017-06-27 21:45:13,209 Epoch[21] Time cost=607.638
2017-06-27 21:45:13,939 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0022.params"
2017-06-27 21:45:15,572 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0022.states"
2017-06-27 21:45:20,361 Epoch[22] Batch [10]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101653,	
2017-06-27 21:45:24,387 Epoch[22] Batch [20]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.107293,	
2017-06-27 21:45:28,439 Epoch[22] Batch [30]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.109389,	
2017-06-27 21:45:32,484 Epoch[22] Batch [40]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.107319,	
2017-06-27 21:45:36,606 Epoch[22] Batch [50]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.108861,	
2017-06-27 21:45:40,625 Epoch[22] Batch [60]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110368,	
2017-06-27 21:45:44,614 Epoch[22] Batch [70]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.109726,	
2017-06-27 21:45:48,637 Epoch[22] Batch [80]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.109686,	
2017-06-27 21:45:52,576 Epoch[22] Batch [90]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.109594,	
2017-06-27 21:45:56,614 Epoch[22] Batch [100]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.110215,	
2017-06-27 21:46:00,584 Epoch[22] Batch [110]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.110760,	
2017-06-27 21:46:04,685 Epoch[22] Batch [120]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.110666,	
2017-06-27 21:46:08,785 Epoch[22] Batch [130]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.111781,	
2017-06-27 21:46:12,890 Epoch[22] Batch [140]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.111159,	
2017-06-27 21:46:16,913 Epoch[22] Batch [150]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.111660,	
2017-06-27 21:46:21,042 Epoch[22] Batch [160]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112382,	
2017-06-27 21:46:25,129 Epoch[22] Batch [170]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.111927,	
2017-06-27 21:46:29,246 Epoch[22] Batch [180]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112193,	
2017-06-27 21:46:33,345 Epoch[22] Batch [190]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112586,	
2017-06-27 21:46:37,494 Epoch[22] Batch [200]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.113210,	
2017-06-27 21:46:41,616 Epoch[22] Batch [210]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.113186,	
2017-06-27 21:46:45,741 Epoch[22] Batch [220]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112898,	
2017-06-27 21:46:49,918 Epoch[22] Batch [230]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112656,	
2017-06-27 21:46:54,007 Epoch[22] Batch [240]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112376,	
2017-06-27 21:46:58,120 Epoch[22] Batch [250]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112367,	
2017-06-27 21:47:02,231 Epoch[22] Batch [260]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112019,	
2017-06-27 21:47:06,410 Epoch[22] Batch [270]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.112567,	
2017-06-27 21:47:10,435 Epoch[22] Batch [280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112524,	
2017-06-27 21:47:14,529 Epoch[22] Batch [290]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112468,	
2017-06-27 21:47:18,540 Epoch[22] Batch [300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111726,	
2017-06-27 21:47:22,660 Epoch[22] Batch [310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.111777,	
2017-06-27 21:47:26,678 Epoch[22] Batch [320]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.111769,	
2017-06-27 21:47:30,657 Epoch[22] Batch [330]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111615,	
2017-06-27 21:47:34,845 Epoch[22] Batch [340]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.111439,	
2017-06-27 21:47:38,881 Epoch[22] Batch [350]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.111422,	
2017-06-27 21:47:42,901 Epoch[22] Batch [360]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.111770,	
2017-06-27 21:47:47,015 Epoch[22] Batch [370]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112166,	
2017-06-27 21:47:51,093 Epoch[22] Batch [380]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.112185,	
2017-06-27 21:47:55,153 Epoch[22] Batch [390]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113117,	
2017-06-27 21:47:59,285 Epoch[22] Batch [400]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.114169,	
2017-06-27 21:48:03,385 Epoch[22] Batch [410]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.115083,	
2017-06-27 21:48:07,456 Epoch[22] Batch [420]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.115446,	
2017-06-27 21:48:11,502 Epoch[22] Batch [430]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116106,	
2017-06-27 21:48:15,627 Epoch[22] Batch [440]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.116938,	
2017-06-27 21:48:19,767 Epoch[22] Batch [450]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.117039,	
2017-06-27 21:48:23,752 Epoch[22] Batch [460]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.117192,	
2017-06-27 21:48:27,796 Epoch[22] Batch [470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117260,	
2017-06-27 21:48:31,866 Epoch[22] Batch [480]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117232,	
2017-06-27 21:48:35,946 Epoch[22] Batch [490]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117271,	
2017-06-27 21:48:40,027 Epoch[22] Batch [500]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117578,	
2017-06-27 21:48:44,028 Epoch[22] Batch [510]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.117430,	
2017-06-27 21:48:48,091 Epoch[22] Batch [520]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117287,	
2017-06-27 21:48:52,086 Epoch[22] Batch [530]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.117538,	
2017-06-27 21:48:56,165 Epoch[22] Batch [540]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117647,	
2017-06-27 21:49:00,198 Epoch[22] Batch [550]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.117692,	
2017-06-27 21:49:04,320 Epoch[22] Batch [560]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117923,	
2017-06-27 21:49:08,300 Epoch[22] Batch [570]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117762,	
2017-06-27 21:49:12,424 Epoch[22] Batch [580]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117688,	
2017-06-27 21:49:16,625 Epoch[22] Batch [590]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.117500,	
2017-06-27 21:49:20,668 Epoch[22] Batch [600]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117512,	
2017-06-27 21:49:24,699 Epoch[22] Batch [610]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.117572,	
2017-06-27 21:49:28,795 Epoch[22] Batch [620]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117778,	
2017-06-27 21:49:32,883 Epoch[22] Batch [630]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117745,	
2017-06-27 21:49:37,052 Epoch[22] Batch [640]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.117700,	
2017-06-27 21:49:41,154 Epoch[22] Batch [650]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.117589,	
2017-06-27 21:49:45,273 Epoch[22] Batch [660]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117567,	
2017-06-27 21:49:49,335 Epoch[22] Batch [670]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117488,	
2017-06-27 21:49:53,414 Epoch[22] Batch [680]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117484,	
2017-06-27 21:49:57,464 Epoch[22] Batch [690]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117458,	
2017-06-27 21:50:01,516 Epoch[22] Batch [700]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.117287,	
2017-06-27 21:50:05,590 Epoch[22] Batch [710]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117242,	
2017-06-27 21:50:09,685 Epoch[22] Batch [720]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117394,	
2017-06-27 21:50:13,816 Epoch[22] Batch [730]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.117309,	
2017-06-27 21:50:17,882 Epoch[22] Batch [740]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117094,	
2017-06-27 21:50:21,880 Epoch[22] Batch [750]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.117027,	
2017-06-27 21:50:25,962 Epoch[22] Batch [760]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116882,	
2017-06-27 21:50:29,972 Epoch[22] Batch [770]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.117039,	
2017-06-27 21:50:34,014 Epoch[22] Batch [780]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.117278,	
2017-06-27 21:50:38,137 Epoch[22] Batch [790]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117274,	
2017-06-27 21:50:42,197 Epoch[22] Batch [800]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117155,	
2017-06-27 21:50:46,193 Epoch[22] Batch [810]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.116958,	
2017-06-27 21:50:50,383 Epoch[22] Batch [820]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.116769,	
2017-06-27 21:50:54,436 Epoch[22] Batch [830]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.116793,	
2017-06-27 21:50:58,458 Epoch[22] Batch [840]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116846,	
2017-06-27 21:51:02,651 Epoch[22] Batch [850]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.116692,	
2017-06-27 21:51:06,820 Epoch[22] Batch [860]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.116718,	
2017-06-27 21:51:10,824 Epoch[22] Batch [870]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.116791,	
2017-06-27 21:51:14,827 Epoch[22] Batch [880]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.116813,	
2017-06-27 21:51:18,762 Epoch[22] Batch [890]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.116806,	
2017-06-27 21:51:22,763 Epoch[22] Batch [900]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116832,	
2017-06-27 21:51:26,742 Epoch[22] Batch [910]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.116695,	
2017-06-27 21:51:30,870 Epoch[22] Batch [920]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.116899,	
2017-06-27 21:51:34,893 Epoch[22] Batch [930]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116789,	
2017-06-27 21:51:38,900 Epoch[22] Batch [940]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.116723,	
2017-06-27 21:51:42,971 Epoch[22] Batch [950]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116743,	
2017-06-27 21:51:47,068 Epoch[22] Batch [960]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116605,	
2017-06-27 21:51:51,236 Epoch[22] Batch [970]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.116654,	
2017-06-27 21:51:55,295 Epoch[22] Batch [980]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116577,	
2017-06-27 21:51:59,285 Epoch[22] Batch [990]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116523,	
2017-06-27 21:52:03,368 Epoch[22] Batch [1000]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116439,	
2017-06-27 21:52:07,427 Epoch[22] Batch [1010]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116288,	
2017-06-27 21:52:11,525 Epoch[22] Batch [1020]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116221,	
2017-06-27 21:52:15,557 Epoch[22] Batch [1030]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116283,	
2017-06-27 21:52:19,638 Epoch[22] Batch [1040]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116206,	
2017-06-27 21:52:23,688 Epoch[22] Batch [1050]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.116113,	
2017-06-27 21:52:27,711 Epoch[22] Batch [1060]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.116074,	
2017-06-27 21:52:31,723 Epoch[22] Batch [1070]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.115947,	
2017-06-27 21:52:35,732 Epoch[22] Batch [1080]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.115912,	
2017-06-27 21:52:39,771 Epoch[22] Batch [1090]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.115907,	
2017-06-27 21:52:43,908 Epoch[22] Batch [1100]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.115839,	
2017-06-27 21:52:47,964 Epoch[22] Batch [1110]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.115746,	
2017-06-27 21:52:51,998 Epoch[22] Batch [1120]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115689,	
2017-06-27 21:52:56,078 Epoch[22] Batch [1130]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.115585,	
2017-06-27 21:53:00,150 Epoch[22] Batch [1140]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115678,	
2017-06-27 21:53:04,179 Epoch[22] Batch [1150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.115650,	
2017-06-27 21:53:08,195 Epoch[22] Batch [1160]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.115683,	
2017-06-27 21:53:12,292 Epoch[22] Batch [1170]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.115780,	
2017-06-27 21:53:16,262 Epoch[22] Batch [1180]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.115725,	
2017-06-27 21:53:20,226 Epoch[22] Batch [1190]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.115706,	
2017-06-27 21:53:24,302 Epoch[22] Batch [1200]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115712,	
2017-06-27 21:53:28,374 Epoch[22] Batch [1210]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115679,	
2017-06-27 21:53:32,545 Epoch[22] Batch [1220]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.115723,	
2017-06-27 21:53:36,702 Epoch[22] Batch [1230]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.115784,	
2017-06-27 21:53:40,851 Epoch[22] Batch [1240]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.115714,	
2017-06-27 21:53:44,991 Epoch[22] Batch [1250]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115640,	
2017-06-27 21:53:49,098 Epoch[22] Batch [1260]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115515,	
2017-06-27 21:53:53,130 Epoch[22] Batch [1270]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115463,	
2017-06-27 21:53:57,236 Epoch[22] Batch [1280]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115462,	
2017-06-27 21:54:01,259 Epoch[22] Batch [1290]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.115283,	
2017-06-27 21:54:05,345 Epoch[22] Batch [1300]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115310,	
2017-06-27 21:54:09,379 Epoch[22] Batch [1310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115292,	
2017-06-27 21:54:13,421 Epoch[22] Batch [1320]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.115324,	
2017-06-27 21:54:17,464 Epoch[22] Batch [1330]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.115269,	
2017-06-27 21:54:21,473 Epoch[22] Batch [1340]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.115257,	
2017-06-27 21:54:25,558 Epoch[22] Batch [1350]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115135,	
2017-06-27 21:54:29,743 Epoch[22] Batch [1360]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.115001,	
2017-06-27 21:54:33,817 Epoch[22] Batch [1370]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114957,	
2017-06-27 21:54:37,891 Epoch[22] Batch [1380]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114895,	
2017-06-27 21:54:41,965 Epoch[22] Batch [1390]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114860,	
2017-06-27 21:54:46,093 Epoch[22] Batch [1400]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.114776,	
2017-06-27 21:54:50,067 Epoch[22] Batch [1410]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.114803,	
2017-06-27 21:54:54,156 Epoch[22] Batch [1420]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114683,	
2017-06-27 21:54:58,108 Epoch[22] Batch [1430]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.114688,	
2017-06-27 21:55:02,123 Epoch[22] Batch [1440]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.114657,	
2017-06-27 21:55:06,271 Epoch[22] Batch [1450]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.114576,	
2017-06-27 21:55:10,357 Epoch[22] Batch [1460]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.114590,	
2017-06-27 21:55:14,438 Epoch[22] Batch [1470]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114587,	
2017-06-27 21:55:18,562 Epoch[22] Batch [1480]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.114612,	
2017-06-27 21:55:20,917 Epoch[22] Train-FCNLogLoss=0.114670
2017-06-27 21:55:20,918 Epoch[22] Time cost=605.345
2017-06-27 21:55:21,689 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0023.params"
2017-06-27 21:55:23,308 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0023.states"
2017-06-27 21:55:28,015 Epoch[23] Batch [10]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104524,	
2017-06-27 21:55:32,040 Epoch[23] Batch [20]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100179,	
2017-06-27 21:55:36,071 Epoch[23] Batch [30]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103998,	
2017-06-27 21:55:40,139 Epoch[23] Batch [40]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104938,	
2017-06-27 21:55:44,167 Epoch[23] Batch [50]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.106742,	
2017-06-27 21:55:48,159 Epoch[23] Batch [60]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.106989,	
2017-06-27 21:55:52,194 Epoch[23] Batch [70]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.107001,	
2017-06-27 21:55:56,235 Epoch[23] Batch [80]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.107889,	
2017-06-27 21:56:00,322 Epoch[23] Batch [90]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.108438,	
2017-06-27 21:56:04,411 Epoch[23] Batch [100]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.108115,	
2017-06-27 21:56:08,449 Epoch[23] Batch [110]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.108884,	
2017-06-27 21:56:12,498 Epoch[23] Batch [120]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.108470,	
2017-06-27 21:56:16,613 Epoch[23] Batch [130]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.107513,	
2017-06-27 21:56:20,647 Epoch[23] Batch [140]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.108431,	
2017-06-27 21:56:24,769 Epoch[23] Batch [150]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.108442,	
2017-06-27 21:56:28,884 Epoch[23] Batch [160]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.108419,	
2017-06-27 21:56:32,979 Epoch[23] Batch [170]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108280,	
2017-06-27 21:56:37,013 Epoch[23] Batch [180]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.109370,	
2017-06-27 21:56:40,938 Epoch[23] Batch [190]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.111165,	
2017-06-27 21:56:45,024 Epoch[23] Batch [200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112036,	
2017-06-27 21:56:48,983 Epoch[23] Batch [210]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.112240,	
2017-06-27 21:56:53,039 Epoch[23] Batch [220]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112863,	
2017-06-27 21:56:57,078 Epoch[23] Batch [230]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113052,	
2017-06-27 21:57:01,101 Epoch[23] Batch [240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112915,	
2017-06-27 21:57:05,112 Epoch[23] Batch [250]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.112631,	
2017-06-27 21:57:09,235 Epoch[23] Batch [260]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112806,	
2017-06-27 21:57:13,285 Epoch[23] Batch [270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113036,	
2017-06-27 21:57:17,380 Epoch[23] Batch [280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113111,	
2017-06-27 21:57:21,428 Epoch[23] Batch [290]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113515,	
2017-06-27 21:57:25,422 Epoch[23] Batch [300]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.113653,	
2017-06-27 21:57:29,461 Epoch[23] Batch [310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.113675,	
2017-06-27 21:57:33,528 Epoch[23] Batch [320]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.114256,	
2017-06-27 21:57:37,523 Epoch[23] Batch [330]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.114206,	
2017-06-27 21:57:41,620 Epoch[23] Batch [340]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.114188,	
2017-06-27 21:57:45,608 Epoch[23] Batch [350]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.114158,	
2017-06-27 21:57:49,591 Epoch[23] Batch [360]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.114054,	
2017-06-27 21:57:53,548 Epoch[23] Batch [370]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.113612,	
2017-06-27 21:57:57,616 Epoch[23] Batch [380]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113787,	
2017-06-27 21:58:01,624 Epoch[23] Batch [390]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113771,	
2017-06-27 21:58:05,758 Epoch[23] Batch [400]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113461,	
2017-06-27 21:58:09,715 Epoch[23] Batch [410]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.113535,	
2017-06-27 21:58:13,824 Epoch[23] Batch [420]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113361,	
2017-06-27 21:58:17,951 Epoch[23] Batch [430]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.113458,	
2017-06-27 21:58:21,988 Epoch[23] Batch [440]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113242,	
2017-06-27 21:58:26,075 Epoch[23] Batch [450]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.113001,	
2017-06-27 21:58:30,100 Epoch[23] Batch [460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112884,	
2017-06-27 21:58:34,015 Epoch[23] Batch [470]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.112903,	
2017-06-27 21:58:38,096 Epoch[23] Batch [480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112918,	
2017-06-27 21:58:42,136 Epoch[23] Batch [490]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112956,	
2017-06-27 21:58:46,261 Epoch[23] Batch [500]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112953,	
2017-06-27 21:58:50,265 Epoch[23] Batch [510]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.113119,	
2017-06-27 21:58:54,276 Epoch[23] Batch [520]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.112967,	
2017-06-27 21:58:58,336 Epoch[23] Batch [530]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112659,	
2017-06-27 21:59:02,431 Epoch[23] Batch [540]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112823,	
2017-06-27 21:59:06,447 Epoch[23] Batch [550]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112837,	
2017-06-27 21:59:10,519 Epoch[23] Batch [560]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112860,	
2017-06-27 21:59:14,542 Epoch[23] Batch [570]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112660,	
2017-06-27 21:59:18,697 Epoch[23] Batch [580]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112701,	
2017-06-27 21:59:22,712 Epoch[23] Batch [590]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112558,	
2017-06-27 21:59:26,738 Epoch[23] Batch [600]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112157,	
2017-06-27 21:59:30,853 Epoch[23] Batch [610]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112284,	
2017-06-27 21:59:34,810 Epoch[23] Batch [620]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.112310,	
2017-06-27 21:59:38,917 Epoch[23] Batch [630]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112104,	
2017-06-27 21:59:43,048 Epoch[23] Batch [640]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112461,	
2017-06-27 21:59:47,041 Epoch[23] Batch [650]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112660,	
2017-06-27 21:59:51,127 Epoch[23] Batch [660]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112525,	
2017-06-27 21:59:55,214 Epoch[23] Batch [670]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112420,	
2017-06-27 21:59:59,236 Epoch[23] Batch [680]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112419,	
2017-06-27 22:00:03,275 Epoch[23] Batch [690]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112407,	
2017-06-27 22:00:07,138 Epoch[23] Batch [700]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.112362,	
2017-06-27 22:00:11,280 Epoch[23] Batch [710]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.112235,	
2017-06-27 22:00:15,302 Epoch[23] Batch [720]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112319,	
2017-06-27 22:00:19,404 Epoch[23] Batch [730]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.112446,	
2017-06-27 22:00:23,457 Epoch[23] Batch [740]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112354,	
2017-06-27 22:00:27,521 Epoch[23] Batch [750]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.112384,	
2017-06-27 22:00:31,587 Epoch[23] Batch [760]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.112404,	
2017-06-27 22:00:35,683 Epoch[23] Batch [770]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112287,	
2017-06-27 22:00:39,760 Epoch[23] Batch [780]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.112350,	
2017-06-27 22:00:43,913 Epoch[23] Batch [790]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112335,	
2017-06-27 22:00:48,012 Epoch[23] Batch [800]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112516,	
2017-06-27 22:00:52,122 Epoch[23] Batch [810]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112463,	
2017-06-27 22:00:56,269 Epoch[23] Batch [820]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112489,	
2017-06-27 22:01:00,430 Epoch[23] Batch [830]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.112473,	
2017-06-27 22:01:04,380 Epoch[23] Batch [840]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.112442,	
2017-06-27 22:01:08,438 Epoch[23] Batch [850]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112476,	
2017-06-27 22:01:12,478 Epoch[23] Batch [860]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112385,	
2017-06-27 22:01:16,597 Epoch[23] Batch [870]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112350,	
2017-06-27 22:01:20,650 Epoch[23] Batch [880]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112474,	
2017-06-27 22:01:24,661 Epoch[23] Batch [890]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.112575,	
2017-06-27 22:01:28,734 Epoch[23] Batch [900]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112533,	
2017-06-27 22:01:32,841 Epoch[23] Batch [910]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112396,	
2017-06-27 22:01:36,859 Epoch[23] Batch [920]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112361,	
2017-06-27 22:01:41,014 Epoch[23] Batch [930]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112348,	
2017-06-27 22:01:45,133 Epoch[23] Batch [940]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112320,	
2017-06-27 22:01:49,240 Epoch[23] Batch [950]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112272,	
2017-06-27 22:01:53,231 Epoch[23] Batch [960]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112343,	
2017-06-27 22:01:57,271 Epoch[23] Batch [970]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112293,	
2017-06-27 22:02:01,327 Epoch[23] Batch [980]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112356,	
2017-06-27 22:02:05,365 Epoch[23] Batch [990]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.112352,	
2017-06-27 22:02:09,404 Epoch[23] Batch [1000]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112286,	
2017-06-27 22:02:13,396 Epoch[23] Batch [1010]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112221,	
2017-06-27 22:02:17,421 Epoch[23] Batch [1020]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112137,	
2017-06-27 22:02:21,450 Epoch[23] Batch [1030]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112052,	
2017-06-27 22:02:25,460 Epoch[23] Batch [1040]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112106,	
2017-06-27 22:02:29,509 Epoch[23] Batch [1050]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112106,	
2017-06-27 22:02:33,511 Epoch[23] Batch [1060]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112069,	
2017-06-27 22:02:37,600 Epoch[23] Batch [1070]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112070,	
2017-06-27 22:02:41,537 Epoch[23] Batch [1080]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.112067,	
2017-06-27 22:02:45,618 Epoch[23] Batch [1090]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111970,	
2017-06-27 22:02:49,612 Epoch[23] Batch [1100]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.111967,	
2017-06-27 22:02:53,754 Epoch[23] Batch [1110]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.112029,	
2017-06-27 22:02:57,756 Epoch[23] Batch [1120]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.112066,	
2017-06-27 22:03:01,913 Epoch[23] Batch [1130]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.112104,	
2017-06-27 22:03:06,000 Epoch[23] Batch [1140]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112322,	
2017-06-27 22:03:10,027 Epoch[23] Batch [1150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112437,	
2017-06-27 22:03:14,128 Epoch[23] Batch [1160]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112383,	
2017-06-27 22:03:18,251 Epoch[23] Batch [1170]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112341,	
2017-06-27 22:03:22,372 Epoch[23] Batch [1180]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112383,	
2017-06-27 22:03:26,482 Epoch[23] Batch [1190]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112470,	
2017-06-27 22:03:30,586 Epoch[23] Batch [1200]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.112565,	
2017-06-27 22:03:34,617 Epoch[23] Batch [1210]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112450,	
2017-06-27 22:03:38,630 Epoch[23] Batch [1220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.112320,	
2017-06-27 22:03:42,582 Epoch[23] Batch [1230]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.112248,	
2017-06-27 22:03:46,696 Epoch[23] Batch [1240]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.112253,	
2017-06-27 22:03:50,662 Epoch[23] Batch [1250]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.112174,	
2017-06-27 22:03:54,689 Epoch[23] Batch [1260]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112195,	
2017-06-27 22:03:58,739 Epoch[23] Batch [1270]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112205,	
2017-06-27 22:04:02,770 Epoch[23] Batch [1280]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112260,	
2017-06-27 22:04:06,869 Epoch[23] Batch [1290]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112155,	
2017-06-27 22:04:10,944 Epoch[23] Batch [1300]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112389,	
2017-06-27 22:04:14,908 Epoch[23] Batch [1310]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.112413,	
2017-06-27 22:04:18,985 Epoch[23] Batch [1320]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.112315,	
2017-06-27 22:04:23,024 Epoch[23] Batch [1330]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112327,	
2017-06-27 22:04:27,100 Epoch[23] Batch [1340]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.112318,	
2017-06-27 22:04:31,137 Epoch[23] Batch [1350]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.112269,	
2017-06-27 22:04:35,146 Epoch[23] Batch [1360]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112163,	
2017-06-27 22:04:39,254 Epoch[23] Batch [1370]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112150,	
2017-06-27 22:04:43,298 Epoch[23] Batch [1380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112113,	
2017-06-27 22:04:47,319 Epoch[23] Batch [1390]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112181,	
2017-06-27 22:04:51,337 Epoch[23] Batch [1400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112172,	
2017-06-27 22:04:55,445 Epoch[23] Batch [1410]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112207,	
2017-06-27 22:04:59,499 Epoch[23] Batch [1420]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112199,	
2017-06-27 22:05:03,557 Epoch[23] Batch [1430]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112109,	
2017-06-27 22:05:07,650 Epoch[23] Batch [1440]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112136,	
2017-06-27 22:05:11,671 Epoch[23] Batch [1450]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112173,	
2017-06-27 22:05:15,727 Epoch[23] Batch [1460]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112287,	
2017-06-27 22:05:19,840 Epoch[23] Batch [1470]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112344,	
2017-06-27 22:05:23,876 Epoch[23] Batch [1480]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.112388,	
2017-06-27 22:05:26,302 Epoch[23] Train-FCNLogLoss=0.112397
2017-06-27 22:05:26,302 Epoch[23] Time cost=602.994
2017-06-27 22:05:27,049 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0024.params"
2017-06-27 22:05:28,671 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0024.states"
2017-06-27 22:05:33,454 Epoch[24] Batch [10]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.106287,	
2017-06-27 22:05:37,447 Epoch[24] Batch [20]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.111489,	
2017-06-27 22:05:41,538 Epoch[24] Batch [30]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110126,	
2017-06-27 22:05:45,667 Epoch[24] Batch [40]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112635,	
2017-06-27 22:05:49,702 Epoch[24] Batch [50]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.112208,	
2017-06-27 22:05:53,792 Epoch[24] Batch [60]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109964,	
2017-06-27 22:05:57,878 Epoch[24] Batch [70]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110266,	
2017-06-27 22:06:02,018 Epoch[24] Batch [80]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110723,	
2017-06-27 22:06:06,194 Epoch[24] Batch [90]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110949,	
2017-06-27 22:06:10,204 Epoch[24] Batch [100]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112452,	
2017-06-27 22:06:14,338 Epoch[24] Batch [110]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.112152,	
2017-06-27 22:06:18,527 Epoch[24] Batch [120]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.111533,	
2017-06-27 22:06:22,664 Epoch[24] Batch [130]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.110571,	
2017-06-27 22:06:26,781 Epoch[24] Batch [140]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.109524,	
2017-06-27 22:06:30,877 Epoch[24] Batch [150]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.109502,	
2017-06-27 22:06:34,919 Epoch[24] Batch [160]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.108582,	
2017-06-27 22:06:39,063 Epoch[24] Batch [170]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.108570,	
2017-06-27 22:06:43,173 Epoch[24] Batch [180]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.108326,	
2017-06-27 22:06:47,253 Epoch[24] Batch [190]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.108349,	
2017-06-27 22:06:51,247 Epoch[24] Batch [200]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.109136,	
2017-06-27 22:06:55,315 Epoch[24] Batch [210]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.109137,	
2017-06-27 22:06:59,432 Epoch[24] Batch [220]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.109491,	
2017-06-27 22:07:03,468 Epoch[24] Batch [230]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.109623,	
2017-06-27 22:07:07,528 Epoch[24] Batch [240]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109290,	
2017-06-27 22:07:11,398 Epoch[24] Batch [250]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.109177,	
2017-06-27 22:07:15,406 Epoch[24] Batch [260]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109061,	
2017-06-27 22:07:19,374 Epoch[24] Batch [270]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.108683,	
2017-06-27 22:07:23,429 Epoch[24] Batch [280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.109041,	
2017-06-27 22:07:27,409 Epoch[24] Batch [290]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.108941,	
2017-06-27 22:07:31,482 Epoch[24] Batch [300]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.109095,	
2017-06-27 22:07:35,484 Epoch[24] Batch [310]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.108724,	
2017-06-27 22:07:39,604 Epoch[24] Batch [320]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.108359,	
2017-06-27 22:07:43,642 Epoch[24] Batch [330]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.108504,	
2017-06-27 22:07:47,749 Epoch[24] Batch [340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.108469,	
2017-06-27 22:07:51,883 Epoch[24] Batch [350]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108399,	
2017-06-27 22:07:55,928 Epoch[24] Batch [360]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.108869,	
2017-06-27 22:07:59,957 Epoch[24] Batch [370]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108510,	
2017-06-27 22:08:04,087 Epoch[24] Batch [380]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.108599,	
2017-06-27 22:08:08,143 Epoch[24] Batch [390]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108965,	
2017-06-27 22:08:12,191 Epoch[24] Batch [400]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.108911,	
2017-06-27 22:08:16,254 Epoch[24] Batch [410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.108933,	
2017-06-27 22:08:20,345 Epoch[24] Batch [420]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.108740,	
2017-06-27 22:08:24,346 Epoch[24] Batch [430]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.108582,	
2017-06-27 22:08:28,453 Epoch[24] Batch [440]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.108490,	
2017-06-27 22:08:32,526 Epoch[24] Batch [450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.108529,	
2017-06-27 22:08:36,575 Epoch[24] Batch [460]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.108516,	
2017-06-27 22:08:40,697 Epoch[24] Batch [470]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.108564,	
2017-06-27 22:08:44,838 Epoch[24] Batch [480]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.108409,	
2017-06-27 22:08:48,983 Epoch[24] Batch [490]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.108418,	
2017-06-27 22:08:53,060 Epoch[24] Batch [500]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.108344,	
2017-06-27 22:08:57,191 Epoch[24] Batch [510]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108229,	
2017-06-27 22:09:01,235 Epoch[24] Batch [520]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.108376,	
2017-06-27 22:09:05,314 Epoch[24] Batch [530]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.108437,	
2017-06-27 22:09:09,437 Epoch[24] Batch [540]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.108258,	
2017-06-27 22:09:13,466 Epoch[24] Batch [550]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108301,	
2017-06-27 22:09:17,465 Epoch[24] Batch [560]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.108162,	
2017-06-27 22:09:21,481 Epoch[24] Batch [570]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.108186,	
2017-06-27 22:09:25,542 Epoch[24] Batch [580]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.108071,	
2017-06-27 22:09:29,499 Epoch[24] Batch [590]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.108078,	
2017-06-27 22:09:33,518 Epoch[24] Batch [600]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.108010,	
2017-06-27 22:09:37,531 Epoch[24] Batch [610]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.107915,	
2017-06-27 22:09:41,574 Epoch[24] Batch [620]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.107724,	
2017-06-27 22:09:45,527 Epoch[24] Batch [630]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.107905,	
2017-06-27 22:09:49,583 Epoch[24] Batch [640]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.107917,	
2017-06-27 22:09:53,653 Epoch[24] Batch [650]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.107883,	
2017-06-27 22:09:57,617 Epoch[24] Batch [660]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.107729,	
2017-06-27 22:10:01,627 Epoch[24] Batch [670]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.107642,	
2017-06-27 22:10:05,716 Epoch[24] Batch [680]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.107936,	
2017-06-27 22:10:09,682 Epoch[24] Batch [690]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.107926,	
2017-06-27 22:10:13,717 Epoch[24] Batch [700]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.107963,	
2017-06-27 22:10:17,738 Epoch[24] Batch [710]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.107818,	
2017-06-27 22:10:21,825 Epoch[24] Batch [720]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.107757,	
2017-06-27 22:10:25,889 Epoch[24] Batch [730]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.107773,	
2017-06-27 22:10:30,022 Epoch[24] Batch [740]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.107817,	
2017-06-27 22:10:34,182 Epoch[24] Batch [750]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.107890,	
2017-06-27 22:10:38,325 Epoch[24] Batch [760]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.107926,	
2017-06-27 22:10:42,363 Epoch[24] Batch [770]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.107768,	
2017-06-27 22:10:46,423 Epoch[24] Batch [780]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.107701,	
2017-06-27 22:10:50,492 Epoch[24] Batch [790]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.107783,	
2017-06-27 22:10:54,495 Epoch[24] Batch [800]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.107707,	
2017-06-27 22:10:58,546 Epoch[24] Batch [810]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.107676,	
2017-06-27 22:11:02,693 Epoch[24] Batch [820]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107638,	
2017-06-27 22:11:06,744 Epoch[24] Batch [830]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.107758,	
2017-06-27 22:11:10,894 Epoch[24] Batch [840]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107791,	
2017-06-27 22:11:14,911 Epoch[24] Batch [850]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.107623,	
2017-06-27 22:11:19,003 Epoch[24] Batch [860]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.107578,	
2017-06-27 22:11:23,006 Epoch[24] Batch [870]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.107602,	
2017-06-27 22:11:27,088 Epoch[24] Batch [880]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.107573,	
2017-06-27 22:11:31,212 Epoch[24] Batch [890]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.107582,	
2017-06-27 22:11:35,266 Epoch[24] Batch [900]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.107881,	
2017-06-27 22:11:39,325 Epoch[24] Batch [910]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108029,	
2017-06-27 22:11:43,336 Epoch[24] Batch [920]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.108091,	
2017-06-27 22:11:47,325 Epoch[24] Batch [930]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.108068,	
2017-06-27 22:11:51,368 Epoch[24] Batch [940]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.108279,	
2017-06-27 22:11:55,384 Epoch[24] Batch [950]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.108333,	
2017-06-27 22:11:59,557 Epoch[24] Batch [960]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.108298,	
2017-06-27 22:12:03,688 Epoch[24] Batch [970]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108326,	
2017-06-27 22:12:07,775 Epoch[24] Batch [980]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.108278,	
2017-06-27 22:12:11,777 Epoch[24] Batch [990]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109163,	
2017-06-27 22:12:15,860 Epoch[24] Batch [1000]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.110548,	
2017-06-27 22:12:19,870 Epoch[24] Batch [1010]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112307,	
2017-06-27 22:12:24,001 Epoch[24] Batch [1020]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113773,	
2017-06-27 22:12:28,063 Epoch[24] Batch [1030]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.114373,	
2017-06-27 22:12:32,228 Epoch[24] Batch [1040]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.114618,	
2017-06-27 22:12:36,187 Epoch[24] Batch [1050]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.114855,	
2017-06-27 22:12:40,251 Epoch[24] Batch [1060]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115491,	
2017-06-27 22:12:44,291 Epoch[24] Batch [1070]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.115861,	
2017-06-27 22:12:48,274 Epoch[24] Batch [1080]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116371,	
2017-06-27 22:12:52,336 Epoch[24] Batch [1090]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116788,	
2017-06-27 22:12:56,442 Epoch[24] Batch [1100]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117133,	
2017-06-27 22:13:00,488 Epoch[24] Batch [1110]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117266,	
2017-06-27 22:13:04,494 Epoch[24] Batch [1120]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.117276,	
2017-06-27 22:13:08,571 Epoch[24] Batch [1130]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117422,	
2017-06-27 22:13:12,596 Epoch[24] Batch [1140]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117569,	
2017-06-27 22:13:16,564 Epoch[24] Batch [1150]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.117750,	
2017-06-27 22:13:20,585 Epoch[24] Batch [1160]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.117736,	
2017-06-27 22:13:24,554 Epoch[24] Batch [1170]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.117957,	
2017-06-27 22:13:28,577 Epoch[24] Batch [1180]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117873,	
2017-06-27 22:13:32,516 Epoch[24] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.117904,	
2017-06-27 22:13:36,612 Epoch[24] Batch [1200]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.118097,	
2017-06-27 22:13:40,709 Epoch[24] Batch [1210]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118100,	
2017-06-27 22:13:44,780 Epoch[24] Batch [1220]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.118092,	
2017-06-27 22:13:48,872 Epoch[24] Batch [1230]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.118046,	
2017-06-27 22:13:52,773 Epoch[24] Batch [1240]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.118146,	
2017-06-27 22:13:56,892 Epoch[24] Batch [1250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.118133,	
2017-06-27 22:14:00,954 Epoch[24] Batch [1260]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.118028,	
2017-06-27 22:14:04,905 Epoch[24] Batch [1270]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.118027,	
2017-06-27 22:14:08,902 Epoch[24] Batch [1280]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118129,	
2017-06-27 22:14:12,979 Epoch[24] Batch [1290]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118051,	
2017-06-27 22:14:17,080 Epoch[24] Batch [1300]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.118105,	
2017-06-27 22:14:21,157 Epoch[24] Batch [1310]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118095,	
2017-06-27 22:14:25,198 Epoch[24] Batch [1320]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118078,	
2017-06-27 22:14:29,155 Epoch[24] Batch [1330]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.118045,	
2017-06-27 22:14:33,287 Epoch[24] Batch [1340]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.117979,	
2017-06-27 22:14:37,316 Epoch[24] Batch [1350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.118019,	
2017-06-27 22:14:41,307 Epoch[24] Batch [1360]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.118112,	
2017-06-27 22:14:45,358 Epoch[24] Batch [1370]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.118179,	
2017-06-27 22:14:49,434 Epoch[24] Batch [1380]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.118115,	
2017-06-27 22:14:53,512 Epoch[24] Batch [1390]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117989,	
2017-06-27 22:14:57,503 Epoch[24] Batch [1400]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.118017,	
2017-06-27 22:15:01,603 Epoch[24] Batch [1410]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118004,	
2017-06-27 22:15:05,525 Epoch[24] Batch [1420]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.118032,	
2017-06-27 22:15:09,549 Epoch[24] Batch [1430]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.118131,	
2017-06-27 22:15:13,579 Epoch[24] Batch [1440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.118133,	
2017-06-27 22:15:17,699 Epoch[24] Batch [1450]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.118268,	
2017-06-27 22:15:21,731 Epoch[24] Batch [1460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.118258,	
2017-06-27 22:15:25,778 Epoch[24] Batch [1470]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.118162,	
2017-06-27 22:15:29,902 Epoch[24] Batch [1480]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.118187,	
2017-06-27 22:15:32,313 Epoch[24] Train-FCNLogLoss=0.118178
2017-06-27 22:15:32,313 Epoch[24] Time cost=603.642
2017-06-27 22:15:33,058 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0025.params"
2017-06-27 22:15:34,732 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0025.states"
2017-06-27 22:15:39,476 Epoch[25] Batch [10]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.102718,	
2017-06-27 22:15:43,532 Epoch[25] Batch [20]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.109673,	
2017-06-27 22:15:47,596 Epoch[25] Batch [30]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.111423,	
2017-06-27 22:15:51,703 Epoch[25] Batch [40]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113840,	
2017-06-27 22:15:55,789 Epoch[25] Batch [50]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115263,	
2017-06-27 22:15:59,926 Epoch[25] Batch [60]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.112407,	
2017-06-27 22:16:03,937 Epoch[25] Batch [70]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.112788,	
2017-06-27 22:16:07,962 Epoch[25] Batch [80]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111352,	
2017-06-27 22:16:12,066 Epoch[25] Batch [90]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.113023,	
2017-06-27 22:16:16,125 Epoch[25] Batch [100]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112798,	
2017-06-27 22:16:20,147 Epoch[25] Batch [110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111806,	
2017-06-27 22:16:24,284 Epoch[25] Batch [120]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.111788,	
2017-06-27 22:16:28,432 Epoch[25] Batch [130]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112441,	
2017-06-27 22:16:32,433 Epoch[25] Batch [140]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.111586,	
2017-06-27 22:16:36,485 Epoch[25] Batch [150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.111921,	
2017-06-27 22:16:40,608 Epoch[25] Batch [160]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112666,	
2017-06-27 22:16:44,642 Epoch[25] Batch [170]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112966,	
2017-06-27 22:16:48,791 Epoch[25] Batch [180]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112932,	
2017-06-27 22:16:52,914 Epoch[25] Batch [190]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112292,	
2017-06-27 22:16:56,952 Epoch[25] Batch [200]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.112033,	
2017-06-27 22:17:01,010 Epoch[25] Batch [210]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112084,	
2017-06-27 22:17:05,075 Epoch[25] Batch [220]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.112159,	
2017-06-27 22:17:09,170 Epoch[25] Batch [230]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112709,	
2017-06-27 22:17:13,082 Epoch[25] Batch [240]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.112630,	
2017-06-27 22:17:17,107 Epoch[25] Batch [250]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112760,	
2017-06-27 22:17:21,088 Epoch[25] Batch [260]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.112654,	
2017-06-27 22:17:25,150 Epoch[25] Batch [270]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113213,	
2017-06-27 22:17:29,149 Epoch[25] Batch [280]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.113329,	
2017-06-27 22:17:33,265 Epoch[25] Batch [290]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.113426,	
2017-06-27 22:17:37,278 Epoch[25] Batch [300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.113540,	
2017-06-27 22:17:41,299 Epoch[25] Batch [310]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113330,	
2017-06-27 22:17:45,398 Epoch[25] Batch [320]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113555,	
2017-06-27 22:17:49,446 Epoch[25] Batch [330]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113210,	
2017-06-27 22:17:53,594 Epoch[25] Batch [340]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.112851,	
2017-06-27 22:17:57,703 Epoch[25] Batch [350]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112576,	
2017-06-27 22:18:01,751 Epoch[25] Batch [360]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112250,	
2017-06-27 22:18:05,657 Epoch[25] Batch [370]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.112494,	
2017-06-27 22:18:09,695 Epoch[25] Batch [380]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112444,	
2017-06-27 22:18:13,717 Epoch[25] Batch [390]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112274,	
2017-06-27 22:18:17,730 Epoch[25] Batch [400]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.112280,	
2017-06-27 22:18:21,802 Epoch[25] Batch [410]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112186,	
2017-06-27 22:18:25,931 Epoch[25] Batch [420]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112254,	
2017-06-27 22:18:29,908 Epoch[25] Batch [430]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.112130,	
2017-06-27 22:18:34,092 Epoch[25] Batch [440]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112083,	
2017-06-27 22:18:38,107 Epoch[25] Batch [450]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.111761,	
2017-06-27 22:18:42,132 Epoch[25] Batch [460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111749,	
2017-06-27 22:18:46,235 Epoch[25] Batch [470]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111641,	
2017-06-27 22:18:50,340 Epoch[25] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111757,	
2017-06-27 22:18:54,413 Epoch[25] Batch [490]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.111685,	
2017-06-27 22:18:58,475 Epoch[25] Batch [500]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111808,	
2017-06-27 22:19:02,563 Epoch[25] Batch [510]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.111510,	
2017-06-27 22:19:06,493 Epoch[25] Batch [520]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.111493,	
2017-06-27 22:19:10,560 Epoch[25] Batch [530]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.111279,	
2017-06-27 22:19:14,649 Epoch[25] Batch [540]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110971,	
2017-06-27 22:19:18,719 Epoch[25] Batch [550]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.111037,	
2017-06-27 22:19:22,741 Epoch[25] Batch [560]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110882,	
2017-06-27 22:19:26,744 Epoch[25] Batch [570]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.110757,	
2017-06-27 22:19:30,937 Epoch[25] Batch [580]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.110774,	
2017-06-27 22:19:34,979 Epoch[25] Batch [590]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110936,	
2017-06-27 22:19:38,963 Epoch[25] Batch [600]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.111230,	
2017-06-27 22:19:42,989 Epoch[25] Batch [610]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111491,	
2017-06-27 22:19:47,123 Epoch[25] Batch [620]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.111542,	
2017-06-27 22:19:51,167 Epoch[25] Batch [630]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111962,	
2017-06-27 22:19:55,295 Epoch[25] Batch [640]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112159,	
2017-06-27 22:19:59,294 Epoch[25] Batch [650]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.112182,	
2017-06-27 22:20:03,378 Epoch[25] Batch [660]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112224,	
2017-06-27 22:20:07,427 Epoch[25] Batch [670]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112060,	
2017-06-27 22:20:11,377 Epoch[25] Batch [680]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.112198,	
2017-06-27 22:20:15,439 Epoch[25] Batch [690]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111966,	
2017-06-27 22:20:19,523 Epoch[25] Batch [700]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112070,	
2017-06-27 22:20:23,585 Epoch[25] Batch [710]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112054,	
2017-06-27 22:20:27,610 Epoch[25] Batch [720]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112144,	
2017-06-27 22:20:31,638 Epoch[25] Batch [730]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112396,	
2017-06-27 22:20:35,692 Epoch[25] Batch [740]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112361,	
2017-06-27 22:20:39,853 Epoch[25] Batch [750]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.112440,	
2017-06-27 22:20:43,941 Epoch[25] Batch [760]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112352,	
2017-06-27 22:20:48,092 Epoch[25] Batch [770]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112253,	
2017-06-27 22:20:52,173 Epoch[25] Batch [780]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112295,	
2017-06-27 22:20:56,284 Epoch[25] Batch [790]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112242,	
2017-06-27 22:21:00,480 Epoch[25] Batch [800]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112249,	
2017-06-27 22:21:04,527 Epoch[25] Batch [810]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112121,	
2017-06-27 22:21:08,578 Epoch[25] Batch [820]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112823,	
2017-06-27 22:21:12,684 Epoch[25] Batch [830]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113200,	
2017-06-27 22:21:16,690 Epoch[25] Batch [840]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.113439,	
2017-06-27 22:21:20,753 Epoch[25] Batch [850]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113638,	
2017-06-27 22:21:24,825 Epoch[25] Batch [860]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113904,	
2017-06-27 22:21:28,833 Epoch[25] Batch [870]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114061,	
2017-06-27 22:21:32,840 Epoch[25] Batch [880]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114245,	
2017-06-27 22:21:36,853 Epoch[25] Batch [890]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.114435,	
2017-06-27 22:21:40,937 Epoch[25] Batch [900]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114442,	
2017-06-27 22:21:45,097 Epoch[25] Batch [910]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.114643,	
2017-06-27 22:21:49,241 Epoch[25] Batch [920]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.114592,	
2017-06-27 22:21:53,237 Epoch[25] Batch [930]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.114626,	
2017-06-27 22:21:57,312 Epoch[25] Batch [940]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114526,	
2017-06-27 22:22:01,343 Epoch[25] Batch [950]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.114461,	
2017-06-27 22:22:05,414 Epoch[25] Batch [960]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.114417,	
2017-06-27 22:22:09,498 Epoch[25] Batch [970]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114352,	
2017-06-27 22:22:13,637 Epoch[25] Batch [980]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.114323,	
2017-06-27 22:22:17,661 Epoch[25] Batch [990]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114285,	
2017-06-27 22:22:21,733 Epoch[25] Batch [1000]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114204,	
2017-06-27 22:22:25,774 Epoch[25] Batch [1010]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114043,	
2017-06-27 22:22:29,808 Epoch[25] Batch [1020]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.114129,	
2017-06-27 22:22:33,869 Epoch[25] Batch [1030]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.114434,	
2017-06-27 22:22:37,895 Epoch[25] Batch [1040]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114901,	
2017-06-27 22:22:41,968 Epoch[25] Batch [1050]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115201,	
2017-06-27 22:22:45,933 Epoch[25] Batch [1060]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.115543,	
2017-06-27 22:22:49,990 Epoch[25] Batch [1070]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.115575,	
2017-06-27 22:22:54,050 Epoch[25] Batch [1080]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.115645,	
2017-06-27 22:22:57,971 Epoch[25] Batch [1090]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.115764,	
2017-06-27 22:23:02,064 Epoch[25] Batch [1100]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.115737,	
2017-06-27 22:23:06,173 Epoch[25] Batch [1110]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.115688,	
2017-06-27 22:23:10,277 Epoch[25] Batch [1120]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.115657,	
2017-06-27 22:23:14,298 Epoch[25] Batch [1130]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115591,	
2017-06-27 22:23:18,407 Epoch[25] Batch [1140]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.115658,	
2017-06-27 22:23:22,434 Epoch[25] Batch [1150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.115562,	
2017-06-27 22:23:26,454 Epoch[25] Batch [1160]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115689,	
2017-06-27 22:23:30,562 Epoch[25] Batch [1170]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.115775,	
2017-06-27 22:23:34,786 Epoch[25] Batch [1180]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.115691,	
2017-06-27 22:23:38,950 Epoch[25] Batch [1190]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.115734,	
2017-06-27 22:23:42,961 Epoch[25] Batch [1200]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.115757,	
2017-06-27 22:23:47,206 Epoch[25] Batch [1210]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.115702,	
2017-06-27 22:23:51,400 Epoch[25] Batch [1220]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.115716,	
2017-06-27 22:23:55,385 Epoch[25] Batch [1230]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.115650,	
2017-06-27 22:23:59,472 Epoch[25] Batch [1240]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115544,	
2017-06-27 22:24:03,539 Epoch[25] Batch [1250]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115480,	
2017-06-27 22:24:07,573 Epoch[25] Batch [1260]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115397,	
2017-06-27 22:24:11,587 Epoch[25] Batch [1270]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.115312,	
2017-06-27 22:24:15,690 Epoch[25] Batch [1280]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.115301,	
2017-06-27 22:24:19,763 Epoch[25] Batch [1290]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115219,	
2017-06-27 22:24:23,809 Epoch[25] Batch [1300]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.115152,	
2017-06-27 22:24:27,964 Epoch[25] Batch [1310]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.115213,	
2017-06-27 22:24:31,974 Epoch[25] Batch [1320]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.115209,	
2017-06-27 22:24:36,059 Epoch[25] Batch [1330]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115125,	
2017-06-27 22:24:40,143 Epoch[25] Batch [1340]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.115078,	
2017-06-27 22:24:44,115 Epoch[25] Batch [1350]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.115026,	
2017-06-27 22:24:48,196 Epoch[25] Batch [1360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114983,	
2017-06-27 22:24:52,277 Epoch[25] Batch [1370]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114918,	
2017-06-27 22:24:56,394 Epoch[25] Batch [1380]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.114923,	
2017-06-27 22:25:00,441 Epoch[25] Batch [1390]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.114896,	
2017-06-27 22:25:04,548 Epoch[25] Batch [1400]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.114823,	
2017-06-27 22:25:08,540 Epoch[25] Batch [1410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.114758,	
2017-06-27 22:25:12,674 Epoch[25] Batch [1420]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.114785,	
2017-06-27 22:25:16,682 Epoch[25] Batch [1430]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.114764,	
2017-06-27 22:25:20,765 Epoch[25] Batch [1440]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114710,	
2017-06-27 22:25:24,798 Epoch[25] Batch [1450]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.114646,	
2017-06-27 22:25:28,861 Epoch[25] Batch [1460]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.114674,	
2017-06-27 22:25:32,904 Epoch[25] Batch [1470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.114602,	
2017-06-27 22:25:36,959 Epoch[25] Batch [1480]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.114592,	
2017-06-27 22:25:39,451 Epoch[25] Train-FCNLogLoss=0.114699
2017-06-27 22:25:39,451 Epoch[25] Time cost=604.718
2017-06-27 22:25:40,162 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0026.params"
2017-06-27 22:25:41,759 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0026.states"
2017-06-27 22:25:46,373 Epoch[26] Batch [10]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.199188,	
2017-06-27 22:25:50,425 Epoch[26] Batch [20]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.173100,	
2017-06-27 22:25:54,508 Epoch[26] Batch [30]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.157860,	
2017-06-27 22:25:58,546 Epoch[26] Batch [40]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.164509,	
2017-06-27 22:26:02,548 Epoch[26] Batch [50]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.188617,	
2017-06-27 22:26:06,697 Epoch[26] Batch [60]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.189517,	
2017-06-27 22:26:10,740 Epoch[26] Batch [70]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.184920,	
2017-06-27 22:26:14,826 Epoch[26] Batch [80]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.180419,	
2017-06-27 22:26:18,940 Epoch[26] Batch [90]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.174858,	
2017-06-27 22:26:23,041 Epoch[26] Batch [100]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.170393,	
2017-06-27 22:26:27,111 Epoch[26] Batch [110]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.164524,	
2017-06-27 22:26:31,245 Epoch[26] Batch [120]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.161504,	
2017-06-27 22:26:35,263 Epoch[26] Batch [130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.158228,	
2017-06-27 22:26:39,259 Epoch[26] Batch [140]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.155640,	
2017-06-27 22:26:43,319 Epoch[26] Batch [150]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.153037,	
2017-06-27 22:26:47,367 Epoch[26] Batch [160]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.150395,	
2017-06-27 22:26:51,400 Epoch[26] Batch [170]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.148229,	
2017-06-27 22:26:55,482 Epoch[26] Batch [180]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.146948,	
2017-06-27 22:26:59,479 Epoch[26] Batch [190]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.145405,	
2017-06-27 22:27:03,559 Epoch[26] Batch [200]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.143741,	
2017-06-27 22:27:07,627 Epoch[26] Batch [210]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.142236,	
2017-06-27 22:27:11,706 Epoch[26] Batch [220]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.140218,	
2017-06-27 22:27:15,690 Epoch[26] Batch [230]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.139451,	
2017-06-27 22:27:19,710 Epoch[26] Batch [240]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.138475,	
2017-06-27 22:27:23,922 Epoch[26] Batch [250]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.137550,	
2017-06-27 22:27:27,992 Epoch[26] Batch [260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.136611,	
2017-06-27 22:27:32,047 Epoch[26] Batch [270]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.135522,	
2017-06-27 22:27:36,139 Epoch[26] Batch [280]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.135296,	
2017-06-27 22:27:40,240 Epoch[26] Batch [290]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.134402,	
2017-06-27 22:27:44,323 Epoch[26] Batch [300]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.134162,	
2017-06-27 22:27:48,327 Epoch[26] Batch [310]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.133068,	
2017-06-27 22:27:52,481 Epoch[26] Batch [320]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.132478,	
2017-06-27 22:27:56,647 Epoch[26] Batch [330]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.131731,	
2017-06-27 22:28:00,735 Epoch[26] Batch [340]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.131327,	
2017-06-27 22:28:04,797 Epoch[26] Batch [350]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.130090,	
2017-06-27 22:28:08,863 Epoch[26] Batch [360]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.130578,	
2017-06-27 22:28:12,944 Epoch[26] Batch [370]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.130477,	
2017-06-27 22:28:16,851 Epoch[26] Batch [380]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.130022,	
2017-06-27 22:28:20,945 Epoch[26] Batch [390]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.129651,	
2017-06-27 22:28:25,018 Epoch[26] Batch [400]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.129264,	
2017-06-27 22:28:29,158 Epoch[26] Batch [410]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.129653,	
2017-06-27 22:28:33,243 Epoch[26] Batch [420]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.130124,	
2017-06-27 22:28:37,239 Epoch[26] Batch [430]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.130849,	
2017-06-27 22:28:41,280 Epoch[26] Batch [440]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.131104,	
2017-06-27 22:28:45,426 Epoch[26] Batch [450]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.131120,	
2017-06-27 22:28:49,551 Epoch[26] Batch [460]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.131466,	
2017-06-27 22:28:53,628 Epoch[26] Batch [470]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.131200,	
2017-06-27 22:28:57,729 Epoch[26] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.131330,	
2017-06-27 22:29:01,775 Epoch[26] Batch [490]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.131475,	
2017-06-27 22:29:05,834 Epoch[26] Batch [500]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.131649,	
2017-06-27 22:29:09,934 Epoch[26] Batch [510]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.132003,	
2017-06-27 22:29:13,986 Epoch[26] Batch [520]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.131483,	
2017-06-27 22:29:17,987 Epoch[26] Batch [530]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.131583,	
2017-06-27 22:29:21,942 Epoch[26] Batch [540]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.131248,	
2017-06-27 22:29:25,980 Epoch[26] Batch [550]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.130898,	
2017-06-27 22:29:30,070 Epoch[26] Batch [560]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.130602,	
2017-06-27 22:29:34,145 Epoch[26] Batch [570]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130450,	
2017-06-27 22:29:38,276 Epoch[26] Batch [580]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.130198,	
2017-06-27 22:29:42,334 Epoch[26] Batch [590]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.130012,	
2017-06-27 22:29:46,461 Epoch[26] Batch [600]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.129675,	
2017-06-27 22:29:50,508 Epoch[26] Batch [610]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.129377,	
2017-06-27 22:29:54,560 Epoch[26] Batch [620]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.129135,	
2017-06-27 22:29:58,642 Epoch[26] Batch [630]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.128819,	
2017-06-27 22:30:02,677 Epoch[26] Batch [640]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.128601,	
2017-06-27 22:30:06,700 Epoch[26] Batch [650]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.128494,	
2017-06-27 22:30:10,788 Epoch[26] Batch [660]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.128367,	
2017-06-27 22:30:14,952 Epoch[26] Batch [670]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.128272,	
2017-06-27 22:30:19,010 Epoch[26] Batch [680]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.127953,	
2017-06-27 22:30:23,073 Epoch[26] Batch [690]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.127741,	
2017-06-27 22:30:27,172 Epoch[26] Batch [700]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.127508,	
2017-06-27 22:30:31,224 Epoch[26] Batch [710]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.127167,	
2017-06-27 22:30:35,525 Epoch[26] Batch [720]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.127051,	
2017-06-27 22:30:39,613 Epoch[26] Batch [730]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.126800,	
2017-06-27 22:30:43,727 Epoch[26] Batch [740]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.126581,	
2017-06-27 22:30:47,820 Epoch[26] Batch [750]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.126437,	
2017-06-27 22:30:51,868 Epoch[26] Batch [760]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.126217,	
2017-06-27 22:30:55,932 Epoch[26] Batch [770]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.126076,	
2017-06-27 22:30:59,998 Epoch[26] Batch [780]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.126004,	
2017-06-27 22:31:04,096 Epoch[26] Batch [790]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.126044,	
2017-06-27 22:31:08,109 Epoch[26] Batch [800]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.125783,	
2017-06-27 22:31:12,153 Epoch[26] Batch [810]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.125679,	
2017-06-27 22:31:16,269 Epoch[26] Batch [820]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.125561,	
2017-06-27 22:31:20,381 Epoch[26] Batch [830]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.125515,	
2017-06-27 22:31:24,407 Epoch[26] Batch [840]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.125133,	
2017-06-27 22:31:28,459 Epoch[26] Batch [850]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.124878,	
2017-06-27 22:31:32,513 Epoch[26] Batch [860]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.124802,	
2017-06-27 22:31:36,587 Epoch[26] Batch [870]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.124810,	
2017-06-27 22:31:40,689 Epoch[26] Batch [880]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.124697,	
2017-06-27 22:31:44,761 Epoch[26] Batch [890]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.124487,	
2017-06-27 22:31:48,787 Epoch[26] Batch [900]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.124447,	
2017-06-27 22:31:52,817 Epoch[26] Batch [910]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.124274,	
2017-06-27 22:31:56,820 Epoch[26] Batch [920]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.124176,	
2017-06-27 22:32:00,857 Epoch[26] Batch [930]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.124330,	
2017-06-27 22:32:04,920 Epoch[26] Batch [940]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.124425,	
2017-06-27 22:32:08,954 Epoch[26] Batch [950]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.124326,	
2017-06-27 22:32:13,034 Epoch[26] Batch [960]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.124185,	
2017-06-27 22:32:17,092 Epoch[26] Batch [970]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.124132,	
2017-06-27 22:32:21,105 Epoch[26] Batch [980]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.124052,	
2017-06-27 22:32:25,056 Epoch[26] Batch [990]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.124068,	
2017-06-27 22:32:29,074 Epoch[26] Batch [1000]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.124119,	
2017-06-27 22:32:33,137 Epoch[26] Batch [1010]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.124024,	
2017-06-27 22:32:37,101 Epoch[26] Batch [1020]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.123959,	
2017-06-27 22:32:41,383 Epoch[26] Batch [1030]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.123987,	
2017-06-27 22:32:45,502 Epoch[26] Batch [1040]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.124023,	
2017-06-27 22:32:49,495 Epoch[26] Batch [1050]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.124065,	
2017-06-27 22:32:53,614 Epoch[26] Batch [1060]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.124056,	
2017-06-27 22:32:57,569 Epoch[26] Batch [1070]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.124033,	
2017-06-27 22:33:01,688 Epoch[26] Batch [1080]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.123990,	
2017-06-27 22:33:05,710 Epoch[26] Batch [1090]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.123845,	
2017-06-27 22:33:09,788 Epoch[26] Batch [1100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.123617,	
2017-06-27 22:33:13,834 Epoch[26] Batch [1110]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.123453,	
2017-06-27 22:33:17,911 Epoch[26] Batch [1120]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.123324,	
2017-06-27 22:33:21,997 Epoch[26] Batch [1130]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.123111,	
2017-06-27 22:33:25,996 Epoch[26] Batch [1140]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.122946,	
2017-06-27 22:33:30,007 Epoch[26] Batch [1150]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.122851,	
2017-06-27 22:33:34,004 Epoch[26] Batch [1160]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.122734,	
2017-06-27 22:33:38,027 Epoch[26] Batch [1170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.122686,	
2017-06-27 22:33:41,985 Epoch[26] Batch [1180]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.122606,	
2017-06-27 22:33:46,063 Epoch[26] Batch [1190]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.122473,	
2017-06-27 22:33:50,112 Epoch[26] Batch [1200]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.122337,	
2017-06-27 22:33:54,167 Epoch[26] Batch [1210]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.122307,	
2017-06-27 22:33:58,127 Epoch[26] Batch [1220]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.122245,	
2017-06-27 22:34:02,144 Epoch[26] Batch [1230]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.122102,	
2017-06-27 22:34:06,155 Epoch[26] Batch [1240]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.121997,	
2017-06-27 22:34:10,159 Epoch[26] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.121977,	
2017-06-27 22:34:14,248 Epoch[26] Batch [1260]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.122034,	
2017-06-27 22:34:18,250 Epoch[26] Batch [1270]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.121829,	
2017-06-27 22:34:22,288 Epoch[26] Batch [1280]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.121761,	
2017-06-27 22:34:26,245 Epoch[26] Batch [1290]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.121588,	
2017-06-27 22:34:30,279 Epoch[26] Batch [1300]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.121427,	
2017-06-27 22:34:34,256 Epoch[26] Batch [1310]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121394,	
2017-06-27 22:34:38,225 Epoch[26] Batch [1320]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.121307,	
2017-06-27 22:34:42,166 Epoch[26] Batch [1330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.121307,	
2017-06-27 22:34:46,140 Epoch[26] Batch [1340]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121289,	
2017-06-27 22:34:50,070 Epoch[26] Batch [1350]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.121219,	
2017-06-27 22:34:54,101 Epoch[26] Batch [1360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.121140,	
2017-06-27 22:34:58,177 Epoch[26] Batch [1370]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.121079,	
2017-06-27 22:35:02,292 Epoch[26] Batch [1380]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.120958,	
2017-06-27 22:35:06,330 Epoch[26] Batch [1390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.120901,	
2017-06-27 22:35:10,384 Epoch[26] Batch [1400]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.120870,	
2017-06-27 22:35:14,553 Epoch[26] Batch [1410]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.120807,	
2017-06-27 22:35:18,564 Epoch[26] Batch [1420]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.120716,	
2017-06-27 22:35:22,615 Epoch[26] Batch [1430]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.120745,	
2017-06-27 22:35:26,543 Epoch[26] Batch [1440]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.120683,	
2017-06-27 22:35:30,571 Epoch[26] Batch [1450]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.120614,	
2017-06-27 22:35:34,605 Epoch[26] Batch [1460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.120498,	
2017-06-27 22:35:38,670 Epoch[26] Batch [1470]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.120356,	
2017-06-27 22:35:42,676 Epoch[26] Batch [1480]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.120272,	
2017-06-27 22:35:45,096 Epoch[26] Train-FCNLogLoss=0.120243
2017-06-27 22:35:45,096 Epoch[26] Time cost=603.336
2017-06-27 22:35:45,858 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0027.params"
2017-06-27 22:35:47,481 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0027.states"
2017-06-27 22:35:52,155 Epoch[27] Batch [10]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103527,	
2017-06-27 22:35:56,204 Epoch[27] Batch [20]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.119268,	
2017-06-27 22:36:00,198 Epoch[27] Batch [30]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.122705,	
2017-06-27 22:36:04,116 Epoch[27] Batch [40]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.122954,	
2017-06-27 22:36:08,204 Epoch[27] Batch [50]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.120549,	
2017-06-27 22:36:12,244 Epoch[27] Batch [60]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.119630,	
2017-06-27 22:36:16,285 Epoch[27] Batch [70]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118017,	
2017-06-27 22:36:20,383 Epoch[27] Batch [80]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.116613,	
2017-06-27 22:36:24,411 Epoch[27] Batch [90]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116717,	
2017-06-27 22:36:28,427 Epoch[27] Batch [100]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117319,	
2017-06-27 22:36:32,466 Epoch[27] Batch [110]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.117852,	
2017-06-27 22:36:36,529 Epoch[27] Batch [120]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.118509,	
2017-06-27 22:36:40,532 Epoch[27] Batch [130]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.117960,	
2017-06-27 22:36:44,694 Epoch[27] Batch [140]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.116987,	
2017-06-27 22:36:48,781 Epoch[27] Batch [150]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117266,	
2017-06-27 22:36:52,818 Epoch[27] Batch [160]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117943,	
2017-06-27 22:36:56,857 Epoch[27] Batch [170]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.118133,	
2017-06-27 22:37:00,856 Epoch[27] Batch [180]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.117968,	
2017-06-27 22:37:04,889 Epoch[27] Batch [190]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.118096,	
2017-06-27 22:37:08,964 Epoch[27] Batch [200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117104,	
2017-06-27 22:37:12,961 Epoch[27] Batch [210]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.117582,	
2017-06-27 22:37:17,045 Epoch[27] Batch [220]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117306,	
2017-06-27 22:37:21,210 Epoch[27] Batch [230]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.117033,	
2017-06-27 22:37:25,294 Epoch[27] Batch [240]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117309,	
2017-06-27 22:37:29,225 Epoch[27] Batch [250]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.117075,	
2017-06-27 22:37:33,310 Epoch[27] Batch [260]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116362,	
2017-06-27 22:37:37,455 Epoch[27] Batch [270]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.115856,	
2017-06-27 22:37:41,442 Epoch[27] Batch [280]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116053,	
2017-06-27 22:37:45,538 Epoch[27] Batch [290]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.115765,	
2017-06-27 22:37:49,649 Epoch[27] Batch [300]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.115109,	
2017-06-27 22:37:53,677 Epoch[27] Batch [310]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.115133,	
2017-06-27 22:37:57,680 Epoch[27] Batch [320]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.115288,	
2017-06-27 22:38:01,803 Epoch[27] Batch [330]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.115205,	
2017-06-27 22:38:05,732 Epoch[27] Batch [340]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.114891,	
2017-06-27 22:38:09,778 Epoch[27] Batch [350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.114768,	
2017-06-27 22:38:13,884 Epoch[27] Batch [360]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.114592,	
2017-06-27 22:38:17,908 Epoch[27] Batch [370]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114387,	
2017-06-27 22:38:21,924 Epoch[27] Batch [380]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.114008,	
2017-06-27 22:38:25,921 Epoch[27] Batch [390]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.114002,	
2017-06-27 22:38:29,982 Epoch[27] Batch [400]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113660,	
2017-06-27 22:38:33,979 Epoch[27] Batch [410]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.113362,	
2017-06-27 22:38:38,019 Epoch[27] Batch [420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113293,	
2017-06-27 22:38:42,113 Epoch[27] Batch [430]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113233,	
2017-06-27 22:38:46,116 Epoch[27] Batch [440]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.113008,	
2017-06-27 22:38:50,113 Epoch[27] Batch [450]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.112826,	
2017-06-27 22:38:54,055 Epoch[27] Batch [460]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.112780,	
2017-06-27 22:38:58,027 Epoch[27] Batch [470]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.112379,	
2017-06-27 22:39:02,186 Epoch[27] Batch [480]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.112154,	
2017-06-27 22:39:06,195 Epoch[27] Batch [490]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112091,	
2017-06-27 22:39:10,351 Epoch[27] Batch [500]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.112050,	
2017-06-27 22:39:14,351 Epoch[27] Batch [510]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.111889,	
2017-06-27 22:39:18,398 Epoch[27] Batch [520]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111688,	
2017-06-27 22:39:22,363 Epoch[27] Batch [530]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.111782,	
2017-06-27 22:39:26,446 Epoch[27] Batch [540]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111669,	
2017-06-27 22:39:30,436 Epoch[27] Batch [550]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.111474,	
2017-06-27 22:39:34,473 Epoch[27] Batch [560]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.111430,	
2017-06-27 22:39:38,574 Epoch[27] Batch [570]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.111312,	
2017-06-27 22:39:42,636 Epoch[27] Batch [580]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111257,	
2017-06-27 22:39:46,632 Epoch[27] Batch [590]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.111019,	
2017-06-27 22:39:50,694 Epoch[27] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110917,	
2017-06-27 22:39:54,755 Epoch[27] Batch [610]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110842,	
2017-06-27 22:39:58,838 Epoch[27] Batch [620]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.110841,	
2017-06-27 22:40:02,953 Epoch[27] Batch [630]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110900,	
2017-06-27 22:40:06,963 Epoch[27] Batch [640]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.111001,	
2017-06-27 22:40:11,024 Epoch[27] Batch [650]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110825,	
2017-06-27 22:40:15,009 Epoch[27] Batch [660]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110873,	
2017-06-27 22:40:19,058 Epoch[27] Batch [670]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.110739,	
2017-06-27 22:40:23,099 Epoch[27] Batch [680]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110594,	
2017-06-27 22:40:27,084 Epoch[27] Batch [690]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110588,	
2017-06-27 22:40:31,195 Epoch[27] Batch [700]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110457,	
2017-06-27 22:40:35,259 Epoch[27] Batch [710]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.110584,	
2017-06-27 22:40:39,322 Epoch[27] Batch [720]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110490,	
2017-06-27 22:40:43,433 Epoch[27] Batch [730]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110517,	
2017-06-27 22:40:47,596 Epoch[27] Batch [740]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.110573,	
2017-06-27 22:40:51,595 Epoch[27] Batch [750]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.110579,	
2017-06-27 22:40:55,677 Epoch[27] Batch [760]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.110442,	
2017-06-27 22:40:59,738 Epoch[27] Batch [770]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110486,	
2017-06-27 22:41:03,808 Epoch[27] Batch [780]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110326,	
2017-06-27 22:41:07,858 Epoch[27] Batch [790]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.110302,	
2017-06-27 22:41:11,886 Epoch[27] Batch [800]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110146,	
2017-06-27 22:41:16,026 Epoch[27] Batch [810]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.110128,	
2017-06-27 22:41:20,122 Epoch[27] Batch [820]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110125,	
2017-06-27 22:41:24,164 Epoch[27] Batch [830]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110276,	
2017-06-27 22:41:28,288 Epoch[27] Batch [840]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110251,	
2017-06-27 22:41:32,421 Epoch[27] Batch [850]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.110233,	
2017-06-27 22:41:36,547 Epoch[27] Batch [860]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110406,	
2017-06-27 22:41:40,642 Epoch[27] Batch [870]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110344,	
2017-06-27 22:41:44,807 Epoch[27] Batch [880]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.110417,	
2017-06-27 22:41:48,893 Epoch[27] Batch [890]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110457,	
2017-06-27 22:41:52,863 Epoch[27] Batch [900]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.110348,	
2017-06-27 22:41:56,873 Epoch[27] Batch [910]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.110264,	
2017-06-27 22:42:00,857 Epoch[27] Batch [920]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110290,	
2017-06-27 22:42:04,966 Epoch[27] Batch [930]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.110354,	
2017-06-27 22:42:09,057 Epoch[27] Batch [940]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110291,	
2017-06-27 22:42:13,136 Epoch[27] Batch [950]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.110297,	
2017-06-27 22:42:17,128 Epoch[27] Batch [960]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110317,	
2017-06-27 22:42:21,197 Epoch[27] Batch [970]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110400,	
2017-06-27 22:42:25,266 Epoch[27] Batch [980]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110228,	
2017-06-27 22:42:29,389 Epoch[27] Batch [990]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110289,	
2017-06-27 22:42:33,458 Epoch[27] Batch [1000]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110230,	
2017-06-27 22:42:37,504 Epoch[27] Batch [1010]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110211,	
2017-06-27 22:42:41,514 Epoch[27] Batch [1020]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.110232,	
2017-06-27 22:42:45,551 Epoch[27] Batch [1030]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.110208,	
2017-06-27 22:42:49,551 Epoch[27] Batch [1040]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.110125,	
2017-06-27 22:42:53,650 Epoch[27] Batch [1050]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.109999,	
2017-06-27 22:42:57,742 Epoch[27] Batch [1060]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110045,	
2017-06-27 22:43:01,859 Epoch[27] Batch [1070]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110057,	
2017-06-27 22:43:05,958 Epoch[27] Batch [1080]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.109927,	
2017-06-27 22:43:09,972 Epoch[27] Batch [1090]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.109863,	
2017-06-27 22:43:14,013 Epoch[27] Batch [1100]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109750,	
2017-06-27 22:43:18,206 Epoch[27] Batch [1110]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.109700,	
2017-06-27 22:43:22,361 Epoch[27] Batch [1120]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.109783,	
2017-06-27 22:43:26,439 Epoch[27] Batch [1130]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109888,	
2017-06-27 22:43:30,506 Epoch[27] Batch [1140]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.109922,	
2017-06-27 22:43:34,578 Epoch[27] Batch [1150]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.109859,	
2017-06-27 22:43:38,736 Epoch[27] Batch [1160]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109855,	
2017-06-27 22:43:42,913 Epoch[27] Batch [1170]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109839,	
2017-06-27 22:43:47,122 Epoch[27] Batch [1180]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.109792,	
2017-06-27 22:43:51,209 Epoch[27] Batch [1190]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.109844,	
2017-06-27 22:43:55,272 Epoch[27] Batch [1200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109890,	
2017-06-27 22:43:59,315 Epoch[27] Batch [1210]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109892,	
2017-06-27 22:44:03,351 Epoch[27] Batch [1220]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.109962,	
2017-06-27 22:44:07,481 Epoch[27] Batch [1230]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.109912,	
2017-06-27 22:44:11,638 Epoch[27] Batch [1240]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109958,	
2017-06-27 22:44:15,730 Epoch[27] Batch [1250]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109925,	
2017-06-27 22:44:19,810 Epoch[27] Batch [1260]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109928,	
2017-06-27 22:44:23,901 Epoch[27] Batch [1270]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109957,	
2017-06-27 22:44:27,923 Epoch[27] Batch [1280]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.109921,	
2017-06-27 22:44:32,090 Epoch[27] Batch [1290]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.109807,	
2017-06-27 22:44:36,150 Epoch[27] Batch [1300]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109886,	
2017-06-27 22:44:40,328 Epoch[27] Batch [1310]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109821,	
2017-06-27 22:44:44,396 Epoch[27] Batch [1320]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.109811,	
2017-06-27 22:44:48,488 Epoch[27] Batch [1330]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109760,	
2017-06-27 22:44:52,680 Epoch[27] Batch [1340]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.109715,	
2017-06-27 22:44:56,725 Epoch[27] Batch [1350]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109819,	
2017-06-27 22:45:00,777 Epoch[27] Batch [1360]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.109759,	
2017-06-27 22:45:04,832 Epoch[27] Batch [1370]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.109775,	
2017-06-27 22:45:08,966 Epoch[27] Batch [1380]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.109690,	
2017-06-27 22:45:13,069 Epoch[27] Batch [1390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.109654,	
2017-06-27 22:45:17,140 Epoch[27] Batch [1400]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109687,	
2017-06-27 22:45:21,205 Epoch[27] Batch [1410]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.109690,	
2017-06-27 22:45:25,207 Epoch[27] Batch [1420]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109639,	
2017-06-27 22:45:29,208 Epoch[27] Batch [1430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.109593,	
2017-06-27 22:45:33,225 Epoch[27] Batch [1440]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109566,	
2017-06-27 22:45:37,265 Epoch[27] Batch [1450]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109641,	
2017-06-27 22:45:41,377 Epoch[27] Batch [1460]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.109617,	
2017-06-27 22:45:45,363 Epoch[27] Batch [1470]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.109544,	
2017-06-27 22:45:49,388 Epoch[27] Batch [1480]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.109577,	
2017-06-27 22:45:51,792 Epoch[27] Train-FCNLogLoss=0.109545
2017-06-27 22:45:51,792 Epoch[27] Time cost=604.311
2017-06-27 22:45:52,480 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0028.params"
2017-06-27 22:45:54,079 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0028.states"
2017-06-27 22:45:58,765 Epoch[28] Batch [10]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.108113,	
2017-06-27 22:46:02,827 Epoch[28] Batch [20]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.106210,	
2017-06-27 22:46:06,837 Epoch[28] Batch [30]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.108871,	
2017-06-27 22:46:10,892 Epoch[28] Batch [40]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.106990,	
2017-06-27 22:46:14,928 Epoch[28] Batch [50]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.107435,	
2017-06-27 22:46:18,916 Epoch[28] Batch [60]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.108071,	
2017-06-27 22:46:22,943 Epoch[28] Batch [70]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107777,	
2017-06-27 22:46:26,983 Epoch[28] Batch [80]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.108361,	
2017-06-27 22:46:30,980 Epoch[28] Batch [90]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.107992,	
2017-06-27 22:46:35,049 Epoch[28] Batch [100]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.107866,	
2017-06-27 22:46:39,165 Epoch[28] Batch [110]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.107419,	
2017-06-27 22:46:43,258 Epoch[28] Batch [120]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.107214,	
2017-06-27 22:46:47,377 Epoch[28] Batch [130]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.106582,	
2017-06-27 22:46:51,375 Epoch[28] Batch [140]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.106251,	
2017-06-27 22:46:55,484 Epoch[28] Batch [150]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105936,	
2017-06-27 22:46:59,512 Epoch[28] Batch [160]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105751,	
2017-06-27 22:47:03,523 Epoch[28] Batch [170]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.105142,	
2017-06-27 22:47:07,546 Epoch[28] Batch [180]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.105112,	
2017-06-27 22:47:11,595 Epoch[28] Batch [190]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104666,	
2017-06-27 22:47:15,662 Epoch[28] Batch [200]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.104307,	
2017-06-27 22:47:19,785 Epoch[28] Batch [210]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.104398,	
2017-06-27 22:47:23,697 Epoch[28] Batch [220]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.104820,	
2017-06-27 22:47:27,788 Epoch[28] Batch [230]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.105444,	
2017-06-27 22:47:31,859 Epoch[28] Batch [240]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105079,	
2017-06-27 22:47:35,891 Epoch[28] Batch [250]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104794,	
2017-06-27 22:47:40,008 Epoch[28] Batch [260]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.104668,	
2017-06-27 22:47:44,029 Epoch[28] Batch [270]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104580,	
2017-06-27 22:47:48,071 Epoch[28] Batch [280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105287,	
2017-06-27 22:47:52,236 Epoch[28] Batch [290]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.105273,	
2017-06-27 22:47:56,342 Epoch[28] Batch [300]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.104940,	
2017-06-27 22:48:00,544 Epoch[28] Batch [310]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.104871,	
2017-06-27 22:48:04,578 Epoch[28] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104966,	
2017-06-27 22:48:08,659 Epoch[28] Batch [330]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.104696,	
2017-06-27 22:48:12,696 Epoch[28] Batch [340]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104785,	
2017-06-27 22:48:16,781 Epoch[28] Batch [350]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104722,	
2017-06-27 22:48:20,805 Epoch[28] Batch [360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.104501,	
2017-06-27 22:48:24,785 Epoch[28] Batch [370]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.104653,	
2017-06-27 22:48:28,948 Epoch[28] Batch [380]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.104866,	
2017-06-27 22:48:33,083 Epoch[28] Batch [390]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105297,	
2017-06-27 22:48:37,110 Epoch[28] Batch [400]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105699,	
2017-06-27 22:48:41,147 Epoch[28] Batch [410]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105984,	
2017-06-27 22:48:45,206 Epoch[28] Batch [420]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.106421,	
2017-06-27 22:48:49,170 Epoch[28] Batch [430]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.106441,	
2017-06-27 22:48:53,289 Epoch[28] Batch [440]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.106174,	
2017-06-27 22:48:57,307 Epoch[28] Batch [450]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.106182,	
2017-06-27 22:49:01,422 Epoch[28] Batch [460]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.106288,	
2017-06-27 22:49:05,461 Epoch[28] Batch [470]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.106102,	
2017-06-27 22:49:09,405 Epoch[28] Batch [480]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.106064,	
2017-06-27 22:49:13,545 Epoch[28] Batch [490]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.106175,	
2017-06-27 22:49:17,616 Epoch[28] Batch [500]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106130,	
2017-06-27 22:49:21,724 Epoch[28] Batch [510]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.106362,	
2017-06-27 22:49:25,786 Epoch[28] Batch [520]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.106321,	
2017-06-27 22:49:29,802 Epoch[28] Batch [530]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.106386,	
2017-06-27 22:49:34,004 Epoch[28] Batch [540]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.106460,	
2017-06-27 22:49:38,100 Epoch[28] Batch [550]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.106203,	
2017-06-27 22:49:42,149 Epoch[28] Batch [560]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106244,	
2017-06-27 22:49:46,202 Epoch[28] Batch [570]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.106201,	
2017-06-27 22:49:50,222 Epoch[28] Batch [580]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.106071,	
2017-06-27 22:49:54,308 Epoch[28] Batch [590]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105962,	
2017-06-27 22:49:58,293 Epoch[28] Batch [600]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.105908,	
2017-06-27 22:50:02,366 Epoch[28] Batch [610]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.106028,	
2017-06-27 22:50:06,408 Epoch[28] Batch [620]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.106160,	
2017-06-27 22:50:10,347 Epoch[28] Batch [630]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.106150,	
2017-06-27 22:50:14,458 Epoch[28] Batch [640]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.106107,	
2017-06-27 22:50:18,490 Epoch[28] Batch [650]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105962,	
2017-06-27 22:50:22,609 Epoch[28] Batch [660]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.106028,	
2017-06-27 22:50:26,800 Epoch[28] Batch [670]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.106024,	
2017-06-27 22:50:30,998 Epoch[28] Batch [680]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.106023,	
2017-06-27 22:50:35,072 Epoch[28] Batch [690]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105989,	
2017-06-27 22:50:39,175 Epoch[28] Batch [700]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105944,	
2017-06-27 22:50:43,285 Epoch[28] Batch [710]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105880,	
2017-06-27 22:50:47,445 Epoch[28] Batch [720]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.105893,	
2017-06-27 22:50:51,606 Epoch[28] Batch [730]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.105831,	
2017-06-27 22:50:55,787 Epoch[28] Batch [740]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.105776,	
2017-06-27 22:50:59,960 Epoch[28] Batch [750]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.105669,	
2017-06-27 22:51:04,105 Epoch[28] Batch [760]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.105725,	
2017-06-27 22:51:08,119 Epoch[28] Batch [770]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.105560,	
2017-06-27 22:51:12,153 Epoch[28] Batch [780]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105424,	
2017-06-27 22:51:16,290 Epoch[28] Batch [790]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105416,	
2017-06-27 22:51:20,307 Epoch[28] Batch [800]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105479,	
2017-06-27 22:51:24,451 Epoch[28] Batch [810]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.105361,	
2017-06-27 22:51:28,576 Epoch[28] Batch [820]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.105313,	
2017-06-27 22:51:32,727 Epoch[28] Batch [830]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.105227,	
2017-06-27 22:51:36,784 Epoch[28] Batch [840]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.105152,	
2017-06-27 22:51:40,855 Epoch[28] Batch [850]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105296,	
2017-06-27 22:51:44,904 Epoch[28] Batch [860]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105359,	
2017-06-27 22:51:48,912 Epoch[28] Batch [870]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105365,	
2017-06-27 22:51:52,960 Epoch[28] Batch [880]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105346,	
2017-06-27 22:51:57,131 Epoch[28] Batch [890]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.105282,	
2017-06-27 22:52:01,254 Epoch[28] Batch [900]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.105177,	
2017-06-27 22:52:05,349 Epoch[28] Batch [910]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105200,	
2017-06-27 22:52:09,484 Epoch[28] Batch [920]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105310,	
2017-06-27 22:52:13,566 Epoch[28] Batch [930]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105297,	
2017-06-27 22:52:17,576 Epoch[28] Batch [940]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105267,	
2017-06-27 22:52:21,744 Epoch[28] Batch [950]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.105165,	
2017-06-27 22:52:25,741 Epoch[28] Batch [960]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.105070,	
2017-06-27 22:52:29,741 Epoch[28] Batch [970]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105000,	
2017-06-27 22:52:33,840 Epoch[28] Batch [980]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105133,	
2017-06-27 22:52:37,913 Epoch[28] Batch [990]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105200,	
2017-06-27 22:52:41,930 Epoch[28] Batch [1000]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105206,	
2017-06-27 22:52:45,995 Epoch[28] Batch [1010]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105113,	
2017-06-27 22:52:50,048 Epoch[28] Batch [1020]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105061,	
2017-06-27 22:52:54,133 Epoch[28] Batch [1030]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105111,	
2017-06-27 22:52:58,130 Epoch[28] Batch [1040]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.105134,	
2017-06-27 22:53:02,268 Epoch[28] Batch [1050]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105164,	
2017-06-27 22:53:06,298 Epoch[28] Batch [1060]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105194,	
2017-06-27 22:53:10,383 Epoch[28] Batch [1070]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105185,	
2017-06-27 22:53:14,364 Epoch[28] Batch [1080]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.105189,	
2017-06-27 22:53:18,463 Epoch[28] Batch [1090]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105273,	
2017-06-27 22:53:22,556 Epoch[28] Batch [1100]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105264,	
2017-06-27 22:53:26,589 Epoch[28] Batch [1110]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105212,	
2017-06-27 22:53:30,572 Epoch[28] Batch [1120]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.105179,	
2017-06-27 22:53:34,542 Epoch[28] Batch [1130]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.105225,	
2017-06-27 22:53:38,540 Epoch[28] Batch [1140]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.105227,	
2017-06-27 22:53:42,607 Epoch[28] Batch [1150]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105144,	
2017-06-27 22:53:46,592 Epoch[28] Batch [1160]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.105116,	
2017-06-27 22:53:50,708 Epoch[28] Batch [1170]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.105036,	
2017-06-27 22:53:54,721 Epoch[28] Batch [1180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.105013,	
2017-06-27 22:53:58,822 Epoch[28] Batch [1190]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105035,	
2017-06-27 22:54:02,847 Epoch[28] Batch [1200]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.104978,	
2017-06-27 22:54:06,900 Epoch[28] Batch [1210]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105021,	
2017-06-27 22:54:11,055 Epoch[28] Batch [1220]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105064,	
2017-06-27 22:54:15,121 Epoch[28] Batch [1230]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105035,	
2017-06-27 22:54:19,144 Epoch[28] Batch [1240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105038,	
2017-06-27 22:54:23,125 Epoch[28] Batch [1250]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.105164,	
2017-06-27 22:54:27,218 Epoch[28] Batch [1260]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105249,	
2017-06-27 22:54:31,371 Epoch[28] Batch [1270]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105236,	
2017-06-27 22:54:35,336 Epoch[28] Batch [1280]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.105205,	
2017-06-27 22:54:39,399 Epoch[28] Batch [1290]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105289,	
2017-06-27 22:54:43,485 Epoch[28] Batch [1300]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105220,	
2017-06-27 22:54:47,550 Epoch[28] Batch [1310]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105232,	
2017-06-27 22:54:51,527 Epoch[28] Batch [1320]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.105198,	
2017-06-27 22:54:55,573 Epoch[28] Batch [1330]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.105193,	
2017-06-27 22:54:59,639 Epoch[28] Batch [1340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105128,	
2017-06-27 22:55:03,568 Epoch[28] Batch [1350]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105073,	
2017-06-27 22:55:07,652 Epoch[28] Batch [1360]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105114,	
2017-06-27 22:55:11,662 Epoch[28] Batch [1370]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105091,	
2017-06-27 22:55:15,705 Epoch[28] Batch [1380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.105060,	
2017-06-27 22:55:19,803 Epoch[28] Batch [1390]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105084,	
2017-06-27 22:55:23,842 Epoch[28] Batch [1400]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105092,	
2017-06-27 22:55:27,978 Epoch[28] Batch [1410]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105193,	
2017-06-27 22:55:32,071 Epoch[28] Batch [1420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105261,	
2017-06-27 22:55:36,087 Epoch[28] Batch [1430]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105179,	
2017-06-27 22:55:40,112 Epoch[28] Batch [1440]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105107,	
2017-06-27 22:55:44,190 Epoch[28] Batch [1450]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105073,	
2017-06-27 22:55:48,211 Epoch[28] Batch [1460]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.105138,	
2017-06-27 22:55:52,269 Epoch[28] Batch [1470]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.105127,	
2017-06-27 22:55:56,198 Epoch[28] Batch [1480]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105145,	
2017-06-27 22:55:58,672 Epoch[28] Train-FCNLogLoss=0.105137
2017-06-27 22:55:58,673 Epoch[28] Time cost=604.593
2017-06-27 22:55:59,387 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0029.params"
2017-06-27 22:56:00,976 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0029.states"
2017-06-27 22:56:05,657 Epoch[29] Batch [10]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.100429,	
2017-06-27 22:56:09,764 Epoch[29] Batch [20]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.096737,	
2017-06-27 22:56:13,861 Epoch[29] Batch [30]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094653,	
2017-06-27 22:56:17,883 Epoch[29] Batch [40]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097093,	
2017-06-27 22:56:21,995 Epoch[29] Batch [50]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096916,	
2017-06-27 22:56:26,081 Epoch[29] Batch [60]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.097501,	
2017-06-27 22:56:30,115 Epoch[29] Batch [70]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.098051,	
2017-06-27 22:56:34,145 Epoch[29] Batch [80]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100007,	
2017-06-27 22:56:38,196 Epoch[29] Batch [90]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.099893,	
2017-06-27 22:56:42,207 Epoch[29] Batch [100]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101806,	
2017-06-27 22:56:46,346 Epoch[29] Batch [110]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.102363,	
2017-06-27 22:56:50,388 Epoch[29] Batch [120]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.102392,	
2017-06-27 22:56:54,602 Epoch[29] Batch [130]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.102260,	
2017-06-27 22:56:58,620 Epoch[29] Batch [140]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.102373,	
2017-06-27 22:57:02,637 Epoch[29] Batch [150]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.102709,	
2017-06-27 22:57:06,594 Epoch[29] Batch [160]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.103039,	
2017-06-27 22:57:10,598 Epoch[29] Batch [170]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.103081,	
2017-06-27 22:57:14,681 Epoch[29] Batch [180]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103578,	
2017-06-27 22:57:18,766 Epoch[29] Batch [190]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.103926,	
2017-06-27 22:57:22,726 Epoch[29] Batch [200]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.104646,	
2017-06-27 22:57:26,865 Epoch[29] Batch [210]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.104626,	
2017-06-27 22:57:30,895 Epoch[29] Batch [220]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.104832,	
2017-06-27 22:57:34,901 Epoch[29] Batch [230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.104685,	
2017-06-27 22:57:39,053 Epoch[29] Batch [240]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.104649,	
2017-06-27 22:57:43,049 Epoch[29] Batch [250]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.104280,	
2017-06-27 22:57:47,148 Epoch[29] Batch [260]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104323,	
2017-06-27 22:57:51,149 Epoch[29] Batch [270]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.104167,	
2017-06-27 22:57:55,183 Epoch[29] Batch [280]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104158,	
2017-06-27 22:57:59,181 Epoch[29] Batch [290]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.104347,	
2017-06-27 22:58:03,196 Epoch[29] Batch [300]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104271,	
2017-06-27 22:58:07,307 Epoch[29] Batch [310]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.104200,	
2017-06-27 22:58:11,428 Epoch[29] Batch [320]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.103933,	
2017-06-27 22:58:15,460 Epoch[29] Batch [330]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104199,	
2017-06-27 22:58:19,517 Epoch[29] Batch [340]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.104085,	
2017-06-27 22:58:23,505 Epoch[29] Batch [350]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104630,	
2017-06-27 22:58:27,637 Epoch[29] Batch [360]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.104391,	
2017-06-27 22:58:31,791 Epoch[29] Batch [370]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104397,	
2017-06-27 22:58:35,937 Epoch[29] Batch [380]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.104527,	
2017-06-27 22:58:40,119 Epoch[29] Batch [390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.104295,	
2017-06-27 22:58:44,167 Epoch[29] Batch [400]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104232,	
2017-06-27 22:58:48,237 Epoch[29] Batch [410]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104065,	
2017-06-27 22:58:52,272 Epoch[29] Batch [420]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104136,	
2017-06-27 22:58:56,231 Epoch[29] Batch [430]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.104120,	
2017-06-27 22:59:00,349 Epoch[29] Batch [440]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.104180,	
2017-06-27 22:59:04,442 Epoch[29] Batch [450]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.104026,	
2017-06-27 22:59:08,438 Epoch[29] Batch [460]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.103993,	
2017-06-27 22:59:12,481 Epoch[29] Batch [470]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104028,	
2017-06-27 22:59:16,551 Epoch[29] Batch [480]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104012,	
2017-06-27 22:59:20,532 Epoch[29] Batch [490]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.104042,	
2017-06-27 22:59:24,701 Epoch[29] Batch [500]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103970,	
2017-06-27 22:59:28,772 Epoch[29] Batch [510]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104021,	
2017-06-27 22:59:32,850 Epoch[29] Batch [520]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103895,	
2017-06-27 22:59:36,918 Epoch[29] Batch [530]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104062,	
2017-06-27 22:59:40,936 Epoch[29] Batch [540]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104193,	
2017-06-27 22:59:44,991 Epoch[29] Batch [550]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.104372,	
2017-06-27 22:59:49,064 Epoch[29] Batch [560]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104542,	
2017-06-27 22:59:53,168 Epoch[29] Batch [570]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104764,	
2017-06-27 22:59:57,249 Epoch[29] Batch [580]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105062,	
2017-06-27 23:00:01,239 Epoch[29] Batch [590]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105085,	
2017-06-27 23:00:05,318 Epoch[29] Batch [600]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105133,	
2017-06-27 23:00:09,340 Epoch[29] Batch [610]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104917,	
2017-06-27 23:00:13,504 Epoch[29] Batch [620]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.104896,	
2017-06-27 23:00:17,541 Epoch[29] Batch [630]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104801,	
2017-06-27 23:00:21,607 Epoch[29] Batch [640]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.104641,	
2017-06-27 23:00:25,590 Epoch[29] Batch [650]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.104695,	
2017-06-27 23:00:29,640 Epoch[29] Batch [660]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104650,	
2017-06-27 23:00:33,752 Epoch[29] Batch [670]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.104620,	
2017-06-27 23:00:37,768 Epoch[29] Batch [680]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104311,	
2017-06-27 23:00:41,827 Epoch[29] Batch [690]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104231,	
2017-06-27 23:00:45,872 Epoch[29] Batch [700]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104336,	
2017-06-27 23:00:49,966 Epoch[29] Batch [710]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.104408,	
2017-06-27 23:00:53,996 Epoch[29] Batch [720]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.104277,	
2017-06-27 23:00:58,087 Epoch[29] Batch [730]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.104423,	
2017-06-27 23:01:02,196 Epoch[29] Batch [740]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.104380,	
2017-06-27 23:01:06,185 Epoch[29] Batch [750]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104311,	
2017-06-27 23:01:10,260 Epoch[29] Batch [760]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104254,	
2017-06-27 23:01:14,392 Epoch[29] Batch [770]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.104158,	
2017-06-27 23:01:18,278 Epoch[29] Batch [780]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.104131,	
2017-06-27 23:01:22,351 Epoch[29] Batch [790]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104181,	
2017-06-27 23:01:26,317 Epoch[29] Batch [800]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.104202,	
2017-06-27 23:01:30,418 Epoch[29] Batch [810]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104018,	
2017-06-27 23:01:34,381 Epoch[29] Batch [820]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.104021,	
2017-06-27 23:01:38,540 Epoch[29] Batch [830]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104167,	
2017-06-27 23:01:42,548 Epoch[29] Batch [840]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.104180,	
2017-06-27 23:01:46,628 Epoch[29] Batch [850]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.104080,	
2017-06-27 23:01:50,768 Epoch[29] Batch [860]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.104041,	
2017-06-27 23:01:54,837 Epoch[29] Batch [870]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104019,	
2017-06-27 23:01:58,942 Epoch[29] Batch [880]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.104041,	
2017-06-27 23:02:03,034 Epoch[29] Batch [890]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.104124,	
2017-06-27 23:02:07,056 Epoch[29] Batch [900]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104099,	
2017-06-27 23:02:11,128 Epoch[29] Batch [910]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104066,	
2017-06-27 23:02:15,299 Epoch[29] Batch [920]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.104130,	
2017-06-27 23:02:19,248 Epoch[29] Batch [930]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.104136,	
2017-06-27 23:02:23,342 Epoch[29] Batch [940]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.104182,	
2017-06-27 23:02:27,316 Epoch[29] Batch [950]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.104207,	
2017-06-27 23:02:31,334 Epoch[29] Batch [960]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104252,	
2017-06-27 23:02:35,304 Epoch[29] Batch [970]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.104294,	
2017-06-27 23:02:39,278 Epoch[29] Batch [980]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.104270,	
2017-06-27 23:02:43,268 Epoch[29] Batch [990]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104353,	
2017-06-27 23:02:47,224 Epoch[29] Batch [1000]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.104411,	
2017-06-27 23:02:51,241 Epoch[29] Batch [1010]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104543,	
2017-06-27 23:02:55,265 Epoch[29] Batch [1020]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.104532,	
2017-06-27 23:02:59,326 Epoch[29] Batch [1030]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104683,	
2017-06-27 23:03:03,445 Epoch[29] Batch [1040]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.104730,	
2017-06-27 23:03:07,514 Epoch[29] Batch [1050]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104778,	
2017-06-27 23:03:11,529 Epoch[29] Batch [1060]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104718,	
2017-06-27 23:03:15,513 Epoch[29] Batch [1070]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.104735,	
2017-06-27 23:03:19,437 Epoch[29] Batch [1080]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.104611,	
2017-06-27 23:03:23,539 Epoch[29] Batch [1090]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104652,	
2017-06-27 23:03:27,583 Epoch[29] Batch [1100]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104596,	
2017-06-27 23:03:31,640 Epoch[29] Batch [1110]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.104604,	
2017-06-27 23:03:35,708 Epoch[29] Batch [1120]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104604,	
2017-06-27 23:03:39,808 Epoch[29] Batch [1130]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104573,	
2017-06-27 23:03:43,892 Epoch[29] Batch [1140]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104569,	
2017-06-27 23:03:47,966 Epoch[29] Batch [1150]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104544,	
2017-06-27 23:03:51,878 Epoch[29] Batch [1160]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.104490,	
2017-06-27 23:03:55,919 Epoch[29] Batch [1170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104495,	
2017-06-27 23:03:59,871 Epoch[29] Batch [1180]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.104467,	
2017-06-27 23:04:03,837 Epoch[29] Batch [1190]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.104520,	
2017-06-27 23:04:07,923 Epoch[29] Batch [1200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104717,	
2017-06-27 23:04:11,910 Epoch[29] Batch [1210]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104816,	
2017-06-27 23:04:15,954 Epoch[29] Batch [1220]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104951,	
2017-06-27 23:04:19,987 Epoch[29] Batch [1230]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104974,	
2017-06-27 23:04:24,055 Epoch[29] Batch [1240]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105035,	
2017-06-27 23:04:28,182 Epoch[29] Batch [1250]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.105146,	
2017-06-27 23:04:32,236 Epoch[29] Batch [1260]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105165,	
2017-06-27 23:04:36,272 Epoch[29] Batch [1270]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105210,	
2017-06-27 23:04:40,356 Epoch[29] Batch [1280]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105273,	
2017-06-27 23:04:44,390 Epoch[29] Batch [1290]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105290,	
2017-06-27 23:04:48,454 Epoch[29] Batch [1300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105381,	
2017-06-27 23:04:52,652 Epoch[29] Batch [1310]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.105414,	
2017-06-27 23:04:56,736 Epoch[29] Batch [1320]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105519,	
2017-06-27 23:05:00,849 Epoch[29] Batch [1330]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105535,	
2017-06-27 23:05:04,921 Epoch[29] Batch [1340]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105559,	
2017-06-27 23:05:08,994 Epoch[29] Batch [1350]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105721,	
2017-06-27 23:05:13,132 Epoch[29] Batch [1360]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105699,	
2017-06-27 23:05:17,146 Epoch[29] Batch [1370]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.105753,	
2017-06-27 23:05:21,247 Epoch[29] Batch [1380]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105726,	
2017-06-27 23:05:25,299 Epoch[29] Batch [1390]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105726,	
2017-06-27 23:05:29,294 Epoch[29] Batch [1400]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.105766,	
2017-06-27 23:05:33,328 Epoch[29] Batch [1410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105747,	
2017-06-27 23:05:37,352 Epoch[29] Batch [1420]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105629,	
2017-06-27 23:05:41,399 Epoch[29] Batch [1430]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105589,	
2017-06-27 23:05:45,486 Epoch[29] Batch [1440]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.105542,	
2017-06-27 23:05:49,517 Epoch[29] Batch [1450]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105671,	
2017-06-27 23:05:53,513 Epoch[29] Batch [1460]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.105670,	
2017-06-27 23:05:57,581 Epoch[29] Batch [1470]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105596,	
2017-06-27 23:06:01,662 Epoch[29] Batch [1480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105532,	
2017-06-27 23:06:04,081 Epoch[29] Train-FCNLogLoss=0.105521
2017-06-27 23:06:04,081 Epoch[29] Time cost=603.105
2017-06-27 23:06:04,751 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0030.params"
2017-06-27 23:06:06,357 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0030.states"
2017-06-27 23:06:11,088 Epoch[30] Batch [10]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101586,	
2017-06-27 23:06:15,236 Epoch[30] Batch [20]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107211,	
2017-06-27 23:06:19,324 Epoch[30] Batch [30]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110341,	
2017-06-27 23:06:23,404 Epoch[30] Batch [40]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109564,	
2017-06-27 23:06:27,482 Epoch[30] Batch [50]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.108569,	
2017-06-27 23:06:31,438 Epoch[30] Batch [60]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.108153,	
2017-06-27 23:06:35,378 Epoch[30] Batch [70]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.107990,	
2017-06-27 23:06:39,402 Epoch[30] Batch [80]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105598,	
2017-06-27 23:06:43,346 Epoch[30] Batch [90]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.105244,	
2017-06-27 23:06:47,476 Epoch[30] Batch [100]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.104204,	
2017-06-27 23:06:51,496 Epoch[30] Batch [110]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104216,	
2017-06-27 23:06:55,543 Epoch[30] Batch [120]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.103741,	
2017-06-27 23:06:59,633 Epoch[30] Batch [130]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.102476,	
2017-06-27 23:07:03,659 Epoch[30] Batch [140]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.102231,	
2017-06-27 23:07:07,700 Epoch[30] Batch [150]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.101666,	
2017-06-27 23:07:11,651 Epoch[30] Batch [160]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.102187,	
2017-06-27 23:07:15,733 Epoch[30] Batch [170]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.102984,	
2017-06-27 23:07:19,727 Epoch[30] Batch [180]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.102847,	
2017-06-27 23:07:23,837 Epoch[30] Batch [190]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.102976,	
2017-06-27 23:07:27,824 Epoch[30] Batch [200]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.102747,	
2017-06-27 23:07:31,925 Epoch[30] Batch [210]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.102870,	
2017-06-27 23:07:35,972 Epoch[30] Batch [220]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.103001,	
2017-06-27 23:07:39,948 Epoch[30] Batch [230]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.103317,	
2017-06-27 23:07:44,008 Epoch[30] Batch [240]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.103415,	
2017-06-27 23:07:48,109 Epoch[30] Batch [250]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.102999,	
2017-06-27 23:07:52,188 Epoch[30] Batch [260]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.103034,	
2017-06-27 23:07:56,250 Epoch[30] Batch [270]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.103397,	
2017-06-27 23:08:00,331 Epoch[30] Batch [280]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103176,	
2017-06-27 23:08:04,348 Epoch[30] Batch [290]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.103221,	
2017-06-27 23:08:08,391 Epoch[30] Batch [300]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.102999,	
2017-06-27 23:08:12,595 Epoch[30] Batch [310]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.102882,	
2017-06-27 23:08:16,707 Epoch[30] Batch [320]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103043,	
2017-06-27 23:08:20,727 Epoch[30] Batch [330]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103419,	
2017-06-27 23:08:24,820 Epoch[30] Batch [340]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.103526,	
2017-06-27 23:08:28,870 Epoch[30] Batch [350]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.103542,	
2017-06-27 23:08:32,899 Epoch[30] Batch [360]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.103568,	
2017-06-27 23:08:37,016 Epoch[30] Batch [370]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103425,	
2017-06-27 23:08:41,046 Epoch[30] Batch [380]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.103776,	
2017-06-27 23:08:45,061 Epoch[30] Batch [390]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104185,	
2017-06-27 23:08:49,095 Epoch[30] Batch [400]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104049,	
2017-06-27 23:08:53,266 Epoch[30] Batch [410]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.104212,	
2017-06-27 23:08:57,392 Epoch[30] Batch [420]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.104089,	
2017-06-27 23:09:01,460 Epoch[30] Batch [430]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104046,	
2017-06-27 23:09:05,548 Epoch[30] Batch [440]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104128,	
2017-06-27 23:09:09,585 Epoch[30] Batch [450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103924,	
2017-06-27 23:09:13,538 Epoch[30] Batch [460]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.104024,	
2017-06-27 23:09:17,624 Epoch[30] Batch [470]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.103974,	
2017-06-27 23:09:21,758 Epoch[30] Batch [480]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.104104,	
2017-06-27 23:09:25,830 Epoch[30] Batch [490]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.103948,	
2017-06-27 23:09:29,860 Epoch[30] Batch [500]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103670,	
2017-06-27 23:09:33,936 Epoch[30] Batch [510]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.103848,	
2017-06-27 23:09:37,957 Epoch[30] Batch [520]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103852,	
2017-06-27 23:09:41,979 Epoch[30] Batch [530]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103921,	
2017-06-27 23:09:46,037 Epoch[30] Batch [540]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.103898,	
2017-06-27 23:09:50,022 Epoch[30] Batch [550]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.103874,	
2017-06-27 23:09:54,046 Epoch[30] Batch [560]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.103880,	
2017-06-27 23:09:58,201 Epoch[30] Batch [570]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.103819,	
2017-06-27 23:10:02,431 Epoch[30] Batch [580]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.103800,	
2017-06-27 23:10:06,460 Epoch[30] Batch [590]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.104001,	
2017-06-27 23:10:10,551 Epoch[30] Batch [600]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.104090,	
2017-06-27 23:10:14,651 Epoch[30] Batch [610]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104128,	
2017-06-27 23:10:18,701 Epoch[30] Batch [620]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104040,	
2017-06-27 23:10:22,704 Epoch[30] Batch [630]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.104219,	
2017-06-27 23:10:26,810 Epoch[30] Batch [640]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.104186,	
2017-06-27 23:10:30,907 Epoch[30] Batch [650]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104264,	
2017-06-27 23:10:34,947 Epoch[30] Batch [660]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104248,	
2017-06-27 23:10:39,063 Epoch[30] Batch [670]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.104161,	
2017-06-27 23:10:43,052 Epoch[30] Batch [680]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104227,	
2017-06-27 23:10:47,151 Epoch[30] Batch [690]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104385,	
2017-06-27 23:10:51,187 Epoch[30] Batch [700]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104392,	
2017-06-27 23:10:55,199 Epoch[30] Batch [710]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.104343,	
2017-06-27 23:10:59,311 Epoch[30] Batch [720]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.104229,	
2017-06-27 23:11:03,423 Epoch[30] Batch [730]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.104341,	
2017-06-27 23:11:07,459 Epoch[30] Batch [740]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104256,	
2017-06-27 23:11:11,535 Epoch[30] Batch [750]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.104244,	
2017-06-27 23:11:15,589 Epoch[30] Batch [760]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104155,	
2017-06-27 23:11:19,755 Epoch[30] Batch [770]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.104233,	
2017-06-27 23:11:23,849 Epoch[30] Batch [780]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.104222,	
2017-06-27 23:11:27,938 Epoch[30] Batch [790]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.104128,	
2017-06-27 23:11:31,901 Epoch[30] Batch [800]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.104067,	
2017-06-27 23:11:35,853 Epoch[30] Batch [810]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.104075,	
2017-06-27 23:11:39,908 Epoch[30] Batch [820]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104071,	
2017-06-27 23:11:43,960 Epoch[30] Batch [830]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.103997,	
2017-06-27 23:11:48,085 Epoch[30] Batch [840]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.103868,	
2017-06-27 23:11:52,221 Epoch[30] Batch [850]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103795,	
2017-06-27 23:11:56,257 Epoch[30] Batch [860]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103790,	
2017-06-27 23:12:00,314 Epoch[30] Batch [870]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.103621,	
2017-06-27 23:12:04,333 Epoch[30] Batch [880]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103498,	
2017-06-27 23:12:08,433 Epoch[30] Batch [890]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.103462,	
2017-06-27 23:12:12,559 Epoch[30] Batch [900]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.103509,	
2017-06-27 23:12:16,740 Epoch[30] Batch [910]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103516,	
2017-06-27 23:12:20,920 Epoch[30] Batch [920]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103515,	
2017-06-27 23:12:24,968 Epoch[30] Batch [930]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.103467,	
2017-06-27 23:12:29,033 Epoch[30] Batch [940]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.103474,	
2017-06-27 23:12:33,013 Epoch[30] Batch [950]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.103305,	
2017-06-27 23:12:37,143 Epoch[30] Batch [960]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103253,	
2017-06-27 23:12:41,264 Epoch[30] Batch [970]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.103227,	
2017-06-27 23:12:45,264 Epoch[30] Batch [980]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.103286,	
2017-06-27 23:12:49,338 Epoch[30] Batch [990]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.103353,	
2017-06-27 23:12:53,467 Epoch[30] Batch [1000]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.103420,	
2017-06-27 23:12:57,600 Epoch[30] Batch [1010]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103428,	
2017-06-27 23:13:01,637 Epoch[30] Batch [1020]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.103453,	
2017-06-27 23:13:05,633 Epoch[30] Batch [1030]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.103418,	
2017-06-27 23:13:09,798 Epoch[30] Batch [1040]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.103429,	
2017-06-27 23:13:13,898 Epoch[30] Batch [1050]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.103414,	
2017-06-27 23:13:17,990 Epoch[30] Batch [1060]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.103396,	
2017-06-27 23:13:22,127 Epoch[30] Batch [1070]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.103350,	
2017-06-27 23:13:26,221 Epoch[30] Batch [1080]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.103280,	
2017-06-27 23:13:30,319 Epoch[30] Batch [1090]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.103388,	
2017-06-27 23:13:34,385 Epoch[30] Batch [1100]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.103458,	
2017-06-27 23:13:38,501 Epoch[30] Batch [1110]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103435,	
2017-06-27 23:13:42,431 Epoch[30] Batch [1120]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.103406,	
2017-06-27 23:13:46,524 Epoch[30] Batch [1130]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.103429,	
2017-06-27 23:13:50,564 Epoch[30] Batch [1140]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.103420,	
2017-06-27 23:13:54,678 Epoch[30] Batch [1150]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103341,	
2017-06-27 23:13:58,785 Epoch[30] Batch [1160]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103490,	
2017-06-27 23:14:02,815 Epoch[30] Batch [1170]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.103498,	
2017-06-27 23:14:06,931 Epoch[30] Batch [1180]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.103459,	
2017-06-27 23:14:11,054 Epoch[30] Batch [1190]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.103499,	
2017-06-27 23:14:15,136 Epoch[30] Batch [1200]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103448,	
2017-06-27 23:14:19,091 Epoch[30] Batch [1210]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.103505,	
2017-06-27 23:14:23,203 Epoch[30] Batch [1220]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103387,	
2017-06-27 23:14:27,337 Epoch[30] Batch [1230]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103439,	
2017-06-27 23:14:31,351 Epoch[30] Batch [1240]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.103344,	
2017-06-27 23:14:35,355 Epoch[30] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.103316,	
2017-06-27 23:14:39,283 Epoch[30] Batch [1260]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.103316,	
2017-06-27 23:14:43,312 Epoch[30] Batch [1270]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.103358,	
2017-06-27 23:14:47,323 Epoch[30] Batch [1280]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.103317,	
2017-06-27 23:14:51,471 Epoch[30] Batch [1290]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.103305,	
2017-06-27 23:14:55,437 Epoch[30] Batch [1300]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.103389,	
2017-06-27 23:14:59,471 Epoch[30] Batch [1310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103401,	
2017-06-27 23:15:03,502 Epoch[30] Batch [1320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103496,	
2017-06-27 23:15:07,654 Epoch[30] Batch [1330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.103482,	
2017-06-27 23:15:11,704 Epoch[30] Batch [1340]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.103450,	
2017-06-27 23:15:15,724 Epoch[30] Batch [1350]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103401,	
2017-06-27 23:15:19,810 Epoch[30] Batch [1360]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.103369,	
2017-06-27 23:15:23,825 Epoch[30] Batch [1370]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.103289,	
2017-06-27 23:15:27,828 Epoch[30] Batch [1380]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.103257,	
2017-06-27 23:15:31,873 Epoch[30] Batch [1390]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.103234,	
2017-06-27 23:15:35,848 Epoch[30] Batch [1400]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.103190,	
2017-06-27 23:15:39,979 Epoch[30] Batch [1410]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103196,	
2017-06-27 23:15:43,882 Epoch[30] Batch [1420]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.103379,	
2017-06-27 23:15:47,977 Epoch[30] Batch [1430]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.103343,	
2017-06-27 23:15:52,040 Epoch[30] Batch [1440]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.103291,	
2017-06-27 23:15:56,107 Epoch[30] Batch [1450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.103342,	
2017-06-27 23:16:00,104 Epoch[30] Batch [1460]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.103335,	
2017-06-27 23:16:04,042 Epoch[30] Batch [1470]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.103358,	
2017-06-27 23:16:08,094 Epoch[30] Batch [1480]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.103397,	
2017-06-27 23:16:10,511 Epoch[30] Train-FCNLogLoss=0.103381
2017-06-27 23:16:10,511 Epoch[30] Time cost=604.153
2017-06-27 23:16:11,259 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0031.params"
2017-06-27 23:16:12,965 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0031.states"
2017-06-27 23:16:17,717 Epoch[31] Batch [10]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.112347,	
2017-06-27 23:16:21,801 Epoch[31] Batch [20]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103973,	
2017-06-27 23:16:25,789 Epoch[31] Batch [30]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.106409,	
2017-06-27 23:16:29,761 Epoch[31] Batch [40]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.102578,	
2017-06-27 23:16:33,864 Epoch[31] Batch [50]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104821,	
2017-06-27 23:16:37,921 Epoch[31] Batch [60]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.102741,	
2017-06-27 23:16:41,878 Epoch[31] Batch [70]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.100938,	
2017-06-27 23:16:45,941 Epoch[31] Batch [80]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.099944,	
2017-06-27 23:16:49,945 Epoch[31] Batch [90]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.100343,	
2017-06-27 23:16:54,008 Epoch[31] Batch [100]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.100081,	
2017-06-27 23:16:58,066 Epoch[31] Batch [110]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100632,	
2017-06-27 23:17:02,129 Epoch[31] Batch [120]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100525,	
2017-06-27 23:17:06,273 Epoch[31] Batch [130]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.100393,	
2017-06-27 23:17:10,297 Epoch[31] Batch [140]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100627,	
2017-06-27 23:17:14,264 Epoch[31] Batch [150]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.101201,	
2017-06-27 23:17:18,303 Epoch[31] Batch [160]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.100753,	
2017-06-27 23:17:22,323 Epoch[31] Batch [170]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.101518,	
2017-06-27 23:17:26,283 Epoch[31] Batch [180]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.101613,	
2017-06-27 23:17:30,314 Epoch[31] Batch [190]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.102071,	
2017-06-27 23:17:34,423 Epoch[31] Batch [200]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.102203,	
2017-06-27 23:17:38,502 Epoch[31] Batch [210]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101949,	
2017-06-27 23:17:42,487 Epoch[31] Batch [220]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.101609,	
2017-06-27 23:17:46,558 Epoch[31] Batch [230]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101352,	
2017-06-27 23:17:50,500 Epoch[31] Batch [240]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.101482,	
2017-06-27 23:17:54,609 Epoch[31] Batch [250]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.102267,	
2017-06-27 23:17:58,690 Epoch[31] Batch [260]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.102027,	
2017-06-27 23:18:02,765 Epoch[31] Batch [270]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101856,	
2017-06-27 23:18:06,774 Epoch[31] Batch [280]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.101978,	
2017-06-27 23:18:10,806 Epoch[31] Batch [290]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.102122,	
2017-06-27 23:18:14,894 Epoch[31] Batch [300]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101922,	
2017-06-27 23:18:18,974 Epoch[31] Batch [310]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101465,	
2017-06-27 23:18:23,016 Epoch[31] Batch [320]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.101536,	
2017-06-27 23:18:27,040 Epoch[31] Batch [330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.101179,	
2017-06-27 23:18:31,121 Epoch[31] Batch [340]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101048,	
2017-06-27 23:18:35,181 Epoch[31] Batch [350]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101110,	
2017-06-27 23:18:39,229 Epoch[31] Batch [360]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101206,	
2017-06-27 23:18:43,279 Epoch[31] Batch [370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101504,	
2017-06-27 23:18:47,369 Epoch[31] Batch [380]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101651,	
2017-06-27 23:18:51,407 Epoch[31] Batch [390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101353,	
2017-06-27 23:18:55,407 Epoch[31] Batch [400]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.101866,	
2017-06-27 23:18:59,468 Epoch[31] Batch [410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101772,	
2017-06-27 23:19:03,532 Epoch[31] Batch [420]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.101624,	
2017-06-27 23:19:07,470 Epoch[31] Batch [430]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.101768,	
2017-06-27 23:19:11,449 Epoch[31] Batch [440]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.101705,	
2017-06-27 23:19:15,523 Epoch[31] Batch [450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101798,	
2017-06-27 23:19:19,553 Epoch[31] Batch [460]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101948,	
2017-06-27 23:19:23,605 Epoch[31] Batch [470]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.101900,	
2017-06-27 23:19:27,685 Epoch[31] Batch [480]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101889,	
2017-06-27 23:19:31,659 Epoch[31] Batch [490]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.101965,	
2017-06-27 23:19:35,731 Epoch[31] Batch [500]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.102015,	
2017-06-27 23:19:39,883 Epoch[31] Batch [510]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.102127,	
2017-06-27 23:19:43,953 Epoch[31] Batch [520]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101828,	
2017-06-27 23:19:47,918 Epoch[31] Batch [530]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.101981,	
2017-06-27 23:19:52,093 Epoch[31] Batch [540]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.102019,	
2017-06-27 23:19:56,224 Epoch[31] Batch [550]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.102105,	
2017-06-27 23:20:00,194 Epoch[31] Batch [560]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.101943,	
2017-06-27 23:20:04,225 Epoch[31] Batch [570]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101956,	
2017-06-27 23:20:08,344 Epoch[31] Batch [580]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.102212,	
2017-06-27 23:20:12,449 Epoch[31] Batch [590]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.102177,	
2017-06-27 23:20:16,504 Epoch[31] Batch [600]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.102047,	
2017-06-27 23:20:20,544 Epoch[31] Batch [610]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.101982,	
2017-06-27 23:20:24,673 Epoch[31] Batch [620]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.102038,	
2017-06-27 23:20:28,757 Epoch[31] Batch [630]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101915,	
2017-06-27 23:20:32,806 Epoch[31] Batch [640]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101990,	
2017-06-27 23:20:36,761 Epoch[31] Batch [650]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.101888,	
2017-06-27 23:20:40,776 Epoch[31] Batch [660]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101895,	
2017-06-27 23:20:44,834 Epoch[31] Batch [670]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101838,	
2017-06-27 23:20:48,923 Epoch[31] Batch [680]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101635,	
2017-06-27 23:20:52,900 Epoch[31] Batch [690]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.101613,	
2017-06-27 23:20:56,930 Epoch[31] Batch [700]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.101539,	
2017-06-27 23:21:00,987 Epoch[31] Batch [710]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101489,	
2017-06-27 23:21:04,979 Epoch[31] Batch [720]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.101492,	
2017-06-27 23:21:09,073 Epoch[31] Batch [730]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101541,	
2017-06-27 23:21:13,107 Epoch[31] Batch [740]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101484,	
2017-06-27 23:21:17,227 Epoch[31] Batch [750]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.101449,	
2017-06-27 23:21:21,254 Epoch[31] Batch [760]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.101324,	
2017-06-27 23:21:25,463 Epoch[31] Batch [770]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.101306,	
2017-06-27 23:21:29,686 Epoch[31] Batch [780]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.101309,	
2017-06-27 23:21:33,788 Epoch[31] Batch [790]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.101346,	
2017-06-27 23:21:37,823 Epoch[31] Batch [800]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101295,	
2017-06-27 23:21:41,768 Epoch[31] Batch [810]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.101241,	
2017-06-27 23:21:45,757 Epoch[31] Batch [820]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.101096,	
2017-06-27 23:21:49,843 Epoch[31] Batch [830]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100978,	
2017-06-27 23:21:53,983 Epoch[31] Batch [840]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.101088,	
2017-06-27 23:21:57,984 Epoch[31] Batch [850]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.101046,	
2017-06-27 23:22:02,010 Epoch[31] Batch [860]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100913,	
2017-06-27 23:22:06,062 Epoch[31] Batch [870]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.100926,	
2017-06-27 23:22:10,158 Epoch[31] Batch [880]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101021,	
2017-06-27 23:22:14,220 Epoch[31] Batch [890]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100995,	
2017-06-27 23:22:18,350 Epoch[31] Batch [900]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.101026,	
2017-06-27 23:22:22,415 Epoch[31] Batch [910]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.100980,	
2017-06-27 23:22:26,494 Epoch[31] Batch [920]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.100925,	
2017-06-27 23:22:30,527 Epoch[31] Batch [930]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100919,	
2017-06-27 23:22:34,539 Epoch[31] Batch [940]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.100841,	
2017-06-27 23:22:38,642 Epoch[31] Batch [950]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.100938,	
2017-06-27 23:22:42,677 Epoch[31] Batch [960]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101089,	
2017-06-27 23:22:46,694 Epoch[31] Batch [970]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.100942,	
2017-06-27 23:22:50,756 Epoch[31] Batch [980]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100902,	
2017-06-27 23:22:54,768 Epoch[31] Batch [990]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.100992,	
2017-06-27 23:22:58,851 Epoch[31] Batch [1000]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101077,	
2017-06-27 23:23:02,887 Epoch[31] Batch [1010]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101140,	
2017-06-27 23:23:07,019 Epoch[31] Batch [1020]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.101160,	
2017-06-27 23:23:11,090 Epoch[31] Batch [1030]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101265,	
2017-06-27 23:23:15,142 Epoch[31] Batch [1040]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.101250,	
2017-06-27 23:23:19,295 Epoch[31] Batch [1050]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101342,	
2017-06-27 23:23:23,400 Epoch[31] Batch [1060]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.101280,	
2017-06-27 23:23:27,409 Epoch[31] Batch [1070]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.102796,	
2017-06-27 23:23:31,482 Epoch[31] Batch [1080]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104575,	
2017-06-27 23:23:35,494 Epoch[31] Batch [1090]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.106446,	
2017-06-27 23:23:39,521 Epoch[31] Batch [1100]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107650,	
2017-06-27 23:23:43,610 Epoch[31] Batch [1110]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.108357,	
2017-06-27 23:23:47,616 Epoch[31] Batch [1120]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109622,	
2017-06-27 23:23:51,657 Epoch[31] Batch [1130]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110393,	
2017-06-27 23:23:55,678 Epoch[31] Batch [1140]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110879,	
2017-06-27 23:23:59,728 Epoch[31] Batch [1150]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.111279,	
2017-06-27 23:24:03,808 Epoch[31] Batch [1160]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111738,	
2017-06-27 23:24:07,881 Epoch[31] Batch [1170]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112119,	
2017-06-27 23:24:11,915 Epoch[31] Batch [1180]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112358,	
2017-06-27 23:24:15,862 Epoch[31] Batch [1190]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.113095,	
2017-06-27 23:24:19,789 Epoch[31] Batch [1200]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.113349,	
2017-06-27 23:24:23,724 Epoch[31] Batch [1210]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.113667,	
2017-06-27 23:24:27,717 Epoch[31] Batch [1220]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.113883,	
2017-06-27 23:24:31,720 Epoch[31] Batch [1230]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.114260,	
2017-06-27 23:24:35,824 Epoch[31] Batch [1240]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.114648,	
2017-06-27 23:24:39,891 Epoch[31] Batch [1250]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.114930,	
2017-06-27 23:24:43,826 Epoch[31] Batch [1260]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.115182,	
2017-06-27 23:24:47,825 Epoch[31] Batch [1270]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.115704,	
2017-06-27 23:24:51,894 Epoch[31] Batch [1280]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116048,	
2017-06-27 23:24:55,945 Epoch[31] Batch [1290]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.116174,	
2017-06-27 23:24:59,928 Epoch[31] Batch [1300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116331,	
2017-06-27 23:25:04,018 Epoch[31] Batch [1310]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116399,	
2017-06-27 23:25:08,196 Epoch[31] Batch [1320]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.116508,	
2017-06-27 23:25:12,195 Epoch[31] Batch [1330]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.116633,	
2017-06-27 23:25:16,310 Epoch[31] Batch [1340]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.116954,	
2017-06-27 23:25:20,477 Epoch[31] Batch [1350]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.117484,	
2017-06-27 23:25:24,485 Epoch[31] Batch [1360]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.118005,	
2017-06-27 23:25:28,481 Epoch[31] Batch [1370]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118181,	
2017-06-27 23:25:32,567 Epoch[31] Batch [1380]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.118463,	
2017-06-27 23:25:36,641 Epoch[31] Batch [1390]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.118598,	
2017-06-27 23:25:40,699 Epoch[31] Batch [1400]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.118661,	
2017-06-27 23:25:44,712 Epoch[31] Batch [1410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.118770,	
2017-06-27 23:25:48,724 Epoch[31] Batch [1420]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.118812,	
2017-06-27 23:25:52,925 Epoch[31] Batch [1430]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.118809,	
2017-06-27 23:25:57,046 Epoch[31] Batch [1440]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.118858,	
2017-06-27 23:26:01,157 Epoch[31] Batch [1450]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.118891,	
2017-06-27 23:26:05,198 Epoch[31] Batch [1460]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118871,	
2017-06-27 23:26:09,318 Epoch[31] Batch [1470]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.118915,	
2017-06-27 23:26:13,460 Epoch[31] Batch [1480]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.118973,	
2017-06-27 23:26:15,865 Epoch[31] Train-FCNLogLoss=0.118944
2017-06-27 23:26:15,865 Epoch[31] Time cost=602.899
2017-06-27 23:26:16,548 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0032.params"
2017-06-27 23:26:18,202 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0032.states"
2017-06-27 23:26:23,019 Epoch[32] Batch [10]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.110655,	
2017-06-27 23:26:27,110 Epoch[32] Batch [20]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.123251,	
2017-06-27 23:26:31,235 Epoch[32] Batch [30]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.119213,	
2017-06-27 23:26:35,212 Epoch[32] Batch [40]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.118992,	
2017-06-27 23:26:39,212 Epoch[32] Batch [50]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.114443,	
2017-06-27 23:26:43,273 Epoch[32] Batch [60]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113884,	
2017-06-27 23:26:47,469 Epoch[32] Batch [70]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.116325,	
2017-06-27 23:26:51,646 Epoch[32] Batch [80]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.115788,	
2017-06-27 23:26:55,707 Epoch[32] Batch [90]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117700,	
2017-06-27 23:26:59,816 Epoch[32] Batch [100]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117000,	
2017-06-27 23:27:03,883 Epoch[32] Batch [110]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115920,	
2017-06-27 23:27:07,923 Epoch[32] Batch [120]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.116191,	
2017-06-27 23:27:12,028 Epoch[32] Batch [130]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.116620,	
2017-06-27 23:27:16,116 Epoch[32] Batch [140]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116778,	
2017-06-27 23:27:20,151 Epoch[32] Batch [150]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.116126,	
2017-06-27 23:27:24,199 Epoch[32] Batch [160]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.116409,	
2017-06-27 23:27:28,282 Epoch[32] Batch [170]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116323,	
2017-06-27 23:27:32,260 Epoch[32] Batch [180]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.115760,	
2017-06-27 23:27:36,420 Epoch[32] Batch [190]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.117110,	
2017-06-27 23:27:40,485 Epoch[32] Batch [200]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.118505,	
2017-06-27 23:27:44,435 Epoch[32] Batch [210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.121424,	
2017-06-27 23:27:48,449 Epoch[32] Batch [220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.122227,	
2017-06-27 23:27:52,504 Epoch[32] Batch [230]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.122958,	
2017-06-27 23:27:56,520 Epoch[32] Batch [240]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.122804,	
2017-06-27 23:28:00,568 Epoch[32] Batch [250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.122520,	
2017-06-27 23:28:04,603 Epoch[32] Batch [260]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.122271,	
2017-06-27 23:28:08,694 Epoch[32] Batch [270]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.122080,	
2017-06-27 23:28:12,730 Epoch[32] Batch [280]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.121444,	
2017-06-27 23:28:16,777 Epoch[32] Batch [290]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.121318,	
2017-06-27 23:28:20,764 Epoch[32] Batch [300]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.121148,	
2017-06-27 23:28:24,790 Epoch[32] Batch [310]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.121150,	
2017-06-27 23:28:28,884 Epoch[32] Batch [320]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.121220,	
2017-06-27 23:28:33,039 Epoch[32] Batch [330]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.121155,	
2017-06-27 23:28:37,186 Epoch[32] Batch [340]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.120795,	
2017-06-27 23:28:41,176 Epoch[32] Batch [350]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.120886,	
2017-06-27 23:28:45,225 Epoch[32] Batch [360]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.120813,	
2017-06-27 23:28:49,223 Epoch[32] Batch [370]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.120987,	
2017-06-27 23:28:53,267 Epoch[32] Batch [380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.120578,	
2017-06-27 23:28:57,154 Epoch[32] Batch [390]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.120371,	
2017-06-27 23:29:01,228 Epoch[32] Batch [400]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.120128,	
2017-06-27 23:29:05,272 Epoch[32] Batch [410]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.119703,	
2017-06-27 23:29:09,357 Epoch[32] Batch [420]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.119268,	
2017-06-27 23:29:13,436 Epoch[32] Batch [430]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118988,	
2017-06-27 23:29:17,568 Epoch[32] Batch [440]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.118538,	
2017-06-27 23:29:21,616 Epoch[32] Batch [450]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117903,	
2017-06-27 23:29:25,667 Epoch[32] Batch [460]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.117799,	
2017-06-27 23:29:29,691 Epoch[32] Batch [470]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117780,	
2017-06-27 23:29:33,657 Epoch[32] Batch [480]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.117532,	
2017-06-27 23:29:37,765 Epoch[32] Batch [490]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117366,	
2017-06-27 23:29:41,893 Epoch[32] Batch [500]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.117340,	
2017-06-27 23:29:45,929 Epoch[32] Batch [510]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117704,	
2017-06-27 23:29:49,952 Epoch[32] Batch [520]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117790,	
2017-06-27 23:29:53,989 Epoch[32] Batch [530]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117862,	
2017-06-27 23:29:57,963 Epoch[32] Batch [540]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.117671,	
2017-06-27 23:30:02,029 Epoch[32] Batch [550]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117514,	
2017-06-27 23:30:06,031 Epoch[32] Batch [560]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.117345,	
2017-06-27 23:30:10,028 Epoch[32] Batch [570]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.117309,	
2017-06-27 23:30:14,056 Epoch[32] Batch [580]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117098,	
2017-06-27 23:30:18,070 Epoch[32] Batch [590]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.117098,	
2017-06-27 23:30:22,081 Epoch[32] Batch [600]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116833,	
2017-06-27 23:30:26,141 Epoch[32] Batch [610]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116943,	
2017-06-27 23:30:30,215 Epoch[32] Batch [620]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.116994,	
2017-06-27 23:30:34,312 Epoch[32] Batch [630]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117155,	
2017-06-27 23:30:38,331 Epoch[32] Batch [640]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.117232,	
2017-06-27 23:30:42,378 Epoch[32] Batch [650]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117982,	
2017-06-27 23:30:46,522 Epoch[32] Batch [660]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.117883,	
2017-06-27 23:30:50,431 Epoch[32] Batch [670]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.118086,	
2017-06-27 23:30:54,525 Epoch[32] Batch [680]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117959,	
2017-06-27 23:30:58,638 Epoch[32] Batch [690]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.117690,	
2017-06-27 23:31:02,687 Epoch[32] Batch [700]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117821,	
2017-06-27 23:31:06,818 Epoch[32] Batch [710]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.117717,	
2017-06-27 23:31:10,899 Epoch[32] Batch [720]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117927,	
2017-06-27 23:31:14,993 Epoch[32] Batch [730]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.118095,	
2017-06-27 23:31:19,224 Epoch[32] Batch [740]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.118204,	
2017-06-27 23:31:23,315 Epoch[32] Batch [750]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.117945,	
2017-06-27 23:31:27,352 Epoch[32] Batch [760]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117947,	
2017-06-27 23:31:31,332 Epoch[32] Batch [770]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117949,	
2017-06-27 23:31:35,380 Epoch[32] Batch [780]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117672,	
2017-06-27 23:31:39,471 Epoch[32] Batch [790]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.117532,	
2017-06-27 23:31:43,482 Epoch[32] Batch [800]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.117514,	
2017-06-27 23:31:47,543 Epoch[32] Batch [810]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117490,	
2017-06-27 23:31:51,541 Epoch[32] Batch [820]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.117406,	
2017-06-27 23:31:55,574 Epoch[32] Batch [830]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.117287,	
2017-06-27 23:31:59,531 Epoch[32] Batch [840]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.117174,	
2017-06-27 23:32:03,545 Epoch[32] Batch [850]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117004,	
2017-06-27 23:32:07,597 Epoch[32] Batch [860]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.116914,	
2017-06-27 23:32:11,698 Epoch[32] Batch [870]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.116660,	
2017-06-27 23:32:15,741 Epoch[32] Batch [880]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116506,	
2017-06-27 23:32:19,850 Epoch[32] Batch [890]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.116373,	
2017-06-27 23:32:23,851 Epoch[32] Batch [900]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116183,	
2017-06-27 23:32:27,895 Epoch[32] Batch [910]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116016,	
2017-06-27 23:32:31,884 Epoch[32] Batch [920]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.115973,	
2017-06-27 23:32:35,960 Epoch[32] Batch [930]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115839,	
2017-06-27 23:32:39,985 Epoch[32] Batch [940]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.115720,	
2017-06-27 23:32:43,977 Epoch[32] Batch [950]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.115914,	
2017-06-27 23:32:48,009 Epoch[32] Batch [960]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115964,	
2017-06-27 23:32:52,101 Epoch[32] Batch [970]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116022,	
2017-06-27 23:32:56,183 Epoch[32] Batch [980]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.115921,	
2017-06-27 23:33:00,184 Epoch[32] Batch [990]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.115849,	
2017-06-27 23:33:04,210 Epoch[32] Batch [1000]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.115745,	
2017-06-27 23:33:08,235 Epoch[32] Batch [1010]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.115728,	
2017-06-27 23:33:12,264 Epoch[32] Batch [1020]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.115633,	
2017-06-27 23:33:16,262 Epoch[32] Batch [1030]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.115606,	
2017-06-27 23:33:20,240 Epoch[32] Batch [1040]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.115628,	
2017-06-27 23:33:24,261 Epoch[32] Batch [1050]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115505,	
2017-06-27 23:33:28,296 Epoch[32] Batch [1060]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.115448,	
2017-06-27 23:33:32,382 Epoch[32] Batch [1070]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115345,	
2017-06-27 23:33:36,453 Epoch[32] Batch [1080]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115308,	
2017-06-27 23:33:40,478 Epoch[32] Batch [1090]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.115209,	
2017-06-27 23:33:44,544 Epoch[32] Batch [1100]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115197,	
2017-06-27 23:33:48,563 Epoch[32] Batch [1110]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115168,	
2017-06-27 23:33:52,656 Epoch[32] Batch [1120]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.115034,	
2017-06-27 23:33:56,669 Epoch[32] Batch [1130]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.115035,	
2017-06-27 23:34:00,819 Epoch[32] Batch [1140]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.114995,	
2017-06-27 23:34:04,863 Epoch[32] Batch [1150]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.114954,	
2017-06-27 23:34:08,946 Epoch[32] Batch [1160]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114811,	
2017-06-27 23:34:12,944 Epoch[32] Batch [1170]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.114594,	
2017-06-27 23:34:16,937 Epoch[32] Batch [1180]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.114451,	
2017-06-27 23:34:21,029 Epoch[32] Batch [1190]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114361,	
2017-06-27 23:34:25,120 Epoch[32] Batch [1200]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114276,	
2017-06-27 23:34:29,138 Epoch[32] Batch [1210]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.114245,	
2017-06-27 23:34:33,217 Epoch[32] Batch [1220]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.114257,	
2017-06-27 23:34:37,379 Epoch[32] Batch [1230]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.114215,	
2017-06-27 23:34:41,470 Epoch[32] Batch [1240]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114187,	
2017-06-27 23:34:45,539 Epoch[32] Batch [1250]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.114137,	
2017-06-27 23:34:49,611 Epoch[32] Batch [1260]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114104,	
2017-06-27 23:34:53,701 Epoch[32] Batch [1270]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114073,	
2017-06-27 23:34:57,720 Epoch[32] Batch [1280]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113971,	
2017-06-27 23:35:01,718 Epoch[32] Batch [1290]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.113782,	
2017-06-27 23:35:05,753 Epoch[32] Batch [1300]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.113685,	
2017-06-27 23:35:09,894 Epoch[32] Batch [1310]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.113592,	
2017-06-27 23:35:14,032 Epoch[32] Batch [1320]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113511,	
2017-06-27 23:35:18,114 Epoch[32] Batch [1330]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.113509,	
2017-06-27 23:35:22,193 Epoch[32] Batch [1340]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113575,	
2017-06-27 23:35:26,125 Epoch[32] Batch [1350]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.113493,	
2017-06-27 23:35:30,176 Epoch[32] Batch [1360]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113412,	
2017-06-27 23:35:34,278 Epoch[32] Batch [1370]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.113358,	
2017-06-27 23:35:38,372 Epoch[32] Batch [1380]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113290,	
2017-06-27 23:35:42,310 Epoch[32] Batch [1390]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.113146,	
2017-06-27 23:35:46,275 Epoch[32] Batch [1400]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.113137,	
2017-06-27 23:35:50,285 Epoch[32] Batch [1410]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113082,	
2017-06-27 23:35:54,304 Epoch[32] Batch [1420]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113079,	
2017-06-27 23:35:58,377 Epoch[32] Batch [1430]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112991,	
2017-06-27 23:36:02,374 Epoch[32] Batch [1440]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.112919,	
2017-06-27 23:36:06,411 Epoch[32] Batch [1450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.112903,	
2017-06-27 23:36:10,361 Epoch[32] Batch [1460]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.112866,	
2017-06-27 23:36:14,364 Epoch[32] Batch [1470]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.112822,	
2017-06-27 23:36:18,408 Epoch[32] Batch [1480]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112797,	
2017-06-27 23:36:20,919 Epoch[32] Train-FCNLogLoss=0.112706
2017-06-27 23:36:20,920 Epoch[32] Time cost=602.717
2017-06-27 23:36:21,634 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0033.params"
2017-06-27 23:36:23,224 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0033.states"
2017-06-27 23:36:27,997 Epoch[33] Batch [10]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.110489,	
2017-06-27 23:36:32,130 Epoch[33] Batch [20]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105761,	
2017-06-27 23:36:36,243 Epoch[33] Batch [30]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103962,	
2017-06-27 23:36:40,269 Epoch[33] Batch [40]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105491,	
2017-06-27 23:36:44,309 Epoch[33] Batch [50]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104582,	
2017-06-27 23:36:48,392 Epoch[33] Batch [60]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.106346,	
2017-06-27 23:36:52,390 Epoch[33] Batch [70]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.107087,	
2017-06-27 23:36:56,371 Epoch[33] Batch [80]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.107320,	
2017-06-27 23:37:00,375 Epoch[33] Batch [90]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.108365,	
2017-06-27 23:37:04,451 Epoch[33] Batch [100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109054,	
2017-06-27 23:37:08,580 Epoch[33] Batch [110]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.108396,	
2017-06-27 23:37:12,663 Epoch[33] Batch [120]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.107613,	
2017-06-27 23:37:16,719 Epoch[33] Batch [130]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.107373,	
2017-06-27 23:37:20,706 Epoch[33] Batch [140]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.107790,	
2017-06-27 23:37:24,704 Epoch[33] Batch [150]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.107364,	
2017-06-27 23:37:28,875 Epoch[33] Batch [160]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.107250,	
2017-06-27 23:37:32,952 Epoch[33] Batch [170]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.106897,	
2017-06-27 23:37:36,996 Epoch[33] Batch [180]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.106705,	
2017-06-27 23:37:41,034 Epoch[33] Batch [190]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.106529,	
2017-06-27 23:37:45,072 Epoch[33] Batch [200]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.106398,	
2017-06-27 23:37:49,020 Epoch[33] Batch [210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.106166,	
2017-06-27 23:37:53,090 Epoch[33] Batch [220]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106298,	
2017-06-27 23:37:57,244 Epoch[33] Batch [230]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.106089,	
2017-06-27 23:38:01,375 Epoch[33] Batch [240]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105834,	
2017-06-27 23:38:05,481 Epoch[33] Batch [250]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105656,	
2017-06-27 23:38:09,556 Epoch[33] Batch [260]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105783,	
2017-06-27 23:38:13,688 Epoch[33] Batch [270]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105759,	
2017-06-27 23:38:17,727 Epoch[33] Batch [280]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105855,	
2017-06-27 23:38:21,858 Epoch[33] Batch [290]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105684,	
2017-06-27 23:38:25,892 Epoch[33] Batch [300]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105788,	
2017-06-27 23:38:29,882 Epoch[33] Batch [310]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105629,	
2017-06-27 23:38:33,904 Epoch[33] Batch [320]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.105204,	
2017-06-27 23:38:37,928 Epoch[33] Batch [330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.104833,	
2017-06-27 23:38:41,913 Epoch[33] Batch [340]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.104894,	
2017-06-27 23:38:46,016 Epoch[33] Batch [350]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104637,	
2017-06-27 23:38:50,114 Epoch[33] Batch [360]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104378,	
2017-06-27 23:38:54,204 Epoch[33] Batch [370]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.104248,	
2017-06-27 23:38:58,267 Epoch[33] Batch [380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104302,	
2017-06-27 23:39:02,287 Epoch[33] Batch [390]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.104500,	
2017-06-27 23:39:06,290 Epoch[33] Batch [400]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.104776,	
2017-06-27 23:39:10,334 Epoch[33] Batch [410]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104737,	
2017-06-27 23:39:14,437 Epoch[33] Batch [420]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104628,	
2017-06-27 23:39:18,567 Epoch[33] Batch [430]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.104695,	
2017-06-27 23:39:22,605 Epoch[33] Batch [440]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104652,	
2017-06-27 23:39:26,597 Epoch[33] Batch [450]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.104474,	
2017-06-27 23:39:30,589 Epoch[33] Batch [460]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.104428,	
2017-06-27 23:39:34,635 Epoch[33] Batch [470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.104113,	
2017-06-27 23:39:38,665 Epoch[33] Batch [480]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.103990,	
2017-06-27 23:39:42,697 Epoch[33] Batch [490]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.103774,	
2017-06-27 23:39:46,692 Epoch[33] Batch [500]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.103858,	
2017-06-27 23:39:50,783 Epoch[33] Batch [510]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.103884,	
2017-06-27 23:39:54,798 Epoch[33] Batch [520]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.103892,	
2017-06-27 23:39:58,848 Epoch[33] Batch [530]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.103895,	
2017-06-27 23:40:02,830 Epoch[33] Batch [540]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.103959,	
2017-06-27 23:40:06,905 Epoch[33] Batch [550]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104023,	
2017-06-27 23:40:11,026 Epoch[33] Batch [560]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.104068,	
2017-06-27 23:40:15,085 Epoch[33] Batch [570]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.104082,	
2017-06-27 23:40:19,158 Epoch[33] Batch [580]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104138,	
2017-06-27 23:40:23,149 Epoch[33] Batch [590]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.104205,	
2017-06-27 23:40:27,165 Epoch[33] Batch [600]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104406,	
2017-06-27 23:40:31,266 Epoch[33] Batch [610]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104382,	
2017-06-27 23:40:35,370 Epoch[33] Batch [620]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104535,	
2017-06-27 23:40:39,444 Epoch[33] Batch [630]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104437,	
2017-06-27 23:40:43,516 Epoch[33] Batch [640]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104353,	
2017-06-27 23:40:47,554 Epoch[33] Batch [650]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104270,	
2017-06-27 23:40:51,572 Epoch[33] Batch [660]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104373,	
2017-06-27 23:40:55,646 Epoch[33] Batch [670]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104275,	
2017-06-27 23:40:59,641 Epoch[33] Batch [680]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.104200,	
2017-06-27 23:41:03,760 Epoch[33] Batch [690]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.104246,	
2017-06-27 23:41:07,835 Epoch[33] Batch [700]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104380,	
2017-06-27 23:41:11,975 Epoch[33] Batch [710]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.104355,	
2017-06-27 23:41:16,023 Epoch[33] Batch [720]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104364,	
2017-06-27 23:41:20,101 Epoch[33] Batch [730]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.104344,	
2017-06-27 23:41:24,208 Epoch[33] Batch [740]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.104356,	
2017-06-27 23:41:28,421 Epoch[33] Batch [750]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.104495,	
2017-06-27 23:41:32,410 Epoch[33] Batch [760]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104571,	
2017-06-27 23:41:36,399 Epoch[33] Batch [770]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104538,	
2017-06-27 23:41:40,443 Epoch[33] Batch [780]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104628,	
2017-06-27 23:41:44,440 Epoch[33] Batch [790]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.104647,	
2017-06-27 23:41:48,501 Epoch[33] Batch [800]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104589,	
2017-06-27 23:41:52,534 Epoch[33] Batch [810]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104656,	
2017-06-27 23:41:56,685 Epoch[33] Batch [820]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104651,	
2017-06-27 23:42:00,736 Epoch[33] Batch [830]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104823,	
2017-06-27 23:42:04,842 Epoch[33] Batch [840]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.104687,	
2017-06-27 23:42:09,015 Epoch[33] Batch [850]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.104659,	
2017-06-27 23:42:13,070 Epoch[33] Batch [860]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104624,	
2017-06-27 23:42:17,056 Epoch[33] Batch [870]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.104607,	
2017-06-27 23:42:21,185 Epoch[33] Batch [880]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.104583,	
2017-06-27 23:42:25,245 Epoch[33] Batch [890]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104532,	
2017-06-27 23:42:29,323 Epoch[33] Batch [900]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.104532,	
2017-06-27 23:42:33,481 Epoch[33] Batch [910]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104578,	
2017-06-27 23:42:37,540 Epoch[33] Batch [920]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104672,	
2017-06-27 23:42:41,549 Epoch[33] Batch [930]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.104616,	
2017-06-27 23:42:45,690 Epoch[33] Batch [940]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.104983,	
2017-06-27 23:42:49,665 Epoch[33] Batch [950]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.105266,	
2017-06-27 23:42:53,715 Epoch[33] Batch [960]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105325,	
2017-06-27 23:42:57,817 Epoch[33] Batch [970]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105349,	
2017-06-27 23:43:01,865 Epoch[33] Batch [980]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105407,	
2017-06-27 23:43:05,995 Epoch[33] Batch [990]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.105382,	
2017-06-27 23:43:10,034 Epoch[33] Batch [1000]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105535,	
2017-06-27 23:43:14,169 Epoch[33] Batch [1010]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105490,	
2017-06-27 23:43:18,247 Epoch[33] Batch [1020]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105530,	
2017-06-27 23:43:22,324 Epoch[33] Batch [1030]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105518,	
2017-06-27 23:43:26,290 Epoch[33] Batch [1040]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.105485,	
2017-06-27 23:43:30,384 Epoch[33] Batch [1050]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105390,	
2017-06-27 23:43:34,483 Epoch[33] Batch [1060]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105390,	
2017-06-27 23:43:38,524 Epoch[33] Batch [1070]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105213,	
2017-06-27 23:43:42,613 Epoch[33] Batch [1080]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.105303,	
2017-06-27 23:43:46,816 Epoch[33] Batch [1090]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.105428,	
2017-06-27 23:43:50,894 Epoch[33] Batch [1100]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105482,	
2017-06-27 23:43:55,030 Epoch[33] Batch [1110]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.105537,	
2017-06-27 23:43:59,138 Epoch[33] Batch [1120]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105517,	
2017-06-27 23:44:03,199 Epoch[33] Batch [1130]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.105502,	
2017-06-27 23:44:07,261 Epoch[33] Batch [1140]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.105563,	
2017-06-27 23:44:11,253 Epoch[33] Batch [1150]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.105706,	
2017-06-27 23:44:15,450 Epoch[33] Batch [1160]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.105635,	
2017-06-27 23:44:19,484 Epoch[33] Batch [1170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.105709,	
2017-06-27 23:44:23,590 Epoch[33] Batch [1180]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105658,	
2017-06-27 23:44:27,692 Epoch[33] Batch [1190]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105661,	
2017-06-27 23:44:31,895 Epoch[33] Batch [1200]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.105623,	
2017-06-27 23:44:35,990 Epoch[33] Batch [1210]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105673,	
2017-06-27 23:44:40,053 Epoch[33] Batch [1220]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.105745,	
2017-06-27 23:44:44,135 Epoch[33] Batch [1230]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105745,	
2017-06-27 23:44:48,228 Epoch[33] Batch [1240]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.105742,	
2017-06-27 23:44:52,348 Epoch[33] Batch [1250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105801,	
2017-06-27 23:44:56,457 Epoch[33] Batch [1260]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105744,	
2017-06-27 23:45:00,580 Epoch[33] Batch [1270]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.105729,	
2017-06-27 23:45:04,623 Epoch[33] Batch [1280]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105696,	
2017-06-27 23:45:08,641 Epoch[33] Batch [1290]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105641,	
2017-06-27 23:45:12,745 Epoch[33] Batch [1300]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105590,	
2017-06-27 23:45:16,750 Epoch[33] Batch [1310]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.105501,	
2017-06-27 23:45:20,868 Epoch[33] Batch [1320]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105449,	
2017-06-27 23:45:24,939 Epoch[33] Batch [1330]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105404,	
2017-06-27 23:45:29,038 Epoch[33] Batch [1340]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105308,	
2017-06-27 23:45:33,093 Epoch[33] Batch [1350]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105284,	
2017-06-27 23:45:37,130 Epoch[33] Batch [1360]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105323,	
2017-06-27 23:45:41,261 Epoch[33] Batch [1370]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.105278,	
2017-06-27 23:45:45,294 Epoch[33] Batch [1380]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105212,	
2017-06-27 23:45:49,208 Epoch[33] Batch [1390]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.105256,	
2017-06-27 23:45:53,262 Epoch[33] Batch [1400]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105197,	
2017-06-27 23:45:57,292 Epoch[33] Batch [1410]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105203,	
2017-06-27 23:46:01,368 Epoch[33] Batch [1420]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.105180,	
2017-06-27 23:46:05,318 Epoch[33] Batch [1430]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.105166,	
2017-06-27 23:46:09,327 Epoch[33] Batch [1440]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105234,	
2017-06-27 23:46:13,373 Epoch[33] Batch [1450]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.105164,	
2017-06-27 23:46:17,351 Epoch[33] Batch [1460]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.105170,	
2017-06-27 23:46:21,357 Epoch[33] Batch [1470]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.105142,	
2017-06-27 23:46:25,462 Epoch[33] Batch [1480]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105074,	
2017-06-27 23:46:27,973 Epoch[33] Train-FCNLogLoss=0.105042
2017-06-27 23:46:27,973 Epoch[33] Time cost=604.749
2017-06-27 23:46:28,638 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0034.params"
2017-06-27 23:46:30,247 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0034.states"
2017-06-27 23:46:34,962 Epoch[34] Batch [10]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.099738,	
2017-06-27 23:46:39,057 Epoch[34] Batch [20]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.098434,	
2017-06-27 23:46:43,077 Epoch[34] Batch [30]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097267,	
2017-06-27 23:46:47,154 Epoch[34] Batch [40]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.097853,	
2017-06-27 23:46:51,315 Epoch[34] Batch [50]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.101562,	
2017-06-27 23:46:55,383 Epoch[34] Batch [60]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101364,	
2017-06-27 23:46:59,432 Epoch[34] Batch [70]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101298,	
2017-06-27 23:47:03,480 Epoch[34] Batch [80]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.100994,	
2017-06-27 23:47:07,666 Epoch[34] Batch [90]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.101174,	
2017-06-27 23:47:11,754 Epoch[34] Batch [100]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.101882,	
2017-06-27 23:47:15,839 Epoch[34] Batch [110]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100624,	
2017-06-27 23:47:19,977 Epoch[34] Batch [120]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.101479,	
2017-06-27 23:47:24,050 Epoch[34] Batch [130]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101186,	
2017-06-27 23:47:28,088 Epoch[34] Batch [140]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.100836,	
2017-06-27 23:47:32,281 Epoch[34] Batch [150]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.100998,	
2017-06-27 23:47:36,300 Epoch[34] Batch [160]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.100696,	
2017-06-27 23:47:40,341 Epoch[34] Batch [170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.100681,	
2017-06-27 23:47:44,420 Epoch[34] Batch [180]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.100376,	
2017-06-27 23:47:48,506 Epoch[34] Batch [190]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100322,	
2017-06-27 23:47:52,577 Epoch[34] Batch [200]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100107,	
2017-06-27 23:47:56,759 Epoch[34] Batch [210]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.099974,	
2017-06-27 23:48:00,737 Epoch[34] Batch [220]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.099652,	
2017-06-27 23:48:04,717 Epoch[34] Batch [230]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.099754,	
2017-06-27 23:48:08,873 Epoch[34] Batch [240]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.099831,	
2017-06-27 23:48:12,992 Epoch[34] Batch [250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.099750,	
2017-06-27 23:48:17,070 Epoch[34] Batch [260]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.099708,	
2017-06-27 23:48:21,197 Epoch[34] Batch [270]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.099993,	
2017-06-27 23:48:25,212 Epoch[34] Batch [280]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.099893,	
2017-06-27 23:48:29,320 Epoch[34] Batch [290]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.099819,	
2017-06-27 23:48:33,494 Epoch[34] Batch [300]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.099654,	
2017-06-27 23:48:37,586 Epoch[34] Batch [310]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.099781,	
2017-06-27 23:48:41,759 Epoch[34] Batch [320]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.099898,	
2017-06-27 23:48:45,927 Epoch[34] Batch [330]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.100054,	
2017-06-27 23:48:50,065 Epoch[34] Batch [340]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.099758,	
2017-06-27 23:48:54,173 Epoch[34] Batch [350]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.099832,	
2017-06-27 23:48:58,316 Epoch[34] Batch [360]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.099800,	
2017-06-27 23:49:02,347 Epoch[34] Batch [370]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.099852,	
2017-06-27 23:49:06,454 Epoch[34] Batch [380]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.099699,	
2017-06-27 23:49:10,492 Epoch[34] Batch [390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.099959,	
2017-06-27 23:49:14,604 Epoch[34] Batch [400]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.100532,	
2017-06-27 23:49:18,810 Epoch[34] Batch [410]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.100597,	
2017-06-27 23:49:22,882 Epoch[34] Batch [420]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.100586,	
2017-06-27 23:49:26,941 Epoch[34] Batch [430]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100667,	
2017-06-27 23:49:30,906 Epoch[34] Batch [440]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.100762,	
2017-06-27 23:49:35,074 Epoch[34] Batch [450]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.100592,	
2017-06-27 23:49:39,193 Epoch[34] Batch [460]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.100698,	
2017-06-27 23:49:43,328 Epoch[34] Batch [470]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.100468,	
2017-06-27 23:49:47,363 Epoch[34] Batch [480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100418,	
2017-06-27 23:49:51,370 Epoch[34] Batch [490]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.100356,	
2017-06-27 23:49:55,397 Epoch[34] Batch [500]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.100138,	
2017-06-27 23:49:59,424 Epoch[34] Batch [510]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.100195,	
2017-06-27 23:50:03,414 Epoch[34] Batch [520]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.100394,	
2017-06-27 23:50:07,414 Epoch[34] Batch [530]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.100744,	
2017-06-27 23:50:11,502 Epoch[34] Batch [540]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100918,	
2017-06-27 23:50:15,559 Epoch[34] Batch [550]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100766,	
2017-06-27 23:50:19,581 Epoch[34] Batch [560]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.100587,	
2017-06-27 23:50:23,711 Epoch[34] Batch [570]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.100362,	
2017-06-27 23:50:27,885 Epoch[34] Batch [580]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.100478,	
2017-06-27 23:50:31,921 Epoch[34] Batch [590]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.100537,	
2017-06-27 23:50:35,866 Epoch[34] Batch [600]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.100519,	
2017-06-27 23:50:39,873 Epoch[34] Batch [610]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.100778,	
2017-06-27 23:50:44,039 Epoch[34] Batch [620]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.100862,	
2017-06-27 23:50:48,101 Epoch[34] Batch [630]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100861,	
2017-06-27 23:50:52,211 Epoch[34] Batch [640]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.100770,	
2017-06-27 23:50:56,330 Epoch[34] Batch [650]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.100837,	
2017-06-27 23:51:00,425 Epoch[34] Batch [660]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100948,	
2017-06-27 23:51:04,449 Epoch[34] Batch [670]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100815,	
2017-06-27 23:51:08,545 Epoch[34] Batch [680]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100725,	
2017-06-27 23:51:12,622 Epoch[34] Batch [690]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.100816,	
2017-06-27 23:51:16,755 Epoch[34] Batch [700]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.100700,	
2017-06-27 23:51:20,790 Epoch[34] Batch [710]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.100572,	
2017-06-27 23:51:24,840 Epoch[34] Batch [720]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.100549,	
2017-06-27 23:51:28,976 Epoch[34] Batch [730]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.100687,	
2017-06-27 23:51:33,043 Epoch[34] Batch [740]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.100660,	
2017-06-27 23:51:37,145 Epoch[34] Batch [750]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.100514,	
2017-06-27 23:51:41,206 Epoch[34] Batch [760]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100661,	
2017-06-27 23:51:45,235 Epoch[34] Batch [770]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.100600,	
2017-06-27 23:51:49,335 Epoch[34] Batch [780]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.100701,	
2017-06-27 23:51:53,453 Epoch[34] Batch [790]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.100616,	
2017-06-27 23:51:57,547 Epoch[34] Batch [800]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100730,	
2017-06-27 23:52:01,597 Epoch[34] Batch [810]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.100744,	
2017-06-27 23:52:05,665 Epoch[34] Batch [820]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100772,	
2017-06-27 23:52:09,747 Epoch[34] Batch [830]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100676,	
2017-06-27 23:52:13,857 Epoch[34] Batch [840]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.100668,	
2017-06-27 23:52:17,978 Epoch[34] Batch [850]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.100698,	
2017-06-27 23:52:22,132 Epoch[34] Batch [860]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.100730,	
2017-06-27 23:52:26,238 Epoch[34] Batch [870]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.100775,	
2017-06-27 23:52:30,330 Epoch[34] Batch [880]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100602,	
2017-06-27 23:52:34,399 Epoch[34] Batch [890]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100570,	
2017-06-27 23:52:38,549 Epoch[34] Batch [900]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.100521,	
2017-06-27 23:52:42,610 Epoch[34] Batch [910]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100593,	
2017-06-27 23:52:46,671 Epoch[34] Batch [920]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100484,	
2017-06-27 23:52:50,706 Epoch[34] Batch [930]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.100415,	
2017-06-27 23:52:54,895 Epoch[34] Batch [940]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.100431,	
2017-06-27 23:52:58,977 Epoch[34] Batch [950]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100355,	
2017-06-27 23:53:02,984 Epoch[34] Batch [960]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.100252,	
2017-06-27 23:53:07,089 Epoch[34] Batch [970]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.100249,	
2017-06-27 23:53:11,169 Epoch[34] Batch [980]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100267,	
2017-06-27 23:53:15,152 Epoch[34] Batch [990]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.100263,	
2017-06-27 23:53:19,172 Epoch[34] Batch [1000]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.100226,	
2017-06-27 23:53:23,195 Epoch[34] Batch [1010]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100280,	
2017-06-27 23:53:27,257 Epoch[34] Batch [1020]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.100322,	
2017-06-27 23:53:31,250 Epoch[34] Batch [1030]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.100350,	
2017-06-27 23:53:35,294 Epoch[34] Batch [1040]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.100363,	
2017-06-27 23:53:39,401 Epoch[34] Batch [1050]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.100455,	
2017-06-27 23:53:43,494 Epoch[34] Batch [1060]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100453,	
2017-06-27 23:53:47,534 Epoch[34] Batch [1070]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.100433,	
2017-06-27 23:53:51,628 Epoch[34] Batch [1080]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100375,	
2017-06-27 23:53:55,698 Epoch[34] Batch [1090]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100391,	
2017-06-27 23:53:59,650 Epoch[34] Batch [1100]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.100256,	
2017-06-27 23:54:03,770 Epoch[34] Batch [1110]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.100201,	
2017-06-27 23:54:07,870 Epoch[34] Batch [1120]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.100209,	
2017-06-27 23:54:11,770 Epoch[34] Batch [1130]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.100419,	
2017-06-27 23:54:15,836 Epoch[34] Batch [1140]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.100547,	
2017-06-27 23:54:19,892 Epoch[34] Batch [1150]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100619,	
2017-06-27 23:54:23,956 Epoch[34] Batch [1160]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.100594,	
2017-06-27 23:54:28,013 Epoch[34] Batch [1170]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100687,	
2017-06-27 23:54:32,034 Epoch[34] Batch [1180]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.100721,	
2017-06-27 23:54:36,040 Epoch[34] Batch [1190]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.100687,	
2017-06-27 23:54:40,037 Epoch[34] Batch [1200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.100766,	
2017-06-27 23:54:44,074 Epoch[34] Batch [1210]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.100853,	
2017-06-27 23:54:48,122 Epoch[34] Batch [1220]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.100772,	
2017-06-27 23:54:52,192 Epoch[34] Batch [1230]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.100778,	
2017-06-27 23:54:56,225 Epoch[34] Batch [1240]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100744,	
2017-06-27 23:55:00,260 Epoch[34] Batch [1250]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.100875,	
2017-06-27 23:55:04,300 Epoch[34] Batch [1260]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.100868,	
2017-06-27 23:55:08,241 Epoch[34] Batch [1270]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.100845,	
2017-06-27 23:55:12,319 Epoch[34] Batch [1280]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.100978,	
2017-06-27 23:55:16,438 Epoch[34] Batch [1290]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.100970,	
2017-06-27 23:55:20,395 Epoch[34] Batch [1300]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.101044,	
2017-06-27 23:55:24,509 Epoch[34] Batch [1310]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.101049,	
2017-06-27 23:55:28,545 Epoch[34] Batch [1320]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101055,	
2017-06-27 23:55:32,527 Epoch[34] Batch [1330]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.100936,	
2017-06-27 23:55:36,528 Epoch[34] Batch [1340]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.100968,	
2017-06-27 23:55:40,519 Epoch[34] Batch [1350]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.100915,	
2017-06-27 23:55:44,657 Epoch[34] Batch [1360]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.100888,	
2017-06-27 23:55:48,683 Epoch[34] Batch [1370]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100927,	
2017-06-27 23:55:52,705 Epoch[34] Batch [1380]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.100933,	
2017-06-27 23:55:56,818 Epoch[34] Batch [1390]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.100995,	
2017-06-27 23:56:00,892 Epoch[34] Batch [1400]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.100971,	
2017-06-27 23:56:04,893 Epoch[34] Batch [1410]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.101033,	
2017-06-27 23:56:08,916 Epoch[34] Batch [1420]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.101065,	
2017-06-27 23:56:13,026 Epoch[34] Batch [1430]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.101112,	
2017-06-27 23:56:17,090 Epoch[34] Batch [1440]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.101154,	
2017-06-27 23:56:21,025 Epoch[34] Batch [1450]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.101188,	
2017-06-27 23:56:25,066 Epoch[34] Batch [1460]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.101098,	
2017-06-27 23:56:29,129 Epoch[34] Batch [1470]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101026,	
2017-06-27 23:56:33,187 Epoch[34] Batch [1480]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101119,	
2017-06-27 23:56:35,692 Epoch[34] Train-FCNLogLoss=0.101116
2017-06-27 23:56:35,693 Epoch[34] Time cost=605.445
2017-06-27 23:56:36,417 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0035.params"
2017-06-27 23:56:38,039 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0035.states"
2017-06-27 23:56:42,787 Epoch[35] Batch [10]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-27 23:56:46,925 Epoch[35] Batch [20]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.091339,	
2017-06-27 23:56:51,085 Epoch[35] Batch [30]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.093139,	
2017-06-27 23:56:55,225 Epoch[35] Batch [40]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.093916,	
2017-06-27 23:56:59,281 Epoch[35] Batch [50]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.093924,	
2017-06-27 23:57:03,403 Epoch[35] Batch [60]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094713,	
2017-06-27 23:57:07,460 Epoch[35] Batch [70]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094673,	
2017-06-27 23:57:11,536 Epoch[35] Batch [80]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095304,	
2017-06-27 23:57:15,701 Epoch[35] Batch [90]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096597,	
2017-06-27 23:57:19,680 Epoch[35] Batch [100]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.097628,	
2017-06-27 23:57:23,780 Epoch[35] Batch [110]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.096668,	
2017-06-27 23:57:27,920 Epoch[35] Batch [120]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097192,	
2017-06-27 23:57:31,966 Epoch[35] Batch [130]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.096504,	
2017-06-27 23:57:36,043 Epoch[35] Batch [140]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095887,	
2017-06-27 23:57:39,979 Epoch[35] Batch [150]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096150,	
2017-06-27 23:57:44,024 Epoch[35] Batch [160]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.096429,	
2017-06-27 23:57:48,048 Epoch[35] Batch [170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096659,	
2017-06-27 23:57:52,083 Epoch[35] Batch [180]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096680,	
2017-06-27 23:57:56,141 Epoch[35] Batch [190]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096479,	
2017-06-27 23:58:00,190 Epoch[35] Batch [200]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097830,	
2017-06-27 23:58:04,208 Epoch[35] Batch [210]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.097719,	
2017-06-27 23:58:08,259 Epoch[35] Batch [220]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.098176,	
2017-06-27 23:58:12,267 Epoch[35] Batch [230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.100125,	
2017-06-27 23:58:16,270 Epoch[35] Batch [240]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.100550,	
2017-06-27 23:58:20,296 Epoch[35] Batch [250]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100523,	
2017-06-27 23:58:24,388 Epoch[35] Batch [260]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100576,	
2017-06-27 23:58:28,482 Epoch[35] Batch [270]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101272,	
2017-06-27 23:58:32,565 Epoch[35] Batch [280]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101261,	
2017-06-27 23:58:36,578 Epoch[35] Batch [290]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101266,	
2017-06-27 23:58:40,696 Epoch[35] Batch [300]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.101264,	
2017-06-27 23:58:44,754 Epoch[35] Batch [310]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101125,	
2017-06-27 23:58:48,817 Epoch[35] Batch [320]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101352,	
2017-06-27 23:58:52,874 Epoch[35] Batch [330]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101442,	
2017-06-27 23:58:56,999 Epoch[35] Batch [340]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.101213,	
2017-06-27 23:59:01,081 Epoch[35] Batch [350]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101236,	
2017-06-27 23:59:05,249 Epoch[35] Batch [360]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.101346,	
2017-06-27 23:59:09,246 Epoch[35] Batch [370]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.101470,	
2017-06-27 23:59:13,301 Epoch[35] Batch [380]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.101627,	
2017-06-27 23:59:17,423 Epoch[35] Batch [390]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.101645,	
2017-06-27 23:59:21,436 Epoch[35] Batch [400]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101805,	
2017-06-27 23:59:25,475 Epoch[35] Batch [410]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.101693,	
2017-06-27 23:59:29,483 Epoch[35] Batch [420]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.101794,	
2017-06-27 23:59:33,582 Epoch[35] Batch [430]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.101913,	
2017-06-27 23:59:37,540 Epoch[35] Batch [440]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.101884,	
2017-06-27 23:59:41,611 Epoch[35] Batch [450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101946,	
2017-06-27 23:59:45,729 Epoch[35] Batch [460]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.102040,	
2017-06-27 23:59:49,827 Epoch[35] Batch [470]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.102171,	
2017-06-27 23:59:53,856 Epoch[35] Batch [480]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.102221,	
2017-06-27 23:59:57,994 Epoch[35] Batch [490]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.102023,	
2017-06-28 00:00:02,142 Epoch[35] Batch [500]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.101942,	
2017-06-28 00:00:06,249 Epoch[35] Batch [510]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.101822,	
2017-06-28 00:00:10,262 Epoch[35] Batch [520]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101803,	
2017-06-28 00:00:14,342 Epoch[35] Batch [530]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.102028,	
2017-06-28 00:00:18,396 Epoch[35] Batch [540]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.102095,	
2017-06-28 00:00:22,445 Epoch[35] Batch [550]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101992,	
2017-06-28 00:00:26,645 Epoch[35] Batch [560]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.101971,	
2017-06-28 00:00:30,713 Epoch[35] Batch [570]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101921,	
2017-06-28 00:00:34,750 Epoch[35] Batch [580]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.102067,	
2017-06-28 00:00:38,838 Epoch[35] Batch [590]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.102100,	
2017-06-28 00:00:42,810 Epoch[35] Batch [600]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.102123,	
2017-06-28 00:00:46,912 Epoch[35] Batch [610]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.102029,	
2017-06-28 00:00:50,883 Epoch[35] Batch [620]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.101797,	
2017-06-28 00:00:54,961 Epoch[35] Batch [630]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101772,	
2017-06-28 00:00:59,008 Epoch[35] Batch [640]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101675,	
2017-06-28 00:01:02,983 Epoch[35] Batch [650]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.101754,	
2017-06-28 00:01:07,179 Epoch[35] Batch [660]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.102002,	
2017-06-28 00:01:11,242 Epoch[35] Batch [670]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.102225,	
2017-06-28 00:01:15,458 Epoch[35] Batch [680]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.102244,	
2017-06-28 00:01:19,511 Epoch[35] Batch [690]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.102536,	
2017-06-28 00:01:23,631 Epoch[35] Batch [700]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.102571,	
2017-06-28 00:01:27,831 Epoch[35] Batch [710]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.102480,	
2017-06-28 00:01:31,988 Epoch[35] Batch [720]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.102597,	
2017-06-28 00:01:36,084 Epoch[35] Batch [730]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.102602,	
2017-06-28 00:01:40,286 Epoch[35] Batch [740]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.102634,	
2017-06-28 00:01:44,259 Epoch[35] Batch [750]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.102613,	
2017-06-28 00:01:48,349 Epoch[35] Batch [760]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.102725,	
2017-06-28 00:01:52,414 Epoch[35] Batch [770]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.102721,	
2017-06-28 00:01:56,529 Epoch[35] Batch [780]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.102854,	
2017-06-28 00:02:00,445 Epoch[35] Batch [790]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.102861,	
2017-06-28 00:02:04,539 Epoch[35] Batch [800]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.102943,	
2017-06-28 00:02:08,609 Epoch[35] Batch [810]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.102799,	
2017-06-28 00:02:12,683 Epoch[35] Batch [820]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.102754,	
2017-06-28 00:02:16,820 Epoch[35] Batch [830]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.102648,	
2017-06-28 00:02:20,826 Epoch[35] Batch [840]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.102388,	
2017-06-28 00:02:24,872 Epoch[35] Batch [850]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.102288,	
2017-06-28 00:02:28,988 Epoch[35] Batch [860]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.102204,	
2017-06-28 00:02:33,031 Epoch[35] Batch [870]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.102219,	
2017-06-28 00:02:37,105 Epoch[35] Batch [880]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.102292,	
2017-06-28 00:02:41,162 Epoch[35] Batch [890]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.102303,	
2017-06-28 00:02:45,222 Epoch[35] Batch [900]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.102301,	
2017-06-28 00:02:49,308 Epoch[35] Batch [910]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.102316,	
2017-06-28 00:02:53,285 Epoch[35] Batch [920]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.102154,	
2017-06-28 00:02:57,345 Epoch[35] Batch [930]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.102192,	
2017-06-28 00:03:01,278 Epoch[35] Batch [940]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.102176,	
2017-06-28 00:03:05,360 Epoch[35] Batch [950]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.102189,	
2017-06-28 00:03:09,411 Epoch[35] Batch [960]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.102204,	
2017-06-28 00:03:13,493 Epoch[35] Batch [970]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.102124,	
2017-06-28 00:03:17,438 Epoch[35] Batch [980]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.102080,	
2017-06-28 00:03:21,403 Epoch[35] Batch [990]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.102131,	
2017-06-28 00:03:25,454 Epoch[35] Batch [1000]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.102107,	
2017-06-28 00:03:29,395 Epoch[35] Batch [1010]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.102039,	
2017-06-28 00:03:33,430 Epoch[35] Batch [1020]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101905,	
2017-06-28 00:03:37,421 Epoch[35] Batch [1030]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.101874,	
2017-06-28 00:03:41,501 Epoch[35] Batch [1040]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.101781,	
2017-06-28 00:03:45,567 Epoch[35] Batch [1050]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.101754,	
2017-06-28 00:03:49,601 Epoch[35] Batch [1060]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101682,	
2017-06-28 00:03:53,635 Epoch[35] Batch [1070]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101711,	
2017-06-28 00:03:57,668 Epoch[35] Batch [1080]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.101728,	
2017-06-28 00:04:01,747 Epoch[35] Batch [1090]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101628,	
2017-06-28 00:04:05,894 Epoch[35] Batch [1100]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.101569,	
2017-06-28 00:04:10,046 Epoch[35] Batch [1110]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101571,	
2017-06-28 00:04:14,153 Epoch[35] Batch [1120]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.101550,	
2017-06-28 00:04:18,256 Epoch[35] Batch [1130]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.101549,	
2017-06-28 00:04:22,333 Epoch[35] Batch [1140]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101477,	
2017-06-28 00:04:26,341 Epoch[35] Batch [1150]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.101453,	
2017-06-28 00:04:30,494 Epoch[35] Batch [1160]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101541,	
2017-06-28 00:04:34,510 Epoch[35] Batch [1170]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101583,	
2017-06-28 00:04:38,572 Epoch[35] Batch [1180]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101610,	
2017-06-28 00:04:42,591 Epoch[35] Batch [1190]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.101672,	
2017-06-28 00:04:46,582 Epoch[35] Batch [1200]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.101639,	
2017-06-28 00:04:50,740 Epoch[35] Batch [1210]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101541,	
2017-06-28 00:04:54,884 Epoch[35] Batch [1220]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.101559,	
2017-06-28 00:04:58,875 Epoch[35] Batch [1230]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.101547,	
2017-06-28 00:05:02,978 Epoch[35] Batch [1240]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.101608,	
2017-06-28 00:05:07,135 Epoch[35] Batch [1250]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101623,	
2017-06-28 00:05:11,261 Epoch[35] Batch [1260]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.101631,	
2017-06-28 00:05:15,409 Epoch[35] Batch [1270]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.101605,	
2017-06-28 00:05:19,571 Epoch[35] Batch [1280]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.101558,	
2017-06-28 00:05:23,660 Epoch[35] Batch [1290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.101594,	
2017-06-28 00:05:27,787 Epoch[35] Batch [1300]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.101561,	
2017-06-28 00:05:31,995 Epoch[35] Batch [1310]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.101604,	
2017-06-28 00:05:36,142 Epoch[35] Batch [1320]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.101524,	
2017-06-28 00:05:40,299 Epoch[35] Batch [1330]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101448,	
2017-06-28 00:05:44,300 Epoch[35] Batch [1340]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.101381,	
2017-06-28 00:05:48,457 Epoch[35] Batch [1350]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101430,	
2017-06-28 00:05:52,619 Epoch[35] Batch [1360]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.101252,	
2017-06-28 00:05:56,515 Epoch[35] Batch [1370]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.101257,	
2017-06-28 00:06:00,587 Epoch[35] Batch [1380]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101310,	
2017-06-28 00:06:04,682 Epoch[35] Batch [1390]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101281,	
2017-06-28 00:06:08,910 Epoch[35] Batch [1400]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.101241,	
2017-06-28 00:06:12,890 Epoch[35] Batch [1410]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.101209,	
2017-06-28 00:06:16,944 Epoch[35] Batch [1420]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.101221,	
2017-06-28 00:06:21,003 Epoch[35] Batch [1430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101180,	
2017-06-28 00:06:25,148 Epoch[35] Batch [1440]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.101164,	
2017-06-28 00:06:29,224 Epoch[35] Batch [1450]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101154,	
2017-06-28 00:06:33,343 Epoch[35] Batch [1460]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.101166,	
2017-06-28 00:06:37,420 Epoch[35] Batch [1470]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.101164,	
2017-06-28 00:06:41,577 Epoch[35] Batch [1480]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.101118,	
2017-06-28 00:06:44,118 Epoch[35] Train-FCNLogLoss=0.101103
2017-06-28 00:06:44,118 Epoch[35] Time cost=606.079
2017-06-28 00:06:44,847 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0036.params"
2017-06-28 00:06:46,471 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0036.states"
2017-06-28 00:06:51,387 Epoch[36] Batch [10]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.122889,	
2017-06-28 00:06:55,602 Epoch[36] Batch [20]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.108418,	
2017-06-28 00:06:59,923 Epoch[36] Batch [30]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.107700,	
2017-06-28 00:07:04,131 Epoch[36] Batch [40]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.105923,	
2017-06-28 00:07:08,270 Epoch[36] Batch [50]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.102145,	
2017-06-28 00:07:12,355 Epoch[36] Batch [60]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.100733,	
2017-06-28 00:07:16,546 Epoch[36] Batch [70]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.100365,	
2017-06-28 00:07:20,703 Epoch[36] Batch [80]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.100048,	
2017-06-28 00:07:24,930 Epoch[36] Batch [90]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.099663,	
2017-06-28 00:07:28,995 Epoch[36] Batch [100]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.099084,	
2017-06-28 00:07:33,203 Epoch[36] Batch [110]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.097781,	
2017-06-28 00:07:37,382 Epoch[36] Batch [120]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.098296,	
2017-06-28 00:07:41,624 Epoch[36] Batch [130]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.098124,	
2017-06-28 00:07:45,887 Epoch[36] Batch [140]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.097744,	
2017-06-28 00:07:49,842 Epoch[36] Batch [150]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.098810,	
2017-06-28 00:07:53,881 Epoch[36] Batch [160]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.100157,	
2017-06-28 00:07:58,078 Epoch[36] Batch [170]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100363,	
2017-06-28 00:08:02,309 Epoch[36] Batch [180]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.100594,	
2017-06-28 00:08:06,658 Epoch[36] Batch [190]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.100797,	
2017-06-28 00:08:10,925 Epoch[36] Batch [200]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.101099,	
2017-06-28 00:08:15,224 Epoch[36] Batch [210]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.101640,	
2017-06-28 00:08:19,485 Epoch[36] Batch [220]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.101495,	
2017-06-28 00:08:23,671 Epoch[36] Batch [230]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.101678,	
2017-06-28 00:08:27,836 Epoch[36] Batch [240]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.102009,	
2017-06-28 00:08:32,156 Epoch[36] Batch [250]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.102560,	
2017-06-28 00:08:36,490 Epoch[36] Batch [260]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.102643,	
2017-06-28 00:08:41,106 Epoch[36] Batch [270]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.102586,	
2017-06-28 00:08:45,408 Epoch[36] Batch [280]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.102122,	
2017-06-28 00:08:49,652 Epoch[36] Batch [290]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.102144,	
2017-06-28 00:08:54,003 Epoch[36] Batch [300]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.102021,	
2017-06-28 00:08:58,121 Epoch[36] Batch [310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.101896,	
2017-06-28 00:09:02,266 Epoch[36] Batch [320]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.101971,	
2017-06-28 00:09:06,337 Epoch[36] Batch [330]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.101681,	
2017-06-28 00:09:10,349 Epoch[36] Batch [340]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101442,	
2017-06-28 00:09:14,444 Epoch[36] Batch [350]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101507,	
2017-06-28 00:09:18,755 Epoch[36] Batch [360]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.101220,	
2017-06-28 00:09:22,935 Epoch[36] Batch [370]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.101318,	
2017-06-28 00:09:27,209 Epoch[36] Batch [380]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.101005,	
2017-06-28 00:09:31,420 Epoch[36] Batch [390]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.100992,	
2017-06-28 00:09:35,790 Epoch[36] Batch [400]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.100799,	
2017-06-28 00:09:39,879 Epoch[36] Batch [410]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100666,	
2017-06-28 00:09:44,048 Epoch[36] Batch [420]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.100669,	
2017-06-28 00:09:48,287 Epoch[36] Batch [430]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100781,	
2017-06-28 00:09:52,543 Epoch[36] Batch [440]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.100767,	
2017-06-28 00:09:56,638 Epoch[36] Batch [450]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100825,	
2017-06-28 00:10:00,972 Epoch[36] Batch [460]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.101028,	
2017-06-28 00:10:05,224 Epoch[36] Batch [470]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.100827,	
2017-06-28 00:10:09,656 Epoch[36] Batch [480]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.100824,	
2017-06-28 00:10:13,836 Epoch[36] Batch [490]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.100583,	
2017-06-28 00:10:18,157 Epoch[36] Batch [500]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.100743,	
2017-06-28 00:10:22,386 Epoch[36] Batch [510]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100903,	
2017-06-28 00:10:26,629 Epoch[36] Batch [520]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100860,	
2017-06-28 00:10:30,987 Epoch[36] Batch [530]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.100740,	
2017-06-28 00:10:35,104 Epoch[36] Batch [540]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.100728,	
2017-06-28 00:10:39,355 Epoch[36] Batch [550]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.100607,	
2017-06-28 00:10:43,411 Epoch[36] Batch [560]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100574,	
2017-06-28 00:10:47,648 Epoch[36] Batch [570]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100714,	
2017-06-28 00:10:51,917 Epoch[36] Batch [580]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.100713,	
2017-06-28 00:10:56,174 Epoch[36] Batch [590]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.100712,	
2017-06-28 00:11:00,412 Epoch[36] Batch [600]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100536,	
2017-06-28 00:11:04,468 Epoch[36] Batch [610]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100491,	
2017-06-28 00:11:08,664 Epoch[36] Batch [620]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100531,	
2017-06-28 00:11:12,864 Epoch[36] Batch [630]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100459,	
2017-06-28 00:11:17,113 Epoch[36] Batch [640]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.100462,	
2017-06-28 00:11:21,299 Epoch[36] Batch [650]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.100464,	
2017-06-28 00:11:25,331 Epoch[36] Batch [660]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.100437,	
2017-06-28 00:11:29,442 Epoch[36] Batch [670]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.100262,	
2017-06-28 00:11:33,591 Epoch[36] Batch [680]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.100084,	
2017-06-28 00:11:37,938 Epoch[36] Batch [690]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.100110,	
2017-06-28 00:11:42,071 Epoch[36] Batch [700]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.100103,	
2017-06-28 00:11:46,307 Epoch[36] Batch [710]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100176,	
2017-06-28 00:11:50,407 Epoch[36] Batch [720]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.100171,	
2017-06-28 00:11:54,605 Epoch[36] Batch [730]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100174,	
2017-06-28 00:11:58,747 Epoch[36] Batch [740]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.100135,	
2017-06-28 00:12:03,044 Epoch[36] Batch [750]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.100157,	
2017-06-28 00:12:07,349 Epoch[36] Batch [760]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.100204,	
2017-06-28 00:12:11,544 Epoch[36] Batch [770]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.100190,	
2017-06-28 00:12:15,684 Epoch[36] Batch [780]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.100224,	
2017-06-28 00:12:19,870 Epoch[36] Batch [790]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.100216,	
2017-06-28 00:12:24,152 Epoch[36] Batch [800]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.100242,	
2017-06-28 00:12:28,376 Epoch[36] Batch [810]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.100289,	
2017-06-28 00:12:32,390 Epoch[36] Batch [820]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.100250,	
2017-06-28 00:12:36,739 Epoch[36] Batch [830]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.100198,	
2017-06-28 00:12:41,091 Epoch[36] Batch [840]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.100245,	
2017-06-28 00:12:45,287 Epoch[36] Batch [850]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.100277,	
2017-06-28 00:12:49,560 Epoch[36] Batch [860]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.100259,	
2017-06-28 00:12:53,788 Epoch[36] Batch [870]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100201,	
2017-06-28 00:12:57,969 Epoch[36] Batch [880]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.100216,	
2017-06-28 00:13:02,294 Epoch[36] Batch [890]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.100324,	
2017-06-28 00:13:06,660 Epoch[36] Batch [900]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.100300,	
2017-06-28 00:13:10,992 Epoch[36] Batch [910]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.100356,	
2017-06-28 00:13:15,049 Epoch[36] Batch [920]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.100291,	
2017-06-28 00:13:19,455 Epoch[36] Batch [930]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.100181,	
2017-06-28 00:13:23,691 Epoch[36] Batch [940]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100177,	
2017-06-28 00:13:27,822 Epoch[36] Batch [950]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.100141,	
2017-06-28 00:13:31,976 Epoch[36] Batch [960]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.100086,	
2017-06-28 00:13:36,256 Epoch[36] Batch [970]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.099981,	
2017-06-28 00:13:40,448 Epoch[36] Batch [980]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.099937,	
2017-06-28 00:13:44,716 Epoch[36] Batch [990]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.099995,	
2017-06-28 00:13:48,845 Epoch[36] Batch [1000]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.100011,	
2017-06-28 00:13:53,140 Epoch[36] Batch [1010]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.099969,	
2017-06-28 00:13:57,293 Epoch[36] Batch [1020]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.099994,	
2017-06-28 00:14:01,522 Epoch[36] Batch [1030]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100002,	
2017-06-28 00:14:05,618 Epoch[36] Batch [1040]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.099933,	
2017-06-28 00:14:09,833 Epoch[36] Batch [1050]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.099881,	
2017-06-28 00:14:14,191 Epoch[36] Batch [1060]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.099893,	
2017-06-28 00:14:18,578 Epoch[36] Batch [1070]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.099950,	
2017-06-28 00:14:23,022 Epoch[36] Batch [1080]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.099959,	
2017-06-28 00:14:27,355 Epoch[36] Batch [1090]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.099984,	
2017-06-28 00:14:31,616 Epoch[36] Batch [1100]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.099910,	
2017-06-28 00:14:35,839 Epoch[36] Batch [1110]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.099870,	
2017-06-28 00:14:40,059 Epoch[36] Batch [1120]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.099885,	
2017-06-28 00:14:44,227 Epoch[36] Batch [1130]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.099875,	
2017-06-28 00:14:48,497 Epoch[36] Batch [1140]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.099939,	
2017-06-28 00:14:52,724 Epoch[36] Batch [1150]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.099873,	
2017-06-28 00:14:57,091 Epoch[36] Batch [1160]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.099788,	
2017-06-28 00:15:01,468 Epoch[36] Batch [1170]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.099694,	
2017-06-28 00:15:05,754 Epoch[36] Batch [1180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.099749,	
2017-06-28 00:15:10,194 Epoch[36] Batch [1190]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.099619,	
2017-06-28 00:15:14,415 Epoch[36] Batch [1200]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.099665,	
2017-06-28 00:15:18,414 Epoch[36] Batch [1210]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.099670,	
2017-06-28 00:15:22,809 Epoch[36] Batch [1220]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.099660,	
2017-06-28 00:15:26,916 Epoch[36] Batch [1230]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.099644,	
2017-06-28 00:15:31,065 Epoch[36] Batch [1240]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.099562,	
2017-06-28 00:15:35,293 Epoch[36] Batch [1250]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.099603,	
2017-06-28 00:15:39,522 Epoch[36] Batch [1260]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.099574,	
2017-06-28 00:15:43,647 Epoch[36] Batch [1270]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.099674,	
2017-06-28 00:15:47,971 Epoch[36] Batch [1280]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.099629,	
2017-06-28 00:15:52,232 Epoch[36] Batch [1290]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.099617,	
2017-06-28 00:15:56,537 Epoch[36] Batch [1300]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.099548,	
2017-06-28 00:16:00,851 Epoch[36] Batch [1310]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.099597,	
2017-06-28 00:16:05,121 Epoch[36] Batch [1320]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.099555,	
2017-06-28 00:16:09,279 Epoch[36] Batch [1330]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.099526,	
2017-06-28 00:16:13,489 Epoch[36] Batch [1340]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.099447,	
2017-06-28 00:16:17,722 Epoch[36] Batch [1350]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.099428,	
2017-06-28 00:16:21,894 Epoch[36] Batch [1360]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.099441,	
2017-06-28 00:16:26,225 Epoch[36] Batch [1370]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.099426,	
2017-06-28 00:16:30,415 Epoch[36] Batch [1380]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.099394,	
2017-06-28 00:16:34,765 Epoch[36] Batch [1390]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.099360,	
2017-06-28 00:16:38,955 Epoch[36] Batch [1400]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.099359,	
2017-06-28 00:16:43,188 Epoch[36] Batch [1410]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.099296,	
2017-06-28 00:16:47,452 Epoch[36] Batch [1420]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.099230,	
2017-06-28 00:16:51,593 Epoch[36] Batch [1430]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.099175,	
2017-06-28 00:16:55,924 Epoch[36] Batch [1440]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.099188,	
2017-06-28 00:17:00,183 Epoch[36] Batch [1450]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.099140,	
2017-06-28 00:17:04,247 Epoch[36] Batch [1460]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.099033,	
2017-06-28 00:17:08,516 Epoch[36] Batch [1470]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.099014,	
2017-06-28 00:17:12,685 Epoch[36] Batch [1480]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.098953,	
2017-06-28 00:17:15,177 Epoch[36] Train-FCNLogLoss=0.098973
2017-06-28 00:17:15,177 Epoch[36] Time cost=628.706
2017-06-28 00:17:15,901 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0037.params"
2017-06-28 00:17:17,536 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0037.states"
2017-06-28 00:17:22,410 Epoch[37] Batch [10]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.103497,	
2017-06-28 00:17:26,603 Epoch[37] Batch [20]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096712,	
2017-06-28 00:17:30,800 Epoch[37] Batch [30]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.098032,	
2017-06-28 00:17:35,060 Epoch[37] Batch [40]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094929,	
2017-06-28 00:17:39,473 Epoch[37] Batch [50]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.096776,	
2017-06-28 00:17:44,017 Epoch[37] Batch [60]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.096992,	
2017-06-28 00:17:48,220 Epoch[37] Batch [70]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.096568,	
2017-06-28 00:17:52,614 Epoch[37] Batch [80]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.097046,	
2017-06-28 00:17:56,806 Epoch[37] Batch [90]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095359,	
2017-06-28 00:18:01,232 Epoch[37] Batch [100]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.096355,	
2017-06-28 00:18:05,341 Epoch[37] Batch [110]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.096763,	
2017-06-28 00:18:09,747 Epoch[37] Batch [120]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.097134,	
2017-06-28 00:18:14,045 Epoch[37] Batch [130]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.097181,	
2017-06-28 00:18:18,413 Epoch[37] Batch [140]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.096445,	
2017-06-28 00:18:22,739 Epoch[37] Batch [150]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.096046,	
2017-06-28 00:18:27,039 Epoch[37] Batch [160]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.096210,	
2017-06-28 00:18:31,501 Epoch[37] Batch [170]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.096315,	
2017-06-28 00:18:35,727 Epoch[37] Batch [180]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.096661,	
2017-06-28 00:18:39,928 Epoch[37] Batch [190]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.096798,	
2017-06-28 00:18:44,042 Epoch[37] Batch [200]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097126,	
2017-06-28 00:18:48,405 Epoch[37] Batch [210]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.096972,	
2017-06-28 00:18:52,678 Epoch[37] Batch [220]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097224,	
2017-06-28 00:18:56,702 Epoch[37] Batch [230]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.097210,	
2017-06-28 00:19:00,809 Epoch[37] Batch [240]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.096841,	
2017-06-28 00:19:04,775 Epoch[37] Batch [250]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096929,	
2017-06-28 00:19:09,115 Epoch[37] Batch [260]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.096920,	
2017-06-28 00:19:13,302 Epoch[37] Batch [270]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.096860,	
2017-06-28 00:19:17,480 Epoch[37] Batch [280]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.097200,	
2017-06-28 00:19:21,764 Epoch[37] Batch [290]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.097317,	
2017-06-28 00:19:26,017 Epoch[37] Batch [300]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.097492,	
2017-06-28 00:19:30,408 Epoch[37] Batch [310]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097296,	
2017-06-28 00:19:34,618 Epoch[37] Batch [320]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.097540,	
2017-06-28 00:19:38,809 Epoch[37] Batch [330]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.097650,	
2017-06-28 00:19:43,151 Epoch[37] Batch [340]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.097756,	
2017-06-28 00:19:47,392 Epoch[37] Batch [350]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.097989,	
2017-06-28 00:19:51,644 Epoch[37] Batch [360]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.098032,	
2017-06-28 00:19:55,966 Epoch[37] Batch [370]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097685,	
2017-06-28 00:20:00,132 Epoch[37] Batch [380]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.097527,	
2017-06-28 00:20:04,314 Epoch[37] Batch [390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097506,	
2017-06-28 00:20:08,711 Epoch[37] Batch [400]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.097423,	
2017-06-28 00:20:13,032 Epoch[37] Batch [410]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097314,	
2017-06-28 00:20:17,153 Epoch[37] Batch [420]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097412,	
2017-06-28 00:20:21,431 Epoch[37] Batch [430]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097417,	
2017-06-28 00:20:25,562 Epoch[37] Batch [440]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097484,	
2017-06-28 00:20:29,871 Epoch[37] Batch [450]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097463,	
2017-06-28 00:20:34,124 Epoch[37] Batch [460]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.097463,	
2017-06-28 00:20:38,498 Epoch[37] Batch [470]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.097486,	
2017-06-28 00:20:42,604 Epoch[37] Batch [480]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.097453,	
2017-06-28 00:20:46,593 Epoch[37] Batch [490]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.097330,	
2017-06-28 00:20:50,666 Epoch[37] Batch [500]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.097390,	
2017-06-28 00:20:54,969 Epoch[37] Batch [510]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.097335,	
2017-06-28 00:20:59,128 Epoch[37] Batch [520]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.097261,	
2017-06-28 00:21:03,281 Epoch[37] Batch [530]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.097100,	
2017-06-28 00:21:07,644 Epoch[37] Batch [540]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.097012,	
2017-06-28 00:21:11,852 Epoch[37] Batch [550]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.096962,	
2017-06-28 00:21:15,985 Epoch[37] Batch [560]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097065,	
2017-06-28 00:21:20,213 Epoch[37] Batch [570]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.097024,	
2017-06-28 00:21:24,475 Epoch[37] Batch [580]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.097013,	
2017-06-28 00:21:28,674 Epoch[37] Batch [590]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097032,	
2017-06-28 00:21:32,932 Epoch[37] Batch [600]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.097186,	
2017-06-28 00:21:37,141 Epoch[37] Batch [610]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.097055,	
2017-06-28 00:21:41,526 Epoch[37] Batch [620]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.097047,	
2017-06-28 00:21:45,705 Epoch[37] Batch [630]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097063,	
2017-06-28 00:21:50,122 Epoch[37] Batch [640]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.096991,	
2017-06-28 00:21:54,315 Epoch[37] Batch [650]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096947,	
2017-06-28 00:21:58,701 Epoch[37] Batch [660]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.096818,	
2017-06-28 00:22:03,040 Epoch[37] Batch [670]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.096647,	
2017-06-28 00:22:07,194 Epoch[37] Batch [680]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.096593,	
2017-06-28 00:22:11,387 Epoch[37] Batch [690]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096634,	
2017-06-28 00:22:15,402 Epoch[37] Batch [700]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.096811,	
2017-06-28 00:22:19,420 Epoch[37] Batch [710]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.096887,	
2017-06-28 00:22:23,572 Epoch[37] Batch [720]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.096849,	
2017-06-28 00:22:27,705 Epoch[37] Batch [730]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.096883,	
2017-06-28 00:22:32,013 Epoch[37] Batch [740]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.096850,	
2017-06-28 00:22:36,141 Epoch[37] Batch [750]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096925,	
2017-06-28 00:22:40,229 Epoch[37] Batch [760]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.096994,	
2017-06-28 00:22:44,542 Epoch[37] Batch [770]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097024,	
2017-06-28 00:22:48,895 Epoch[37] Batch [780]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.097120,	
2017-06-28 00:22:52,971 Epoch[37] Batch [790]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.097133,	
2017-06-28 00:22:57,175 Epoch[37] Batch [800]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.097053,	
2017-06-28 00:23:01,403 Epoch[37] Batch [810]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.096923,	
2017-06-28 00:23:05,591 Epoch[37] Batch [820]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.096858,	
2017-06-28 00:23:09,766 Epoch[37] Batch [830]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.096871,	
2017-06-28 00:23:13,986 Epoch[37] Batch [840]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.096946,	
2017-06-28 00:23:18,191 Epoch[37] Batch [850]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.096893,	
2017-06-28 00:23:22,480 Epoch[37] Batch [860]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.096905,	
2017-06-28 00:23:26,547 Epoch[37] Batch [870]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.096944,	
2017-06-28 00:23:30,752 Epoch[37] Batch [880]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.096807,	
2017-06-28 00:23:35,191 Epoch[37] Batch [890]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.096843,	
2017-06-28 00:23:39,271 Epoch[37] Batch [900]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096850,	
2017-06-28 00:23:43,471 Epoch[37] Batch [910]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.096825,	
2017-06-28 00:23:47,665 Epoch[37] Batch [920]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096868,	
2017-06-28 00:23:52,059 Epoch[37] Batch [930]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.096932,	
2017-06-28 00:23:56,169 Epoch[37] Batch [940]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096939,	
2017-06-28 00:24:00,270 Epoch[37] Batch [950]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.096972,	
2017-06-28 00:24:04,603 Epoch[37] Batch [960]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097035,	
2017-06-28 00:24:08,874 Epoch[37] Batch [970]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.097056,	
2017-06-28 00:24:13,129 Epoch[37] Batch [980]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.096953,	
2017-06-28 00:24:17,223 Epoch[37] Batch [990]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.096996,	
2017-06-28 00:24:21,334 Epoch[37] Batch [1000]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096921,	
2017-06-28 00:24:25,677 Epoch[37] Batch [1010]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.097036,	
2017-06-28 00:24:29,838 Epoch[37] Batch [1020]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.096907,	
2017-06-28 00:24:34,022 Epoch[37] Batch [1030]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.096993,	
2017-06-28 00:24:38,251 Epoch[37] Batch [1040]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.096967,	
2017-06-28 00:24:42,454 Epoch[37] Batch [1050]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.096937,	
2017-06-28 00:24:46,607 Epoch[37] Batch [1060]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.097037,	
2017-06-28 00:24:50,895 Epoch[37] Batch [1070]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097060,	
2017-06-28 00:24:55,065 Epoch[37] Batch [1080]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097039,	
2017-06-28 00:24:59,188 Epoch[37] Batch [1090]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.097087,	
2017-06-28 00:25:03,322 Epoch[37] Batch [1100]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097044,	
2017-06-28 00:25:07,577 Epoch[37] Batch [1110]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.097054,	
2017-06-28 00:25:11,771 Epoch[37] Batch [1120]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.096991,	
2017-06-28 00:25:16,058 Epoch[37] Batch [1130]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.097044,	
2017-06-28 00:25:20,333 Epoch[37] Batch [1140]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097116,	
2017-06-28 00:25:24,456 Epoch[37] Batch [1150]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.097141,	
2017-06-28 00:25:28,769 Epoch[37] Batch [1160]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097285,	
2017-06-28 00:25:33,013 Epoch[37] Batch [1170]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.097385,	
2017-06-28 00:25:37,184 Epoch[37] Batch [1180]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097388,	
2017-06-28 00:25:41,462 Epoch[37] Batch [1190]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097394,	
2017-06-28 00:25:45,927 Epoch[37] Batch [1200]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097375,	
2017-06-28 00:25:50,341 Epoch[37] Batch [1210]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.097332,	
2017-06-28 00:25:54,624 Epoch[37] Batch [1220]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.097432,	
2017-06-28 00:25:58,864 Epoch[37] Batch [1230]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.097460,	
2017-06-28 00:26:03,106 Epoch[37] Batch [1240]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.097434,	
2017-06-28 00:26:07,488 Epoch[37] Batch [1250]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.097426,	
2017-06-28 00:26:11,633 Epoch[37] Batch [1260]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.097433,	
2017-06-28 00:26:15,829 Epoch[37] Batch [1270]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097458,	
2017-06-28 00:26:20,086 Epoch[37] Batch [1280]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.097513,	
2017-06-28 00:26:24,187 Epoch[37] Batch [1290]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097577,	
2017-06-28 00:26:28,465 Epoch[37] Batch [1300]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097521,	
2017-06-28 00:26:32,858 Epoch[37] Batch [1310]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.097582,	
2017-06-28 00:26:37,022 Epoch[37] Batch [1320]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.097632,	
2017-06-28 00:26:41,033 Epoch[37] Batch [1330]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.097592,	
2017-06-28 00:26:45,414 Epoch[37] Batch [1340]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.097586,	
2017-06-28 00:26:49,618 Epoch[37] Batch [1350]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.097593,	
2017-06-28 00:26:53,663 Epoch[37] Batch [1360]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.097620,	
2017-06-28 00:26:57,801 Epoch[37] Batch [1370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097605,	
2017-06-28 00:27:01,938 Epoch[37] Batch [1380]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097584,	
2017-06-28 00:27:06,285 Epoch[37] Batch [1390]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.097641,	
2017-06-28 00:27:10,548 Epoch[37] Batch [1400]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.097643,	
2017-06-28 00:27:14,743 Epoch[37] Batch [1410]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097720,	
2017-06-28 00:27:18,925 Epoch[37] Batch [1420]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097707,	
2017-06-28 00:27:23,158 Epoch[37] Batch [1430]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.097665,	
2017-06-28 00:27:27,212 Epoch[37] Batch [1440]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.097602,	
2017-06-28 00:27:31,248 Epoch[37] Batch [1450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097581,	
2017-06-28 00:27:35,447 Epoch[37] Batch [1460]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097540,	
2017-06-28 00:27:39,729 Epoch[37] Batch [1470]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.097582,	
2017-06-28 00:27:43,861 Epoch[37] Batch [1480]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097586,	
2017-06-28 00:27:46,390 Epoch[37] Train-FCNLogLoss=0.097588
2017-06-28 00:27:46,390 Epoch[37] Time cost=628.854
2017-06-28 00:27:47,215 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0038.params"
2017-06-28 00:27:49,044 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0038.states"
2017-06-28 00:27:53,871 Epoch[38] Batch [10]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.091613,	
2017-06-28 00:27:58,187 Epoch[38] Batch [20]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.097520,	
2017-06-28 00:28:02,374 Epoch[38] Batch [30]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095407,	
2017-06-28 00:28:06,615 Epoch[38] Batch [40]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.095621,	
2017-06-28 00:28:10,842 Epoch[38] Batch [50]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.093749,	
2017-06-28 00:28:15,060 Epoch[38] Batch [60]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.094195,	
2017-06-28 00:28:19,314 Epoch[38] Batch [70]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.096185,	
2017-06-28 00:28:23,513 Epoch[38] Batch [80]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097343,	
2017-06-28 00:28:27,588 Epoch[38] Batch [90]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.097257,	
2017-06-28 00:28:31,749 Epoch[38] Batch [100]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.097942,	
2017-06-28 00:28:36,029 Epoch[38] Batch [110]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.098084,	
2017-06-28 00:28:40,363 Epoch[38] Batch [120]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.099252,	
2017-06-28 00:28:44,782 Epoch[38] Batch [130]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.099304,	
2017-06-28 00:28:49,048 Epoch[38] Batch [140]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.099500,	
2017-06-28 00:28:53,344 Epoch[38] Batch [150]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.099554,	
2017-06-28 00:28:57,609 Epoch[38] Batch [160]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.100098,	
2017-06-28 00:29:01,911 Epoch[38] Batch [170]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.099478,	
2017-06-28 00:29:06,171 Epoch[38] Batch [180]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.099681,	
2017-06-28 00:29:10,474 Epoch[38] Batch [190]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.099893,	
2017-06-28 00:29:14,643 Epoch[38] Batch [200]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.099548,	
2017-06-28 00:29:18,912 Epoch[38] Batch [210]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.099167,	
2017-06-28 00:29:23,244 Epoch[38] Batch [220]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.099178,	
2017-06-28 00:29:27,481 Epoch[38] Batch [230]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.099305,	
2017-06-28 00:29:31,680 Epoch[38] Batch [240]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.099267,	
2017-06-28 00:29:35,946 Epoch[38] Batch [250]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.099215,	
2017-06-28 00:29:40,169 Epoch[38] Batch [260]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.099175,	
2017-06-28 00:29:44,439 Epoch[38] Batch [270]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.098624,	
2017-06-28 00:29:48,710 Epoch[38] Batch [280]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.099001,	
2017-06-28 00:29:52,891 Epoch[38] Batch [290]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.099126,	
2017-06-28 00:29:57,059 Epoch[38] Batch [300]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.098671,	
2017-06-28 00:30:01,139 Epoch[38] Batch [310]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.098934,	
2017-06-28 00:30:05,208 Epoch[38] Batch [320]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.098405,	
2017-06-28 00:30:09,264 Epoch[38] Batch [330]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098835,	
2017-06-28 00:30:13,487 Epoch[38] Batch [340]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.098596,	
2017-06-28 00:30:17,787 Epoch[38] Batch [350]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.098328,	
2017-06-28 00:30:21,811 Epoch[38] Batch [360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.098224,	
2017-06-28 00:30:25,897 Epoch[38] Batch [370]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.098107,	
2017-06-28 00:30:30,045 Epoch[38] Batch [380]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.097992,	
2017-06-28 00:30:34,350 Epoch[38] Batch [390]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.098139,	
2017-06-28 00:30:38,500 Epoch[38] Batch [400]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.098263,	
2017-06-28 00:30:42,770 Epoch[38] Batch [410]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.098145,	
2017-06-28 00:30:46,864 Epoch[38] Batch [420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.098103,	
2017-06-28 00:30:51,118 Epoch[38] Batch [430]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.098174,	
2017-06-28 00:30:55,348 Epoch[38] Batch [440]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.098495,	
2017-06-28 00:30:59,770 Epoch[38] Batch [450]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.098691,	
2017-06-28 00:31:04,002 Epoch[38] Batch [460]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.098749,	
2017-06-28 00:31:08,241 Epoch[38] Batch [470]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.098562,	
2017-06-28 00:31:12,385 Epoch[38] Batch [480]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.098263,	
2017-06-28 00:31:16,707 Epoch[38] Batch [490]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.098205,	
2017-06-28 00:31:20,872 Epoch[38] Batch [500]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.098191,	
2017-06-28 00:31:25,208 Epoch[38] Batch [510]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.098186,	
2017-06-28 00:31:29,619 Epoch[38] Batch [520]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.098201,	
2017-06-28 00:31:33,945 Epoch[38] Batch [530]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.098359,	
2017-06-28 00:31:38,141 Epoch[38] Batch [540]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.098411,	
2017-06-28 00:31:42,292 Epoch[38] Batch [550]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.098360,	
2017-06-28 00:31:46,605 Epoch[38] Batch [560]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.098376,	
2017-06-28 00:31:50,742 Epoch[38] Batch [570]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.098377,	
2017-06-28 00:31:55,040 Epoch[38] Batch [580]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.098549,	
2017-06-28 00:31:59,401 Epoch[38] Batch [590]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.098453,	
2017-06-28 00:32:03,693 Epoch[38] Batch [600]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.098467,	
2017-06-28 00:32:08,000 Epoch[38] Batch [610]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.098414,	
2017-06-28 00:32:12,172 Epoch[38] Batch [620]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.098483,	
2017-06-28 00:32:16,386 Epoch[38] Batch [630]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.098628,	
2017-06-28 00:32:20,854 Epoch[38] Batch [640]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.098532,	
2017-06-28 00:32:25,006 Epoch[38] Batch [650]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.098438,	
2017-06-28 00:32:29,318 Epoch[38] Batch [660]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.098494,	
2017-06-28 00:32:33,462 Epoch[38] Batch [670]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.098441,	
2017-06-28 00:32:37,762 Epoch[38] Batch [680]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.098376,	
2017-06-28 00:32:41,871 Epoch[38] Batch [690]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.098302,	
2017-06-28 00:32:46,219 Epoch[38] Batch [700]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.098297,	
2017-06-28 00:32:50,473 Epoch[38] Batch [710]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.098363,	
2017-06-28 00:32:54,670 Epoch[38] Batch [720]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.098236,	
2017-06-28 00:32:58,900 Epoch[38] Batch [730]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.098337,	
2017-06-28 00:33:03,133 Epoch[38] Batch [740]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.098333,	
2017-06-28 00:33:07,205 Epoch[38] Batch [750]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.098161,	
2017-06-28 00:33:11,482 Epoch[38] Batch [760]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.098040,	
2017-06-28 00:33:15,567 Epoch[38] Batch [770]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.097996,	
2017-06-28 00:33:19,703 Epoch[38] Batch [780]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.098016,	
2017-06-28 00:33:24,036 Epoch[38] Batch [790]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097874,	
2017-06-28 00:33:28,356 Epoch[38] Batch [800]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097811,	
2017-06-28 00:33:32,661 Epoch[38] Batch [810]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.097868,	
2017-06-28 00:33:36,748 Epoch[38] Batch [820]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.097828,	
2017-06-28 00:33:40,806 Epoch[38] Batch [830]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.097822,	
2017-06-28 00:33:45,157 Epoch[38] Batch [840]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.097821,	
2017-06-28 00:33:49,378 Epoch[38] Batch [850]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.097798,	
2017-06-28 00:33:53,740 Epoch[38] Batch [860]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.097862,	
2017-06-28 00:33:58,031 Epoch[38] Batch [870]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.097850,	
2017-06-28 00:34:02,307 Epoch[38] Batch [880]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097751,	
2017-06-28 00:34:06,619 Epoch[38] Batch [890]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097686,	
2017-06-28 00:34:10,758 Epoch[38] Batch [900]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097763,	
2017-06-28 00:34:15,001 Epoch[38] Batch [910]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.097662,	
2017-06-28 00:34:19,336 Epoch[38] Batch [920]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097686,	
2017-06-28 00:34:23,514 Epoch[38] Batch [930]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097789,	
2017-06-28 00:34:27,766 Epoch[38] Batch [940]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.097706,	
2017-06-28 00:34:32,046 Epoch[38] Batch [950]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097622,	
2017-06-28 00:34:36,369 Epoch[38] Batch [960]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.097645,	
2017-06-28 00:34:40,603 Epoch[38] Batch [970]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.097641,	
2017-06-28 00:34:44,872 Epoch[38] Batch [980]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.097651,	
2017-06-28 00:34:49,065 Epoch[38] Batch [990]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.097611,	
2017-06-28 00:34:53,249 Epoch[38] Batch [1000]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.097597,	
2017-06-28 00:34:57,520 Epoch[38] Batch [1010]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.097556,	
2017-06-28 00:35:01,922 Epoch[38] Batch [1020]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.097443,	
2017-06-28 00:35:06,260 Epoch[38] Batch [1030]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.097473,	
2017-06-28 00:35:10,629 Epoch[38] Batch [1040]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.097490,	
2017-06-28 00:35:14,941 Epoch[38] Batch [1050]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097499,	
2017-06-28 00:35:19,074 Epoch[38] Batch [1060]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097497,	
2017-06-28 00:35:23,272 Epoch[38] Batch [1070]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.097490,	
2017-06-28 00:35:27,581 Epoch[38] Batch [1080]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097621,	
2017-06-28 00:35:32,013 Epoch[38] Batch [1090]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.097546,	
2017-06-28 00:35:36,324 Epoch[38] Batch [1100]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.097450,	
2017-06-28 00:35:40,608 Epoch[38] Batch [1110]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.097504,	
2017-06-28 00:35:44,914 Epoch[38] Batch [1120]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.097600,	
2017-06-28 00:35:49,145 Epoch[38] Batch [1130]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.097579,	
2017-06-28 00:35:53,181 Epoch[38] Batch [1140]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097585,	
2017-06-28 00:35:57,361 Epoch[38] Batch [1150]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.097581,	
2017-06-28 00:36:01,618 Epoch[38] Batch [1160]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.097565,	
2017-06-28 00:36:05,736 Epoch[38] Batch [1170]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097581,	
2017-06-28 00:36:09,944 Epoch[38] Batch [1180]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.097559,	
2017-06-28 00:36:14,221 Epoch[38] Batch [1190]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097636,	
2017-06-28 00:36:18,461 Epoch[38] Batch [1200]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.097584,	
2017-06-28 00:36:22,694 Epoch[38] Batch [1210]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.097565,	
2017-06-28 00:36:26,951 Epoch[38] Batch [1220]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.097629,	
2017-06-28 00:36:31,373 Epoch[38] Batch [1230]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.097653,	
2017-06-28 00:36:35,639 Epoch[38] Batch [1240]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.097632,	
2017-06-28 00:36:39,802 Epoch[38] Batch [1250]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.097650,	
2017-06-28 00:36:44,054 Epoch[38] Batch [1260]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.097578,	
2017-06-28 00:36:48,302 Epoch[38] Batch [1270]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.097603,	
2017-06-28 00:36:52,449 Epoch[38] Batch [1280]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.097605,	
2017-06-28 00:36:56,675 Epoch[38] Batch [1290]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.097596,	
2017-06-28 00:37:00,817 Epoch[38] Batch [1300]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097579,	
2017-06-28 00:37:05,032 Epoch[38] Batch [1310]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.097558,	
2017-06-28 00:37:09,353 Epoch[38] Batch [1320]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097566,	
2017-06-28 00:37:13,497 Epoch[38] Batch [1330]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.097664,	
2017-06-28 00:37:17,515 Epoch[38] Batch [1340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.097620,	
2017-06-28 00:37:21,794 Epoch[38] Batch [1350]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097579,	
2017-06-28 00:37:25,932 Epoch[38] Batch [1360]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097551,	
2017-06-28 00:37:30,069 Epoch[38] Batch [1370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097616,	
2017-06-28 00:37:34,220 Epoch[38] Batch [1380]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.097578,	
2017-06-28 00:37:38,225 Epoch[38] Batch [1390]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097565,	
2017-06-28 00:37:42,508 Epoch[38] Batch [1400]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.097496,	
2017-06-28 00:37:46,680 Epoch[38] Batch [1410]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097475,	
2017-06-28 00:37:50,886 Epoch[38] Batch [1420]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.097456,	
2017-06-28 00:37:55,128 Epoch[38] Batch [1430]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.097434,	
2017-06-28 00:37:59,444 Epoch[38] Batch [1440]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.097390,	
2017-06-28 00:38:03,637 Epoch[38] Batch [1450]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.097432,	
2017-06-28 00:38:07,912 Epoch[38] Batch [1460]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097452,	
2017-06-28 00:38:12,208 Epoch[38] Batch [1470]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.097426,	
2017-06-28 00:38:16,575 Epoch[38] Batch [1480]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.097442,	
2017-06-28 00:38:19,014 Epoch[38] Train-FCNLogLoss=0.097444
2017-06-28 00:38:19,014 Epoch[38] Time cost=629.970
2017-06-28 00:38:19,692 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0039.params"
2017-06-28 00:38:21,386 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0039.states"
2017-06-28 00:38:26,166 Epoch[39] Batch [10]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.093890,	
2017-06-28 00:38:30,648 Epoch[39] Batch [20]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.096595,	
2017-06-28 00:38:34,863 Epoch[39] Batch [30]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.097695,	
2017-06-28 00:38:39,350 Epoch[39] Batch [40]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.096867,	
2017-06-28 00:38:43,642 Epoch[39] Batch [50]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.096487,	
2017-06-28 00:38:47,769 Epoch[39] Batch [60]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096238,	
2017-06-28 00:38:51,836 Epoch[39] Batch [70]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.096385,	
2017-06-28 00:38:56,117 Epoch[39] Batch [80]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.095029,	
2017-06-28 00:39:00,434 Epoch[39] Batch [90]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.095281,	
2017-06-28 00:39:04,612 Epoch[39] Batch [100]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.095025,	
2017-06-28 00:39:08,806 Epoch[39] Batch [110]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095243,	
2017-06-28 00:39:13,092 Epoch[39] Batch [120]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.095389,	
2017-06-28 00:39:17,316 Epoch[39] Batch [130]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.095992,	
2017-06-28 00:39:21,780 Epoch[39] Batch [140]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.096393,	
2017-06-28 00:39:26,027 Epoch[39] Batch [150]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.096870,	
2017-06-28 00:39:30,243 Epoch[39] Batch [160]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.097189,	
2017-06-28 00:39:34,562 Epoch[39] Batch [170]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096335,	
2017-06-28 00:39:38,797 Epoch[39] Batch [180]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095964,	
2017-06-28 00:39:43,210 Epoch[39] Batch [190]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.095504,	
2017-06-28 00:39:47,323 Epoch[39] Batch [200]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095146,	
2017-06-28 00:39:51,411 Epoch[39] Batch [210]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095000,	
2017-06-28 00:39:55,655 Epoch[39] Batch [220]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.095045,	
2017-06-28 00:39:59,860 Epoch[39] Batch [230]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095367,	
2017-06-28 00:40:04,046 Epoch[39] Batch [240]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095391,	
2017-06-28 00:40:08,199 Epoch[39] Batch [250]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094925,	
2017-06-28 00:40:12,317 Epoch[39] Batch [260]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095081,	
2017-06-28 00:40:16,488 Epoch[39] Batch [270]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095017,	
2017-06-28 00:40:20,405 Epoch[39] Batch [280]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094838,	
2017-06-28 00:40:24,731 Epoch[39] Batch [290]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.094928,	
2017-06-28 00:40:28,981 Epoch[39] Batch [300]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.095109,	
2017-06-28 00:40:33,284 Epoch[39] Batch [310]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.095294,	
2017-06-28 00:40:37,430 Epoch[39] Batch [320]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095377,	
2017-06-28 00:40:41,703 Epoch[39] Batch [330]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.095410,	
2017-06-28 00:40:46,063 Epoch[39] Batch [340]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.095504,	
2017-06-28 00:40:50,296 Epoch[39] Batch [350]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095188,	
2017-06-28 00:40:54,507 Epoch[39] Batch [360]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094993,	
2017-06-28 00:40:58,797 Epoch[39] Batch [370]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094936,	
2017-06-28 00:41:03,104 Epoch[39] Batch [380]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094977,	
2017-06-28 00:41:07,234 Epoch[39] Batch [390]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094959,	
2017-06-28 00:41:11,452 Epoch[39] Batch [400]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.095067,	
2017-06-28 00:41:15,681 Epoch[39] Batch [410]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094815,	
2017-06-28 00:41:19,857 Epoch[39] Batch [420]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094902,	
2017-06-28 00:41:23,992 Epoch[39] Batch [430]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.095180,	
2017-06-28 00:41:28,363 Epoch[39] Batch [440]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095164,	
2017-06-28 00:41:32,635 Epoch[39] Batch [450]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.095274,	
2017-06-28 00:41:36,704 Epoch[39] Batch [460]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095204,	
2017-06-28 00:41:40,876 Epoch[39] Batch [470]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095089,	
2017-06-28 00:41:45,006 Epoch[39] Batch [480]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095282,	
2017-06-28 00:41:49,286 Epoch[39] Batch [490]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095112,	
2017-06-28 00:41:53,479 Epoch[39] Batch [500]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094999,	
2017-06-28 00:41:57,715 Epoch[39] Batch [510]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.095073,	
2017-06-28 00:42:01,920 Epoch[39] Batch [520]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095123,	
2017-06-28 00:42:06,240 Epoch[39] Batch [530]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.094795,	
2017-06-28 00:42:10,541 Epoch[39] Batch [540]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094816,	
2017-06-28 00:42:14,588 Epoch[39] Batch [550]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094637,	
2017-06-28 00:42:18,944 Epoch[39] Batch [560]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.094746,	
2017-06-28 00:42:23,332 Epoch[39] Batch [570]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.094595,	
2017-06-28 00:42:27,618 Epoch[39] Batch [580]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.094652,	
2017-06-28 00:42:31,707 Epoch[39] Batch [590]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094789,	
2017-06-28 00:42:35,917 Epoch[39] Batch [600]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.095010,	
2017-06-28 00:42:40,067 Epoch[39] Batch [610]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094984,	
2017-06-28 00:42:44,375 Epoch[39] Batch [620]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094847,	
2017-06-28 00:42:48,520 Epoch[39] Batch [630]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.094855,	
2017-06-28 00:42:52,746 Epoch[39] Batch [640]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094703,	
2017-06-28 00:42:56,915 Epoch[39] Batch [650]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.094858,	
2017-06-28 00:43:01,095 Epoch[39] Batch [660]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.094784,	
2017-06-28 00:43:05,433 Epoch[39] Batch [670]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.094677,	
2017-06-28 00:43:09,778 Epoch[39] Batch [680]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.094534,	
2017-06-28 00:43:13,923 Epoch[39] Batch [690]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.094514,	
2017-06-28 00:43:18,169 Epoch[39] Batch [700]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.094317,	
2017-06-28 00:43:22,519 Epoch[39] Batch [710]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.094346,	
2017-06-28 00:43:26,777 Epoch[39] Batch [720]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.094273,	
2017-06-28 00:43:31,191 Epoch[39] Batch [730]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.094298,	
2017-06-28 00:43:35,579 Epoch[39] Batch [740]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.094344,	
2017-06-28 00:43:39,886 Epoch[39] Batch [750]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094372,	
2017-06-28 00:43:44,105 Epoch[39] Batch [760]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.094496,	
2017-06-28 00:43:48,386 Epoch[39] Batch [770]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094482,	
2017-06-28 00:43:52,653 Epoch[39] Batch [780]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.094403,	
2017-06-28 00:43:56,849 Epoch[39] Batch [790]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094475,	
2017-06-28 00:44:01,171 Epoch[39] Batch [800]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.094467,	
2017-06-28 00:44:05,508 Epoch[39] Batch [810]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.094511,	
2017-06-28 00:44:09,621 Epoch[39] Batch [820]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.094533,	
2017-06-28 00:44:13,905 Epoch[39] Batch [830]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.094518,	
2017-06-28 00:44:18,074 Epoch[39] Batch [840]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094493,	
2017-06-28 00:44:22,412 Epoch[39] Batch [850]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.094475,	
2017-06-28 00:44:26,491 Epoch[39] Batch [860]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094425,	
2017-06-28 00:44:30,678 Epoch[39] Batch [870]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.094550,	
2017-06-28 00:44:34,924 Epoch[39] Batch [880]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.094585,	
2017-06-28 00:44:39,117 Epoch[39] Batch [890]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094587,	
2017-06-28 00:44:43,369 Epoch[39] Batch [900]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.094506,	
2017-06-28 00:44:47,546 Epoch[39] Batch [910]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094589,	
2017-06-28 00:44:51,752 Epoch[39] Batch [920]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.094561,	
2017-06-28 00:44:56,060 Epoch[39] Batch [930]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094454,	
2017-06-28 00:45:00,355 Epoch[39] Batch [940]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094480,	
2017-06-28 00:45:04,645 Epoch[39] Batch [950]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094433,	
2017-06-28 00:45:08,976 Epoch[39] Batch [960]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.094362,	
2017-06-28 00:45:13,238 Epoch[39] Batch [970]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.094291,	
2017-06-28 00:45:17,589 Epoch[39] Batch [980]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.094290,	
2017-06-28 00:45:21,758 Epoch[39] Batch [990]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094273,	
2017-06-28 00:45:26,033 Epoch[39] Batch [1000]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.094319,	
2017-06-28 00:45:30,122 Epoch[39] Batch [1010]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094373,	
2017-06-28 00:45:34,254 Epoch[39] Batch [1020]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094355,	
2017-06-28 00:45:38,495 Epoch[39] Batch [1030]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.094422,	
2017-06-28 00:45:42,717 Epoch[39] Batch [1040]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094302,	
2017-06-28 00:45:46,981 Epoch[39] Batch [1050]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.094421,	
2017-06-28 00:45:51,334 Epoch[39] Batch [1060]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.094486,	
2017-06-28 00:45:55,560 Epoch[39] Batch [1070]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094535,	
2017-06-28 00:45:59,782 Epoch[39] Batch [1080]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094522,	
2017-06-28 00:46:03,887 Epoch[39] Batch [1090]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094555,	
2017-06-28 00:46:08,207 Epoch[39] Batch [1100]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.094537,	
2017-06-28 00:46:12,437 Epoch[39] Batch [1110]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094602,	
2017-06-28 00:46:16,596 Epoch[39] Batch [1120]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.094618,	
2017-06-28 00:46:20,865 Epoch[39] Batch [1130]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.094585,	
2017-06-28 00:46:25,187 Epoch[39] Batch [1140]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.094704,	
2017-06-28 00:46:29,487 Epoch[39] Batch [1150]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094656,	
2017-06-28 00:46:33,660 Epoch[39] Batch [1160]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.094664,	
2017-06-28 00:46:37,912 Epoch[39] Batch [1170]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.094701,	
2017-06-28 00:46:42,173 Epoch[39] Batch [1180]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094721,	
2017-06-28 00:46:46,503 Epoch[39] Batch [1190]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.094709,	
2017-06-28 00:46:50,787 Epoch[39] Batch [1200]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.094673,	
2017-06-28 00:46:55,061 Epoch[39] Batch [1210]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.094671,	
2017-06-28 00:46:59,290 Epoch[39] Batch [1220]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.094796,	
2017-06-28 00:47:03,672 Epoch[39] Batch [1230]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.094785,	
2017-06-28 00:47:08,001 Epoch[39] Batch [1240]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.094870,	
2017-06-28 00:47:12,090 Epoch[39] Batch [1250]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094976,	
2017-06-28 00:47:16,328 Epoch[39] Batch [1260]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.095078,	
2017-06-28 00:47:20,605 Epoch[39] Batch [1270]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095097,	
2017-06-28 00:47:24,768 Epoch[39] Batch [1280]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.095120,	
2017-06-28 00:47:28,791 Epoch[39] Batch [1290]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095171,	
2017-06-28 00:47:33,141 Epoch[39] Batch [1300]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.095146,	
2017-06-28 00:47:37,291 Epoch[39] Batch [1310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.095142,	
2017-06-28 00:47:41,540 Epoch[39] Batch [1320]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.095179,	
2017-06-28 00:47:45,841 Epoch[39] Batch [1330]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.095132,	
2017-06-28 00:47:50,041 Epoch[39] Batch [1340]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095030,	
2017-06-28 00:47:54,422 Epoch[39] Batch [1350]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095071,	
2017-06-28 00:47:58,693 Epoch[39] Batch [1360]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.095087,	
2017-06-28 00:48:03,101 Epoch[39] Batch [1370]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.095083,	
2017-06-28 00:48:07,304 Epoch[39] Batch [1380]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095167,	
2017-06-28 00:48:11,650 Epoch[39] Batch [1390]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.095140,	
2017-06-28 00:48:15,748 Epoch[39] Batch [1400]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095175,	
2017-06-28 00:48:19,982 Epoch[39] Batch [1410]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.095144,	
2017-06-28 00:48:24,312 Epoch[39] Batch [1420]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.095089,	
2017-06-28 00:48:28,486 Epoch[39] Batch [1430]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.095151,	
2017-06-28 00:48:32,916 Epoch[39] Batch [1440]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.095233,	
2017-06-28 00:48:37,195 Epoch[39] Batch [1450]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095265,	
2017-06-28 00:48:41,520 Epoch[39] Batch [1460]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095249,	
2017-06-28 00:48:45,723 Epoch[39] Batch [1470]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095190,	
2017-06-28 00:48:49,913 Epoch[39] Batch [1480]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095184,	
2017-06-28 00:48:52,461 Epoch[39] Train-FCNLogLoss=0.095137
2017-06-28 00:48:52,462 Epoch[39] Time cost=631.075
2017-06-28 00:48:53,201 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0040.params"
2017-06-28 00:48:54,928 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0040.states"
2017-06-28 00:49:00,006 Epoch[40] Batch [10]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.104297,	
2017-06-28 00:49:04,195 Epoch[40] Batch [20]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.103340,	
2017-06-28 00:49:08,502 Epoch[40] Batch [30]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.102191,	
2017-06-28 00:49:12,637 Epoch[40] Batch [40]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.100267,	
2017-06-28 00:49:16,787 Epoch[40] Batch [50]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.100425,	
2017-06-28 00:49:21,070 Epoch[40] Batch [60]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.098780,	
2017-06-28 00:49:25,266 Epoch[40] Batch [70]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.098708,	
2017-06-28 00:49:29,747 Epoch[40] Batch [80]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.098056,	
2017-06-28 00:49:34,049 Epoch[40] Batch [90]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.097617,	
2017-06-28 00:49:38,352 Epoch[40] Batch [100]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.097944,	
2017-06-28 00:49:42,562 Epoch[40] Batch [110]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.100251,	
2017-06-28 00:49:46,928 Epoch[40] Batch [120]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.099716,	
2017-06-28 00:49:50,967 Epoch[40] Batch [130]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.099565,	
2017-06-28 00:49:55,058 Epoch[40] Batch [140]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.100194,	
2017-06-28 00:49:59,375 Epoch[40] Batch [150]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.099832,	
2017-06-28 00:50:03,496 Epoch[40] Batch [160]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.099471,	
2017-06-28 00:50:07,853 Epoch[40] Batch [170]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.098806,	
2017-06-28 00:50:12,125 Epoch[40] Batch [180]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.098959,	
2017-06-28 00:50:16,393 Epoch[40] Batch [190]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.098375,	
2017-06-28 00:50:20,730 Epoch[40] Batch [200]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.098020,	
2017-06-28 00:50:24,987 Epoch[40] Batch [210]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.097516,	
2017-06-28 00:50:29,158 Epoch[40] Batch [220]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097231,	
2017-06-28 00:50:33,300 Epoch[40] Batch [230]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097715,	
2017-06-28 00:50:37,503 Epoch[40] Batch [240]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.098280,	
2017-06-28 00:50:41,623 Epoch[40] Batch [250]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.098892,	
2017-06-28 00:50:45,998 Epoch[40] Batch [260]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.098985,	
2017-06-28 00:50:50,170 Epoch[40] Batch [270]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.099313,	
2017-06-28 00:50:54,282 Epoch[40] Batch [280]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.098955,	
2017-06-28 00:50:58,572 Epoch[40] Batch [290]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.098989,	
2017-06-28 00:51:02,760 Epoch[40] Batch [300]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098782,	
2017-06-28 00:51:06,853 Epoch[40] Batch [310]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.098604,	
2017-06-28 00:51:11,178 Epoch[40] Batch [320]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.098619,	
2017-06-28 00:51:15,576 Epoch[40] Batch [330]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.098530,	
2017-06-28 00:51:19,894 Epoch[40] Batch [340]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.098768,	
2017-06-28 00:51:24,139 Epoch[40] Batch [350]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.098798,	
2017-06-28 00:51:28,479 Epoch[40] Batch [360]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.099253,	
2017-06-28 00:51:32,729 Epoch[40] Batch [370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.099377,	
2017-06-28 00:51:36,966 Epoch[40] Batch [380]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.100214,	
2017-06-28 00:51:41,086 Epoch[40] Batch [390]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.100871,	
2017-06-28 00:51:45,328 Epoch[40] Batch [400]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.101374,	
2017-06-28 00:51:49,535 Epoch[40] Batch [410]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.101581,	
2017-06-28 00:51:53,621 Epoch[40] Batch [420]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.101900,	
2017-06-28 00:51:57,987 Epoch[40] Batch [430]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101738,	
2017-06-28 00:52:02,035 Epoch[40] Batch [440]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101704,	
2017-06-28 00:52:06,128 Epoch[40] Batch [450]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101501,	
2017-06-28 00:52:10,163 Epoch[40] Batch [460]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.101852,	
2017-06-28 00:52:14,167 Epoch[40] Batch [470]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.101654,	
2017-06-28 00:52:18,355 Epoch[40] Batch [480]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.101512,	
2017-06-28 00:52:22,588 Epoch[40] Batch [490]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.101474,	
2017-06-28 00:52:26,739 Epoch[40] Batch [500]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.101568,	
2017-06-28 00:52:30,787 Epoch[40] Batch [510]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101557,	
2017-06-28 00:52:34,360 Update[60000]: Change learning rate to 5.00000e-05
2017-06-28 00:52:35,052 Epoch[40] Batch [520]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.101564,	
2017-06-28 00:52:39,208 Epoch[40] Batch [530]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.101826,	
2017-06-28 00:52:43,428 Epoch[40] Batch [540]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.101871,	
2017-06-28 00:52:47,761 Epoch[40] Batch [550]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.101664,	
2017-06-28 00:52:52,126 Epoch[40] Batch [560]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101817,	
2017-06-28 00:52:56,333 Epoch[40] Batch [570]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.101629,	
2017-06-28 00:53:00,561 Epoch[40] Batch [580]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.101556,	
2017-06-28 00:53:04,856 Epoch[40] Batch [590]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.101462,	
2017-06-28 00:53:09,128 Epoch[40] Batch [600]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.101283,	
2017-06-28 00:53:13,150 Epoch[40] Batch [610]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.101309,	
2017-06-28 00:53:17,472 Epoch[40] Batch [620]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.101125,	
2017-06-28 00:53:21,734 Epoch[40] Batch [630]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.100954,	
2017-06-28 00:53:26,007 Epoch[40] Batch [640]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.100770,	
2017-06-28 00:53:30,229 Epoch[40] Batch [650]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.100803,	
2017-06-28 00:53:34,400 Epoch[40] Batch [660]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.100743,	
2017-06-28 00:53:38,721 Epoch[40] Batch [670]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.100608,	
2017-06-28 00:53:42,846 Epoch[40] Batch [680]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.100482,	
2017-06-28 00:53:47,015 Epoch[40] Batch [690]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.100582,	
2017-06-28 00:53:51,110 Epoch[40] Batch [700]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.100606,	
2017-06-28 00:53:55,297 Epoch[40] Batch [710]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.100559,	
2017-06-28 00:53:59,611 Epoch[40] Batch [720]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.100385,	
2017-06-28 00:54:03,865 Epoch[40] Batch [730]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.100321,	
2017-06-28 00:54:07,992 Epoch[40] Batch [740]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.100160,	
2017-06-28 00:54:12,286 Epoch[40] Batch [750]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.100187,	
2017-06-28 00:54:16,666 Epoch[40] Batch [760]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.100144,	
2017-06-28 00:54:20,821 Epoch[40] Batch [770]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.099901,	
2017-06-28 00:54:25,011 Epoch[40] Batch [780]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.099773,	
2017-06-28 00:54:29,378 Epoch[40] Batch [790]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.099601,	
2017-06-28 00:54:33,503 Epoch[40] Batch [800]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.099579,	
2017-06-28 00:54:37,781 Epoch[40] Batch [810]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.099639,	
2017-06-28 00:54:41,977 Epoch[40] Batch [820]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.099516,	
2017-06-28 00:54:46,279 Epoch[40] Batch [830]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.099466,	
2017-06-28 00:54:50,676 Epoch[40] Batch [840]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.099437,	
2017-06-28 00:54:54,919 Epoch[40] Batch [850]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.099389,	
2017-06-28 00:54:59,047 Epoch[40] Batch [860]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.099255,	
2017-06-28 00:55:03,291 Epoch[40] Batch [870]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.099139,	
2017-06-28 00:55:07,393 Epoch[40] Batch [880]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.099082,	
2017-06-28 00:55:11,643 Epoch[40] Batch [890]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.098997,	
2017-06-28 00:55:15,930 Epoch[40] Batch [900]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.099075,	
2017-06-28 00:55:20,146 Epoch[40] Batch [910]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.098975,	
2017-06-28 00:55:24,360 Epoch[40] Batch [920]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.098980,	
2017-06-28 00:55:28,635 Epoch[40] Batch [930]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.098784,	
2017-06-28 00:55:32,770 Epoch[40] Batch [940]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.098765,	
2017-06-28 00:55:36,965 Epoch[40] Batch [950]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.098608,	
2017-06-28 00:55:40,999 Epoch[40] Batch [960]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.098575,	
2017-06-28 00:55:45,100 Epoch[40] Batch [970]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.098525,	
2017-06-28 00:55:49,574 Epoch[40] Batch [980]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.098509,	
2017-06-28 00:55:53,763 Epoch[40] Batch [990]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098486,	
2017-06-28 00:55:58,240 Epoch[40] Batch [1000]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.098485,	
2017-06-28 00:56:02,577 Epoch[40] Batch [1010]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.098435,	
2017-06-28 00:56:07,003 Epoch[40] Batch [1020]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.098399,	
2017-06-28 00:56:11,301 Epoch[40] Batch [1030]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.098383,	
2017-06-28 00:56:15,595 Epoch[40] Batch [1040]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.098246,	
2017-06-28 00:56:19,992 Epoch[40] Batch [1050]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.098153,	
2017-06-28 00:56:24,280 Epoch[40] Batch [1060]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.098133,	
2017-06-28 00:56:28,743 Epoch[40] Batch [1070]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.098068,	
2017-06-28 00:56:33,033 Epoch[40] Batch [1080]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.097971,	
2017-06-28 00:56:37,334 Epoch[40] Batch [1090]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.098029,	
2017-06-28 00:56:41,723 Epoch[40] Batch [1100]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.097967,	
2017-06-28 00:56:46,081 Epoch[40] Batch [1110]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.097900,	
2017-06-28 00:56:50,313 Epoch[40] Batch [1120]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.097903,	
2017-06-28 00:56:54,682 Epoch[40] Batch [1130]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.097966,	
2017-06-28 00:56:58,888 Epoch[40] Batch [1140]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.097973,	
2017-06-28 00:57:03,163 Epoch[40] Batch [1150]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097958,	
2017-06-28 00:57:07,426 Epoch[40] Batch [1160]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.097910,	
2017-06-28 00:57:11,639 Epoch[40] Batch [1170]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.097931,	
2017-06-28 00:57:15,901 Epoch[40] Batch [1180]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.097884,	
2017-06-28 00:57:20,247 Epoch[40] Batch [1190]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.097808,	
2017-06-28 00:57:24,582 Epoch[40] Batch [1200]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.097778,	
2017-06-28 00:57:28,807 Epoch[40] Batch [1210]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.097736,	
2017-06-28 00:57:33,206 Epoch[40] Batch [1220]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.097688,	
2017-06-28 00:57:37,670 Epoch[40] Batch [1230]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097623,	
2017-06-28 00:57:42,133 Epoch[40] Batch [1240]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097440,	
2017-06-28 00:57:46,579 Epoch[40] Batch [1250]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.097412,	
2017-06-28 00:57:51,109 Epoch[40] Batch [1260]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.097401,	
2017-06-28 00:57:55,415 Epoch[40] Batch [1270]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.097420,	
2017-06-28 00:57:59,706 Epoch[40] Batch [1280]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.097422,	
2017-06-28 00:58:04,046 Epoch[40] Batch [1290]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.097332,	
2017-06-28 00:58:08,479 Epoch[40] Batch [1300]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.097266,	
2017-06-28 00:58:12,865 Epoch[40] Batch [1310]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.097169,	
2017-06-28 00:58:17,138 Epoch[40] Batch [1320]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097116,	
2017-06-28 00:58:21,539 Epoch[40] Batch [1330]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.097168,	
2017-06-28 00:58:26,001 Epoch[40] Batch [1340]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.097116,	
2017-06-28 00:58:30,372 Epoch[40] Batch [1350]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.097111,	
2017-06-28 00:58:34,726 Epoch[40] Batch [1360]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.097041,	
2017-06-28 00:58:39,016 Epoch[40] Batch [1370]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.096977,	
2017-06-28 00:58:43,251 Epoch[40] Batch [1380]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.096960,	
2017-06-28 00:58:47,627 Epoch[40] Batch [1390]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.096927,	
2017-06-28 00:58:52,114 Epoch[40] Batch [1400]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.096928,	
2017-06-28 00:58:56,369 Epoch[40] Batch [1410]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.096879,	
2017-06-28 00:59:00,627 Epoch[40] Batch [1420]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.096857,	
2017-06-28 00:59:05,005 Epoch[40] Batch [1430]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.096831,	
2017-06-28 00:59:09,535 Epoch[40] Batch [1440]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.096758,	
2017-06-28 00:59:14,268 Epoch[40] Batch [1450]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.096705,	
2017-06-28 00:59:18,870 Epoch[40] Batch [1460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.096697,	
2017-06-28 00:59:23,572 Epoch[40] Batch [1470]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.096704,	
2017-06-28 00:59:28,060 Epoch[40] Batch [1480]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.096673,	
2017-06-28 00:59:30,777 Epoch[40] Train-FCNLogLoss=0.096649
2017-06-28 00:59:30,777 Epoch[40] Time cost=635.849
2017-06-28 00:59:31,475 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0041.params"
2017-06-28 00:59:33,418 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0041.states"
2017-06-28 00:59:39,096 Epoch[41] Batch [10]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.098974,	
2017-06-28 00:59:43,778 Epoch[41] Batch [20]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092690,	
2017-06-28 00:59:48,811 Epoch[41] Batch [30]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.091030,	
2017-06-28 00:59:53,379 Epoch[41] Batch [40]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092309,	
2017-06-28 00:59:57,706 Epoch[41] Batch [50]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.091688,	
2017-06-28 01:00:02,185 Epoch[41] Batch [60]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.091733,	
2017-06-28 01:00:06,692 Epoch[41] Batch [70]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091742,	
2017-06-28 01:00:11,303 Epoch[41] Batch [80]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090924,	
2017-06-28 01:00:15,850 Epoch[41] Batch [90]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092220,	
2017-06-28 01:00:20,301 Epoch[41] Batch [100]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.092289,	
2017-06-28 01:00:24,889 Epoch[41] Batch [110]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092911,	
2017-06-28 01:00:29,472 Epoch[41] Batch [120]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092829,	
2017-06-28 01:00:34,275 Epoch[41] Batch [130]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.092711,	
2017-06-28 01:00:38,853 Epoch[41] Batch [140]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092059,	
2017-06-28 01:00:43,111 Epoch[41] Batch [150]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.092299,	
2017-06-28 01:00:47,535 Epoch[41] Batch [160]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.092704,	
2017-06-28 01:00:52,100 Epoch[41] Batch [170]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092707,	
2017-06-28 01:00:56,856 Epoch[41] Batch [180]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092864,	
2017-06-28 01:01:01,505 Epoch[41] Batch [190]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092700,	
2017-06-28 01:01:05,956 Epoch[41] Batch [200]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.092638,	
2017-06-28 01:01:10,600 Epoch[41] Batch [210]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092187,	
2017-06-28 01:01:15,337 Epoch[41] Batch [220]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092132,	
2017-06-28 01:01:19,999 Epoch[41] Batch [230]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.092099,	
2017-06-28 01:01:24,373 Epoch[41] Batch [240]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.092277,	
2017-06-28 01:01:29,055 Epoch[41] Batch [250]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.092664,	
2017-06-28 01:01:33,606 Epoch[41] Batch [260]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.092517,	
2017-06-28 01:01:38,213 Epoch[41] Batch [270]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.092507,	
2017-06-28 01:01:43,048 Epoch[41] Batch [280]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092400,	
2017-06-28 01:01:47,423 Epoch[41] Batch [290]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.092841,	
2017-06-28 01:01:52,020 Epoch[41] Batch [300]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.093273,	
2017-06-28 01:01:56,642 Epoch[41] Batch [310]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.093261,	
2017-06-28 01:02:01,239 Epoch[41] Batch [320]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.093288,	
2017-06-28 01:02:05,955 Epoch[41] Batch [330]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.093026,	
2017-06-28 01:02:10,452 Epoch[41] Batch [340]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.093053,	
2017-06-28 01:02:15,163 Epoch[41] Batch [350]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.093131,	
2017-06-28 01:02:19,668 Epoch[41] Batch [360]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.092884,	
2017-06-28 01:02:24,248 Epoch[41] Batch [370]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092733,	
2017-06-28 01:02:28,806 Epoch[41] Batch [380]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092716,	
2017-06-28 01:02:33,463 Epoch[41] Batch [390]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092533,	
2017-06-28 01:02:38,103 Epoch[41] Batch [400]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092345,	
2017-06-28 01:02:42,629 Epoch[41] Batch [410]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092476,	
2017-06-28 01:02:47,274 Epoch[41] Batch [420]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092326,	
2017-06-28 01:02:51,931 Epoch[41] Batch [430]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092253,	
2017-06-28 01:02:56,576 Epoch[41] Batch [440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092149,	
2017-06-28 01:03:01,049 Epoch[41] Batch [450]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092025,	
2017-06-28 01:03:05,680 Epoch[41] Batch [460]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091854,	
2017-06-28 01:03:10,080 Epoch[41] Batch [470]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.091832,	
2017-06-28 01:03:14,551 Epoch[41] Batch [480]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091789,	
2017-06-28 01:03:19,167 Epoch[41] Batch [490]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091953,	
2017-06-28 01:03:23,756 Epoch[41] Batch [500]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092003,	
2017-06-28 01:03:28,550 Epoch[41] Batch [510]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.091875,	
2017-06-28 01:03:33,181 Epoch[41] Batch [520]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091793,	
2017-06-28 01:03:37,689 Epoch[41] Batch [530]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091728,	
2017-06-28 01:03:42,240 Epoch[41] Batch [540]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091554,	
2017-06-28 01:03:46,857 Epoch[41] Batch [550]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091851,	
2017-06-28 01:03:51,518 Epoch[41] Batch [560]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091819,	
2017-06-28 01:03:56,111 Epoch[41] Batch [570]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.091864,	
2017-06-28 01:04:00,536 Epoch[41] Batch [580]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.091885,	
2017-06-28 01:04:05,101 Epoch[41] Batch [590]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091808,	
2017-06-28 01:04:09,843 Epoch[41] Batch [600]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.091813,	
2017-06-28 01:04:14,423 Epoch[41] Batch [610]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091929,	
2017-06-28 01:04:18,985 Epoch[41] Batch [620]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092118,	
2017-06-28 01:04:23,365 Epoch[41] Batch [630]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.092004,	
2017-06-28 01:04:27,904 Epoch[41] Batch [640]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092025,	
2017-06-28 01:04:32,540 Epoch[41] Batch [650]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.092052,	
2017-06-28 01:04:37,268 Epoch[41] Batch [660]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.092127,	
2017-06-28 01:04:41,503 Epoch[41] Batch [670]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091869,	
2017-06-28 01:04:46,181 Epoch[41] Batch [680]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091954,	
2017-06-28 01:04:50,878 Epoch[41] Batch [690]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091977,	
2017-06-28 01:04:55,504 Epoch[41] Batch [700]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091995,	
2017-06-28 01:05:00,173 Epoch[41] Batch [710]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.092176,	
2017-06-28 01:05:04,613 Epoch[41] Batch [720]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.092130,	
2017-06-28 01:05:09,117 Epoch[41] Batch [730]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.092132,	
2017-06-28 01:05:13,924 Epoch[41] Batch [740]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092018,	
2017-06-28 01:05:18,319 Epoch[41] Batch [750]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.092084,	
2017-06-28 01:05:22,698 Epoch[41] Batch [760]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.092049,	
2017-06-28 01:05:27,178 Epoch[41] Batch [770]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.092088,	
2017-06-28 01:05:32,007 Epoch[41] Batch [780]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092351,	
2017-06-28 01:05:36,444 Epoch[41] Batch [790]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.092238,	
2017-06-28 01:05:41,182 Epoch[41] Batch [800]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092243,	
2017-06-28 01:05:45,729 Epoch[41] Batch [810]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092309,	
2017-06-28 01:05:50,685 Epoch[41] Batch [820]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.092350,	
2017-06-28 01:05:55,388 Epoch[41] Batch [830]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.092295,	
2017-06-28 01:06:00,060 Epoch[41] Batch [840]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092226,	
2017-06-28 01:06:04,680 Epoch[41] Batch [850]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092173,	
2017-06-28 01:06:09,320 Epoch[41] Batch [860]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092112,	
2017-06-28 01:06:13,796 Epoch[41] Batch [870]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092048,	
2017-06-28 01:06:18,413 Epoch[41] Batch [880]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091999,	
2017-06-28 01:06:23,021 Epoch[41] Batch [890]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091886,	
2017-06-28 01:06:27,733 Epoch[41] Batch [900]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.091832,	
2017-06-28 01:06:32,369 Epoch[41] Batch [910]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.091851,	
2017-06-28 01:06:36,812 Epoch[41] Batch [920]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.091927,	
2017-06-28 01:06:41,415 Epoch[41] Batch [930]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092000,	
2017-06-28 01:06:45,939 Epoch[41] Batch [940]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091986,	
2017-06-28 01:06:50,569 Epoch[41] Batch [950]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091933,	
2017-06-28 01:06:55,072 Epoch[41] Batch [960]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.091974,	
2017-06-28 01:06:59,657 Epoch[41] Batch [970]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091995,	
2017-06-28 01:07:04,351 Epoch[41] Batch [980]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.092104,	
2017-06-28 01:07:09,102 Epoch[41] Batch [990]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092227,	
2017-06-28 01:07:13,571 Epoch[41] Batch [1000]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.092242,	
2017-06-28 01:07:18,312 Epoch[41] Batch [1010]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092242,	
2017-06-28 01:07:23,222 Epoch[41] Batch [1020]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.092241,	
2017-06-28 01:07:27,766 Epoch[41] Batch [1030]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092185,	
2017-06-28 01:07:32,528 Epoch[41] Batch [1040]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.092243,	
2017-06-28 01:07:36,901 Epoch[41] Batch [1050]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.092269,	
2017-06-28 01:07:41,425 Epoch[41] Batch [1060]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092219,	
2017-06-28 01:07:46,074 Epoch[41] Batch [1070]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.092266,	
2017-06-28 01:07:50,719 Epoch[41] Batch [1080]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092239,	
2017-06-28 01:07:55,517 Epoch[41] Batch [1090]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092166,	
2017-06-28 01:08:00,032 Epoch[41] Batch [1100]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092274,	
2017-06-28 01:08:04,820 Epoch[41] Batch [1110]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.092258,	
2017-06-28 01:08:09,383 Epoch[41] Batch [1120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092299,	
2017-06-28 01:08:13,998 Epoch[41] Batch [1130]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092129,	
2017-06-28 01:08:18,638 Epoch[41] Batch [1140]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092138,	
2017-06-28 01:08:23,330 Epoch[41] Batch [1150]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092134,	
2017-06-28 01:08:27,872 Epoch[41] Batch [1160]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092180,	
2017-06-28 01:08:32,656 Epoch[41] Batch [1170]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092149,	
2017-06-28 01:08:37,138 Epoch[41] Batch [1180]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.092156,	
2017-06-28 01:08:41,751 Epoch[41] Batch [1190]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092110,	
2017-06-28 01:08:46,153 Epoch[41] Batch [1200]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.092086,	
2017-06-28 01:08:50,792 Epoch[41] Batch [1210]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092130,	
2017-06-28 01:08:55,124 Epoch[41] Batch [1220]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.092114,	
2017-06-28 01:08:59,746 Epoch[41] Batch [1230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092205,	
2017-06-28 01:09:04,413 Epoch[41] Batch [1240]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.092301,	
2017-06-28 01:09:09,184 Epoch[41] Batch [1250]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092329,	
2017-06-28 01:09:13,885 Epoch[41] Batch [1260]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092269,	
2017-06-28 01:09:18,813 Epoch[41] Batch [1270]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.092274,	
2017-06-28 01:09:23,774 Epoch[41] Batch [1280]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.092246,	
2017-06-28 01:09:28,223 Epoch[41] Batch [1290]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.092330,	
2017-06-28 01:09:33,084 Epoch[41] Batch [1300]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.092235,	
2017-06-28 01:09:37,848 Epoch[41] Batch [1310]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.092217,	
2017-06-28 01:09:42,594 Epoch[41] Batch [1320]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.092182,	
2017-06-28 01:09:47,231 Epoch[41] Batch [1330]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.092160,	
2017-06-28 01:09:52,045 Epoch[41] Batch [1340]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092080,	
2017-06-28 01:09:56,785 Epoch[41] Batch [1350]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092176,	
2017-06-28 01:10:01,301 Epoch[41] Batch [1360]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092125,	
2017-06-28 01:10:05,834 Epoch[41] Batch [1370]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.092065,	
2017-06-28 01:10:10,291 Epoch[41] Batch [1380]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.092061,	
2017-06-28 01:10:14,735 Epoch[41] Batch [1390]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.092161,	
2017-06-28 01:10:19,075 Epoch[41] Batch [1400]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.092143,	
2017-06-28 01:10:23,740 Epoch[41] Batch [1410]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.092166,	
2017-06-28 01:10:28,468 Epoch[41] Batch [1420]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.092154,	
2017-06-28 01:10:32,879 Epoch[41] Batch [1430]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.092153,	
2017-06-28 01:10:37,270 Epoch[41] Batch [1440]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.092166,	
2017-06-28 01:10:41,645 Epoch[41] Batch [1450]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.092101,	
2017-06-28 01:10:46,394 Epoch[41] Batch [1460]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092107,	
2017-06-28 01:10:51,232 Epoch[41] Batch [1470]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092061,	
2017-06-28 01:10:55,810 Epoch[41] Batch [1480]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092093,	
2017-06-28 01:10:58,630 Epoch[41] Train-FCNLogLoss=0.092103
2017-06-28 01:10:58,631 Epoch[41] Time cost=685.212
2017-06-28 01:10:59,379 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0042.params"
2017-06-28 01:11:01,089 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0042.states"
2017-06-28 01:11:06,531 Epoch[42] Batch [10]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091005,	
2017-06-28 01:11:10,923 Epoch[42] Batch [20]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.086307,	
2017-06-28 01:11:15,594 Epoch[42] Batch [30]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088536,	
2017-06-28 01:11:20,039 Epoch[42] Batch [40]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.089484,	
2017-06-28 01:11:24,538 Epoch[42] Batch [50]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090328,	
2017-06-28 01:11:29,280 Epoch[42] Batch [60]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.090076,	
2017-06-28 01:11:33,744 Epoch[42] Batch [70]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.089976,	
2017-06-28 01:11:38,421 Epoch[42] Batch [80]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090386,	
2017-06-28 01:11:42,930 Epoch[42] Batch [90]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091180,	
2017-06-28 01:11:47,498 Epoch[42] Batch [100]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091103,	
2017-06-28 01:11:52,190 Epoch[42] Batch [110]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.091748,	
2017-06-28 01:11:56,739 Epoch[42] Batch [120]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091401,	
2017-06-28 01:12:01,536 Epoch[42] Batch [130]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092141,	
2017-06-28 01:12:06,246 Epoch[42] Batch [140]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.092022,	
2017-06-28 01:12:11,143 Epoch[42] Batch [150]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.092889,	
2017-06-28 01:12:15,517 Epoch[42] Batch [160]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.092244,	
2017-06-28 01:12:19,726 Epoch[42] Batch [170]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.092137,	
2017-06-28 01:12:24,404 Epoch[42] Batch [180]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.092324,	
2017-06-28 01:12:28,932 Epoch[42] Batch [190]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092865,	
2017-06-28 01:12:33,307 Epoch[42] Batch [200]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.092834,	
2017-06-28 01:12:37,974 Epoch[42] Batch [210]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.093003,	
2017-06-28 01:12:42,646 Epoch[42] Batch [220]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.093029,	
2017-06-28 01:12:47,333 Epoch[42] Batch [230]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092592,	
2017-06-28 01:12:51,962 Epoch[42] Batch [240]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.092572,	
2017-06-28 01:12:56,489 Epoch[42] Batch [250]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092452,	
2017-06-28 01:13:00,926 Epoch[42] Batch [260]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.092550,	
2017-06-28 01:13:05,638 Epoch[42] Batch [270]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.092415,	
2017-06-28 01:13:10,297 Epoch[42] Batch [280]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092113,	
2017-06-28 01:13:14,780 Epoch[42] Batch [290]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.092014,	
2017-06-28 01:13:19,413 Epoch[42] Batch [300]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.092172,	
2017-06-28 01:13:23,728 Epoch[42] Batch [310]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.092142,	
2017-06-28 01:13:28,310 Epoch[42] Batch [320]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092450,	
2017-06-28 01:13:32,642 Epoch[42] Batch [330]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.092531,	
2017-06-28 01:13:37,333 Epoch[42] Batch [340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092415,	
2017-06-28 01:13:41,846 Epoch[42] Batch [350]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092574,	
2017-06-28 01:13:46,402 Epoch[42] Batch [360]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092606,	
2017-06-28 01:13:51,202 Epoch[42] Batch [370]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092551,	
2017-06-28 01:13:55,880 Epoch[42] Batch [380]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.092290,	
2017-06-28 01:14:00,359 Epoch[42] Batch [390]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.092268,	
2017-06-28 01:14:05,251 Epoch[42] Batch [400]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.092290,	
2017-06-28 01:14:09,843 Epoch[42] Batch [410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092210,	
2017-06-28 01:14:14,520 Epoch[42] Batch [420]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091954,	
2017-06-28 01:14:19,438 Epoch[42] Batch [430]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.092061,	
2017-06-28 01:14:24,271 Epoch[42] Batch [440]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.092115,	
2017-06-28 01:14:29,221 Epoch[42] Batch [450]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.092269,	
2017-06-28 01:14:33,806 Epoch[42] Batch [460]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092201,	
2017-06-28 01:14:38,225 Epoch[42] Batch [470]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.092114,	
2017-06-28 01:14:42,800 Epoch[42] Batch [480]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092301,	
2017-06-28 01:14:47,576 Epoch[42] Batch [490]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.092342,	
2017-06-28 01:14:52,292 Epoch[42] Batch [500]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.092550,	
2017-06-28 01:14:57,191 Epoch[42] Batch [510]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.092374,	
2017-06-28 01:15:02,044 Epoch[42] Batch [520]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.092423,	
2017-06-28 01:15:06,784 Epoch[42] Batch [530]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092493,	
2017-06-28 01:15:11,883 Epoch[42] Batch [540]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092440,	
2017-06-28 01:15:16,509 Epoch[42] Batch [550]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.092557,	
2017-06-28 01:15:21,029 Epoch[42] Batch [560]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.092392,	
2017-06-28 01:15:25,290 Epoch[42] Batch [570]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.092573,	
2017-06-28 01:15:30,157 Epoch[42] Batch [580]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092624,	
2017-06-28 01:15:34,922 Epoch[42] Batch [590]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.092551,	
2017-06-28 01:15:39,597 Epoch[42] Batch [600]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092493,	
2017-06-28 01:15:44,356 Epoch[42] Batch [610]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092644,	
2017-06-28 01:15:49,031 Epoch[42] Batch [620]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092475,	
2017-06-28 01:15:53,677 Epoch[42] Batch [630]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092503,	
2017-06-28 01:15:58,191 Epoch[42] Batch [640]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092564,	
2017-06-28 01:16:02,682 Epoch[42] Batch [650]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.092675,	
2017-06-28 01:16:07,560 Epoch[42] Batch [660]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.092666,	
2017-06-28 01:16:12,291 Epoch[42] Batch [670]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.092686,	
2017-06-28 01:16:16,755 Epoch[42] Batch [680]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.092659,	
2017-06-28 01:16:21,414 Epoch[42] Batch [690]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092605,	
2017-06-28 01:16:26,116 Epoch[42] Batch [700]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092455,	
2017-06-28 01:16:31,018 Epoch[42] Batch [710]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092382,	
2017-06-28 01:16:35,577 Epoch[42] Batch [720]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.092390,	
2017-06-28 01:16:40,148 Epoch[42] Batch [730]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.092377,	
2017-06-28 01:16:44,837 Epoch[42] Batch [740]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092555,	
2017-06-28 01:16:49,382 Epoch[42] Batch [750]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092534,	
2017-06-28 01:16:53,946 Epoch[42] Batch [760]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092608,	
2017-06-28 01:16:58,546 Epoch[42] Batch [770]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092476,	
2017-06-28 01:17:03,020 Epoch[42] Batch [780]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092525,	
2017-06-28 01:17:07,505 Epoch[42] Batch [790]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.092541,	
2017-06-28 01:17:12,076 Epoch[42] Batch [800]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.092604,	
2017-06-28 01:17:16,622 Epoch[42] Batch [810]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092600,	
2017-06-28 01:17:21,209 Epoch[42] Batch [820]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.092555,	
2017-06-28 01:17:26,047 Epoch[42] Batch [830]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092571,	
2017-06-28 01:17:30,702 Epoch[42] Batch [840]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092520,	
2017-06-28 01:17:35,541 Epoch[42] Batch [850]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092459,	
2017-06-28 01:17:40,258 Epoch[42] Batch [860]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.092575,	
2017-06-28 01:17:44,870 Epoch[42] Batch [870]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092553,	
2017-06-28 01:17:49,278 Epoch[42] Batch [880]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.092564,	
2017-06-28 01:17:53,750 Epoch[42] Batch [890]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.092614,	
2017-06-28 01:17:58,362 Epoch[42] Batch [900]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092613,	
2017-06-28 01:18:02,851 Epoch[42] Batch [910]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.092659,	
2017-06-28 01:18:07,469 Epoch[42] Batch [920]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.092703,	
2017-06-28 01:18:12,114 Epoch[42] Batch [930]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092704,	
2017-06-28 01:18:16,435 Epoch[42] Batch [940]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.092774,	
2017-06-28 01:18:21,283 Epoch[42] Batch [950]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.092728,	
2017-06-28 01:18:26,293 Epoch[42] Batch [960]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.092798,	
2017-06-28 01:18:31,044 Epoch[42] Batch [970]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092820,	
2017-06-28 01:18:35,637 Epoch[42] Batch [980]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.092907,	
2017-06-28 01:18:40,211 Epoch[42] Batch [990]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.092952,	
2017-06-28 01:18:44,737 Epoch[42] Batch [1000]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092953,	
2017-06-28 01:18:49,114 Epoch[42] Batch [1010]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.092932,	
2017-06-28 01:18:53,912 Epoch[42] Batch [1020]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.092917,	
2017-06-28 01:18:58,736 Epoch[42] Batch [1030]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092999,	
2017-06-28 01:19:03,296 Epoch[42] Batch [1040]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092951,	
2017-06-28 01:19:07,758 Epoch[42] Batch [1050]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.092902,	
2017-06-28 01:19:12,088 Epoch[42] Batch [1060]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.092957,	
2017-06-28 01:19:16,525 Epoch[42] Batch [1070]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.092959,	
2017-06-28 01:19:21,196 Epoch[42] Batch [1080]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.092963,	
2017-06-28 01:19:25,680 Epoch[42] Batch [1090]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.092915,	
2017-06-28 01:19:30,488 Epoch[42] Batch [1100]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092910,	
2017-06-28 01:19:35,062 Epoch[42] Batch [1110]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.092948,	
2017-06-28 01:19:39,819 Epoch[42] Batch [1120]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092906,	
2017-06-28 01:19:44,454 Epoch[42] Batch [1130]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.092794,	
2017-06-28 01:19:49,115 Epoch[42] Batch [1140]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.092786,	
2017-06-28 01:19:53,655 Epoch[42] Batch [1150]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092764,	
2017-06-28 01:19:58,257 Epoch[42] Batch [1160]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092749,	
2017-06-28 01:20:02,665 Epoch[42] Batch [1170]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.092746,	
2017-06-28 01:20:07,231 Epoch[42] Batch [1180]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.092676,	
2017-06-28 01:20:11,873 Epoch[42] Batch [1190]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092635,	
2017-06-28 01:20:16,288 Epoch[42] Batch [1200]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.092609,	
2017-06-28 01:20:20,653 Epoch[42] Batch [1210]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.092542,	
2017-06-28 01:20:25,180 Epoch[42] Batch [1220]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092558,	
2017-06-28 01:20:29,779 Epoch[42] Batch [1230]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092544,	
2017-06-28 01:20:34,754 Epoch[42] Batch [1240]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.092479,	
2017-06-28 01:20:39,303 Epoch[42] Batch [1250]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.092391,	
2017-06-28 01:20:43,833 Epoch[42] Batch [1260]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.092361,	
2017-06-28 01:20:48,569 Epoch[42] Batch [1270]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.092422,	
2017-06-28 01:20:53,092 Epoch[42] Batch [1280]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.092338,	
2017-06-28 01:20:57,501 Epoch[42] Batch [1290]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.092295,	
2017-06-28 01:21:01,888 Epoch[42] Batch [1300]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.092261,	
2017-06-28 01:21:06,428 Epoch[42] Batch [1310]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092253,	
2017-06-28 01:21:11,144 Epoch[42] Batch [1320]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.092328,	
2017-06-28 01:21:15,741 Epoch[42] Batch [1330]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.092312,	
2017-06-28 01:21:20,428 Epoch[42] Batch [1340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092324,	
2017-06-28 01:21:24,879 Epoch[42] Batch [1350]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.092375,	
2017-06-28 01:21:29,228 Epoch[42] Batch [1360]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.092339,	
2017-06-28 01:21:33,628 Epoch[42] Batch [1370]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.092277,	
2017-06-28 01:21:38,054 Epoch[42] Batch [1380]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.092264,	
2017-06-28 01:21:42,803 Epoch[42] Batch [1390]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.092271,	
2017-06-28 01:21:47,525 Epoch[42] Batch [1400]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092284,	
2017-06-28 01:21:52,209 Epoch[42] Batch [1410]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092310,	
2017-06-28 01:21:56,604 Epoch[42] Batch [1420]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.092294,	
2017-06-28 01:22:01,183 Epoch[42] Batch [1430]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092268,	
2017-06-28 01:22:05,769 Epoch[42] Batch [1440]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092199,	
2017-06-28 01:22:10,451 Epoch[42] Batch [1450]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092141,	
2017-06-28 01:22:15,275 Epoch[42] Batch [1460]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092124,	
2017-06-28 01:22:19,799 Epoch[42] Batch [1470]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092185,	
2017-06-28 01:22:24,517 Epoch[42] Batch [1480]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.092191,	
2017-06-28 01:22:27,131 Epoch[42] Train-FCNLogLoss=0.092181
2017-06-28 01:22:27,131 Epoch[42] Time cost=686.041
2017-06-28 01:22:27,789 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0043.params"
2017-06-28 01:22:29,269 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0043.states"
2017-06-28 01:22:34,793 Epoch[43] Batch [10]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.097891,	
2017-06-28 01:22:39,287 Epoch[43] Batch [20]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089929,	
2017-06-28 01:22:43,998 Epoch[43] Batch [30]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.093006,	
2017-06-28 01:22:48,729 Epoch[43] Batch [40]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.093063,	
2017-06-28 01:22:53,391 Epoch[43] Batch [50]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.093906,	
2017-06-28 01:22:58,110 Epoch[43] Batch [60]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.092537,	
2017-06-28 01:23:02,959 Epoch[43] Batch [70]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.092096,	
2017-06-28 01:23:07,463 Epoch[43] Batch [80]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.092483,	
2017-06-28 01:23:11,939 Epoch[43] Batch [90]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.092919,	
2017-06-28 01:23:16,409 Epoch[43] Batch [100]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.093204,	
2017-06-28 01:23:20,734 Epoch[43] Batch [110]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.092550,	
2017-06-28 01:23:25,377 Epoch[43] Batch [120]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.092206,	
2017-06-28 01:23:29,899 Epoch[43] Batch [130]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.092001,	
2017-06-28 01:23:34,426 Epoch[43] Batch [140]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091868,	
2017-06-28 01:23:39,235 Epoch[43] Batch [150]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.092305,	
2017-06-28 01:23:43,723 Epoch[43] Batch [160]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.092354,	
2017-06-28 01:23:48,200 Epoch[43] Batch [170]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091948,	
2017-06-28 01:23:52,830 Epoch[43] Batch [180]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091693,	
2017-06-28 01:23:57,328 Epoch[43] Batch [190]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091429,	
2017-06-28 01:24:02,000 Epoch[43] Batch [200]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090776,	
2017-06-28 01:24:06,385 Epoch[43] Batch [210]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090757,	
2017-06-28 01:24:11,196 Epoch[43] Batch [220]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.090549,	
2017-06-28 01:24:15,897 Epoch[43] Batch [230]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.090708,	
2017-06-28 01:24:20,707 Epoch[43] Batch [240]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.090749,	
2017-06-28 01:24:25,576 Epoch[43] Batch [250]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.090786,	
2017-06-28 01:24:30,099 Epoch[43] Batch [260]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.090671,	
2017-06-28 01:24:34,818 Epoch[43] Batch [270]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090383,	
2017-06-28 01:24:39,537 Epoch[43] Batch [280]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090226,	
2017-06-28 01:24:44,127 Epoch[43] Batch [290]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.089861,	
2017-06-28 01:24:48,536 Epoch[43] Batch [300]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089549,	
2017-06-28 01:24:53,224 Epoch[43] Batch [310]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089337,	
2017-06-28 01:24:57,934 Epoch[43] Batch [320]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089891,	
2017-06-28 01:25:02,634 Epoch[43] Batch [330]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089422,	
2017-06-28 01:25:06,987 Epoch[43] Batch [340]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.089613,	
2017-06-28 01:25:11,378 Epoch[43] Batch [350]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.089627,	
2017-06-28 01:25:16,232 Epoch[43] Batch [360]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.089534,	
2017-06-28 01:25:20,691 Epoch[43] Batch [370]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.089585,	
2017-06-28 01:25:25,253 Epoch[43] Batch [380]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089522,	
2017-06-28 01:25:29,941 Epoch[43] Batch [390]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089554,	
2017-06-28 01:25:34,691 Epoch[43] Batch [400]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089659,	
2017-06-28 01:25:39,575 Epoch[43] Batch [410]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.089439,	
2017-06-28 01:25:44,222 Epoch[43] Batch [420]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089200,	
2017-06-28 01:25:48,848 Epoch[43] Batch [430]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089305,	
2017-06-28 01:25:53,499 Epoch[43] Batch [440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089259,	
2017-06-28 01:25:58,095 Epoch[43] Batch [450]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089415,	
2017-06-28 01:26:02,689 Epoch[43] Batch [460]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089488,	
2017-06-28 01:26:07,277 Epoch[43] Batch [470]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.089749,	
2017-06-28 01:26:11,849 Epoch[43] Batch [480]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.089683,	
2017-06-28 01:26:16,486 Epoch[43] Batch [490]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089509,	
2017-06-28 01:26:21,013 Epoch[43] Batch [500]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089620,	
2017-06-28 01:26:25,726 Epoch[43] Batch [510]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089768,	
2017-06-28 01:26:30,352 Epoch[43] Batch [520]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089565,	
2017-06-28 01:26:34,803 Epoch[43] Batch [530]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.089529,	
2017-06-28 01:26:39,544 Epoch[43] Batch [540]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089371,	
2017-06-28 01:26:44,164 Epoch[43] Batch [550]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.089261,	
2017-06-28 01:26:49,083 Epoch[43] Batch [560]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-28 01:26:53,763 Epoch[43] Batch [570]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089416,	
2017-06-28 01:26:58,269 Epoch[43] Batch [580]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089461,	
2017-06-28 01:27:02,797 Epoch[43] Batch [590]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089500,	
2017-06-28 01:27:07,446 Epoch[43] Batch [600]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089469,	
2017-06-28 01:27:11,725 Epoch[43] Batch [610]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.089445,	
2017-06-28 01:27:16,320 Epoch[43] Batch [620]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089367,	
2017-06-28 01:27:21,174 Epoch[43] Batch [630]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.089426,	
2017-06-28 01:27:25,739 Epoch[43] Batch [640]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089574,	
2017-06-28 01:27:30,228 Epoch[43] Batch [650]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.089524,	
2017-06-28 01:27:34,669 Epoch[43] Batch [660]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.089495,	
2017-06-28 01:27:39,415 Epoch[43] Batch [670]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089593,	
2017-06-28 01:27:44,046 Epoch[43] Batch [680]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089663,	
2017-06-28 01:27:48,841 Epoch[43] Batch [690]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089715,	
2017-06-28 01:27:53,258 Epoch[43] Batch [700]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.089754,	
2017-06-28 01:27:57,795 Epoch[43] Batch [710]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.089875,	
2017-06-28 01:28:02,048 Epoch[43] Batch [720]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.089869,	
2017-06-28 01:28:06,381 Epoch[43] Batch [730]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.089877,	
2017-06-28 01:28:10,814 Epoch[43] Batch [740]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.089905,	
2017-06-28 01:28:15,803 Epoch[43] Batch [750]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089797,	
2017-06-28 01:28:20,613 Epoch[43] Batch [760]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089847,	
2017-06-28 01:28:25,261 Epoch[43] Batch [770]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089803,	
2017-06-28 01:28:29,963 Epoch[43] Batch [780]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089845,	
2017-06-28 01:28:34,513 Epoch[43] Batch [790]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089827,	
2017-06-28 01:28:39,125 Epoch[43] Batch [800]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.089839,	
2017-06-28 01:28:43,805 Epoch[43] Batch [810]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089780,	
2017-06-28 01:28:48,460 Epoch[43] Batch [820]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089785,	
2017-06-28 01:28:53,061 Epoch[43] Batch [830]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089814,	
2017-06-28 01:28:57,694 Epoch[43] Batch [840]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089804,	
2017-06-28 01:29:02,071 Epoch[43] Batch [850]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.089722,	
2017-06-28 01:29:06,526 Epoch[43] Batch [860]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.089721,	
2017-06-28 01:29:11,210 Epoch[43] Batch [870]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089663,	
2017-06-28 01:29:15,636 Epoch[43] Batch [880]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.089763,	
2017-06-28 01:29:20,181 Epoch[43] Batch [890]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089808,	
2017-06-28 01:29:24,781 Epoch[43] Batch [900]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089705,	
2017-06-28 01:29:29,165 Epoch[43] Batch [910]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.089687,	
2017-06-28 01:29:33,550 Epoch[43] Batch [920]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.089717,	
2017-06-28 01:29:38,236 Epoch[43] Batch [930]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089662,	
2017-06-28 01:29:42,973 Epoch[43] Batch [940]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089788,	
2017-06-28 01:29:47,541 Epoch[43] Batch [950]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089729,	
2017-06-28 01:29:52,058 Epoch[43] Batch [960]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089870,	
2017-06-28 01:29:56,729 Epoch[43] Batch [970]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089868,	
2017-06-28 01:30:01,287 Epoch[43] Batch [980]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.089884,	
2017-06-28 01:30:05,922 Epoch[43] Batch [990]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089998,	
2017-06-28 01:30:10,540 Epoch[43] Batch [1000]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090109,	
2017-06-28 01:30:15,465 Epoch[43] Batch [1010]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.090199,	
2017-06-28 01:30:20,066 Epoch[43] Batch [1020]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090277,	
2017-06-28 01:30:24,652 Epoch[43] Batch [1030]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.090360,	
2017-06-28 01:30:29,174 Epoch[43] Batch [1040]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.090358,	
2017-06-28 01:30:33,705 Epoch[43] Batch [1050]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.090406,	
2017-06-28 01:30:38,297 Epoch[43] Batch [1060]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090524,	
2017-06-28 01:30:42,969 Epoch[43] Batch [1070]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090544,	
2017-06-28 01:30:47,557 Epoch[43] Batch [1080]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.090618,	
2017-06-28 01:30:52,411 Epoch[43] Batch [1090]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090709,	
2017-06-28 01:30:57,080 Epoch[43] Batch [1100]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090717,	
2017-06-28 01:31:01,821 Epoch[43] Batch [1110]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090788,	
2017-06-28 01:31:06,508 Epoch[43] Batch [1120]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090811,	
2017-06-28 01:31:10,855 Epoch[43] Batch [1130]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.090792,	
2017-06-28 01:31:15,377 Epoch[43] Batch [1140]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.090758,	
2017-06-28 01:31:20,078 Epoch[43] Batch [1150]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.090796,	
2017-06-28 01:31:24,779 Epoch[43] Batch [1160]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.090707,	
2017-06-28 01:31:29,387 Epoch[43] Batch [1170]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090672,	
2017-06-28 01:31:33,929 Epoch[43] Batch [1180]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090646,	
2017-06-28 01:31:38,310 Epoch[43] Batch [1190]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.090731,	
2017-06-28 01:31:42,771 Epoch[43] Batch [1200]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.090684,	
2017-06-28 01:31:47,377 Epoch[43] Batch [1210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090648,	
2017-06-28 01:31:51,949 Epoch[43] Batch [1220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090659,	
2017-06-28 01:31:56,681 Epoch[43] Batch [1230]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090631,	
2017-06-28 01:32:01,295 Epoch[43] Batch [1240]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.090623,	
2017-06-28 01:32:06,305 Epoch[43] Batch [1250]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.090548,	
2017-06-28 01:32:11,023 Epoch[43] Batch [1260]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090636,	
2017-06-28 01:32:15,812 Epoch[43] Batch [1270]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.090658,	
2017-06-28 01:32:20,477 Epoch[43] Batch [1280]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090693,	
2017-06-28 01:32:25,383 Epoch[43] Batch [1290]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.090728,	
2017-06-28 01:32:30,015 Epoch[43] Batch [1300]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090752,	
2017-06-28 01:32:34,651 Epoch[43] Batch [1310]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090770,	
2017-06-28 01:32:39,375 Epoch[43] Batch [1320]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090798,	
2017-06-28 01:32:43,908 Epoch[43] Batch [1330]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090848,	
2017-06-28 01:32:48,462 Epoch[43] Batch [1340]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090857,	
2017-06-28 01:32:52,936 Epoch[43] Batch [1350]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090928,	
2017-06-28 01:32:57,609 Epoch[43] Batch [1360]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090947,	
2017-06-28 01:33:02,337 Epoch[43] Batch [1370]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090964,	
2017-06-28 01:33:07,009 Epoch[43] Batch [1380]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090991,	
2017-06-28 01:33:11,452 Epoch[43] Batch [1390]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090971,	
2017-06-28 01:33:16,103 Epoch[43] Batch [1400]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090988,	
2017-06-28 01:33:20,705 Epoch[43] Batch [1410]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.091008,	
2017-06-28 01:33:25,233 Epoch[43] Batch [1420]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.090987,	
2017-06-28 01:33:29,804 Epoch[43] Batch [1430]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091039,	
2017-06-28 01:33:34,419 Epoch[43] Batch [1440]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091039,	
2017-06-28 01:33:39,194 Epoch[43] Batch [1450]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.091122,	
2017-06-28 01:33:43,642 Epoch[43] Batch [1460]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091154,	
2017-06-28 01:33:48,152 Epoch[43] Batch [1470]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091216,	
2017-06-28 01:33:52,776 Epoch[43] Batch [1480]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091253,	
2017-06-28 01:33:55,340 Epoch[43] Train-FCNLogLoss=0.091277
2017-06-28 01:33:55,340 Epoch[43] Time cost=686.070
2017-06-28 01:33:56,178 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0044.params"
2017-06-28 01:33:58,429 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0044.states"
2017-06-28 01:34:03,800 Epoch[44] Batch [10]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091658,	
2017-06-28 01:34:08,278 Epoch[44] Batch [20]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.091275,	
2017-06-28 01:34:13,179 Epoch[44] Batch [30]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.092185,	
2017-06-28 01:34:17,678 Epoch[44] Batch [40]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090512,	
2017-06-28 01:34:22,007 Epoch[44] Batch [50]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.089637,	
2017-06-28 01:34:26,766 Epoch[44] Batch [60]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090276,	
2017-06-28 01:34:31,339 Epoch[44] Batch [70]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.092307,	
2017-06-28 01:34:35,919 Epoch[44] Batch [80]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091048,	
2017-06-28 01:34:40,412 Epoch[44] Batch [90]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090700,	
2017-06-28 01:34:45,122 Epoch[44] Batch [100]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090068,	
2017-06-28 01:34:49,696 Epoch[44] Batch [110]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090339,	
2017-06-28 01:34:54,605 Epoch[44] Batch [120]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.090109,	
2017-06-28 01:34:59,176 Epoch[44] Batch [130]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090983,	
2017-06-28 01:35:03,516 Epoch[44] Batch [140]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.090957,	
2017-06-28 01:35:07,820 Epoch[44] Batch [150]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.090916,	
2017-06-28 01:35:12,576 Epoch[44] Batch [160]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.091210,	
2017-06-28 01:35:17,104 Epoch[44] Batch [170]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.090798,	
2017-06-28 01:35:21,612 Epoch[44] Batch [180]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.090510,	
2017-06-28 01:35:26,012 Epoch[44] Batch [190]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.090815,	
2017-06-28 01:35:30,505 Epoch[44] Batch [200]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090586,	
2017-06-28 01:35:34,920 Epoch[44] Batch [210]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.090937,	
2017-06-28 01:35:39,456 Epoch[44] Batch [220]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090892,	
2017-06-28 01:35:43,964 Epoch[44] Batch [230]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.090976,	
2017-06-28 01:35:48,572 Epoch[44] Batch [240]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091092,	
2017-06-28 01:35:53,214 Epoch[44] Batch [250]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.090971,	
2017-06-28 01:35:57,654 Epoch[44] Batch [260]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.091198,	
2017-06-28 01:36:02,251 Epoch[44] Batch [270]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091123,	
2017-06-28 01:36:06,648 Epoch[44] Batch [280]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090940,	
2017-06-28 01:36:11,358 Epoch[44] Batch [290]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090762,	
2017-06-28 01:36:16,270 Epoch[44] Batch [300]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.090968,	
2017-06-28 01:36:20,999 Epoch[44] Batch [310]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090959,	
2017-06-28 01:36:25,516 Epoch[44] Batch [320]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091264,	
2017-06-28 01:36:30,094 Epoch[44] Batch [330]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091377,	
2017-06-28 01:36:34,854 Epoch[44] Batch [340]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090919,	
2017-06-28 01:36:39,790 Epoch[44] Batch [350]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.091097,	
2017-06-28 01:36:44,436 Epoch[44] Batch [360]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091038,	
2017-06-28 01:36:49,127 Epoch[44] Batch [370]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.091312,	
2017-06-28 01:36:53,702 Epoch[44] Batch [380]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091278,	
2017-06-28 01:36:58,663 Epoch[44] Batch [390]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.091356,	
2017-06-28 01:37:03,243 Epoch[44] Batch [400]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091453,	
2017-06-28 01:37:08,317 Epoch[44] Batch [410]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.091509,	
2017-06-28 01:37:12,955 Epoch[44] Batch [420]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091372,	
2017-06-28 01:37:17,667 Epoch[44] Batch [430]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.091344,	
2017-06-28 01:37:22,342 Epoch[44] Batch [440]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.091265,	
2017-06-28 01:37:27,279 Epoch[44] Batch [450]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.091120,	
2017-06-28 01:37:32,024 Epoch[44] Batch [460]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.091234,	
2017-06-28 01:37:36,572 Epoch[44] Batch [470]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091166,	
2017-06-28 01:37:41,277 Epoch[44] Batch [480]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091080,	
2017-06-28 01:37:46,143 Epoch[44] Batch [490]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.091128,	
2017-06-28 01:37:50,685 Epoch[44] Batch [500]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.091133,	
2017-06-28 01:37:55,248 Epoch[44] Batch [510]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091083,	
2017-06-28 01:37:59,856 Epoch[44] Batch [520]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091096,	
2017-06-28 01:38:04,408 Epoch[44] Batch [530]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091174,	
2017-06-28 01:38:09,091 Epoch[44] Batch [540]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.091087,	
2017-06-28 01:38:13,422 Epoch[44] Batch [550]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.091103,	
2017-06-28 01:38:17,714 Epoch[44] Batch [560]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.090929,	
2017-06-28 01:38:22,400 Epoch[44] Batch [570]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090983,	
2017-06-28 01:38:27,048 Epoch[44] Batch [580]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090950,	
2017-06-28 01:38:31,761 Epoch[44] Batch [590]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090886,	
2017-06-28 01:38:36,441 Epoch[44] Batch [600]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091043,	
2017-06-28 01:38:41,084 Epoch[44] Batch [610]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091054,	
2017-06-28 01:38:45,807 Epoch[44] Batch [620]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.091077,	
2017-06-28 01:38:50,852 Epoch[44] Batch [630]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.090980,	
2017-06-28 01:38:55,478 Epoch[44] Batch [640]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091129,	
2017-06-28 01:38:59,951 Epoch[44] Batch [650]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091159,	
2017-06-28 01:39:04,688 Epoch[44] Batch [660]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.091033,	
2017-06-28 01:39:09,445 Epoch[44] Batch [670]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090993,	
2017-06-28 01:39:14,086 Epoch[44] Batch [680]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091043,	
2017-06-28 01:39:18,561 Epoch[44] Batch [690]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090945,	
2017-06-28 01:39:23,186 Epoch[44] Batch [700]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091090,	
2017-06-28 01:39:28,013 Epoch[44] Batch [710]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091064,	
2017-06-28 01:39:32,524 Epoch[44] Batch [720]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091059,	
2017-06-28 01:39:37,160 Epoch[44] Batch [730]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.091162,	
2017-06-28 01:39:41,403 Epoch[44] Batch [740]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.091200,	
2017-06-28 01:39:45,741 Epoch[44] Batch [750]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.091270,	
2017-06-28 01:39:50,284 Epoch[44] Batch [760]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.091226,	
2017-06-28 01:39:55,157 Epoch[44] Batch [770]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.091188,	
2017-06-28 01:39:59,779 Epoch[44] Batch [780]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091165,	
2017-06-28 01:40:04,624 Epoch[44] Batch [790]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091023,	
2017-06-28 01:40:09,273 Epoch[44] Batch [800]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090970,	
2017-06-28 01:40:13,724 Epoch[44] Batch [810]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.090956,	
2017-06-28 01:40:18,540 Epoch[44] Batch [820]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.091045,	
2017-06-28 01:40:23,195 Epoch[44] Batch [830]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091053,	
2017-06-28 01:40:27,975 Epoch[44] Batch [840]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.091131,	
2017-06-28 01:40:32,610 Epoch[44] Batch [850]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.091146,	
2017-06-28 01:40:37,206 Epoch[44] Batch [860]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091217,	
2017-06-28 01:40:42,296 Epoch[44] Batch [870]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.091207,	
2017-06-28 01:40:46,942 Epoch[44] Batch [880]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091124,	
2017-06-28 01:40:51,551 Epoch[44] Batch [890]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091160,	
2017-06-28 01:40:56,053 Epoch[44] Batch [900]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.091275,	
2017-06-28 01:41:00,703 Epoch[44] Batch [910]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091219,	
2017-06-28 01:41:05,374 Epoch[44] Batch [920]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.091245,	
2017-06-28 01:41:10,368 Epoch[44] Batch [930]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.091324,	
2017-06-28 01:41:14,753 Epoch[44] Batch [940]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.091253,	
2017-06-28 01:41:19,130 Epoch[44] Batch [950]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.091307,	
2017-06-28 01:41:23,368 Epoch[44] Batch [960]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091260,	
2017-06-28 01:41:27,876 Epoch[44] Batch [970]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091333,	
2017-06-28 01:41:32,584 Epoch[44] Batch [980]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091299,	
2017-06-28 01:41:37,225 Epoch[44] Batch [990]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091250,	
2017-06-28 01:41:41,799 Epoch[44] Batch [1000]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091314,	
2017-06-28 01:41:46,570 Epoch[44] Batch [1010]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.091317,	
2017-06-28 01:41:51,212 Epoch[44] Batch [1020]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091388,	
2017-06-28 01:41:55,798 Epoch[44] Batch [1030]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091369,	
2017-06-28 01:42:00,323 Epoch[44] Batch [1040]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091335,	
2017-06-28 01:42:04,968 Epoch[44] Batch [1050]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091339,	
2017-06-28 01:42:09,597 Epoch[44] Batch [1060]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091333,	
2017-06-28 01:42:14,015 Epoch[44] Batch [1070]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.091285,	
2017-06-28 01:42:18,740 Epoch[44] Batch [1080]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.091275,	
2017-06-28 01:42:23,505 Epoch[44] Batch [1090]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091221,	
2017-06-28 01:42:28,119 Epoch[44] Batch [1100]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091099,	
2017-06-28 01:42:32,670 Epoch[44] Batch [1110]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091007,	
2017-06-28 01:42:37,174 Epoch[44] Batch [1120]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.090983,	
2017-06-28 01:42:41,773 Epoch[44] Batch [1130]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090972,	
2017-06-28 01:42:46,713 Epoch[44] Batch [1140]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.090934,	
2017-06-28 01:42:51,403 Epoch[44] Batch [1150]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090927,	
2017-06-28 01:42:55,741 Epoch[44] Batch [1160]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.090927,	
2017-06-28 01:43:00,113 Epoch[44] Batch [1170]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.090929,	
2017-06-28 01:43:04,525 Epoch[44] Batch [1180]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.090937,	
2017-06-28 01:43:08,970 Epoch[44] Batch [1190]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090905,	
2017-06-28 01:43:13,446 Epoch[44] Batch [1200]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090862,	
2017-06-28 01:43:18,050 Epoch[44] Batch [1210]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090915,	
2017-06-28 01:43:22,760 Epoch[44] Batch [1220]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090859,	
2017-06-28 01:43:27,488 Epoch[44] Batch [1230]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090823,	
2017-06-28 01:43:32,094 Epoch[44] Batch [1240]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090827,	
2017-06-28 01:43:36,857 Epoch[44] Batch [1250]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.090771,	
2017-06-28 01:43:41,499 Epoch[44] Batch [1260]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.090790,	
2017-06-28 01:43:46,197 Epoch[44] Batch [1270]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090838,	
2017-06-28 01:43:50,885 Epoch[44] Batch [1280]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090896,	
2017-06-28 01:43:55,386 Epoch[44] Batch [1290]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091013,	
2017-06-28 01:44:00,128 Epoch[44] Batch [1300]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.091008,	
2017-06-28 01:44:04,810 Epoch[44] Batch [1310]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090964,	
2017-06-28 01:44:09,762 Epoch[44] Batch [1320]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.090997,	
2017-06-28 01:44:14,470 Epoch[44] Batch [1330]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.090972,	
2017-06-28 01:44:19,138 Epoch[44] Batch [1340]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090975,	
2017-06-28 01:44:23,475 Epoch[44] Batch [1350]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.090915,	
2017-06-28 01:44:28,291 Epoch[44] Batch [1360]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.090956,	
2017-06-28 01:44:33,142 Epoch[44] Batch [1370]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.090937,	
2017-06-28 01:44:37,916 Epoch[44] Batch [1380]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.090903,	
2017-06-28 01:44:42,651 Epoch[44] Batch [1390]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090969,	
2017-06-28 01:44:47,297 Epoch[44] Batch [1400]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090905,	
2017-06-28 01:44:51,835 Epoch[44] Batch [1410]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090944,	
2017-06-28 01:44:56,373 Epoch[44] Batch [1420]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090916,	
2017-06-28 01:45:00,779 Epoch[44] Batch [1430]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.090918,	
2017-06-28 01:45:05,277 Epoch[44] Batch [1440]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090898,	
2017-06-28 01:45:10,071 Epoch[44] Batch [1450]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.090775,	
2017-06-28 01:45:14,739 Epoch[44] Batch [1460]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090837,	
2017-06-28 01:45:19,476 Epoch[44] Batch [1470]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090781,	
2017-06-28 01:45:23,783 Epoch[44] Batch [1480]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.090807,	
2017-06-28 01:45:26,333 Epoch[44] Train-FCNLogLoss=0.090755
2017-06-28 01:45:26,333 Epoch[44] Time cost=687.904
2017-06-28 01:45:27,152 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0045.params"
2017-06-28 01:45:28,942 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0045.states"
2017-06-28 01:45:34,214 Epoch[45] Batch [10]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091047,	
2017-06-28 01:45:38,642 Epoch[45] Batch [20]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.090434,	
2017-06-28 01:45:43,296 Epoch[45] Batch [30]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.092301,	
2017-06-28 01:45:47,794 Epoch[45] Batch [40]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.093653,	
2017-06-28 01:45:52,554 Epoch[45] Batch [50]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.093787,	
2017-06-28 01:45:57,070 Epoch[45] Batch [60]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.092806,	
2017-06-28 01:46:01,616 Epoch[45] Batch [70]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.092591,	
2017-06-28 01:46:06,401 Epoch[45] Batch [80]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.091958,	
2017-06-28 01:46:10,892 Epoch[45] Batch [90]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091852,	
2017-06-28 01:46:15,419 Epoch[45] Batch [100]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.092363,	
2017-06-28 01:46:19,976 Epoch[45] Batch [110]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.093403,	
2017-06-28 01:46:24,579 Epoch[45] Batch [120]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092951,	
2017-06-28 01:46:29,309 Epoch[45] Batch [130]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.093571,	
2017-06-28 01:46:34,165 Epoch[45] Batch [140]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.094051,	
2017-06-28 01:46:39,094 Epoch[45] Batch [150]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.093430,	
2017-06-28 01:46:43,835 Epoch[45] Batch [160]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.093781,	
2017-06-28 01:46:48,687 Epoch[45] Batch [170]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.094090,	
2017-06-28 01:46:53,197 Epoch[45] Batch [180]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.094012,	
2017-06-28 01:46:57,942 Epoch[45] Batch [190]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.093645,	
2017-06-28 01:47:02,569 Epoch[45] Batch [200]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.093253,	
2017-06-28 01:47:07,116 Epoch[45] Batch [210]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.093325,	
2017-06-28 01:47:11,779 Epoch[45] Batch [220]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.093282,	
2017-06-28 01:47:16,332 Epoch[45] Batch [230]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.093313,	
2017-06-28 01:47:20,844 Epoch[45] Batch [240]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.092418,	
2017-06-28 01:47:25,645 Epoch[45] Batch [250]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.092226,	
2017-06-28 01:47:30,174 Epoch[45] Batch [260]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.092166,	
2017-06-28 01:47:34,863 Epoch[45] Batch [270]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.092250,	
2017-06-28 01:47:39,530 Epoch[45] Batch [280]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.092230,	
2017-06-28 01:47:43,838 Epoch[45] Batch [290]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.091961,	
2017-06-28 01:47:48,457 Epoch[45] Batch [300]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091982,	
2017-06-28 01:47:53,251 Epoch[45] Batch [310]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.091762,	
2017-06-28 01:47:57,642 Epoch[45] Batch [320]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.092030,	
2017-06-28 01:48:02,239 Epoch[45] Batch [330]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091982,	
2017-06-28 01:48:06,841 Epoch[45] Batch [340]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.091696,	
2017-06-28 01:48:11,567 Epoch[45] Batch [350]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091881,	
2017-06-28 01:48:16,114 Epoch[45] Batch [360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091708,	
2017-06-28 01:48:20,639 Epoch[45] Batch [370]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091853,	
2017-06-28 01:48:25,461 Epoch[45] Batch [380]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.091841,	
2017-06-28 01:48:30,126 Epoch[45] Batch [390]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091810,	
2017-06-28 01:48:34,977 Epoch[45] Batch [400]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091707,	
2017-06-28 01:48:39,821 Epoch[45] Batch [410]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091680,	
2017-06-28 01:48:44,466 Epoch[45] Batch [420]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091361,	
2017-06-28 01:48:49,240 Epoch[45] Batch [430]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.091356,	
2017-06-28 01:48:54,014 Epoch[45] Batch [440]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.091265,	
2017-06-28 01:48:58,718 Epoch[45] Batch [450]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091410,	
2017-06-28 01:49:03,299 Epoch[45] Batch [460]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091119,	
2017-06-28 01:49:08,189 Epoch[45] Batch [470]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.091142,	
2017-06-28 01:49:12,840 Epoch[45] Batch [480]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091092,	
2017-06-28 01:49:17,604 Epoch[45] Batch [490]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.091167,	
2017-06-28 01:49:22,251 Epoch[45] Batch [500]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091137,	
2017-06-28 01:49:26,645 Epoch[45] Batch [510]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.091354,	
2017-06-28 01:49:31,193 Epoch[45] Batch [520]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091487,	
2017-06-28 01:49:35,688 Epoch[45] Batch [530]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091583,	
2017-06-28 01:49:40,363 Epoch[45] Batch [540]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.091646,	
2017-06-28 01:49:45,281 Epoch[45] Batch [550]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.091672,	
2017-06-28 01:49:49,836 Epoch[45] Batch [560]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091743,	
2017-06-28 01:49:54,265 Epoch[45] Batch [570]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.091772,	
2017-06-28 01:49:58,922 Epoch[45] Batch [580]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091696,	
2017-06-28 01:50:03,476 Epoch[45] Batch [590]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091501,	
2017-06-28 01:50:08,193 Epoch[45] Batch [600]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091514,	
2017-06-28 01:50:12,910 Epoch[45] Batch [610]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091615,	
2017-06-28 01:50:17,802 Epoch[45] Batch [620]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.091504,	
2017-06-28 01:50:22,220 Epoch[45] Batch [630]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.091423,	
2017-06-28 01:50:27,081 Epoch[45] Batch [640]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.091530,	
2017-06-28 01:50:31,716 Epoch[45] Batch [650]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.091404,	
2017-06-28 01:50:36,539 Epoch[45] Batch [660]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091632,	
2017-06-28 01:50:41,385 Epoch[45] Batch [670]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091576,	
2017-06-28 01:50:45,986 Epoch[45] Batch [680]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.091519,	
2017-06-28 01:50:50,300 Epoch[45] Batch [690]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.091405,	
2017-06-28 01:50:54,639 Epoch[45] Batch [700]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.091436,	
2017-06-28 01:50:59,250 Epoch[45] Batch [710]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091614,	
2017-06-28 01:51:03,839 Epoch[45] Batch [720]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091624,	
2017-06-28 01:51:08,377 Epoch[45] Batch [730]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.091625,	
2017-06-28 01:51:12,998 Epoch[45] Batch [740]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091480,	
2017-06-28 01:51:17,404 Epoch[45] Batch [750]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.091514,	
2017-06-28 01:51:21,729 Epoch[45] Batch [760]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.091433,	
2017-06-28 01:51:25,947 Epoch[45] Batch [770]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.091474,	
2017-06-28 01:51:30,395 Epoch[45] Batch [780]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091387,	
2017-06-28 01:51:35,095 Epoch[45] Batch [790]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091458,	
2017-06-28 01:51:39,424 Epoch[45] Batch [800]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.091344,	
2017-06-28 01:51:44,195 Epoch[45] Batch [810]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.091324,	
2017-06-28 01:51:48,755 Epoch[45] Batch [820]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091359,	
2017-06-28 01:51:53,480 Epoch[45] Batch [830]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.091372,	
2017-06-28 01:51:58,201 Epoch[45] Batch [840]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.091351,	
2017-06-28 01:52:02,995 Epoch[45] Batch [850]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.091364,	
2017-06-28 01:52:07,623 Epoch[45] Batch [860]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091398,	
2017-06-28 01:52:12,000 Epoch[45] Batch [870]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.091400,	
2017-06-28 01:52:16,563 Epoch[45] Batch [880]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091455,	
2017-06-28 01:52:21,245 Epoch[45] Batch [890]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091430,	
2017-06-28 01:52:26,000 Epoch[45] Batch [900]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.091611,	
2017-06-28 01:52:30,494 Epoch[45] Batch [910]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.091685,	
2017-06-28 01:52:35,243 Epoch[45] Batch [920]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.091776,	
2017-06-28 01:52:40,093 Epoch[45] Batch [930]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091721,	
2017-06-28 01:52:44,670 Epoch[45] Batch [940]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091671,	
2017-06-28 01:52:49,183 Epoch[45] Batch [950]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091700,	
2017-06-28 01:52:54,146 Epoch[45] Batch [960]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.091633,	
2017-06-28 01:52:58,747 Epoch[45] Batch [970]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091666,	
2017-06-28 01:53:03,058 Epoch[45] Batch [980]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.091627,	
2017-06-28 01:53:07,618 Epoch[45] Batch [990]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091634,	
2017-06-28 01:53:12,294 Epoch[45] Batch [1000]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.091629,	
2017-06-28 01:53:16,773 Epoch[45] Batch [1010]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.091605,	
2017-06-28 01:53:21,539 Epoch[45] Batch [1020]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091473,	
2017-06-28 01:53:26,308 Epoch[45] Batch [1030]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.091439,	
2017-06-28 01:53:31,027 Epoch[45] Batch [1040]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.091413,	
2017-06-28 01:53:35,695 Epoch[45] Batch [1050]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.091413,	
2017-06-28 01:53:40,381 Epoch[45] Batch [1060]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.091358,	
2017-06-28 01:53:45,258 Epoch[45] Batch [1070]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.091364,	
2017-06-28 01:53:49,759 Epoch[45] Batch [1080]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091368,	
2017-06-28 01:53:54,545 Epoch[45] Batch [1090]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.091340,	
2017-06-28 01:53:59,395 Epoch[45] Batch [1100]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091344,	
2017-06-28 01:54:03,906 Epoch[45] Batch [1110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091396,	
2017-06-28 01:54:08,357 Epoch[45] Batch [1120]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091432,	
2017-06-28 01:54:13,049 Epoch[45] Batch [1130]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091411,	
2017-06-28 01:54:17,729 Epoch[45] Batch [1140]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091513,	
2017-06-28 01:54:22,371 Epoch[45] Batch [1150]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091569,	
2017-06-28 01:54:26,986 Epoch[45] Batch [1160]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091636,	
2017-06-28 01:54:31,490 Epoch[45] Batch [1170]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.091598,	
2017-06-28 01:54:36,127 Epoch[45] Batch [1180]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.091629,	
2017-06-28 01:54:40,754 Epoch[45] Batch [1190]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091650,	
2017-06-28 01:54:45,483 Epoch[45] Batch [1200]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091622,	
2017-06-28 01:54:50,231 Epoch[45] Batch [1210]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.091639,	
2017-06-28 01:54:54,935 Epoch[45] Batch [1220]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091613,	
2017-06-28 01:54:59,601 Epoch[45] Batch [1230]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.091638,	
2017-06-28 01:55:04,186 Epoch[45] Batch [1240]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091607,	
2017-06-28 01:55:08,773 Epoch[45] Batch [1250]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091564,	
2017-06-28 01:55:13,459 Epoch[45] Batch [1260]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.091504,	
2017-06-28 01:55:18,379 Epoch[45] Batch [1270]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.091415,	
2017-06-28 01:55:23,358 Epoch[45] Batch [1280]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.091374,	
2017-06-28 01:55:27,805 Epoch[45] Batch [1290]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.091407,	
2017-06-28 01:55:32,322 Epoch[45] Batch [1300]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091419,	
2017-06-28 01:55:36,911 Epoch[45] Batch [1310]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091406,	
2017-06-28 01:55:41,496 Epoch[45] Batch [1320]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091473,	
2017-06-28 01:55:46,168 Epoch[45] Batch [1330]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.091391,	
2017-06-28 01:55:51,128 Epoch[45] Batch [1340]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.091363,	
2017-06-28 01:55:55,529 Epoch[45] Batch [1350]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.091312,	
2017-06-28 01:55:59,822 Epoch[45] Batch [1360]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.091305,	
2017-06-28 01:56:04,401 Epoch[45] Batch [1370]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091354,	
2017-06-28 01:56:08,744 Epoch[45] Batch [1380]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.091303,	
2017-06-28 01:56:13,175 Epoch[45] Batch [1390]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.091294,	
2017-06-28 01:56:17,912 Epoch[45] Batch [1400]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.091196,	
2017-06-28 01:56:22,089 Epoch[45] Batch [1410]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.091155,	
2017-06-28 01:56:26,223 Epoch[45] Batch [1420]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.091157,	
2017-06-28 01:56:30,709 Epoch[45] Batch [1430]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.091247,	
2017-06-28 01:56:35,355 Epoch[45] Batch [1440]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091261,	
2017-06-28 01:56:40,173 Epoch[45] Batch [1450]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.091238,	
2017-06-28 01:56:44,772 Epoch[45] Batch [1460]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091170,	
2017-06-28 01:56:49,380 Epoch[45] Batch [1470]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091169,	
2017-06-28 01:56:53,744 Epoch[45] Batch [1480]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.091180,	
2017-06-28 01:56:56,532 Epoch[45] Train-FCNLogLoss=0.091223
2017-06-28 01:56:56,532 Epoch[45] Time cost=687.589
2017-06-28 01:56:57,304 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0046.params"
2017-06-28 01:56:59,443 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0046.states"
2017-06-28 01:57:04,947 Epoch[46] Batch [10]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090728,	
2017-06-28 01:57:09,805 Epoch[46] Batch [20]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090135,	
2017-06-28 01:57:14,417 Epoch[46] Batch [30]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092707,	
2017-06-28 01:57:19,220 Epoch[46] Batch [40]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.092835,	
2017-06-28 01:57:24,158 Epoch[46] Batch [50]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.093418,	
2017-06-28 01:57:28,696 Epoch[46] Batch [60]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.092989,	
2017-06-28 01:57:33,145 Epoch[46] Batch [70]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.092115,	
2017-06-28 01:57:38,068 Epoch[46] Batch [80]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.091513,	
2017-06-28 01:57:42,798 Epoch[46] Batch [90]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091754,	
2017-06-28 01:57:47,553 Epoch[46] Batch [100]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.091741,	
2017-06-28 01:57:52,398 Epoch[46] Batch [110]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.091771,	
2017-06-28 01:57:57,212 Epoch[46] Batch [120]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.092028,	
2017-06-28 01:58:01,685 Epoch[46] Batch [130]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091458,	
2017-06-28 01:58:06,443 Epoch[46] Batch [140]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.091690,	
2017-06-28 01:58:11,082 Epoch[46] Batch [150]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092167,	
2017-06-28 01:58:15,637 Epoch[46] Batch [160]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091524,	
2017-06-28 01:58:20,396 Epoch[46] Batch [170]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.092165,	
2017-06-28 01:58:25,009 Epoch[46] Batch [180]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091973,	
2017-06-28 01:58:29,618 Epoch[46] Batch [190]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091587,	
2017-06-28 01:58:34,314 Epoch[46] Batch [200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090858,	
2017-06-28 01:58:38,949 Epoch[46] Batch [210]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090722,	
2017-06-28 01:58:43,411 Epoch[46] Batch [220]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.090386,	
2017-06-28 01:58:47,892 Epoch[46] Batch [230]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089999,	
2017-06-28 01:58:52,251 Epoch[46] Batch [240]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.089941,	
2017-06-28 01:58:56,750 Epoch[46] Batch [250]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089659,	
2017-06-28 01:59:01,079 Epoch[46] Batch [260]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.089307,	
2017-06-28 01:59:05,669 Epoch[46] Batch [270]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.089443,	
2017-06-28 01:59:10,347 Epoch[46] Batch [280]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089482,	
2017-06-28 01:59:15,020 Epoch[46] Batch [290]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089438,	
2017-06-28 01:59:19,715 Epoch[46] Batch [300]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089608,	
2017-06-28 01:59:24,374 Epoch[46] Batch [310]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089699,	
2017-06-28 01:59:28,923 Epoch[46] Batch [320]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089503,	
2017-06-28 01:59:33,651 Epoch[46] Batch [330]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089943,	
2017-06-28 01:59:38,339 Epoch[46] Batch [340]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090285,	
2017-06-28 01:59:42,933 Epoch[46] Batch [350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090146,	
2017-06-28 01:59:47,748 Epoch[46] Batch [360]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.089914,	
2017-06-28 01:59:52,438 Epoch[46] Batch [370]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089918,	
2017-06-28 01:59:57,133 Epoch[46] Batch [380]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090022,	
2017-06-28 02:00:01,623 Epoch[46] Batch [390]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.089962,	
2017-06-28 02:00:06,185 Epoch[46] Batch [400]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090161,	
2017-06-28 02:00:10,695 Epoch[46] Batch [410]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.090151,	
2017-06-28 02:00:15,335 Epoch[46] Batch [420]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.090007,	
2017-06-28 02:00:19,912 Epoch[46] Batch [430]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090142,	
2017-06-28 02:00:24,495 Epoch[46] Batch [440]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090020,	
2017-06-28 02:00:29,028 Epoch[46] Batch [450]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089986,	
2017-06-28 02:00:33,631 Epoch[46] Batch [460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090212,	
2017-06-28 02:00:38,124 Epoch[46] Batch [470]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090257,	
2017-06-28 02:00:42,985 Epoch[46] Batch [480]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.090180,	
2017-06-28 02:00:47,709 Epoch[46] Batch [490]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090133,	
2017-06-28 02:00:52,646 Epoch[46] Batch [500]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.090290,	
2017-06-28 02:00:56,999 Epoch[46] Batch [510]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.090286,	
2017-06-28 02:01:01,498 Epoch[46] Batch [520]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090216,	
2017-06-28 02:01:05,886 Epoch[46] Batch [530]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090342,	
2017-06-28 02:01:10,510 Epoch[46] Batch [540]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.090260,	
2017-06-28 02:01:15,012 Epoch[46] Batch [550]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090260,	
2017-06-28 02:01:19,666 Epoch[46] Batch [560]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090267,	
2017-06-28 02:01:24,297 Epoch[46] Batch [570]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090433,	
2017-06-28 02:01:28,875 Epoch[46] Batch [580]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090341,	
2017-06-28 02:01:33,570 Epoch[46] Batch [590]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090376,	
2017-06-28 02:01:38,165 Epoch[46] Batch [600]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090403,	
2017-06-28 02:01:42,652 Epoch[46] Batch [610]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.090434,	
2017-06-28 02:01:47,330 Epoch[46] Batch [620]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090357,	
2017-06-28 02:01:52,163 Epoch[46] Batch [630]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.090407,	
2017-06-28 02:01:56,606 Epoch[46] Batch [640]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090444,	
2017-06-28 02:02:01,037 Epoch[46] Batch [650]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.090411,	
2017-06-28 02:02:05,696 Epoch[46] Batch [660]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090614,	
2017-06-28 02:02:10,083 Epoch[46] Batch [670]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090525,	
2017-06-28 02:02:14,864 Epoch[46] Batch [680]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.090563,	
2017-06-28 02:02:19,859 Epoch[46] Batch [690]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.090462,	
2017-06-28 02:02:24,608 Epoch[46] Batch [700]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090497,	
2017-06-28 02:02:29,303 Epoch[46] Batch [710]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090486,	
2017-06-28 02:02:34,250 Epoch[46] Batch [720]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.090565,	
2017-06-28 02:02:38,778 Epoch[46] Batch [730]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.090560,	
2017-06-28 02:02:43,170 Epoch[46] Batch [740]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090485,	
2017-06-28 02:02:47,939 Epoch[46] Batch [750]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090505,	
2017-06-28 02:02:52,696 Epoch[46] Batch [760]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090559,	
2017-06-28 02:02:57,656 Epoch[46] Batch [770]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.090361,	
2017-06-28 02:03:02,165 Epoch[46] Batch [780]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.090369,	
2017-06-28 02:03:06,863 Epoch[46] Batch [790]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.090378,	
2017-06-28 02:03:11,516 Epoch[46] Batch [800]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090582,	
2017-06-28 02:03:16,194 Epoch[46] Batch [810]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090566,	
2017-06-28 02:03:20,684 Epoch[46] Batch [820]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.090410,	
2017-06-28 02:03:25,198 Epoch[46] Batch [830]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090372,	
2017-06-28 02:03:29,856 Epoch[46] Batch [840]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090347,	
2017-06-28 02:03:34,648 Epoch[46] Batch [850]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.090408,	
2017-06-28 02:03:39,702 Epoch[46] Batch [860]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.090312,	
2017-06-28 02:03:44,303 Epoch[46] Batch [870]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090352,	
2017-06-28 02:03:48,879 Epoch[46] Batch [880]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090275,	
2017-06-28 02:03:53,571 Epoch[46] Batch [890]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090239,	
2017-06-28 02:03:58,143 Epoch[46] Batch [900]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090321,	
2017-06-28 02:04:02,777 Epoch[46] Batch [910]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090349,	
2017-06-28 02:04:07,243 Epoch[46] Batch [920]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.090389,	
2017-06-28 02:04:11,770 Epoch[46] Batch [930]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.090483,	
2017-06-28 02:04:16,615 Epoch[46] Batch [940]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.090376,	
2017-06-28 02:04:21,268 Epoch[46] Batch [950]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090282,	
2017-06-28 02:04:25,992 Epoch[46] Batch [960]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090312,	
2017-06-28 02:04:30,642 Epoch[46] Batch [970]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090327,	
2017-06-28 02:04:35,145 Epoch[46] Batch [980]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.090334,	
2017-06-28 02:04:40,027 Epoch[46] Batch [990]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.090269,	
2017-06-28 02:04:44,755 Epoch[46] Batch [1000]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090294,	
2017-06-28 02:04:49,548 Epoch[46] Batch [1010]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.090258,	
2017-06-28 02:04:54,239 Epoch[46] Batch [1020]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090232,	
2017-06-28 02:04:58,868 Epoch[46] Batch [1030]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090239,	
2017-06-28 02:05:03,468 Epoch[46] Batch [1040]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090257,	
2017-06-28 02:05:08,103 Epoch[46] Batch [1050]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090302,	
2017-06-28 02:05:12,853 Epoch[46] Batch [1060]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090269,	
2017-06-28 02:05:17,370 Epoch[46] Batch [1070]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090216,	
2017-06-28 02:05:22,061 Epoch[46] Batch [1080]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090232,	
2017-06-28 02:05:26,644 Epoch[46] Batch [1090]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090305,	
2017-06-28 02:05:31,291 Epoch[46] Batch [1100]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090334,	
2017-06-28 02:05:36,131 Epoch[46] Batch [1110]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.090376,	
2017-06-28 02:05:40,767 Epoch[46] Batch [1120]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090367,	
2017-06-28 02:05:45,547 Epoch[46] Batch [1130]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.090370,	
2017-06-28 02:05:50,118 Epoch[46] Batch [1140]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090410,	
2017-06-28 02:05:54,636 Epoch[46] Batch [1150]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.090413,	
2017-06-28 02:05:59,329 Epoch[46] Batch [1160]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090438,	
2017-06-28 02:06:03,873 Epoch[46] Batch [1170]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090485,	
2017-06-28 02:06:08,597 Epoch[46] Batch [1180]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090435,	
2017-06-28 02:06:12,985 Epoch[46] Batch [1190]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090376,	
2017-06-28 02:06:17,440 Epoch[46] Batch [1200]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.090332,	
2017-06-28 02:06:22,097 Epoch[46] Batch [1210]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090352,	
2017-06-28 02:06:26,666 Epoch[46] Batch [1220]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.090402,	
2017-06-28 02:06:31,192 Epoch[46] Batch [1230]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.090352,	
2017-06-28 02:06:35,746 Epoch[46] Batch [1240]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090403,	
2017-06-28 02:06:40,164 Epoch[46] Batch [1250]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.090427,	
2017-06-28 02:06:44,625 Epoch[46] Batch [1260]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.090425,	
2017-06-28 02:06:48,999 Epoch[46] Batch [1270]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.090322,	
2017-06-28 02:06:53,579 Epoch[46] Batch [1280]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090364,	
2017-06-28 02:06:58,123 Epoch[46] Batch [1290]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090362,	
2017-06-28 02:07:02,628 Epoch[46] Batch [1300]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.090412,	
2017-06-28 02:07:07,373 Epoch[46] Batch [1310]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.090398,	
2017-06-28 02:07:11,849 Epoch[46] Batch [1320]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090366,	
2017-06-28 02:07:16,501 Epoch[46] Batch [1330]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090338,	
2017-06-28 02:07:21,100 Epoch[46] Batch [1340]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090315,	
2017-06-28 02:07:25,722 Epoch[46] Batch [1350]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090312,	
2017-06-28 02:07:30,159 Epoch[46] Batch [1360]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090293,	
2017-06-28 02:07:34,733 Epoch[46] Batch [1370]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090283,	
2017-06-28 02:07:39,424 Epoch[46] Batch [1380]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-28 02:07:44,133 Epoch[46] Batch [1390]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.090338,	
2017-06-28 02:07:48,930 Epoch[46] Batch [1400]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.090320,	
2017-06-28 02:07:53,623 Epoch[46] Batch [1410]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090257,	
2017-06-28 02:07:58,555 Epoch[46] Batch [1420]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.090208,	
2017-06-28 02:08:03,021 Epoch[46] Batch [1430]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.090204,	
2017-06-28 02:08:07,569 Epoch[46] Batch [1440]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090266,	
2017-06-28 02:08:12,117 Epoch[46] Batch [1450]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090315,	
2017-06-28 02:08:16,592 Epoch[46] Batch [1460]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090345,	
2017-06-28 02:08:21,173 Epoch[46] Batch [1470]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090422,	
2017-06-28 02:08:25,672 Epoch[46] Batch [1480]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090450,	
2017-06-28 02:08:28,385 Epoch[46] Train-FCNLogLoss=0.090416
2017-06-28 02:08:28,385 Epoch[46] Time cost=688.942
2017-06-28 02:08:29,194 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0047.params"
2017-06-28 02:08:31,293 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0047.states"
2017-06-28 02:08:36,675 Epoch[47] Batch [10]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091314,	
2017-06-28 02:08:40,849 Epoch[47] Batch [20]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.090102,	
2017-06-28 02:08:45,684 Epoch[47] Batch [30]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.092350,	
2017-06-28 02:08:50,328 Epoch[47] Batch [40]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090148,	
2017-06-28 02:08:54,911 Epoch[47] Batch [50]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089080,	
2017-06-28 02:08:59,688 Epoch[47] Batch [60]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.090363,	
2017-06-28 02:09:04,283 Epoch[47] Batch [70]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089509,	
2017-06-28 02:09:08,943 Epoch[47] Batch [80]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091819,	
2017-06-28 02:09:13,525 Epoch[47] Batch [90]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091693,	
2017-06-28 02:09:18,127 Epoch[47] Batch [100]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092075,	
2017-06-28 02:09:22,809 Epoch[47] Batch [110]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092344,	
2017-06-28 02:09:27,675 Epoch[47] Batch [120]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.092024,	
2017-06-28 02:09:32,361 Epoch[47] Batch [130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.092380,	
2017-06-28 02:09:37,038 Epoch[47] Batch [140]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.092332,	
2017-06-28 02:09:41,770 Epoch[47] Batch [150]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.092366,	
2017-06-28 02:09:46,421 Epoch[47] Batch [160]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.092247,	
2017-06-28 02:09:51,162 Epoch[47] Batch [170]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.092778,	
2017-06-28 02:09:55,856 Epoch[47] Batch [180]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.093114,	
2017-06-28 02:10:00,622 Epoch[47] Batch [190]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.093023,	
2017-06-28 02:10:05,150 Epoch[47] Batch [200]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.092805,	
2017-06-28 02:10:09,733 Epoch[47] Batch [210]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092692,	
2017-06-28 02:10:14,314 Epoch[47] Batch [220]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.092697,	
2017-06-28 02:10:19,017 Epoch[47] Batch [230]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.092557,	
2017-06-28 02:10:23,694 Epoch[47] Batch [240]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.092514,	
2017-06-28 02:10:28,091 Epoch[47] Batch [250]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.092198,	
2017-06-28 02:10:32,481 Epoch[47] Batch [260]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.092014,	
2017-06-28 02:10:37,182 Epoch[47] Batch [270]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091973,	
2017-06-28 02:10:41,578 Epoch[47] Batch [280]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.091547,	
2017-06-28 02:10:46,149 Epoch[47] Batch [290]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091077,	
2017-06-28 02:10:50,626 Epoch[47] Batch [300]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.091241,	
2017-06-28 02:10:55,174 Epoch[47] Batch [310]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091696,	
2017-06-28 02:10:59,405 Epoch[47] Batch [320]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.091521,	
2017-06-28 02:11:03,806 Epoch[47] Batch [330]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.091851,	
2017-06-28 02:11:08,004 Epoch[47] Batch [340]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.091808,	
2017-06-28 02:11:12,564 Epoch[47] Batch [350]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091916,	
2017-06-28 02:11:17,062 Epoch[47] Batch [360]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091817,	
2017-06-28 02:11:21,590 Epoch[47] Batch [370]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.091834,	
2017-06-28 02:11:26,040 Epoch[47] Batch [380]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091998,	
2017-06-28 02:11:30,413 Epoch[47] Batch [390]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.091637,	
2017-06-28 02:11:34,966 Epoch[47] Batch [400]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091550,	
2017-06-28 02:11:39,674 Epoch[47] Batch [410]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091650,	
2017-06-28 02:11:44,144 Epoch[47] Batch [420]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091600,	
2017-06-28 02:11:48,751 Epoch[47] Batch [430]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091525,	
2017-06-28 02:11:53,545 Epoch[47] Batch [440]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.091445,	
2017-06-28 02:11:58,034 Epoch[47] Batch [450]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.091264,	
2017-06-28 02:12:02,917 Epoch[47] Batch [460]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.091417,	
2017-06-28 02:12:07,636 Epoch[47] Batch [470]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091435,	
2017-06-28 02:12:11,860 Epoch[47] Batch [480]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.091591,	
2017-06-28 02:12:16,003 Epoch[47] Batch [490]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.091515,	
2017-06-28 02:12:20,642 Epoch[47] Batch [500]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091556,	
2017-06-28 02:12:25,109 Epoch[47] Batch [510]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.091615,	
2017-06-28 02:12:29,737 Epoch[47] Batch [520]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091706,	
2017-06-28 02:12:34,517 Epoch[47] Batch [530]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.091690,	
2017-06-28 02:12:38,798 Epoch[47] Batch [540]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.091656,	
2017-06-28 02:12:43,456 Epoch[47] Batch [550]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.091398,	
2017-06-28 02:12:47,811 Epoch[47] Batch [560]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.091373,	
2017-06-28 02:12:52,055 Epoch[47] Batch [570]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.091403,	
2017-06-28 02:12:56,958 Epoch[47] Batch [580]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.091377,	
2017-06-28 02:13:01,579 Epoch[47] Batch [590]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091432,	
2017-06-28 02:13:06,134 Epoch[47] Batch [600]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091444,	
2017-06-28 02:13:10,872 Epoch[47] Batch [610]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.091316,	
2017-06-28 02:13:15,590 Epoch[47] Batch [620]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091565,	
2017-06-28 02:13:20,207 Epoch[47] Batch [630]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091650,	
2017-06-28 02:13:24,693 Epoch[47] Batch [640]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.091545,	
2017-06-28 02:13:29,284 Epoch[47] Batch [650]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.091618,	
2017-06-28 02:13:33,986 Epoch[47] Batch [660]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091486,	
2017-06-28 02:13:38,572 Epoch[47] Batch [670]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091524,	
2017-06-28 02:13:42,903 Epoch[47] Batch [680]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.091418,	
2017-06-28 02:13:47,282 Epoch[47] Batch [690]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.091535,	
2017-06-28 02:13:51,750 Epoch[47] Batch [700]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091533,	
2017-06-28 02:13:56,422 Epoch[47] Batch [710]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.091540,	
2017-06-28 02:14:01,028 Epoch[47] Batch [720]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.091545,	
2017-06-28 02:14:05,498 Epoch[47] Batch [730]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091472,	
2017-06-28 02:14:10,204 Epoch[47] Batch [740]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091512,	
2017-06-28 02:14:14,655 Epoch[47] Batch [750]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091588,	
2017-06-28 02:14:19,128 Epoch[47] Batch [760]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.091541,	
2017-06-28 02:14:23,715 Epoch[47] Batch [770]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091467,	
2017-06-28 02:14:28,101 Epoch[47] Batch [780]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.091516,	
2017-06-28 02:14:32,656 Epoch[47] Batch [790]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091546,	
2017-06-28 02:14:37,223 Epoch[47] Batch [800]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091374,	
2017-06-28 02:14:41,864 Epoch[47] Batch [810]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.091411,	
2017-06-28 02:14:46,303 Epoch[47] Batch [820]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.091350,	
2017-06-28 02:14:50,587 Epoch[47] Batch [830]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.091263,	
2017-06-28 02:14:55,308 Epoch[47] Batch [840]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.091223,	
2017-06-28 02:14:59,677 Epoch[47] Batch [850]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.091194,	
2017-06-28 02:15:04,031 Epoch[47] Batch [860]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.091249,	
2017-06-28 02:15:08,591 Epoch[47] Batch [870]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091147,	
2017-06-28 02:15:13,160 Epoch[47] Batch [880]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091159,	
2017-06-28 02:15:17,600 Epoch[47] Batch [890]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.091086,	
2017-06-28 02:15:22,212 Epoch[47] Batch [900]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091200,	
2017-06-28 02:15:26,757 Epoch[47] Batch [910]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.091175,	
2017-06-28 02:15:31,338 Epoch[47] Batch [920]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091097,	
2017-06-28 02:15:36,035 Epoch[47] Batch [930]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091081,	
2017-06-28 02:15:40,667 Epoch[47] Batch [940]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091108,	
2017-06-28 02:15:45,300 Epoch[47] Batch [950]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091178,	
2017-06-28 02:15:50,137 Epoch[47] Batch [960]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.091170,	
2017-06-28 02:15:55,076 Epoch[47] Batch [970]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.091142,	
2017-06-28 02:15:59,673 Epoch[47] Batch [980]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091087,	
2017-06-28 02:16:04,282 Epoch[47] Batch [990]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091190,	
2017-06-28 02:16:08,979 Epoch[47] Batch [1000]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091127,	
2017-06-28 02:16:13,643 Epoch[47] Batch [1010]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.091176,	
2017-06-28 02:16:18,513 Epoch[47] Batch [1020]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.091259,	
2017-06-28 02:16:23,086 Epoch[47] Batch [1030]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091291,	
2017-06-28 02:16:27,773 Epoch[47] Batch [1040]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.091293,	
2017-06-28 02:16:32,169 Epoch[47] Batch [1050]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.091310,	
2017-06-28 02:16:36,889 Epoch[47] Batch [1060]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091404,	
2017-06-28 02:16:41,712 Epoch[47] Batch [1070]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.091421,	
2017-06-28 02:16:46,594 Epoch[47] Batch [1080]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.091382,	
2017-06-28 02:16:51,310 Epoch[47] Batch [1090]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.091435,	
2017-06-28 02:16:56,046 Epoch[47] Batch [1100]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.091442,	
2017-06-28 02:17:00,510 Epoch[47] Batch [1110]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.091391,	
2017-06-28 02:17:05,010 Epoch[47] Batch [1120]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.091286,	
2017-06-28 02:17:09,468 Epoch[47] Batch [1130]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091169,	
2017-06-28 02:17:13,920 Epoch[47] Batch [1140]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091203,	
2017-06-28 02:17:18,517 Epoch[47] Batch [1150]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091154,	
2017-06-28 02:17:23,033 Epoch[47] Batch [1160]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.091198,	
2017-06-28 02:17:27,612 Epoch[47] Batch [1170]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091204,	
2017-06-28 02:17:31,981 Epoch[47] Batch [1180]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.091244,	
2017-06-28 02:17:36,593 Epoch[47] Batch [1190]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091179,	
2017-06-28 02:17:40,612 Epoch[47] Batch [1200]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.091203,	
2017-06-28 02:17:44,925 Epoch[47] Batch [1210]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.091173,	
2017-06-28 02:17:49,342 Epoch[47] Batch [1220]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091242,	
2017-06-28 02:17:53,900 Epoch[47] Batch [1230]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.091250,	
2017-06-28 02:17:58,335 Epoch[47] Batch [1240]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.091276,	
2017-06-28 02:18:02,662 Epoch[47] Batch [1250]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.091283,	
2017-06-28 02:18:07,073 Epoch[47] Batch [1260]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.091303,	
2017-06-28 02:18:11,646 Epoch[47] Batch [1270]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.091270,	
2017-06-28 02:18:16,188 Epoch[47] Batch [1280]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.091269,	
2017-06-28 02:18:20,698 Epoch[47] Batch [1290]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.091286,	
2017-06-28 02:18:25,137 Epoch[47] Batch [1300]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.091357,	
2017-06-28 02:18:29,936 Epoch[47] Batch [1310]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.091315,	
2017-06-28 02:18:34,228 Epoch[47] Batch [1320]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.091303,	
2017-06-28 02:18:38,569 Epoch[47] Batch [1330]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.091202,	
2017-06-28 02:18:43,296 Epoch[47] Batch [1340]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091176,	
2017-06-28 02:18:47,865 Epoch[47] Batch [1350]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091120,	
2017-06-28 02:18:52,232 Epoch[47] Batch [1360]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.091153,	
2017-06-28 02:18:56,985 Epoch[47] Batch [1370]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.091180,	
2017-06-28 02:19:01,669 Epoch[47] Batch [1380]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.091210,	
2017-06-28 02:19:06,252 Epoch[47] Batch [1390]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091155,	
2017-06-28 02:19:11,042 Epoch[47] Batch [1400]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.091164,	
2017-06-28 02:19:15,694 Epoch[47] Batch [1410]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091163,	
2017-06-28 02:19:20,497 Epoch[47] Batch [1420]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.091129,	
2017-06-28 02:19:24,849 Epoch[47] Batch [1430]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.091113,	
2017-06-28 02:19:29,300 Epoch[47] Batch [1440]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.091105,	
2017-06-28 02:19:33,882 Epoch[47] Batch [1450]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091104,	
2017-06-28 02:19:38,316 Epoch[47] Batch [1460]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.091082,	
2017-06-28 02:19:42,947 Epoch[47] Batch [1470]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091052,	
2017-06-28 02:19:47,591 Epoch[47] Batch [1480]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091036,	
2017-06-28 02:19:50,123 Epoch[47] Train-FCNLogLoss=0.091056
2017-06-28 02:19:50,123 Epoch[47] Time cost=678.830
2017-06-28 02:19:50,885 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0048.params"
2017-06-28 02:19:52,705 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0048.states"
2017-06-28 02:19:58,083 Epoch[48] Batch [10]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.089983,	
2017-06-28 02:20:02,774 Epoch[48] Batch [20]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.085573,	
2017-06-28 02:20:07,285 Epoch[48] Batch [30]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087778,	
2017-06-28 02:20:11,857 Epoch[48] Batch [40]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.085400,	
2017-06-28 02:20:16,398 Epoch[48] Batch [50]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.086450,	
2017-06-28 02:20:20,939 Epoch[48] Batch [60]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087440,	
2017-06-28 02:20:25,462 Epoch[48] Batch [70]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087866,	
2017-06-28 02:20:29,877 Epoch[48] Batch [80]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.088594,	
2017-06-28 02:20:34,579 Epoch[48] Batch [90]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087680,	
2017-06-28 02:20:39,345 Epoch[48] Batch [100]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.087249,	
2017-06-28 02:20:44,059 Epoch[48] Batch [110]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088379,	
2017-06-28 02:20:48,625 Epoch[48] Batch [120]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.088583,	
2017-06-28 02:20:53,095 Epoch[48] Batch [130]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088934,	
2017-06-28 02:20:57,726 Epoch[48] Batch [140]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088852,	
2017-06-28 02:21:02,372 Epoch[48] Batch [150]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089357,	
2017-06-28 02:21:06,776 Epoch[48] Batch [160]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.089577,	
2017-06-28 02:21:11,512 Epoch[48] Batch [170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089930,	
2017-06-28 02:21:15,932 Epoch[48] Batch [180]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.089660,	
2017-06-28 02:21:20,356 Epoch[48] Batch [190]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.089841,	
2017-06-28 02:21:24,876 Epoch[48] Batch [200]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.090079,	
2017-06-28 02:21:29,559 Epoch[48] Batch [210]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090289,	
2017-06-28 02:21:34,281 Epoch[48] Batch [220]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090609,	
2017-06-28 02:21:38,811 Epoch[48] Batch [230]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.090100,	
2017-06-28 02:21:43,361 Epoch[48] Batch [240]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090101,	
2017-06-28 02:21:48,207 Epoch[48] Batch [250]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.090288,	
2017-06-28 02:21:52,813 Epoch[48] Batch [260]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090437,	
2017-06-28 02:21:57,306 Epoch[48] Batch [270]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090287,	
2017-06-28 02:22:01,862 Epoch[48] Batch [280]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.090518,	
2017-06-28 02:22:06,326 Epoch[48] Batch [290]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.090378,	
2017-06-28 02:22:11,076 Epoch[48] Batch [300]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090656,	
2017-06-28 02:22:15,576 Epoch[48] Batch [310]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090419,	
2017-06-28 02:22:20,335 Epoch[48] Batch [320]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090216,	
2017-06-28 02:22:24,735 Epoch[48] Batch [330]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.089961,	
2017-06-28 02:22:29,461 Epoch[48] Batch [340]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090208,	
2017-06-28 02:22:33,931 Epoch[48] Batch [350]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.090558,	
2017-06-28 02:22:38,421 Epoch[48] Batch [360]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.090460,	
2017-06-28 02:22:43,126 Epoch[48] Batch [370]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.090344,	
2017-06-28 02:22:47,538 Epoch[48] Batch [380]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.090160,	
2017-06-28 02:22:51,768 Epoch[48] Batch [390]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.089965,	
2017-06-28 02:22:56,412 Epoch[48] Batch [400]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090036,	
2017-06-28 02:23:01,006 Epoch[48] Batch [410]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090166,	
2017-06-28 02:23:05,600 Epoch[48] Batch [420]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090252,	
2017-06-28 02:23:10,089 Epoch[48] Batch [430]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.090281,	
2017-06-28 02:23:14,787 Epoch[48] Batch [440]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.090130,	
2017-06-28 02:23:19,303 Epoch[48] Batch [450]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090163,	
2017-06-28 02:23:23,708 Epoch[48] Batch [460]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.090283,	
2017-06-28 02:23:28,209 Epoch[48] Batch [470]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090148,	
2017-06-28 02:23:32,807 Epoch[48] Batch [480]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090234,	
2017-06-28 02:23:37,460 Epoch[48] Batch [490]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090217,	
2017-06-28 02:23:41,855 Epoch[48] Batch [500]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090290,	
2017-06-28 02:23:46,532 Epoch[48] Batch [510]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090529,	
2017-06-28 02:23:51,125 Epoch[48] Batch [520]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090539,	
2017-06-28 02:23:55,808 Epoch[48] Batch [530]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090497,	
2017-06-28 02:24:00,442 Epoch[48] Batch [540]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090311,	
2017-06-28 02:24:05,067 Epoch[48] Batch [550]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.090442,	
2017-06-28 02:24:09,810 Epoch[48] Batch [560]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.090435,	
2017-06-28 02:24:14,692 Epoch[48] Batch [570]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.090580,	
2017-06-28 02:24:19,482 Epoch[48] Batch [580]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.090731,	
2017-06-28 02:24:23,964 Epoch[48] Batch [590]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.090653,	
2017-06-28 02:24:28,791 Epoch[48] Batch [600]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090815,	
2017-06-28 02:24:33,342 Epoch[48] Batch [610]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090673,	
2017-06-28 02:24:37,722 Epoch[48] Batch [620]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.090632,	
2017-06-28 02:24:42,356 Epoch[48] Batch [630]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090494,	
2017-06-28 02:24:46,846 Epoch[48] Batch [640]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.090411,	
2017-06-28 02:24:51,315 Epoch[48] Batch [650]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.090429,	
2017-06-28 02:24:55,922 Epoch[48] Batch [660]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090437,	
2017-06-28 02:25:00,638 Epoch[48] Batch [670]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090348,	
2017-06-28 02:25:05,200 Epoch[48] Batch [680]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090372,	
2017-06-28 02:25:09,969 Epoch[48] Batch [690]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090336,	
2017-06-28 02:25:14,616 Epoch[48] Batch [700]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090382,	
2017-06-28 02:25:19,274 Epoch[48] Batch [710]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090470,	
2017-06-28 02:25:24,013 Epoch[48] Batch [720]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090562,	
2017-06-28 02:25:28,616 Epoch[48] Batch [730]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090485,	
2017-06-28 02:25:33,370 Epoch[48] Batch [740]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090436,	
2017-06-28 02:25:37,868 Epoch[48] Batch [750]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090519,	
2017-06-28 02:25:42,417 Epoch[48] Batch [760]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090444,	
2017-06-28 02:25:46,994 Epoch[48] Batch [770]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090550,	
2017-06-28 02:25:51,473 Epoch[48] Batch [780]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.090545,	
2017-06-28 02:25:56,152 Epoch[48] Batch [790]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090531,	
2017-06-28 02:26:00,802 Epoch[48] Batch [800]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090546,	
2017-06-28 02:26:05,298 Epoch[48] Batch [810]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090561,	
2017-06-28 02:26:09,739 Epoch[48] Batch [820]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.090620,	
2017-06-28 02:26:14,311 Epoch[48] Batch [830]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.090612,	
2017-06-28 02:26:19,043 Epoch[48] Batch [840]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090569,	
2017-06-28 02:26:23,698 Epoch[48] Batch [850]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090570,	
2017-06-28 02:26:28,085 Epoch[48] Batch [860]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090514,	
2017-06-28 02:26:32,683 Epoch[48] Batch [870]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090576,	
2017-06-28 02:26:37,441 Epoch[48] Batch [880]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090579,	
2017-06-28 02:26:41,939 Epoch[48] Batch [890]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090659,	
2017-06-28 02:26:46,502 Epoch[48] Batch [900]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090749,	
2017-06-28 02:26:51,196 Epoch[48] Batch [910]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090715,	
2017-06-28 02:26:55,965 Epoch[48] Batch [920]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090671,	
2017-06-28 02:27:00,680 Epoch[48] Batch [930]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090717,	
2017-06-28 02:27:05,464 Epoch[48] Batch [940]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090742,	
2017-06-28 02:27:10,182 Epoch[48] Batch [950]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090686,	
2017-06-28 02:27:14,877 Epoch[48] Batch [960]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090750,	
2017-06-28 02:27:19,414 Epoch[48] Batch [970]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090720,	
2017-06-28 02:27:24,123 Epoch[48] Batch [980]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.090819,	
2017-06-28 02:27:28,579 Epoch[48] Batch [990]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.090763,	
2017-06-28 02:27:33,094 Epoch[48] Batch [1000]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090780,	
2017-06-28 02:27:37,464 Epoch[48] Batch [1010]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.090734,	
2017-06-28 02:27:42,142 Epoch[48] Batch [1020]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090721,	
2017-06-28 02:27:46,995 Epoch[48] Batch [1030]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090627,	
2017-06-28 02:27:51,556 Epoch[48] Batch [1040]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090695,	
2017-06-28 02:27:56,116 Epoch[48] Batch [1050]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090741,	
2017-06-28 02:28:00,902 Epoch[48] Batch [1060]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090806,	
2017-06-28 02:28:05,338 Epoch[48] Batch [1070]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090802,	
2017-06-28 02:28:09,884 Epoch[48] Batch [1080]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090759,	
2017-06-28 02:28:14,459 Epoch[48] Batch [1090]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090708,	
2017-06-28 02:28:18,839 Epoch[48] Batch [1100]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.090768,	
2017-06-28 02:28:23,597 Epoch[48] Batch [1110]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090674,	
2017-06-28 02:28:28,250 Epoch[48] Batch [1120]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090716,	
2017-06-28 02:28:32,966 Epoch[48] Batch [1130]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090757,	
2017-06-28 02:28:37,504 Epoch[48] Batch [1140]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090809,	
2017-06-28 02:28:42,238 Epoch[48] Batch [1150]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090858,	
2017-06-28 02:28:46,951 Epoch[48] Batch [1160]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090842,	
2017-06-28 02:28:51,582 Epoch[48] Batch [1170]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.090904,	
2017-06-28 02:28:56,093 Epoch[48] Batch [1180]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.090855,	
2017-06-28 02:29:00,675 Epoch[48] Batch [1190]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090880,	
2017-06-28 02:29:05,276 Epoch[48] Batch [1200]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090932,	
2017-06-28 02:29:09,888 Epoch[48] Batch [1210]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.090850,	
2017-06-28 02:29:14,640 Epoch[48] Batch [1220]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090815,	
2017-06-28 02:29:19,395 Epoch[48] Batch [1230]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.090771,	
2017-06-28 02:29:24,143 Epoch[48] Batch [1240]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090775,	
2017-06-28 02:29:28,765 Epoch[48] Batch [1250]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090763,	
2017-06-28 02:29:33,532 Epoch[48] Batch [1260]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090672,	
2017-06-28 02:29:38,015 Epoch[48] Batch [1270]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.090662,	
2017-06-28 02:29:42,514 Epoch[48] Batch [1280]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090570,	
2017-06-28 02:29:47,205 Epoch[48] Batch [1290]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090639,	
2017-06-28 02:29:51,916 Epoch[48] Batch [1300]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090647,	
2017-06-28 02:29:56,736 Epoch[48] Batch [1310]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.090571,	
2017-06-28 02:30:01,476 Epoch[48] Batch [1320]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090670,	
2017-06-28 02:30:06,159 Epoch[48] Batch [1330]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090676,	
2017-06-28 02:30:10,709 Epoch[48] Batch [1340]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090650,	
2017-06-28 02:30:15,588 Epoch[48] Batch [1350]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090610,	
2017-06-28 02:30:20,298 Epoch[48] Batch [1360]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090660,	
2017-06-28 02:30:24,701 Epoch[48] Batch [1370]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.090718,	
2017-06-28 02:30:29,029 Epoch[48] Batch [1380]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.090711,	
2017-06-28 02:30:33,720 Epoch[48] Batch [1390]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090747,	
2017-06-28 02:30:38,222 Epoch[48] Batch [1400]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.090741,	
2017-06-28 02:30:42,867 Epoch[48] Batch [1410]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090725,	
2017-06-28 02:30:47,646 Epoch[48] Batch [1420]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.090642,	
2017-06-28 02:30:52,071 Epoch[48] Batch [1430]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.090559,	
2017-06-28 02:30:56,688 Epoch[48] Batch [1440]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090515,	
2017-06-28 02:31:01,080 Epoch[48] Batch [1450]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.090487,	
2017-06-28 02:31:05,307 Epoch[48] Batch [1460]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.090552,	
2017-06-28 02:31:09,862 Epoch[48] Batch [1470]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.090554,	
2017-06-28 02:31:14,735 Epoch[48] Batch [1480]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.090557,	
2017-06-28 02:31:17,764 Epoch[48] Train-FCNLogLoss=0.090540
2017-06-28 02:31:17,764 Epoch[48] Time cost=685.059
2017-06-28 02:31:18,555 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0049.params"
2017-06-28 02:31:20,875 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0049.states"
2017-06-28 02:31:26,206 Epoch[49] Batch [10]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.088159,	
2017-06-28 02:31:30,690 Epoch[49] Batch [20]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.090661,	
2017-06-28 02:31:35,196 Epoch[49] Batch [30]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089590,	
2017-06-28 02:31:40,008 Epoch[49] Batch [40]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.090431,	
2017-06-28 02:31:44,843 Epoch[49] Batch [50]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.091229,	
2017-06-28 02:31:49,690 Epoch[49] Batch [60]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091010,	
2017-06-28 02:31:54,253 Epoch[49] Batch [70]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091717,	
2017-06-28 02:31:58,805 Epoch[49] Batch [80]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091594,	
2017-06-28 02:32:03,646 Epoch[49] Batch [90]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.090734,	
2017-06-28 02:32:07,947 Epoch[49] Batch [100]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.090821,	
2017-06-28 02:32:12,670 Epoch[49] Batch [110]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.092352,	
2017-06-28 02:32:17,255 Epoch[49] Batch [120]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091926,	
2017-06-28 02:32:22,054 Epoch[49] Batch [130]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.091689,	
2017-06-28 02:32:26,383 Epoch[49] Batch [140]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.091305,	
2017-06-28 02:32:31,105 Epoch[49] Batch [150]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.091471,	
2017-06-28 02:32:35,555 Epoch[49] Batch [160]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.092125,	
2017-06-28 02:32:40,291 Epoch[49] Batch [170]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.092023,	
2017-06-28 02:32:44,912 Epoch[49] Batch [180]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.091428,	
2017-06-28 02:32:49,795 Epoch[49] Batch [190]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.091309,	
2017-06-28 02:32:54,332 Epoch[49] Batch [200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.091604,	
2017-06-28 02:32:58,537 Epoch[49] Batch [210]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.091487,	
2017-06-28 02:33:02,824 Epoch[49] Batch [220]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.091214,	
2017-06-28 02:33:07,305 Epoch[49] Batch [230]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.090982,	
2017-06-28 02:33:11,889 Epoch[49] Batch [240]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090886,	
2017-06-28 02:33:16,595 Epoch[49] Batch [250]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.091088,	
2017-06-28 02:33:21,134 Epoch[49] Batch [260]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090939,	
2017-06-28 02:33:25,648 Epoch[49] Batch [270]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090740,	
2017-06-28 02:33:30,062 Epoch[49] Batch [280]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.091022,	
2017-06-28 02:33:34,641 Epoch[49] Batch [290]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.090954,	
2017-06-28 02:33:39,009 Epoch[49] Batch [300]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.090548,	
2017-06-28 02:33:43,667 Epoch[49] Batch [310]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-28 02:33:48,700 Epoch[49] Batch [320]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.090255,	
2017-06-28 02:33:53,496 Epoch[49] Batch [330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.090114,	
2017-06-28 02:33:58,181 Epoch[49] Batch [340]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.090034,	
2017-06-28 02:34:02,617 Epoch[49] Batch [350]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090109,	
2017-06-28 02:34:07,162 Epoch[49] Batch [360]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090031,	
2017-06-28 02:34:11,594 Epoch[49] Batch [370]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.090037,	
2017-06-28 02:34:16,219 Epoch[49] Batch [380]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089964,	
2017-06-28 02:34:20,932 Epoch[49] Batch [390]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090044,	
2017-06-28 02:34:25,415 Epoch[49] Batch [400]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.089868,	
2017-06-28 02:34:29,866 Epoch[49] Batch [410]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.089822,	
2017-06-28 02:34:34,362 Epoch[49] Batch [420]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089651,	
2017-06-28 02:34:39,241 Epoch[49] Batch [430]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089626,	
2017-06-28 02:34:44,290 Epoch[49] Batch [440]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089607,	
2017-06-28 02:34:49,364 Epoch[49] Batch [450]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089554,	
2017-06-28 02:34:54,135 Epoch[49] Batch [460]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089612,	
2017-06-28 02:34:58,654 Epoch[49] Batch [470]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.089677,	
2017-06-28 02:35:03,316 Epoch[49] Batch [480]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089928,	
2017-06-28 02:35:08,170 Epoch[49] Batch [490]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.089935,	
2017-06-28 02:35:12,848 Epoch[49] Batch [500]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089985,	
2017-06-28 02:35:17,447 Epoch[49] Batch [510]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089999,	
2017-06-28 02:35:21,970 Epoch[49] Batch [520]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089907,	
2017-06-28 02:35:26,656 Epoch[49] Batch [530]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089874,	
2017-06-28 02:35:30,990 Epoch[49] Batch [540]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.089764,	
2017-06-28 02:35:35,429 Epoch[49] Batch [550]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.089653,	
2017-06-28 02:35:40,112 Epoch[49] Batch [560]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089560,	
2017-06-28 02:35:44,856 Epoch[49] Batch [570]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089436,	
2017-06-28 02:35:49,529 Epoch[49] Batch [580]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089268,	
2017-06-28 02:35:54,217 Epoch[49] Batch [590]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089373,	
2017-06-28 02:35:58,912 Epoch[49] Batch [600]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089377,	
2017-06-28 02:36:03,526 Epoch[49] Batch [610]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.089443,	
2017-06-28 02:36:08,162 Epoch[49] Batch [620]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089557,	
2017-06-28 02:36:12,678 Epoch[49] Batch [630]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.089623,	
2017-06-28 02:36:17,258 Epoch[49] Batch [640]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089552,	
2017-06-28 02:36:21,922 Epoch[49] Batch [650]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089447,	
2017-06-28 02:36:26,445 Epoch[49] Batch [660]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089483,	
2017-06-28 02:36:31,221 Epoch[49] Batch [670]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089533,	
2017-06-28 02:36:35,986 Epoch[49] Batch [680]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089552,	
2017-06-28 02:36:40,530 Epoch[49] Batch [690]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089556,	
2017-06-28 02:36:45,263 Epoch[49] Batch [700]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089552,	
2017-06-28 02:36:49,801 Epoch[49] Batch [710]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.089542,	
2017-06-28 02:36:54,545 Epoch[49] Batch [720]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089578,	
2017-06-28 02:36:59,226 Epoch[49] Batch [730]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089607,	
2017-06-28 02:37:03,693 Epoch[49] Batch [740]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.089602,	
2017-06-28 02:37:08,221 Epoch[49] Batch [750]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.089710,	
2017-06-28 02:37:12,921 Epoch[49] Batch [760]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089719,	
2017-06-28 02:37:17,659 Epoch[49] Batch [770]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089700,	
2017-06-28 02:37:22,136 Epoch[49] Batch [780]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.089694,	
2017-06-28 02:37:26,622 Epoch[49] Batch [790]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.089694,	
2017-06-28 02:37:31,373 Epoch[49] Batch [800]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089721,	
2017-06-28 02:37:36,348 Epoch[49] Batch [810]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.089841,	
2017-06-28 02:37:40,922 Epoch[49] Batch [820]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089803,	
2017-06-28 02:37:45,332 Epoch[49] Batch [830]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089802,	
2017-06-28 02:37:49,880 Epoch[49] Batch [840]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089779,	
2017-06-28 02:37:54,662 Epoch[49] Batch [850]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089665,	
2017-06-28 02:37:59,244 Epoch[49] Batch [860]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089729,	
2017-06-28 02:38:03,890 Epoch[49] Batch [870]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089699,	
2017-06-28 02:38:08,430 Epoch[49] Batch [880]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.089589,	
2017-06-28 02:38:13,207 Epoch[49] Batch [890]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.089645,	
2017-06-28 02:38:17,958 Epoch[49] Batch [900]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.089591,	
2017-06-28 02:38:22,423 Epoch[49] Batch [910]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.089735,	
2017-06-28 02:38:26,814 Epoch[49] Batch [920]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.089661,	
2017-06-28 02:38:31,816 Epoch[49] Batch [930]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.089714,	
2017-06-28 02:38:36,833 Epoch[49] Batch [940]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089793,	
2017-06-28 02:38:41,705 Epoch[49] Batch [950]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.089864,	
2017-06-28 02:38:46,209 Epoch[49] Batch [960]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089889,	
2017-06-28 02:38:50,881 Epoch[49] Batch [970]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089911,	
2017-06-28 02:38:55,610 Epoch[49] Batch [980]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089917,	
2017-06-28 02:39:00,284 Epoch[49] Batch [990]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089965,	
2017-06-28 02:39:05,016 Epoch[49] Batch [1000]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089973,	
2017-06-28 02:39:09,419 Epoch[49] Batch [1010]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.090077,	
2017-06-28 02:39:14,083 Epoch[49] Batch [1020]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.090048,	
2017-06-28 02:39:18,805 Epoch[49] Batch [1030]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.090046,	
2017-06-28 02:39:23,248 Epoch[49] Batch [1040]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.090048,	
2017-06-28 02:39:28,205 Epoch[49] Batch [1050]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.090041,	
2017-06-28 02:39:32,975 Epoch[49] Batch [1060]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089968,	
2017-06-28 02:39:37,448 Epoch[49] Batch [1070]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.090068,	
2017-06-28 02:39:42,038 Epoch[49] Batch [1080]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.090100,	
2017-06-28 02:39:46,619 Epoch[49] Batch [1090]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090148,	
2017-06-28 02:39:51,215 Epoch[49] Batch [1100]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.090091,	
2017-06-28 02:39:55,850 Epoch[49] Batch [1110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090004,	
2017-06-28 02:40:00,724 Epoch[49] Batch [1120]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.089950,	
2017-06-28 02:40:05,437 Epoch[49] Batch [1130]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089869,	
2017-06-28 02:40:10,345 Epoch[49] Batch [1140]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089838,	
2017-06-28 02:40:15,039 Epoch[49] Batch [1150]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089901,	
2017-06-28 02:40:19,680 Epoch[49] Batch [1160]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089978,	
2017-06-28 02:40:24,270 Epoch[49] Batch [1170]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089965,	
2017-06-28 02:40:28,973 Epoch[49] Batch [1180]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089944,	
2017-06-28 02:40:33,557 Epoch[49] Batch [1190]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089864,	
2017-06-28 02:40:38,191 Epoch[49] Batch [1200]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.089919,	
2017-06-28 02:40:42,853 Epoch[49] Batch [1210]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089901,	
2017-06-28 02:40:47,355 Epoch[49] Batch [1220]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089903,	
2017-06-28 02:40:51,838 Epoch[49] Batch [1230]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.089957,	
2017-06-28 02:40:56,529 Epoch[49] Batch [1240]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089983,	
2017-06-28 02:41:00,929 Epoch[49] Batch [1250]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.090000,	
2017-06-28 02:41:05,464 Epoch[49] Batch [1260]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090095,	
2017-06-28 02:41:10,192 Epoch[49] Batch [1270]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090007,	
2017-06-28 02:41:14,931 Epoch[49] Batch [1280]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090008,	
2017-06-28 02:41:19,764 Epoch[49] Batch [1290]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.090008,	
2017-06-28 02:41:24,196 Epoch[49] Batch [1300]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.089996,	
2017-06-28 02:41:28,718 Epoch[49] Batch [1310]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.089958,	
2017-06-28 02:41:33,094 Epoch[49] Batch [1320]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.089923,	
2017-06-28 02:41:37,591 Epoch[49] Batch [1330]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089922,	
2017-06-28 02:41:42,186 Epoch[49] Batch [1340]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089896,	
2017-06-28 02:41:46,907 Epoch[49] Batch [1350]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089976,	
2017-06-28 02:41:51,816 Epoch[49] Batch [1360]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089958,	
2017-06-28 02:41:56,030 Epoch[49] Batch [1370]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.089972,	
2017-06-28 02:42:00,630 Epoch[49] Batch [1380]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089973,	
2017-06-28 02:42:05,177 Epoch[49] Batch [1390]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089983,	
2017-06-28 02:42:09,772 Epoch[49] Batch [1400]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090042,	
2017-06-28 02:42:14,221 Epoch[49] Batch [1410]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.089994,	
2017-06-28 02:42:18,898 Epoch[49] Batch [1420]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090035,	
2017-06-28 02:42:23,569 Epoch[49] Batch [1430]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090026,	
2017-06-28 02:42:28,221 Epoch[49] Batch [1440]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090012,	
2017-06-28 02:42:33,076 Epoch[49] Batch [1450]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090077,	
2017-06-28 02:42:37,742 Epoch[49] Batch [1460]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090112,	
2017-06-28 02:42:42,430 Epoch[49] Batch [1470]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090167,	
2017-06-28 02:42:47,083 Epoch[49] Batch [1480]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090071,	
2017-06-28 02:42:49,724 Epoch[49] Train-FCNLogLoss=0.090052
2017-06-28 02:42:49,725 Epoch[49] Time cost=688.849
2017-06-28 02:42:50,508 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0050.params"
2017-06-28 02:42:52,605 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0050.states"
2017-06-28 02:42:58,273 Epoch[50] Batch [10]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.093762,	
2017-06-28 02:43:02,972 Epoch[50] Batch [20]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087131,	
2017-06-28 02:43:07,758 Epoch[50] Batch [30]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.088021,	
2017-06-28 02:43:12,654 Epoch[50] Batch [40]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.087952,	
2017-06-28 02:43:17,251 Epoch[50] Batch [50]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087221,	
2017-06-28 02:43:21,894 Epoch[50] Batch [60]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089141,	
2017-06-28 02:43:26,630 Epoch[50] Batch [70]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089144,	
2017-06-28 02:43:31,364 Epoch[50] Batch [80]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088726,	
2017-06-28 02:43:35,863 Epoch[50] Batch [90]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088983,	
2017-06-28 02:43:40,946 Epoch[50] Batch [100]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089370,	
2017-06-28 02:43:45,471 Epoch[50] Batch [110]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.090220,	
2017-06-28 02:43:50,139 Epoch[50] Batch [120]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089878,	
2017-06-28 02:43:54,812 Epoch[50] Batch [130]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090237,	
2017-06-28 02:43:59,579 Epoch[50] Batch [140]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090231,	
2017-06-28 02:44:04,341 Epoch[50] Batch [150]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.090494,	
2017-06-28 02:44:08,832 Epoch[50] Batch [160]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.090961,	
2017-06-28 02:44:13,314 Epoch[50] Batch [170]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.090564,	
2017-06-28 02:44:17,636 Epoch[50] Batch [180]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.090748,	
2017-06-28 02:44:22,263 Epoch[50] Batch [190]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.090629,	
2017-06-28 02:44:26,900 Epoch[50] Batch [200]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090459,	
2017-06-28 02:44:31,534 Epoch[50] Batch [210]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090697,	
2017-06-28 02:44:36,227 Epoch[50] Batch [220]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090479,	
2017-06-28 02:44:40,750 Epoch[50] Batch [230]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.090994,	
2017-06-28 02:44:45,407 Epoch[50] Batch [240]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090929,	
2017-06-28 02:44:50,166 Epoch[50] Batch [250]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.090659,	
2017-06-28 02:44:55,071 Epoch[50] Batch [260]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.090733,	
2017-06-28 02:44:59,885 Epoch[50] Batch [270]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.090921,	
2017-06-28 02:45:04,573 Epoch[50] Batch [280]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.091272,	
2017-06-28 02:45:09,251 Epoch[50] Batch [290]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.091371,	
2017-06-28 02:45:14,029 Epoch[50] Batch [300]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.091516,	
2017-06-28 02:45:18,728 Epoch[50] Batch [310]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091561,	
2017-06-28 02:45:23,635 Epoch[50] Batch [320]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.091527,	
2017-06-28 02:45:28,167 Epoch[50] Batch [330]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.091686,	
2017-06-28 02:45:32,540 Epoch[50] Batch [340]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.091662,	
2017-06-28 02:45:37,168 Epoch[50] Batch [350]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.091689,	
2017-06-28 02:45:41,865 Epoch[50] Batch [360]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091984,	
2017-06-28 02:45:46,597 Epoch[50] Batch [370]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.092296,	
2017-06-28 02:45:51,238 Epoch[50] Batch [380]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.092330,	
2017-06-28 02:45:55,843 Epoch[50] Batch [390]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.092412,	
2017-06-28 02:46:00,413 Epoch[50] Batch [400]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.092048,	
2017-06-28 02:46:05,079 Epoch[50] Batch [410]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.092054,	
2017-06-28 02:46:09,642 Epoch[50] Batch [420]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.092182,	
2017-06-28 02:46:14,133 Epoch[50] Batch [430]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.092297,	
2017-06-28 02:46:18,919 Epoch[50] Batch [440]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.092115,	
2017-06-28 02:46:23,744 Epoch[50] Batch [450]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.092119,	
2017-06-28 02:46:28,360 Epoch[50] Batch [460]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.092091,	
2017-06-28 02:46:32,935 Epoch[50] Batch [470]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.092164,	
2017-06-28 02:46:37,501 Epoch[50] Batch [480]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.091834,	
2017-06-28 02:46:42,277 Epoch[50] Batch [490]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.091866,	
2017-06-28 02:46:47,149 Epoch[50] Batch [500]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.091757,	
2017-06-28 02:46:51,845 Epoch[50] Batch [510]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091476,	
2017-06-28 02:46:56,641 Epoch[50] Batch [520]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.091370,	
2017-06-28 02:47:01,257 Epoch[50] Batch [530]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091514,	
2017-06-28 02:47:05,715 Epoch[50] Batch [540]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091410,	
2017-06-28 02:47:10,256 Epoch[50] Batch [550]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.091442,	
2017-06-28 02:47:14,900 Epoch[50] Batch [560]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091412,	
2017-06-28 02:47:19,664 Epoch[50] Batch [570]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.091362,	
2017-06-28 02:47:24,274 Epoch[50] Batch [580]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.091395,	
2017-06-28 02:47:28,919 Epoch[50] Batch [590]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091446,	
2017-06-28 02:47:33,377 Epoch[50] Batch [600]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091361,	
2017-06-28 02:47:37,966 Epoch[50] Batch [610]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091379,	
2017-06-28 02:47:42,571 Epoch[50] Batch [620]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.091291,	
2017-06-28 02:47:46,939 Epoch[50] Batch [630]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.091334,	
2017-06-28 02:47:51,555 Epoch[50] Batch [640]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.091308,	
2017-06-28 02:47:55,795 Epoch[50] Batch [650]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091180,	
2017-06-28 02:48:00,221 Epoch[50] Batch [660]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.091207,	
2017-06-28 02:48:04,771 Epoch[50] Batch [670]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.091221,	
2017-06-28 02:48:09,359 Epoch[50] Batch [680]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.091241,	
2017-06-28 02:48:13,953 Epoch[50] Batch [690]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.091134,	
2017-06-28 02:48:18,553 Epoch[50] Batch [700]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.091082,	
2017-06-28 02:48:23,247 Epoch[50] Batch [710]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.091086,	
2017-06-28 02:48:27,950 Epoch[50] Batch [720]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091012,	
2017-06-28 02:48:32,756 Epoch[50] Batch [730]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.091020,	
2017-06-28 02:48:37,408 Epoch[50] Batch [740]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.091109,	
2017-06-28 02:48:41,987 Epoch[50] Batch [750]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.091086,	
2017-06-28 02:48:46,632 Epoch[50] Batch [760]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.091078,	
2017-06-28 02:48:51,381 Epoch[50] Batch [770]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.091056,	
2017-06-28 02:48:55,973 Epoch[50] Batch [780]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.091023,	
2017-06-28 02:49:00,597 Epoch[50] Batch [790]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.091022,	
2017-06-28 02:49:05,337 Epoch[50] Batch [800]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.091010,	
2017-06-28 02:49:10,014 Epoch[50] Batch [810]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.090997,	
2017-06-28 02:49:14,741 Epoch[50] Batch [820]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.091023,	
2017-06-28 02:49:19,603 Epoch[50] Batch [830]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.091070,	
2017-06-28 02:49:24,349 Epoch[50] Batch [840]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.090954,	
2017-06-28 02:49:28,802 Epoch[50] Batch [850]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091024,	
2017-06-28 02:49:33,392 Epoch[50] Batch [860]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.090954,	
2017-06-28 02:49:38,082 Epoch[50] Batch [870]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090891,	
2017-06-28 02:49:42,756 Epoch[50] Batch [880]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090851,	
2017-06-28 02:49:47,457 Epoch[50] Batch [890]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.090870,	
2017-06-28 02:49:51,779 Epoch[50] Batch [900]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.090947,	
2017-06-28 02:49:56,494 Epoch[50] Batch [910]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.090894,	
2017-06-28 02:50:00,873 Epoch[50] Batch [920]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.090814,	
2017-06-28 02:50:05,464 Epoch[50] Batch [930]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090671,	
2017-06-28 02:50:10,134 Epoch[50] Batch [940]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090543,	
2017-06-28 02:50:14,783 Epoch[50] Batch [950]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090501,	
2017-06-28 02:50:19,297 Epoch[50] Batch [960]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090487,	
2017-06-28 02:50:23,843 Epoch[50] Batch [970]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.090460,	
2017-06-28 02:50:28,450 Epoch[50] Batch [980]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.090544,	
2017-06-28 02:50:32,915 Epoch[50] Batch [990]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.090433,	
2017-06-28 02:50:37,470 Epoch[50] Batch [1000]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.090368,	
2017-06-28 02:50:42,343 Epoch[50] Batch [1010]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.090328,	
2017-06-28 02:50:46,840 Epoch[50] Batch [1020]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090354,	
2017-06-28 02:50:51,797 Epoch[50] Batch [1030]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.090388,	
2017-06-28 02:50:56,159 Epoch[50] Batch [1040]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-28 02:51:00,780 Epoch[50] Batch [1050]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.090460,	
2017-06-28 02:51:05,282 Epoch[50] Batch [1060]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.090542,	
2017-06-28 02:51:10,146 Epoch[50] Batch [1070]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.090505,	
2017-06-28 02:51:14,461 Epoch[50] Batch [1080]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.090417,	
2017-06-28 02:51:19,293 Epoch[50] Batch [1090]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.090425,	
2017-06-28 02:51:23,733 Epoch[50] Batch [1100]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.090425,	
2017-06-28 02:51:28,459 Epoch[50] Batch [1110]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.090434,	
2017-06-28 02:51:33,096 Epoch[50] Batch [1120]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090407,	
2017-06-28 02:51:37,768 Epoch[50] Batch [1130]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090422,	
2017-06-28 02:51:42,414 Epoch[50] Batch [1140]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.090502,	
2017-06-28 02:51:47,121 Epoch[50] Batch [1150]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.090375,	
2017-06-28 02:51:51,942 Epoch[50] Batch [1160]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.090421,	
2017-06-28 02:51:56,613 Epoch[50] Batch [1170]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.090434,	
2017-06-28 02:52:01,207 Epoch[50] Batch [1180]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090452,	
2017-06-28 02:52:05,723 Epoch[50] Batch [1190]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090393,	
2017-06-28 02:52:10,219 Epoch[50] Batch [1200]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.090384,	
2017-06-28 02:52:15,035 Epoch[50] Batch [1210]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.090366,	
2017-06-28 02:52:19,785 Epoch[50] Batch [1220]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090380,	
2017-06-28 02:52:24,767 Epoch[50] Batch [1230]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.090343,	
2017-06-28 02:52:29,238 Epoch[50] Batch [1240]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.090326,	
2017-06-28 02:52:33,796 Epoch[50] Batch [1250]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.090366,	
2017-06-28 02:52:38,499 Epoch[50] Batch [1260]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.090403,	
2017-06-28 02:52:43,059 Epoch[50] Batch [1270]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.090416,	
2017-06-28 02:52:47,695 Epoch[50] Batch [1280]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.090420,	
2017-06-28 02:52:52,774 Epoch[50] Batch [1290]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.090379,	
2017-06-28 02:52:57,203 Epoch[50] Batch [1300]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.090287,	
2017-06-28 02:53:01,992 Epoch[50] Batch [1310]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.090288,	
2017-06-28 02:53:06,541 Epoch[50] Batch [1320]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.090309,	
2017-06-28 02:53:11,145 Epoch[50] Batch [1330]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090325,	
2017-06-28 02:53:15,650 Epoch[50] Batch [1340]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.090336,	
2017-06-28 02:53:20,391 Epoch[50] Batch [1350]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090300,	
2017-06-28 02:53:25,130 Epoch[50] Batch [1360]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090278,	
2017-06-28 02:53:29,645 Epoch[50] Batch [1370]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090335,	
2017-06-28 02:53:34,184 Epoch[50] Batch [1380]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.090265,	
2017-06-28 02:53:38,845 Epoch[50] Batch [1390]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.090339,	
2017-06-28 02:53:43,671 Epoch[50] Batch [1400]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.090310,	
2017-06-28 02:53:48,058 Epoch[50] Batch [1410]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.090275,	
2017-06-28 02:53:52,593 Epoch[50] Batch [1420]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090309,	
2017-06-28 02:53:57,341 Epoch[50] Batch [1430]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.090365,	
2017-06-28 02:54:02,141 Epoch[50] Batch [1440]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.090332,	
2017-06-28 02:54:06,808 Epoch[50] Batch [1450]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.090350,	
2017-06-28 02:54:11,321 Epoch[50] Batch [1460]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.090393,	
2017-06-28 02:54:15,664 Epoch[50] Batch [1470]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.090446,	
2017-06-28 02:54:20,314 Epoch[50] Batch [1480]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.090512,	
2017-06-28 02:54:23,047 Epoch[50] Train-FCNLogLoss=0.090514
2017-06-28 02:54:23,048 Epoch[50] Time cost=690.442
2017-06-28 02:54:23,911 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0051.params"
2017-06-28 02:54:25,912 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0051.states"
2017-06-28 02:54:31,380 Epoch[51] Batch [10]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.087485,	
2017-06-28 02:54:35,900 Epoch[51] Batch [20]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.086414,	
2017-06-28 02:54:40,359 Epoch[51] Batch [30]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.085937,	
2017-06-28 02:54:45,187 Epoch[51] Batch [40]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.086161,	
2017-06-28 02:54:49,787 Epoch[51] Batch [50]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.084584,	
2017-06-28 02:54:54,261 Epoch[51] Batch [60]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.085350,	
2017-06-28 02:54:58,800 Epoch[51] Batch [70]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.087113,	
2017-06-28 02:55:03,256 Epoch[51] Batch [80]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.086664,	
2017-06-28 02:55:07,843 Epoch[51] Batch [90]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.087187,	
2017-06-28 02:55:12,540 Epoch[51] Batch [100]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087616,	
2017-06-28 02:55:17,175 Epoch[51] Batch [110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088016,	
2017-06-28 02:55:21,713 Epoch[51] Batch [120]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088004,	
2017-06-28 02:55:26,391 Epoch[51] Batch [130]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088619,	
2017-06-28 02:55:30,901 Epoch[51] Batch [140]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088244,	
2017-06-28 02:55:35,812 Epoch[51] Batch [150]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088952,	
2017-06-28 02:55:40,441 Epoch[51] Batch [160]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089752,	
2017-06-28 02:55:45,008 Epoch[51] Batch [170]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089597,	
2017-06-28 02:55:49,927 Epoch[51] Batch [180]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.089566,	
2017-06-28 02:55:54,632 Epoch[51] Batch [190]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089296,	
2017-06-28 02:55:59,369 Epoch[51] Batch [200]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088767,	
2017-06-28 02:56:04,110 Epoch[51] Batch [210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.088978,	
2017-06-28 02:56:08,768 Epoch[51] Batch [220]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089042,	
2017-06-28 02:56:13,504 Epoch[51] Batch [230]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089717,	
2017-06-28 02:56:18,208 Epoch[51] Batch [240]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089396,	
2017-06-28 02:56:22,716 Epoch[51] Batch [250]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.089393,	
2017-06-28 02:56:27,268 Epoch[51] Batch [260]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089543,	
2017-06-28 02:56:31,898 Epoch[51] Batch [270]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089564,	
2017-06-28 02:56:36,311 Epoch[51] Batch [280]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.089247,	
2017-06-28 02:56:40,759 Epoch[51] Batch [290]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.089258,	
2017-06-28 02:56:45,218 Epoch[51] Batch [300]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.089315,	
2017-06-28 02:56:49,799 Epoch[51] Batch [310]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089161,	
2017-06-28 02:56:54,394 Epoch[51] Batch [320]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089173,	
2017-06-28 02:56:59,068 Epoch[51] Batch [330]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089421,	
2017-06-28 02:57:03,490 Epoch[51] Batch [340]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.089393,	
2017-06-28 02:57:08,037 Epoch[51] Batch [350]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089488,	
2017-06-28 02:57:12,667 Epoch[51] Batch [360]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089107,	
2017-06-28 02:57:17,107 Epoch[51] Batch [370]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.088927,	
2017-06-28 02:57:21,545 Epoch[51] Batch [380]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.089006,	
2017-06-28 02:57:26,051 Epoch[51] Batch [390]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089106,	
2017-06-28 02:57:30,660 Epoch[51] Batch [400]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.089023,	
2017-06-28 02:57:35,289 Epoch[51] Batch [410]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089151,	
2017-06-28 02:57:39,868 Epoch[51] Batch [420]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089046,	
2017-06-28 02:57:44,582 Epoch[51] Batch [430]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089018,	
2017-06-28 02:57:49,186 Epoch[51] Batch [440]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.088919,	
2017-06-28 02:57:53,678 Epoch[51] Batch [450]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.088808,	
2017-06-28 02:57:58,241 Epoch[51] Batch [460]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.088877,	
2017-06-28 02:58:02,778 Epoch[51] Batch [470]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088913,	
2017-06-28 02:58:07,667 Epoch[51] Batch [480]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088753,	
2017-06-28 02:58:12,336 Epoch[51] Batch [490]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.088897,	
2017-06-28 02:58:16,956 Epoch[51] Batch [500]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.088872,	
2017-06-28 02:58:21,437 Epoch[51] Batch [510]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.088776,	
2017-06-28 02:58:26,408 Epoch[51] Batch [520]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088703,	
2017-06-28 02:58:31,219 Epoch[51] Batch [530]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088683,	
2017-06-28 02:58:35,475 Epoch[51] Batch [540]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.088638,	
2017-06-28 02:58:39,897 Epoch[51] Batch [550]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-28 02:58:44,621 Epoch[51] Batch [560]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.088789,	
2017-06-28 02:58:49,209 Epoch[51] Batch [570]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.088876,	
2017-06-28 02:58:53,784 Epoch[51] Batch [580]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088850,	
2017-06-28 02:58:58,192 Epoch[51] Batch [590]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.088859,	
2017-06-28 02:59:02,674 Epoch[51] Batch [600]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.088836,	
2017-06-28 02:59:07,111 Epoch[51] Batch [610]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.088877,	
2017-06-28 02:59:11,684 Epoch[51] Batch [620]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.088931,	
2017-06-28 02:59:16,440 Epoch[51] Batch [630]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.089000,	
2017-06-28 02:59:21,121 Epoch[51] Batch [640]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088883,	
2017-06-28 02:59:25,792 Epoch[51] Batch [650]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088976,	
2017-06-28 02:59:30,280 Epoch[51] Batch [660]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.088973,	
2017-06-28 02:59:34,855 Epoch[51] Batch [670]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.088796,	
2017-06-28 02:59:39,768 Epoch[51] Batch [680]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088837,	
2017-06-28 02:59:44,207 Epoch[51] Batch [690]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.088860,	
2017-06-28 02:59:49,019 Epoch[51] Batch [700]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088718,	
2017-06-28 02:59:53,634 Epoch[51] Batch [710]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088581,	
2017-06-28 02:59:58,318 Epoch[51] Batch [720]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.088552,	
2017-06-28 03:00:03,096 Epoch[51] Batch [730]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.088596,	
2017-06-28 03:00:08,030 Epoch[51] Batch [740]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.088613,	
2017-06-28 03:00:12,570 Epoch[51] Batch [750]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.088600,	
2017-06-28 03:00:16,870 Epoch[51] Batch [760]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-28 03:00:21,224 Epoch[51] Batch [770]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.088732,	
2017-06-28 03:00:25,571 Epoch[51] Batch [780]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.088677,	
2017-06-28 03:00:30,101 Epoch[51] Batch [790]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-28 03:00:34,715 Epoch[51] Batch [800]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088680,	
2017-06-28 03:00:39,327 Epoch[51] Batch [810]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.088668,	
2017-06-28 03:00:44,102 Epoch[51] Batch [820]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.088674,	
2017-06-28 03:00:48,697 Epoch[51] Batch [830]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.088701,	
2017-06-28 03:00:53,403 Epoch[51] Batch [840]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088796,	
2017-06-28 03:00:57,847 Epoch[51] Batch [850]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.088749,	
2017-06-28 03:01:02,536 Epoch[51] Batch [860]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.088793,	
2017-06-28 03:01:07,196 Epoch[51] Batch [870]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.088837,	
2017-06-28 03:01:12,062 Epoch[51] Batch [880]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.088788,	
2017-06-28 03:01:16,572 Epoch[51] Batch [890]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088769,	
2017-06-28 03:01:21,286 Epoch[51] Batch [900]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.088776,	
2017-06-28 03:01:25,798 Epoch[51] Batch [910]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088818,	
2017-06-28 03:01:30,299 Epoch[51] Batch [920]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088841,	
2017-06-28 03:01:34,801 Epoch[51] Batch [930]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088834,	
2017-06-28 03:01:39,496 Epoch[51] Batch [940]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088871,	
2017-06-28 03:01:44,342 Epoch[51] Batch [950]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.088897,	
2017-06-28 03:01:48,779 Epoch[51] Batch [960]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.088927,	
2017-06-28 03:01:53,637 Epoch[51] Batch [970]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088987,	
2017-06-28 03:01:58,274 Epoch[51] Batch [980]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088962,	
2017-06-28 03:02:02,687 Epoch[51] Batch [990]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088928,	
2017-06-28 03:02:07,365 Epoch[51] Batch [1000]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088887,	
2017-06-28 03:02:11,776 Epoch[51] Batch [1010]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.088889,	
2017-06-28 03:02:16,105 Epoch[51] Batch [1020]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.088902,	
2017-06-28 03:02:20,434 Epoch[51] Batch [1030]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.088905,	
2017-06-28 03:02:25,113 Epoch[51] Batch [1040]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088860,	
2017-06-28 03:02:29,745 Epoch[51] Batch [1050]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.088854,	
2017-06-28 03:02:34,380 Epoch[51] Batch [1060]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.088808,	
2017-06-28 03:02:38,849 Epoch[51] Batch [1070]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.088796,	
2017-06-28 03:02:43,306 Epoch[51] Batch [1080]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.088761,	
2017-06-28 03:02:48,365 Epoch[51] Batch [1090]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.088737,	
2017-06-28 03:02:53,038 Epoch[51] Batch [1100]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088808,	
2017-06-28 03:02:57,646 Epoch[51] Batch [1110]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088797,	
2017-06-28 03:03:02,293 Epoch[51] Batch [1120]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.088767,	
2017-06-28 03:03:07,011 Epoch[51] Batch [1130]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088717,	
2017-06-28 03:03:11,825 Epoch[51] Batch [1140]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-28 03:03:16,840 Epoch[51] Batch [1150]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-28 03:03:21,645 Epoch[51] Batch [1160]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.088791,	
2017-06-28 03:03:26,283 Epoch[51] Batch [1170]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.088809,	
2017-06-28 03:03:31,036 Epoch[51] Batch [1180]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088900,	
2017-06-28 03:03:35,458 Epoch[51] Batch [1190]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088934,	
2017-06-28 03:03:40,382 Epoch[51] Batch [1200]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088978,	
2017-06-28 03:03:44,811 Epoch[51] Batch [1210]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.088959,	
2017-06-28 03:03:49,354 Epoch[51] Batch [1220]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.089146,	
2017-06-28 03:03:54,045 Epoch[51] Batch [1230]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089057,	
2017-06-28 03:03:58,842 Epoch[51] Batch [1240]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089215,	
2017-06-28 03:04:03,406 Epoch[51] Batch [1250]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.089176,	
2017-06-28 03:04:08,011 Epoch[51] Batch [1260]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089185,	
2017-06-28 03:04:12,772 Epoch[51] Batch [1270]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089196,	
2017-06-28 03:04:17,428 Epoch[51] Batch [1280]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089293,	
2017-06-28 03:04:21,556 Epoch[51] Batch [1290]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.089378,	
2017-06-28 03:04:26,151 Epoch[51] Batch [1300]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089378,	
2017-06-28 03:04:30,774 Epoch[51] Batch [1310]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089303,	
2017-06-28 03:04:35,755 Epoch[51] Batch [1320]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.089353,	
2017-06-28 03:04:40,479 Epoch[51] Batch [1330]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089398,	
2017-06-28 03:04:45,128 Epoch[51] Batch [1340]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089488,	
2017-06-28 03:04:49,606 Epoch[51] Batch [1350]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089519,	
2017-06-28 03:04:54,031 Epoch[51] Batch [1360]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.089523,	
2017-06-28 03:04:58,575 Epoch[51] Batch [1370]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.089598,	
2017-06-28 03:05:03,297 Epoch[51] Batch [1380]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089644,	
2017-06-28 03:05:08,043 Epoch[51] Batch [1390]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089723,	
2017-06-28 03:05:12,686 Epoch[51] Batch [1400]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089728,	
2017-06-28 03:05:17,519 Epoch[51] Batch [1410]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089741,	
2017-06-28 03:05:22,083 Epoch[51] Batch [1420]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089796,	
2017-06-28 03:05:26,726 Epoch[51] Batch [1430]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089784,	
2017-06-28 03:05:31,283 Epoch[51] Batch [1440]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.089757,	
2017-06-28 03:05:35,782 Epoch[51] Batch [1450]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089733,	
2017-06-28 03:05:40,545 Epoch[51] Batch [1460]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089679,	
2017-06-28 03:05:44,923 Epoch[51] Batch [1470]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.089676,	
2017-06-28 03:05:49,286 Epoch[51] Batch [1480]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.089681,	
2017-06-28 03:05:51,883 Epoch[51] Train-FCNLogLoss=0.089718
2017-06-28 03:05:51,883 Epoch[51] Time cost=685.971
2017-06-28 03:05:52,612 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0052.params"
2017-06-28 03:05:54,454 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0052.states"
2017-06-28 03:05:59,696 Epoch[52] Batch [10]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.091016,	
2017-06-28 03:06:03,984 Epoch[52] Batch [20]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.086065,	
2017-06-28 03:06:08,660 Epoch[52] Batch [30]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.086148,	
2017-06-28 03:06:13,231 Epoch[52] Batch [40]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.085495,	
2017-06-28 03:06:18,009 Epoch[52] Batch [50]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.086865,	
2017-06-28 03:06:22,398 Epoch[52] Batch [60]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086330,	
2017-06-28 03:06:26,871 Epoch[52] Batch [70]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.086310,	
2017-06-28 03:06:31,805 Epoch[52] Batch [80]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.086281,	
2017-06-28 03:06:36,505 Epoch[52] Batch [90]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.087235,	
2017-06-28 03:06:41,131 Epoch[52] Batch [100]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086531,	
2017-06-28 03:06:45,866 Epoch[52] Batch [110]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.087272,	
2017-06-28 03:06:50,698 Epoch[52] Batch [120]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.087302,	
2017-06-28 03:06:55,405 Epoch[52] Batch [130]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.087181,	
2017-06-28 03:07:00,179 Epoch[52] Batch [140]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.086580,	
2017-06-28 03:07:04,949 Epoch[52] Batch [150]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.087594,	
2017-06-28 03:07:09,857 Epoch[52] Batch [160]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086823,	
2017-06-28 03:07:14,722 Epoch[52] Batch [170]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.086346,	
2017-06-28 03:07:19,347 Epoch[52] Batch [180]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.086490,	
2017-06-28 03:07:24,263 Epoch[52] Batch [190]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.086603,	
2017-06-28 03:07:29,203 Epoch[52] Batch [200]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.086410,	
2017-06-28 03:07:33,598 Epoch[52] Batch [210]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087077,	
2017-06-28 03:07:38,168 Epoch[52] Batch [220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.087110,	
2017-06-28 03:07:42,630 Epoch[52] Batch [230]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087114,	
2017-06-28 03:07:47,068 Epoch[52] Batch [240]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.087397,	
2017-06-28 03:07:51,580 Epoch[52] Batch [250]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-28 03:07:56,058 Epoch[52] Batch [260]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087936,	
2017-06-28 03:08:00,621 Epoch[52] Batch [270]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.087737,	
2017-06-28 03:08:05,144 Epoch[52] Batch [280]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-28 03:08:09,731 Epoch[52] Batch [290]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.088265,	
2017-06-28 03:08:14,284 Epoch[52] Batch [300]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088428,	
2017-06-28 03:08:19,101 Epoch[52] Batch [310]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.088831,	
2017-06-28 03:08:23,789 Epoch[52] Batch [320]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.088647,	
2017-06-28 03:08:28,327 Epoch[52] Batch [330]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.088845,	
2017-06-28 03:08:32,999 Epoch[52] Batch [340]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.088866,	
2017-06-28 03:08:37,582 Epoch[52] Batch [350]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.088899,	
2017-06-28 03:08:42,410 Epoch[52] Batch [360]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089170,	
2017-06-28 03:08:47,376 Epoch[52] Batch [370]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.089408,	
2017-06-28 03:08:52,040 Epoch[52] Batch [380]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089587,	
2017-06-28 03:08:56,566 Epoch[52] Batch [390]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089472,	
2017-06-28 03:09:01,171 Epoch[52] Batch [400]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.089480,	
2017-06-28 03:09:05,625 Epoch[52] Batch [410]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.089337,	
2017-06-28 03:09:10,205 Epoch[52] Batch [420]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089222,	
2017-06-28 03:09:14,623 Epoch[52] Batch [430]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.089292,	
2017-06-28 03:09:19,211 Epoch[52] Batch [440]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.089211,	
2017-06-28 03:09:23,820 Epoch[52] Batch [450]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.089380,	
2017-06-28 03:09:28,315 Epoch[52] Batch [460]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089677,	
2017-06-28 03:09:33,294 Epoch[52] Batch [470]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.089573,	
2017-06-28 03:09:38,117 Epoch[52] Batch [480]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089508,	
2017-06-28 03:09:42,641 Epoch[52] Batch [490]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089290,	
2017-06-28 03:09:47,556 Epoch[52] Batch [500]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089270,	
2017-06-28 03:09:52,584 Epoch[52] Batch [510]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089473,	
2017-06-28 03:09:57,381 Epoch[52] Batch [520]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089587,	
2017-06-28 03:10:01,791 Epoch[52] Batch [530]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.089471,	
2017-06-28 03:10:06,389 Epoch[52] Batch [540]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089553,	
2017-06-28 03:10:11,169 Epoch[52] Batch [550]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089522,	
2017-06-28 03:10:15,847 Epoch[52] Batch [560]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.089723,	
2017-06-28 03:10:20,254 Epoch[52] Batch [570]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.089737,	
2017-06-28 03:10:24,574 Epoch[52] Batch [580]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.089827,	
2017-06-28 03:10:29,353 Epoch[52] Batch [590]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.089835,	
2017-06-28 03:10:34,151 Epoch[52] Batch [600]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.089791,	
2017-06-28 03:10:38,796 Epoch[52] Batch [610]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.089832,	
2017-06-28 03:10:43,774 Epoch[52] Batch [620]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.089884,	
2017-06-28 03:10:48,413 Epoch[52] Batch [630]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.089849,	
2017-06-28 03:10:53,261 Epoch[52] Batch [640]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089890,	
2017-06-28 03:10:58,105 Epoch[52] Batch [650]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.090019,	
2017-06-28 03:11:02,608 Epoch[52] Batch [660]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089946,	
2017-06-28 03:11:06,910 Epoch[52] Batch [670]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.089912,	
2017-06-28 03:11:11,187 Epoch[52] Batch [680]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.089906,	
2017-06-28 03:11:15,872 Epoch[52] Batch [690]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089978,	
2017-06-28 03:11:20,463 Epoch[52] Batch [700]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090080,	
2017-06-28 03:11:25,045 Epoch[52] Batch [710]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.090020,	
2017-06-28 03:11:29,580 Epoch[52] Batch [720]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.090025,	
2017-06-28 03:11:34,107 Epoch[52] Batch [730]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.090104,	
2017-06-28 03:11:38,712 Epoch[52] Batch [740]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.090123,	
2017-06-28 03:11:43,367 Epoch[52] Batch [750]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.090106,	
2017-06-28 03:11:48,106 Epoch[52] Batch [760]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090157,	
2017-06-28 03:11:52,719 Epoch[52] Batch [770]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.090160,	
2017-06-28 03:11:57,380 Epoch[52] Batch [780]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.090232,	
2017-06-28 03:12:01,971 Epoch[52] Batch [790]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.090131,	
2017-06-28 03:12:06,719 Epoch[52] Batch [800]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.090117,	
2017-06-28 03:12:11,745 Epoch[52] Batch [810]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.090106,	
2017-06-28 03:12:16,091 Epoch[52] Batch [820]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.089990,	
2017-06-28 03:12:20,709 Epoch[52] Batch [830]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.089855,	
2017-06-28 03:12:25,419 Epoch[52] Batch [840]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089902,	
2017-06-28 03:12:30,104 Epoch[52] Batch [850]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.089930,	
2017-06-28 03:12:34,603 Epoch[52] Batch [860]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089968,	
2017-06-28 03:12:39,323 Epoch[52] Batch [870]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.090011,	
2017-06-28 03:12:44,021 Epoch[52] Batch [880]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.090084,	
2017-06-28 03:12:48,547 Epoch[52] Batch [890]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089978,	
2017-06-28 03:12:53,251 Epoch[52] Batch [900]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.089941,	
2017-06-28 03:12:57,991 Epoch[52] Batch [910]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.089904,	
2017-06-28 03:13:02,759 Epoch[52] Batch [920]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.089871,	
2017-06-28 03:13:07,435 Epoch[52] Batch [930]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.089773,	
2017-06-28 03:13:12,335 Epoch[52] Batch [940]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089685,	
2017-06-28 03:13:17,229 Epoch[52] Batch [950]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089602,	
2017-06-28 03:13:21,505 Epoch[52] Batch [960]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.089677,	
2017-06-28 03:13:26,085 Epoch[52] Batch [970]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.089771,	
2017-06-28 03:13:30,608 Epoch[52] Batch [980]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089713,	
2017-06-28 03:13:35,319 Epoch[52] Batch [990]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089690,	
2017-06-28 03:13:39,820 Epoch[52] Batch [1000]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089698,	
2017-06-28 03:13:44,192 Epoch[52] Batch [1010]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.089719,	
2017-06-28 03:13:48,783 Epoch[52] Batch [1020]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089758,	
2017-06-28 03:13:53,602 Epoch[52] Batch [1030]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.089674,	
2017-06-28 03:13:58,297 Epoch[52] Batch [1040]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.089616,	
2017-06-28 03:14:02,892 Epoch[52] Batch [1050]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089691,	
2017-06-28 03:14:07,544 Epoch[52] Batch [1060]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089573,	
2017-06-28 03:14:12,236 Epoch[52] Batch [1070]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089484,	
2017-06-28 03:14:16,960 Epoch[52] Batch [1080]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.089456,	
2017-06-28 03:14:21,506 Epoch[52] Batch [1090]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.089479,	
2017-06-28 03:14:26,072 Epoch[52] Batch [1100]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089483,	
2017-06-28 03:14:30,547 Epoch[52] Batch [1110]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.089426,	
2017-06-28 03:14:35,132 Epoch[52] Batch [1120]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.089429,	
2017-06-28 03:14:39,875 Epoch[52] Batch [1130]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.089438,	
2017-06-28 03:14:44,385 Epoch[52] Batch [1140]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.089430,	
2017-06-28 03:14:49,119 Epoch[52] Batch [1150]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.089420,	
2017-06-28 03:14:53,881 Epoch[52] Batch [1160]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089387,	
2017-06-28 03:14:58,281 Epoch[52] Batch [1170]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.089383,	
2017-06-28 03:15:02,737 Epoch[52] Batch [1180]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.089459,	
2017-06-28 03:15:06,911 Epoch[52] Batch [1190]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.089553,	
2017-06-28 03:15:11,504 Epoch[52] Batch [1200]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089525,	
2017-06-28 03:15:16,012 Epoch[52] Batch [1210]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.089467,	
2017-06-28 03:15:20,677 Epoch[52] Batch [1220]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-28 03:15:25,289 Epoch[52] Batch [1230]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.089532,	
2017-06-28 03:15:30,100 Epoch[52] Batch [1240]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.089535,	
2017-06-28 03:15:34,893 Epoch[52] Batch [1250]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089545,	
2017-06-28 03:15:39,592 Epoch[52] Batch [1260]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.089591,	
2017-06-28 03:15:44,115 Epoch[52] Batch [1270]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.089623,	
2017-06-28 03:15:48,746 Epoch[52] Batch [1280]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089593,	
2017-06-28 03:15:53,249 Epoch[52] Batch [1290]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.089579,	
2017-06-28 03:15:57,747 Epoch[52] Batch [1300]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.089643,	
2017-06-28 03:16:02,399 Epoch[52] Batch [1310]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089677,	
2017-06-28 03:16:07,053 Epoch[52] Batch [1320]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.089667,	
2017-06-28 03:16:11,704 Epoch[52] Batch [1330]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.089724,	
2017-06-28 03:16:16,600 Epoch[52] Batch [1340]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089773,	
2017-06-28 03:16:21,176 Epoch[52] Batch [1350]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.089800,	
2017-06-28 03:16:25,789 Epoch[52] Batch [1360]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.089771,	
2017-06-28 03:16:30,268 Epoch[52] Batch [1370]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089749,	
2017-06-28 03:16:34,836 Epoch[52] Batch [1380]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.089790,	
2017-06-28 03:16:39,399 Epoch[52] Batch [1390]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089784,	
2017-06-28 03:16:44,026 Epoch[52] Batch [1400]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.089812,	
2017-06-28 03:16:48,519 Epoch[52] Batch [1410]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.089833,	
2017-06-28 03:16:52,996 Epoch[52] Batch [1420]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089919,	
2017-06-28 03:16:57,558 Epoch[52] Batch [1430]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.089898,	
2017-06-28 03:17:02,347 Epoch[52] Batch [1440]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089884,	
2017-06-28 03:17:07,190 Epoch[52] Batch [1450]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.089878,	
2017-06-28 03:17:11,878 Epoch[52] Batch [1460]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089964,	
2017-06-28 03:17:16,476 Epoch[52] Batch [1470]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.089903,	
2017-06-28 03:17:20,956 Epoch[52] Batch [1480]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.089898,	
2017-06-28 03:17:23,667 Epoch[52] Train-FCNLogLoss=0.089901
2017-06-28 03:17:23,667 Epoch[52] Time cost=689.213
2017-06-28 03:17:24,458 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0053.params"
2017-06-28 03:17:26,620 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9-0053.states"
2017-06-28 03:17:26,693 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate9x9',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate9x9'}

2017-06-28 03:17:35,993 testing 4/500 data 1.0366s net 0.2948s post 0.0098s
2017-06-28 03:17:36,638 testing 8/500 data 0.7106s net 0.2716s post 0.0107s
2017-06-28 03:17:37,332 testing 12/500 data 0.6194s net 0.2633s post 0.0106s
2017-06-28 03:17:37,931 testing 16/500 data 0.5507s net 0.2585s post 0.0105s
2017-06-28 03:17:38,512 testing 20/500 data 0.5056s net 0.2558s post 0.0105s
2017-06-28 03:17:39,179 testing 24/500 data 0.4901s net 0.2543s post 0.0100s
2017-06-28 03:17:39,928 testing 28/500 data 0.4900s net 0.2534s post 0.0103s
2017-06-28 03:17:40,621 testing 32/500 data 0.4834s net 0.2523s post 0.0104s
2017-06-28 03:17:41,314 testing 36/500 data 0.4785s net 0.2516s post 0.0100s
2017-06-28 03:17:41,880 testing 40/500 data 0.4618s net 0.2512s post 0.0098s
2017-06-28 03:17:42,539 testing 44/500 data 0.4561s net 0.2508s post 0.0100s
2017-06-28 03:17:43,253 testing 48/500 data 0.4563s net 0.2503s post 0.0102s
2017-06-28 03:17:43,980 testing 52/500 data 0.4574s net 0.2500s post 0.0100s
2017-06-28 03:17:44,552 testing 56/500 data 0.4474s net 0.2499s post 0.0098s
2017-06-28 03:17:45,212 testing 60/500 data 0.4449s net 0.2495s post 0.0096s
2017-06-28 03:17:45,953 testing 64/500 data 0.4477s net 0.2491s post 0.0095s
2017-06-28 03:17:46,685 testing 68/500 data 0.4496s net 0.2489s post 0.0094s
2017-06-28 03:17:47,423 testing 72/500 data 0.4514s net 0.2486s post 0.0096s
2017-06-28 03:17:48,124 testing 76/500 data 0.4510s net 0.2483s post 0.0097s
2017-06-28 03:17:48,845 testing 80/500 data 0.4520s net 0.2481s post 0.0096s
2017-06-28 03:17:49,561 testing 84/500 data 0.4523s net 0.2479s post 0.0097s
2017-06-28 03:17:50,294 testing 88/500 data 0.4534s net 0.2477s post 0.0099s
2017-06-28 03:17:51,009 testing 92/500 data 0.4537s net 0.2475s post 0.0099s
2017-06-28 03:17:51,738 testing 96/500 data 0.4546s net 0.2475s post 0.0098s
2017-06-28 03:17:52,468 testing 100/500 data 0.4553s net 0.2475s post 0.0099s
2017-06-28 03:17:53,231 testing 104/500 data 0.4572s net 0.2474s post 0.0100s
2017-06-28 03:17:53,992 testing 108/500 data 0.4591s net 0.2472s post 0.0099s
2017-06-28 03:17:54,686 testing 112/500 data 0.4585s net 0.2472s post 0.0098s
2017-06-28 03:17:55,449 testing 116/500 data 0.4604s net 0.2471s post 0.0097s
2017-06-28 03:17:56,154 testing 120/500 data 0.4600s net 0.2470s post 0.0097s
2017-06-28 03:17:56,870 testing 124/500 data 0.4599s net 0.2470s post 0.0098s
2017-06-28 03:17:57,606 testing 128/500 data 0.4606s net 0.2470s post 0.0097s
2017-06-28 03:17:58,378 testing 132/500 data 0.4623s net 0.2470s post 0.0096s
2017-06-28 03:17:59,004 testing 136/500 data 0.4597s net 0.2470s post 0.0096s
2017-06-28 03:17:59,597 testing 140/500 data 0.4562s net 0.2470s post 0.0095s
2017-06-28 03:18:00,296 testing 144/500 data 0.4558s net 0.2470s post 0.0095s
2017-06-28 03:18:00,900 testing 148/500 data 0.4530s net 0.2470s post 0.0095s
2017-06-28 03:18:01,499 testing 152/500 data 0.4502s net 0.2469s post 0.0094s
2017-06-28 03:18:02,098 testing 156/500 data 0.4474s net 0.2469s post 0.0094s
2017-06-28 03:18:02,790 testing 160/500 data 0.4473s net 0.2469s post 0.0093s
2017-06-28 03:18:03,438 testing 164/500 data 0.4459s net 0.2468s post 0.0094s
2017-06-28 03:18:04,018 testing 168/500 data 0.4431s net 0.2468s post 0.0093s
2017-06-28 03:18:04,616 testing 172/500 data 0.4408s net 0.2468s post 0.0093s
2017-06-28 03:18:05,203 testing 176/500 data 0.4384s net 0.2468s post 0.0092s
2017-06-28 03:18:05,793 testing 180/500 data 0.4362s net 0.2467s post 0.0092s
2017-06-28 03:18:06,520 testing 184/500 data 0.4369s net 0.2466s post 0.0093s
2017-06-28 03:18:07,233 testing 188/500 data 0.4374s net 0.2466s post 0.0092s
2017-06-28 03:18:07,931 testing 192/500 data 0.4376s net 0.2465s post 0.0092s
2017-06-28 03:18:08,590 testing 196/500 data 0.4368s net 0.2465s post 0.0093s
2017-06-28 03:18:09,185 testing 200/500 data 0.4349s net 0.2464s post 0.0094s
2017-06-28 03:18:09,871 testing 204/500 data 0.4348s net 0.2463s post 0.0095s
2017-06-28 03:18:10,591 testing 208/500 data 0.4353s net 0.2463s post 0.0095s
2017-06-28 03:18:11,236 testing 212/500 data 0.4345s net 0.2462s post 0.0095s
2017-06-28 03:18:11,827 testing 216/500 data 0.4327s net 0.2462s post 0.0096s
2017-06-28 03:18:12,557 testing 220/500 data 0.4335s net 0.2461s post 0.0096s
2017-06-28 03:18:13,258 testing 224/500 data 0.4337s net 0.2461s post 0.0096s
2017-06-28 03:18:13,920 testing 228/500 data 0.4333s net 0.2460s post 0.0096s
2017-06-28 03:18:14,516 testing 232/500 data 0.4317s net 0.2460s post 0.0096s
2017-06-28 03:18:15,113 testing 236/500 data 0.4301s net 0.2460s post 0.0097s
2017-06-28 03:18:15,708 testing 240/500 data 0.4286s net 0.2459s post 0.0097s
2017-06-28 03:18:16,414 testing 244/500 data 0.4290s net 0.2459s post 0.0097s
2017-06-28 03:18:17,188 testing 248/500 data 0.4305s net 0.2459s post 0.0097s
2017-06-28 03:18:17,840 testing 252/500 data 0.4300s net 0.2458s post 0.0097s
2017-06-28 03:18:18,426 testing 256/500 data 0.4285s net 0.2458s post 0.0097s
2017-06-28 03:18:19,093 testing 260/500 data 0.4283s net 0.2458s post 0.0097s
2017-06-28 03:18:19,798 testing 264/500 data 0.4285s net 0.2458s post 0.0097s
2017-06-28 03:18:20,397 testing 268/500 data 0.4274s net 0.2457s post 0.0097s
2017-06-28 03:18:20,996 testing 272/500 data 0.4261s net 0.2457s post 0.0097s
2017-06-28 03:18:21,582 testing 276/500 data 0.4248s net 0.2457s post 0.0097s
2017-06-28 03:18:22,147 testing 280/500 data 0.4232s net 0.2456s post 0.0097s
2017-06-28 03:18:22,821 testing 284/500 data 0.4232s net 0.2456s post 0.0096s
2017-06-28 03:18:23,541 testing 288/500 data 0.4238s net 0.2456s post 0.0096s
2017-06-28 03:18:24,214 testing 292/500 data 0.4238s net 0.2455s post 0.0095s
2017-06-28 03:18:24,825 testing 296/500 data 0.4230s net 0.2455s post 0.0095s
2017-06-28 03:18:25,419 testing 300/500 data 0.4219s net 0.2455s post 0.0095s
2017-06-28 03:18:25,997 testing 304/500 data 0.4206s net 0.2455s post 0.0095s
2017-06-28 03:18:26,576 testing 308/500 data 0.4194s net 0.2454s post 0.0095s
2017-06-28 03:18:27,165 testing 312/500 data 0.4184s net 0.2454s post 0.0094s
2017-06-28 03:18:27,746 testing 316/500 data 0.4173s net 0.2454s post 0.0094s
2017-06-28 03:18:28,335 testing 320/500 data 0.4163s net 0.2454s post 0.0094s
2017-06-28 03:18:29,038 testing 324/500 data 0.4167s net 0.2454s post 0.0093s
2017-06-28 03:18:29,729 testing 328/500 data 0.4170s net 0.2453s post 0.0093s
2017-06-28 03:18:30,442 testing 332/500 data 0.4176s net 0.2453s post 0.0093s
2017-06-28 03:18:31,115 testing 336/500 data 0.4175s net 0.2453s post 0.0094s
2017-06-28 03:18:31,811 testing 340/500 data 0.4179s net 0.2452s post 0.0093s
2017-06-28 03:18:32,429 testing 344/500 data 0.4173s net 0.2452s post 0.0094s
2017-06-28 03:18:33,095 testing 348/500 data 0.4173s net 0.2452s post 0.0093s
2017-06-28 03:18:33,692 testing 352/500 data 0.4164s net 0.2452s post 0.0094s
2017-06-28 03:18:34,282 testing 356/500 data 0.4154s net 0.2452s post 0.0094s
2017-06-28 03:18:34,869 testing 360/500 data 0.4144s net 0.2452s post 0.0094s
2017-06-28 03:18:35,533 testing 364/500 data 0.4143s net 0.2452s post 0.0095s
2017-06-28 03:18:36,102 testing 368/500 data 0.4132s net 0.2453s post 0.0095s
2017-06-28 03:18:36,768 testing 372/500 data 0.4131s net 0.2453s post 0.0095s
2017-06-28 03:18:37,348 testing 376/500 data 0.4121s net 0.2453s post 0.0095s
2017-06-28 03:18:38,022 testing 380/500 data 0.4121s net 0.2454s post 0.0096s
2017-06-28 03:18:38,706 testing 384/500 data 0.4123s net 0.2454s post 0.0096s
2017-06-28 03:18:39,410 testing 388/500 data 0.4126s net 0.2454s post 0.0096s
2017-06-28 03:18:40,174 testing 392/500 data 0.4136s net 0.2454s post 0.0096s
2017-06-28 03:18:40,899 testing 396/500 data 0.4141s net 0.2454s post 0.0096s
2017-06-28 03:18:41,528 testing 400/500 data 0.4137s net 0.2454s post 0.0097s
2017-06-28 03:18:42,095 testing 404/500 data 0.4126s net 0.2454s post 0.0097s
2017-06-28 03:18:42,656 testing 408/500 data 0.4117s net 0.2454s post 0.0096s
2017-06-28 03:18:43,246 testing 412/500 data 0.4109s net 0.2454s post 0.0096s
2017-06-28 03:18:43,830 testing 416/500 data 0.4101s net 0.2454s post 0.0097s
2017-06-28 03:18:44,393 testing 420/500 data 0.4092s net 0.2453s post 0.0096s
2017-06-28 03:18:45,095 testing 424/500 data 0.4096s net 0.2453s post 0.0096s
2017-06-28 03:18:45,793 testing 428/500 data 0.4099s net 0.2453s post 0.0096s
2017-06-28 03:18:46,427 testing 432/500 data 0.4096s net 0.2453s post 0.0096s
2017-06-28 03:18:47,031 testing 436/500 data 0.4090s net 0.2454s post 0.0096s
2017-06-28 03:18:47,756 testing 440/500 data 0.4095s net 0.2454s post 0.0097s
2017-06-28 03:18:48,361 testing 444/500 data 0.4090s net 0.2454s post 0.0097s
2017-06-28 03:18:49,020 testing 448/500 data 0.4089s net 0.2454s post 0.0097s
2017-06-28 03:18:49,807 testing 452/500 data 0.4100s net 0.2454s post 0.0097s
2017-06-28 03:18:50,536 testing 456/500 data 0.4105s net 0.2454s post 0.0097s
2017-06-28 03:18:51,220 testing 460/500 data 0.4106s net 0.2454s post 0.0097s
2017-06-28 03:18:51,986 testing 464/500 data 0.4115s net 0.2455s post 0.0097s
2017-06-28 03:18:52,656 testing 468/500 data 0.4115s net 0.2455s post 0.0097s
2017-06-28 03:18:53,354 testing 472/500 data 0.4117s net 0.2455s post 0.0098s
2017-06-28 03:18:54,013 testing 476/500 data 0.4116s net 0.2455s post 0.0098s
2017-06-28 03:18:54,611 testing 480/500 data 0.4110s net 0.2455s post 0.0097s
2017-06-28 03:18:55,188 testing 484/500 data 0.4103s net 0.2455s post 0.0098s
2017-06-28 03:18:55,777 testing 488/500 data 0.4096s net 0.2455s post 0.0098s
2017-06-28 03:18:56,515 testing 492/500 data 0.4102s net 0.2456s post 0.0098s
2017-06-28 03:18:57,176 testing 496/500 data 0.4100s net 0.2457s post 0.0098s
2017-06-28 03:18:57,749 testing 500/500 data 0.4092s net 0.2457s post 0.0098s
2017-06-28 03:20:55,245 evaluate segmentation: 

2017-06-28 03:20:55,245 IU_array:

2017-06-28 03:20:55,245 0.97848
2017-06-28 03:20:55,246 0.82724
2017-06-28 03:20:55,246 0.91276
2017-06-28 03:20:55,246 0.52735
2017-06-28 03:20:55,246 0.52061
2017-06-28 03:20:55,246 0.53865
2017-06-28 03:20:55,246 0.63383
2017-06-28 03:20:55,246 0.72916
2017-06-28 03:20:55,246 0.91445
2017-06-28 03:20:55,246 0.61439
2017-06-28 03:20:55,246 0.93461
2017-06-28 03:20:55,246 0.77563
2017-06-28 03:20:55,246 0.56819
2017-06-28 03:20:55,246 0.93642
2017-06-28 03:20:55,246 0.64179
2017-06-28 03:20:55,246 0.79233
2017-06-28 03:20:55,246 0.59455
2017-06-28 03:20:55,246 0.58379
2017-06-28 03:20:55,246 0.73959
2017-06-28 03:20:55,246 meanIU:0.72441

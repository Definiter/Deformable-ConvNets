2017-06-23 15:50:39,250 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate3x3'}

2017-06-23 15:51:46,771 Epoch[0] Batch [10]	Speed: 6.72 samples/sec	Train-FCNLogLoss=2.888954,	
2017-06-23 15:51:53,306 Epoch[0] Batch [20]	Speed: 6.12 samples/sec	Train-FCNLogLoss=2.748586,	
2017-06-23 15:51:59,748 Epoch[0] Batch [30]	Speed: 6.21 samples/sec	Train-FCNLogLoss=2.495935,	
2017-06-23 15:52:06,595 Epoch[0] Batch [40]	Speed: 5.84 samples/sec	Train-FCNLogLoss=2.246604,	
2017-06-23 15:52:12,827 Epoch[0] Batch [50]	Speed: 6.42 samples/sec	Train-FCNLogLoss=2.040770,	
2017-06-23 15:52:18,658 Epoch[0] Batch [60]	Speed: 6.86 samples/sec	Train-FCNLogLoss=1.860578,	
2017-06-23 15:52:24,593 Epoch[0] Batch [70]	Speed: 6.74 samples/sec	Train-FCNLogLoss=1.741332,	
2017-06-23 15:52:30,356 Epoch[0] Batch [80]	Speed: 6.94 samples/sec	Train-FCNLogLoss=1.619108,	
2017-06-23 15:52:35,556 Epoch[0] Batch [90]	Speed: 7.69 samples/sec	Train-FCNLogLoss=1.539819,	
2017-06-23 15:52:42,649 Epoch[0] Batch [100]	Speed: 5.64 samples/sec	Train-FCNLogLoss=1.444110,	
2017-06-23 15:52:54,328 Epoch[0] Batch [110]	Speed: 3.43 samples/sec	Train-FCNLogLoss=1.364236,	
2017-06-23 15:52:58,679 Epoch[0] Batch [120]	Speed: 9.19 samples/sec	Train-FCNLogLoss=1.298728,	
2017-06-23 15:53:03,196 Epoch[0] Batch [130]	Speed: 8.86 samples/sec	Train-FCNLogLoss=1.242698,	
2017-06-23 15:53:07,895 Epoch[0] Batch [140]	Speed: 8.51 samples/sec	Train-FCNLogLoss=1.198236,	
2017-06-23 15:53:12,350 Epoch[0] Batch [150]	Speed: 8.98 samples/sec	Train-FCNLogLoss=1.156083,	
2017-06-23 15:53:16,611 Epoch[0] Batch [160]	Speed: 9.39 samples/sec	Train-FCNLogLoss=1.119809,	
2017-06-23 15:53:20,967 Epoch[0] Batch [170]	Speed: 9.18 samples/sec	Train-FCNLogLoss=1.084647,	
2017-06-23 15:53:25,404 Epoch[0] Batch [180]	Speed: 9.04 samples/sec	Train-FCNLogLoss=1.052870,	
2017-06-23 15:53:29,776 Epoch[0] Batch [190]	Speed: 9.15 samples/sec	Train-FCNLogLoss=1.027015,	
2017-06-23 15:53:34,399 Epoch[0] Batch [200]	Speed: 8.65 samples/sec	Train-FCNLogLoss=1.000966,	
2017-06-23 15:53:38,776 Epoch[0] Batch [210]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.972996,	
2017-06-23 15:53:43,367 Epoch[0] Batch [220]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.950606,	
2017-06-23 15:53:47,941 Epoch[0] Batch [230]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.929915,	
2017-06-23 15:53:52,527 Epoch[0] Batch [240]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.909729,	
2017-06-23 15:53:57,096 Epoch[0] Batch [250]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.894068,	
2017-06-23 15:54:01,488 Epoch[0] Batch [260]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.876772,	
2017-06-23 15:54:06,021 Epoch[0] Batch [270]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.860721,	
2017-06-23 15:54:10,451 Epoch[0] Batch [280]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.847992,	
2017-06-23 15:54:15,280 Epoch[0] Batch [290]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.835737,	
2017-06-23 15:54:19,675 Epoch[0] Batch [300]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.820592,	
2017-06-23 15:54:23,793 Epoch[0] Batch [310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.808412,	
2017-06-23 15:54:28,346 Epoch[0] Batch [320]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.796686,	
2017-06-23 15:54:32,884 Epoch[0] Batch [330]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.785780,	
2017-06-23 15:54:37,585 Epoch[0] Batch [340]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.776729,	
2017-06-23 15:54:42,095 Epoch[0] Batch [350]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.768243,	
2017-06-23 15:54:47,148 Epoch[0] Batch [360]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.756201,	
2017-06-23 15:54:51,780 Epoch[0] Batch [370]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.746142,	
2017-06-23 15:54:56,535 Epoch[0] Batch [380]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.736433,	
2017-06-23 15:55:01,046 Epoch[0] Batch [390]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.728375,	
2017-06-23 15:55:05,223 Epoch[0] Batch [400]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.720810,	
2017-06-23 15:55:09,431 Epoch[0] Batch [410]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.712463,	
2017-06-23 15:55:13,844 Epoch[0] Batch [420]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.703212,	
2017-06-23 15:55:18,005 Epoch[0] Batch [430]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.695705,	
2017-06-23 15:55:22,425 Epoch[0] Batch [440]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.690163,	
2017-06-23 15:55:26,875 Epoch[0] Batch [450]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.683715,	
2017-06-23 15:55:31,101 Epoch[0] Batch [460]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.678348,	
2017-06-23 15:55:35,580 Epoch[0] Batch [470]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.672196,	
2017-06-23 15:55:40,064 Epoch[0] Batch [480]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.666212,	
2017-06-23 15:55:44,544 Epoch[0] Batch [490]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.659316,	
2017-06-23 15:55:48,994 Epoch[0] Batch [500]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.653382,	
2017-06-23 15:55:53,412 Epoch[0] Batch [510]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.648951,	
2017-06-23 15:55:57,553 Epoch[0] Batch [520]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.643346,	
2017-06-23 15:56:01,742 Epoch[0] Batch [530]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.637125,	
2017-06-23 15:56:06,019 Epoch[0] Batch [540]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.632054,	
2017-06-23 15:56:10,487 Epoch[0] Batch [550]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.626078,	
2017-06-23 15:56:15,338 Epoch[0] Batch [560]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.621442,	
2017-06-23 15:56:19,695 Epoch[0] Batch [570]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.616730,	
2017-06-23 15:56:23,819 Epoch[0] Batch [580]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.611950,	
2017-06-23 15:56:28,417 Epoch[0] Batch [590]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.606685,	
2017-06-23 15:56:32,780 Epoch[0] Batch [600]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.602428,	
2017-06-23 15:56:37,138 Epoch[0] Batch [610]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.598541,	
2017-06-23 15:56:41,642 Epoch[0] Batch [620]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.594959,	
2017-06-23 15:56:45,839 Epoch[0] Batch [630]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.590607,	
2017-06-23 15:56:50,183 Epoch[0] Batch [640]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.586877,	
2017-06-23 15:56:54,536 Epoch[0] Batch [650]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.583101,	
2017-06-23 15:56:58,979 Epoch[0] Batch [660]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.579247,	
2017-06-23 15:57:03,112 Epoch[0] Batch [670]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.575691,	
2017-06-23 15:57:07,406 Epoch[0] Batch [680]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.572846,	
2017-06-23 15:57:11,710 Epoch[0] Batch [690]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.570245,	
2017-06-23 15:57:16,362 Epoch[0] Batch [700]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.566764,	
2017-06-23 15:57:21,242 Epoch[0] Batch [710]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.563567,	
2017-06-23 15:57:25,292 Epoch[0] Batch [720]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.559750,	
2017-06-23 15:57:29,337 Epoch[0] Batch [730]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.556473,	
2017-06-23 15:57:34,046 Epoch[0] Batch [740]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.553463,	
2017-06-23 15:57:38,258 Epoch[0] Batch [750]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.550625,	
2017-06-23 15:57:42,732 Epoch[0] Batch [760]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.548450,	
2017-06-23 15:57:49,605 Epoch[0] Batch [770]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.545814,	
2017-06-23 15:57:54,492 Epoch[0] Batch [780]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.543156,	
2017-06-23 15:57:58,609 Epoch[0] Batch [790]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.541067,	
2017-06-23 15:58:02,998 Epoch[0] Batch [800]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.537996,	
2017-06-23 15:58:07,513 Epoch[0] Batch [810]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.535074,	
2017-06-23 15:58:12,140 Epoch[0] Batch [820]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.533039,	
2017-06-23 15:58:16,711 Epoch[0] Batch [830]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.530863,	
2017-06-23 15:58:21,429 Epoch[0] Batch [840]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.528144,	
2017-06-23 15:58:25,790 Epoch[0] Batch [850]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.526552,	
2017-06-23 15:58:30,218 Epoch[0] Batch [860]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.524345,	
2017-06-23 15:58:34,605 Epoch[0] Batch [870]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.522358,	
2017-06-23 15:58:39,131 Epoch[0] Batch [880]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.520086,	
2017-06-23 15:58:43,508 Epoch[0] Batch [890]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.517967,	
2017-06-23 15:58:47,690 Epoch[0] Batch [900]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.516300,	
2017-06-23 15:58:52,278 Epoch[0] Batch [910]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.514222,	
2017-06-23 15:58:56,725 Epoch[0] Batch [920]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.511759,	
2017-06-23 15:59:01,627 Epoch[0] Batch [930]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.509857,	
2017-06-23 15:59:06,020 Epoch[0] Batch [940]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.507543,	
2017-06-23 15:59:11,041 Epoch[0] Batch [950]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.505844,	
2017-06-23 15:59:15,698 Epoch[0] Batch [960]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.503898,	
2017-06-23 15:59:20,409 Epoch[0] Batch [970]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.502238,	
2017-06-23 15:59:24,593 Epoch[0] Batch [980]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.500050,	
2017-06-23 15:59:29,421 Epoch[0] Batch [990]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.498592,	
2017-06-23 15:59:34,020 Epoch[0] Batch [1000]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.497842,	
2017-06-23 15:59:38,293 Epoch[0] Batch [1010]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.497005,	
2017-06-23 15:59:42,906 Epoch[0] Batch [1020]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.496920,	
2017-06-23 15:59:47,558 Epoch[0] Batch [1030]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.497282,	
2017-06-23 15:59:51,863 Epoch[0] Batch [1040]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.496919,	
2017-06-23 15:59:56,300 Epoch[0] Batch [1050]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.496693,	
2017-06-23 16:00:00,759 Epoch[0] Batch [1060]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.496366,	
2017-06-23 16:00:07,342 Epoch[0] Batch [1070]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.495763,	
2017-06-23 16:00:13,508 Epoch[0] Batch [1080]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.494631,	
2017-06-23 16:00:18,205 Epoch[0] Batch [1090]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.494048,	
2017-06-23 16:00:23,114 Epoch[0] Batch [1100]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.492981,	
2017-06-23 16:00:27,772 Epoch[0] Batch [1110]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.491643,	
2017-06-23 16:00:32,893 Epoch[0] Batch [1120]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.490795,	
2017-06-23 16:00:38,647 Epoch[0] Batch [1130]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.489615,	
2017-06-23 16:00:45,291 Epoch[0] Batch [1140]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.489148,	
2017-06-23 16:00:52,501 Epoch[0] Batch [1150]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.487477,	
2017-06-23 16:01:00,355 Epoch[0] Batch [1160]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.487221,	
2017-06-23 16:01:08,321 Epoch[0] Batch [1170]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.485925,	
2017-06-23 16:01:15,286 Epoch[0] Batch [1180]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.484216,	
2017-06-23 16:01:21,646 Epoch[0] Batch [1190]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.483096,	
2017-06-23 16:01:27,160 Epoch[0] Batch [1200]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.481695,	
2017-06-23 16:01:32,026 Epoch[0] Batch [1210]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.480300,	
2017-06-23 16:01:36,647 Epoch[0] Batch [1220]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.479570,	
2017-06-23 16:01:41,351 Epoch[0] Batch [1230]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.479386,	
2017-06-23 16:01:46,239 Epoch[0] Batch [1240]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.478752,	
2017-06-23 16:01:50,822 Epoch[0] Batch [1250]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.478309,	
2017-06-23 16:01:56,289 Epoch[0] Batch [1260]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.477524,	
2017-06-23 16:02:00,805 Epoch[0] Batch [1270]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.476553,	
2017-06-23 16:02:05,250 Epoch[0] Batch [1280]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.475092,	
2017-06-23 16:02:09,728 Epoch[0] Batch [1290]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.474855,	
2017-06-23 16:02:14,242 Epoch[0] Batch [1300]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.473264,	
2017-06-23 16:02:19,444 Epoch[0] Batch [1310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.472112,	
2017-06-23 16:02:26,485 Epoch[0] Batch [1320]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.471349,	
2017-06-23 16:02:34,062 Epoch[0] Batch [1330]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.470793,	
2017-06-23 16:02:45,067 Epoch[0] Batch [1340]	Speed: 3.63 samples/sec	Train-FCNLogLoss=0.469552,	
2017-06-23 16:02:54,421 Epoch[0] Batch [1350]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.468166,	
2017-06-23 16:03:02,061 Epoch[0] Batch [1360]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.466741,	
2017-06-23 16:03:08,230 Epoch[0] Batch [1370]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.465295,	
2017-06-23 16:03:14,001 Epoch[0] Batch [1380]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.463809,	
2017-06-23 16:03:19,727 Epoch[0] Batch [1390]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.462598,	
2017-06-23 16:03:24,955 Epoch[0] Batch [1400]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.461304,	
2017-06-23 16:03:30,413 Epoch[0] Batch [1410]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.460097,	
2017-06-23 16:03:36,223 Epoch[0] Batch [1420]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.459156,	
2017-06-23 16:03:41,690 Epoch[0] Batch [1430]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.458733,	
2017-06-23 16:03:47,265 Epoch[0] Batch [1440]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.457792,	
2017-06-23 16:03:52,657 Epoch[0] Batch [1450]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.456532,	
2017-06-23 16:03:57,993 Epoch[0] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.455769,	
2017-06-23 16:04:03,127 Epoch[0] Batch [1470]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.454469,	
2017-06-23 16:04:08,437 Epoch[0] Batch [1480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.453331,	
2017-06-23 16:04:11,336 Epoch[0] Train-FCNLogLoss=0.452654
2017-06-23 16:04:11,336 Epoch[0] Time cost=760.945
2017-06-23 16:04:12,375 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0001.params"
2017-06-23 16:04:18,413 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0001.states"
2017-06-23 16:04:24,583 Epoch[1] Batch [10]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.288273,	
2017-06-23 16:04:29,388 Epoch[1] Batch [20]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.267258,	
2017-06-23 16:04:34,478 Epoch[1] Batch [30]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.290034,	
2017-06-23 16:04:39,119 Epoch[1] Batch [40]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.286995,	
2017-06-23 16:04:44,137 Epoch[1] Batch [50]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.282741,	
2017-06-23 16:04:49,183 Epoch[1] Batch [60]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.281388,	
2017-06-23 16:04:54,810 Epoch[1] Batch [70]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.271992,	
2017-06-23 16:04:59,765 Epoch[1] Batch [80]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.265473,	
2017-06-23 16:05:04,563 Epoch[1] Batch [90]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.268064,	
2017-06-23 16:05:09,430 Epoch[1] Batch [100]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.269210,	
2017-06-23 16:05:14,065 Epoch[1] Batch [110]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.272502,	
2017-06-23 16:05:18,817 Epoch[1] Batch [120]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.271738,	
2017-06-23 16:05:23,996 Epoch[1] Batch [130]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.271940,	
2017-06-23 16:05:28,919 Epoch[1] Batch [140]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.269917,	
2017-06-23 16:05:33,790 Epoch[1] Batch [150]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.267617,	
2017-06-23 16:05:38,592 Epoch[1] Batch [160]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.266393,	
2017-06-23 16:05:44,174 Epoch[1] Batch [170]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.264434,	
2017-06-23 16:05:48,922 Epoch[1] Batch [180]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.264262,	
2017-06-23 16:05:53,590 Epoch[1] Batch [190]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.265606,	
2017-06-23 16:05:58,125 Epoch[1] Batch [200]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.265245,	
2017-06-23 16:06:02,769 Epoch[1] Batch [210]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.265523,	
2017-06-23 16:06:07,633 Epoch[1] Batch [220]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.265677,	
2017-06-23 16:06:12,430 Epoch[1] Batch [230]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.264363,	
2017-06-23 16:06:17,190 Epoch[1] Batch [240]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.263983,	
2017-06-23 16:06:22,170 Epoch[1] Batch [250]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.264672,	
2017-06-23 16:06:27,301 Epoch[1] Batch [260]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.264664,	
2017-06-23 16:06:32,648 Epoch[1] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.265195,	
2017-06-23 16:06:37,374 Epoch[1] Batch [280]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.265756,	
2017-06-23 16:06:42,047 Epoch[1] Batch [290]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.266790,	
2017-06-23 16:06:46,795 Epoch[1] Batch [300]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.268774,	
2017-06-23 16:06:52,372 Epoch[1] Batch [310]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.267568,	
2017-06-23 16:06:57,034 Epoch[1] Batch [320]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.266524,	
2017-06-23 16:07:01,756 Epoch[1] Batch [330]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.266912,	
2017-06-23 16:07:06,545 Epoch[1] Batch [340]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.265703,	
2017-06-23 16:07:11,551 Epoch[1] Batch [350]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.266430,	
2017-06-23 16:07:16,391 Epoch[1] Batch [360]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.267198,	
2017-06-23 16:07:21,292 Epoch[1] Batch [370]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.266850,	
2017-06-23 16:07:26,343 Epoch[1] Batch [380]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.266525,	
2017-06-23 16:07:31,244 Epoch[1] Batch [390]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.267367,	
2017-06-23 16:07:36,064 Epoch[1] Batch [400]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.267998,	
2017-06-23 16:07:40,527 Epoch[1] Batch [410]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.269338,	
2017-06-23 16:07:45,087 Epoch[1] Batch [420]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.269763,	
2017-06-23 16:07:49,876 Epoch[1] Batch [430]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.269502,	
2017-06-23 16:07:54,212 Epoch[1] Batch [440]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.269913,	
2017-06-23 16:07:58,491 Epoch[1] Batch [450]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.269454,	
2017-06-23 16:08:02,950 Epoch[1] Batch [460]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.268874,	
2017-06-23 16:08:07,192 Epoch[1] Batch [470]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.268008,	
2017-06-23 16:08:11,594 Epoch[1] Batch [480]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.269196,	
2017-06-23 16:08:15,759 Epoch[1] Batch [490]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.269320,	
2017-06-23 16:08:19,934 Epoch[1] Batch [500]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.268247,	
2017-06-23 16:08:23,982 Epoch[1] Batch [510]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.268356,	
2017-06-23 16:08:28,196 Epoch[1] Batch [520]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.268042,	
2017-06-23 16:08:32,284 Epoch[1] Batch [530]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.267332,	
2017-06-23 16:08:36,208 Epoch[1] Batch [540]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.267084,	
2017-06-23 16:08:40,425 Epoch[1] Batch [550]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.266117,	
2017-06-23 16:08:44,486 Epoch[1] Batch [560]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.266376,	
2017-06-23 16:08:48,476 Epoch[1] Batch [570]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.266028,	
2017-06-23 16:08:52,566 Epoch[1] Batch [580]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.265665,	
2017-06-23 16:08:56,732 Epoch[1] Batch [590]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.265157,	
2017-06-23 16:09:01,061 Epoch[1] Batch [600]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.265611,	
2017-06-23 16:09:05,810 Epoch[1] Batch [610]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.265412,	
2017-06-23 16:09:10,753 Epoch[1] Batch [620]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.264762,	
2017-06-23 16:09:15,475 Epoch[1] Batch [630]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.263889,	
2017-06-23 16:09:20,075 Epoch[1] Batch [640]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.263816,	
2017-06-23 16:09:25,024 Epoch[1] Batch [650]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.262960,	
2017-06-23 16:09:29,663 Epoch[1] Batch [660]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.262246,	
2017-06-23 16:09:34,311 Epoch[1] Batch [670]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.261388,	
2017-06-23 16:09:38,580 Epoch[1] Batch [680]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.260446,	
2017-06-23 16:09:42,659 Epoch[1] Batch [690]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.262208,	
2017-06-23 16:09:46,521 Epoch[1] Batch [700]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.262855,	
2017-06-23 16:09:50,370 Epoch[1] Batch [710]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.263681,	
2017-06-23 16:09:54,395 Epoch[1] Batch [720]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.265725,	
2017-06-23 16:09:58,334 Epoch[1] Batch [730]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.266419,	
2017-06-23 16:10:02,294 Epoch[1] Batch [740]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.266182,	
2017-06-23 16:10:06,111 Epoch[1] Batch [750]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.266553,	
2017-06-23 16:10:10,035 Epoch[1] Batch [760]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.266441,	
2017-06-23 16:10:13,908 Epoch[1] Batch [770]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.266623,	
2017-06-23 16:10:17,624 Epoch[1] Batch [780]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.267395,	
2017-06-23 16:10:21,330 Epoch[1] Batch [790]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.267295,	
2017-06-23 16:10:25,093 Epoch[1] Batch [800]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.267812,	
2017-06-23 16:10:28,820 Epoch[1] Batch [810]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.267844,	
2017-06-23 16:10:32,533 Epoch[1] Batch [820]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.267175,	
2017-06-23 16:10:36,330 Epoch[1] Batch [830]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.266664,	
2017-06-23 16:10:40,094 Epoch[1] Batch [840]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.266046,	
2017-06-23 16:10:43,908 Epoch[1] Batch [850]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.265559,	
2017-06-23 16:10:47,621 Epoch[1] Batch [860]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.265199,	
2017-06-23 16:10:51,634 Epoch[1] Batch [870]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.264834,	
2017-06-23 16:10:55,682 Epoch[1] Batch [880]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.264359,	
2017-06-23 16:10:59,723 Epoch[1] Batch [890]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.263987,	
2017-06-23 16:11:03,630 Epoch[1] Batch [900]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.263287,	
2017-06-23 16:11:07,477 Epoch[1] Batch [910]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.262732,	
2017-06-23 16:11:11,399 Epoch[1] Batch [920]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.262413,	
2017-06-23 16:11:15,238 Epoch[1] Batch [930]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.262084,	
2017-06-23 16:11:19,163 Epoch[1] Batch [940]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.261527,	
2017-06-23 16:11:23,459 Epoch[1] Batch [950]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.261042,	
2017-06-23 16:11:27,261 Epoch[1] Batch [960]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.260669,	
2017-06-23 16:11:30,963 Epoch[1] Batch [970]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.260373,	
2017-06-23 16:11:34,781 Epoch[1] Batch [980]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.259880,	
2017-06-23 16:11:38,465 Epoch[1] Batch [990]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.259822,	
2017-06-23 16:11:42,184 Epoch[1] Batch [1000]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.259567,	
2017-06-23 16:11:46,164 Epoch[1] Batch [1010]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.259045,	
2017-06-23 16:11:50,058 Epoch[1] Batch [1020]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.258921,	
2017-06-23 16:11:54,113 Epoch[1] Batch [1030]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.258911,	
2017-06-23 16:11:58,010 Epoch[1] Batch [1040]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.258923,	
2017-06-23 16:12:01,773 Epoch[1] Batch [1050]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.258878,	
2017-06-23 16:12:05,548 Epoch[1] Batch [1060]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.258627,	
2017-06-23 16:12:09,396 Epoch[1] Batch [1070]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.258609,	
2017-06-23 16:12:13,080 Epoch[1] Batch [1080]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.258418,	
2017-06-23 16:12:16,847 Epoch[1] Batch [1090]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.258181,	
2017-06-23 16:12:20,712 Epoch[1] Batch [1100]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.257684,	
2017-06-23 16:12:24,875 Epoch[1] Batch [1110]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.257044,	
2017-06-23 16:12:29,995 Epoch[1] Batch [1120]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.256571,	
2017-06-23 16:12:36,106 Epoch[1] Batch [1130]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.256065,	
2017-06-23 16:12:42,601 Epoch[1] Batch [1140]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.255657,	
2017-06-23 16:12:48,828 Epoch[1] Batch [1150]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.255362,	
2017-06-23 16:12:53,992 Epoch[1] Batch [1160]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.255190,	
2017-06-23 16:12:58,829 Epoch[1] Batch [1170]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.255220,	
2017-06-23 16:13:02,748 Epoch[1] Batch [1180]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.255722,	
2017-06-23 16:13:06,649 Epoch[1] Batch [1190]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.256004,	
2017-06-23 16:13:10,287 Epoch[1] Batch [1200]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.256618,	
2017-06-23 16:13:13,973 Epoch[1] Batch [1210]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.256406,	
2017-06-23 16:13:17,725 Epoch[1] Batch [1220]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.256212,	
2017-06-23 16:13:21,433 Epoch[1] Batch [1230]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.256203,	
2017-06-23 16:13:25,288 Epoch[1] Batch [1240]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.256284,	
2017-06-23 16:13:28,932 Epoch[1] Batch [1250]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.256056,	
2017-06-23 16:13:32,710 Epoch[1] Batch [1260]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.256167,	
2017-06-23 16:13:36,525 Epoch[1] Batch [1270]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.256020,	
2017-06-23 16:13:40,405 Epoch[1] Batch [1280]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.255706,	
2017-06-23 16:13:44,487 Epoch[1] Batch [1290]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.255664,	
2017-06-23 16:13:48,377 Epoch[1] Batch [1300]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.255455,	
2017-06-23 16:13:52,249 Epoch[1] Batch [1310]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.255074,	
2017-06-23 16:13:56,093 Epoch[1] Batch [1320]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.254844,	
2017-06-23 16:13:59,862 Epoch[1] Batch [1330]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.254535,	
2017-06-23 16:14:03,762 Epoch[1] Batch [1340]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.254204,	
2017-06-23 16:14:07,892 Epoch[1] Batch [1350]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.254243,	
2017-06-23 16:14:12,360 Epoch[1] Batch [1360]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.253860,	
2017-06-23 16:14:17,448 Epoch[1] Batch [1370]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.253897,	
2017-06-23 16:14:22,910 Epoch[1] Batch [1380]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.253624,	
2017-06-23 16:14:29,290 Epoch[1] Batch [1390]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.253505,	
2017-06-23 16:14:37,861 Epoch[1] Batch [1400]	Speed: 4.67 samples/sec	Train-FCNLogLoss=0.253332,	
2017-06-23 16:14:45,897 Epoch[1] Batch [1410]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.253296,	
2017-06-23 16:14:54,295 Epoch[1] Batch [1420]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.253038,	
2017-06-23 16:15:02,185 Epoch[1] Batch [1430]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.253040,	
2017-06-23 16:15:09,758 Epoch[1] Batch [1440]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.252757,	
2017-06-23 16:15:15,881 Epoch[1] Batch [1450]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.252328,	
2017-06-23 16:15:21,999 Epoch[1] Batch [1460]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.252195,	
2017-06-23 16:15:27,137 Epoch[1] Batch [1470]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.252086,	
2017-06-23 16:15:32,829 Epoch[1] Batch [1480]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.251807,	
2017-06-23 16:15:35,847 Epoch[1] Train-FCNLogLoss=0.251617
2017-06-23 16:15:35,847 Epoch[1] Time cost=677.434
2017-06-23 16:15:37,006 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0002.params"
2017-06-23 16:15:41,670 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0002.states"
2017-06-23 16:15:49,052 Epoch[2] Batch [10]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.217226,	
2017-06-23 16:15:55,457 Epoch[2] Batch [20]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.201501,	
2017-06-23 16:16:01,922 Epoch[2] Batch [30]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.206403,	
2017-06-23 16:16:08,483 Epoch[2] Batch [40]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.222228,	
2017-06-23 16:16:14,588 Epoch[2] Batch [50]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.225450,	
2017-06-23 16:16:20,471 Epoch[2] Batch [60]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.222526,	
2017-06-23 16:16:26,448 Epoch[2] Batch [70]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.223244,	
2017-06-23 16:16:31,756 Epoch[2] Batch [80]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.224535,	
2017-06-23 16:16:36,543 Epoch[2] Batch [90]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.222311,	
2017-06-23 16:16:41,691 Epoch[2] Batch [100]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.219523,	
2017-06-23 16:16:45,693 Epoch[2] Batch [110]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.217286,	
2017-06-23 16:16:49,935 Epoch[2] Batch [120]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.217616,	
2017-06-23 16:16:54,055 Epoch[2] Batch [130]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.216299,	
2017-06-23 16:16:58,136 Epoch[2] Batch [140]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.214262,	
2017-06-23 16:17:02,236 Epoch[2] Batch [150]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.214575,	
2017-06-23 16:17:06,283 Epoch[2] Batch [160]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.213611,	
2017-06-23 16:17:10,201 Epoch[2] Batch [170]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.213089,	
2017-06-23 16:17:14,062 Epoch[2] Batch [180]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.212624,	
2017-06-23 16:17:17,828 Epoch[2] Batch [190]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.212581,	
2017-06-23 16:17:21,701 Epoch[2] Batch [200]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.213271,	
2017-06-23 16:17:25,548 Epoch[2] Batch [210]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.214508,	
2017-06-23 16:17:29,349 Epoch[2] Batch [220]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.213614,	
2017-06-23 16:17:33,208 Epoch[2] Batch [230]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.212439,	
2017-06-23 16:17:37,003 Epoch[2] Batch [240]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.213419,	
2017-06-23 16:17:40,803 Epoch[2] Batch [250]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.213810,	
2017-06-23 16:17:44,595 Epoch[2] Batch [260]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.212927,	
2017-06-23 16:17:48,482 Epoch[2] Batch [270]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.212927,	
2017-06-23 16:17:52,274 Epoch[2] Batch [280]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.214141,	
2017-06-23 16:17:56,096 Epoch[2] Batch [290]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.214807,	
2017-06-23 16:17:59,852 Epoch[2] Batch [300]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.214193,	
2017-06-23 16:18:03,621 Epoch[2] Batch [310]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.213220,	
2017-06-23 16:18:07,367 Epoch[2] Batch [320]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.213537,	
2017-06-23 16:18:11,179 Epoch[2] Batch [330]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.213001,	
2017-06-23 16:18:14,940 Epoch[2] Batch [340]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.213361,	
2017-06-23 16:18:18,631 Epoch[2] Batch [350]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.213439,	
2017-06-23 16:18:22,403 Epoch[2] Batch [360]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.213344,	
2017-06-23 16:18:26,156 Epoch[2] Batch [370]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.213045,	
2017-06-23 16:18:29,864 Epoch[2] Batch [380]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.212743,	
2017-06-23 16:18:33,552 Epoch[2] Batch [390]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.213064,	
2017-06-23 16:18:37,304 Epoch[2] Batch [400]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.213417,	
2017-06-23 16:18:41,110 Epoch[2] Batch [410]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.213459,	
2017-06-23 16:18:44,863 Epoch[2] Batch [420]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.213876,	
2017-06-23 16:18:48,848 Epoch[2] Batch [430]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.213254,	
2017-06-23 16:18:52,800 Epoch[2] Batch [440]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.213293,	
2017-06-23 16:18:56,866 Epoch[2] Batch [450]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.213016,	
2017-06-23 16:19:00,854 Epoch[2] Batch [460]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.212846,	
2017-06-23 16:19:04,661 Epoch[2] Batch [470]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.212626,	
2017-06-23 16:19:08,432 Epoch[2] Batch [480]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.212505,	
2017-06-23 16:19:12,210 Epoch[2] Batch [490]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.212001,	
2017-06-23 16:19:16,251 Epoch[2] Batch [500]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.211840,	
2017-06-23 16:19:20,038 Epoch[2] Batch [510]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.212032,	
2017-06-23 16:19:24,003 Epoch[2] Batch [520]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.211074,	
2017-06-23 16:19:27,890 Epoch[2] Batch [530]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.211247,	
2017-06-23 16:19:32,188 Epoch[2] Batch [540]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.211120,	
2017-06-23 16:19:37,423 Epoch[2] Batch [550]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.210649,	
2017-06-23 16:19:44,064 Epoch[2] Batch [560]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.210860,	
2017-06-23 16:19:50,519 Epoch[2] Batch [570]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.211455,	
2017-06-23 16:19:55,189 Epoch[2] Batch [580]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.211812,	
2017-06-23 16:20:00,243 Epoch[2] Batch [590]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.212579,	
2017-06-23 16:20:05,477 Epoch[2] Batch [600]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.212601,	
2017-06-23 16:20:10,028 Epoch[2] Batch [610]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.212917,	
2017-06-23 16:20:14,577 Epoch[2] Batch [620]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.212962,	
2017-06-23 16:20:18,940 Epoch[2] Batch [630]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.212680,	
2017-06-23 16:20:23,356 Epoch[2] Batch [640]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.212432,	
2017-06-23 16:20:27,350 Epoch[2] Batch [650]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.212298,	
2017-06-23 16:20:31,232 Epoch[2] Batch [660]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.212042,	
2017-06-23 16:20:35,316 Epoch[2] Batch [670]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.211851,	
2017-06-23 16:20:39,396 Epoch[2] Batch [680]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.211498,	
2017-06-23 16:20:43,501 Epoch[2] Batch [690]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.211393,	
2017-06-23 16:20:47,697 Epoch[2] Batch [700]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.211769,	
2017-06-23 16:20:51,854 Epoch[2] Batch [710]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.211263,	
2017-06-23 16:20:56,087 Epoch[2] Batch [720]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.211118,	
2017-06-23 16:21:00,230 Epoch[2] Batch [730]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.211321,	
2017-06-23 16:21:04,418 Epoch[2] Batch [740]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.211495,	
2017-06-23 16:21:08,345 Epoch[2] Batch [750]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.211670,	
2017-06-23 16:21:12,316 Epoch[2] Batch [760]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.211983,	
2017-06-23 16:21:16,174 Epoch[2] Batch [770]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.211752,	
2017-06-23 16:21:19,950 Epoch[2] Batch [780]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.211831,	
2017-06-23 16:21:24,037 Epoch[2] Batch [790]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.211626,	
2017-06-23 16:21:29,821 Epoch[2] Batch [800]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.211360,	
2017-06-23 16:21:35,767 Epoch[2] Batch [810]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.210941,	
2017-06-23 16:21:41,160 Epoch[2] Batch [820]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.210614,	
2017-06-23 16:21:47,918 Epoch[2] Batch [830]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.210713,	
2017-06-23 16:21:55,590 Epoch[2] Batch [840]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.210592,	
2017-06-23 16:22:03,212 Epoch[2] Batch [850]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.210576,	
2017-06-23 16:22:12,247 Epoch[2] Batch [860]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.210396,	
2017-06-23 16:22:20,103 Epoch[2] Batch [870]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.210141,	
2017-06-23 16:22:24,152 Epoch[2] Batch [880]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.210042,	
2017-06-23 16:22:27,994 Epoch[2] Batch [890]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.210094,	
2017-06-23 16:22:31,718 Epoch[2] Batch [900]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.209923,	
2017-06-23 16:22:35,523 Epoch[2] Batch [910]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.209848,	
2017-06-23 16:22:39,239 Epoch[2] Batch [920]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.209516,	
2017-06-23 16:22:42,952 Epoch[2] Batch [930]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.209646,	
2017-06-23 16:22:46,792 Epoch[2] Batch [940]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.209495,	
2017-06-23 16:22:50,461 Epoch[2] Batch [950]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.209161,	
2017-06-23 16:22:54,180 Epoch[2] Batch [960]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.208880,	
2017-06-23 16:22:57,932 Epoch[2] Batch [970]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.208749,	
2017-06-23 16:23:01,708 Epoch[2] Batch [980]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.208564,	
2017-06-23 16:23:05,411 Epoch[2] Batch [990]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.208292,	
2017-06-23 16:23:09,327 Epoch[2] Batch [1000]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.208460,	
2017-06-23 16:23:13,083 Epoch[2] Batch [1010]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.208391,	
2017-06-23 16:23:16,825 Epoch[2] Batch [1020]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.207989,	
2017-06-23 16:23:20,539 Epoch[2] Batch [1030]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.207530,	
2017-06-23 16:23:24,312 Epoch[2] Batch [1040]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.207751,	
2017-06-23 16:23:28,027 Epoch[2] Batch [1050]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.207695,	
2017-06-23 16:23:31,766 Epoch[2] Batch [1060]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.207656,	
2017-06-23 16:23:35,637 Epoch[2] Batch [1070]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.207555,	
2017-06-23 16:23:39,365 Epoch[2] Batch [1080]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.207280,	
2017-06-23 16:23:43,111 Epoch[2] Batch [1090]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.207000,	
2017-06-23 16:23:46,846 Epoch[2] Batch [1100]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.206581,	
2017-06-23 16:23:50,586 Epoch[2] Batch [1110]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.206181,	
2017-06-23 16:23:54,304 Epoch[2] Batch [1120]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.205974,	
2017-06-23 16:23:58,002 Epoch[2] Batch [1130]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.205795,	
2017-06-23 16:24:01,731 Epoch[2] Batch [1140]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.205995,	
2017-06-23 16:24:05,474 Epoch[2] Batch [1150]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.206047,	
2017-06-23 16:24:09,393 Epoch[2] Batch [1160]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.205918,	
2017-06-23 16:24:13,327 Epoch[2] Batch [1170]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.205744,	
2017-06-23 16:24:17,320 Epoch[2] Batch [1180]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.205819,	
2017-06-23 16:24:21,257 Epoch[2] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.205569,	
2017-06-23 16:24:25,047 Epoch[2] Batch [1200]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.205511,	
2017-06-23 16:24:28,812 Epoch[2] Batch [1210]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.205448,	
2017-06-23 16:24:32,550 Epoch[2] Batch [1220]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.205271,	
2017-06-23 16:24:36,284 Epoch[2] Batch [1230]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.205337,	
2017-06-23 16:24:40,069 Epoch[2] Batch [1240]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.205068,	
2017-06-23 16:24:43,839 Epoch[2] Batch [1250]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.204762,	
2017-06-23 16:24:47,672 Epoch[2] Batch [1260]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.204669,	
2017-06-23 16:24:51,483 Epoch[2] Batch [1270]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.204510,	
2017-06-23 16:24:55,229 Epoch[2] Batch [1280]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.204614,	
2017-06-23 16:24:59,135 Epoch[2] Batch [1290]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.204382,	
2017-06-23 16:25:05,794 Epoch[2] Batch [1300]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.203953,	
2017-06-23 16:25:12,857 Epoch[2] Batch [1310]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.203881,	
2017-06-23 16:25:19,043 Epoch[2] Batch [1320]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.203807,	
2017-06-23 16:25:24,809 Epoch[2] Batch [1330]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.203567,	
2017-06-23 16:25:29,836 Epoch[2] Batch [1340]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.203423,	
2017-06-23 16:25:34,990 Epoch[2] Batch [1350]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.203347,	
2017-06-23 16:25:40,042 Epoch[2] Batch [1360]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.203778,	
2017-06-23 16:25:46,034 Epoch[2] Batch [1370]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.203948,	
2017-06-23 16:25:52,421 Epoch[2] Batch [1380]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.203902,	
2017-06-23 16:26:00,210 Epoch[2] Batch [1390]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.203858,	
2017-06-23 16:26:04,936 Epoch[2] Batch [1400]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.203881,	
2017-06-23 16:26:09,119 Epoch[2] Batch [1410]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.203692,	
2017-06-23 16:26:13,188 Epoch[2] Batch [1420]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.203586,	
2017-06-23 16:26:17,119 Epoch[2] Batch [1430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.203706,	
2017-06-23 16:26:21,203 Epoch[2] Batch [1440]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.203634,	
2017-06-23 16:26:25,354 Epoch[2] Batch [1450]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.203517,	
2017-06-23 16:26:29,796 Epoch[2] Batch [1460]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.203504,	
2017-06-23 16:26:35,084 Epoch[2] Batch [1470]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.203640,	
2017-06-23 16:26:42,063 Epoch[2] Batch [1480]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.203618,	
2017-06-23 16:26:47,144 Epoch[2] Train-FCNLogLoss=0.203431
2017-06-23 16:26:47,145 Epoch[2] Time cost=665.474
2017-06-23 16:26:48,274 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0003.params"
2017-06-23 16:26:52,719 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0003.states"
2017-06-23 16:27:00,445 Epoch[3] Batch [10]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.213438,	
2017-06-23 16:27:06,176 Epoch[3] Batch [20]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.196382,	
2017-06-23 16:27:11,525 Epoch[3] Batch [30]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.192810,	
2017-06-23 16:27:16,556 Epoch[3] Batch [40]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.189226,	
2017-06-23 16:27:21,892 Epoch[3] Batch [50]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.188389,	
2017-06-23 16:27:27,627 Epoch[3] Batch [60]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.185891,	
2017-06-23 16:27:33,584 Epoch[3] Batch [70]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.183427,	
2017-06-23 16:27:39,680 Epoch[3] Batch [80]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.183182,	
2017-06-23 16:27:46,361 Epoch[3] Batch [90]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.182552,	
2017-06-23 16:27:53,741 Epoch[3] Batch [100]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.183988,	
2017-06-23 16:28:01,706 Epoch[3] Batch [110]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.182648,	
2017-06-23 16:28:09,600 Epoch[3] Batch [120]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.182882,	
2017-06-23 16:28:17,095 Epoch[3] Batch [130]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.181527,	
2017-06-23 16:28:24,335 Epoch[3] Batch [140]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.181019,	
2017-06-23 16:28:32,032 Epoch[3] Batch [150]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.180542,	
2017-06-23 16:28:39,520 Epoch[3] Batch [160]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.179236,	
2017-06-23 16:28:46,965 Epoch[3] Batch [170]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.180070,	
2017-06-23 16:28:54,683 Epoch[3] Batch [180]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.181897,	
2017-06-23 16:29:01,014 Epoch[3] Batch [190]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.182605,	
2017-06-23 16:29:04,893 Epoch[3] Batch [200]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.182588,	
2017-06-23 16:29:08,698 Epoch[3] Batch [210]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.183093,	
2017-06-23 16:29:12,508 Epoch[3] Batch [220]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.182191,	
2017-06-23 16:29:16,295 Epoch[3] Batch [230]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.182537,	
2017-06-23 16:29:19,939 Epoch[3] Batch [240]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.181685,	
2017-06-23 16:29:23,812 Epoch[3] Batch [250]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.181754,	
2017-06-23 16:29:27,595 Epoch[3] Batch [260]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.181624,	
2017-06-23 16:29:31,453 Epoch[3] Batch [270]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.181513,	
2017-06-23 16:29:35,138 Epoch[3] Batch [280]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.182954,	
2017-06-23 16:29:38,889 Epoch[3] Batch [290]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.183255,	
2017-06-23 16:29:42,591 Epoch[3] Batch [300]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.183801,	
2017-06-23 16:29:46,582 Epoch[3] Batch [310]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.183083,	
2017-06-23 16:29:50,925 Epoch[3] Batch [320]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.183040,	
2017-06-23 16:29:55,764 Epoch[3] Batch [330]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.184065,	
2017-06-23 16:30:01,202 Epoch[3] Batch [340]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.183912,	
2017-06-23 16:30:06,046 Epoch[3] Batch [350]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.183359,	
2017-06-23 16:30:10,046 Epoch[3] Batch [360]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.182355,	
2017-06-23 16:30:13,948 Epoch[3] Batch [370]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.182013,	
2017-06-23 16:30:17,663 Epoch[3] Batch [380]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.181936,	
2017-06-23 16:30:21,395 Epoch[3] Batch [390]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.181579,	
2017-06-23 16:30:25,348 Epoch[3] Batch [400]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.182210,	
2017-06-23 16:30:29,341 Epoch[3] Batch [410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.182421,	
2017-06-23 16:30:33,302 Epoch[3] Batch [420]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.182559,	
2017-06-23 16:30:37,102 Epoch[3] Batch [430]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.182698,	
2017-06-23 16:30:40,910 Epoch[3] Batch [440]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.183161,	
2017-06-23 16:30:44,844 Epoch[3] Batch [450]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.184586,	
2017-06-23 16:30:48,868 Epoch[3] Batch [460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.185108,	
2017-06-23 16:30:52,908 Epoch[3] Batch [470]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.185707,	
2017-06-23 16:30:57,002 Epoch[3] Batch [480]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.185180,	
2017-06-23 16:31:00,876 Epoch[3] Batch [490]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.185087,	
2017-06-23 16:31:04,644 Epoch[3] Batch [500]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.184485,	
2017-06-23 16:31:08,546 Epoch[3] Batch [510]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.184000,	
2017-06-23 16:31:12,262 Epoch[3] Batch [520]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.183760,	
2017-06-23 16:31:16,057 Epoch[3] Batch [530]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.183808,	
2017-06-23 16:31:19,919 Epoch[3] Batch [540]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.183831,	
2017-06-23 16:31:23,697 Epoch[3] Batch [550]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.184233,	
2017-06-23 16:31:27,461 Epoch[3] Batch [560]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.184604,	
2017-06-23 16:31:31,353 Epoch[3] Batch [570]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.184468,	
2017-06-23 16:31:35,128 Epoch[3] Batch [580]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.184085,	
2017-06-23 16:31:38,833 Epoch[3] Batch [590]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.183961,	
2017-06-23 16:31:42,709 Epoch[3] Batch [600]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.184034,	
2017-06-23 16:31:46,510 Epoch[3] Batch [610]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.184183,	
2017-06-23 16:31:50,394 Epoch[3] Batch [620]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.184475,	
2017-06-23 16:31:54,147 Epoch[3] Batch [630]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.185028,	
2017-06-23 16:31:57,917 Epoch[3] Batch [640]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.185007,	
2017-06-23 16:32:01,817 Epoch[3] Batch [650]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.184858,	
2017-06-23 16:32:05,772 Epoch[3] Batch [660]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.185027,	
2017-06-23 16:32:09,662 Epoch[3] Batch [670]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.185034,	
2017-06-23 16:32:13,426 Epoch[3] Batch [680]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.184989,	
2017-06-23 16:32:17,264 Epoch[3] Batch [690]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.184888,	
2017-06-23 16:32:21,220 Epoch[3] Batch [700]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.184523,	
2017-06-23 16:32:25,204 Epoch[3] Batch [710]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.184480,	
2017-06-23 16:32:28,987 Epoch[3] Batch [720]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.184246,	
2017-06-23 16:32:32,820 Epoch[3] Batch [730]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.183854,	
2017-06-23 16:32:36,576 Epoch[3] Batch [740]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.183719,	
2017-06-23 16:32:40,481 Epoch[3] Batch [750]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.183607,	
2017-06-23 16:32:44,515 Epoch[3] Batch [760]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.183522,	
2017-06-23 16:32:48,617 Epoch[3] Batch [770]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.183170,	
2017-06-23 16:32:52,532 Epoch[3] Batch [780]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.182570,	
2017-06-23 16:32:56,345 Epoch[3] Batch [790]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.182981,	
2017-06-23 16:33:00,267 Epoch[3] Batch [800]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.183186,	
2017-06-23 16:33:04,006 Epoch[3] Batch [810]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.183280,	
2017-06-23 16:33:07,819 Epoch[3] Batch [820]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.183248,	
2017-06-23 16:33:11,592 Epoch[3] Batch [830]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.183873,	
2017-06-23 16:33:15,408 Epoch[3] Batch [840]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.183839,	
2017-06-23 16:33:19,152 Epoch[3] Batch [850]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.183912,	
2017-06-23 16:33:22,870 Epoch[3] Batch [860]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.183872,	
2017-06-23 16:33:26,599 Epoch[3] Batch [870]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.184066,	
2017-06-23 16:33:30,442 Epoch[3] Batch [880]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.184257,	
2017-06-23 16:33:34,214 Epoch[3] Batch [890]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.184107,	
2017-06-23 16:33:37,965 Epoch[3] Batch [900]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.184031,	
2017-06-23 16:33:41,826 Epoch[3] Batch [910]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.184360,	
2017-06-23 16:33:45,594 Epoch[3] Batch [920]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.184097,	
2017-06-23 16:33:49,392 Epoch[3] Batch [930]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.184373,	
2017-06-23 16:33:53,107 Epoch[3] Batch [940]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.184501,	
2017-06-23 16:33:56,973 Epoch[3] Batch [950]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.184467,	
2017-06-23 16:34:00,819 Epoch[3] Batch [960]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.184311,	
2017-06-23 16:34:04,583 Epoch[3] Batch [970]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.184176,	
2017-06-23 16:34:08,493 Epoch[3] Batch [980]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.184109,	
2017-06-23 16:34:12,527 Epoch[3] Batch [990]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.183772,	
2017-06-23 16:34:16,222 Epoch[3] Batch [1000]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.183783,	
2017-06-23 16:34:20,092 Epoch[3] Batch [1010]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.183860,	
2017-06-23 16:34:24,059 Epoch[3] Batch [1020]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.183802,	
2017-06-23 16:34:27,835 Epoch[3] Batch [1030]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.184068,	
2017-06-23 16:34:31,704 Epoch[3] Batch [1040]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.183894,	
2017-06-23 16:34:35,718 Epoch[3] Batch [1050]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.184118,	
2017-06-23 16:34:39,701 Epoch[3] Batch [1060]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.184016,	
2017-06-23 16:34:43,819 Epoch[3] Batch [1070]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.183922,	
2017-06-23 16:34:47,816 Epoch[3] Batch [1080]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.183918,	
2017-06-23 16:34:51,630 Epoch[3] Batch [1090]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.183610,	
2017-06-23 16:34:55,455 Epoch[3] Batch [1100]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.183721,	
2017-06-23 16:34:59,174 Epoch[3] Batch [1110]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.183567,	
2017-06-23 16:35:02,899 Epoch[3] Batch [1120]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.183488,	
2017-06-23 16:35:06,708 Epoch[3] Batch [1130]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.183403,	
2017-06-23 16:35:10,434 Epoch[3] Batch [1140]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.183512,	
2017-06-23 16:35:14,258 Epoch[3] Batch [1150]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.183804,	
2017-06-23 16:35:18,088 Epoch[3] Batch [1160]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.183623,	
2017-06-23 16:35:21,876 Epoch[3] Batch [1170]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.183550,	
2017-06-23 16:35:25,726 Epoch[3] Batch [1180]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.183365,	
2017-06-23 16:35:29,643 Epoch[3] Batch [1190]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.183362,	
2017-06-23 16:35:33,414 Epoch[3] Batch [1200]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.183439,	
2017-06-23 16:35:37,211 Epoch[3] Batch [1210]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.183788,	
2017-06-23 16:35:41,966 Epoch[3] Batch [1220]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.184007,	
2017-06-23 16:35:45,950 Epoch[3] Batch [1230]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.183950,	
2017-06-23 16:35:49,847 Epoch[3] Batch [1240]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.183937,	
2017-06-23 16:35:53,543 Epoch[3] Batch [1250]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.183966,	
2017-06-23 16:35:57,240 Epoch[3] Batch [1260]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.183877,	
2017-06-23 16:36:01,071 Epoch[3] Batch [1270]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.183925,	
2017-06-23 16:36:04,826 Epoch[3] Batch [1280]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.183847,	
2017-06-23 16:36:08,588 Epoch[3] Batch [1290]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.183624,	
2017-06-23 16:36:12,296 Epoch[3] Batch [1300]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.183497,	
2017-06-23 16:36:16,132 Epoch[3] Batch [1310]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.183410,	
2017-06-23 16:36:19,861 Epoch[3] Batch [1320]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.183338,	
2017-06-23 16:36:23,474 Epoch[3] Batch [1330]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.183244,	
2017-06-23 16:36:27,185 Epoch[3] Batch [1340]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.183139,	
2017-06-23 16:36:30,886 Epoch[3] Batch [1350]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.183139,	
2017-06-23 16:36:34,840 Epoch[3] Batch [1360]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.183368,	
2017-06-23 16:36:38,650 Epoch[3] Batch [1370]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.183454,	
2017-06-23 16:36:42,522 Epoch[3] Batch [1380]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.183321,	
2017-06-23 16:36:46,412 Epoch[3] Batch [1390]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.183349,	
2017-06-23 16:36:50,213 Epoch[3] Batch [1400]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.183349,	
2017-06-23 16:36:53,958 Epoch[3] Batch [1410]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.183215,	
2017-06-23 16:36:57,763 Epoch[3] Batch [1420]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.183055,	
2017-06-23 16:37:01,565 Epoch[3] Batch [1430]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.183058,	
2017-06-23 16:37:05,486 Epoch[3] Batch [1440]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.183371,	
2017-06-23 16:37:09,424 Epoch[3] Batch [1450]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.183262,	
2017-06-23 16:37:13,253 Epoch[3] Batch [1460]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.183350,	
2017-06-23 16:37:17,131 Epoch[3] Batch [1470]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.183590,	
2017-06-23 16:37:20,933 Epoch[3] Batch [1480]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.183641,	
2017-06-23 16:37:23,209 Epoch[3] Train-FCNLogLoss=0.183541
2017-06-23 16:37:23,210 Epoch[3] Time cost=630.490
2017-06-23 16:37:23,960 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0004.params"
2017-06-23 16:37:28,239 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0004.states"
2017-06-23 16:37:33,367 Epoch[4] Batch [10]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.174946,	
2017-06-23 16:37:37,723 Epoch[4] Batch [20]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.163474,	
2017-06-23 16:37:41,852 Epoch[4] Batch [30]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.165070,	
2017-06-23 16:37:45,548 Epoch[4] Batch [40]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.159646,	
2017-06-23 16:37:49,273 Epoch[4] Batch [50]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.161575,	
2017-06-23 16:37:53,018 Epoch[4] Batch [60]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.162247,	
2017-06-23 16:37:56,689 Epoch[4] Batch [70]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.164275,	
2017-06-23 16:38:00,544 Epoch[4] Batch [80]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.161796,	
2017-06-23 16:38:04,165 Epoch[4] Batch [90]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.160717,	
2017-06-23 16:38:07,939 Epoch[4] Batch [100]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.170017,	
2017-06-23 16:38:11,703 Epoch[4] Batch [110]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.170542,	
2017-06-23 16:38:15,552 Epoch[4] Batch [120]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.169837,	
2017-06-23 16:38:19,266 Epoch[4] Batch [130]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.169761,	
2017-06-23 16:38:23,031 Epoch[4] Batch [140]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.171043,	
2017-06-23 16:38:26,787 Epoch[4] Batch [150]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.171627,	
2017-06-23 16:38:30,684 Epoch[4] Batch [160]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.170986,	
2017-06-23 16:38:34,645 Epoch[4] Batch [170]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.170701,	
2017-06-23 16:38:38,649 Epoch[4] Batch [180]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.169792,	
2017-06-23 16:38:42,535 Epoch[4] Batch [190]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.169061,	
2017-06-23 16:38:46,308 Epoch[4] Batch [200]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.168505,	
2017-06-23 16:38:50,057 Epoch[4] Batch [210]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.169854,	
2017-06-23 16:38:53,790 Epoch[4] Batch [220]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.170893,	
2017-06-23 16:38:57,508 Epoch[4] Batch [230]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.170393,	
2017-06-23 16:39:01,290 Epoch[4] Batch [240]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.170827,	
2017-06-23 16:39:05,141 Epoch[4] Batch [250]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.170405,	
2017-06-23 16:39:08,954 Epoch[4] Batch [260]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.170355,	
2017-06-23 16:39:12,710 Epoch[4] Batch [270]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.169181,	
2017-06-23 16:39:16,640 Epoch[4] Batch [280]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.170795,	
2017-06-23 16:39:20,654 Epoch[4] Batch [290]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.170997,	
2017-06-23 16:39:24,798 Epoch[4] Batch [300]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.170858,	
2017-06-23 16:39:29,774 Epoch[4] Batch [310]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.170880,	
2017-06-23 16:39:34,319 Epoch[4] Batch [320]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.171006,	
2017-06-23 16:39:38,216 Epoch[4] Batch [330]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.171349,	
2017-06-23 16:39:41,990 Epoch[4] Batch [340]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.171943,	
2017-06-23 16:39:45,679 Epoch[4] Batch [350]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.172011,	
2017-06-23 16:39:49,375 Epoch[4] Batch [360]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.171736,	
2017-06-23 16:39:53,112 Epoch[4] Batch [370]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.171386,	
2017-06-23 16:39:56,855 Epoch[4] Batch [380]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.171873,	
2017-06-23 16:40:00,607 Epoch[4] Batch [390]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.171824,	
2017-06-23 16:40:04,309 Epoch[4] Batch [400]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.172019,	
2017-06-23 16:40:08,008 Epoch[4] Batch [410]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.171894,	
2017-06-23 16:40:11,711 Epoch[4] Batch [420]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.172132,	
2017-06-23 16:40:15,395 Epoch[4] Batch [430]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.172187,	
2017-06-23 16:40:19,129 Epoch[4] Batch [440]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.172723,	
2017-06-23 16:40:23,049 Epoch[4] Batch [450]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.173741,	
2017-06-23 16:40:26,992 Epoch[4] Batch [460]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.174018,	
2017-06-23 16:40:30,846 Epoch[4] Batch [470]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.174194,	
2017-06-23 16:40:34,838 Epoch[4] Batch [480]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.174308,	
2017-06-23 16:40:38,710 Epoch[4] Batch [490]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.174209,	
2017-06-23 16:40:42,498 Epoch[4] Batch [500]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.174088,	
2017-06-23 16:40:46,215 Epoch[4] Batch [510]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.174609,	
2017-06-23 16:40:50,010 Epoch[4] Batch [520]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.174682,	
2017-06-23 16:40:53,841 Epoch[4] Batch [530]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.174393,	
2017-06-23 16:40:57,525 Epoch[4] Batch [540]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.174931,	
2017-06-23 16:41:01,452 Epoch[4] Batch [550]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.175458,	
2017-06-23 16:41:05,342 Epoch[4] Batch [560]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.175620,	
2017-06-23 16:41:09,130 Epoch[4] Batch [570]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.175412,	
2017-06-23 16:41:13,101 Epoch[4] Batch [580]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.175042,	
2017-06-23 16:41:17,497 Epoch[4] Batch [590]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.174990,	
2017-06-23 16:41:23,309 Epoch[4] Batch [600]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.174616,	
2017-06-23 16:41:28,937 Epoch[4] Batch [610]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.175092,	
2017-06-23 16:41:34,209 Epoch[4] Batch [620]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.175042,	
2017-06-23 16:41:38,647 Epoch[4] Batch [630]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.175344,	
2017-06-23 16:41:42,807 Epoch[4] Batch [640]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.174793,	
2017-06-23 16:41:46,658 Epoch[4] Batch [650]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.174767,	
2017-06-23 16:41:50,331 Epoch[4] Batch [660]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.174925,	
2017-06-23 16:41:54,089 Epoch[4] Batch [670]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.174781,	
2017-06-23 16:41:57,796 Epoch[4] Batch [680]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.174762,	
2017-06-23 16:42:01,505 Epoch[4] Batch [690]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.174474,	
2017-06-23 16:42:05,192 Epoch[4] Batch [700]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.174471,	
2017-06-23 16:42:08,884 Epoch[4] Batch [710]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.174125,	
2017-06-23 16:42:12,801 Epoch[4] Batch [720]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.174035,	
2017-06-23 16:42:16,758 Epoch[4] Batch [730]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.173693,	
2017-06-23 16:42:20,807 Epoch[4] Batch [740]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.173560,	
2017-06-23 16:42:24,891 Epoch[4] Batch [750]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.173295,	
2017-06-23 16:42:28,660 Epoch[4] Batch [760]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.172981,	
2017-06-23 16:42:32,476 Epoch[4] Batch [770]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.172976,	
2017-06-23 16:42:36,263 Epoch[4] Batch [780]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.172625,	
2017-06-23 16:42:39,977 Epoch[4] Batch [790]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.172677,	
2017-06-23 16:42:43,723 Epoch[4] Batch [800]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.172685,	
2017-06-23 16:42:47,584 Epoch[4] Batch [810]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.172887,	
2017-06-23 16:42:51,382 Epoch[4] Batch [820]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.173122,	
2017-06-23 16:42:55,149 Epoch[4] Batch [830]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.173190,	
2017-06-23 16:42:58,975 Epoch[4] Batch [840]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.172998,	
2017-06-23 16:43:02,807 Epoch[4] Batch [850]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.173143,	
2017-06-23 16:43:06,591 Epoch[4] Batch [860]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.172933,	
2017-06-23 16:43:10,297 Epoch[4] Batch [870]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.172713,	
2017-06-23 16:43:14,091 Epoch[4] Batch [880]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.172432,	
2017-06-23 16:43:17,837 Epoch[4] Batch [890]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.172467,	
2017-06-23 16:43:21,576 Epoch[4] Batch [900]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.172441,	
2017-06-23 16:43:25,351 Epoch[4] Batch [910]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.172201,	
2017-06-23 16:43:29,121 Epoch[4] Batch [920]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.172076,	
2017-06-23 16:43:32,864 Epoch[4] Batch [930]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.171904,	
2017-06-23 16:43:36,681 Epoch[4] Batch [940]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.171807,	
2017-06-23 16:43:40,379 Epoch[4] Batch [950]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.171552,	
2017-06-23 16:43:44,150 Epoch[4] Batch [960]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.171552,	
2017-06-23 16:43:47,879 Epoch[4] Batch [970]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.171504,	
2017-06-23 16:43:51,669 Epoch[4] Batch [980]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.171668,	
2017-06-23 16:43:55,453 Epoch[4] Batch [990]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.171583,	
2017-06-23 16:43:59,213 Epoch[4] Batch [1000]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.171667,	
2017-06-23 16:44:02,942 Epoch[4] Batch [1010]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.171456,	
2017-06-23 16:44:06,703 Epoch[4] Batch [1020]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.171717,	
2017-06-23 16:44:10,642 Epoch[4] Batch [1030]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.172101,	
2017-06-23 16:44:14,627 Epoch[4] Batch [1040]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.172189,	
2017-06-23 16:44:18,519 Epoch[4] Batch [1050]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.172148,	
2017-06-23 16:44:22,578 Epoch[4] Batch [1060]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.172029,	
2017-06-23 16:44:26,400 Epoch[4] Batch [1070]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.172052,	
2017-06-23 16:44:30,116 Epoch[4] Batch [1080]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.172129,	
2017-06-23 16:44:33,906 Epoch[4] Batch [1090]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.172209,	
2017-06-23 16:44:37,688 Epoch[4] Batch [1100]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.172064,	
2017-06-23 16:44:41,504 Epoch[4] Batch [1110]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.172139,	
2017-06-23 16:44:45,318 Epoch[4] Batch [1120]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.171961,	
2017-06-23 16:44:49,150 Epoch[4] Batch [1130]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.171867,	
2017-06-23 16:44:53,042 Epoch[4] Batch [1140]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.171788,	
2017-06-23 16:44:56,802 Epoch[4] Batch [1150]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.171747,	
2017-06-23 16:45:00,606 Epoch[4] Batch [1160]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.171783,	
2017-06-23 16:45:04,361 Epoch[4] Batch [1170]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.171775,	
2017-06-23 16:45:08,153 Epoch[4] Batch [1180]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.171631,	
2017-06-23 16:45:11,952 Epoch[4] Batch [1190]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.171647,	
2017-06-23 16:45:15,746 Epoch[4] Batch [1200]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.172184,	
2017-06-23 16:45:19,590 Epoch[4] Batch [1210]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.172302,	
2017-06-23 16:45:23,230 Epoch[4] Batch [1220]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.172241,	
2017-06-23 16:45:27,068 Epoch[4] Batch [1230]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.172316,	
2017-06-23 16:45:30,855 Epoch[4] Batch [1240]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.172189,	
2017-06-23 16:45:34,635 Epoch[4] Batch [1250]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.172190,	
2017-06-23 16:45:38,391 Epoch[4] Batch [1260]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.172178,	
2017-06-23 16:45:42,096 Epoch[4] Batch [1270]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.172056,	
2017-06-23 16:45:45,904 Epoch[4] Batch [1280]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.172043,	
2017-06-23 16:45:49,608 Epoch[4] Batch [1290]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.172318,	
2017-06-23 16:45:53,371 Epoch[4] Batch [1300]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.172403,	
2017-06-23 16:45:57,135 Epoch[4] Batch [1310]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.172429,	
2017-06-23 16:46:00,866 Epoch[4] Batch [1320]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.172401,	
2017-06-23 16:46:04,607 Epoch[4] Batch [1330]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.172461,	
2017-06-23 16:46:08,424 Epoch[4] Batch [1340]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.172391,	
2017-06-23 16:46:12,407 Epoch[4] Batch [1350]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.172370,	
2017-06-23 16:46:16,354 Epoch[4] Batch [1360]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.172346,	
2017-06-23 16:46:20,462 Epoch[4] Batch [1370]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.172402,	
2017-06-23 16:46:24,316 Epoch[4] Batch [1380]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.172291,	
2017-06-23 16:46:28,072 Epoch[4] Batch [1390]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.172240,	
2017-06-23 16:46:31,901 Epoch[4] Batch [1400]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.172008,	
2017-06-23 16:46:35,701 Epoch[4] Batch [1410]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.171870,	
2017-06-23 16:46:39,511 Epoch[4] Batch [1420]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.172107,	
2017-06-23 16:46:43,256 Epoch[4] Batch [1430]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.172043,	
2017-06-23 16:46:47,105 Epoch[4] Batch [1440]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.171811,	
2017-06-23 16:46:50,887 Epoch[4] Batch [1450]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.171880,	
2017-06-23 16:46:54,650 Epoch[4] Batch [1460]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.171870,	
2017-06-23 16:46:58,411 Epoch[4] Batch [1470]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.171803,	
2017-06-23 16:47:02,238 Epoch[4] Batch [1480]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.171958,	
2017-06-23 16:47:04,474 Epoch[4] Train-FCNLogLoss=0.172000
2017-06-23 16:47:04,474 Epoch[4] Time cost=576.235
2017-06-23 16:47:05,224 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0005.params"
2017-06-23 16:47:07,928 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0005.states"
2017-06-23 16:47:12,439 Epoch[5] Batch [10]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.173117,	
2017-06-23 16:47:16,131 Epoch[5] Batch [20]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.169330,	
2017-06-23 16:47:19,983 Epoch[5] Batch [30]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.167727,	
2017-06-23 16:47:23,679 Epoch[5] Batch [40]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.172364,	
2017-06-23 16:47:27,556 Epoch[5] Batch [50]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.171684,	
2017-06-23 16:47:31,329 Epoch[5] Batch [60]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.171165,	
2017-06-23 16:47:35,101 Epoch[5] Batch [70]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.169310,	
2017-06-23 16:47:38,802 Epoch[5] Batch [80]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.169885,	
2017-06-23 16:47:42,559 Epoch[5] Batch [90]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.171048,	
2017-06-23 16:47:46,318 Epoch[5] Batch [100]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.168886,	
2017-06-23 16:47:50,022 Epoch[5] Batch [110]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.168197,	
2017-06-23 16:47:53,711 Epoch[5] Batch [120]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.166867,	
2017-06-23 16:47:57,359 Epoch[5] Batch [130]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.165644,	
2017-06-23 16:48:01,089 Epoch[5] Batch [140]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.165763,	
2017-06-23 16:48:04,803 Epoch[5] Batch [150]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.164558,	
2017-06-23 16:48:08,709 Epoch[5] Batch [160]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.165001,	
2017-06-23 16:48:12,735 Epoch[5] Batch [170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.164820,	
2017-06-23 16:48:16,737 Epoch[5] Batch [180]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.163359,	
2017-06-23 16:48:20,486 Epoch[5] Batch [190]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.162737,	
2017-06-23 16:48:24,251 Epoch[5] Batch [200]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.164413,	
2017-06-23 16:48:28,059 Epoch[5] Batch [210]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.164152,	
2017-06-23 16:48:31,842 Epoch[5] Batch [220]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.164391,	
2017-06-23 16:48:35,585 Epoch[5] Batch [230]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.163721,	
2017-06-23 16:48:39,347 Epoch[5] Batch [240]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.163121,	
2017-06-23 16:48:43,078 Epoch[5] Batch [250]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.163514,	
2017-06-23 16:48:46,861 Epoch[5] Batch [260]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.163686,	
2017-06-23 16:48:50,673 Epoch[5] Batch [270]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.163070,	
2017-06-23 16:48:54,492 Epoch[5] Batch [280]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.163003,	
2017-06-23 16:48:58,268 Epoch[5] Batch [290]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.163085,	
2017-06-23 16:49:02,025 Epoch[5] Batch [300]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.163304,	
2017-06-23 16:49:05,784 Epoch[5] Batch [310]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.162471,	
2017-06-23 16:49:09,491 Epoch[5] Batch [320]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.162500,	
2017-06-23 16:49:13,286 Epoch[5] Batch [330]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.162545,	
2017-06-23 16:49:17,231 Epoch[5] Batch [340]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.161981,	
2017-06-23 16:49:20,995 Epoch[5] Batch [350]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.162977,	
2017-06-23 16:49:24,809 Epoch[5] Batch [360]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.162430,	
2017-06-23 16:49:28,607 Epoch[5] Batch [370]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.162016,	
2017-06-23 16:49:32,372 Epoch[5] Batch [380]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.161663,	
2017-06-23 16:49:36,118 Epoch[5] Batch [390]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.161687,	
2017-06-23 16:49:39,856 Epoch[5] Batch [400]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.162460,	
2017-06-23 16:49:43,610 Epoch[5] Batch [410]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.162414,	
2017-06-23 16:49:47,364 Epoch[5] Batch [420]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.162599,	
2017-06-23 16:49:51,101 Epoch[5] Batch [430]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.162406,	
2017-06-23 16:49:54,858 Epoch[5] Batch [440]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.162710,	
2017-06-23 16:49:58,586 Epoch[5] Batch [450]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.163278,	
2017-06-23 16:50:02,341 Epoch[5] Batch [460]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.163022,	
2017-06-23 16:50:06,176 Epoch[5] Batch [470]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.162798,	
2017-06-23 16:50:10,288 Epoch[5] Batch [480]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.162791,	
2017-06-23 16:50:14,198 Epoch[5] Batch [490]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.162774,	
2017-06-23 16:50:18,067 Epoch[5] Batch [500]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.162569,	
2017-06-23 16:50:21,812 Epoch[5] Batch [510]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.162314,	
2017-06-23 16:50:25,530 Epoch[5] Batch [520]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.161935,	
2017-06-23 16:50:29,362 Epoch[5] Batch [530]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.161510,	
2017-06-23 16:50:32,988 Epoch[5] Batch [540]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.161336,	
2017-06-23 16:50:36,758 Epoch[5] Batch [550]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.161760,	
2017-06-23 16:50:40,534 Epoch[5] Batch [560]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.161581,	
2017-06-23 16:50:44,259 Epoch[5] Batch [570]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.161666,	
2017-06-23 16:50:47,978 Epoch[5] Batch [580]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.161588,	
2017-06-23 16:50:51,765 Epoch[5] Batch [590]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.161400,	
2017-06-23 16:50:55,591 Epoch[5] Batch [600]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.161212,	
2017-06-23 16:50:59,362 Epoch[5] Batch [610]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.161103,	
2017-06-23 16:51:03,129 Epoch[5] Batch [620]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.160932,	
2017-06-23 16:51:07,163 Epoch[5] Batch [630]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.160822,	
2017-06-23 16:51:11,174 Epoch[5] Batch [640]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.161016,	
2017-06-23 16:51:15,386 Epoch[5] Batch [650]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.160804,	
2017-06-23 16:51:19,400 Epoch[5] Batch [660]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.160653,	
2017-06-23 16:51:23,305 Epoch[5] Batch [670]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.160536,	
2017-06-23 16:51:27,105 Epoch[5] Batch [680]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.160842,	
2017-06-23 16:51:30,992 Epoch[5] Batch [690]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.161240,	
2017-06-23 16:51:34,752 Epoch[5] Batch [700]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.161794,	
2017-06-23 16:51:38,500 Epoch[5] Batch [710]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.161760,	
2017-06-23 16:51:42,319 Epoch[5] Batch [720]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.161958,	
2017-06-23 16:51:46,004 Epoch[5] Batch [730]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.161863,	
2017-06-23 16:51:49,741 Epoch[5] Batch [740]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.161649,	
2017-06-23 16:51:53,541 Epoch[5] Batch [750]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.161597,	
2017-06-23 16:51:57,276 Epoch[5] Batch [760]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.161506,	
2017-06-23 16:52:01,037 Epoch[5] Batch [770]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.161432,	
2017-06-23 16:52:04,790 Epoch[5] Batch [780]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.161066,	
2017-06-23 16:52:08,755 Epoch[5] Batch [790]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.160935,	
2017-06-23 16:52:12,727 Epoch[5] Batch [800]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.161075,	
2017-06-23 16:52:16,506 Epoch[5] Batch [810]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.160834,	
2017-06-23 16:52:20,284 Epoch[5] Batch [820]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.160873,	
2017-06-23 16:52:23,990 Epoch[5] Batch [830]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.160575,	
2017-06-23 16:52:27,777 Epoch[5] Batch [840]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.160523,	
2017-06-23 16:52:31,518 Epoch[5] Batch [850]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.160352,	
2017-06-23 16:52:35,302 Epoch[5] Batch [860]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.160499,	
2017-06-23 16:52:39,094 Epoch[5] Batch [870]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.160695,	
2017-06-23 16:52:42,871 Epoch[5] Batch [880]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.160530,	
2017-06-23 16:52:46,676 Epoch[5] Batch [890]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.160436,	
2017-06-23 16:52:50,453 Epoch[5] Batch [900]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.160522,	
2017-06-23 16:52:54,209 Epoch[5] Batch [910]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.160521,	
2017-06-23 16:52:58,047 Epoch[5] Batch [920]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.160446,	
2017-06-23 16:53:02,338 Epoch[5] Batch [930]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.160356,	
2017-06-23 16:53:07,023 Epoch[5] Batch [940]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.160144,	
2017-06-23 16:53:11,708 Epoch[5] Batch [950]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.159984,	
2017-06-23 16:53:15,807 Epoch[5] Batch [960]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.159765,	
2017-06-23 16:53:19,776 Epoch[5] Batch [970]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.159618,	
2017-06-23 16:53:23,694 Epoch[5] Batch [980]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.159909,	
2017-06-23 16:53:27,516 Epoch[5] Batch [990]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.159844,	
2017-06-23 16:53:31,263 Epoch[5] Batch [1000]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.159927,	
2017-06-23 16:53:35,006 Epoch[5] Batch [1010]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.159743,	
2017-06-23 16:53:38,867 Epoch[5] Batch [1020]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.159813,	
2017-06-23 16:53:42,642 Epoch[5] Batch [1030]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.159881,	
2017-06-23 16:53:46,406 Epoch[5] Batch [1040]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.159829,	
2017-06-23 16:53:50,195 Epoch[5] Batch [1050]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.159637,	
2017-06-23 16:53:53,970 Epoch[5] Batch [1060]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.159591,	
2017-06-23 16:53:58,074 Epoch[5] Batch [1070]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.159472,	
2017-06-23 16:54:01,981 Epoch[5] Batch [1080]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.159808,	
2017-06-23 16:54:05,830 Epoch[5] Batch [1090]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.159906,	
2017-06-23 16:54:09,815 Epoch[5] Batch [1100]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.160130,	
2017-06-23 16:54:13,569 Epoch[5] Batch [1110]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.160340,	
2017-06-23 16:54:17,314 Epoch[5] Batch [1120]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.160445,	
2017-06-23 16:54:21,099 Epoch[5] Batch [1130]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.160312,	
2017-06-23 16:54:24,816 Epoch[5] Batch [1140]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.160386,	
2017-06-23 16:54:28,584 Epoch[5] Batch [1150]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.160560,	
2017-06-23 16:54:32,343 Epoch[5] Batch [1160]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.160706,	
2017-06-23 16:54:36,041 Epoch[5] Batch [1170]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.160846,	
2017-06-23 16:54:39,836 Epoch[5] Batch [1180]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.160979,	
2017-06-23 16:54:43,788 Epoch[5] Batch [1190]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.160994,	
2017-06-23 16:54:47,949 Epoch[5] Batch [1200]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.161114,	
2017-06-23 16:54:52,994 Epoch[5] Batch [1210]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.161177,	
2017-06-23 16:54:58,148 Epoch[5] Batch [1220]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.161187,	
2017-06-23 16:55:02,749 Epoch[5] Batch [1230]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.161179,	
2017-06-23 16:55:07,489 Epoch[5] Batch [1240]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.161206,	
2017-06-23 16:55:11,790 Epoch[5] Batch [1250]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.161490,	
2017-06-23 16:55:15,919 Epoch[5] Batch [1260]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.161418,	
2017-06-23 16:55:20,089 Epoch[5] Batch [1270]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.161311,	
2017-06-23 16:55:25,412 Epoch[5] Batch [1280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.161266,	
2017-06-23 16:55:29,581 Epoch[5] Batch [1290]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.161173,	
2017-06-23 16:55:33,837 Epoch[5] Batch [1300]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.161433,	
2017-06-23 16:55:38,075 Epoch[5] Batch [1310]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.161518,	
2017-06-23 16:55:41,942 Epoch[5] Batch [1320]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.161406,	
2017-06-23 16:55:45,883 Epoch[5] Batch [1330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.161382,	
2017-06-23 16:55:49,872 Epoch[5] Batch [1340]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.161667,	
2017-06-23 16:55:53,850 Epoch[5] Batch [1350]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.161517,	
2017-06-23 16:55:57,719 Epoch[5] Batch [1360]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.161495,	
2017-06-23 16:56:01,469 Epoch[5] Batch [1370]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.161491,	
2017-06-23 16:56:05,227 Epoch[5] Batch [1380]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.161378,	
2017-06-23 16:56:08,964 Epoch[5] Batch [1390]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.161549,	
2017-06-23 16:56:12,736 Epoch[5] Batch [1400]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.161409,	
2017-06-23 16:56:16,429 Epoch[5] Batch [1410]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.161435,	
2017-06-23 16:56:20,159 Epoch[5] Batch [1420]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.161499,	
2017-06-23 16:56:23,952 Epoch[5] Batch [1430]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.161428,	
2017-06-23 16:56:27,805 Epoch[5] Batch [1440]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.161495,	
2017-06-23 16:56:31,537 Epoch[5] Batch [1450]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.161471,	
2017-06-23 16:56:35,475 Epoch[5] Batch [1460]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.161505,	
2017-06-23 16:56:39,505 Epoch[5] Batch [1470]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.161444,	
2017-06-23 16:56:44,003 Epoch[5] Batch [1480]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.161633,	
2017-06-23 16:56:46,935 Epoch[5] Train-FCNLogLoss=0.161664
2017-06-23 16:56:46,935 Epoch[5] Time cost=579.007
2017-06-23 16:56:47,954 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0006.params"
2017-06-23 16:56:52,318 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0006.states"
2017-06-23 16:56:57,251 Epoch[6] Batch [10]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.148098,	
2017-06-23 16:57:01,066 Epoch[6] Batch [20]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.148267,	
2017-06-23 16:57:04,853 Epoch[6] Batch [30]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.149235,	
2017-06-23 16:57:08,602 Epoch[6] Batch [40]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.147222,	
2017-06-23 16:57:12,402 Epoch[6] Batch [50]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.147908,	
2017-06-23 16:57:16,216 Epoch[6] Batch [60]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.152508,	
2017-06-23 16:57:19,929 Epoch[6] Batch [70]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.148971,	
2017-06-23 16:57:23,714 Epoch[6] Batch [80]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.147938,	
2017-06-23 16:57:27,415 Epoch[6] Batch [90]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.148320,	
2017-06-23 16:57:31,472 Epoch[6] Batch [100]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.151114,	
2017-06-23 16:57:35,244 Epoch[6] Batch [110]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.151280,	
2017-06-23 16:57:39,210 Epoch[6] Batch [120]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.150480,	
2017-06-23 16:57:43,128 Epoch[6] Batch [130]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.149948,	
2017-06-23 16:57:47,156 Epoch[6] Batch [140]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.149860,	
2017-06-23 16:57:51,029 Epoch[6] Batch [150]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.149144,	
2017-06-23 16:57:54,817 Epoch[6] Batch [160]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.150456,	
2017-06-23 16:57:58,596 Epoch[6] Batch [170]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.149606,	
2017-06-23 16:58:02,426 Epoch[6] Batch [180]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.148662,	
2017-06-23 16:58:06,211 Epoch[6] Batch [190]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.148903,	
2017-06-23 16:58:09,987 Epoch[6] Batch [200]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.149637,	
2017-06-23 16:58:13,846 Epoch[6] Batch [210]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.149396,	
2017-06-23 16:58:18,306 Epoch[6] Batch [220]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.150778,	
2017-06-23 16:58:23,487 Epoch[6] Batch [230]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.150686,	
2017-06-23 16:58:29,495 Epoch[6] Batch [240]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.150866,	
2017-06-23 16:58:35,241 Epoch[6] Batch [250]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.151803,	
2017-06-23 16:58:40,565 Epoch[6] Batch [260]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.151540,	
2017-06-23 16:58:45,435 Epoch[6] Batch [270]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.151614,	
2017-06-23 16:58:49,689 Epoch[6] Batch [280]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.151494,	
2017-06-23 16:58:53,484 Epoch[6] Batch [290]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.150870,	
2017-06-23 16:58:57,253 Epoch[6] Batch [300]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.150933,	
2017-06-23 16:59:01,087 Epoch[6] Batch [310]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.150888,	
2017-06-23 16:59:04,910 Epoch[6] Batch [320]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.151342,	
2017-06-23 16:59:08,595 Epoch[6] Batch [330]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.151499,	
2017-06-23 16:59:12,277 Epoch[6] Batch [340]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.151956,	
2017-06-23 16:59:16,092 Epoch[6] Batch [350]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.151507,	
2017-06-23 16:59:19,763 Epoch[6] Batch [360]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.151377,	
2017-06-23 16:59:23,517 Epoch[6] Batch [370]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.151535,	
2017-06-23 16:59:27,306 Epoch[6] Batch [380]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.152024,	
2017-06-23 16:59:31,248 Epoch[6] Batch [390]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.152193,	
2017-06-23 16:59:35,138 Epoch[6] Batch [400]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.152142,	
2017-06-23 16:59:39,112 Epoch[6] Batch [410]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.152380,	
2017-06-23 16:59:42,932 Epoch[6] Batch [420]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.152352,	
2017-06-23 16:59:46,848 Epoch[6] Batch [430]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.151862,	
2017-06-23 16:59:50,879 Epoch[6] Batch [440]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.152326,	
2017-06-23 16:59:54,940 Epoch[6] Batch [450]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.152434,	
2017-06-23 16:59:59,275 Epoch[6] Batch [460]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.152449,	
2017-06-23 17:00:03,797 Epoch[6] Batch [470]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.152674,	
2017-06-23 17:00:08,966 Epoch[6] Batch [480]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.152773,	
2017-06-23 17:00:15,378 Epoch[6] Batch [490]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.152564,	
2017-06-23 17:00:21,089 Epoch[6] Batch [500]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.152413,	
2017-06-23 17:00:26,364 Epoch[6] Batch [510]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.152541,	
2017-06-23 17:00:31,197 Epoch[6] Batch [520]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.152678,	
2017-06-23 17:00:35,264 Epoch[6] Batch [530]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.152727,	
2017-06-23 17:00:39,373 Epoch[6] Batch [540]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.152921,	
2017-06-23 17:00:43,200 Epoch[6] Batch [550]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.153050,	
2017-06-23 17:00:47,053 Epoch[6] Batch [560]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.152844,	
2017-06-23 17:00:50,934 Epoch[6] Batch [570]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.152588,	
2017-06-23 17:00:54,844 Epoch[6] Batch [580]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.152624,	
2017-06-23 17:00:58,607 Epoch[6] Batch [590]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.152666,	
2017-06-23 17:01:02,506 Epoch[6] Batch [600]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.152842,	
2017-06-23 17:01:06,610 Epoch[6] Batch [610]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.152383,	
2017-06-23 17:01:10,642 Epoch[6] Batch [620]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.152098,	
2017-06-23 17:01:14,560 Epoch[6] Batch [630]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.151676,	
2017-06-23 17:01:18,544 Epoch[6] Batch [640]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.151594,	
2017-06-23 17:01:22,618 Epoch[6] Batch [650]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.151458,	
2017-06-23 17:01:26,406 Epoch[6] Batch [660]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.151435,	
2017-06-23 17:01:30,283 Epoch[6] Batch [670]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.151298,	
2017-06-23 17:01:34,055 Epoch[6] Batch [680]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.151050,	
2017-06-23 17:01:37,871 Epoch[6] Batch [690]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.151405,	
2017-06-23 17:01:41,719 Epoch[6] Batch [700]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.151740,	
2017-06-23 17:01:46,379 Epoch[6] Batch [710]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.151910,	
2017-06-23 17:01:51,709 Epoch[6] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.151811,	
2017-06-23 17:01:57,818 Epoch[6] Batch [730]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.151667,	
2017-06-23 17:02:03,403 Epoch[6] Batch [740]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.151930,	
2017-06-23 17:02:08,639 Epoch[6] Batch [750]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.152465,	
2017-06-23 17:02:12,927 Epoch[6] Batch [760]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.152816,	
2017-06-23 17:02:16,933 Epoch[6] Batch [770]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.152822,	
2017-06-23 17:02:20,824 Epoch[6] Batch [780]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.153016,	
2017-06-23 17:02:24,591 Epoch[6] Batch [790]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.153448,	
2017-06-23 17:02:28,384 Epoch[6] Batch [800]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.153874,	
2017-06-23 17:02:32,414 Epoch[6] Batch [810]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.153902,	
2017-06-23 17:02:36,212 Epoch[6] Batch [820]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.154169,	
2017-06-23 17:02:40,027 Epoch[6] Batch [830]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.154140,	
2017-06-23 17:02:43,857 Epoch[6] Batch [840]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.154204,	
2017-06-23 17:02:47,687 Epoch[6] Batch [850]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.154239,	
2017-06-23 17:02:51,589 Epoch[6] Batch [860]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.154185,	
2017-06-23 17:02:55,565 Epoch[6] Batch [870]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.154182,	
2017-06-23 17:02:59,646 Epoch[6] Batch [880]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.154349,	
2017-06-23 17:03:03,590 Epoch[6] Batch [890]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.154560,	
2017-06-23 17:03:07,520 Epoch[6] Batch [900]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.154506,	
2017-06-23 17:03:11,221 Epoch[6] Batch [910]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.154538,	
2017-06-23 17:03:14,978 Epoch[6] Batch [920]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.154520,	
2017-06-23 17:03:18,798 Epoch[6] Batch [930]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.154403,	
2017-06-23 17:03:22,545 Epoch[6] Batch [940]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.154679,	
2017-06-23 17:03:26,421 Epoch[6] Batch [950]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.154646,	
2017-06-23 17:03:30,786 Epoch[6] Batch [960]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.154523,	
2017-06-23 17:03:35,933 Epoch[6] Batch [970]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.154252,	
2017-06-23 17:03:41,032 Epoch[6] Batch [980]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.154166,	
2017-06-23 17:03:47,412 Epoch[6] Batch [990]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.154079,	
2017-06-23 17:03:53,025 Epoch[6] Batch [1000]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.154075,	
2017-06-23 17:03:57,948 Epoch[6] Batch [1010]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.154204,	
2017-06-23 17:04:02,368 Epoch[6] Batch [1020]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.154208,	
2017-06-23 17:04:06,501 Epoch[6] Batch [1030]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.154146,	
2017-06-23 17:04:10,393 Epoch[6] Batch [1040]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.154054,	
2017-06-23 17:04:14,098 Epoch[6] Batch [1050]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.154198,	
2017-06-23 17:04:17,905 Epoch[6] Batch [1060]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.154108,	
2017-06-23 17:04:21,732 Epoch[6] Batch [1070]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.154236,	
2017-06-23 17:04:25,660 Epoch[6] Batch [1080]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.154317,	
2017-06-23 17:04:29,478 Epoch[6] Batch [1090]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.154399,	
2017-06-23 17:04:33,286 Epoch[6] Batch [1100]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.154715,	
2017-06-23 17:04:37,208 Epoch[6] Batch [1110]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.154619,	
2017-06-23 17:04:41,284 Epoch[6] Batch [1120]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.154584,	
2017-06-23 17:04:45,314 Epoch[6] Batch [1130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.154842,	
2017-06-23 17:04:49,378 Epoch[6] Batch [1140]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.154791,	
2017-06-23 17:04:53,203 Epoch[6] Batch [1150]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.154681,	
2017-06-23 17:04:57,069 Epoch[6] Batch [1160]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.154488,	
2017-06-23 17:05:00,961 Epoch[6] Batch [1170]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.154381,	
2017-06-23 17:05:04,809 Epoch[6] Batch [1180]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.154337,	
2017-06-23 17:05:08,741 Epoch[6] Batch [1190]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.154192,	
2017-06-23 17:05:12,936 Epoch[6] Batch [1200]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.154080,	
2017-06-23 17:05:17,489 Epoch[6] Batch [1210]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.154308,	
2017-06-23 17:05:22,877 Epoch[6] Batch [1220]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.154699,	
2017-06-23 17:05:28,911 Epoch[6] Batch [1230]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.155091,	
2017-06-23 17:05:34,800 Epoch[6] Batch [1240]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.155243,	
2017-06-23 17:05:40,028 Epoch[6] Batch [1250]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.155351,	
2017-06-23 17:05:44,664 Epoch[6] Batch [1260]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.155573,	
2017-06-23 17:05:48,743 Epoch[6] Batch [1270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.155605,	
2017-06-23 17:05:52,727 Epoch[6] Batch [1280]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.155801,	
2017-06-23 17:05:56,431 Epoch[6] Batch [1290]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.156135,	
2017-06-23 17:06:00,289 Epoch[6] Batch [1300]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.156385,	
2017-06-23 17:06:04,052 Epoch[6] Batch [1310]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.156506,	
2017-06-23 17:06:07,798 Epoch[6] Batch [1320]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.156565,	
2017-06-23 17:06:11,554 Epoch[6] Batch [1330]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.156425,	
2017-06-23 17:06:15,261 Epoch[6] Batch [1340]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.156377,	
2017-06-23 17:06:19,057 Epoch[6] Batch [1350]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.156360,	
2017-06-23 17:06:22,940 Epoch[6] Batch [1360]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.156355,	
2017-06-23 17:06:26,899 Epoch[6] Batch [1370]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.156283,	
2017-06-23 17:06:30,781 Epoch[6] Batch [1380]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.156322,	
2017-06-23 17:06:34,773 Epoch[6] Batch [1390]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.156351,	
2017-06-23 17:06:38,568 Epoch[6] Batch [1400]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.156444,	
2017-06-23 17:06:42,411 Epoch[6] Batch [1410]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.156343,	
2017-06-23 17:06:46,207 Epoch[6] Batch [1420]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.156320,	
2017-06-23 17:06:50,013 Epoch[6] Batch [1430]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.156387,	
2017-06-23 17:06:53,895 Epoch[6] Batch [1440]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.156304,	
2017-06-23 17:06:57,626 Epoch[6] Batch [1450]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.156215,	
2017-06-23 17:07:01,411 Epoch[6] Batch [1460]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.156103,	
2017-06-23 17:07:05,252 Epoch[6] Batch [1470]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.156061,	
2017-06-23 17:07:08,934 Epoch[6] Batch [1480]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.155937,	
2017-06-23 17:07:11,280 Epoch[6] Train-FCNLogLoss=0.155835
2017-06-23 17:07:11,280 Epoch[6] Time cost=618.962
2017-06-23 17:07:11,987 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0007.params"
2017-06-23 17:07:15,359 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0007.states"
2017-06-23 17:07:19,846 Epoch[7] Batch [10]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.164372,	
2017-06-23 17:07:23,628 Epoch[7] Batch [20]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.158172,	
2017-06-23 17:07:27,377 Epoch[7] Batch [30]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.156104,	
2017-06-23 17:07:31,095 Epoch[7] Batch [40]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.152636,	
2017-06-23 17:07:34,895 Epoch[7] Batch [50]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.150484,	
2017-06-23 17:07:38,671 Epoch[7] Batch [60]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.147158,	
2017-06-23 17:07:42,419 Epoch[7] Batch [70]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.144944,	
2017-06-23 17:07:46,237 Epoch[7] Batch [80]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.146860,	
2017-06-23 17:07:50,060 Epoch[7] Batch [90]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.144664,	
2017-06-23 17:07:53,892 Epoch[7] Batch [100]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.145556,	
2017-06-23 17:07:57,632 Epoch[7] Batch [110]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.145476,	
2017-06-23 17:08:01,401 Epoch[7] Batch [120]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.145448,	
2017-06-23 17:08:05,187 Epoch[7] Batch [130]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.145494,	
2017-06-23 17:08:09,018 Epoch[7] Batch [140]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.145810,	
2017-06-23 17:08:12,792 Epoch[7] Batch [150]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.145391,	
2017-06-23 17:08:16,744 Epoch[7] Batch [160]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.145856,	
2017-06-23 17:08:20,612 Epoch[7] Batch [170]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.147302,	
2017-06-23 17:08:24,624 Epoch[7] Batch [180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.147011,	
2017-06-23 17:08:28,669 Epoch[7] Batch [190]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.148322,	
2017-06-23 17:08:32,676 Epoch[7] Batch [200]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.149081,	
2017-06-23 17:08:36,521 Epoch[7] Batch [210]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.148546,	
2017-06-23 17:08:40,438 Epoch[7] Batch [220]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.148793,	
2017-06-23 17:08:44,225 Epoch[7] Batch [230]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.148668,	
2017-06-23 17:08:48,069 Epoch[7] Batch [240]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.148718,	
2017-06-23 17:08:51,808 Epoch[7] Batch [250]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.148425,	
2017-06-23 17:08:55,609 Epoch[7] Batch [260]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.148920,	
2017-06-23 17:08:59,408 Epoch[7] Batch [270]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.148553,	
2017-06-23 17:09:03,247 Epoch[7] Batch [280]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.148760,	
2017-06-23 17:09:07,112 Epoch[7] Batch [290]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.148768,	
2017-06-23 17:09:10,976 Epoch[7] Batch [300]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.147854,	
2017-06-23 17:09:14,795 Epoch[7] Batch [310]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.148363,	
2017-06-23 17:09:18,608 Epoch[7] Batch [320]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.148792,	
2017-06-23 17:09:22,463 Epoch[7] Batch [330]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.148788,	
2017-06-23 17:09:26,241 Epoch[7] Batch [340]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.148219,	
2017-06-23 17:09:30,128 Epoch[7] Batch [350]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.148602,	
2017-06-23 17:09:33,898 Epoch[7] Batch [360]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.149062,	
2017-06-23 17:09:37,594 Epoch[7] Batch [370]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.149123,	
2017-06-23 17:09:41,441 Epoch[7] Batch [380]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.148903,	
2017-06-23 17:09:45,147 Epoch[7] Batch [390]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.148781,	
2017-06-23 17:09:48,921 Epoch[7] Batch [400]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.148615,	
2017-06-23 17:09:52,717 Epoch[7] Batch [410]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.148453,	
2017-06-23 17:09:56,607 Epoch[7] Batch [420]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.149330,	
2017-06-23 17:10:00,471 Epoch[7] Batch [430]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.149065,	
2017-06-23 17:10:04,224 Epoch[7] Batch [440]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.149154,	
2017-06-23 17:10:08,061 Epoch[7] Batch [450]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.149117,	
2017-06-23 17:10:11,889 Epoch[7] Batch [460]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.149343,	
2017-06-23 17:10:15,808 Epoch[7] Batch [470]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.149275,	
2017-06-23 17:10:19,768 Epoch[7] Batch [480]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.149105,	
2017-06-23 17:10:23,768 Epoch[7] Batch [490]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.148819,	
2017-06-23 17:10:27,836 Epoch[7] Batch [500]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.148663,	
2017-06-23 17:10:31,809 Epoch[7] Batch [510]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.148155,	
2017-06-23 17:10:35,700 Epoch[7] Batch [520]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.148315,	
2017-06-23 17:10:39,517 Epoch[7] Batch [530]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.148255,	
2017-06-23 17:10:43,375 Epoch[7] Batch [540]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.148628,	
2017-06-23 17:10:47,138 Epoch[7] Batch [550]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.148905,	
2017-06-23 17:10:51,110 Epoch[7] Batch [560]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.149270,	
2017-06-23 17:10:54,979 Epoch[7] Batch [570]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.149173,	
2017-06-23 17:10:58,909 Epoch[7] Batch [580]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.148919,	
2017-06-23 17:11:02,760 Epoch[7] Batch [590]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.149010,	
2017-06-23 17:11:06,612 Epoch[7] Batch [600]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.149123,	
2017-06-23 17:11:10,614 Epoch[7] Batch [610]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.148872,	
2017-06-23 17:11:14,553 Epoch[7] Batch [620]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.148515,	
2017-06-23 17:11:18,727 Epoch[7] Batch [630]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.148390,	
2017-06-23 17:11:23,147 Epoch[7] Batch [640]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.148646,	
2017-06-23 17:11:27,785 Epoch[7] Batch [650]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.148707,	
2017-06-23 17:11:32,124 Epoch[7] Batch [660]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.148617,	
2017-06-23 17:11:36,649 Epoch[7] Batch [670]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.148440,	
2017-06-23 17:11:40,670 Epoch[7] Batch [680]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.148240,	
2017-06-23 17:11:44,473 Epoch[7] Batch [690]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.148477,	
2017-06-23 17:11:48,339 Epoch[7] Batch [700]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.148527,	
2017-06-23 17:11:52,160 Epoch[7] Batch [710]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.148551,	
2017-06-23 17:11:55,994 Epoch[7] Batch [720]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.148573,	
2017-06-23 17:11:59,787 Epoch[7] Batch [730]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.148534,	
2017-06-23 17:12:03,637 Epoch[7] Batch [740]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.148244,	
2017-06-23 17:12:07,454 Epoch[7] Batch [750]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.148009,	
2017-06-23 17:12:11,492 Epoch[7] Batch [760]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.148238,	
2017-06-23 17:12:15,500 Epoch[7] Batch [770]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.148330,	
2017-06-23 17:12:19,461 Epoch[7] Batch [780]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.148185,	
2017-06-23 17:12:23,420 Epoch[7] Batch [790]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.148158,	
2017-06-23 17:12:27,301 Epoch[7] Batch [800]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.148154,	
2017-06-23 17:12:31,078 Epoch[7] Batch [810]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.148123,	
2017-06-23 17:12:34,900 Epoch[7] Batch [820]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.148018,	
2017-06-23 17:12:38,818 Epoch[7] Batch [830]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.147989,	
2017-06-23 17:12:42,664 Epoch[7] Batch [840]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.147798,	
2017-06-23 17:12:46,466 Epoch[7] Batch [850]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.147905,	
2017-06-23 17:12:50,207 Epoch[7] Batch [860]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.147879,	
2017-06-23 17:12:54,034 Epoch[7] Batch [870]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.148023,	
2017-06-23 17:12:57,887 Epoch[7] Batch [880]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.147896,	
2017-06-23 17:13:01,671 Epoch[7] Batch [890]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.147846,	
2017-06-23 17:13:05,454 Epoch[7] Batch [900]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.147981,	
2017-06-23 17:13:09,235 Epoch[7] Batch [910]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.147925,	
2017-06-23 17:13:13,080 Epoch[7] Batch [920]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.147892,	
2017-06-23 17:13:16,892 Epoch[7] Batch [930]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.147721,	
2017-06-23 17:13:20,740 Epoch[7] Batch [940]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.147714,	
2017-06-23 17:13:24,537 Epoch[7] Batch [950]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.148264,	
2017-06-23 17:13:28,405 Epoch[7] Batch [960]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.148474,	
2017-06-23 17:13:32,207 Epoch[7] Batch [970]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.149432,	
2017-06-23 17:13:35,966 Epoch[7] Batch [980]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.149756,	
2017-06-23 17:13:39,907 Epoch[7] Batch [990]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.149794,	
2017-06-23 17:13:43,847 Epoch[7] Batch [1000]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.150063,	
2017-06-23 17:13:47,743 Epoch[7] Batch [1010]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.150072,	
2017-06-23 17:13:51,459 Epoch[7] Batch [1020]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.149989,	
2017-06-23 17:13:55,207 Epoch[7] Batch [1030]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.149982,	
2017-06-23 17:13:58,959 Epoch[7] Batch [1040]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.149939,	
2017-06-23 17:14:02,712 Epoch[7] Batch [1050]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.149968,	
2017-06-23 17:14:06,580 Epoch[7] Batch [1060]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.149978,	
2017-06-23 17:14:10,581 Epoch[7] Batch [1070]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.149999,	
2017-06-23 17:14:14,543 Epoch[7] Batch [1080]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.150190,	
2017-06-23 17:14:18,502 Epoch[7] Batch [1090]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.150153,	
2017-06-23 17:14:22,270 Epoch[7] Batch [1100]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.149996,	
2017-06-23 17:14:26,117 Epoch[7] Batch [1110]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.150027,	
2017-06-23 17:14:29,964 Epoch[7] Batch [1120]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.149851,	
2017-06-23 17:14:33,732 Epoch[7] Batch [1130]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.149969,	
2017-06-23 17:14:37,494 Epoch[7] Batch [1140]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.149995,	
2017-06-23 17:14:41,234 Epoch[7] Batch [1150]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.150019,	
2017-06-23 17:14:44,976 Epoch[7] Batch [1160]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.150065,	
2017-06-23 17:14:48,760 Epoch[7] Batch [1170]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.150141,	
2017-06-23 17:14:52,518 Epoch[7] Batch [1180]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.150087,	
2017-06-23 17:14:56,307 Epoch[7] Batch [1190]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.150288,	
2017-06-23 17:15:00,058 Epoch[7] Batch [1200]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.150099,	
2017-06-23 17:15:03,802 Epoch[7] Batch [1210]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.150146,	
2017-06-23 17:15:07,745 Epoch[7] Batch [1220]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.150141,	
2017-06-23 17:15:11,473 Epoch[7] Batch [1230]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.150142,	
2017-06-23 17:15:15,294 Epoch[7] Batch [1240]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.150046,	
2017-06-23 17:15:18,951 Epoch[7] Batch [1250]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.150092,	
2017-06-23 17:15:22,715 Epoch[7] Batch [1260]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.150165,	
2017-06-23 17:15:26,466 Epoch[7] Batch [1270]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.150029,	
2017-06-23 17:15:30,132 Epoch[7] Batch [1280]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.149997,	
2017-06-23 17:15:33,944 Epoch[7] Batch [1290]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.150110,	
2017-06-23 17:15:37,659 Epoch[7] Batch [1300]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.150182,	
2017-06-23 17:15:41,462 Epoch[7] Batch [1310]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.150128,	
2017-06-23 17:15:45,197 Epoch[7] Batch [1320]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.150169,	
2017-06-23 17:15:48,895 Epoch[7] Batch [1330]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.150031,	
2017-06-23 17:15:52,668 Epoch[7] Batch [1340]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.150112,	
2017-06-23 17:15:56,352 Epoch[7] Batch [1350]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.150238,	
2017-06-23 17:16:00,130 Epoch[7] Batch [1360]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.150158,	
2017-06-23 17:16:03,814 Epoch[7] Batch [1370]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.150147,	
2017-06-23 17:16:07,739 Epoch[7] Batch [1380]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.150166,	
2017-06-23 17:16:11,644 Epoch[7] Batch [1390]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.150039,	
2017-06-23 17:16:15,580 Epoch[7] Batch [1400]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.149974,	
2017-06-23 17:16:19,390 Epoch[7] Batch [1410]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.149967,	
2017-06-23 17:16:23,265 Epoch[7] Batch [1420]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.150023,	
2017-06-23 17:16:27,062 Epoch[7] Batch [1430]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.150040,	
2017-06-23 17:16:30,871 Epoch[7] Batch [1440]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.149955,	
2017-06-23 17:16:34,680 Epoch[7] Batch [1450]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.149962,	
2017-06-23 17:16:38,436 Epoch[7] Batch [1460]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.149844,	
2017-06-23 17:16:42,127 Epoch[7] Batch [1470]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.149896,	
2017-06-23 17:16:45,944 Epoch[7] Batch [1480]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.149880,	
2017-06-23 17:16:48,107 Epoch[7] Train-FCNLogLoss=0.149815
2017-06-23 17:16:48,108 Epoch[7] Time cost=572.748
2017-06-23 17:16:48,820 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0008.params"
2017-06-23 17:16:51,746 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0008.states"
2017-06-23 17:16:56,269 Epoch[8] Batch [10]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.134945,	
2017-06-23 17:16:59,954 Epoch[8] Batch [20]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.149771,	
2017-06-23 17:17:03,722 Epoch[8] Batch [30]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.145853,	
2017-06-23 17:17:07,486 Epoch[8] Batch [40]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.144019,	
2017-06-23 17:17:11,310 Epoch[8] Batch [50]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.142267,	
2017-06-23 17:17:15,172 Epoch[8] Batch [60]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.140759,	
2017-06-23 17:17:18,928 Epoch[8] Batch [70]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.140808,	
2017-06-23 17:17:22,671 Epoch[8] Batch [80]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.140203,	
2017-06-23 17:17:26,353 Epoch[8] Batch [90]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.142185,	
2017-06-23 17:17:30,111 Epoch[8] Batch [100]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.145415,	
2017-06-23 17:17:33,849 Epoch[8] Batch [110]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.146616,	
2017-06-23 17:17:37,537 Epoch[8] Batch [120]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.148228,	
2017-06-23 17:17:41,394 Epoch[8] Batch [130]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.148097,	
2017-06-23 17:17:45,174 Epoch[8] Batch [140]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.148640,	
2017-06-23 17:17:48,963 Epoch[8] Batch [150]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.148324,	
2017-06-23 17:17:52,687 Epoch[8] Batch [160]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.147601,	
2017-06-23 17:17:56,515 Epoch[8] Batch [170]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.146999,	
2017-06-23 17:18:00,382 Epoch[8] Batch [180]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.147355,	
2017-06-23 17:18:04,208 Epoch[8] Batch [190]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.146619,	
2017-06-23 17:18:08,055 Epoch[8] Batch [200]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.147173,	
2017-06-23 17:18:12,006 Epoch[8] Batch [210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.146760,	
2017-06-23 17:18:15,925 Epoch[8] Batch [220]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.147086,	
2017-06-23 17:18:19,714 Epoch[8] Batch [230]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.145877,	
2017-06-23 17:18:23,464 Epoch[8] Batch [240]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.145228,	
2017-06-23 17:18:27,165 Epoch[8] Batch [250]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.144858,	
2017-06-23 17:18:30,945 Epoch[8] Batch [260]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.144551,	
2017-06-23 17:18:34,764 Epoch[8] Batch [270]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.144532,	
2017-06-23 17:18:38,571 Epoch[8] Batch [280]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.144781,	
2017-06-23 17:18:42,364 Epoch[8] Batch [290]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.144966,	
2017-06-23 17:18:46,260 Epoch[8] Batch [300]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.144506,	
2017-06-23 17:18:50,018 Epoch[8] Batch [310]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.143950,	
2017-06-23 17:18:53,745 Epoch[8] Batch [320]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.143984,	
2017-06-23 17:18:57,582 Epoch[8] Batch [330]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.144718,	
2017-06-23 17:19:01,351 Epoch[8] Batch [340]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.144611,	
2017-06-23 17:19:05,078 Epoch[8] Batch [350]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.144761,	
2017-06-23 17:19:08,796 Epoch[8] Batch [360]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.145226,	
2017-06-23 17:19:12,620 Epoch[8] Batch [370]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.145189,	
2017-06-23 17:19:16,427 Epoch[8] Batch [380]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.145414,	
2017-06-23 17:19:20,212 Epoch[8] Batch [390]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.145369,	
2017-06-23 17:19:23,881 Epoch[8] Batch [400]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.145278,	
2017-06-23 17:19:27,623 Epoch[8] Batch [410]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.144921,	
2017-06-23 17:19:31,267 Epoch[8] Batch [420]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.144441,	
2017-06-23 17:19:34,994 Epoch[8] Batch [430]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.144232,	
2017-06-23 17:19:38,675 Epoch[8] Batch [440]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.144910,	
2017-06-23 17:19:42,328 Epoch[8] Batch [450]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.144941,	
2017-06-23 17:19:46,076 Epoch[8] Batch [460]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.144944,	
2017-06-23 17:19:49,859 Epoch[8] Batch [470]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.145192,	
2017-06-23 17:19:53,580 Epoch[8] Batch [480]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.145592,	
2017-06-23 17:19:57,254 Epoch[8] Batch [490]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.145083,	
2017-06-23 17:20:01,096 Epoch[8] Batch [500]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.144804,	
2017-06-23 17:20:05,109 Epoch[8] Batch [510]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.144878,	
2017-06-23 17:20:09,066 Epoch[8] Batch [520]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.144861,	
2017-06-23 17:20:13,059 Epoch[8] Batch [530]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.145040,	
2017-06-23 17:20:16,988 Epoch[8] Batch [540]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.144808,	
2017-06-23 17:20:20,770 Epoch[8] Batch [550]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.144744,	
2017-06-23 17:20:24,567 Epoch[8] Batch [560]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.144385,	
2017-06-23 17:20:28,393 Epoch[8] Batch [570]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.144604,	
2017-06-23 17:20:32,225 Epoch[8] Batch [580]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.144377,	
2017-06-23 17:20:36,016 Epoch[8] Batch [590]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.144780,	
2017-06-23 17:20:39,767 Epoch[8] Batch [600]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.144705,	
2017-06-23 17:20:43,510 Epoch[8] Batch [610]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.144554,	
2017-06-23 17:20:47,288 Epoch[8] Batch [620]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.144267,	
2017-06-23 17:20:51,076 Epoch[8] Batch [630]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.144204,	
2017-06-23 17:20:54,809 Epoch[8] Batch [640]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.144186,	
2017-06-23 17:20:58,559 Epoch[8] Batch [650]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.144581,	
2017-06-23 17:21:02,313 Epoch[8] Batch [660]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.144401,	
2017-06-23 17:21:06,016 Epoch[8] Batch [670]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.144216,	
2017-06-23 17:21:09,742 Epoch[8] Batch [680]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.144149,	
2017-06-23 17:21:13,469 Epoch[8] Batch [690]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.144457,	
2017-06-23 17:21:17,247 Epoch[8] Batch [700]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.144419,	
2017-06-23 17:21:21,060 Epoch[8] Batch [710]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.144563,	
2017-06-23 17:21:24,826 Epoch[8] Batch [720]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.144675,	
2017-06-23 17:21:28,577 Epoch[8] Batch [730]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.144390,	
2017-06-23 17:21:32,282 Epoch[8] Batch [740]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.144397,	
2017-06-23 17:21:35,972 Epoch[8] Batch [750]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.144388,	
2017-06-23 17:21:39,674 Epoch[8] Batch [760]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.144386,	
2017-06-23 17:21:43,392 Epoch[8] Batch [770]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.144309,	
2017-06-23 17:21:47,159 Epoch[8] Batch [780]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.144471,	
2017-06-23 17:21:50,939 Epoch[8] Batch [790]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.144531,	
2017-06-23 17:21:54,636 Epoch[8] Batch [800]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.144400,	
2017-06-23 17:21:58,401 Epoch[8] Batch [810]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.144308,	
2017-06-23 17:22:02,475 Epoch[8] Batch [820]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.144064,	
2017-06-23 17:22:06,458 Epoch[8] Batch [830]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.143997,	
2017-06-23 17:22:10,362 Epoch[8] Batch [840]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.144172,	
2017-06-23 17:22:14,399 Epoch[8] Batch [850]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.144332,	
2017-06-23 17:22:18,151 Epoch[8] Batch [860]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.144264,	
2017-06-23 17:22:21,882 Epoch[8] Batch [870]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.144076,	
2017-06-23 17:22:25,590 Epoch[8] Batch [880]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.144150,	
2017-06-23 17:22:29,370 Epoch[8] Batch [890]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.144118,	
2017-06-23 17:22:33,231 Epoch[8] Batch [900]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.144067,	
2017-06-23 17:22:36,885 Epoch[8] Batch [910]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.143930,	
2017-06-23 17:22:40,727 Epoch[8] Batch [920]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.143838,	
2017-06-23 17:22:44,480 Epoch[8] Batch [930]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.143777,	
2017-06-23 17:22:48,289 Epoch[8] Batch [940]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.143518,	
2017-06-23 17:22:52,054 Epoch[8] Batch [950]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.143666,	
2017-06-23 17:22:55,860 Epoch[8] Batch [960]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.143405,	
2017-06-23 17:22:59,571 Epoch[8] Batch [970]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.143220,	
2017-06-23 17:23:03,278 Epoch[8] Batch [980]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.143089,	
2017-06-23 17:23:06,988 Epoch[8] Batch [990]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.143083,	
2017-06-23 17:23:10,641 Epoch[8] Batch [1000]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.143130,	
2017-06-23 17:23:14,441 Epoch[8] Batch [1010]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.143202,	
2017-06-23 17:23:18,293 Epoch[8] Batch [1020]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.143030,	
2017-06-23 17:23:21,963 Epoch[8] Batch [1030]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.142952,	
2017-06-23 17:23:25,754 Epoch[8] Batch [1040]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.142855,	
2017-06-23 17:23:29,518 Epoch[8] Batch [1050]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.142758,	
2017-06-23 17:23:33,299 Epoch[8] Batch [1060]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.142783,	
2017-06-23 17:23:37,028 Epoch[8] Batch [1070]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.142720,	
2017-06-23 17:23:40,842 Epoch[8] Batch [1080]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.142793,	
2017-06-23 17:23:44,552 Epoch[8] Batch [1090]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.142779,	
2017-06-23 17:23:48,307 Epoch[8] Batch [1100]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.142620,	
2017-06-23 17:23:52,105 Epoch[8] Batch [1110]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.142493,	
2017-06-23 17:23:55,824 Epoch[8] Batch [1120]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.142379,	
2017-06-23 17:23:59,616 Epoch[8] Batch [1130]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.142405,	
2017-06-23 17:24:03,536 Epoch[8] Batch [1140]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.142444,	
2017-06-23 17:24:07,285 Epoch[8] Batch [1150]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.142386,	
2017-06-23 17:24:11,411 Epoch[8] Batch [1160]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.142320,	
2017-06-23 17:24:15,331 Epoch[8] Batch [1170]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.142157,	
2017-06-23 17:24:19,183 Epoch[8] Batch [1180]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.142069,	
2017-06-23 17:24:22,929 Epoch[8] Batch [1190]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.141940,	
2017-06-23 17:24:26,755 Epoch[8] Batch [1200]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.141854,	
2017-06-23 17:24:30,529 Epoch[8] Batch [1210]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.141792,	
2017-06-23 17:24:34,315 Epoch[8] Batch [1220]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.141809,	
2017-06-23 17:24:38,103 Epoch[8] Batch [1230]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.141707,	
2017-06-23 17:24:42,331 Epoch[8] Batch [1240]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.141615,	
2017-06-23 17:24:47,208 Epoch[8] Batch [1250]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.141588,	
2017-06-23 17:24:52,018 Epoch[8] Batch [1260]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.141594,	
2017-06-23 17:24:57,581 Epoch[8] Batch [1270]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.141654,	
2017-06-23 17:25:03,220 Epoch[8] Batch [1280]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.141612,	
2017-06-23 17:25:08,037 Epoch[8] Batch [1290]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.141589,	
2017-06-23 17:25:12,370 Epoch[8] Batch [1300]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.141483,	
2017-06-23 17:25:16,192 Epoch[8] Batch [1310]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.141382,	
2017-06-23 17:25:19,866 Epoch[8] Batch [1320]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.141265,	
2017-06-23 17:25:23,593 Epoch[8] Batch [1330]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.141226,	
2017-06-23 17:25:27,330 Epoch[8] Batch [1340]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.141241,	
2017-06-23 17:25:31,039 Epoch[8] Batch [1350]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.141151,	
2017-06-23 17:25:35,053 Epoch[8] Batch [1360]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.141048,	
2017-06-23 17:25:38,820 Epoch[8] Batch [1370]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.141046,	
2017-06-23 17:25:42,536 Epoch[8] Batch [1380]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.141044,	
2017-06-23 17:25:46,268 Epoch[8] Batch [1390]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.141055,	
2017-06-23 17:25:50,169 Epoch[8] Batch [1400]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.141046,	
2017-06-23 17:25:54,119 Epoch[8] Batch [1410]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.141041,	
2017-06-23 17:25:58,060 Epoch[8] Batch [1420]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.141003,	
2017-06-23 17:26:02,138 Epoch[8] Batch [1430]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.140969,	
2017-06-23 17:26:05,971 Epoch[8] Batch [1440]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.140962,	
2017-06-23 17:26:09,759 Epoch[8] Batch [1450]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.141021,	
2017-06-23 17:26:13,522 Epoch[8] Batch [1460]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.141236,	
2017-06-23 17:26:17,418 Epoch[8] Batch [1470]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.141212,	
2017-06-23 17:26:21,424 Epoch[8] Batch [1480]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.141124,	
2017-06-23 17:26:23,896 Epoch[8] Train-FCNLogLoss=0.141116
2017-06-23 17:26:23,896 Epoch[8] Time cost=572.149
2017-06-23 17:26:24,686 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0009.params"
2017-06-23 17:26:28,904 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0009.states"
2017-06-23 17:26:34,613 Epoch[9] Batch [10]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.141333,	
2017-06-23 17:26:39,768 Epoch[9] Batch [20]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.144608,	
2017-06-23 17:26:44,513 Epoch[9] Batch [30]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.145828,	
2017-06-23 17:26:49,956 Epoch[9] Batch [40]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.142155,	
2017-06-23 17:26:55,246 Epoch[9] Batch [50]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.140675,	
2017-06-23 17:27:00,045 Epoch[9] Batch [60]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.138170,	
2017-06-23 17:27:04,490 Epoch[9] Batch [70]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.143795,	
2017-06-23 17:27:08,963 Epoch[9] Batch [80]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.146537,	
2017-06-23 17:27:13,406 Epoch[9] Batch [90]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.146610,	
2017-06-23 17:27:17,770 Epoch[9] Batch [100]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.146410,	
2017-06-23 17:27:22,198 Epoch[9] Batch [110]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.145282,	
2017-06-23 17:27:26,485 Epoch[9] Batch [120]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.144878,	
2017-06-23 17:27:30,552 Epoch[9] Batch [130]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.145673,	
2017-06-23 17:27:34,869 Epoch[9] Batch [140]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.144576,	
2017-06-23 17:27:39,107 Epoch[9] Batch [150]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.146269,	
2017-06-23 17:27:43,330 Epoch[9] Batch [160]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.146887,	
2017-06-23 17:27:47,283 Epoch[9] Batch [170]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.146077,	
2017-06-23 17:27:50,896 Epoch[9] Batch [180]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.145642,	
2017-06-23 17:27:54,671 Epoch[9] Batch [190]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.146592,	
2017-06-23 17:27:58,481 Epoch[9] Batch [200]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.145997,	
2017-06-23 17:28:02,347 Epoch[9] Batch [210]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.145466,	
2017-06-23 17:28:06,356 Epoch[9] Batch [220]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.144919,	
2017-06-23 17:28:10,484 Epoch[9] Batch [230]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.144627,	
2017-06-23 17:28:14,868 Epoch[9] Batch [240]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.144682,	
2017-06-23 17:28:20,136 Epoch[9] Batch [250]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.144067,	
2017-06-23 17:28:25,946 Epoch[9] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.143977,	
2017-06-23 17:28:33,870 Epoch[9] Batch [270]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.143569,	
2017-06-23 17:28:41,114 Epoch[9] Batch [280]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.143325,	
2017-06-23 17:28:47,041 Epoch[9] Batch [290]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.143203,	
2017-06-23 17:28:52,683 Epoch[9] Batch [300]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.142423,	
2017-06-23 17:28:57,478 Epoch[9] Batch [310]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.142235,	
2017-06-23 17:29:01,986 Epoch[9] Batch [320]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.142384,	
2017-06-23 17:29:06,426 Epoch[9] Batch [330]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.142433,	
2017-06-23 17:29:10,855 Epoch[9] Batch [340]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.141935,	
2017-06-23 17:29:15,350 Epoch[9] Batch [350]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.141216,	
2017-06-23 17:29:19,547 Epoch[9] Batch [360]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.141400,	
2017-06-23 17:29:23,677 Epoch[9] Batch [370]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.141144,	
2017-06-23 17:29:27,481 Epoch[9] Batch [380]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.140961,	
2017-06-23 17:29:31,308 Epoch[9] Batch [390]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.140871,	
2017-06-23 17:29:35,207 Epoch[9] Batch [400]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.140738,	
2017-06-23 17:29:39,092 Epoch[9] Batch [410]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.140979,	
2017-06-23 17:29:42,913 Epoch[9] Batch [420]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.141260,	
2017-06-23 17:29:46,660 Epoch[9] Batch [430]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.140845,	
2017-06-23 17:29:50,361 Epoch[9] Batch [440]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.141433,	
2017-06-23 17:29:54,137 Epoch[9] Batch [450]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.141298,	
2017-06-23 17:29:57,986 Epoch[9] Batch [460]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.140767,	
2017-06-23 17:30:01,949 Epoch[9] Batch [470]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.140778,	
2017-06-23 17:30:06,527 Epoch[9] Batch [480]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.140740,	
2017-06-23 17:30:10,859 Epoch[9] Batch [490]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.140639,	
2017-06-23 17:30:15,396 Epoch[9] Batch [500]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.140646,	
2017-06-23 17:30:19,713 Epoch[9] Batch [510]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.140525,	
2017-06-23 17:30:23,886 Epoch[9] Batch [520]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.140354,	
2017-06-23 17:30:27,699 Epoch[9] Batch [530]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.140451,	
2017-06-23 17:30:31,561 Epoch[9] Batch [540]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.140068,	
2017-06-23 17:30:35,342 Epoch[9] Batch [550]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.139926,	
2017-06-23 17:30:39,258 Epoch[9] Batch [560]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.139636,	
2017-06-23 17:30:42,960 Epoch[9] Batch [570]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.139485,	
2017-06-23 17:30:46,881 Epoch[9] Batch [580]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.139560,	
2017-06-23 17:30:50,849 Epoch[9] Batch [590]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.139117,	
2017-06-23 17:30:54,670 Epoch[9] Batch [600]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.139152,	
2017-06-23 17:30:58,361 Epoch[9] Batch [610]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.138992,	
2017-06-23 17:31:02,464 Epoch[9] Batch [620]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.138771,	
2017-06-23 17:31:06,579 Epoch[9] Batch [630]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.138502,	
2017-06-23 17:31:10,769 Epoch[9] Batch [640]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.138281,	
2017-06-23 17:31:15,049 Epoch[9] Batch [650]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.138007,	
2017-06-23 17:31:19,445 Epoch[9] Batch [660]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.138048,	
2017-06-23 17:31:23,786 Epoch[9] Batch [670]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.138193,	
2017-06-23 17:31:27,942 Epoch[9] Batch [680]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.138156,	
2017-06-23 17:31:32,072 Epoch[9] Batch [690]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.138349,	
2017-06-23 17:31:36,242 Epoch[9] Batch [700]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.138392,	
2017-06-23 17:31:40,337 Epoch[9] Batch [710]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.138208,	
2017-06-23 17:31:44,552 Epoch[9] Batch [720]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.138084,	
2017-06-23 17:31:48,636 Epoch[9] Batch [730]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.138095,	
2017-06-23 17:31:52,848 Epoch[9] Batch [740]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.137699,	
2017-06-23 17:31:57,083 Epoch[9] Batch [750]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.137549,	
2017-06-23 17:32:01,159 Epoch[9] Batch [760]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.137550,	
2017-06-23 17:32:05,291 Epoch[9] Batch [770]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.137935,	
2017-06-23 17:32:09,478 Epoch[9] Batch [780]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.138319,	
2017-06-23 17:32:13,560 Epoch[9] Batch [790]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.138260,	
2017-06-23 17:32:17,858 Epoch[9] Batch [800]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.138486,	
2017-06-23 17:32:22,048 Epoch[9] Batch [810]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.138623,	
2017-06-23 17:32:26,290 Epoch[9] Batch [820]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.138724,	
2017-06-23 17:32:30,512 Epoch[9] Batch [830]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.138508,	
2017-06-23 17:32:34,786 Epoch[9] Batch [840]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.138609,	
2017-06-23 17:32:38,993 Epoch[9] Batch [850]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.138875,	
2017-06-23 17:32:43,066 Epoch[9] Batch [860]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.139099,	
2017-06-23 17:32:47,082 Epoch[9] Batch [870]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.139006,	
2017-06-23 17:32:51,165 Epoch[9] Batch [880]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.138927,	
2017-06-23 17:32:55,349 Epoch[9] Batch [890]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.139001,	
2017-06-23 17:32:59,438 Epoch[9] Batch [900]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.138828,	
2017-06-23 17:33:03,503 Epoch[9] Batch [910]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.139082,	
2017-06-23 17:33:07,569 Epoch[9] Batch [920]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.139122,	
2017-06-23 17:33:11,559 Epoch[9] Batch [930]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.139042,	
2017-06-23 17:33:15,746 Epoch[9] Batch [940]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.139078,	
2017-06-23 17:33:19,984 Epoch[9] Batch [950]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.138991,	
2017-06-23 17:33:23,948 Epoch[9] Batch [960]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.138963,	
2017-06-23 17:33:27,976 Epoch[9] Batch [970]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.139089,	
2017-06-23 17:33:32,011 Epoch[9] Batch [980]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.139124,	
2017-06-23 17:33:36,112 Epoch[9] Batch [990]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.138979,	
2017-06-23 17:33:40,310 Epoch[9] Batch [1000]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.139204,	
2017-06-23 17:33:45,294 Epoch[9] Batch [1010]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.139099,	
2017-06-23 17:33:49,265 Epoch[9] Batch [1020]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.139039,	
2017-06-23 17:33:53,310 Epoch[9] Batch [1030]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.139083,	
2017-06-23 17:33:57,524 Epoch[9] Batch [1040]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.139179,	
2017-06-23 17:34:01,622 Epoch[9] Batch [1050]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.139250,	
2017-06-23 17:34:05,639 Epoch[9] Batch [1060]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.139451,	
2017-06-23 17:34:09,732 Epoch[9] Batch [1070]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.139599,	
2017-06-23 17:34:13,760 Epoch[9] Batch [1080]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.139755,	
2017-06-23 17:34:17,894 Epoch[9] Batch [1090]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.139839,	
2017-06-23 17:34:21,939 Epoch[9] Batch [1100]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.139788,	
2017-06-23 17:34:25,964 Epoch[9] Batch [1110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.139972,	
2017-06-23 17:34:29,905 Epoch[9] Batch [1120]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.139856,	
2017-06-23 17:34:33,856 Epoch[9] Batch [1130]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.139735,	
2017-06-23 17:34:38,091 Epoch[9] Batch [1140]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.139790,	
2017-06-23 17:34:42,270 Epoch[9] Batch [1150]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.139679,	
2017-06-23 17:34:46,287 Epoch[9] Batch [1160]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.139573,	
2017-06-23 17:34:50,357 Epoch[9] Batch [1170]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.139471,	
2017-06-23 17:34:54,417 Epoch[9] Batch [1180]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.139441,	
2017-06-23 17:34:58,620 Epoch[9] Batch [1190]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.139303,	
2017-06-23 17:35:02,865 Epoch[9] Batch [1200]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.139339,	
2017-06-23 17:35:07,165 Epoch[9] Batch [1210]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.139371,	
2017-06-23 17:35:11,360 Epoch[9] Batch [1220]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.139624,	
2017-06-23 17:35:15,506 Epoch[9] Batch [1230]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.139677,	
2017-06-23 17:35:19,920 Epoch[9] Batch [1240]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.140240,	
2017-06-23 17:35:24,293 Epoch[9] Batch [1250]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.140490,	
2017-06-23 17:35:29,832 Epoch[9] Batch [1260]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.140610,	
2017-06-23 17:35:35,452 Epoch[9] Batch [1270]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.140558,	
2017-06-23 17:35:42,175 Epoch[9] Batch [1280]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.140687,	
2017-06-23 17:35:49,128 Epoch[9] Batch [1290]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.140657,	
2017-06-23 17:35:55,260 Epoch[9] Batch [1300]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.140563,	
2017-06-23 17:36:01,468 Epoch[9] Batch [1310]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.140596,	
2017-06-23 17:36:08,491 Epoch[9] Batch [1320]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.140486,	
2017-06-23 17:36:14,226 Epoch[9] Batch [1330]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.140403,	
2017-06-23 17:36:19,962 Epoch[9] Batch [1340]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.140260,	
2017-06-23 17:36:24,934 Epoch[9] Batch [1350]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.140133,	
2017-06-23 17:36:32,540 Epoch[9] Batch [1360]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.140039,	
2017-06-23 17:36:39,999 Epoch[9] Batch [1370]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.140015,	
2017-06-23 17:36:47,312 Epoch[9] Batch [1380]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.140063,	
2017-06-23 17:36:54,409 Epoch[9] Batch [1390]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.140147,	
2017-06-23 17:37:01,548 Epoch[9] Batch [1400]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.140169,	
2017-06-23 17:37:09,196 Epoch[9] Batch [1410]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.140092,	
2017-06-23 17:37:16,867 Epoch[9] Batch [1420]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.140034,	
2017-06-23 17:37:25,228 Epoch[9] Batch [1430]	Speed: 4.78 samples/sec	Train-FCNLogLoss=0.140164,	
2017-06-23 17:37:33,625 Epoch[9] Batch [1440]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.140146,	
2017-06-23 17:37:41,684 Epoch[9] Batch [1450]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.140174,	
2017-06-23 17:37:49,592 Epoch[9] Batch [1460]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.140169,	
2017-06-23 17:37:57,567 Epoch[9] Batch [1470]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.140093,	
2017-06-23 17:38:05,450 Epoch[9] Batch [1480]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.140159,	
2017-06-23 17:38:10,370 Epoch[9] Train-FCNLogLoss=0.140081
2017-06-23 17:38:10,371 Epoch[9] Time cost=701.466
2017-06-23 17:38:11,409 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0010.params"
2017-06-23 17:38:16,304 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0010.states"
2017-06-23 17:38:25,708 Epoch[10] Batch [10]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.142659,	
2017-06-23 17:38:30,980 Epoch[10] Batch [20]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.138180,	
2017-06-23 17:38:35,042 Epoch[10] Batch [30]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.134615,	
2017-06-23 17:38:39,190 Epoch[10] Batch [40]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.136720,	
2017-06-23 17:38:43,358 Epoch[10] Batch [50]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.136215,	
2017-06-23 17:38:47,464 Epoch[10] Batch [60]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.132545,	
2017-06-23 17:38:51,560 Epoch[10] Batch [70]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.132185,	
2017-06-23 17:38:55,680 Epoch[10] Batch [80]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.131390,	
2017-06-23 17:38:59,858 Epoch[10] Batch [90]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.132080,	
2017-06-23 17:39:03,858 Epoch[10] Batch [100]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.131786,	
2017-06-23 17:39:07,950 Epoch[10] Batch [110]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.131048,	
2017-06-23 17:39:12,118 Epoch[10] Batch [120]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.130915,	
2017-06-23 17:39:16,253 Epoch[10] Batch [130]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.132112,	
2017-06-23 17:39:20,421 Epoch[10] Batch [140]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.133308,	
2017-06-23 17:39:24,534 Epoch[10] Batch [150]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134011,	
2017-06-23 17:39:28,543 Epoch[10] Batch [160]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.135191,	
2017-06-23 17:39:32,586 Epoch[10] Batch [170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.135424,	
2017-06-23 17:39:36,595 Epoch[10] Batch [180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.135119,	
2017-06-23 17:39:40,781 Epoch[10] Batch [190]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.134872,	
2017-06-23 17:39:44,835 Epoch[10] Batch [200]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.135084,	
2017-06-23 17:39:49,000 Epoch[10] Batch [210]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.135918,	
2017-06-23 17:39:53,186 Epoch[10] Batch [220]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.136292,	
2017-06-23 17:39:57,159 Epoch[10] Batch [230]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.136532,	
2017-06-23 17:40:01,293 Epoch[10] Batch [240]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.136283,	
2017-06-23 17:40:05,379 Epoch[10] Batch [250]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.135660,	
2017-06-23 17:40:09,533 Epoch[10] Batch [260]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.135644,	
2017-06-23 17:40:13,709 Epoch[10] Batch [270]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.135079,	
2017-06-23 17:40:17,953 Epoch[10] Batch [280]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.136060,	
2017-06-23 17:40:22,042 Epoch[10] Batch [290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.135733,	
2017-06-23 17:40:26,123 Epoch[10] Batch [300]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.135722,	
2017-06-23 17:40:30,027 Epoch[10] Batch [310]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.135940,	
2017-06-23 17:40:34,167 Epoch[10] Batch [320]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.136153,	
2017-06-23 17:40:38,158 Epoch[10] Batch [330]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.136634,	
2017-06-23 17:40:42,177 Epoch[10] Batch [340]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.136253,	
2017-06-23 17:40:46,308 Epoch[10] Batch [350]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.136206,	
2017-06-23 17:40:50,508 Epoch[10] Batch [360]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.136010,	
2017-06-23 17:40:54,575 Epoch[10] Batch [370]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.135534,	
2017-06-23 17:40:58,636 Epoch[10] Batch [380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.135387,	
2017-06-23 17:41:02,739 Epoch[10] Batch [390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.135418,	
2017-06-23 17:41:06,912 Epoch[10] Batch [400]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.135420,	
2017-06-23 17:41:11,083 Epoch[10] Batch [410]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.135286,	
2017-06-23 17:41:15,201 Epoch[10] Batch [420]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.135374,	
2017-06-23 17:41:19,419 Epoch[10] Batch [430]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.135656,	
2017-06-23 17:41:23,419 Epoch[10] Batch [440]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.136139,	
2017-06-23 17:41:27,491 Epoch[10] Batch [450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.136368,	
2017-06-23 17:41:31,576 Epoch[10] Batch [460]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.137119,	
2017-06-23 17:41:35,761 Epoch[10] Batch [470]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.137172,	
2017-06-23 17:41:39,802 Epoch[10] Batch [480]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.137051,	
2017-06-23 17:41:44,036 Epoch[10] Batch [490]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.137060,	
2017-06-23 17:41:48,308 Epoch[10] Batch [500]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.137141,	
2017-06-23 17:41:52,407 Epoch[10] Batch [510]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.136996,	
2017-06-23 17:41:56,560 Epoch[10] Batch [520]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.136961,	
2017-06-23 17:42:00,719 Epoch[10] Batch [530]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.137212,	
2017-06-23 17:42:04,733 Epoch[10] Batch [540]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.137172,	
2017-06-23 17:42:08,907 Epoch[10] Batch [550]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.136937,	
2017-06-23 17:42:13,177 Epoch[10] Batch [560]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.136933,	
2017-06-23 17:42:17,396 Epoch[10] Batch [570]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.136988,	
2017-06-23 17:42:21,596 Epoch[10] Batch [580]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.137303,	
2017-06-23 17:42:25,716 Epoch[10] Batch [590]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.137298,	
2017-06-23 17:42:29,866 Epoch[10] Batch [600]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.137347,	
2017-06-23 17:42:33,916 Epoch[10] Batch [610]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.137064,	
2017-06-23 17:42:37,978 Epoch[10] Batch [620]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.137144,	
2017-06-23 17:42:42,158 Epoch[10] Batch [630]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.137042,	
2017-06-23 17:42:46,278 Epoch[10] Batch [640]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.136870,	
2017-06-23 17:42:50,419 Epoch[10] Batch [650]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.136633,	
2017-06-23 17:42:54,536 Epoch[10] Batch [660]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.136381,	
2017-06-23 17:42:58,416 Epoch[10] Batch [670]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.136211,	
2017-06-23 17:43:02,532 Epoch[10] Batch [680]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.136110,	
2017-06-23 17:43:06,658 Epoch[10] Batch [690]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.135854,	
2017-06-23 17:43:10,739 Epoch[10] Batch [700]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.135892,	
2017-06-23 17:43:14,962 Epoch[10] Batch [710]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.135586,	
2017-06-23 17:43:19,059 Epoch[10] Batch [720]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.135887,	
2017-06-23 17:43:23,243 Epoch[10] Batch [730]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.136165,	
2017-06-23 17:43:27,350 Epoch[10] Batch [740]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136170,	
2017-06-23 17:43:31,636 Epoch[10] Batch [750]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.136241,	
2017-06-23 17:43:35,785 Epoch[10] Batch [760]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.136178,	
2017-06-23 17:43:39,932 Epoch[10] Batch [770]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136124,	
2017-06-23 17:43:44,043 Epoch[10] Batch [780]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.136149,	
2017-06-23 17:43:48,149 Epoch[10] Batch [790]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136264,	
2017-06-23 17:43:52,315 Epoch[10] Batch [800]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.136259,	
2017-06-23 17:43:56,420 Epoch[10] Batch [810]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136345,	
2017-06-23 17:44:00,485 Epoch[10] Batch [820]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.136326,	
2017-06-23 17:44:04,629 Epoch[10] Batch [830]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136309,	
2017-06-23 17:44:08,812 Epoch[10] Batch [840]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.136388,	
2017-06-23 17:44:12,814 Epoch[10] Batch [850]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.136248,	
2017-06-23 17:44:17,008 Epoch[10] Batch [860]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.136407,	
2017-06-23 17:44:21,085 Epoch[10] Batch [870]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.136347,	
2017-06-23 17:44:25,107 Epoch[10] Batch [880]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.136213,	
2017-06-23 17:44:29,254 Epoch[10] Batch [890]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136252,	
2017-06-23 17:44:33,395 Epoch[10] Batch [900]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.136284,	
2017-06-23 17:44:37,407 Epoch[10] Batch [910]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.136059,	
2017-06-23 17:44:41,381 Epoch[10] Batch [920]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.135897,	
2017-06-23 17:44:45,393 Epoch[10] Batch [930]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.135928,	
2017-06-23 17:44:49,375 Epoch[10] Batch [940]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.135778,	
2017-06-23 17:44:53,419 Epoch[10] Batch [950]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.135838,	
2017-06-23 17:44:57,521 Epoch[10] Batch [960]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.135685,	
2017-06-23 17:45:01,632 Epoch[10] Batch [970]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.135626,	
2017-06-23 17:45:05,484 Epoch[10] Batch [980]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.135589,	
2017-06-23 17:45:09,532 Epoch[10] Batch [990]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.135468,	
2017-06-23 17:45:13,651 Epoch[10] Batch [1000]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.135539,	
2017-06-23 17:45:17,884 Epoch[10] Batch [1010]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.135578,	
2017-06-23 17:45:21,975 Epoch[10] Batch [1020]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.136101,	
2017-06-23 17:45:26,103 Epoch[10] Batch [1030]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.136328,	
2017-06-23 17:45:30,333 Epoch[10] Batch [1040]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.136444,	
2017-06-23 17:45:34,441 Epoch[10] Batch [1050]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.136458,	
2017-06-23 17:45:38,451 Epoch[10] Batch [1060]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.136522,	
2017-06-23 17:45:42,561 Epoch[10] Batch [1070]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.136409,	
2017-06-23 17:45:46,623 Epoch[10] Batch [1080]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.136296,	
2017-06-23 17:45:50,843 Epoch[10] Batch [1090]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.136302,	
2017-06-23 17:45:54,927 Epoch[10] Batch [1100]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.136351,	
2017-06-23 17:45:58,991 Epoch[10] Batch [1110]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.136684,	
2017-06-23 17:46:03,204 Epoch[10] Batch [1120]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.136828,	
2017-06-23 17:46:07,305 Epoch[10] Batch [1130]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.136755,	
2017-06-23 17:46:11,381 Epoch[10] Batch [1140]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.136754,	
2017-06-23 17:46:15,464 Epoch[10] Batch [1150]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.136718,	
2017-06-23 17:46:19,610 Epoch[10] Batch [1160]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136690,	
2017-06-23 17:46:23,779 Epoch[10] Batch [1170]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.136763,	
2017-06-23 17:46:27,815 Epoch[10] Batch [1180]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.136693,	
2017-06-23 17:46:31,954 Epoch[10] Batch [1190]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.136547,	
2017-06-23 17:46:36,142 Epoch[10] Batch [1200]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.136734,	
2017-06-23 17:46:40,327 Epoch[10] Batch [1210]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.136974,	
2017-06-23 17:46:44,353 Epoch[10] Batch [1220]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.136926,	
2017-06-23 17:46:48,654 Epoch[10] Batch [1230]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.136984,	
2017-06-23 17:46:52,769 Epoch[10] Batch [1240]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.136895,	
2017-06-23 17:46:56,895 Epoch[10] Batch [1250]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.136790,	
2017-06-23 17:47:00,904 Epoch[10] Batch [1260]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.136661,	
2017-06-23 17:47:04,852 Epoch[10] Batch [1270]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.136577,	
2017-06-23 17:47:08,988 Epoch[10] Batch [1280]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.136453,	
2017-06-23 17:47:13,182 Epoch[10] Batch [1290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.136608,	
2017-06-23 17:47:17,374 Epoch[10] Batch [1300]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.136560,	
2017-06-23 17:47:21,424 Epoch[10] Batch [1310]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.136564,	
2017-06-23 17:47:25,565 Epoch[10] Batch [1320]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.136542,	
2017-06-23 17:47:29,708 Epoch[10] Batch [1330]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.136397,	
2017-06-23 17:47:33,702 Epoch[10] Batch [1340]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.136617,	
2017-06-23 17:47:37,798 Epoch[10] Batch [1350]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.136867,	
2017-06-23 17:47:41,795 Epoch[10] Batch [1360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.137180,	
2017-06-23 17:47:45,921 Epoch[10] Batch [1370]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.137608,	
2017-06-23 17:47:50,093 Epoch[10] Batch [1380]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.137730,	
2017-06-23 17:47:54,181 Epoch[10] Batch [1390]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.137599,	
2017-06-23 17:47:58,306 Epoch[10] Batch [1400]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.137513,	
2017-06-23 17:48:02,370 Epoch[10] Batch [1410]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.137449,	
2017-06-23 17:48:06,485 Epoch[10] Batch [1420]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.137369,	
2017-06-23 17:48:10,613 Epoch[10] Batch [1430]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.137307,	
2017-06-23 17:48:14,740 Epoch[10] Batch [1440]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.137331,	
2017-06-23 17:48:18,954 Epoch[10] Batch [1450]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.137343,	
2017-06-23 17:48:22,932 Epoch[10] Batch [1460]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.137404,	
2017-06-23 17:48:27,035 Epoch[10] Batch [1470]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.137390,	
2017-06-23 17:48:31,104 Epoch[10] Batch [1480]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.137429,	
2017-06-23 17:48:33,715 Epoch[10] Train-FCNLogLoss=0.137424
2017-06-23 17:48:33,715 Epoch[10] Time cost=617.411
2017-06-23 17:48:34,467 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0011.params"
2017-06-23 17:48:35,949 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0011.states"
2017-06-23 17:48:40,807 Epoch[11] Batch [10]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.141240,	
2017-06-23 17:48:44,971 Epoch[11] Batch [20]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.133818,	
2017-06-23 17:48:49,151 Epoch[11] Batch [30]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.132014,	
2017-06-23 17:48:53,312 Epoch[11] Batch [40]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.134020,	
2017-06-23 17:48:57,479 Epoch[11] Batch [50]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.135804,	
2017-06-23 17:49:01,468 Epoch[11] Batch [60]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.134396,	
2017-06-23 17:49:05,565 Epoch[11] Batch [70]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.138998,	
2017-06-23 17:49:09,621 Epoch[11] Batch [80]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.137800,	
2017-06-23 17:49:13,685 Epoch[11] Batch [90]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.136832,	
2017-06-23 17:49:17,640 Epoch[11] Batch [100]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.135490,	
2017-06-23 17:49:21,736 Epoch[11] Batch [110]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.134890,	
2017-06-23 17:49:25,752 Epoch[11] Batch [120]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.134058,	
2017-06-23 17:49:29,881 Epoch[11] Batch [130]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.133470,	
2017-06-23 17:49:34,182 Epoch[11] Batch [140]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.135010,	
2017-06-23 17:49:38,291 Epoch[11] Batch [150]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.137111,	
2017-06-23 17:49:42,515 Epoch[11] Batch [160]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.138519,	
2017-06-23 17:49:46,717 Epoch[11] Batch [170]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.139008,	
2017-06-23 17:49:50,767 Epoch[11] Batch [180]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.139496,	
2017-06-23 17:49:55,020 Epoch[11] Batch [190]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.140445,	
2017-06-23 17:49:59,123 Epoch[11] Batch [200]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.140567,	
2017-06-23 17:50:03,036 Epoch[11] Batch [210]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.140010,	
2017-06-23 17:50:06,860 Epoch[11] Batch [220]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.140334,	
2017-06-23 17:50:10,757 Epoch[11] Batch [230]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.138953,	
2017-06-23 17:50:14,620 Epoch[11] Batch [240]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.138825,	
2017-06-23 17:50:18,415 Epoch[11] Batch [250]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.138293,	
2017-06-23 17:50:22,227 Epoch[11] Batch [260]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.138802,	
2017-06-23 17:50:26,097 Epoch[11] Batch [270]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.137955,	
2017-06-23 17:50:29,966 Epoch[11] Batch [280]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.138014,	
2017-06-23 17:50:33,894 Epoch[11] Batch [290]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.138792,	
2017-06-23 17:50:37,897 Epoch[11] Batch [300]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.139045,	
2017-06-23 17:50:42,113 Epoch[11] Batch [310]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.138832,	
2017-06-23 17:50:46,797 Epoch[11] Batch [320]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.138734,	
2017-06-23 17:50:52,156 Epoch[11] Batch [330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.138563,	
2017-06-23 17:50:56,869 Epoch[11] Batch [340]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.138204,	
2017-06-23 17:51:01,294 Epoch[11] Batch [350]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.138069,	
2017-06-23 17:51:05,278 Epoch[11] Batch [360]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.138107,	
2017-06-23 17:51:09,090 Epoch[11] Batch [370]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.138158,	
2017-06-23 17:51:12,914 Epoch[11] Batch [380]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.138379,	
2017-06-23 17:51:16,664 Epoch[11] Batch [390]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.137666,	
2017-06-23 17:51:20,500 Epoch[11] Batch [400]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.137078,	
2017-06-23 17:51:24,337 Epoch[11] Batch [410]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.137017,	
2017-06-23 17:51:28,064 Epoch[11] Batch [420]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.136690,	
2017-06-23 17:51:31,983 Epoch[11] Batch [430]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.136566,	
2017-06-23 17:51:35,814 Epoch[11] Batch [440]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.136389,	
2017-06-23 17:51:39,703 Epoch[11] Batch [450]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.136362,	
2017-06-23 17:51:43,705 Epoch[11] Batch [460]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.136239,	
2017-06-23 17:51:48,670 Epoch[11] Batch [470]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.135803,	
2017-06-23 17:51:52,566 Epoch[11] Batch [480]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.135783,	
2017-06-23 17:51:56,337 Epoch[11] Batch [490]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.135435,	
2017-06-23 17:52:00,174 Epoch[11] Batch [500]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.135068,	
2017-06-23 17:52:03,851 Epoch[11] Batch [510]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.135021,	
2017-06-23 17:52:07,611 Epoch[11] Batch [520]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.134709,	
2017-06-23 17:52:11,344 Epoch[11] Batch [530]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.134685,	
2017-06-23 17:52:15,131 Epoch[11] Batch [540]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.135067,	
2017-06-23 17:52:18,916 Epoch[11] Batch [550]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.135382,	
2017-06-23 17:52:22,689 Epoch[11] Batch [560]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.135740,	
2017-06-23 17:52:26,558 Epoch[11] Batch [570]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.135682,	
2017-06-23 17:52:30,591 Epoch[11] Batch [580]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.135545,	
2017-06-23 17:52:35,292 Epoch[11] Batch [590]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.135532,	
2017-06-23 17:52:40,880 Epoch[11] Batch [600]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.135522,	
2017-06-23 17:52:46,057 Epoch[11] Batch [610]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.135599,	
2017-06-23 17:52:50,553 Epoch[11] Batch [620]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.135414,	
2017-06-23 17:52:54,886 Epoch[11] Batch [630]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.135462,	
2017-06-23 17:52:58,829 Epoch[11] Batch [640]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.135530,	
2017-06-23 17:53:02,713 Epoch[11] Batch [650]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.135415,	
2017-06-23 17:53:06,418 Epoch[11] Batch [660]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.135222,	
2017-06-23 17:53:10,229 Epoch[11] Batch [670]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.135084,	
2017-06-23 17:53:13,925 Epoch[11] Batch [680]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.134996,	
2017-06-23 17:53:17,561 Epoch[11] Batch [690]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.134907,	
2017-06-23 17:53:21,292 Epoch[11] Batch [700]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.134989,	
2017-06-23 17:53:25,042 Epoch[11] Batch [710]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.135016,	
2017-06-23 17:53:28,843 Epoch[11] Batch [720]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.134791,	
2017-06-23 17:53:32,577 Epoch[11] Batch [730]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.134686,	
2017-06-23 17:53:36,382 Epoch[11] Batch [740]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.134514,	
2017-06-23 17:53:40,323 Epoch[11] Batch [750]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.134486,	
2017-06-23 17:53:44,291 Epoch[11] Batch [760]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.134439,	
2017-06-23 17:53:48,388 Epoch[11] Batch [770]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.135244,	
2017-06-23 17:53:52,143 Epoch[11] Batch [780]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.136763,	
2017-06-23 17:53:55,966 Epoch[11] Batch [790]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.137449,	
2017-06-23 17:53:59,815 Epoch[11] Batch [800]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.137667,	
2017-06-23 17:54:03,578 Epoch[11] Batch [810]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.138515,	
2017-06-23 17:54:07,344 Epoch[11] Batch [820]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.139169,	
2017-06-23 17:54:11,104 Epoch[11] Batch [830]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.139224,	
2017-06-23 17:54:14,967 Epoch[11] Batch [840]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.139342,	
2017-06-23 17:54:19,005 Epoch[11] Batch [850]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.139316,	
2017-06-23 17:54:23,763 Epoch[11] Batch [860]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.139561,	
2017-06-23 17:54:29,206 Epoch[11] Batch [870]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.139826,	
2017-06-23 17:54:35,159 Epoch[11] Batch [880]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.139994,	
2017-06-23 17:54:40,399 Epoch[11] Batch [890]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.140062,	
2017-06-23 17:54:44,853 Epoch[11] Batch [900]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.140218,	
2017-06-23 17:54:48,867 Epoch[11] Batch [910]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.140312,	
2017-06-23 17:54:52,734 Epoch[11] Batch [920]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.140450,	
2017-06-23 17:54:56,778 Epoch[11] Batch [930]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.140815,	
2017-06-23 17:55:00,611 Epoch[11] Batch [940]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.140809,	
2017-06-23 17:55:04,605 Epoch[11] Batch [950]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.140886,	
2017-06-23 17:55:08,580 Epoch[11] Batch [960]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.140985,	
2017-06-23 17:55:12,426 Epoch[11] Batch [970]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.141318,	
2017-06-23 17:55:16,307 Epoch[11] Batch [980]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.141427,	
2017-06-23 17:55:20,088 Epoch[11] Batch [990]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.141542,	
2017-06-23 17:55:23,928 Epoch[11] Batch [1000]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.141610,	
2017-06-23 17:55:27,917 Epoch[11] Batch [1010]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.141638,	
2017-06-23 17:55:32,030 Epoch[11] Batch [1020]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.141563,	
2017-06-23 17:55:36,111 Epoch[11] Batch [1030]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.141389,	
2017-06-23 17:55:39,929 Epoch[11] Batch [1040]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.141359,	
2017-06-23 17:55:43,669 Epoch[11] Batch [1050]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.141329,	
2017-06-23 17:55:47,473 Epoch[11] Batch [1060]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.141575,	
2017-06-23 17:55:51,254 Epoch[11] Batch [1070]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.141618,	
2017-06-23 17:55:55,025 Epoch[11] Batch [1080]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.141576,	
2017-06-23 17:55:58,798 Epoch[11] Batch [1090]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.141601,	
2017-06-23 17:56:02,545 Epoch[11] Batch [1100]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.141416,	
2017-06-23 17:56:06,443 Epoch[11] Batch [1110]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.141300,	
2017-06-23 17:56:10,308 Epoch[11] Batch [1120]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.141158,	
2017-06-23 17:56:14,093 Epoch[11] Batch [1130]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.141009,	
2017-06-23 17:56:17,801 Epoch[11] Batch [1140]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.140990,	
2017-06-23 17:56:21,711 Epoch[11] Batch [1150]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.140876,	
2017-06-23 17:56:26,561 Epoch[11] Batch [1160]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.140979,	
2017-06-23 17:56:31,105 Epoch[11] Batch [1170]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.140911,	
2017-06-23 17:56:35,229 Epoch[11] Batch [1180]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.140675,	
2017-06-23 17:56:39,107 Epoch[11] Batch [1190]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.140939,	
2017-06-23 17:56:42,946 Epoch[11] Batch [1200]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.141160,	
2017-06-23 17:56:46,950 Epoch[11] Batch [1210]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.141320,	
2017-06-23 17:56:50,967 Epoch[11] Batch [1220]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.141296,	
2017-06-23 17:56:54,805 Epoch[11] Batch [1230]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.141212,	
2017-06-23 17:56:58,579 Epoch[11] Batch [1240]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.141277,	
2017-06-23 17:57:02,380 Epoch[11] Batch [1250]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.141319,	
2017-06-23 17:57:06,162 Epoch[11] Batch [1260]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.141278,	
2017-06-23 17:57:09,935 Epoch[11] Batch [1270]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.141174,	
2017-06-23 17:57:14,022 Epoch[11] Batch [1280]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.141006,	
2017-06-23 17:57:18,115 Epoch[11] Batch [1290]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.141005,	
2017-06-23 17:57:22,239 Epoch[11] Batch [1300]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.141065,	
2017-06-23 17:57:26,315 Epoch[11] Batch [1310]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.140979,	
2017-06-23 17:57:30,230 Epoch[11] Batch [1320]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.140932,	
2017-06-23 17:57:34,072 Epoch[11] Batch [1330]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.140761,	
2017-06-23 17:57:37,991 Epoch[11] Batch [1340]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.140611,	
2017-06-23 17:57:41,696 Epoch[11] Batch [1350]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.140534,	
2017-06-23 17:57:45,426 Epoch[11] Batch [1360]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.140581,	
2017-06-23 17:57:49,141 Epoch[11] Batch [1370]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.140477,	
2017-06-23 17:57:52,908 Epoch[11] Batch [1380]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.140349,	
2017-06-23 17:57:56,659 Epoch[11] Batch [1390]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.140213,	
2017-06-23 17:58:00,553 Epoch[11] Batch [1400]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.140199,	
2017-06-23 17:58:04,357 Epoch[11] Batch [1410]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.140072,	
2017-06-23 17:58:08,221 Epoch[11] Batch [1420]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.140082,	
2017-06-23 17:58:12,297 Epoch[11] Batch [1430]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.140089,	
2017-06-23 17:58:16,726 Epoch[11] Batch [1440]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.140013,	
2017-06-23 17:58:21,581 Epoch[11] Batch [1450]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.140001,	
2017-06-23 17:58:25,999 Epoch[11] Batch [1460]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.139969,	
2017-06-23 17:58:29,974 Epoch[11] Batch [1470]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.139952,	
2017-06-23 17:58:33,863 Epoch[11] Batch [1480]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.139979,	
2017-06-23 17:58:36,097 Epoch[11] Train-FCNLogLoss=0.139860
2017-06-23 17:58:36,097 Epoch[11] Time cost=600.148
2017-06-23 17:58:36,872 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0012.params"
2017-06-23 17:58:40,489 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0012.states"
2017-06-23 17:58:45,074 Epoch[12] Batch [10]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.118675,	
2017-06-23 17:58:49,005 Epoch[12] Batch [20]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.129775,	
2017-06-23 17:58:52,806 Epoch[12] Batch [30]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.132390,	
2017-06-23 17:58:56,592 Epoch[12] Batch [40]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.131061,	
2017-06-23 17:59:00,421 Epoch[12] Batch [50]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.129950,	
2017-06-23 17:59:04,236 Epoch[12] Batch [60]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.128513,	
2017-06-23 17:59:08,188 Epoch[12] Batch [70]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.128106,	
2017-06-23 17:59:12,159 Epoch[12] Batch [80]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.130645,	
2017-06-23 17:59:16,098 Epoch[12] Batch [90]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.132017,	
2017-06-23 17:59:19,897 Epoch[12] Batch [100]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.132845,	
2017-06-23 17:59:23,707 Epoch[12] Batch [110]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.133015,	
2017-06-23 17:59:27,412 Epoch[12] Batch [120]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.133344,	
2017-06-23 17:59:31,131 Epoch[12] Batch [130]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.132733,	
2017-06-23 17:59:34,954 Epoch[12] Batch [140]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.133682,	
2017-06-23 17:59:38,686 Epoch[12] Batch [150]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.132096,	
2017-06-23 17:59:42,561 Epoch[12] Batch [160]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.131532,	
2017-06-23 17:59:46,379 Epoch[12] Batch [170]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.131110,	
2017-06-23 17:59:50,208 Epoch[12] Batch [180]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.130877,	
2017-06-23 17:59:54,153 Epoch[12] Batch [190]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.130516,	
2017-06-23 17:59:58,034 Epoch[12] Batch [200]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.130634,	
2017-06-23 18:00:01,820 Epoch[12] Batch [210]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.130283,	
2017-06-23 18:00:05,597 Epoch[12] Batch [220]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.130647,	
2017-06-23 18:00:09,422 Epoch[12] Batch [230]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.130583,	
2017-06-23 18:00:13,152 Epoch[12] Batch [240]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.130011,	
2017-06-23 18:00:16,998 Epoch[12] Batch [250]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.129660,	
2017-06-23 18:00:20,754 Epoch[12] Batch [260]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.129400,	
2017-06-23 18:00:24,495 Epoch[12] Batch [270]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.129241,	
2017-06-23 18:00:28,288 Epoch[12] Batch [280]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.128904,	
2017-06-23 18:00:32,004 Epoch[12] Batch [290]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.128367,	
2017-06-23 18:00:35,734 Epoch[12] Batch [300]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.128244,	
2017-06-23 18:00:39,516 Epoch[12] Batch [310]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.127592,	
2017-06-23 18:00:43,153 Epoch[12] Batch [320]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.127395,	
2017-06-23 18:00:46,842 Epoch[12] Batch [330]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.127052,	
2017-06-23 18:00:50,633 Epoch[12] Batch [340]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.127240,	
2017-06-23 18:00:54,334 Epoch[12] Batch [350]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.127571,	
2017-06-23 18:00:58,094 Epoch[12] Batch [360]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.127323,	
2017-06-23 18:01:01,901 Epoch[12] Batch [370]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.127324,	
2017-06-23 18:01:05,721 Epoch[12] Batch [380]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.127998,	
2017-06-23 18:01:09,725 Epoch[12] Batch [390]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.128945,	
2017-06-23 18:01:13,634 Epoch[12] Batch [400]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.128951,	
2017-06-23 18:01:17,550 Epoch[12] Batch [410]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.128799,	
2017-06-23 18:01:21,297 Epoch[12] Batch [420]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.128456,	
2017-06-23 18:01:25,070 Epoch[12] Batch [430]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.128507,	
2017-06-23 18:01:28,814 Epoch[12] Batch [440]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.128227,	
2017-06-23 18:01:32,524 Epoch[12] Batch [450]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.128080,	
2017-06-23 18:01:36,288 Epoch[12] Batch [460]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.127737,	
2017-06-23 18:01:40,013 Epoch[12] Batch [470]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.127572,	
2017-06-23 18:01:43,776 Epoch[12] Batch [480]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.127569,	
2017-06-23 18:01:47,541 Epoch[12] Batch [490]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.127341,	
2017-06-23 18:01:51,201 Epoch[12] Batch [500]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.127229,	
2017-06-23 18:01:55,031 Epoch[12] Batch [510]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.127331,	
2017-06-23 18:01:58,782 Epoch[12] Batch [520]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.127243,	
2017-06-23 18:02:02,556 Epoch[12] Batch [530]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.126944,	
2017-06-23 18:02:06,294 Epoch[12] Batch [540]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.127052,	
2017-06-23 18:02:10,010 Epoch[12] Batch [550]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.126901,	
2017-06-23 18:02:13,812 Epoch[12] Batch [560]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.126701,	
2017-06-23 18:02:17,579 Epoch[12] Batch [570]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.126437,	
2017-06-23 18:02:21,380 Epoch[12] Batch [580]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.126981,	
2017-06-23 18:02:25,164 Epoch[12] Batch [590]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.126904,	
2017-06-23 18:02:28,915 Epoch[12] Batch [600]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.126848,	
2017-06-23 18:02:32,687 Epoch[12] Batch [610]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.127018,	
2017-06-23 18:02:36,415 Epoch[12] Batch [620]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.127029,	
2017-06-23 18:02:40,149 Epoch[12] Batch [630]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.126973,	
2017-06-23 18:02:43,831 Epoch[12] Batch [640]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.126976,	
2017-06-23 18:02:47,578 Epoch[12] Batch [650]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.127011,	
2017-06-23 18:02:51,359 Epoch[12] Batch [660]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.127098,	
2017-06-23 18:02:55,080 Epoch[12] Batch [670]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.126863,	
2017-06-23 18:02:58,791 Epoch[12] Batch [680]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.126879,	
2017-06-23 18:03:02,732 Epoch[12] Batch [690]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.127297,	
2017-06-23 18:03:06,536 Epoch[12] Batch [700]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.127742,	
2017-06-23 18:03:10,551 Epoch[12] Batch [710]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.127818,	
2017-06-23 18:03:14,434 Epoch[12] Batch [720]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.127784,	
2017-06-23 18:03:18,151 Epoch[12] Batch [730]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.127689,	
2017-06-23 18:03:21,968 Epoch[12] Batch [740]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.127730,	
2017-06-23 18:03:25,744 Epoch[12] Batch [750]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.127574,	
2017-06-23 18:03:29,447 Epoch[12] Batch [760]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.127697,	
2017-06-23 18:03:33,263 Epoch[12] Batch [770]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.127645,	
2017-06-23 18:03:37,048 Epoch[12] Batch [780]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.127715,	
2017-06-23 18:03:40,859 Epoch[12] Batch [790]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.127926,	
2017-06-23 18:03:44,670 Epoch[12] Batch [800]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.127769,	
2017-06-23 18:03:48,397 Epoch[12] Batch [810]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.127878,	
2017-06-23 18:03:52,141 Epoch[12] Batch [820]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.127821,	
2017-06-23 18:03:55,871 Epoch[12] Batch [830]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.127951,	
2017-06-23 18:03:59,656 Epoch[12] Batch [840]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.127748,	
2017-06-23 18:04:03,410 Epoch[12] Batch [850]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.127653,	
2017-06-23 18:04:07,232 Epoch[12] Batch [860]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.127484,	
2017-06-23 18:04:11,014 Epoch[12] Batch [870]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.127627,	
2017-06-23 18:04:14,704 Epoch[12] Batch [880]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.127595,	
2017-06-23 18:04:18,576 Epoch[12] Batch [890]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.127389,	
2017-06-23 18:04:22,283 Epoch[12] Batch [900]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.127532,	
2017-06-23 18:04:26,019 Epoch[12] Batch [910]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.127510,	
2017-06-23 18:04:29,678 Epoch[12] Batch [920]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.127315,	
2017-06-23 18:04:33,489 Epoch[12] Batch [930]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.127229,	
2017-06-23 18:04:37,217 Epoch[12] Batch [940]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.127300,	
2017-06-23 18:04:40,962 Epoch[12] Batch [950]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.127266,	
2017-06-23 18:04:44,630 Epoch[12] Batch [960]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.127151,	
2017-06-23 18:04:48,297 Epoch[12] Batch [970]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.127245,	
2017-06-23 18:04:52,115 Epoch[12] Batch [980]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.127425,	
2017-06-23 18:04:55,823 Epoch[12] Batch [990]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.127523,	
2017-06-23 18:04:59,600 Epoch[12] Batch [1000]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.127609,	
2017-06-23 18:05:03,343 Epoch[12] Batch [1010]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.127718,	
2017-06-23 18:05:07,108 Epoch[12] Batch [1020]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.127789,	
2017-06-23 18:05:10,973 Epoch[12] Batch [1030]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.127831,	
2017-06-23 18:05:14,875 Epoch[12] Batch [1040]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.127852,	
2017-06-23 18:05:18,585 Epoch[12] Batch [1050]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.127734,	
2017-06-23 18:05:22,393 Epoch[12] Batch [1060]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.127674,	
2017-06-23 18:05:26,188 Epoch[12] Batch [1070]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.127719,	
2017-06-23 18:05:29,945 Epoch[12] Batch [1080]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.127566,	
2017-06-23 18:05:33,678 Epoch[12] Batch [1090]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.127541,	
2017-06-23 18:05:37,489 Epoch[12] Batch [1100]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.127546,	
2017-06-23 18:05:41,310 Epoch[12] Batch [1110]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.127590,	
2017-06-23 18:05:45,075 Epoch[12] Batch [1120]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.127531,	
2017-06-23 18:05:48,857 Epoch[12] Batch [1130]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.127501,	
2017-06-23 18:05:52,602 Epoch[12] Batch [1140]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.127349,	
2017-06-23 18:05:56,423 Epoch[12] Batch [1150]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.127277,	
2017-06-23 18:06:00,210 Epoch[12] Batch [1160]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.127372,	
2017-06-23 18:06:03,964 Epoch[12] Batch [1170]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.127337,	
2017-06-23 18:06:07,712 Epoch[12] Batch [1180]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.127348,	
2017-06-23 18:06:11,432 Epoch[12] Batch [1190]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.127270,	
2017-06-23 18:06:15,177 Epoch[12] Batch [1200]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.127388,	
2017-06-23 18:06:18,906 Epoch[12] Batch [1210]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.127473,	
2017-06-23 18:06:22,703 Epoch[12] Batch [1220]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.127438,	
2017-06-23 18:06:26,425 Epoch[12] Batch [1230]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.127590,	
2017-06-23 18:06:30,202 Epoch[12] Batch [1240]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.127694,	
2017-06-23 18:06:33,888 Epoch[12] Batch [1250]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.127605,	
2017-06-23 18:06:37,564 Epoch[12] Batch [1260]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.127630,	
2017-06-23 18:06:41,304 Epoch[12] Batch [1270]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.127559,	
2017-06-23 18:06:44,933 Epoch[12] Batch [1280]	Speed: 11.02 samples/sec	Train-FCNLogLoss=0.127563,	
2017-06-23 18:06:48,631 Epoch[12] Batch [1290]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.127514,	
2017-06-23 18:06:52,430 Epoch[12] Batch [1300]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.127614,	
2017-06-23 18:06:56,118 Epoch[12] Batch [1310]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.127632,	
2017-06-23 18:06:59,813 Epoch[12] Batch [1320]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.127589,	
2017-06-23 18:07:03,839 Epoch[12] Batch [1330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.127463,	
2017-06-23 18:07:07,854 Epoch[12] Batch [1340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.127399,	
2017-06-23 18:07:11,802 Epoch[12] Batch [1350]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.127417,	
2017-06-23 18:07:15,607 Epoch[12] Batch [1360]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.127349,	
2017-06-23 18:07:19,338 Epoch[12] Batch [1370]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.127316,	
2017-06-23 18:07:23,141 Epoch[12] Batch [1380]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.127353,	
2017-06-23 18:07:26,918 Epoch[12] Batch [1390]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.127352,	
2017-06-23 18:07:30,688 Epoch[12] Batch [1400]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.127357,	
2017-06-23 18:07:34,393 Epoch[12] Batch [1410]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.127380,	
2017-06-23 18:07:38,145 Epoch[12] Batch [1420]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.127330,	
2017-06-23 18:07:41,919 Epoch[12] Batch [1430]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.127281,	
2017-06-23 18:07:45,723 Epoch[12] Batch [1440]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.127250,	
2017-06-23 18:07:49,525 Epoch[12] Batch [1450]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.127157,	
2017-06-23 18:07:53,291 Epoch[12] Batch [1460]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.127114,	
2017-06-23 18:07:57,052 Epoch[12] Batch [1470]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.127194,	
2017-06-23 18:08:00,778 Epoch[12] Batch [1480]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.127379,	
2017-06-23 18:08:02,981 Epoch[12] Train-FCNLogLoss=0.127392
2017-06-23 18:08:02,981 Epoch[12] Time cost=562.492
2017-06-23 18:08:03,749 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0013.params"
2017-06-23 18:08:07,993 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0013.states"
2017-06-23 18:08:12,786 Epoch[13] Batch [10]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.138352,	
2017-06-23 18:08:16,790 Epoch[13] Batch [20]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.133022,	
2017-06-23 18:08:20,753 Epoch[13] Batch [30]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.132702,	
2017-06-23 18:08:24,598 Epoch[13] Batch [40]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.127424,	
2017-06-23 18:08:28,385 Epoch[13] Batch [50]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.125995,	
2017-06-23 18:08:32,150 Epoch[13] Batch [60]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.128485,	
2017-06-23 18:08:36,000 Epoch[13] Batch [70]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.127450,	
2017-06-23 18:08:39,889 Epoch[13] Batch [80]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.126163,	
2017-06-23 18:08:43,685 Epoch[13] Batch [90]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123472,	
2017-06-23 18:08:47,361 Epoch[13] Batch [100]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.123863,	
2017-06-23 18:08:51,121 Epoch[13] Batch [110]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.124746,	
2017-06-23 18:08:54,838 Epoch[13] Batch [120]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.124766,	
2017-06-23 18:08:58,762 Epoch[13] Batch [130]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.125768,	
2017-06-23 18:09:02,570 Epoch[13] Batch [140]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.125740,	
2017-06-23 18:09:06,479 Epoch[13] Batch [150]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.126224,	
2017-06-23 18:09:10,534 Epoch[13] Batch [160]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.125218,	
2017-06-23 18:09:14,231 Epoch[13] Batch [170]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.124953,	
2017-06-23 18:09:18,112 Epoch[13] Batch [180]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.124507,	
2017-06-23 18:09:21,896 Epoch[13] Batch [190]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.124201,	
2017-06-23 18:09:25,682 Epoch[13] Batch [200]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.123769,	
2017-06-23 18:09:29,538 Epoch[13] Batch [210]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.123528,	
2017-06-23 18:09:33,302 Epoch[13] Batch [220]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.123352,	
2017-06-23 18:09:37,162 Epoch[13] Batch [230]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.123554,	
2017-06-23 18:09:40,926 Epoch[13] Batch [240]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.123559,	
2017-06-23 18:09:44,617 Epoch[13] Batch [250]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.123396,	
2017-06-23 18:09:48,424 Epoch[13] Batch [260]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123349,	
2017-06-23 18:09:52,149 Epoch[13] Batch [270]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.122459,	
2017-06-23 18:09:55,863 Epoch[13] Batch [280]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.122202,	
2017-06-23 18:09:59,685 Epoch[13] Batch [290]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.122801,	
2017-06-23 18:10:03,429 Epoch[13] Batch [300]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.123195,	
2017-06-23 18:10:07,235 Epoch[13] Batch [310]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123414,	
2017-06-23 18:10:10,903 Epoch[13] Batch [320]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.123299,	
2017-06-23 18:10:14,621 Epoch[13] Batch [330]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.123641,	
2017-06-23 18:10:18,426 Epoch[13] Batch [340]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123543,	
2017-06-23 18:10:22,215 Epoch[13] Batch [350]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.123760,	
2017-06-23 18:10:25,896 Epoch[13] Batch [360]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.124202,	
2017-06-23 18:10:29,589 Epoch[13] Batch [370]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.124597,	
2017-06-23 18:10:33,424 Epoch[13] Batch [380]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.124206,	
2017-06-23 18:10:37,188 Epoch[13] Batch [390]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.124217,	
2017-06-23 18:10:40,932 Epoch[13] Batch [400]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.124471,	
2017-06-23 18:10:44,713 Epoch[13] Batch [410]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.124435,	
2017-06-23 18:10:48,568 Epoch[13] Batch [420]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.124485,	
2017-06-23 18:10:52,286 Epoch[13] Batch [430]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.124195,	
2017-06-23 18:10:56,106 Epoch[13] Batch [440]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.124098,	
2017-06-23 18:11:00,123 Epoch[13] Batch [450]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.124256,	
2017-06-23 18:11:04,102 Epoch[13] Batch [460]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.124469,	
2017-06-23 18:11:07,989 Epoch[13] Batch [470]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.124537,	
2017-06-23 18:11:11,843 Epoch[13] Batch [480]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.125117,	
2017-06-23 18:11:15,615 Epoch[13] Batch [490]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.125411,	
2017-06-23 18:11:19,373 Epoch[13] Batch [500]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.125582,	
2017-06-23 18:11:23,148 Epoch[13] Batch [510]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.125273,	
2017-06-23 18:11:26,914 Epoch[13] Batch [520]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.125207,	
2017-06-23 18:11:30,853 Epoch[13] Batch [530]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.124870,	
2017-06-23 18:11:35,118 Epoch[13] Batch [540]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.124980,	
2017-06-23 18:11:40,147 Epoch[13] Batch [550]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.124867,	
2017-06-23 18:11:46,337 Epoch[13] Batch [560]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.125013,	
2017-06-23 18:11:53,247 Epoch[13] Batch [570]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.125009,	
2017-06-23 18:11:59,336 Epoch[13] Batch [580]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.125091,	
2017-06-23 18:12:05,165 Epoch[13] Batch [590]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.125283,	
2017-06-23 18:12:10,740 Epoch[13] Batch [600]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.125340,	
2017-06-23 18:12:15,752 Epoch[13] Batch [610]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.125217,	
2017-06-23 18:12:20,427 Epoch[13] Batch [620]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.125342,	
2017-06-23 18:12:24,841 Epoch[13] Batch [630]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.125449,	
2017-06-23 18:12:28,920 Epoch[13] Batch [640]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.125386,	
2017-06-23 18:12:32,867 Epoch[13] Batch [650]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.125491,	
2017-06-23 18:12:36,728 Epoch[13] Batch [660]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.125245,	
2017-06-23 18:12:40,621 Epoch[13] Batch [670]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.125326,	
2017-06-23 18:12:44,543 Epoch[13] Batch [680]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.125184,	
2017-06-23 18:12:48,434 Epoch[13] Batch [690]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.125250,	
2017-06-23 18:12:52,404 Epoch[13] Batch [700]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.124951,	
2017-06-23 18:12:56,253 Epoch[13] Batch [710]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.124794,	
2017-06-23 18:13:00,063 Epoch[13] Batch [720]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.124909,	
2017-06-23 18:13:03,905 Epoch[13] Batch [730]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.125018,	
2017-06-23 18:13:07,781 Epoch[13] Batch [740]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.125073,	
2017-06-23 18:13:11,615 Epoch[13] Batch [750]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.124851,	
2017-06-23 18:13:15,588 Epoch[13] Batch [760]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.124936,	
2017-06-23 18:13:19,543 Epoch[13] Batch [770]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.124956,	
2017-06-23 18:13:23,400 Epoch[13] Batch [780]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.125165,	
2017-06-23 18:13:27,199 Epoch[13] Batch [790]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.125182,	
2017-06-23 18:13:30,960 Epoch[13] Batch [800]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.125070,	
2017-06-23 18:13:34,791 Epoch[13] Batch [810]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.125003,	
2017-06-23 18:13:38,535 Epoch[13] Batch [820]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.125032,	
2017-06-23 18:13:42,285 Epoch[13] Batch [830]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.125407,	
2017-06-23 18:13:45,992 Epoch[13] Batch [840]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.125326,	
2017-06-23 18:13:49,716 Epoch[13] Batch [850]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.125296,	
2017-06-23 18:13:53,387 Epoch[13] Batch [860]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.125340,	
2017-06-23 18:13:57,192 Epoch[13] Batch [870]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.125423,	
2017-06-23 18:14:00,900 Epoch[13] Batch [880]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.125439,	
2017-06-23 18:14:04,569 Epoch[13] Batch [890]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.125269,	
2017-06-23 18:14:08,348 Epoch[13] Batch [900]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.125363,	
2017-06-23 18:14:12,056 Epoch[13] Batch [910]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.125330,	
2017-06-23 18:14:15,773 Epoch[13] Batch [920]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.125394,	
2017-06-23 18:14:19,573 Epoch[13] Batch [930]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.125546,	
2017-06-23 18:14:23,323 Epoch[13] Batch [940]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.125469,	
2017-06-23 18:14:27,126 Epoch[13] Batch [950]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.125474,	
2017-06-23 18:14:31,016 Epoch[13] Batch [960]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.125611,	
2017-06-23 18:14:34,777 Epoch[13] Batch [970]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.125807,	
2017-06-23 18:14:38,653 Epoch[13] Batch [980]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.125776,	
2017-06-23 18:14:42,436 Epoch[13] Batch [990]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.125770,	
2017-06-23 18:14:46,424 Epoch[13] Batch [1000]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.125807,	
2017-06-23 18:14:50,367 Epoch[13] Batch [1010]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.125905,	
2017-06-23 18:14:54,260 Epoch[13] Batch [1020]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.125796,	
2017-06-23 18:14:57,965 Epoch[13] Batch [1030]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.125664,	
2017-06-23 18:15:01,670 Epoch[13] Batch [1040]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.125699,	
2017-06-23 18:15:05,457 Epoch[13] Batch [1050]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.125831,	
2017-06-23 18:15:09,252 Epoch[13] Batch [1060]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.125830,	
2017-06-23 18:15:12,976 Epoch[13] Batch [1070]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.125809,	
2017-06-23 18:15:16,791 Epoch[13] Batch [1080]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.125841,	
2017-06-23 18:15:20,631 Epoch[13] Batch [1090]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.125729,	
2017-06-23 18:15:24,290 Epoch[13] Batch [1100]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.125674,	
2017-06-23 18:15:28,041 Epoch[13] Batch [1110]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.125621,	
2017-06-23 18:15:31,780 Epoch[13] Batch [1120]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.125405,	
2017-06-23 18:15:35,520 Epoch[13] Batch [1130]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.125345,	
2017-06-23 18:15:39,353 Epoch[13] Batch [1140]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.125396,	
2017-06-23 18:15:43,069 Epoch[13] Batch [1150]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.125428,	
2017-06-23 18:15:46,875 Epoch[13] Batch [1160]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.125481,	
2017-06-23 18:15:50,614 Epoch[13] Batch [1170]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.125439,	
2017-06-23 18:15:54,355 Epoch[13] Batch [1180]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.125431,	
2017-06-23 18:15:58,037 Epoch[13] Batch [1190]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.125473,	
2017-06-23 18:16:01,801 Epoch[13] Batch [1200]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.125565,	
2017-06-23 18:16:05,548 Epoch[13] Batch [1210]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.125620,	
2017-06-23 18:16:09,305 Epoch[13] Batch [1220]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.125672,	
2017-06-23 18:16:13,134 Epoch[13] Batch [1230]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.125730,	
2017-06-23 18:16:16,858 Epoch[13] Batch [1240]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.125737,	
2017-06-23 18:16:20,639 Epoch[13] Batch [1250]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.125608,	
2017-06-23 18:16:24,407 Epoch[13] Batch [1260]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.125650,	
2017-06-23 18:16:28,156 Epoch[13] Batch [1270]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.125808,	
2017-06-23 18:16:31,864 Epoch[13] Batch [1280]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.126031,	
2017-06-23 18:16:35,512 Epoch[13] Batch [1290]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.126044,	
2017-06-23 18:16:39,381 Epoch[13] Batch [1300]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.126020,	
2017-06-23 18:16:43,285 Epoch[13] Batch [1310]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.126079,	
2017-06-23 18:16:47,215 Epoch[13] Batch [1320]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.126026,	
2017-06-23 18:16:51,206 Epoch[13] Batch [1330]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.126073,	
2017-06-23 18:16:55,011 Epoch[13] Batch [1340]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.126156,	
2017-06-23 18:16:58,766 Epoch[13] Batch [1350]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.126171,	
2017-06-23 18:17:02,486 Epoch[13] Batch [1360]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.126181,	
2017-06-23 18:17:06,272 Epoch[13] Batch [1370]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.126183,	
2017-06-23 18:17:10,018 Epoch[13] Batch [1380]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.126098,	
2017-06-23 18:17:13,800 Epoch[13] Batch [1390]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.126091,	
2017-06-23 18:17:17,540 Epoch[13] Batch [1400]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.126104,	
2017-06-23 18:17:21,290 Epoch[13] Batch [1410]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.126185,	
2017-06-23 18:17:25,050 Epoch[13] Batch [1420]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.126124,	
2017-06-23 18:17:28,750 Epoch[13] Batch [1430]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.126076,	
2017-06-23 18:17:32,463 Epoch[13] Batch [1440]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.126027,	
2017-06-23 18:17:36,285 Epoch[13] Batch [1450]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.126026,	
2017-06-23 18:17:40,051 Epoch[13] Batch [1460]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.126050,	
2017-06-23 18:17:43,810 Epoch[13] Batch [1470]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.126079,	
2017-06-23 18:17:47,577 Epoch[13] Batch [1480]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.126072,	
2017-06-23 18:17:49,787 Epoch[13] Train-FCNLogLoss=0.126169
2017-06-23 18:17:49,787 Epoch[13] Time cost=581.793
2017-06-23 18:17:50,533 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0014.params"
2017-06-23 18:17:53,978 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0014.states"
2017-06-23 18:17:58,516 Epoch[14] Batch [10]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.122708,	
2017-06-23 18:18:02,238 Epoch[14] Batch [20]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.125706,	
2017-06-23 18:18:05,949 Epoch[14] Batch [30]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.125155,	
2017-06-23 18:18:09,723 Epoch[14] Batch [40]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.126891,	
2017-06-23 18:18:13,471 Epoch[14] Batch [50]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.126251,	
2017-06-23 18:18:17,274 Epoch[14] Batch [60]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.124783,	
2017-06-23 18:18:21,048 Epoch[14] Batch [70]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.125187,	
2017-06-23 18:18:24,746 Epoch[14] Batch [80]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.125088,	
2017-06-23 18:18:28,466 Epoch[14] Batch [90]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.123487,	
2017-06-23 18:18:32,208 Epoch[14] Batch [100]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.123971,	
2017-06-23 18:18:36,000 Epoch[14] Batch [110]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.124675,	
2017-06-23 18:18:40,163 Epoch[14] Batch [120]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.123338,	
2017-06-23 18:18:44,016 Epoch[14] Batch [130]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.123302,	
2017-06-23 18:18:47,961 Epoch[14] Batch [140]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.125214,	
2017-06-23 18:18:51,764 Epoch[14] Batch [150]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.125347,	
2017-06-23 18:18:55,534 Epoch[14] Batch [160]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.125369,	
2017-06-23 18:18:59,356 Epoch[14] Batch [170]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.125112,	
2017-06-23 18:19:03,050 Epoch[14] Batch [180]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.125563,	
2017-06-23 18:19:06,814 Epoch[14] Batch [190]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.124338,	
2017-06-23 18:19:10,708 Epoch[14] Batch [200]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.124491,	
2017-06-23 18:19:14,705 Epoch[14] Batch [210]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.125269,	
2017-06-23 18:19:19,249 Epoch[14] Batch [220]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.126225,	
2017-06-23 18:19:24,222 Epoch[14] Batch [230]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.125942,	
2017-06-23 18:19:30,053 Epoch[14] Batch [240]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.125754,	
2017-06-23 18:19:35,592 Epoch[14] Batch [250]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.125845,	
2017-06-23 18:19:39,972 Epoch[14] Batch [260]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.126217,	
2017-06-23 18:19:44,164 Epoch[14] Batch [270]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.126341,	
2017-06-23 18:19:47,989 Epoch[14] Batch [280]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.126706,	
2017-06-23 18:19:51,736 Epoch[14] Batch [290]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.126135,	
2017-06-23 18:19:55,471 Epoch[14] Batch [300]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.125995,	
2017-06-23 18:19:59,253 Epoch[14] Batch [310]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.125985,	
2017-06-23 18:20:03,183 Epoch[14] Batch [320]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.126068,	
2017-06-23 18:20:06,993 Epoch[14] Batch [330]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.125997,	
2017-06-23 18:20:10,686 Epoch[14] Batch [340]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.126126,	
2017-06-23 18:20:14,292 Epoch[14] Batch [350]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.125876,	
2017-06-23 18:20:18,029 Epoch[14] Batch [360]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.125448,	
2017-06-23 18:20:21,700 Epoch[14] Batch [370]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.125485,	
2017-06-23 18:20:25,442 Epoch[14] Batch [380]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.125232,	
2017-06-23 18:20:29,364 Epoch[14] Batch [390]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.124689,	
2017-06-23 18:20:33,169 Epoch[14] Batch [400]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.124983,	
2017-06-23 18:20:37,127 Epoch[14] Batch [410]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.125027,	
2017-06-23 18:20:40,929 Epoch[14] Batch [420]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.125358,	
2017-06-23 18:20:44,693 Epoch[14] Batch [430]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.125592,	
2017-06-23 18:20:48,423 Epoch[14] Batch [440]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.125708,	
2017-06-23 18:20:52,141 Epoch[14] Batch [450]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.125580,	
2017-06-23 18:20:55,905 Epoch[14] Batch [460]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.125618,	
2017-06-23 18:20:59,732 Epoch[14] Batch [470]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.125554,	
2017-06-23 18:21:03,774 Epoch[14] Batch [480]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.125363,	
2017-06-23 18:21:07,871 Epoch[14] Batch [490]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.125069,	
2017-06-23 18:21:12,779 Epoch[14] Batch [500]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.125051,	
2017-06-23 18:21:18,198 Epoch[14] Batch [510]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.124982,	
2017-06-23 18:21:24,320 Epoch[14] Batch [520]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.124747,	
2017-06-23 18:21:29,698 Epoch[14] Batch [530]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.124565,	
2017-06-23 18:21:35,229 Epoch[14] Batch [540]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.124309,	
2017-06-23 18:21:40,194 Epoch[14] Batch [550]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.124311,	
2017-06-23 18:21:44,343 Epoch[14] Batch [560]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.124171,	
2017-06-23 18:21:48,138 Epoch[14] Batch [570]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123809,	
2017-06-23 18:21:51,990 Epoch[14] Batch [580]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.123661,	
2017-06-23 18:21:55,847 Epoch[14] Batch [590]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.123706,	
2017-06-23 18:21:59,908 Epoch[14] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.123667,	
2017-06-23 18:22:03,792 Epoch[14] Batch [610]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.123594,	
2017-06-23 18:22:07,638 Epoch[14] Batch [620]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.123631,	
2017-06-23 18:22:11,408 Epoch[14] Batch [630]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123375,	
2017-06-23 18:22:15,161 Epoch[14] Batch [640]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.123267,	
2017-06-23 18:22:19,131 Epoch[14] Batch [650]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.123225,	
2017-06-23 18:22:23,073 Epoch[14] Batch [660]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.123096,	
2017-06-23 18:22:26,916 Epoch[14] Batch [670]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.122829,	
2017-06-23 18:22:30,658 Epoch[14] Batch [680]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.122769,	
2017-06-23 18:22:34,491 Epoch[14] Batch [690]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.122575,	
2017-06-23 18:22:38,211 Epoch[14] Batch [700]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.122583,	
2017-06-23 18:22:41,978 Epoch[14] Batch [710]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.122667,	
2017-06-23 18:22:45,677 Epoch[14] Batch [720]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.122769,	
2017-06-23 18:22:49,518 Epoch[14] Batch [730]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.122723,	
2017-06-23 18:22:53,269 Epoch[14] Batch [740]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.122698,	
2017-06-23 18:22:57,247 Epoch[14] Batch [750]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.122701,	
2017-06-23 18:23:01,894 Epoch[14] Batch [760]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.122629,	
2017-06-23 18:23:06,702 Epoch[14] Batch [770]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.122598,	
2017-06-23 18:23:12,157 Epoch[14] Batch [780]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.122619,	
2017-06-23 18:23:17,281 Epoch[14] Batch [790]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.122482,	
2017-06-23 18:23:21,771 Epoch[14] Batch [800]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.122442,	
2017-06-23 18:23:25,925 Epoch[14] Batch [810]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.122442,	
2017-06-23 18:23:29,887 Epoch[14] Batch [820]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.122562,	
2017-06-23 18:23:33,699 Epoch[14] Batch [830]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.122800,	
2017-06-23 18:23:37,501 Epoch[14] Batch [840]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.122773,	
2017-06-23 18:23:41,366 Epoch[14] Batch [850]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.122816,	
2017-06-23 18:23:45,180 Epoch[14] Batch [860]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.122731,	
2017-06-23 18:23:48,999 Epoch[14] Batch [870]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.122625,	
2017-06-23 18:23:52,798 Epoch[14] Batch [880]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.122510,	
2017-06-23 18:23:56,655 Epoch[14] Batch [890]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.122442,	
2017-06-23 18:24:00,539 Epoch[14] Batch [900]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.122480,	
2017-06-23 18:24:04,602 Epoch[14] Batch [910]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.122484,	
2017-06-23 18:24:08,662 Epoch[14] Batch [920]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.122535,	
2017-06-23 18:24:12,674 Epoch[14] Batch [930]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.122787,	
2017-06-23 18:24:16,504 Epoch[14] Batch [940]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.122803,	
2017-06-23 18:24:20,275 Epoch[14] Batch [950]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.122947,	
2017-06-23 18:24:24,172 Epoch[14] Batch [960]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.122918,	
2017-06-23 18:24:28,108 Epoch[14] Batch [970]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.122943,	
2017-06-23 18:24:31,937 Epoch[14] Batch [980]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.122993,	
2017-06-23 18:24:35,778 Epoch[14] Batch [990]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.123146,	
2017-06-23 18:24:39,565 Epoch[14] Batch [1000]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.123031,	
2017-06-23 18:24:43,511 Epoch[14] Batch [1010]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.122955,	
2017-06-23 18:24:47,573 Epoch[14] Batch [1020]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.123110,	
2017-06-23 18:24:52,203 Epoch[14] Batch [1030]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.123238,	
2017-06-23 18:24:57,090 Epoch[14] Batch [1040]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.123098,	
2017-06-23 18:25:02,034 Epoch[14] Batch [1050]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.123132,	
2017-06-23 18:25:07,139 Epoch[14] Batch [1060]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.123202,	
2017-06-23 18:25:11,179 Epoch[14] Batch [1070]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.123193,	
2017-06-23 18:25:15,151 Epoch[14] Batch [1080]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.123076,	
2017-06-23 18:25:19,039 Epoch[14] Batch [1090]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.123084,	
2017-06-23 18:25:22,915 Epoch[14] Batch [1100]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.123061,	
2017-06-23 18:25:26,824 Epoch[14] Batch [1110]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.123181,	
2017-06-23 18:25:30,724 Epoch[14] Batch [1120]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.123179,	
2017-06-23 18:25:34,618 Epoch[14] Batch [1130]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.122993,	
2017-06-23 18:25:38,520 Epoch[14] Batch [1140]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.122980,	
2017-06-23 18:25:42,328 Epoch[14] Batch [1150]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123046,	
2017-06-23 18:25:46,198 Epoch[14] Batch [1160]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.122971,	
2017-06-23 18:25:50,277 Epoch[14] Batch [1170]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.122935,	
2017-06-23 18:25:54,484 Epoch[14] Batch [1180]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.122926,	
2017-06-23 18:25:58,451 Epoch[14] Batch [1190]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.122848,	
2017-06-23 18:26:02,529 Epoch[14] Batch [1200]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.122892,	
2017-06-23 18:26:06,344 Epoch[14] Batch [1210]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.122877,	
2017-06-23 18:26:10,111 Epoch[14] Batch [1220]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.122950,	
2017-06-23 18:26:13,716 Epoch[14] Batch [1230]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.122962,	
2017-06-23 18:26:17,534 Epoch[14] Batch [1240]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.122915,	
2017-06-23 18:26:21,233 Epoch[14] Batch [1250]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.122846,	
2017-06-23 18:26:25,024 Epoch[14] Batch [1260]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.122637,	
2017-06-23 18:26:28,910 Epoch[14] Batch [1270]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.122600,	
2017-06-23 18:26:32,969 Epoch[14] Batch [1280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.122499,	
2017-06-23 18:26:37,350 Epoch[14] Batch [1290]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.122375,	
2017-06-23 18:26:42,790 Epoch[14] Batch [1300]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.122394,	
2017-06-23 18:26:48,255 Epoch[14] Batch [1310]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.122562,	
2017-06-23 18:26:53,124 Epoch[14] Batch [1320]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.122749,	
2017-06-23 18:26:57,558 Epoch[14] Batch [1330]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.122815,	
2017-06-23 18:27:01,664 Epoch[14] Batch [1340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.122918,	
2017-06-23 18:27:05,547 Epoch[14] Batch [1350]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.122966,	
2017-06-23 18:27:09,447 Epoch[14] Batch [1360]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.123069,	
2017-06-23 18:27:13,259 Epoch[14] Batch [1370]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.123017,	
2017-06-23 18:27:17,252 Epoch[14] Batch [1380]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.123087,	
2017-06-23 18:27:21,181 Epoch[14] Batch [1390]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.123353,	
2017-06-23 18:27:25,015 Epoch[14] Batch [1400]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.123336,	
2017-06-23 18:27:28,857 Epoch[14] Batch [1410]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.123362,	
2017-06-23 18:27:32,537 Epoch[14] Batch [1420]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.123633,	
2017-06-23 18:27:36,460 Epoch[14] Batch [1430]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.123906,	
2017-06-23 18:27:40,486 Epoch[14] Batch [1440]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.124003,	
2017-06-23 18:27:44,467 Epoch[14] Batch [1450]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.124115,	
2017-06-23 18:27:48,503 Epoch[14] Batch [1460]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.124178,	
2017-06-23 18:27:52,219 Epoch[14] Batch [1470]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.124113,	
2017-06-23 18:27:55,934 Epoch[14] Batch [1480]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.124207,	
2017-06-23 18:27:58,167 Epoch[14] Train-FCNLogLoss=0.124261
2017-06-23 18:27:58,167 Epoch[14] Time cost=604.189
2017-06-23 18:27:58,913 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0015.params"
2017-06-23 18:28:02,274 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0015.states"
2017-06-23 18:28:06,892 Epoch[15] Batch [10]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.146846,	
2017-06-23 18:28:10,603 Epoch[15] Batch [20]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.133072,	
2017-06-23 18:28:14,413 Epoch[15] Batch [30]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.141141,	
2017-06-23 18:28:18,540 Epoch[15] Batch [40]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.134624,	
2017-06-23 18:28:23,126 Epoch[15] Batch [50]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.133173,	
2017-06-23 18:28:27,801 Epoch[15] Batch [60]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.131730,	
2017-06-23 18:28:33,785 Epoch[15] Batch [70]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.131449,	
2017-06-23 18:28:39,708 Epoch[15] Batch [80]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.130983,	
2017-06-23 18:28:44,969 Epoch[15] Batch [90]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.130664,	
2017-06-23 18:28:49,765 Epoch[15] Batch [100]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.130904,	
2017-06-23 18:28:54,954 Epoch[15] Batch [110]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.130485,	
2017-06-23 18:29:00,119 Epoch[15] Batch [120]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.129546,	
2017-06-23 18:29:05,186 Epoch[15] Batch [130]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.128830,	
2017-06-23 18:29:09,675 Epoch[15] Batch [140]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.127873,	
2017-06-23 18:29:13,710 Epoch[15] Batch [150]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.128132,	
2017-06-23 18:29:17,796 Epoch[15] Batch [160]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.127360,	
2017-06-23 18:29:21,861 Epoch[15] Batch [170]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.125944,	
2017-06-23 18:29:26,062 Epoch[15] Batch [180]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.125939,	
2017-06-23 18:29:29,957 Epoch[15] Batch [190]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.125540,	
2017-06-23 18:29:33,706 Epoch[15] Batch [200]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.124877,	
2017-06-23 18:29:37,483 Epoch[15] Batch [210]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.125533,	
2017-06-23 18:29:41,295 Epoch[15] Batch [220]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.125294,	
2017-06-23 18:29:45,154 Epoch[15] Batch [230]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.124818,	
2017-06-23 18:29:48,960 Epoch[15] Batch [240]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.124631,	
2017-06-23 18:29:52,630 Epoch[15] Batch [250]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.123804,	
2017-06-23 18:29:56,486 Epoch[15] Batch [260]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.123611,	
2017-06-23 18:30:00,840 Epoch[15] Batch [270]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.123274,	
2017-06-23 18:30:06,069 Epoch[15] Batch [280]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.123001,	
2017-06-23 18:30:11,630 Epoch[15] Batch [290]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.123258,	
2017-06-23 18:30:17,202 Epoch[15] Batch [300]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.123953,	
2017-06-23 18:30:22,352 Epoch[15] Batch [310]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.125402,	
2017-06-23 18:30:26,696 Epoch[15] Batch [320]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.126074,	
2017-06-23 18:30:30,901 Epoch[15] Batch [330]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.126061,	
2017-06-23 18:30:34,812 Epoch[15] Batch [340]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.125985,	
2017-06-23 18:30:38,575 Epoch[15] Batch [350]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.126658,	
2017-06-23 18:30:42,369 Epoch[15] Batch [360]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.126930,	
2017-06-23 18:30:46,144 Epoch[15] Batch [370]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.126566,	
2017-06-23 18:30:49,943 Epoch[15] Batch [380]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.126011,	
2017-06-23 18:30:53,785 Epoch[15] Batch [390]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.125912,	
2017-06-23 18:30:57,508 Epoch[15] Batch [400]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.125907,	
2017-06-23 18:31:01,391 Epoch[15] Batch [410]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.125447,	
2017-06-23 18:31:05,180 Epoch[15] Batch [420]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.125143,	
2017-06-23 18:31:09,066 Epoch[15] Batch [430]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.125046,	
2017-06-23 18:31:13,098 Epoch[15] Batch [440]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.125195,	
2017-06-23 18:31:17,056 Epoch[15] Batch [450]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.125019,	
2017-06-23 18:31:20,878 Epoch[15] Batch [460]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.124816,	
2017-06-23 18:31:24,662 Epoch[15] Batch [470]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.124710,	
2017-06-23 18:31:28,498 Epoch[15] Batch [480]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.124461,	
2017-06-23 18:31:32,265 Epoch[15] Batch [490]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.124439,	
2017-06-23 18:31:36,022 Epoch[15] Batch [500]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.124711,	
2017-06-23 18:31:39,836 Epoch[15] Batch [510]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.124943,	
2017-06-23 18:31:43,674 Epoch[15] Batch [520]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.125415,	
2017-06-23 18:31:47,445 Epoch[15] Batch [530]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.125421,	
2017-06-23 18:31:51,220 Epoch[15] Batch [540]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.125496,	
2017-06-23 18:31:55,286 Epoch[15] Batch [550]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.125518,	
2017-06-23 18:32:00,600 Epoch[15] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125151,	
2017-06-23 18:32:06,859 Epoch[15] Batch [570]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.124948,	
2017-06-23 18:32:13,398 Epoch[15] Batch [580]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.124646,	
2017-06-23 18:32:20,236 Epoch[15] Batch [590]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.124354,	
2017-06-23 18:32:26,716 Epoch[15] Batch [600]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.124325,	
2017-06-23 18:32:33,776 Epoch[15] Batch [610]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.124401,	
2017-06-23 18:32:40,128 Epoch[15] Batch [620]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.124206,	
2017-06-23 18:32:45,869 Epoch[15] Batch [630]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.124478,	
2017-06-23 18:32:49,981 Epoch[15] Batch [640]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.124364,	
2017-06-23 18:32:53,858 Epoch[15] Batch [650]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.124119,	
2017-06-23 18:32:57,777 Epoch[15] Batch [660]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.124120,	
2017-06-23 18:33:01,959 Epoch[15] Batch [670]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.124028,	
2017-06-23 18:33:05,776 Epoch[15] Batch [680]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.124062,	
2017-06-23 18:33:09,499 Epoch[15] Batch [690]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.124018,	
2017-06-23 18:33:13,271 Epoch[15] Batch [700]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123763,	
2017-06-23 18:33:17,043 Epoch[15] Batch [710]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.123613,	
2017-06-23 18:33:20,815 Epoch[15] Batch [720]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123591,	
2017-06-23 18:33:24,711 Epoch[15] Batch [730]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.123688,	
2017-06-23 18:33:28,584 Epoch[15] Batch [740]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.123644,	
2017-06-23 18:33:32,380 Epoch[15] Batch [750]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.123486,	
2017-06-23 18:33:36,213 Epoch[15] Batch [760]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.123410,	
2017-06-23 18:33:40,280 Epoch[15] Batch [770]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.123319,	
2017-06-23 18:33:44,879 Epoch[15] Batch [780]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.123344,	
2017-06-23 18:33:50,297 Epoch[15] Batch [790]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.123247,	
2017-06-23 18:33:55,889 Epoch[15] Batch [800]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.123011,	
2017-06-23 18:34:00,518 Epoch[15] Batch [810]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.123028,	
2017-06-23 18:34:04,797 Epoch[15] Batch [820]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.123083,	
2017-06-23 18:34:08,799 Epoch[15] Batch [830]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.122964,	
2017-06-23 18:34:12,607 Epoch[15] Batch [840]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.122935,	
2017-06-23 18:34:16,374 Epoch[15] Batch [850]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.122803,	
2017-06-23 18:34:20,153 Epoch[15] Batch [860]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.122788,	
2017-06-23 18:34:24,007 Epoch[15] Batch [870]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.122626,	
2017-06-23 18:34:27,710 Epoch[15] Batch [880]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.122743,	
2017-06-23 18:34:31,529 Epoch[15] Batch [890]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.122658,	
2017-06-23 18:34:35,306 Epoch[15] Batch [900]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.122700,	
2017-06-23 18:34:39,017 Epoch[15] Batch [910]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.122773,	
2017-06-23 18:34:42,962 Epoch[15] Batch [920]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.122787,	
2017-06-23 18:34:46,866 Epoch[15] Batch [930]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.122744,	
2017-06-23 18:34:50,904 Epoch[15] Batch [940]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.122953,	
2017-06-23 18:34:54,811 Epoch[15] Batch [950]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.123027,	
2017-06-23 18:34:58,578 Epoch[15] Batch [960]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.122916,	
2017-06-23 18:35:02,365 Epoch[15] Batch [970]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.122731,	
2017-06-23 18:35:06,098 Epoch[15] Batch [980]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.122567,	
2017-06-23 18:35:09,860 Epoch[15] Batch [990]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.122550,	
2017-06-23 18:35:13,607 Epoch[15] Batch [1000]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.122519,	
2017-06-23 18:35:17,334 Epoch[15] Batch [1010]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.122555,	
2017-06-23 18:35:21,300 Epoch[15] Batch [1020]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.122447,	
2017-06-23 18:35:26,493 Epoch[15] Batch [1030]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.122442,	
2017-06-23 18:35:34,088 Epoch[15] Batch [1040]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.122404,	
2017-06-23 18:35:43,450 Epoch[15] Batch [1050]	Speed: 4.27 samples/sec	Train-FCNLogLoss=0.122355,	
2017-06-23 18:35:51,211 Epoch[15] Batch [1060]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.122379,	
2017-06-23 18:35:57,688 Epoch[15] Batch [1070]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.122322,	
2017-06-23 18:36:04,312 Epoch[15] Batch [1080]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.122237,	
2017-06-23 18:36:10,086 Epoch[15] Batch [1090]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.122191,	
2017-06-23 18:36:15,570 Epoch[15] Batch [1100]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.122100,	
2017-06-23 18:36:20,307 Epoch[15] Batch [1110]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.122051,	
2017-06-23 18:36:24,078 Epoch[15] Batch [1120]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.121867,	
2017-06-23 18:36:27,916 Epoch[15] Batch [1130]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.121668,	
2017-06-23 18:36:31,908 Epoch[15] Batch [1140]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.121645,	
2017-06-23 18:36:35,769 Epoch[15] Batch [1150]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.121494,	
2017-06-23 18:36:39,470 Epoch[15] Batch [1160]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.121558,	
2017-06-23 18:36:43,288 Epoch[15] Batch [1170]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.121501,	
2017-06-23 18:36:47,037 Epoch[15] Batch [1180]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.121534,	
2017-06-23 18:36:50,867 Epoch[15] Batch [1190]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.121480,	
2017-06-23 18:36:54,602 Epoch[15] Batch [1200]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.121479,	
2017-06-23 18:36:58,566 Epoch[15] Batch [1210]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.121502,	
2017-06-23 18:37:02,978 Epoch[15] Batch [1220]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.121645,	
2017-06-23 18:37:07,728 Epoch[15] Batch [1230]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.121619,	
2017-06-23 18:37:14,017 Epoch[15] Batch [1240]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.121856,	
2017-06-23 18:37:22,066 Epoch[15] Batch [1250]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.122034,	
2017-06-23 18:37:31,014 Epoch[15] Batch [1260]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.122231,	
2017-06-23 18:37:38,236 Epoch[15] Batch [1270]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.122351,	
2017-06-23 18:37:44,097 Epoch[15] Batch [1280]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.122382,	
2017-06-23 18:37:49,892 Epoch[15] Batch [1290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.122582,	
2017-06-23 18:37:54,897 Epoch[15] Batch [1300]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.122501,	
2017-06-23 18:38:00,121 Epoch[15] Batch [1310]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.122400,	
2017-06-23 18:38:05,343 Epoch[15] Batch [1320]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.122330,	
2017-06-23 18:38:10,151 Epoch[15] Batch [1330]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.122291,	
2017-06-23 18:38:14,886 Epoch[15] Batch [1340]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.122130,	
2017-06-23 18:38:18,730 Epoch[15] Batch [1350]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.122164,	
2017-06-23 18:38:22,569 Epoch[15] Batch [1360]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.122228,	
2017-06-23 18:38:26,351 Epoch[15] Batch [1370]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.122360,	
2017-06-23 18:38:30,118 Epoch[15] Batch [1380]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.122435,	
2017-06-23 18:38:34,013 Epoch[15] Batch [1390]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.122482,	
2017-06-23 18:38:37,801 Epoch[15] Batch [1400]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.122669,	
2017-06-23 18:38:41,658 Epoch[15] Batch [1410]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.122588,	
2017-06-23 18:38:45,454 Epoch[15] Batch [1420]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.122469,	
2017-06-23 18:38:50,780 Epoch[15] Batch [1430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122394,	
2017-06-23 18:38:55,757 Epoch[15] Batch [1440]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.122278,	
2017-06-23 18:39:01,667 Epoch[15] Batch [1450]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.122263,	
2017-06-23 18:39:07,035 Epoch[15] Batch [1460]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122198,	
2017-06-23 18:39:11,538 Epoch[15] Batch [1470]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.122246,	
2017-06-23 18:39:15,401 Epoch[15] Batch [1480]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.122273,	
2017-06-23 18:39:17,738 Epoch[15] Train-FCNLogLoss=0.122379
2017-06-23 18:39:17,738 Epoch[15] Time cost=675.463
2017-06-23 18:39:18,442 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0016.params"
2017-06-23 18:39:22,493 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0016.states"
2017-06-23 18:39:27,142 Epoch[16] Batch [10]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.124426,	
2017-06-23 18:39:30,925 Epoch[16] Batch [20]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.136946,	
2017-06-23 18:39:34,751 Epoch[16] Batch [30]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.130766,	
2017-06-23 18:39:38,523 Epoch[16] Batch [40]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.125887,	
2017-06-23 18:39:42,228 Epoch[16] Batch [50]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.124791,	
2017-06-23 18:39:46,006 Epoch[16] Batch [60]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.122982,	
2017-06-23 18:39:49,798 Epoch[16] Batch [70]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.123328,	
2017-06-23 18:39:53,929 Epoch[16] Batch [80]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.127933,	
2017-06-23 18:39:57,865 Epoch[16] Batch [90]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.136401,	
2017-06-23 18:40:01,659 Epoch[16] Batch [100]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.140528,	
2017-06-23 18:40:05,472 Epoch[16] Batch [110]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.142120,	
2017-06-23 18:40:09,253 Epoch[16] Batch [120]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.143316,	
2017-06-23 18:40:13,061 Epoch[16] Batch [130]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.143323,	
2017-06-23 18:40:16,844 Epoch[16] Batch [140]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.142659,	
2017-06-23 18:40:20,600 Epoch[16] Batch [150]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.141655,	
2017-06-23 18:40:24,398 Epoch[16] Batch [160]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.141599,	
2017-06-23 18:40:28,201 Epoch[16] Batch [170]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.140985,	
2017-06-23 18:40:31,946 Epoch[16] Batch [180]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.140791,	
2017-06-23 18:40:35,685 Epoch[16] Batch [190]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.139683,	
2017-06-23 18:40:39,428 Epoch[16] Batch [200]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.139046,	
2017-06-23 18:40:43,197 Epoch[16] Batch [210]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.137900,	
2017-06-23 18:40:46,999 Epoch[16] Batch [220]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.137270,	
2017-06-23 18:40:50,776 Epoch[16] Batch [230]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.136380,	
2017-06-23 18:40:54,532 Epoch[16] Batch [240]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.135486,	
2017-06-23 18:40:58,271 Epoch[16] Batch [250]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.134698,	
2017-06-23 18:41:02,048 Epoch[16] Batch [260]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.134131,	
2017-06-23 18:41:05,776 Epoch[16] Batch [270]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.133141,	
2017-06-23 18:41:09,582 Epoch[16] Batch [280]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.132714,	
2017-06-23 18:41:13,353 Epoch[16] Batch [290]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.131553,	
2017-06-23 18:41:17,057 Epoch[16] Batch [300]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.131288,	
2017-06-23 18:41:20,771 Epoch[16] Batch [310]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.131021,	
2017-06-23 18:41:24,478 Epoch[16] Batch [320]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.130844,	
2017-06-23 18:41:28,187 Epoch[16] Batch [330]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.130866,	
2017-06-23 18:41:31,920 Epoch[16] Batch [340]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.130414,	
2017-06-23 18:41:35,647 Epoch[16] Batch [350]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.130217,	
2017-06-23 18:41:39,299 Epoch[16] Batch [360]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.129879,	
2017-06-23 18:41:43,074 Epoch[16] Batch [370]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.129535,	
2017-06-23 18:41:46,801 Epoch[16] Batch [380]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.129169,	
2017-06-23 18:41:50,686 Epoch[16] Batch [390]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.128866,	
2017-06-23 18:41:54,629 Epoch[16] Batch [400]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.128700,	
2017-06-23 18:41:58,420 Epoch[16] Batch [410]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.128564,	
2017-06-23 18:42:02,353 Epoch[16] Batch [420]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.128221,	
2017-06-23 18:42:06,111 Epoch[16] Batch [430]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.127915,	
2017-06-23 18:42:09,886 Epoch[16] Batch [440]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.127622,	
2017-06-23 18:42:13,566 Epoch[16] Batch [450]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.127255,	
2017-06-23 18:42:17,348 Epoch[16] Batch [460]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.127084,	
2017-06-23 18:42:21,114 Epoch[16] Batch [470]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.126898,	
2017-06-23 18:42:24,794 Epoch[16] Batch [480]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.126729,	
2017-06-23 18:42:28,563 Epoch[16] Batch [490]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.126469,	
2017-06-23 18:42:32,395 Epoch[16] Batch [500]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.125858,	
2017-06-23 18:42:36,155 Epoch[16] Batch [510]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.125801,	
2017-06-23 18:42:39,926 Epoch[16] Batch [520]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.125628,	
2017-06-23 18:42:43,713 Epoch[16] Batch [530]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.125666,	
2017-06-23 18:42:47,416 Epoch[16] Batch [540]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.125633,	
2017-06-23 18:42:51,227 Epoch[16] Batch [550]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.125576,	
2017-06-23 18:42:55,008 Epoch[16] Batch [560]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.125532,	
2017-06-23 18:42:58,725 Epoch[16] Batch [570]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.125446,	
2017-06-23 18:43:02,502 Epoch[16] Batch [580]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.125420,	
2017-06-23 18:43:06,179 Epoch[16] Batch [590]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.125528,	
2017-06-23 18:43:10,046 Epoch[16] Batch [600]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.125744,	
2017-06-23 18:43:13,701 Epoch[16] Batch [610]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.125615,	
2017-06-23 18:43:17,314 Epoch[16] Batch [620]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.125786,	
2017-06-23 18:43:20,934 Epoch[16] Batch [630]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.125829,	
2017-06-23 18:43:24,623 Epoch[16] Batch [640]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.125644,	
2017-06-23 18:43:28,354 Epoch[16] Batch [650]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.125336,	
2017-06-23 18:43:32,119 Epoch[16] Batch [660]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.125143,	
2017-06-23 18:43:35,843 Epoch[16] Batch [670]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.124872,	
2017-06-23 18:43:39,569 Epoch[16] Batch [680]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.124868,	
2017-06-23 18:43:43,292 Epoch[16] Batch [690]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.124845,	
2017-06-23 18:43:47,070 Epoch[16] Batch [700]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.124676,	
2017-06-23 18:43:51,118 Epoch[16] Batch [710]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.124637,	
2017-06-23 18:43:54,997 Epoch[16] Batch [720]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.124382,	
2017-06-23 18:43:59,002 Epoch[16] Batch [730]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.124245,	
2017-06-23 18:44:02,934 Epoch[16] Batch [740]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.124178,	
2017-06-23 18:44:06,635 Epoch[16] Batch [750]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.124105,	
2017-06-23 18:44:10,359 Epoch[16] Batch [760]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.123950,	
2017-06-23 18:44:14,152 Epoch[16] Batch [770]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.123806,	
2017-06-23 18:44:17,924 Epoch[16] Batch [780]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123617,	
2017-06-23 18:44:21,710 Epoch[16] Batch [790]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.123597,	
2017-06-23 18:44:25,514 Epoch[16] Batch [800]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123591,	
2017-06-23 18:44:29,282 Epoch[16] Batch [810]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.123598,	
2017-06-23 18:44:33,049 Epoch[16] Batch [820]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.123522,	
2017-06-23 18:44:36,781 Epoch[16] Batch [830]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.123630,	
2017-06-23 18:44:40,518 Epoch[16] Batch [840]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.123599,	
2017-06-23 18:44:44,602 Epoch[16] Batch [850]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.123462,	
2017-06-23 18:44:49,389 Epoch[16] Batch [860]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.123340,	
2017-06-23 18:44:54,984 Epoch[16] Batch [870]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.123243,	
2017-06-23 18:44:59,611 Epoch[16] Batch [880]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.123321,	
2017-06-23 18:45:04,125 Epoch[16] Batch [890]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.123479,	
2017-06-23 18:45:08,040 Epoch[16] Batch [900]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.123613,	
2017-06-23 18:45:11,876 Epoch[16] Batch [910]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.123649,	
2017-06-23 18:45:15,720 Epoch[16] Batch [920]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.123552,	
2017-06-23 18:45:19,417 Epoch[16] Batch [930]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.123408,	
2017-06-23 18:45:23,264 Epoch[16] Batch [940]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.123394,	
2017-06-23 18:45:26,951 Epoch[16] Batch [950]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.123298,	
2017-06-23 18:45:30,652 Epoch[16] Batch [960]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.123508,	
2017-06-23 18:45:34,384 Epoch[16] Batch [970]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.123505,	
2017-06-23 18:45:38,192 Epoch[16] Batch [980]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.123387,	
2017-06-23 18:45:41,971 Epoch[16] Batch [990]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.123405,	
2017-06-23 18:45:46,125 Epoch[16] Batch [1000]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.123510,	
2017-06-23 18:45:50,079 Epoch[16] Batch [1010]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.123457,	
2017-06-23 18:45:53,937 Epoch[16] Batch [1020]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.123370,	
2017-06-23 18:45:57,690 Epoch[16] Batch [1030]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.123289,	
2017-06-23 18:46:01,467 Epoch[16] Batch [1040]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.123175,	
2017-06-23 18:46:05,183 Epoch[16] Batch [1050]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.123045,	
2017-06-23 18:46:08,991 Epoch[16] Batch [1060]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.123115,	
2017-06-23 18:46:12,761 Epoch[16] Batch [1070]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.123184,	
2017-06-23 18:46:16,539 Epoch[16] Batch [1080]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.123186,	
2017-06-23 18:46:20,287 Epoch[16] Batch [1090]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.123137,	
2017-06-23 18:46:24,022 Epoch[16] Batch [1100]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.123134,	
2017-06-23 18:46:27,783 Epoch[16] Batch [1110]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.122995,	
2017-06-23 18:46:31,614 Epoch[16] Batch [1120]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.122904,	
2017-06-23 18:46:35,411 Epoch[16] Batch [1130]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.122961,	
2017-06-23 18:46:39,189 Epoch[16] Batch [1140]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.122999,	
2017-06-23 18:46:42,900 Epoch[16] Batch [1150]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.123036,	
2017-06-23 18:46:46,642 Epoch[16] Batch [1160]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.123063,	
2017-06-23 18:46:50,479 Epoch[16] Batch [1170]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.122905,	
2017-06-23 18:46:54,204 Epoch[16] Batch [1180]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.122894,	
2017-06-23 18:46:58,005 Epoch[16] Batch [1190]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.122854,	
2017-06-23 18:47:01,650 Epoch[16] Batch [1200]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.122699,	
2017-06-23 18:47:05,477 Epoch[16] Batch [1210]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.122607,	
2017-06-23 18:47:09,238 Epoch[16] Batch [1220]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.122526,	
2017-06-23 18:47:13,022 Epoch[16] Batch [1230]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.122516,	
2017-06-23 18:47:16,775 Epoch[16] Batch [1240]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.122295,	
2017-06-23 18:47:20,611 Epoch[16] Batch [1250]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.122263,	
2017-06-23 18:47:24,412 Epoch[16] Batch [1260]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.122239,	
2017-06-23 18:47:28,155 Epoch[16] Batch [1270]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.122332,	
2017-06-23 18:47:31,864 Epoch[16] Batch [1280]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.122232,	
2017-06-23 18:47:35,732 Epoch[16] Batch [1290]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.122338,	
2017-06-23 18:47:39,468 Epoch[16] Batch [1300]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.122502,	
2017-06-23 18:47:43,396 Epoch[16] Batch [1310]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.122566,	
2017-06-23 18:47:47,386 Epoch[16] Batch [1320]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.122461,	
2017-06-23 18:47:51,409 Epoch[16] Batch [1330]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.122504,	
2017-06-23 18:47:55,287 Epoch[16] Batch [1340]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.122491,	
2017-06-23 18:47:59,035 Epoch[16] Batch [1350]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.122515,	
2017-06-23 18:48:02,848 Epoch[16] Batch [1360]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.122468,	
2017-06-23 18:48:06,623 Epoch[16] Batch [1370]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.122438,	
2017-06-23 18:48:10,427 Epoch[16] Batch [1380]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.122485,	
2017-06-23 18:48:14,290 Epoch[16] Batch [1390]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.122445,	
2017-06-23 18:48:18,067 Epoch[16] Batch [1400]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.122487,	
2017-06-23 18:48:22,024 Epoch[16] Batch [1410]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.122566,	
2017-06-23 18:48:25,768 Epoch[16] Batch [1420]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.122565,	
2017-06-23 18:48:29,600 Epoch[16] Batch [1430]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.122653,	
2017-06-23 18:48:33,382 Epoch[16] Batch [1440]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.122630,	
2017-06-23 18:48:37,195 Epoch[16] Batch [1450]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.122687,	
2017-06-23 18:48:40,911 Epoch[16] Batch [1460]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.122629,	
2017-06-23 18:48:44,692 Epoch[16] Batch [1470]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.122699,	
2017-06-23 18:48:48,386 Epoch[16] Batch [1480]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.122691,	
2017-06-23 18:48:50,565 Epoch[16] Train-FCNLogLoss=0.122641
2017-06-23 18:48:50,565 Epoch[16] Time cost=568.072
2017-06-23 18:48:51,336 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0017.params"
2017-06-23 18:48:54,212 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0017.states"
2017-06-23 18:48:58,673 Epoch[17] Batch [10]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.134939,	
2017-06-23 18:49:02,395 Epoch[17] Batch [20]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.128049,	
2017-06-23 18:49:06,115 Epoch[17] Batch [30]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.125197,	
2017-06-23 18:49:09,773 Epoch[17] Batch [40]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.119886,	
2017-06-23 18:49:13,587 Epoch[17] Batch [50]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.120592,	
2017-06-23 18:49:17,373 Epoch[17] Batch [60]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.118125,	
2017-06-23 18:49:21,115 Epoch[17] Batch [70]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.116667,	
2017-06-23 18:49:24,860 Epoch[17] Batch [80]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.116240,	
2017-06-23 18:49:28,766 Epoch[17] Batch [90]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.115964,	
2017-06-23 18:49:32,564 Epoch[17] Batch [100]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.114953,	
2017-06-23 18:49:36,270 Epoch[17] Batch [110]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.114252,	
2017-06-23 18:49:40,209 Epoch[17] Batch [120]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.115535,	
2017-06-23 18:49:44,253 Epoch[17] Batch [130]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116257,	
2017-06-23 18:49:48,169 Epoch[17] Batch [140]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.115849,	
2017-06-23 18:49:52,003 Epoch[17] Batch [150]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.115623,	
2017-06-23 18:49:55,787 Epoch[17] Batch [160]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.115328,	
2017-06-23 18:49:59,488 Epoch[17] Batch [170]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.116207,	
2017-06-23 18:50:03,214 Epoch[17] Batch [180]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.115595,	
2017-06-23 18:50:06,968 Epoch[17] Batch [190]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.115789,	
2017-06-23 18:50:10,659 Epoch[17] Batch [200]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.115882,	
2017-06-23 18:50:14,525 Epoch[17] Batch [210]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.115422,	
2017-06-23 18:50:18,392 Epoch[17] Batch [220]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.115622,	
2017-06-23 18:50:22,206 Epoch[17] Batch [230]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.115910,	
2017-06-23 18:50:26,238 Epoch[17] Batch [240]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115787,	
2017-06-23 18:50:30,560 Epoch[17] Batch [250]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.115419,	
2017-06-23 18:50:35,712 Epoch[17] Batch [260]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.115541,	
2017-06-23 18:50:41,111 Epoch[17] Batch [270]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.115404,	
2017-06-23 18:50:46,057 Epoch[17] Batch [280]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.116300,	
2017-06-23 18:50:50,146 Epoch[17] Batch [290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116212,	
2017-06-23 18:50:54,053 Epoch[17] Batch [300]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.116028,	
2017-06-23 18:50:57,873 Epoch[17] Batch [310]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.115797,	
2017-06-23 18:51:01,781 Epoch[17] Batch [320]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.115570,	
2017-06-23 18:51:05,610 Epoch[17] Batch [330]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.115356,	
2017-06-23 18:51:09,409 Epoch[17] Batch [340]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.115379,	
2017-06-23 18:51:13,228 Epoch[17] Batch [350]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.115326,	
2017-06-23 18:51:17,005 Epoch[17] Batch [360]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.115226,	
2017-06-23 18:51:21,055 Epoch[17] Batch [370]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.115123,	
2017-06-23 18:51:25,044 Epoch[17] Batch [380]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.114979,	
2017-06-23 18:51:28,937 Epoch[17] Batch [390]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.115469,	
2017-06-23 18:51:33,042 Epoch[17] Batch [400]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115570,	
2017-06-23 18:51:37,050 Epoch[17] Batch [410]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.115797,	
2017-06-23 18:51:40,894 Epoch[17] Batch [420]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.115676,	
2017-06-23 18:51:44,658 Epoch[17] Batch [430]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.115850,	
2017-06-23 18:51:48,494 Epoch[17] Batch [440]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.116175,	
2017-06-23 18:51:52,328 Epoch[17] Batch [450]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.116425,	
2017-06-23 18:51:56,137 Epoch[17] Batch [460]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.116631,	
2017-06-23 18:51:59,970 Epoch[17] Batch [470]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.116670,	
2017-06-23 18:52:03,771 Epoch[17] Batch [480]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.116357,	
2017-06-23 18:52:07,556 Epoch[17] Batch [490]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.116316,	
2017-06-23 18:52:11,415 Epoch[17] Batch [500]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.116204,	
2017-06-23 18:52:15,187 Epoch[17] Batch [510]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.116370,	
2017-06-23 18:52:19,294 Epoch[17] Batch [520]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.116085,	
2017-06-23 18:52:23,445 Epoch[17] Batch [530]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.116165,	
2017-06-23 18:52:28,368 Epoch[17] Batch [540]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.116181,	
2017-06-23 18:52:32,850 Epoch[17] Batch [550]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.116587,	
2017-06-23 18:52:36,869 Epoch[17] Batch [560]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116484,	
2017-06-23 18:52:40,799 Epoch[17] Batch [570]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116429,	
2017-06-23 18:52:44,680 Epoch[17] Batch [580]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.116275,	
2017-06-23 18:52:48,632 Epoch[17] Batch [590]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.116227,	
2017-06-23 18:52:52,665 Epoch[17] Batch [600]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116085,	
2017-06-23 18:52:56,381 Epoch[17] Batch [610]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.116261,	
2017-06-23 18:53:00,150 Epoch[17] Batch [620]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.116667,	
2017-06-23 18:53:03,888 Epoch[17] Batch [630]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.116809,	
2017-06-23 18:53:07,754 Epoch[17] Batch [640]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.116861,	
2017-06-23 18:53:11,580 Epoch[17] Batch [650]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.116922,	
2017-06-23 18:53:15,348 Epoch[17] Batch [660]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.117069,	
2017-06-23 18:53:19,562 Epoch[17] Batch [670]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.117015,	
2017-06-23 18:53:23,627 Epoch[17] Batch [680]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117125,	
2017-06-23 18:53:27,516 Epoch[17] Batch [690]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.117286,	
2017-06-23 18:53:31,252 Epoch[17] Batch [700]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.117388,	
2017-06-23 18:53:35,177 Epoch[17] Batch [710]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.117422,	
2017-06-23 18:53:38,901 Epoch[17] Batch [720]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.117387,	
2017-06-23 18:53:42,640 Epoch[17] Batch [730]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.117448,	
2017-06-23 18:53:46,389 Epoch[17] Batch [740]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.117246,	
2017-06-23 18:53:50,083 Epoch[17] Batch [750]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.117269,	
2017-06-23 18:53:53,928 Epoch[17] Batch [760]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.117306,	
2017-06-23 18:53:57,716 Epoch[17] Batch [770]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.117320,	
2017-06-23 18:54:01,611 Epoch[17] Batch [780]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.117635,	
2017-06-23 18:54:05,520 Epoch[17] Batch [790]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.117885,	
2017-06-23 18:54:09,309 Epoch[17] Batch [800]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.117953,	
2017-06-23 18:54:13,212 Epoch[17] Batch [810]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.118102,	
2017-06-23 18:54:17,919 Epoch[17] Batch [820]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.118061,	
2017-06-23 18:54:23,004 Epoch[17] Batch [830]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.118236,	
2017-06-23 18:54:27,394 Epoch[17] Batch [840]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.118225,	
2017-06-23 18:54:31,589 Epoch[17] Batch [850]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.118311,	
2017-06-23 18:54:35,445 Epoch[17] Batch [860]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.118222,	
2017-06-23 18:54:39,236 Epoch[17] Batch [870]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.118185,	
2017-06-23 18:54:43,221 Epoch[17] Batch [880]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118138,	
2017-06-23 18:54:47,015 Epoch[17] Batch [890]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.118023,	
2017-06-23 18:54:50,746 Epoch[17] Batch [900]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.118002,	
2017-06-23 18:54:54,476 Epoch[17] Batch [910]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.118022,	
2017-06-23 18:54:58,371 Epoch[17] Batch [920]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.117969,	
2017-06-23 18:55:02,198 Epoch[17] Batch [930]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.117863,	
2017-06-23 18:55:06,055 Epoch[17] Batch [940]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.117967,	
2017-06-23 18:55:10,116 Epoch[17] Batch [950]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.118307,	
2017-06-23 18:55:14,217 Epoch[17] Batch [960]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.118422,	
2017-06-23 18:55:18,259 Epoch[17] Batch [970]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118422,	
2017-06-23 18:55:22,213 Epoch[17] Batch [980]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.118292,	
2017-06-23 18:55:25,991 Epoch[17] Batch [990]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.118223,	
2017-06-23 18:55:29,699 Epoch[17] Batch [1000]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.118068,	
2017-06-23 18:55:33,488 Epoch[17] Batch [1010]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.118065,	
2017-06-23 18:55:37,287 Epoch[17] Batch [1020]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.118134,	
2017-06-23 18:55:40,994 Epoch[17] Batch [1030]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.118074,	
2017-06-23 18:55:44,798 Epoch[17] Batch [1040]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.118076,	
2017-06-23 18:55:48,725 Epoch[17] Batch [1050]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.118329,	
2017-06-23 18:55:52,561 Epoch[17] Batch [1060]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.118799,	
2017-06-23 18:55:56,301 Epoch[17] Batch [1070]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.118815,	
2017-06-23 18:56:00,170 Epoch[17] Batch [1080]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.118841,	
2017-06-23 18:56:04,348 Epoch[17] Batch [1090]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.118814,	
2017-06-23 18:56:09,011 Epoch[17] Batch [1100]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.118755,	
2017-06-23 18:56:13,878 Epoch[17] Batch [1110]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.118844,	
2017-06-23 18:56:18,375 Epoch[17] Batch [1120]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.118813,	
2017-06-23 18:56:22,787 Epoch[17] Batch [1130]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.118869,	
2017-06-23 18:56:26,859 Epoch[17] Batch [1140]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.118824,	
2017-06-23 18:56:30,832 Epoch[17] Batch [1150]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118885,	
2017-06-23 18:56:34,570 Epoch[17] Batch [1160]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.118956,	
2017-06-23 18:56:38,301 Epoch[17] Batch [1170]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.118945,	
2017-06-23 18:56:42,029 Epoch[17] Batch [1180]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.119039,	
2017-06-23 18:56:45,746 Epoch[17] Batch [1190]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.119396,	
2017-06-23 18:56:49,574 Epoch[17] Batch [1200]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.119597,	
2017-06-23 18:56:53,344 Epoch[17] Batch [1210]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.119756,	
2017-06-23 18:56:57,036 Epoch[17] Batch [1220]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.119724,	
2017-06-23 18:57:00,893 Epoch[17] Batch [1230]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.119754,	
2017-06-23 18:57:05,048 Epoch[17] Batch [1240]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.119787,	
2017-06-23 18:57:08,958 Epoch[17] Batch [1250]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.119740,	
2017-06-23 18:57:12,996 Epoch[17] Batch [1260]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.119799,	
2017-06-23 18:57:16,724 Epoch[17] Batch [1270]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.119812,	
2017-06-23 18:57:20,464 Epoch[17] Batch [1280]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.119867,	
2017-06-23 18:57:24,302 Epoch[17] Batch [1290]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.119868,	
2017-06-23 18:57:28,077 Epoch[17] Batch [1300]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.119757,	
2017-06-23 18:57:31,816 Epoch[17] Batch [1310]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.119631,	
2017-06-23 18:57:35,464 Epoch[17] Batch [1320]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.119699,	
2017-06-23 18:57:39,379 Epoch[17] Batch [1330]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.119696,	
2017-06-23 18:57:43,758 Epoch[17] Batch [1340]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.119732,	
2017-06-23 18:57:47,951 Epoch[17] Batch [1350]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.119684,	
2017-06-23 18:57:52,746 Epoch[17] Batch [1360]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.119652,	
2017-06-23 18:57:58,311 Epoch[17] Batch [1370]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.119633,	
2017-06-23 18:58:03,874 Epoch[17] Batch [1380]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.119590,	
2017-06-23 18:58:08,794 Epoch[17] Batch [1390]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.119553,	
2017-06-23 18:58:13,144 Epoch[17] Batch [1400]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.119506,	
2017-06-23 18:58:17,087 Epoch[17] Batch [1410]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.119435,	
2017-06-23 18:58:20,791 Epoch[17] Batch [1420]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.119406,	
2017-06-23 18:58:24,553 Epoch[17] Batch [1430]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.119483,	
2017-06-23 18:58:28,218 Epoch[17] Batch [1440]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.119436,	
2017-06-23 18:58:32,067 Epoch[17] Batch [1450]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.119451,	
2017-06-23 18:58:35,761 Epoch[17] Batch [1460]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.119404,	
2017-06-23 18:58:39,571 Epoch[17] Batch [1470]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.119433,	
2017-06-23 18:58:43,306 Epoch[17] Batch [1480]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.119441,	
2017-06-23 18:58:45,511 Epoch[17] Train-FCNLogLoss=0.119571
2017-06-23 18:58:45,511 Epoch[17] Time cost=591.299
2017-06-23 18:58:46,287 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0018.params"
2017-06-23 18:58:49,324 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0018.states"
2017-06-23 18:58:53,983 Epoch[18] Batch [10]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.124306,	
2017-06-23 18:58:57,779 Epoch[18] Batch [20]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.122713,	
2017-06-23 18:59:01,665 Epoch[18] Batch [30]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.121154,	
2017-06-23 18:59:05,509 Epoch[18] Batch [40]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.118317,	
2017-06-23 18:59:09,305 Epoch[18] Batch [50]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.118784,	
2017-06-23 18:59:13,069 Epoch[18] Batch [60]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.116351,	
2017-06-23 18:59:16,871 Epoch[18] Batch [70]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.116186,	
2017-06-23 18:59:20,638 Epoch[18] Batch [80]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.116150,	
2017-06-23 18:59:24,403 Epoch[18] Batch [90]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.115857,	
2017-06-23 18:59:28,313 Epoch[18] Batch [100]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.116280,	
2017-06-23 18:59:32,244 Epoch[18] Batch [110]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116941,	
2017-06-23 18:59:36,565 Epoch[18] Batch [120]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.117158,	
2017-06-23 18:59:41,856 Epoch[18] Batch [130]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.116436,	
2017-06-23 18:59:47,665 Epoch[18] Batch [140]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.116452,	
2017-06-23 18:59:53,400 Epoch[18] Batch [150]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.117351,	
2017-06-23 18:59:58,287 Epoch[18] Batch [160]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.118174,	
2017-06-23 19:00:02,337 Epoch[18] Batch [170]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117940,	
2017-06-23 19:00:06,164 Epoch[18] Batch [180]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.117744,	
2017-06-23 19:00:09,921 Epoch[18] Batch [190]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.116475,	
2017-06-23 19:00:13,672 Epoch[18] Batch [200]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.117378,	
2017-06-23 19:00:17,663 Epoch[18] Batch [210]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.117340,	
2017-06-23 19:00:21,352 Epoch[18] Batch [220]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.117672,	
2017-06-23 19:00:25,188 Epoch[18] Batch [230]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.118814,	
2017-06-23 19:00:29,014 Epoch[18] Batch [240]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.119231,	
2017-06-23 19:00:32,681 Epoch[18] Batch [250]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.118960,	
2017-06-23 19:00:36,410 Epoch[18] Batch [260]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.119902,	
2017-06-23 19:00:40,104 Epoch[18] Batch [270]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.119808,	
2017-06-23 19:00:43,890 Epoch[18] Batch [280]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.119490,	
2017-06-23 19:00:47,726 Epoch[18] Batch [290]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.119688,	
2017-06-23 19:00:51,696 Epoch[18] Batch [300]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.119567,	
2017-06-23 19:00:55,477 Epoch[18] Batch [310]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.119149,	
2017-06-23 19:00:59,310 Epoch[18] Batch [320]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.118443,	
2017-06-23 19:01:03,067 Epoch[18] Batch [330]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.118724,	
2017-06-23 19:01:06,725 Epoch[18] Batch [340]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.118482,	
2017-06-23 19:01:10,605 Epoch[18] Batch [350]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.118275,	
2017-06-23 19:01:14,644 Epoch[18] Batch [360]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118366,	
2017-06-23 19:01:18,894 Epoch[18] Batch [370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.118041,	
2017-06-23 19:01:23,896 Epoch[18] Batch [380]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.117916,	
2017-06-23 19:01:30,134 Epoch[18] Batch [390]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.117785,	
2017-06-23 19:01:36,288 Epoch[18] Batch [400]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.117569,	
2017-06-23 19:01:42,283 Epoch[18] Batch [410]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.117460,	
2017-06-23 19:01:47,407 Epoch[18] Batch [420]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.117041,	
2017-06-23 19:01:51,755 Epoch[18] Batch [430]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.117238,	
2017-06-23 19:01:55,723 Epoch[18] Batch [440]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.117196,	
2017-06-23 19:01:59,466 Epoch[18] Batch [450]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.117280,	
2017-06-23 19:02:03,239 Epoch[18] Batch [460]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.116912,	
2017-06-23 19:02:06,988 Epoch[18] Batch [470]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.116914,	
2017-06-23 19:02:10,704 Epoch[18] Batch [480]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.117193,	
2017-06-23 19:02:14,508 Epoch[18] Batch [490]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.117191,	
2017-06-23 19:02:18,188 Epoch[18] Batch [500]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.116991,	
2017-06-23 19:02:21,967 Epoch[18] Batch [510]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.116572,	
2017-06-23 19:02:25,701 Epoch[18] Batch [520]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.116517,	
2017-06-23 19:02:29,473 Epoch[18] Batch [530]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.116472,	
2017-06-23 19:02:33,348 Epoch[18] Batch [540]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.116472,	
2017-06-23 19:02:37,194 Epoch[18] Batch [550]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.116283,	
2017-06-23 19:02:41,099 Epoch[18] Batch [560]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.116001,	
2017-06-23 19:02:44,866 Epoch[18] Batch [570]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.116064,	
2017-06-23 19:02:48,672 Epoch[18] Batch [580]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.115830,	
2017-06-23 19:02:52,563 Epoch[18] Batch [590]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.116033,	
2017-06-23 19:02:56,267 Epoch[18] Batch [600]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.115677,	
2017-06-23 19:03:00,267 Epoch[18] Batch [610]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.115394,	
2017-06-23 19:03:04,665 Epoch[18] Batch [620]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.115286,	
2017-06-23 19:03:09,524 Epoch[18] Batch [630]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.115089,	
2017-06-23 19:03:15,864 Epoch[18] Batch [640]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.115067,	
2017-06-23 19:03:22,230 Epoch[18] Batch [650]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.115051,	
2017-06-23 19:03:28,311 Epoch[18] Batch [660]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.114886,	
2017-06-23 19:03:33,149 Epoch[18] Batch [670]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.114898,	
2017-06-23 19:03:37,373 Epoch[18] Batch [680]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.114973,	
2017-06-23 19:03:41,408 Epoch[18] Batch [690]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115118,	
2017-06-23 19:03:45,239 Epoch[18] Batch [700]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.115058,	
2017-06-23 19:03:49,180 Epoch[18] Batch [710]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.115314,	
2017-06-23 19:03:52,907 Epoch[18] Batch [720]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.115332,	
2017-06-23 19:03:56,724 Epoch[18] Batch [730]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.115362,	
2017-06-23 19:04:00,427 Epoch[18] Batch [740]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.115540,	
2017-06-23 19:04:04,245 Epoch[18] Batch [750]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.115482,	
2017-06-23 19:04:08,040 Epoch[18] Batch [760]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.115600,	
2017-06-23 19:04:11,684 Epoch[18] Batch [770]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.115718,	
2017-06-23 19:04:15,514 Epoch[18] Batch [780]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.115919,	
2017-06-23 19:04:19,501 Epoch[18] Batch [790]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116361,	
2017-06-23 19:04:23,453 Epoch[18] Batch [800]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.116141,	
2017-06-23 19:04:27,431 Epoch[18] Batch [810]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.116027,	
2017-06-23 19:04:31,270 Epoch[18] Batch [820]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.116056,	
2017-06-23 19:04:35,070 Epoch[18] Batch [830]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.116122,	
2017-06-23 19:04:38,850 Epoch[18] Batch [840]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.115964,	
2017-06-23 19:04:42,666 Epoch[18] Batch [850]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.116064,	
2017-06-23 19:04:46,502 Epoch[18] Batch [860]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.116013,	
2017-06-23 19:04:50,334 Epoch[18] Batch [870]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.115980,	
2017-06-23 19:04:54,183 Epoch[18] Batch [880]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.116015,	
2017-06-23 19:04:58,025 Epoch[18] Batch [890]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.116018,	
2017-06-23 19:05:01,980 Epoch[18] Batch [900]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.115893,	
2017-06-23 19:05:06,876 Epoch[18] Batch [910]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.115688,	
2017-06-23 19:05:13,043 Epoch[18] Batch [920]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.115504,	
2017-06-23 19:05:19,279 Epoch[18] Batch [930]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.115561,	
2017-06-23 19:05:24,237 Epoch[18] Batch [940]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.115481,	
2017-06-23 19:05:28,763 Epoch[18] Batch [950]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.115346,	
2017-06-23 19:05:32,872 Epoch[18] Batch [960]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115249,	
2017-06-23 19:05:36,671 Epoch[18] Batch [970]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.115360,	
2017-06-23 19:05:40,528 Epoch[18] Batch [980]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.115415,	
2017-06-23 19:05:44,311 Epoch[18] Batch [990]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.115465,	
2017-06-23 19:05:48,124 Epoch[18] Batch [1000]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.115547,	
2017-06-23 19:05:51,953 Epoch[18] Batch [1010]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.115525,	
2017-06-23 19:05:55,761 Epoch[18] Batch [1020]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.115568,	
2017-06-23 19:05:59,530 Epoch[18] Batch [1030]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.115569,	
2017-06-23 19:06:03,449 Epoch[18] Batch [1040]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.115524,	
2017-06-23 19:06:07,441 Epoch[18] Batch [1050]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.115448,	
2017-06-23 19:06:11,474 Epoch[18] Batch [1060]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115415,	
2017-06-23 19:06:15,515 Epoch[18] Batch [1070]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.115408,	
2017-06-23 19:06:19,347 Epoch[18] Batch [1080]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.115609,	
2017-06-23 19:06:23,315 Epoch[18] Batch [1090]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.115511,	
2017-06-23 19:06:27,270 Epoch[18] Batch [1100]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.115449,	
2017-06-23 19:06:31,220 Epoch[18] Batch [1110]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.115361,	
2017-06-23 19:06:35,180 Epoch[18] Batch [1120]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.115206,	
2017-06-23 19:06:39,266 Epoch[18] Batch [1130]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.115129,	
2017-06-23 19:06:43,068 Epoch[18] Batch [1140]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.115245,	
2017-06-23 19:06:46,845 Epoch[18] Batch [1150]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.115137,	
2017-06-23 19:06:50,565 Epoch[18] Batch [1160]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.115252,	
2017-06-23 19:06:54,366 Epoch[18] Batch [1170]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.115405,	
2017-06-23 19:06:58,201 Epoch[18] Batch [1180]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.115515,	
2017-06-23 19:07:01,992 Epoch[18] Batch [1190]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.115466,	
2017-06-23 19:07:05,695 Epoch[18] Batch [1200]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.115504,	
2017-06-23 19:07:09,456 Epoch[18] Batch [1210]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.115519,	
2017-06-23 19:07:13,197 Epoch[18] Batch [1220]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.115557,	
2017-06-23 19:07:16,959 Epoch[18] Batch [1230]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.115490,	
2017-06-23 19:07:20,781 Epoch[18] Batch [1240]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.115395,	
2017-06-23 19:07:24,525 Epoch[18] Batch [1250]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.115489,	
2017-06-23 19:07:28,191 Epoch[18] Batch [1260]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.115438,	
2017-06-23 19:07:31,952 Epoch[18] Batch [1270]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.115560,	
2017-06-23 19:07:35,760 Epoch[18] Batch [1280]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.115515,	
2017-06-23 19:07:39,477 Epoch[18] Batch [1290]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.115551,	
2017-06-23 19:07:43,187 Epoch[18] Batch [1300]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.115573,	
2017-06-23 19:07:46,932 Epoch[18] Batch [1310]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.115592,	
2017-06-23 19:07:50,745 Epoch[18] Batch [1320]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.115650,	
2017-06-23 19:07:54,556 Epoch[18] Batch [1330]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.115550,	
2017-06-23 19:07:58,327 Epoch[18] Batch [1340]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.115481,	
2017-06-23 19:08:02,309 Epoch[18] Batch [1350]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.115452,	
2017-06-23 19:08:06,119 Epoch[18] Batch [1360]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.115607,	
2017-06-23 19:08:10,088 Epoch[18] Batch [1370]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.115598,	
2017-06-23 19:08:14,005 Epoch[18] Batch [1380]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.115591,	
2017-06-23 19:08:17,766 Epoch[18] Batch [1390]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.115498,	
2017-06-23 19:08:21,545 Epoch[18] Batch [1400]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.115592,	
2017-06-23 19:08:25,370 Epoch[18] Batch [1410]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.115621,	
2017-06-23 19:08:29,203 Epoch[18] Batch [1420]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.115643,	
2017-06-23 19:08:32,990 Epoch[18] Batch [1430]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.115558,	
2017-06-23 19:08:36,725 Epoch[18] Batch [1440]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.115539,	
2017-06-23 19:08:40,505 Epoch[18] Batch [1450]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.115628,	
2017-06-23 19:08:44,190 Epoch[18] Batch [1460]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.115691,	
2017-06-23 19:08:47,936 Epoch[18] Batch [1470]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.115613,	
2017-06-23 19:08:51,703 Epoch[18] Batch [1480]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.115568,	
2017-06-23 19:08:53,976 Epoch[18] Train-FCNLogLoss=0.115604
2017-06-23 19:08:53,976 Epoch[18] Time cost=604.652
2017-06-23 19:08:54,721 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0019.params"
2017-06-23 19:08:58,174 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0019.states"
2017-06-23 19:09:02,723 Epoch[19] Batch [10]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.119771,	
2017-06-23 19:09:06,450 Epoch[19] Batch [20]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.129971,	
2017-06-23 19:09:10,147 Epoch[19] Batch [30]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.127347,	
2017-06-23 19:09:13,955 Epoch[19] Batch [40]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.128357,	
2017-06-23 19:09:17,626 Epoch[19] Batch [50]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.124330,	
2017-06-23 19:09:21,401 Epoch[19] Batch [60]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.120992,	
2017-06-23 19:09:25,084 Epoch[19] Batch [70]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.118995,	
2017-06-23 19:09:28,777 Epoch[19] Batch [80]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.118233,	
2017-06-23 19:09:32,495 Epoch[19] Batch [90]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.117198,	
2017-06-23 19:09:36,263 Epoch[19] Batch [100]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.116210,	
2017-06-23 19:09:40,043 Epoch[19] Batch [110]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.115983,	
2017-06-23 19:09:43,801 Epoch[19] Batch [120]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.115889,	
2017-06-23 19:09:47,602 Epoch[19] Batch [130]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.116499,	
2017-06-23 19:09:51,263 Epoch[19] Batch [140]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.116276,	
2017-06-23 19:09:54,993 Epoch[19] Batch [150]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.116105,	
2017-06-23 19:09:58,825 Epoch[19] Batch [160]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.116402,	
2017-06-23 19:10:02,708 Epoch[19] Batch [170]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.116339,	
2017-06-23 19:10:06,739 Epoch[19] Batch [180]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116085,	
2017-06-23 19:10:10,761 Epoch[19] Batch [190]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115525,	
2017-06-23 19:10:14,654 Epoch[19] Batch [200]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.115589,	
2017-06-23 19:10:18,433 Epoch[19] Batch [210]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.114953,	
2017-06-23 19:10:22,335 Epoch[19] Batch [220]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.114368,	
2017-06-23 19:10:26,124 Epoch[19] Batch [230]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.114485,	
2017-06-23 19:10:29,856 Epoch[19] Batch [240]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.114137,	
2017-06-23 19:10:33,633 Epoch[19] Batch [250]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.114528,	
2017-06-23 19:10:37,391 Epoch[19] Batch [260]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.114070,	
2017-06-23 19:10:41,124 Epoch[19] Batch [270]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.113804,	
2017-06-23 19:10:44,855 Epoch[19] Batch [280]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.113533,	
2017-06-23 19:10:48,662 Epoch[19] Batch [290]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.113904,	
2017-06-23 19:10:52,421 Epoch[19] Batch [300]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.114006,	
2017-06-23 19:10:56,198 Epoch[19] Batch [310]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.113763,	
2017-06-23 19:10:59,971 Epoch[19] Batch [320]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.113777,	
2017-06-23 19:11:03,729 Epoch[19] Batch [330]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.113543,	
2017-06-23 19:11:07,438 Epoch[19] Batch [340]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.113755,	
2017-06-23 19:11:11,131 Epoch[19] Batch [350]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.113949,	
2017-06-23 19:11:14,816 Epoch[19] Batch [360]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.113754,	
2017-06-23 19:11:18,502 Epoch[19] Batch [370]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.113630,	
2017-06-23 19:11:22,226 Epoch[19] Batch [380]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.113631,	
2017-06-23 19:11:26,094 Epoch[19] Batch [390]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.113644,	
2017-06-23 19:11:29,787 Epoch[19] Batch [400]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.113650,	
2017-06-23 19:11:33,475 Epoch[19] Batch [410]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.113666,	
2017-06-23 19:11:37,128 Epoch[19] Batch [420]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.113741,	
2017-06-23 19:11:40,846 Epoch[19] Batch [430]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.113569,	
2017-06-23 19:11:44,619 Epoch[19] Batch [440]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.113890,	
2017-06-23 19:11:48,432 Epoch[19] Batch [450]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.113774,	
2017-06-23 19:11:52,192 Epoch[19] Batch [460]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.114040,	
2017-06-23 19:11:55,936 Epoch[19] Batch [470]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.113965,	
2017-06-23 19:11:59,739 Epoch[19] Batch [480]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.113967,	
2017-06-23 19:12:03,782 Epoch[19] Batch [490]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113874,	
2017-06-23 19:12:07,910 Epoch[19] Batch [500]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.113737,	
2017-06-23 19:12:11,983 Epoch[19] Batch [510]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113632,	
2017-06-23 19:12:15,727 Epoch[19] Batch [520]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.113605,	
2017-06-23 19:12:19,402 Epoch[19] Batch [530]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.113676,	
2017-06-23 19:12:23,163 Epoch[19] Batch [540]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.113859,	
2017-06-23 19:12:26,952 Epoch[19] Batch [550]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.114028,	
2017-06-23 19:12:30,800 Epoch[19] Batch [560]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.114671,	
2017-06-23 19:12:34,629 Epoch[19] Batch [570]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.114689,	
2017-06-23 19:12:38,321 Epoch[19] Batch [580]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.114594,	
2017-06-23 19:12:42,073 Epoch[19] Batch [590]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.114683,	
2017-06-23 19:12:45,881 Epoch[19] Batch [600]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.114661,	
2017-06-23 19:12:49,585 Epoch[19] Batch [610]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.114873,	
2017-06-23 19:12:53,330 Epoch[19] Batch [620]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.114895,	
2017-06-23 19:12:57,114 Epoch[19] Batch [630]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.115029,	
2017-06-23 19:13:00,814 Epoch[19] Batch [640]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.114878,	
2017-06-23 19:13:04,577 Epoch[19] Batch [650]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.114800,	
2017-06-23 19:13:08,387 Epoch[19] Batch [660]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.114833,	
2017-06-23 19:13:12,061 Epoch[19] Batch [670]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.114899,	
2017-06-23 19:13:15,804 Epoch[19] Batch [680]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.114818,	
2017-06-23 19:13:19,606 Epoch[19] Batch [690]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.114720,	
2017-06-23 19:13:23,376 Epoch[19] Batch [700]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.114590,	
2017-06-23 19:13:27,127 Epoch[19] Batch [710]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.114514,	
2017-06-23 19:13:30,844 Epoch[19] Batch [720]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.114440,	
2017-06-23 19:13:34,552 Epoch[19] Batch [730]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.114496,	
2017-06-23 19:13:38,339 Epoch[19] Batch [740]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.114338,	
2017-06-23 19:13:42,076 Epoch[19] Batch [750]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.114326,	
2017-06-23 19:13:45,878 Epoch[19] Batch [760]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.114221,	
2017-06-23 19:13:49,644 Epoch[19] Batch [770]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.114134,	
2017-06-23 19:13:53,384 Epoch[19] Batch [780]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.114165,	
2017-06-23 19:13:57,068 Epoch[19] Batch [790]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.114024,	
2017-06-23 19:14:00,989 Epoch[19] Batch [800]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.114513,	
2017-06-23 19:14:04,842 Epoch[19] Batch [810]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.114586,	
2017-06-23 19:14:08,880 Epoch[19] Batch [820]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.114522,	
2017-06-23 19:14:12,826 Epoch[19] Batch [830]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.114500,	
2017-06-23 19:14:16,618 Epoch[19] Batch [840]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.114562,	
2017-06-23 19:14:20,416 Epoch[19] Batch [850]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.114317,	
2017-06-23 19:14:24,166 Epoch[19] Batch [860]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.114304,	
2017-06-23 19:14:27,888 Epoch[19] Batch [870]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.114238,	
2017-06-23 19:14:31,713 Epoch[19] Batch [880]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.114072,	
2017-06-23 19:14:35,514 Epoch[19] Batch [890]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.114108,	
2017-06-23 19:14:39,227 Epoch[19] Batch [900]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.113983,	
2017-06-23 19:14:43,097 Epoch[19] Batch [910]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.114033,	
2017-06-23 19:14:46,811 Epoch[19] Batch [920]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.114045,	
2017-06-23 19:14:50,827 Epoch[19] Batch [930]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.114014,	
2017-06-23 19:14:55,540 Epoch[19] Batch [940]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.113921,	
2017-06-23 19:15:01,736 Epoch[19] Batch [950]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.113917,	
2017-06-23 19:15:07,373 Epoch[19] Batch [960]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.113828,	
2017-06-23 19:15:12,420 Epoch[19] Batch [970]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.113683,	
2017-06-23 19:15:17,919 Epoch[19] Batch [980]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.113778,	
2017-06-23 19:15:22,214 Epoch[19] Batch [990]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.113758,	
2017-06-23 19:15:26,150 Epoch[19] Batch [1000]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.113661,	
2017-06-23 19:15:30,112 Epoch[19] Batch [1010]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.113610,	
2017-06-23 19:15:33,936 Epoch[19] Batch [1020]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.113674,	
2017-06-23 19:15:37,678 Epoch[19] Batch [1030]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.113569,	
2017-06-23 19:15:41,362 Epoch[19] Batch [1040]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.113506,	
2017-06-23 19:15:45,102 Epoch[19] Batch [1050]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.113436,	
2017-06-23 19:15:49,126 Epoch[19] Batch [1060]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.113245,	
2017-06-23 19:15:53,194 Epoch[19] Batch [1070]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.113304,	
2017-06-23 19:15:57,118 Epoch[19] Batch [1080]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.113262,	
2017-06-23 19:16:01,054 Epoch[19] Batch [1090]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.113286,	
2017-06-23 19:16:04,833 Epoch[19] Batch [1100]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.113219,	
2017-06-23 19:16:08,636 Epoch[19] Batch [1110]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.113224,	
2017-06-23 19:16:12,475 Epoch[19] Batch [1120]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.113269,	
2017-06-23 19:16:16,328 Epoch[19] Batch [1130]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.113258,	
2017-06-23 19:16:20,173 Epoch[19] Batch [1140]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.113158,	
2017-06-23 19:16:24,031 Epoch[19] Batch [1150]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.113134,	
2017-06-23 19:16:27,728 Epoch[19] Batch [1160]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.113071,	
2017-06-23 19:16:31,444 Epoch[19] Batch [1170]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.113047,	
2017-06-23 19:16:35,240 Epoch[19] Batch [1180]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.113095,	
2017-06-23 19:16:39,051 Epoch[19] Batch [1190]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.113121,	
2017-06-23 19:16:43,623 Epoch[19] Batch [1200]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.113064,	
2017-06-23 19:16:49,374 Epoch[19] Batch [1210]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.113101,	
2017-06-23 19:16:55,062 Epoch[19] Batch [1220]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.113143,	
2017-06-23 19:17:00,661 Epoch[19] Batch [1230]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.113023,	
2017-06-23 19:17:05,499 Epoch[19] Batch [1240]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.112970,	
2017-06-23 19:17:09,527 Epoch[19] Batch [1250]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112887,	
2017-06-23 19:17:13,436 Epoch[19] Batch [1260]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.112875,	
2017-06-23 19:17:17,192 Epoch[19] Batch [1270]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.112893,	
2017-06-23 19:17:20,974 Epoch[19] Batch [1280]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.112965,	
2017-06-23 19:17:24,731 Epoch[19] Batch [1290]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.112920,	
2017-06-23 19:17:28,394 Epoch[19] Batch [1300]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.112881,	
2017-06-23 19:17:32,141 Epoch[19] Batch [1310]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.112781,	
2017-06-23 19:17:35,943 Epoch[19] Batch [1320]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.112813,	
2017-06-23 19:17:39,695 Epoch[19] Batch [1330]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.112731,	
2017-06-23 19:17:43,722 Epoch[19] Batch [1340]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112756,	
2017-06-23 19:17:47,713 Epoch[19] Batch [1350]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112734,	
2017-06-23 19:17:51,406 Epoch[19] Batch [1360]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.112718,	
2017-06-23 19:17:55,314 Epoch[19] Batch [1370]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.112719,	
2017-06-23 19:17:59,146 Epoch[19] Batch [1380]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.112685,	
2017-06-23 19:18:02,985 Epoch[19] Batch [1390]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.112620,	
2017-06-23 19:18:06,817 Epoch[19] Batch [1400]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.112519,	
2017-06-23 19:18:11,227 Epoch[19] Batch [1410]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.112482,	
2017-06-23 19:18:16,157 Epoch[19] Batch [1420]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.112417,	
2017-06-23 19:18:21,321 Epoch[19] Batch [1430]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.112386,	
2017-06-23 19:18:27,012 Epoch[19] Batch [1440]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.112303,	
2017-06-23 19:18:33,142 Epoch[19] Batch [1450]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.112207,	
2017-06-23 19:18:39,789 Epoch[19] Batch [1460]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.112244,	
2017-06-23 19:18:46,111 Epoch[19] Batch [1470]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.112178,	
2017-06-23 19:18:51,442 Epoch[19] Batch [1480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.112123,	
2017-06-23 19:18:54,123 Epoch[19] Train-FCNLogLoss=0.112108
2017-06-23 19:18:54,123 Epoch[19] Time cost=595.948
2017-06-23 19:18:54,960 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0020.params"
2017-06-23 19:18:59,287 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0020.states"
2017-06-23 19:19:04,038 Epoch[20] Batch [10]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.106794,	
2017-06-23 19:19:07,831 Epoch[20] Batch [20]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.108015,	
2017-06-23 19:19:11,756 Epoch[20] Batch [30]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.101656,	
2017-06-23 19:19:15,878 Epoch[20] Batch [40]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.100892,	
2017-06-23 19:19:19,921 Epoch[20] Batch [50]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105027,	
2017-06-23 19:19:24,022 Epoch[20] Batch [60]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104455,	
2017-06-23 19:19:27,931 Epoch[20] Batch [70]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.105006,	
2017-06-23 19:19:31,569 Epoch[20] Batch [80]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.105350,	
2017-06-23 19:19:35,289 Epoch[20] Batch [90]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.107586,	
2017-06-23 19:19:39,103 Epoch[20] Batch [100]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.107904,	
2017-06-23 19:19:42,890 Epoch[20] Batch [110]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.107339,	
2017-06-23 19:19:46,983 Epoch[20] Batch [120]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.107263,	
2017-06-23 19:19:50,789 Epoch[20] Batch [130]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.107950,	
2017-06-23 19:19:54,742 Epoch[20] Batch [140]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.108241,	
2017-06-23 19:19:58,914 Epoch[20] Batch [150]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.108823,	
2017-06-23 19:20:03,508 Epoch[20] Batch [160]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.108647,	
2017-06-23 19:20:09,094 Epoch[20] Batch [170]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.108946,	
2017-06-23 19:20:15,554 Epoch[20] Batch [180]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.109482,	
2017-06-23 19:20:20,641 Epoch[20] Batch [190]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.109982,	
2017-06-23 19:20:25,247 Epoch[20] Batch [200]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.109527,	
2017-06-23 19:20:29,325 Epoch[20] Batch [210]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109910,	
2017-06-23 19:20:33,243 Epoch[20] Batch [220]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.109758,	
2017-06-23 19:20:36,985 Epoch[20] Batch [230]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.109970,	
2017-06-23 19:20:40,803 Epoch[20] Batch [240]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.110450,	
2017-06-23 19:20:44,628 Epoch[20] Batch [250]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.110655,	
2017-06-23 19:20:48,475 Epoch[20] Batch [260]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.110837,	
2017-06-23 19:20:52,392 Epoch[20] Batch [270]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.110860,	
2017-06-23 19:20:56,371 Epoch[20] Batch [280]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.110613,	
2017-06-23 19:21:00,373 Epoch[20] Batch [290]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.110556,	
2017-06-23 19:21:04,283 Epoch[20] Batch [300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.110921,	
2017-06-23 19:21:08,317 Epoch[20] Batch [310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110661,	
2017-06-23 19:21:12,343 Epoch[20] Batch [320]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110796,	
2017-06-23 19:21:16,073 Epoch[20] Batch [330]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.110845,	
2017-06-23 19:21:20,046 Epoch[20] Batch [340]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.111287,	
2017-06-23 19:21:23,852 Epoch[20] Batch [350]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.111441,	
2017-06-23 19:21:27,657 Epoch[20] Batch [360]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.111304,	
2017-06-23 19:21:31,309 Epoch[20] Batch [370]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.111319,	
2017-06-23 19:21:35,090 Epoch[20] Batch [380]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.111618,	
2017-06-23 19:21:38,868 Epoch[20] Batch [390]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.111587,	
2017-06-23 19:21:42,739 Epoch[20] Batch [400]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.111268,	
2017-06-23 19:21:46,611 Epoch[20] Batch [410]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.111149,	
2017-06-23 19:21:51,873 Epoch[20] Batch [420]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.111170,	
2017-06-23 19:21:58,178 Epoch[20] Batch [430]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.111007,	
2017-06-23 19:22:02,975 Epoch[20] Batch [440]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.110931,	
2017-06-23 19:22:07,225 Epoch[20] Batch [450]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.111210,	
2017-06-23 19:22:11,435 Epoch[20] Batch [460]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.110965,	
2017-06-23 19:22:15,396 Epoch[20] Batch [470]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.110748,	
2017-06-23 19:22:19,203 Epoch[20] Batch [480]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.110621,	
2017-06-23 19:22:23,003 Epoch[20] Batch [490]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.110328,	
2017-06-23 19:22:27,017 Epoch[20] Batch [500]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.110471,	
2017-06-23 19:22:30,961 Epoch[20] Batch [510]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.110535,	
2017-06-23 19:22:34,774 Epoch[20] Batch [520]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.110698,	
2017-06-23 19:22:38,701 Epoch[20] Batch [530]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.111024,	
2017-06-23 19:22:42,778 Epoch[20] Batch [540]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.110905,	
2017-06-23 19:22:46,795 Epoch[20] Batch [550]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110941,	
2017-06-23 19:22:50,914 Epoch[20] Batch [560]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.110988,	
2017-06-23 19:22:54,829 Epoch[20] Batch [570]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.110730,	
2017-06-23 19:22:59,146 Epoch[20] Batch [580]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.110729,	
2017-06-23 19:23:03,551 Epoch[20] Batch [590]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.110643,	
2017-06-23 19:23:07,888 Epoch[20] Batch [600]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.110684,	
2017-06-23 19:23:12,110 Epoch[20] Batch [610]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.110742,	
2017-06-23 19:23:16,407 Epoch[20] Batch [620]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.110543,	
2017-06-23 19:23:20,563 Epoch[20] Batch [630]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.110407,	
2017-06-23 19:23:24,743 Epoch[20] Batch [640]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.110357,	
2017-06-23 19:23:29,031 Epoch[20] Batch [650]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.110152,	
2017-06-23 19:23:33,201 Epoch[20] Batch [660]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.110225,	
2017-06-23 19:23:37,248 Epoch[20] Batch [670]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.110309,	
2017-06-23 19:23:41,592 Epoch[20] Batch [680]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.110175,	
2017-06-23 19:23:45,703 Epoch[20] Batch [690]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110037,	
2017-06-23 19:23:49,836 Epoch[20] Batch [700]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.110078,	
2017-06-23 19:23:53,894 Epoch[20] Batch [710]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110191,	
2017-06-23 19:23:57,921 Epoch[20] Batch [720]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110281,	
2017-06-23 19:24:01,780 Epoch[20] Batch [730]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.110537,	
2017-06-23 19:24:05,737 Epoch[20] Batch [740]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.110452,	
2017-06-23 19:24:09,905 Epoch[20] Batch [750]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.110527,	
2017-06-23 19:24:13,882 Epoch[20] Batch [760]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.110386,	
2017-06-23 19:24:17,895 Epoch[20] Batch [770]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.110407,	
2017-06-23 19:24:22,023 Epoch[20] Batch [780]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.110525,	
2017-06-23 19:24:26,141 Epoch[20] Batch [790]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.110420,	
2017-06-23 19:24:30,416 Epoch[20] Batch [800]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.110438,	
2017-06-23 19:24:34,630 Epoch[20] Batch [810]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.110496,	
2017-06-23 19:24:38,652 Epoch[20] Batch [820]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110604,	
2017-06-23 19:24:42,737 Epoch[20] Batch [830]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110416,	
2017-06-23 19:24:46,979 Epoch[20] Batch [840]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.110949,	
2017-06-23 19:24:51,011 Epoch[20] Batch [850]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110916,	
2017-06-23 19:24:55,180 Epoch[20] Batch [860]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.111036,	
2017-06-23 19:24:59,163 Epoch[20] Batch [870]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110931,	
2017-06-23 19:25:03,188 Epoch[20] Batch [880]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.110892,	
2017-06-23 19:25:07,309 Epoch[20] Batch [890]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.111022,	
2017-06-23 19:25:11,312 Epoch[20] Batch [900]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.111077,	
2017-06-23 19:25:15,498 Epoch[20] Batch [910]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.111196,	
2017-06-23 19:25:19,599 Epoch[20] Batch [920]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.111067,	
2017-06-23 19:25:23,448 Epoch[20] Batch [930]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.111148,	
2017-06-23 19:25:27,563 Epoch[20] Batch [940]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.111097,	
2017-06-23 19:25:31,740 Epoch[20] Batch [950]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110980,	
2017-06-23 19:25:35,784 Epoch[20] Batch [960]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110918,	
2017-06-23 19:25:39,773 Epoch[20] Batch [970]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.110887,	
2017-06-23 19:25:43,940 Epoch[20] Batch [980]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.110716,	
2017-06-23 19:25:48,065 Epoch[20] Batch [990]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110697,	
2017-06-23 19:25:51,998 Epoch[20] Batch [1000]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.110642,	
2017-06-23 19:25:55,817 Epoch[20] Batch [1010]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.110791,	
2017-06-23 19:25:59,995 Epoch[20] Batch [1020]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110771,	
2017-06-23 19:26:04,146 Epoch[20] Batch [1030]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.110774,	
2017-06-23 19:26:08,372 Epoch[20] Batch [1040]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.110733,	
2017-06-23 19:26:12,465 Epoch[20] Batch [1050]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.110556,	
2017-06-23 19:26:16,509 Epoch[20] Batch [1060]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110629,	
2017-06-23 19:26:21,196 Epoch[20] Batch [1070]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.110554,	
2017-06-23 19:26:25,749 Epoch[20] Batch [1080]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.110455,	
2017-06-23 19:26:30,724 Epoch[20] Batch [1090]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.110425,	
2017-06-23 19:26:35,577 Epoch[20] Batch [1100]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.110410,	
2017-06-23 19:26:40,392 Epoch[20] Batch [1110]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.110293,	
2017-06-23 19:26:45,088 Epoch[20] Batch [1120]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.110548,	
2017-06-23 19:26:50,329 Epoch[20] Batch [1130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.110600,	
2017-06-23 19:26:55,324 Epoch[20] Batch [1140]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.110704,	
2017-06-23 19:27:00,186 Epoch[20] Batch [1150]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.110821,	
2017-06-23 19:27:05,182 Epoch[20] Batch [1160]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.110921,	
2017-06-23 19:27:09,845 Epoch[20] Batch [1170]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.111069,	
2017-06-23 19:27:14,210 Epoch[20] Batch [1180]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.111100,	
2017-06-23 19:27:19,217 Epoch[20] Batch [1190]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.111173,	
2017-06-23 19:27:24,698 Epoch[20] Batch [1200]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.111213,	
2017-06-23 19:27:29,885 Epoch[20] Batch [1210]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.111259,	
2017-06-23 19:27:35,222 Epoch[20] Batch [1220]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.111279,	
2017-06-23 19:27:40,592 Epoch[20] Batch [1230]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.111425,	
2017-06-23 19:27:45,882 Epoch[20] Batch [1240]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.111355,	
2017-06-23 19:27:50,874 Epoch[20] Batch [1250]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.111364,	
2017-06-23 19:27:56,240 Epoch[20] Batch [1260]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.111311,	
2017-06-23 19:28:01,416 Epoch[20] Batch [1270]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.111432,	
2017-06-23 19:28:06,200 Epoch[20] Batch [1280]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.111537,	
2017-06-23 19:28:11,455 Epoch[20] Batch [1290]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111504,	
2017-06-23 19:28:16,306 Epoch[20] Batch [1300]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.111544,	
2017-06-23 19:28:21,313 Epoch[20] Batch [1310]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.111594,	
2017-06-23 19:28:26,327 Epoch[20] Batch [1320]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.111568,	
2017-06-23 19:28:31,507 Epoch[20] Batch [1330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111616,	
2017-06-23 19:28:36,686 Epoch[20] Batch [1340]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.111663,	
2017-06-23 19:28:42,209 Epoch[20] Batch [1350]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.111674,	
2017-06-23 19:28:47,410 Epoch[20] Batch [1360]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.111713,	
2017-06-23 19:28:52,668 Epoch[20] Batch [1370]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.111818,	
2017-06-23 19:28:57,690 Epoch[20] Batch [1380]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.111912,	
2017-06-23 19:29:02,920 Epoch[20] Batch [1390]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111857,	
2017-06-23 19:29:07,946 Epoch[20] Batch [1400]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.111856,	
2017-06-23 19:29:13,014 Epoch[20] Batch [1410]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.111801,	
2017-06-23 19:29:18,131 Epoch[20] Batch [1420]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.111770,	
2017-06-23 19:29:23,090 Epoch[20] Batch [1430]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.111793,	
2017-06-23 19:29:28,212 Epoch[20] Batch [1440]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.111790,	
2017-06-23 19:29:33,279 Epoch[20] Batch [1450]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.111860,	
2017-06-23 19:29:38,151 Epoch[20] Batch [1460]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.111948,	
2017-06-23 19:29:43,207 Epoch[20] Batch [1470]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.112001,	
2017-06-23 19:29:48,220 Epoch[20] Batch [1480]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.111976,	
2017-06-23 19:29:51,434 Epoch[20] Train-FCNLogLoss=0.111989
2017-06-23 19:29:51,434 Epoch[20] Time cost=652.147
2017-06-23 19:29:52,246 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0021.params"
2017-06-23 19:29:56,354 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0021.states"
2017-06-23 19:30:02,452 Epoch[21] Batch [10]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.102580,	
2017-06-23 19:30:07,378 Epoch[21] Batch [20]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.108006,	
2017-06-23 19:30:12,371 Epoch[21] Batch [30]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.108903,	
2017-06-23 19:30:17,650 Epoch[21] Batch [40]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.110653,	
2017-06-23 19:30:22,840 Epoch[21] Batch [50]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.110390,	
2017-06-23 19:30:27,881 Epoch[21] Batch [60]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.108711,	
2017-06-23 19:30:33,099 Epoch[21] Batch [70]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.108600,	
2017-06-23 19:30:38,038 Epoch[21] Batch [80]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.108877,	
2017-06-23 19:30:43,167 Epoch[21] Batch [90]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.108052,	
2017-06-23 19:30:48,262 Epoch[21] Batch [100]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.108048,	
2017-06-23 19:30:53,254 Epoch[21] Batch [110]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.107919,	
2017-06-23 19:30:58,486 Epoch[21] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.107773,	
2017-06-23 19:31:03,776 Epoch[21] Batch [130]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.108909,	
2017-06-23 19:31:08,747 Epoch[21] Batch [140]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.108036,	
2017-06-23 19:31:14,002 Epoch[21] Batch [150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.108012,	
2017-06-23 19:31:19,178 Epoch[21] Batch [160]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.108593,	
2017-06-23 19:31:24,284 Epoch[21] Batch [170]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.108724,	
2017-06-23 19:31:29,257 Epoch[21] Batch [180]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.108606,	
2017-06-23 19:31:34,489 Epoch[21] Batch [190]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.108590,	
2017-06-23 19:31:39,500 Epoch[21] Batch [200]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.108352,	
2017-06-23 19:31:44,471 Epoch[21] Batch [210]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.108815,	
2017-06-23 19:31:49,507 Epoch[21] Batch [220]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.108585,	
2017-06-23 19:31:54,480 Epoch[21] Batch [230]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.108893,	
2017-06-23 19:31:59,659 Epoch[21] Batch [240]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.108888,	
2017-06-23 19:32:04,548 Epoch[21] Batch [250]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.108749,	
2017-06-23 19:32:09,805 Epoch[21] Batch [260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.108847,	
2017-06-23 19:32:15,042 Epoch[21] Batch [270]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.108845,	
2017-06-23 19:32:20,283 Epoch[21] Batch [280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.109228,	
2017-06-23 19:32:25,254 Epoch[21] Batch [290]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.109463,	
2017-06-23 19:32:30,460 Epoch[21] Batch [300]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.109520,	
2017-06-23 19:32:35,714 Epoch[21] Batch [310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.109889,	
2017-06-23 19:32:40,760 Epoch[21] Batch [320]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.109778,	
2017-06-23 19:32:45,995 Epoch[21] Batch [330]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.110298,	
2017-06-23 19:32:51,040 Epoch[21] Batch [340]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.110406,	
2017-06-23 19:32:55,896 Epoch[21] Batch [350]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.110309,	
2017-06-23 19:33:00,874 Epoch[21] Batch [360]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.110305,	
2017-06-23 19:33:06,119 Epoch[21] Batch [370]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.110386,	
2017-06-23 19:33:11,104 Epoch[21] Batch [380]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.110542,	
2017-06-23 19:33:16,333 Epoch[21] Batch [390]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.110249,	
2017-06-23 19:33:21,381 Epoch[21] Batch [400]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.110344,	
2017-06-23 19:33:26,596 Epoch[21] Batch [410]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.110264,	
2017-06-23 19:33:31,597 Epoch[21] Batch [420]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.110447,	
2017-06-23 19:33:36,496 Epoch[21] Batch [430]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.110419,	
2017-06-23 19:33:41,652 Epoch[21] Batch [440]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.110237,	
2017-06-23 19:33:46,654 Epoch[21] Batch [450]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.110176,	
2017-06-23 19:33:51,761 Epoch[21] Batch [460]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.110214,	
2017-06-23 19:33:56,770 Epoch[21] Batch [470]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.111327,	
2017-06-23 19:34:01,862 Epoch[21] Batch [480]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.111799,	
2017-06-23 19:34:07,444 Epoch[21] Batch [490]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.112007,	
2017-06-23 19:34:12,615 Epoch[21] Batch [500]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.112208,	
2017-06-23 19:34:17,610 Epoch[21] Batch [510]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.112524,	
2017-06-23 19:34:22,622 Epoch[21] Batch [520]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.112637,	
2017-06-23 19:34:27,614 Epoch[21] Batch [530]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.112755,	
2017-06-23 19:34:32,871 Epoch[21] Batch [540]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.112856,	
2017-06-23 19:34:38,156 Epoch[21] Batch [550]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.112808,	
2017-06-23 19:34:43,165 Epoch[21] Batch [560]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.112742,	
2017-06-23 19:34:48,270 Epoch[21] Batch [570]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.112641,	
2017-06-23 19:34:53,319 Epoch[21] Batch [580]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.112717,	
2017-06-23 19:34:58,411 Epoch[21] Batch [590]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.112774,	
2017-06-23 19:35:03,481 Epoch[21] Batch [600]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.112925,	
2017-06-23 19:35:08,817 Epoch[21] Batch [610]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.112712,	
2017-06-23 19:35:13,795 Epoch[21] Batch [620]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.112617,	
2017-06-23 19:35:18,833 Epoch[21] Batch [630]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.112654,	
2017-06-23 19:35:24,208 Epoch[21] Batch [640]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.112513,	
2017-06-23 19:35:29,398 Epoch[21] Batch [650]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112309,	
2017-06-23 19:35:34,700 Epoch[21] Batch [660]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.112296,	
2017-06-23 19:35:39,635 Epoch[21] Batch [670]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.112227,	
2017-06-23 19:35:44,871 Epoch[21] Batch [680]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112288,	
2017-06-23 19:35:49,828 Epoch[21] Batch [690]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.112369,	
2017-06-23 19:35:55,045 Epoch[21] Batch [700]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112320,	
2017-06-23 19:36:00,274 Epoch[21] Batch [710]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112340,	
2017-06-23 19:36:05,319 Epoch[21] Batch [720]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.112288,	
2017-06-23 19:36:10,357 Epoch[21] Batch [730]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.112147,	
2017-06-23 19:36:15,605 Epoch[21] Batch [740]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.112076,	
2017-06-23 19:36:20,715 Epoch[21] Batch [750]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.112068,	
2017-06-23 19:36:25,795 Epoch[21] Batch [760]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.111905,	
2017-06-23 19:36:30,725 Epoch[21] Batch [770]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.112088,	
2017-06-23 19:36:35,931 Epoch[21] Batch [780]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.112072,	
2017-06-23 19:36:40,978 Epoch[21] Batch [790]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.112280,	
2017-06-23 19:36:46,083 Epoch[21] Batch [800]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.112274,	
2017-06-23 19:36:51,142 Epoch[21] Batch [810]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.112134,	
2017-06-23 19:36:56,378 Epoch[21] Batch [820]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.112200,	
2017-06-23 19:37:01,416 Epoch[21] Batch [830]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.112171,	
2017-06-23 19:37:06,391 Epoch[21] Batch [840]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.112156,	
2017-06-23 19:37:11,551 Epoch[21] Batch [850]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.112236,	
2017-06-23 19:37:16,531 Epoch[21] Batch [860]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.112344,	
2017-06-23 19:37:21,732 Epoch[21] Batch [870]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.112248,	
2017-06-23 19:37:26,761 Epoch[21] Batch [880]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.112246,	
2017-06-23 19:37:31,982 Epoch[21] Batch [890]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112218,	
2017-06-23 19:37:37,172 Epoch[21] Batch [900]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.112368,	
2017-06-23 19:37:42,141 Epoch[21] Batch [910]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.112449,	
2017-06-23 19:37:47,191 Epoch[21] Batch [920]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.112343,	
2017-06-23 19:37:52,421 Epoch[21] Batch [930]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.112266,	
2017-06-23 19:37:57,465 Epoch[21] Batch [940]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.112176,	
2017-06-23 19:38:02,602 Epoch[21] Batch [950]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.112170,	
2017-06-23 19:38:07,895 Epoch[21] Batch [960]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.112118,	
2017-06-23 19:38:13,172 Epoch[21] Batch [970]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.112042,	
2017-06-23 19:38:18,180 Epoch[21] Batch [980]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.112009,	
2017-06-23 19:38:23,401 Epoch[21] Batch [990]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.112031,	
2017-06-23 19:38:28,366 Epoch[21] Batch [1000]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.112030,	
2017-06-23 19:38:33,360 Epoch[21] Batch [1010]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.111931,	
2017-06-23 19:38:38,673 Epoch[21] Batch [1020]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.112009,	
2017-06-23 19:38:43,828 Epoch[21] Batch [1030]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.112123,	
2017-06-23 19:38:48,770 Epoch[21] Batch [1040]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.112089,	
2017-06-23 19:38:53,860 Epoch[21] Batch [1050]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.111988,	
2017-06-23 19:38:58,916 Epoch[21] Batch [1060]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.112079,	
2017-06-23 19:39:03,914 Epoch[21] Batch [1070]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.111957,	
2017-06-23 19:39:08,820 Epoch[21] Batch [1080]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.111983,	
2017-06-23 19:39:13,865 Epoch[21] Batch [1090]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.111953,	
2017-06-23 19:39:18,962 Epoch[21] Batch [1100]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.111849,	
2017-06-23 19:39:24,083 Epoch[21] Batch [1110]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.111876,	
2017-06-23 19:39:29,186 Epoch[21] Batch [1120]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.111717,	
2017-06-23 19:39:34,145 Epoch[21] Batch [1130]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.111731,	
2017-06-23 19:39:39,232 Epoch[21] Batch [1140]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.111616,	
2017-06-23 19:39:44,449 Epoch[21] Batch [1150]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111586,	
2017-06-23 19:39:49,409 Epoch[21] Batch [1160]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.111610,	
2017-06-23 19:39:54,544 Epoch[21] Batch [1170]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.111619,	
2017-06-23 19:39:59,701 Epoch[21] Batch [1180]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.111734,	
2017-06-23 19:40:04,783 Epoch[21] Batch [1190]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.111753,	
2017-06-23 19:40:09,987 Epoch[21] Batch [1200]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.111800,	
2017-06-23 19:40:15,028 Epoch[21] Batch [1210]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.111852,	
2017-06-23 19:40:20,024 Epoch[21] Batch [1220]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.111977,	
2017-06-23 19:40:25,173 Epoch[21] Batch [1230]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.111947,	
2017-06-23 19:40:30,220 Epoch[21] Batch [1240]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.111952,	
2017-06-23 19:40:35,141 Epoch[21] Batch [1250]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.111884,	
2017-06-23 19:40:40,200 Epoch[21] Batch [1260]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.111809,	
2017-06-23 19:40:44,458 Epoch[21] Batch [1270]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.111812,	
2017-06-23 19:40:49,711 Epoch[21] Batch [1280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.111832,	
2017-06-23 19:40:54,924 Epoch[21] Batch [1290]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111861,	
2017-06-23 19:41:00,085 Epoch[21] Batch [1300]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.111716,	
2017-06-23 19:41:05,247 Epoch[21] Batch [1310]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.111617,	
2017-06-23 19:41:10,474 Epoch[21] Batch [1320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.111618,	
2017-06-23 19:41:15,601 Epoch[21] Batch [1330]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.111597,	
2017-06-23 19:41:20,775 Epoch[21] Batch [1340]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.111584,	
2017-06-23 19:41:25,999 Epoch[21] Batch [1350]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111606,	
2017-06-23 19:41:31,221 Epoch[21] Batch [1360]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111744,	
2017-06-23 19:41:36,368 Epoch[21] Batch [1370]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.111764,	
2017-06-23 19:41:41,605 Epoch[21] Batch [1380]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.111700,	
2017-06-23 19:41:46,755 Epoch[21] Batch [1390]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.111657,	
2017-06-23 19:41:51,961 Epoch[21] Batch [1400]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.111647,	
2017-06-23 19:41:57,186 Epoch[21] Batch [1410]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111654,	
2017-06-23 19:42:02,363 Epoch[21] Batch [1420]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.111574,	
2017-06-23 19:42:07,549 Epoch[21] Batch [1430]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.111518,	
2017-06-23 19:42:12,770 Epoch[21] Batch [1440]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.111553,	
2017-06-23 19:42:17,942 Epoch[21] Batch [1450]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.111472,	
2017-06-23 19:42:23,132 Epoch[21] Batch [1460]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.111495,	
2017-06-23 19:42:28,349 Epoch[21] Batch [1470]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.111408,	
2017-06-23 19:42:33,449 Epoch[21] Batch [1480]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.111347,	
2017-06-23 19:42:36,629 Epoch[21] Train-FCNLogLoss=0.111368
2017-06-23 19:42:36,630 Epoch[21] Time cost=760.275
2017-06-23 19:42:37,481 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0022.params"
2017-06-23 19:42:40,802 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0022.states"
2017-06-23 19:42:46,851 Epoch[22] Batch [10]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.111988,	
2017-06-23 19:42:52,024 Epoch[22] Batch [20]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.108586,	
2017-06-23 19:42:57,300 Epoch[22] Batch [30]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.110170,	
2017-06-23 19:43:02,455 Epoch[22] Batch [40]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.108465,	
2017-06-23 19:43:07,694 Epoch[22] Batch [50]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.113142,	
2017-06-23 19:43:12,924 Epoch[22] Batch [60]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.110060,	
2017-06-23 19:43:18,133 Epoch[22] Batch [70]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108934,	
2017-06-23 19:43:23,351 Epoch[22] Batch [80]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.107746,	
2017-06-23 19:43:28,548 Epoch[22] Batch [90]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.108415,	
2017-06-23 19:43:33,786 Epoch[22] Batch [100]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.107426,	
2017-06-23 19:43:39,043 Epoch[22] Batch [110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.107463,	
2017-06-23 19:43:44,238 Epoch[22] Batch [120]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.107798,	
2017-06-23 19:43:49,445 Epoch[22] Batch [130]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108424,	
2017-06-23 19:43:54,671 Epoch[22] Batch [140]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.108784,	
2017-06-23 19:43:59,864 Epoch[22] Batch [150]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.108759,	
2017-06-23 19:44:05,069 Epoch[22] Batch [160]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.107935,	
2017-06-23 19:44:10,252 Epoch[22] Batch [170]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.108083,	
2017-06-23 19:44:15,463 Epoch[22] Batch [180]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108272,	
2017-06-23 19:44:20,668 Epoch[22] Batch [190]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.108555,	
2017-06-23 19:44:25,859 Epoch[22] Batch [200]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.108794,	
2017-06-23 19:44:31,076 Epoch[22] Batch [210]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.108746,	
2017-06-23 19:44:36,299 Epoch[22] Batch [220]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.108526,	
2017-06-23 19:44:41,469 Epoch[22] Batch [230]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.108280,	
2017-06-23 19:44:46,663 Epoch[22] Batch [240]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.108530,	
2017-06-23 19:44:51,862 Epoch[22] Batch [250]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.108909,	
2017-06-23 19:44:57,075 Epoch[22] Batch [260]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.109434,	
2017-06-23 19:45:02,278 Epoch[22] Batch [270]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.109835,	
2017-06-23 19:45:07,445 Epoch[22] Batch [280]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.110248,	
2017-06-23 19:45:12,648 Epoch[22] Batch [290]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.110057,	
2017-06-23 19:45:17,856 Epoch[22] Batch [300]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.110287,	
2017-06-23 19:45:23,057 Epoch[22] Batch [310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.109880,	
2017-06-23 19:45:28,260 Epoch[22] Batch [320]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.109893,	
2017-06-23 19:45:33,479 Epoch[22] Batch [330]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.109695,	
2017-06-23 19:45:38,660 Epoch[22] Batch [340]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.109376,	
2017-06-23 19:45:43,907 Epoch[22] Batch [350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.109152,	
2017-06-23 19:45:49,118 Epoch[22] Batch [360]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.109282,	
2017-06-23 19:45:54,253 Epoch[22] Batch [370]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.109420,	
2017-06-23 19:45:59,434 Epoch[22] Batch [380]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.110342,	
2017-06-23 19:46:04,606 Epoch[22] Batch [390]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.110350,	
2017-06-23 19:46:09,838 Epoch[22] Batch [400]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.110015,	
2017-06-23 19:46:15,039 Epoch[22] Batch [410]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.109999,	
2017-06-23 19:46:20,241 Epoch[22] Batch [420]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.109837,	
2017-06-23 19:46:25,469 Epoch[22] Batch [430]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.109884,	
2017-06-23 19:46:30,709 Epoch[22] Batch [440]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.109677,	
2017-06-23 19:46:35,898 Epoch[22] Batch [450]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.109599,	
2017-06-23 19:46:41,103 Epoch[22] Batch [460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.109616,	
2017-06-23 19:46:46,302 Epoch[22] Batch [470]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.109583,	
2017-06-23 19:46:51,490 Epoch[22] Batch [480]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.109660,	
2017-06-23 19:46:56,663 Epoch[22] Batch [490]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.109482,	
2017-06-23 19:47:01,890 Epoch[22] Batch [500]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.109484,	
2017-06-23 19:47:07,140 Epoch[22] Batch [510]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.109530,	
2017-06-23 19:47:12,331 Epoch[22] Batch [520]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.109323,	
2017-06-23 19:47:17,542 Epoch[22] Batch [530]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.109191,	
2017-06-23 19:47:22,724 Epoch[22] Batch [540]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.108988,	
2017-06-23 19:47:27,933 Epoch[22] Batch [550]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108888,	
2017-06-23 19:47:33,213 Epoch[22] Batch [560]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.108846,	
2017-06-23 19:47:38,379 Epoch[22] Batch [570]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.108832,	
2017-06-23 19:47:43,545 Epoch[22] Batch [580]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.108837,	
2017-06-23 19:47:48,785 Epoch[22] Batch [590]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.108692,	
2017-06-23 19:47:54,057 Epoch[22] Batch [600]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.108801,	
2017-06-23 19:47:59,168 Epoch[22] Batch [610]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.108864,	
2017-06-23 19:48:04,380 Epoch[22] Batch [620]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.108692,	
2017-06-23 19:48:09,573 Epoch[22] Batch [630]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.108901,	
2017-06-23 19:48:14,785 Epoch[22] Batch [640]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.108870,	
2017-06-23 19:48:19,942 Epoch[22] Batch [650]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.108851,	
2017-06-23 19:48:25,204 Epoch[22] Batch [660]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.109125,	
2017-06-23 19:48:30,409 Epoch[22] Batch [670]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.109192,	
2017-06-23 19:48:35,611 Epoch[22] Batch [680]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.109147,	
2017-06-23 19:48:40,840 Epoch[22] Batch [690]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.108990,	
2017-06-23 19:48:45,989 Epoch[22] Batch [700]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.108949,	
2017-06-23 19:48:51,222 Epoch[22] Batch [710]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.108814,	
2017-06-23 19:48:56,434 Epoch[22] Batch [720]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108677,	
2017-06-23 19:49:01,670 Epoch[22] Batch [730]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.108794,	
2017-06-23 19:49:06,841 Epoch[22] Batch [740]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.108824,	
2017-06-23 19:49:12,045 Epoch[22] Batch [750]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.108821,	
2017-06-23 19:49:17,218 Epoch[22] Batch [760]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.108956,	
2017-06-23 19:49:22,408 Epoch[22] Batch [770]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.108958,	
2017-06-23 19:49:27,619 Epoch[22] Batch [780]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108900,	
2017-06-23 19:49:32,838 Epoch[22] Batch [790]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.108921,	
2017-06-23 19:49:38,083 Epoch[22] Batch [800]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.108813,	
2017-06-23 19:49:43,254 Epoch[22] Batch [810]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.108729,	
2017-06-23 19:49:48,445 Epoch[22] Batch [820]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.108544,	
2017-06-23 19:49:53,694 Epoch[22] Batch [830]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.108695,	
2017-06-23 19:49:58,857 Epoch[22] Batch [840]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.108735,	
2017-06-23 19:50:04,091 Epoch[22] Batch [850]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.108554,	
2017-06-23 19:50:09,375 Epoch[22] Batch [860]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.108556,	
2017-06-23 19:50:14,536 Epoch[22] Batch [870]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.108573,	
2017-06-23 19:50:19,742 Epoch[22] Batch [880]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108680,	
2017-06-23 19:50:25,019 Epoch[22] Batch [890]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.108709,	
2017-06-23 19:50:30,313 Epoch[22] Batch [900]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.108575,	
2017-06-23 19:50:35,484 Epoch[22] Batch [910]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.108560,	
2017-06-23 19:50:40,693 Epoch[22] Batch [920]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.108512,	
2017-06-23 19:50:45,914 Epoch[22] Batch [930]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.108479,	
2017-06-23 19:50:51,168 Epoch[22] Batch [940]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.108438,	
2017-06-23 19:50:56,339 Epoch[22] Batch [950]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.108288,	
2017-06-23 19:51:01,614 Epoch[22] Batch [960]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.108204,	
2017-06-23 19:51:06,879 Epoch[22] Batch [970]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.108055,	
2017-06-23 19:51:12,124 Epoch[22] Batch [980]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.108107,	
2017-06-23 19:51:17,362 Epoch[22] Batch [990]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.108166,	
2017-06-23 19:51:22,493 Epoch[22] Batch [1000]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.108133,	
2017-06-23 19:51:27,664 Epoch[22] Batch [1010]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.107990,	
2017-06-23 19:51:32,890 Epoch[22] Batch [1020]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.108042,	
2017-06-23 19:51:38,312 Epoch[22] Batch [1030]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.108108,	
2017-06-23 19:51:43,507 Epoch[22] Batch [1040]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.108009,	
2017-06-23 19:51:48,808 Epoch[22] Batch [1050]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.107948,	
2017-06-23 19:51:53,942 Epoch[22] Batch [1060]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.107970,	
2017-06-23 19:51:59,242 Epoch[22] Batch [1070]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.107989,	
2017-06-23 19:52:04,345 Epoch[22] Batch [1080]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.107931,	
2017-06-23 19:52:09,619 Epoch[22] Batch [1090]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.107885,	
2017-06-23 19:52:14,838 Epoch[22] Batch [1100]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.107819,	
2017-06-23 19:52:19,977 Epoch[22] Batch [1110]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.107824,	
2017-06-23 19:52:25,133 Epoch[22] Batch [1120]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.107699,	
2017-06-23 19:52:30,343 Epoch[22] Batch [1130]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.107632,	
2017-06-23 19:52:35,596 Epoch[22] Batch [1140]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.107591,	
2017-06-23 19:52:40,909 Epoch[22] Batch [1150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.107611,	
2017-06-23 19:52:46,609 Epoch[22] Batch [1160]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.107728,	
2017-06-23 19:52:52,279 Epoch[22] Batch [1170]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.107772,	
2017-06-23 19:52:57,736 Epoch[22] Batch [1180]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.107637,	
2017-06-23 19:53:03,137 Epoch[22] Batch [1190]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.107542,	
2017-06-23 19:53:08,956 Epoch[22] Batch [1200]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107523,	
2017-06-23 19:53:15,108 Epoch[22] Batch [1210]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.107467,	
2017-06-23 19:53:20,982 Epoch[22] Batch [1220]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.107458,	
2017-06-23 19:53:26,652 Epoch[22] Batch [1230]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.107477,	
2017-06-23 19:53:32,624 Epoch[22] Batch [1240]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.107358,	
2017-06-23 19:53:38,815 Epoch[22] Batch [1250]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.107390,	
2017-06-23 19:53:45,192 Epoch[22] Batch [1260]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.107330,	
2017-06-23 19:53:51,364 Epoch[22] Batch [1270]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.107304,	
2017-06-23 19:53:57,755 Epoch[22] Batch [1280]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.107371,	
2017-06-23 19:54:04,352 Epoch[22] Batch [1290]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.107311,	
2017-06-23 19:54:10,971 Epoch[22] Batch [1300]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.107329,	
2017-06-23 19:54:17,726 Epoch[22] Batch [1310]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.107382,	
2017-06-23 19:54:23,447 Epoch[22] Batch [1320]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.107388,	
2017-06-23 19:54:29,441 Epoch[22] Batch [1330]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.107339,	
2017-06-23 19:54:34,533 Epoch[22] Batch [1340]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.107307,	
2017-06-23 19:54:39,709 Epoch[22] Batch [1350]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.107323,	
2017-06-23 19:54:44,943 Epoch[22] Batch [1360]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.107541,	
2017-06-23 19:54:50,145 Epoch[22] Batch [1370]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.107553,	
2017-06-23 19:54:55,308 Epoch[22] Batch [1380]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.107587,	
2017-06-23 19:55:00,520 Epoch[22] Batch [1390]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.107649,	
2017-06-23 19:55:05,696 Epoch[22] Batch [1400]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.107701,	
2017-06-23 19:55:10,929 Epoch[22] Batch [1410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.107668,	
2017-06-23 19:55:16,180 Epoch[22] Batch [1420]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.107702,	
2017-06-23 19:55:21,298 Epoch[22] Batch [1430]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.107777,	
2017-06-23 19:55:26,531 Epoch[22] Batch [1440]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.107861,	
2017-06-23 19:55:31,725 Epoch[22] Batch [1450]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.107956,	
2017-06-23 19:55:36,932 Epoch[22] Batch [1460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.107956,	
2017-06-23 19:55:42,133 Epoch[22] Batch [1470]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.107968,	
2017-06-23 19:55:47,360 Epoch[22] Batch [1480]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.107957,	
2017-06-23 19:55:50,505 Epoch[22] Train-FCNLogLoss=0.107943
2017-06-23 19:55:50,506 Epoch[22] Time cost=789.703
2017-06-23 19:55:51,386 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0023.params"
2017-06-23 19:55:54,555 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0023.states"
2017-06-23 19:56:00,451 Epoch[23] Batch [10]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.095000,	
2017-06-23 19:56:05,558 Epoch[23] Batch [20]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.092615,	
2017-06-23 19:56:10,775 Epoch[23] Batch [30]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096718,	
2017-06-23 19:56:16,009 Epoch[23] Batch [40]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099730,	
2017-06-23 19:56:21,161 Epoch[23] Batch [50]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.104254,	
2017-06-23 19:56:26,341 Epoch[23] Batch [60]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.104419,	
2017-06-23 19:56:31,612 Epoch[23] Batch [70]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.106158,	
2017-06-23 19:56:36,879 Epoch[23] Batch [80]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.105936,	
2017-06-23 19:56:42,057 Epoch[23] Batch [90]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.104941,	
2017-06-23 19:56:47,216 Epoch[23] Batch [100]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.105154,	
2017-06-23 19:56:52,394 Epoch[23] Batch [110]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.104631,	
2017-06-23 19:56:57,623 Epoch[23] Batch [120]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.105012,	
2017-06-23 19:57:02,787 Epoch[23] Batch [130]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.104052,	
2017-06-23 19:57:07,972 Epoch[23] Batch [140]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.104222,	
2017-06-23 19:57:13,163 Epoch[23] Batch [150]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.104518,	
2017-06-23 19:57:18,369 Epoch[23] Batch [160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.104414,	
2017-06-23 19:57:23,558 Epoch[23] Batch [170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105393,	
2017-06-23 19:57:28,760 Epoch[23] Batch [180]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.106661,	
2017-06-23 19:57:33,933 Epoch[23] Batch [190]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.106488,	
2017-06-23 19:57:39,147 Epoch[23] Batch [200]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.106523,	
2017-06-23 19:57:44,302 Epoch[23] Batch [210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.107061,	
2017-06-23 19:57:49,521 Epoch[23] Batch [220]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.107115,	
2017-06-23 19:57:54,694 Epoch[23] Batch [230]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.107125,	
2017-06-23 19:57:59,914 Epoch[23] Batch [240]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.106964,	
2017-06-23 19:58:05,086 Epoch[23] Batch [250]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.106795,	
2017-06-23 19:58:10,305 Epoch[23] Batch [260]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.106518,	
2017-06-23 19:58:15,480 Epoch[23] Batch [270]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.106851,	
2017-06-23 19:58:20,629 Epoch[23] Batch [280]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.106620,	
2017-06-23 19:58:25,818 Epoch[23] Batch [290]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.106194,	
2017-06-23 19:58:31,043 Epoch[23] Batch [300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.106094,	
2017-06-23 19:58:36,213 Epoch[23] Batch [310]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.106086,	
2017-06-23 19:58:41,402 Epoch[23] Batch [320]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105909,	
2017-06-23 19:58:46,628 Epoch[23] Batch [330]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105850,	
2017-06-23 19:58:51,785 Epoch[23] Batch [340]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.105785,	
2017-06-23 19:58:56,995 Epoch[23] Batch [350]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105547,	
2017-06-23 19:59:02,180 Epoch[23] Batch [360]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105414,	
2017-06-23 19:59:07,363 Epoch[23] Batch [370]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105198,	
2017-06-23 19:59:12,580 Epoch[23] Batch [380]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.105024,	
2017-06-23 19:59:17,748 Epoch[23] Batch [390]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.105053,	
2017-06-23 19:59:22,974 Epoch[23] Batch [400]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.105095,	
2017-06-23 19:59:28,140 Epoch[23] Batch [410]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.105133,	
2017-06-23 19:59:33,352 Epoch[23] Batch [420]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105037,	
2017-06-23 19:59:38,532 Epoch[23] Batch [430]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.104863,	
2017-06-23 19:59:43,721 Epoch[23] Batch [440]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105295,	
2017-06-23 19:59:48,943 Epoch[23] Batch [450]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105722,	
2017-06-23 19:59:54,134 Epoch[23] Batch [460]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105606,	
2017-06-23 19:59:59,313 Epoch[23] Batch [470]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105791,	
2017-06-23 20:00:04,552 Epoch[23] Batch [480]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.105730,	
2017-06-23 20:00:09,709 Epoch[23] Batch [490]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.105672,	
2017-06-23 20:00:14,897 Epoch[23] Batch [500]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105812,	
2017-06-23 20:00:20,078 Epoch[23] Batch [510]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105886,	
2017-06-23 20:00:25,289 Epoch[23] Batch [520]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105651,	
2017-06-23 20:00:30,483 Epoch[23] Batch [530]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.105738,	
2017-06-23 20:00:35,690 Epoch[23] Batch [540]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.105813,	
2017-06-23 20:00:40,855 Epoch[23] Batch [550]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.105758,	
2017-06-23 20:00:46,059 Epoch[23] Batch [560]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.105730,	
2017-06-23 20:00:51,256 Epoch[23] Batch [570]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.105620,	
2017-06-23 20:00:56,452 Epoch[23] Batch [580]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.105617,	
2017-06-23 20:01:01,681 Epoch[23] Batch [590]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.105609,	
2017-06-23 20:01:06,865 Epoch[23] Batch [600]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105621,	
2017-06-23 20:01:12,089 Epoch[23] Batch [610]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105660,	
2017-06-23 20:01:17,313 Epoch[23] Batch [620]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105592,	
2017-06-23 20:01:22,482 Epoch[23] Batch [630]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.105671,	
2017-06-23 20:01:27,730 Epoch[23] Batch [640]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.105792,	
2017-06-23 20:01:32,903 Epoch[23] Batch [650]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.105924,	
2017-06-23 20:01:38,087 Epoch[23] Batch [660]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.105959,	
2017-06-23 20:01:43,316 Epoch[23] Batch [670]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.106199,	
2017-06-23 20:01:48,511 Epoch[23] Batch [680]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.105990,	
2017-06-23 20:01:53,731 Epoch[23] Batch [690]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.105860,	
2017-06-23 20:01:58,894 Epoch[23] Batch [700]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.105810,	
2017-06-23 20:02:04,261 Epoch[23] Batch [710]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.105917,	
2017-06-23 20:02:09,667 Epoch[23] Batch [720]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.105992,	
2017-06-23 20:02:15,037 Epoch[23] Batch [730]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.106006,	
2017-06-23 20:02:20,447 Epoch[23] Batch [740]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.105909,	
2017-06-23 20:02:25,810 Epoch[23] Batch [750]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.106029,	
2017-06-23 20:02:31,001 Epoch[23] Batch [760]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105929,	
2017-06-23 20:02:36,226 Epoch[23] Batch [770]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.106041,	
2017-06-23 20:02:41,481 Epoch[23] Batch [780]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.105862,	
2017-06-23 20:02:46,722 Epoch[23] Batch [790]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.105936,	
2017-06-23 20:02:52,024 Epoch[23] Batch [800]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.105906,	
2017-06-23 20:02:57,164 Epoch[23] Batch [810]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.105866,	
2017-06-23 20:03:02,403 Epoch[23] Batch [820]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.105754,	
2017-06-23 20:03:07,592 Epoch[23] Batch [830]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.105800,	
2017-06-23 20:03:12,865 Epoch[23] Batch [840]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.105931,	
2017-06-23 20:03:18,382 Epoch[23] Batch [850]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.105911,	
2017-06-23 20:03:24,315 Epoch[23] Batch [860]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106060,	
2017-06-23 20:03:30,300 Epoch[23] Batch [870]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106355,	
2017-06-23 20:03:36,046 Epoch[23] Batch [880]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.106342,	
2017-06-23 20:03:42,298 Epoch[23] Batch [890]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.106435,	
2017-06-23 20:03:48,320 Epoch[23] Batch [900]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.106297,	
2017-06-23 20:03:54,340 Epoch[23] Batch [910]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.106230,	
2017-06-23 20:04:00,612 Epoch[23] Batch [920]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.106232,	
2017-06-23 20:04:06,761 Epoch[23] Batch [930]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.106593,	
2017-06-23 20:04:13,070 Epoch[23] Batch [940]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.107115,	
2017-06-23 20:04:18,994 Epoch[23] Batch [950]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107298,	
2017-06-23 20:04:25,438 Epoch[23] Batch [960]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.107435,	
2017-06-23 20:04:32,129 Epoch[23] Batch [970]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.107506,	
2017-06-23 20:04:38,427 Epoch[23] Batch [980]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.107565,	
2017-06-23 20:04:44,831 Epoch[23] Batch [990]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.107556,	
2017-06-23 20:04:51,588 Epoch[23] Batch [1000]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.107869,	
2017-06-23 20:04:57,682 Epoch[23] Batch [1010]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107933,	
2017-06-23 20:05:03,774 Epoch[23] Batch [1020]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108142,	
2017-06-23 20:05:09,801 Epoch[23] Batch [1030]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.108228,	
2017-06-23 20:05:15,832 Epoch[23] Batch [1040]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.108347,	
2017-06-23 20:05:22,029 Epoch[23] Batch [1050]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.108327,	
2017-06-23 20:05:28,025 Epoch[23] Batch [1060]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.108358,	
2017-06-23 20:05:34,064 Epoch[23] Batch [1070]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108260,	
2017-06-23 20:05:39,962 Epoch[23] Batch [1080]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108284,	
2017-06-23 20:05:45,957 Epoch[23] Batch [1090]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.108264,	
2017-06-23 20:05:51,911 Epoch[23] Batch [1100]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.108273,	
2017-06-23 20:05:57,792 Epoch[23] Batch [1110]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.108337,	
2017-06-23 20:06:03,691 Epoch[23] Batch [1120]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108662,	
2017-06-23 20:06:09,634 Epoch[23] Batch [1130]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.108731,	
2017-06-23 20:06:15,345 Epoch[23] Batch [1140]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.108928,	
2017-06-23 20:06:21,114 Epoch[23] Batch [1150]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.108981,	
2017-06-23 20:06:26,941 Epoch[23] Batch [1160]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108949,	
2017-06-23 20:06:32,940 Epoch[23] Batch [1170]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.108881,	
2017-06-23 20:06:38,514 Epoch[23] Batch [1180]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.108913,	
2017-06-23 20:06:43,749 Epoch[23] Batch [1190]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.108865,	
2017-06-23 20:06:50,755 Epoch[23] Batch [1200]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.108847,	
2017-06-23 20:06:56,603 Epoch[23] Batch [1210]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.108943,	
2017-06-23 20:07:02,431 Epoch[23] Batch [1220]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108888,	
2017-06-23 20:07:08,278 Epoch[23] Batch [1230]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.108881,	
2017-06-23 20:07:14,183 Epoch[23] Batch [1240]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.108857,	
2017-06-23 20:07:19,995 Epoch[23] Batch [1250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.108879,	
2017-06-23 20:07:25,833 Epoch[23] Batch [1260]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.108894,	
2017-06-23 20:07:31,406 Epoch[23] Batch [1270]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.108934,	
2017-06-23 20:07:37,417 Epoch[23] Batch [1280]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.108879,	
2017-06-23 20:07:44,077 Epoch[23] Batch [1290]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.108824,	
2017-06-23 20:07:49,818 Epoch[23] Batch [1300]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.108884,	
2017-06-23 20:07:57,022 Epoch[23] Batch [1310]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.108768,	
2017-06-23 20:08:04,047 Epoch[23] Batch [1320]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.108705,	
2017-06-23 20:08:10,661 Epoch[23] Batch [1330]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.108721,	
2017-06-23 20:08:17,087 Epoch[23] Batch [1340]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.108723,	
2017-06-23 20:08:23,384 Epoch[23] Batch [1350]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.108750,	
2017-06-23 20:08:29,534 Epoch[23] Batch [1360]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.108838,	
2017-06-23 20:08:35,923 Epoch[23] Batch [1370]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.108734,	
2017-06-23 20:08:41,930 Epoch[23] Batch [1380]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.108811,	
2017-06-23 20:08:48,459 Epoch[23] Batch [1390]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.108868,	
2017-06-23 20:08:55,046 Epoch[23] Batch [1400]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.108843,	
2017-06-23 20:09:01,703 Epoch[23] Batch [1410]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.108857,	
2017-06-23 20:09:07,599 Epoch[23] Batch [1420]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108871,	
2017-06-23 20:09:13,697 Epoch[23] Batch [1430]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.108930,	
2017-06-23 20:09:19,594 Epoch[23] Batch [1440]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.109008,	
2017-06-23 20:09:25,487 Epoch[23] Batch [1450]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.109026,	
2017-06-23 20:09:31,462 Epoch[23] Batch [1460]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.109006,	
2017-06-23 20:09:37,402 Epoch[23] Batch [1470]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109058,	
2017-06-23 20:09:43,549 Epoch[23] Batch [1480]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.109177,	
2017-06-23 20:09:47,127 Epoch[23] Train-FCNLogLoss=0.109209
2017-06-23 20:09:47,127 Epoch[23] Time cost=832.572
2017-06-23 20:09:48,325 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0024.params"
2017-06-23 20:09:51,960 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0024.states"
2017-06-23 20:09:59,553 Epoch[24] Batch [10]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.105667,	
2017-06-23 20:10:06,100 Epoch[24] Batch [20]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.108086,	
2017-06-23 20:10:12,720 Epoch[24] Batch [30]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.105126,	
2017-06-23 20:10:19,377 Epoch[24] Batch [40]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.107904,	
2017-06-23 20:10:26,641 Epoch[24] Batch [50]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.106374,	
2017-06-23 20:10:33,750 Epoch[24] Batch [60]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.106840,	
2017-06-23 20:10:40,198 Epoch[24] Batch [70]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.108551,	
2017-06-23 20:10:47,187 Epoch[24] Batch [80]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.108254,	
2017-06-23 20:10:54,138 Epoch[24] Batch [90]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.109517,	
2017-06-23 20:11:01,193 Epoch[24] Batch [100]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.108701,	
2017-06-23 20:11:07,812 Epoch[24] Batch [110]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.108698,	
2017-06-23 20:11:14,955 Epoch[24] Batch [120]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.108294,	
2017-06-23 20:11:21,552 Epoch[24] Batch [130]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.107972,	
2017-06-23 20:11:28,590 Epoch[24] Batch [140]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.108788,	
2017-06-23 20:11:35,631 Epoch[24] Batch [150]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.108469,	
2017-06-23 20:11:42,638 Epoch[24] Batch [160]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.108232,	
2017-06-23 20:11:49,789 Epoch[24] Batch [170]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.107803,	
2017-06-23 20:11:57,259 Epoch[24] Batch [180]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.107048,	
2017-06-23 20:12:04,034 Epoch[24] Batch [190]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.107727,	
2017-06-23 20:12:10,900 Epoch[24] Batch [200]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.107357,	
2017-06-23 20:12:17,471 Epoch[24] Batch [210]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.107836,	
2017-06-23 20:12:23,735 Epoch[24] Batch [220]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.108169,	
2017-06-23 20:12:29,887 Epoch[24] Batch [230]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.108452,	
2017-06-23 20:12:36,819 Epoch[24] Batch [240]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.108105,	
2017-06-23 20:12:43,432 Epoch[24] Batch [250]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.108354,	
2017-06-23 20:12:50,914 Epoch[24] Batch [260]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.108871,	
2017-06-23 20:12:57,897 Epoch[24] Batch [270]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.108928,	
2017-06-23 20:13:04,477 Epoch[24] Batch [280]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.109070,	
2017-06-23 20:13:11,130 Epoch[24] Batch [290]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.109475,	
2017-06-23 20:13:17,260 Epoch[24] Batch [300]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.109906,	
2017-06-23 20:13:23,891 Epoch[24] Batch [310]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.109858,	
2017-06-23 20:13:30,251 Epoch[24] Batch [320]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.109939,	
2017-06-23 20:13:37,273 Epoch[24] Batch [330]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.109975,	
2017-06-23 20:13:43,513 Epoch[24] Batch [340]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.110236,	
2017-06-23 20:13:50,133 Epoch[24] Batch [350]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.110250,	
2017-06-23 20:13:57,010 Epoch[24] Batch [360]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.110049,	
2017-06-23 20:14:03,886 Epoch[24] Batch [370]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.110128,	
2017-06-23 20:14:10,069 Epoch[24] Batch [380]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.109889,	
2017-06-23 20:14:17,049 Epoch[24] Batch [390]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.109502,	
2017-06-23 20:14:24,473 Epoch[24] Batch [400]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.109604,	
2017-06-23 20:14:31,835 Epoch[24] Batch [410]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.109435,	
2017-06-23 20:14:38,723 Epoch[24] Batch [420]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.109317,	
2017-06-23 20:14:45,761 Epoch[24] Batch [430]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.109295,	
2017-06-23 20:14:53,232 Epoch[24] Batch [440]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.109171,	
2017-06-23 20:15:00,478 Epoch[24] Batch [450]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.109087,	
2017-06-23 20:15:08,354 Epoch[24] Batch [460]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.109156,	
2017-06-23 20:15:15,277 Epoch[24] Batch [470]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.109252,	
2017-06-23 20:15:22,473 Epoch[24] Batch [480]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.109072,	
2017-06-23 20:15:29,787 Epoch[24] Batch [490]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.109296,	
2017-06-23 20:15:37,339 Epoch[24] Batch [500]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.109376,	
2017-06-23 20:15:44,609 Epoch[24] Batch [510]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.109390,	
2017-06-23 20:15:51,939 Epoch[24] Batch [520]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.109374,	
2017-06-23 20:15:59,557 Epoch[24] Batch [530]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.109332,	
2017-06-23 20:16:07,232 Epoch[24] Batch [540]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.109489,	
2017-06-23 20:16:14,341 Epoch[24] Batch [550]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.109457,	
2017-06-23 20:16:21,148 Epoch[24] Batch [560]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.109288,	
2017-06-23 20:16:28,335 Epoch[24] Batch [570]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.109563,	
2017-06-23 20:16:35,445 Epoch[24] Batch [580]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.109500,	
2017-06-23 20:16:42,335 Epoch[24] Batch [590]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.109558,	
2017-06-23 20:16:49,312 Epoch[24] Batch [600]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.109618,	
2017-06-23 20:16:55,762 Epoch[24] Batch [610]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.109607,	
2017-06-23 20:17:01,968 Epoch[24] Batch [620]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.109711,	
2017-06-23 20:17:08,461 Epoch[24] Batch [630]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.109836,	
2017-06-23 20:17:14,571 Epoch[24] Batch [640]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.109693,	
2017-06-23 20:17:20,999 Epoch[24] Batch [650]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.109629,	
2017-06-23 20:17:26,889 Epoch[24] Batch [660]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.109488,	
2017-06-23 20:17:32,938 Epoch[24] Batch [670]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109397,	
2017-06-23 20:17:38,909 Epoch[24] Batch [680]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.109424,	
2017-06-23 20:17:44,892 Epoch[24] Batch [690]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.109433,	
2017-06-23 20:17:50,706 Epoch[24] Batch [700]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.109406,	
2017-06-23 20:17:56,663 Epoch[24] Batch [710]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.109418,	
2017-06-23 20:18:02,997 Epoch[24] Batch [720]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.109507,	
2017-06-23 20:18:09,029 Epoch[24] Batch [730]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.109601,	
2017-06-23 20:18:15,032 Epoch[24] Batch [740]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.109775,	
2017-06-23 20:18:21,212 Epoch[24] Batch [750]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.109720,	
2017-06-23 20:18:27,248 Epoch[24] Batch [760]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.109683,	
2017-06-23 20:18:33,319 Epoch[24] Batch [770]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109633,	
2017-06-23 20:18:39,366 Epoch[24] Batch [780]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109816,	
2017-06-23 20:18:45,477 Epoch[24] Batch [790]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.109885,	
2017-06-23 20:18:51,708 Epoch[24] Batch [800]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.109976,	
2017-06-23 20:18:57,980 Epoch[24] Batch [810]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.110066,	
2017-06-23 20:19:04,303 Epoch[24] Batch [820]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.110063,	
2017-06-23 20:19:09,936 Epoch[24] Batch [830]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.110043,	
2017-06-23 20:19:16,181 Epoch[24] Batch [840]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.109962,	
2017-06-23 20:19:22,140 Epoch[24] Batch [850]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.109981,	
2017-06-23 20:19:28,736 Epoch[24] Batch [860]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.109841,	
2017-06-23 20:19:35,219 Epoch[24] Batch [870]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.109850,	
2017-06-23 20:19:41,613 Epoch[24] Batch [880]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.109884,	
2017-06-23 20:19:47,669 Epoch[24] Batch [890]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109879,	
2017-06-23 20:19:53,625 Epoch[24] Batch [900]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.109829,	
2017-06-23 20:19:59,527 Epoch[24] Batch [910]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.109742,	
2017-06-23 20:20:05,548 Epoch[24] Batch [920]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.109647,	
2017-06-23 20:20:11,452 Epoch[24] Batch [930]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.109699,	
2017-06-23 20:20:17,448 Epoch[24] Batch [940]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.109609,	
2017-06-23 20:20:23,368 Epoch[24] Batch [950]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.109529,	
2017-06-23 20:20:29,375 Epoch[24] Batch [960]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.109559,	
2017-06-23 20:20:35,332 Epoch[24] Batch [970]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.109563,	
2017-06-23 20:20:41,261 Epoch[24] Batch [980]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.109549,	
2017-06-23 20:20:47,218 Epoch[24] Batch [990]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.109475,	
2017-06-23 20:20:53,217 Epoch[24] Batch [1000]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.109462,	
2017-06-23 20:20:59,071 Epoch[24] Batch [1010]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.109412,	
2017-06-23 20:21:05,352 Epoch[24] Batch [1020]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.109455,	
2017-06-23 20:21:11,509 Epoch[24] Batch [1030]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.109608,	
2017-06-23 20:21:17,421 Epoch[24] Batch [1040]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.109779,	
2017-06-23 20:21:23,347 Epoch[24] Batch [1050]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.109982,	
2017-06-23 20:21:29,294 Epoch[24] Batch [1060]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.110043,	
2017-06-23 20:21:35,218 Epoch[24] Batch [1070]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.110010,	
2017-06-23 20:21:41,167 Epoch[24] Batch [1080]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.110144,	
2017-06-23 20:21:47,120 Epoch[24] Batch [1090]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.110171,	
2017-06-23 20:21:53,086 Epoch[24] Batch [1100]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.110218,	
2017-06-23 20:21:59,026 Epoch[24] Batch [1110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.110398,	
2017-06-23 20:22:04,930 Epoch[24] Batch [1120]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.110319,	
2017-06-23 20:22:10,826 Epoch[24] Batch [1130]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.110451,	
2017-06-23 20:22:16,802 Epoch[24] Batch [1140]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.110529,	
2017-06-23 20:22:22,849 Epoch[24] Batch [1150]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.110411,	
2017-06-23 20:22:28,829 Epoch[24] Batch [1160]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.110628,	
2017-06-23 20:22:34,793 Epoch[24] Batch [1170]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.110560,	
2017-06-23 20:22:40,761 Epoch[24] Batch [1180]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.110595,	
2017-06-23 20:22:46,728 Epoch[24] Batch [1190]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.110607,	
2017-06-23 20:22:52,600 Epoch[24] Batch [1200]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.110540,	
2017-06-23 20:22:58,587 Epoch[24] Batch [1210]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.110611,	
2017-06-23 20:23:04,504 Epoch[24] Batch [1220]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.110507,	
2017-06-23 20:23:10,505 Epoch[24] Batch [1230]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.110515,	
2017-06-23 20:23:16,758 Epoch[24] Batch [1240]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.110522,	
2017-06-23 20:23:22,742 Epoch[24] Batch [1250]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.110598,	
2017-06-23 20:23:28,351 Epoch[24] Batch [1260]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.110599,	
2017-06-23 20:23:34,793 Epoch[24] Batch [1270]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.110721,	
2017-06-23 20:23:40,802 Epoch[24] Batch [1280]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.110732,	
2017-06-23 20:23:47,151 Epoch[24] Batch [1290]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.110758,	
2017-06-23 20:23:53,428 Epoch[24] Batch [1300]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.110816,	
2017-06-23 20:23:59,472 Epoch[24] Batch [1310]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.110817,	
2017-06-23 20:24:05,475 Epoch[24] Batch [1320]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.110918,	
2017-06-23 20:24:11,650 Epoch[24] Batch [1330]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.110871,	
2017-06-23 20:24:17,773 Epoch[24] Batch [1340]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.111006,	
2017-06-23 20:24:23,677 Epoch[24] Batch [1350]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.111240,	
2017-06-23 20:24:29,890 Epoch[24] Batch [1360]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.111345,	
2017-06-23 20:24:35,814 Epoch[24] Batch [1370]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.111475,	
2017-06-23 20:24:42,117 Epoch[24] Batch [1380]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.111546,	
2017-06-23 20:24:48,514 Epoch[24] Batch [1390]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.111587,	
2017-06-23 20:24:54,647 Epoch[24] Batch [1400]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.111661,	
2017-06-23 20:25:00,557 Epoch[24] Batch [1410]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.111562,	
2017-06-23 20:25:06,739 Epoch[24] Batch [1420]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.111492,	
2017-06-23 20:25:13,230 Epoch[24] Batch [1430]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.111560,	
2017-06-23 20:25:19,479 Epoch[24] Batch [1440]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.111603,	
2017-06-23 20:25:25,462 Epoch[24] Batch [1450]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.111609,	
2017-06-23 20:25:31,796 Epoch[24] Batch [1460]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.111744,	
2017-06-23 20:25:37,761 Epoch[24] Batch [1470]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.111825,	
2017-06-23 20:25:44,126 Epoch[24] Batch [1480]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.111830,	
2017-06-23 20:25:47,695 Epoch[24] Train-FCNLogLoss=0.111850
2017-06-23 20:25:47,695 Epoch[24] Time cost=955.735
2017-06-23 20:25:48,718 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0025.params"
2017-06-23 20:25:52,369 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0025.states"
2017-06-23 20:25:59,314 Epoch[25] Batch [10]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.124499,	
2017-06-23 20:26:05,615 Epoch[25] Batch [20]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.118606,	
2017-06-23 20:26:12,052 Epoch[25] Batch [30]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.117072,	
2017-06-23 20:26:18,417 Epoch[25] Batch [40]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.118342,	
2017-06-23 20:26:24,565 Epoch[25] Batch [50]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.115902,	
2017-06-23 20:26:30,798 Epoch[25] Batch [60]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.114573,	
2017-06-23 20:26:36,799 Epoch[25] Batch [70]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.112095,	
2017-06-23 20:26:42,811 Epoch[25] Batch [80]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.111212,	
2017-06-23 20:26:48,869 Epoch[25] Batch [90]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.109378,	
2017-06-23 20:26:54,743 Epoch[25] Batch [100]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.108995,	
2017-06-23 20:27:00,986 Epoch[25] Batch [110]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.108793,	
2017-06-23 20:27:07,002 Epoch[25] Batch [120]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.109035,	
2017-06-23 20:27:12,919 Epoch[25] Batch [130]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.109158,	
2017-06-23 20:27:18,962 Epoch[25] Batch [140]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108196,	
2017-06-23 20:27:24,865 Epoch[25] Batch [150]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.107766,	
2017-06-23 20:27:30,811 Epoch[25] Batch [160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106872,	
2017-06-23 20:27:36,785 Epoch[25] Batch [170]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.107044,	
2017-06-23 20:27:42,681 Epoch[25] Batch [180]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.107574,	
2017-06-23 20:27:48,635 Epoch[25] Batch [190]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.107166,	
2017-06-23 20:27:54,720 Epoch[25] Batch [200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107024,	
2017-06-23 20:28:00,588 Epoch[25] Batch [210]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.107334,	
2017-06-23 20:28:06,540 Epoch[25] Batch [220]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106620,	
2017-06-23 20:28:12,575 Epoch[25] Batch [230]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.106697,	
2017-06-23 20:28:18,458 Epoch[25] Batch [240]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.107016,	
2017-06-23 20:28:24,472 Epoch[25] Batch [250]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107106,	
2017-06-23 20:28:30,403 Epoch[25] Batch [260]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107044,	
2017-06-23 20:28:36,549 Epoch[25] Batch [270]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.106741,	
2017-06-23 20:28:42,982 Epoch[25] Batch [280]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.106682,	
2017-06-23 20:28:48,876 Epoch[25] Batch [290]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106536,	
2017-06-23 20:28:54,820 Epoch[25] Batch [300]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106563,	
2017-06-23 20:29:00,793 Epoch[25] Batch [310]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.106321,	
2017-06-23 20:29:06,743 Epoch[25] Batch [320]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105903,	
2017-06-23 20:29:12,711 Epoch[25] Batch [330]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105503,	
2017-06-23 20:29:18,665 Epoch[25] Batch [340]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105565,	
2017-06-23 20:29:24,570 Epoch[25] Batch [350]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.105591,	
2017-06-23 20:29:30,538 Epoch[25] Batch [360]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105614,	
2017-06-23 20:29:36,595 Epoch[25] Batch [370]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.106062,	
2017-06-23 20:29:42,491 Epoch[25] Batch [380]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106013,	
2017-06-23 20:29:48,485 Epoch[25] Batch [390]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.106211,	
2017-06-23 20:29:54,393 Epoch[25] Batch [400]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.106385,	
2017-06-23 20:30:00,356 Epoch[25] Batch [410]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106095,	
2017-06-23 20:30:06,306 Epoch[25] Batch [420]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105886,	
2017-06-23 20:30:12,302 Epoch[25] Batch [430]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.105794,	
2017-06-23 20:30:18,250 Epoch[25] Batch [440]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105939,	
2017-06-23 20:30:24,227 Epoch[25] Batch [450]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.106404,	
2017-06-23 20:30:30,184 Epoch[25] Batch [460]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106469,	
2017-06-23 20:30:36,101 Epoch[25] Batch [470]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.106524,	
2017-06-23 20:30:42,090 Epoch[25] Batch [480]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106616,	
2017-06-23 20:30:47,980 Epoch[25] Batch [490]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106695,	
2017-06-23 20:30:53,940 Epoch[25] Batch [500]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106886,	
2017-06-23 20:30:59,932 Epoch[25] Batch [510]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106736,	
2017-06-23 20:31:05,840 Epoch[25] Batch [520]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.106816,	
2017-06-23 20:31:11,813 Epoch[25] Batch [530]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.106897,	
2017-06-23 20:31:17,768 Epoch[25] Batch [540]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106623,	
2017-06-23 20:31:23,755 Epoch[25] Batch [550]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106501,	
2017-06-23 20:31:29,652 Epoch[25] Batch [560]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106078,	
2017-06-23 20:31:35,660 Epoch[25] Batch [570]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.105973,	
2017-06-23 20:31:41,550 Epoch[25] Batch [580]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.105937,	
2017-06-23 20:31:47,507 Epoch[25] Batch [590]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105787,	
2017-06-23 20:31:53,468 Epoch[25] Batch [600]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105749,	
2017-06-23 20:31:59,352 Epoch[25] Batch [610]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.105951,	
2017-06-23 20:32:05,349 Epoch[25] Batch [620]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.105847,	
2017-06-23 20:32:11,243 Epoch[25] Batch [630]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106042,	
2017-06-23 20:32:17,219 Epoch[25] Batch [640]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.106053,	
2017-06-23 20:32:23,182 Epoch[25] Batch [650]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105901,	
2017-06-23 20:32:29,070 Epoch[25] Batch [660]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.105884,	
2017-06-23 20:32:34,912 Epoch[25] Batch [670]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105732,	
2017-06-23 20:32:40,931 Epoch[25] Batch [680]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.105726,	
2017-06-23 20:32:46,954 Epoch[25] Batch [690]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.105732,	
2017-06-23 20:32:52,773 Epoch[25] Batch [700]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105677,	
2017-06-23 20:32:58,721 Epoch[25] Batch [710]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105586,	
2017-06-23 20:33:04,639 Epoch[25] Batch [720]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.105640,	
2017-06-23 20:33:10,583 Epoch[25] Batch [730]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105500,	
2017-06-23 20:33:16,512 Epoch[25] Batch [740]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105346,	
2017-06-23 20:33:22,485 Epoch[25] Batch [750]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105306,	
2017-06-23 20:33:28,412 Epoch[25] Batch [760]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105541,	
2017-06-23 20:33:34,379 Epoch[25] Batch [770]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105678,	
2017-06-23 20:33:40,319 Epoch[25] Batch [780]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105623,	
2017-06-23 20:33:46,278 Epoch[25] Batch [790]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105584,	
2017-06-23 20:33:52,212 Epoch[25] Batch [800]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105610,	
2017-06-23 20:33:58,122 Epoch[25] Batch [810]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.105669,	
2017-06-23 20:34:04,038 Epoch[25] Batch [820]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.105604,	
2017-06-23 20:34:10,014 Epoch[25] Batch [830]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.105684,	
2017-06-23 20:34:15,976 Epoch[25] Batch [840]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105686,	
2017-06-23 20:34:21,898 Epoch[25] Batch [850]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.105641,	
2017-06-23 20:34:27,840 Epoch[25] Batch [860]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105836,	
2017-06-23 20:34:33,811 Epoch[25] Batch [870]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105827,	
2017-06-23 20:34:39,767 Epoch[25] Batch [880]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105892,	
2017-06-23 20:34:45,702 Epoch[25] Batch [890]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105819,	
2017-06-23 20:34:51,652 Epoch[25] Batch [900]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105871,	
2017-06-23 20:34:57,672 Epoch[25] Batch [910]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.105725,	
2017-06-23 20:35:03,575 Epoch[25] Batch [920]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.105642,	
2017-06-23 20:35:09,522 Epoch[25] Batch [930]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105628,	
2017-06-23 20:35:15,423 Epoch[25] Batch [940]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.105616,	
2017-06-23 20:35:21,343 Epoch[25] Batch [950]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.105527,	
2017-06-23 20:35:27,342 Epoch[25] Batch [960]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.105396,	
2017-06-23 20:35:33,264 Epoch[25] Batch [970]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105365,	
2017-06-23 20:35:39,173 Epoch[25] Batch [980]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.105283,	
2017-06-23 20:35:45,170 Epoch[25] Batch [990]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.105328,	
2017-06-23 20:35:51,074 Epoch[25] Batch [1000]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.105242,	
2017-06-23 20:35:57,052 Epoch[25] Batch [1010]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.105249,	
2017-06-23 20:36:02,978 Epoch[25] Batch [1020]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105234,	
2017-06-23 20:36:08,944 Epoch[25] Batch [1030]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105227,	
2017-06-23 20:36:14,870 Epoch[25] Batch [1040]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105160,	
2017-06-23 20:36:20,791 Epoch[25] Batch [1050]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.105169,	
2017-06-23 20:36:26,759 Epoch[25] Batch [1060]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105182,	
2017-06-23 20:36:32,746 Epoch[25] Batch [1070]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.105033,	
2017-06-23 20:36:38,598 Epoch[25] Batch [1080]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105103,	
2017-06-23 20:36:44,417 Epoch[25] Batch [1090]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105153,	
2017-06-23 20:36:50,361 Epoch[25] Batch [1100]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105181,	
2017-06-23 20:36:56,368 Epoch[25] Batch [1110]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.105115,	
2017-06-23 20:37:02,160 Epoch[25] Batch [1120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105122,	
2017-06-23 20:37:08,115 Epoch[25] Batch [1130]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105085,	
2017-06-23 20:37:14,001 Epoch[25] Batch [1140]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.105079,	
2017-06-23 20:37:19,954 Epoch[25] Batch [1150]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105061,	
2017-06-23 20:37:25,901 Epoch[25] Batch [1160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105033,	
2017-06-23 20:37:31,834 Epoch[25] Batch [1170]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.104906,	
2017-06-23 20:37:37,764 Epoch[25] Batch [1180]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.104809,	
2017-06-23 20:37:43,710 Epoch[25] Batch [1190]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.104783,	
2017-06-23 20:37:49,634 Epoch[25] Batch [1200]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.104724,	
2017-06-23 20:37:55,578 Epoch[25] Batch [1210]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.104615,	
2017-06-23 20:38:01,551 Epoch[25] Batch [1220]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.104628,	
2017-06-23 20:38:07,476 Epoch[25] Batch [1230]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.104524,	
2017-06-23 20:38:13,216 Epoch[25] Batch [1240]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.104472,	
2017-06-23 20:38:19,840 Epoch[25] Batch [1250]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.104472,	
2017-06-23 20:38:25,809 Epoch[25] Batch [1260]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.104507,	
2017-06-23 20:38:31,827 Epoch[25] Batch [1270]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.104533,	
2017-06-23 20:38:37,665 Epoch[25] Batch [1280]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.104475,	
2017-06-23 20:38:43,646 Epoch[25] Batch [1290]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.104630,	
2017-06-23 20:38:49,564 Epoch[25] Batch [1300]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.104614,	
2017-06-23 20:38:55,485 Epoch[25] Batch [1310]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.104599,	
2017-06-23 20:39:01,548 Epoch[25] Batch [1320]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104584,	
2017-06-23 20:39:07,458 Epoch[25] Batch [1330]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104627,	
2017-06-23 20:39:13,405 Epoch[25] Batch [1340]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.104582,	
2017-06-23 20:39:19,530 Epoch[25] Batch [1350]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.104571,	
2017-06-23 20:39:25,505 Epoch[25] Batch [1360]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.104648,	
2017-06-23 20:39:31,759 Epoch[25] Batch [1370]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.104626,	
2017-06-23 20:39:37,797 Epoch[25] Batch [1380]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.104604,	
2017-06-23 20:39:43,819 Epoch[25] Batch [1390]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.104598,	
2017-06-23 20:39:50,020 Epoch[25] Batch [1400]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.104795,	
2017-06-23 20:39:56,006 Epoch[25] Batch [1410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.104824,	
2017-06-23 20:40:01,957 Epoch[25] Batch [1420]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104835,	
2017-06-23 20:40:07,866 Epoch[25] Batch [1430]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104857,	
2017-06-23 20:40:13,903 Epoch[25] Batch [1440]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.104890,	
2017-06-23 20:40:20,099 Epoch[25] Batch [1450]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.104870,	
2017-06-23 20:40:26,272 Epoch[25] Batch [1460]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.104886,	
2017-06-23 20:40:32,240 Epoch[25] Batch [1470]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105163,	
2017-06-23 20:40:38,641 Epoch[25] Batch [1480]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.105240,	
2017-06-23 20:40:42,440 Epoch[25] Train-FCNLogLoss=0.105298
2017-06-23 20:40:42,441 Epoch[25] Time cost=890.071
2017-06-23 20:40:43,194 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0026.params"
2017-06-23 20:40:46,856 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0026.states"
2017-06-23 20:40:53,688 Epoch[26] Batch [10]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.094862,	
2017-06-23 20:40:59,604 Epoch[26] Batch [20]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.100624,	
2017-06-23 20:41:05,452 Epoch[26] Batch [30]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.103275,	
2017-06-23 20:41:11,543 Epoch[26] Batch [40]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.104058,	
2017-06-23 20:41:17,452 Epoch[26] Batch [50]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104474,	
2017-06-23 20:41:23,346 Epoch[26] Batch [60]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106723,	
2017-06-23 20:41:29,428 Epoch[26] Batch [70]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107178,	
2017-06-23 20:41:35,248 Epoch[26] Batch [80]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107957,	
2017-06-23 20:41:41,177 Epoch[26] Batch [90]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106969,	
2017-06-23 20:41:47,194 Epoch[26] Batch [100]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.106682,	
2017-06-23 20:41:53,296 Epoch[26] Batch [110]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107541,	
2017-06-23 20:41:59,566 Epoch[26] Batch [120]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.107833,	
2017-06-23 20:42:05,486 Epoch[26] Batch [130]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107115,	
2017-06-23 20:42:11,701 Epoch[26] Batch [140]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.107107,	
2017-06-23 20:42:17,997 Epoch[26] Batch [150]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.106943,	
2017-06-23 20:42:24,081 Epoch[26] Batch [160]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107123,	
2017-06-23 20:42:29,984 Epoch[26] Batch [170]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.107066,	
2017-06-23 20:42:35,863 Epoch[26] Batch [180]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.107358,	
2017-06-23 20:42:41,791 Epoch[26] Batch [190]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107039,	
2017-06-23 20:42:47,720 Epoch[26] Batch [200]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107003,	
2017-06-23 20:42:53,642 Epoch[26] Batch [210]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107205,	
2017-06-23 20:42:59,623 Epoch[26] Batch [220]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.108083,	
2017-06-23 20:43:05,537 Epoch[26] Batch [230]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.108451,	
2017-06-23 20:43:11,486 Epoch[26] Batch [240]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.108305,	
2017-06-23 20:43:17,419 Epoch[26] Batch [250]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108292,	
2017-06-23 20:43:23,381 Epoch[26] Batch [260]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.107929,	
2017-06-23 20:43:29,312 Epoch[26] Batch [270]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.107418,	
2017-06-23 20:43:35,379 Epoch[26] Batch [280]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107401,	
2017-06-23 20:43:41,324 Epoch[26] Batch [290]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.107424,	
2017-06-23 20:43:47,310 Epoch[26] Batch [300]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.107274,	
2017-06-23 20:43:53,162 Epoch[26] Batch [310]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107775,	
2017-06-23 20:43:59,113 Epoch[26] Batch [320]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.107856,	
2017-06-23 20:44:05,065 Epoch[26] Batch [330]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.107678,	
2017-06-23 20:44:10,984 Epoch[26] Batch [340]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107543,	
2017-06-23 20:44:16,936 Epoch[26] Batch [350]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.107199,	
2017-06-23 20:44:22,791 Epoch[26] Batch [360]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.106840,	
2017-06-23 20:44:29,011 Epoch[26] Batch [370]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.106791,	
2017-06-23 20:44:35,151 Epoch[26] Batch [380]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.106464,	
2017-06-23 20:44:40,961 Epoch[26] Batch [390]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.106448,	
2017-06-23 20:44:46,884 Epoch[26] Batch [400]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106124,	
2017-06-23 20:44:52,840 Epoch[26] Batch [410]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106249,	
2017-06-23 20:44:58,809 Epoch[26] Batch [420]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.106451,	
2017-06-23 20:45:04,738 Epoch[26] Batch [430]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106480,	
2017-06-23 20:45:10,699 Epoch[26] Batch [440]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106427,	
2017-06-23 20:45:16,636 Epoch[26] Batch [450]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106424,	
2017-06-23 20:45:22,558 Epoch[26] Batch [460]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106342,	
2017-06-23 20:45:28,497 Epoch[26] Batch [470]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106421,	
2017-06-23 20:45:34,453 Epoch[26] Batch [480]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106716,	
2017-06-23 20:45:40,392 Epoch[26] Batch [490]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.106638,	
2017-06-23 20:45:46,380 Epoch[26] Batch [500]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106654,	
2017-06-23 20:45:52,297 Epoch[26] Batch [510]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.106577,	
2017-06-23 20:45:58,264 Epoch[26] Batch [520]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.106550,	
2017-06-23 20:46:04,301 Epoch[26] Batch [530]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.106250,	
2017-06-23 20:46:10,173 Epoch[26] Batch [540]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.105940,	
2017-06-23 20:46:16,106 Epoch[26] Batch [550]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105940,	
2017-06-23 20:46:22,003 Epoch[26] Batch [560]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.105850,	
2017-06-23 20:46:27,952 Epoch[26] Batch [570]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105561,	
2017-06-23 20:46:33,874 Epoch[26] Batch [580]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.105646,	
2017-06-23 20:46:39,838 Epoch[26] Batch [590]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105706,	
2017-06-23 20:46:45,774 Epoch[26] Batch [600]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105617,	
2017-06-23 20:46:51,700 Epoch[26] Batch [610]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105532,	
2017-06-23 20:46:57,650 Epoch[26] Batch [620]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105575,	
2017-06-23 20:47:03,577 Epoch[26] Batch [630]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105580,	
2017-06-23 20:47:09,519 Epoch[26] Batch [640]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105657,	
2017-06-23 20:47:15,487 Epoch[26] Batch [650]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105629,	
2017-06-23 20:47:21,457 Epoch[26] Batch [660]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105548,	
2017-06-23 20:47:27,374 Epoch[26] Batch [670]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.105422,	
2017-06-23 20:47:33,316 Epoch[26] Batch [680]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105287,	
2017-06-23 20:47:39,193 Epoch[26] Batch [690]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.105205,	
2017-06-23 20:47:45,129 Epoch[26] Batch [700]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105125,	
2017-06-23 20:47:51,026 Epoch[26] Batch [710]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.105183,	
2017-06-23 20:47:56,985 Epoch[26] Batch [720]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105114,	
2017-06-23 20:48:02,939 Epoch[26] Batch [730]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104945,	
2017-06-23 20:48:08,794 Epoch[26] Batch [740]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.104927,	
2017-06-23 20:48:14,780 Epoch[26] Batch [750]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.104819,	
2017-06-23 20:48:20,658 Epoch[26] Batch [760]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.104780,	
2017-06-23 20:48:26,388 Epoch[26] Batch [770]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.104769,	
2017-06-23 20:48:32,264 Epoch[26] Batch [780]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.104705,	
2017-06-23 20:48:38,051 Epoch[26] Batch [790]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.104533,	
2017-06-23 20:48:43,804 Epoch[26] Batch [800]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.104501,	
2017-06-23 20:48:49,522 Epoch[26] Batch [810]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.104397,	
2017-06-23 20:48:55,545 Epoch[26] Batch [820]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.104255,	
2017-06-23 20:49:01,466 Epoch[26] Batch [830]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.104152,	
2017-06-23 20:49:07,442 Epoch[26] Batch [840]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.104271,	
2017-06-23 20:49:13,396 Epoch[26] Batch [850]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104214,	
2017-06-23 20:49:19,294 Epoch[26] Batch [860]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.104162,	
2017-06-23 20:49:25,251 Epoch[26] Batch [870]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.104186,	
2017-06-23 20:49:31,228 Epoch[26] Batch [880]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.104149,	
2017-06-23 20:49:37,170 Epoch[26] Batch [890]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.104079,	
2017-06-23 20:49:43,088 Epoch[26] Batch [900]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.103990,	
2017-06-23 20:49:49,062 Epoch[26] Batch [910]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.103939,	
2017-06-23 20:49:55,012 Epoch[26] Batch [920]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.103880,	
2017-06-23 20:50:00,946 Epoch[26] Batch [930]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103857,	
2017-06-23 20:50:06,872 Epoch[26] Batch [940]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103921,	
2017-06-23 20:50:12,838 Epoch[26] Batch [950]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.103813,	
2017-06-23 20:50:18,777 Epoch[26] Batch [960]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103669,	
2017-06-23 20:50:24,848 Epoch[26] Batch [970]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103664,	
2017-06-23 20:50:30,783 Epoch[26] Batch [980]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103578,	
2017-06-23 20:50:36,711 Epoch[26] Batch [990]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103528,	
2017-06-23 20:50:42,597 Epoch[26] Batch [1000]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.103429,	
2017-06-23 20:50:48,586 Epoch[26] Batch [1010]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.103434,	
2017-06-23 20:50:54,499 Epoch[26] Batch [1020]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.103501,	
2017-06-23 20:51:00,410 Epoch[26] Batch [1030]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.103532,	
2017-06-23 20:51:06,469 Epoch[26] Batch [1040]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104150,	
2017-06-23 20:51:12,314 Epoch[26] Batch [1050]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.104405,	
2017-06-23 20:51:18,263 Epoch[26] Batch [1060]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104625,	
2017-06-23 20:51:24,043 Epoch[26] Batch [1070]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.104848,	
2017-06-23 20:51:29,908 Epoch[26] Batch [1080]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.105090,	
2017-06-23 20:51:35,752 Epoch[26] Batch [1090]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.105307,	
2017-06-23 20:51:41,575 Epoch[26] Batch [1100]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.105408,	
2017-06-23 20:51:47,312 Epoch[26] Batch [1110]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.105502,	
2017-06-23 20:51:53,418 Epoch[26] Batch [1120]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.105957,	
2017-06-23 20:51:59,470 Epoch[26] Batch [1130]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.106023,	
2017-06-23 20:52:05,394 Epoch[26] Batch [1140]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106159,	
2017-06-23 20:52:11,407 Epoch[26] Batch [1150]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.106236,	
2017-06-23 20:52:17,402 Epoch[26] Batch [1160]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.106486,	
2017-06-23 20:52:23,124 Epoch[26] Batch [1170]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.106578,	
2017-06-23 20:52:29,110 Epoch[26] Batch [1180]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106609,	
2017-06-23 20:52:35,384 Epoch[26] Batch [1190]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.106579,	
2017-06-23 20:52:41,694 Epoch[26] Batch [1200]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.106553,	
2017-06-23 20:52:47,546 Epoch[26] Batch [1210]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.106480,	
2017-06-23 20:52:53,415 Epoch[26] Batch [1220]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.106651,	
2017-06-23 20:52:59,377 Epoch[26] Batch [1230]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.107014,	
2017-06-23 20:53:04,862 Epoch[26] Batch [1240]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.107337,	
2017-06-23 20:53:10,747 Epoch[26] Batch [1250]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.107541,	
2017-06-23 20:53:16,624 Epoch[26] Batch [1260]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.107621,	
2017-06-23 20:53:22,575 Epoch[26] Batch [1270]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.107838,	
2017-06-23 20:53:28,623 Epoch[26] Batch [1280]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107915,	
2017-06-23 20:53:34,503 Epoch[26] Batch [1290]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.107905,	
2017-06-23 20:53:40,497 Epoch[26] Batch [1300]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.108079,	
2017-06-23 20:53:46,425 Epoch[26] Batch [1310]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.108183,	
2017-06-23 20:53:52,379 Epoch[26] Batch [1320]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.108235,	
2017-06-23 20:53:58,282 Epoch[26] Batch [1330]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108263,	
2017-06-23 20:54:04,271 Epoch[26] Batch [1340]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.108287,	
2017-06-23 20:54:10,207 Epoch[26] Batch [1350]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108301,	
2017-06-23 20:54:16,126 Epoch[26] Batch [1360]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.108296,	
2017-06-23 20:54:22,049 Epoch[26] Batch [1370]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.108310,	
2017-06-23 20:54:28,067 Epoch[26] Batch [1380]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.108338,	
2017-06-23 20:54:34,168 Epoch[26] Batch [1390]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.108201,	
2017-06-23 20:54:40,475 Epoch[26] Batch [1400]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.108187,	
2017-06-23 20:54:46,635 Epoch[26] Batch [1410]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.108057,	
2017-06-23 20:54:52,968 Epoch[26] Batch [1420]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.108236,	
2017-06-23 20:54:58,933 Epoch[26] Batch [1430]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.108296,	
2017-06-23 20:55:05,412 Epoch[26] Batch [1440]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.108343,	
2017-06-23 20:55:11,726 Epoch[26] Batch [1450]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.108242,	
2017-06-23 20:55:17,625 Epoch[26] Batch [1460]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108243,	
2017-06-23 20:55:23,565 Epoch[26] Batch [1470]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.108177,	
2017-06-23 20:55:29,500 Epoch[26] Batch [1480]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108135,	
2017-06-23 20:55:33,053 Epoch[26] Train-FCNLogLoss=0.108249
2017-06-23 20:55:33,053 Epoch[26] Time cost=886.197
2017-06-23 20:55:34,254 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0027.params"
2017-06-23 20:55:37,940 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0027.states"
2017-06-23 20:55:44,960 Epoch[27] Batch [10]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.113329,	
2017-06-23 20:55:50,848 Epoch[27] Batch [20]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.106599,	
2017-06-23 20:55:56,805 Epoch[27] Batch [30]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.111453,	
2017-06-23 20:56:02,704 Epoch[27] Batch [40]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.113172,	
2017-06-23 20:56:08,706 Epoch[27] Batch [50]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.112851,	
2017-06-23 20:56:14,844 Epoch[27] Batch [60]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.112624,	
2017-06-23 20:56:20,858 Epoch[27] Batch [70]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.111339,	
2017-06-23 20:56:26,717 Epoch[27] Batch [80]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.110056,	
2017-06-23 20:56:32,665 Epoch[27] Batch [90]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.109031,	
2017-06-23 20:56:38,661 Epoch[27] Batch [100]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.109050,	
2017-06-23 20:56:44,641 Epoch[27] Batch [110]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.108324,	
2017-06-23 20:56:50,559 Epoch[27] Batch [120]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.108213,	
2017-06-23 20:56:56,468 Epoch[27] Batch [130]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.108990,	
2017-06-23 20:57:02,440 Epoch[27] Batch [140]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.108331,	
2017-06-23 20:57:08,345 Epoch[27] Batch [150]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.108198,	
2017-06-23 20:57:14,291 Epoch[27] Batch [160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.107692,	
2017-06-23 20:57:20,331 Epoch[27] Batch [170]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108321,	
2017-06-23 20:57:26,168 Epoch[27] Batch [180]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.107899,	
2017-06-23 20:57:32,122 Epoch[27] Batch [190]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.107883,	
2017-06-23 20:57:38,084 Epoch[27] Batch [200]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.108413,	
2017-06-23 20:57:44,148 Epoch[27] Batch [210]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108359,	
2017-06-23 20:57:49,946 Epoch[27] Batch [220]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.108910,	
2017-06-23 20:57:55,930 Epoch[27] Batch [230]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.108574,	
2017-06-23 20:58:01,871 Epoch[27] Batch [240]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109173,	
2017-06-23 20:58:07,790 Epoch[27] Batch [250]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.109190,	
2017-06-23 20:58:13,734 Epoch[27] Batch [260]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109625,	
2017-06-23 20:58:19,755 Epoch[27] Batch [270]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.109560,	
2017-06-23 20:58:25,709 Epoch[27] Batch [280]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.109328,	
2017-06-23 20:58:31,624 Epoch[27] Batch [290]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.109337,	
2017-06-23 20:58:37,636 Epoch[27] Batch [300]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.109437,	
2017-06-23 20:58:43,543 Epoch[27] Batch [310]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.109349,	
2017-06-23 20:58:49,482 Epoch[27] Batch [320]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.109536,	
2017-06-23 20:58:55,426 Epoch[27] Batch [330]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109607,	
2017-06-23 20:59:01,413 Epoch[27] Batch [340]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.109356,	
2017-06-23 20:59:07,351 Epoch[27] Batch [350]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.109185,	
2017-06-23 20:59:13,298 Epoch[27] Batch [360]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109083,	
2017-06-23 20:59:19,180 Epoch[27] Batch [370]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.108665,	
2017-06-23 20:59:25,120 Epoch[27] Batch [380]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.108523,	
2017-06-23 20:59:31,052 Epoch[27] Batch [390]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108526,	
2017-06-23 20:59:37,047 Epoch[27] Batch [400]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.108698,	
2017-06-23 20:59:42,943 Epoch[27] Batch [410]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108459,	
2017-06-23 20:59:48,902 Epoch[27] Batch [420]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.108373,	
2017-06-23 20:59:54,851 Epoch[27] Batch [430]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.108341,	
2017-06-23 21:00:00,859 Epoch[27] Batch [440]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.107930,	
2017-06-23 21:00:06,580 Epoch[27] Batch [450]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.107964,	
2017-06-23 21:00:12,628 Epoch[27] Batch [460]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.107791,	
2017-06-23 21:00:18,539 Epoch[27] Batch [470]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.107763,	
2017-06-23 21:00:24,436 Epoch[27] Batch [480]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.107635,	
2017-06-23 21:00:30,254 Epoch[27] Batch [490]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.107476,	
2017-06-23 21:00:36,222 Epoch[27] Batch [500]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.107182,	
2017-06-23 21:00:42,167 Epoch[27] Batch [510]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106989,	
2017-06-23 21:00:48,092 Epoch[27] Batch [520]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.106742,	
2017-06-23 21:00:54,044 Epoch[27] Batch [530]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106784,	
2017-06-23 21:00:59,953 Epoch[27] Batch [540]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.106737,	
2017-06-23 21:01:05,932 Epoch[27] Batch [550]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.106721,	
2017-06-23 21:01:11,879 Epoch[27] Batch [560]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.106541,	
2017-06-23 21:01:17,867 Epoch[27] Batch [570]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.106522,	
2017-06-23 21:01:23,764 Epoch[27] Batch [580]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.106470,	
2017-06-23 21:01:29,744 Epoch[27] Batch [590]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.106550,	
2017-06-23 21:01:35,650 Epoch[27] Batch [600]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.106411,	
2017-06-23 21:01:41,609 Epoch[27] Batch [610]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.106456,	
2017-06-23 21:01:47,585 Epoch[27] Batch [620]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.106390,	
2017-06-23 21:01:53,560 Epoch[27] Batch [630]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.106328,	
2017-06-23 21:01:59,562 Epoch[27] Batch [640]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.106301,	
2017-06-23 21:02:05,558 Epoch[27] Batch [650]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.106420,	
2017-06-23 21:02:11,647 Epoch[27] Batch [660]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106204,	
2017-06-23 21:02:18,023 Epoch[27] Batch [670]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.106128,	
2017-06-23 21:02:24,322 Epoch[27] Batch [680]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.105997,	
2017-06-23 21:02:30,769 Epoch[27] Batch [690]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.106012,	
2017-06-23 21:02:36,968 Epoch[27] Batch [700]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.106170,	
2017-06-23 21:02:43,198 Epoch[27] Batch [710]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.105940,	
2017-06-23 21:02:49,071 Epoch[27] Batch [720]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.106099,	
2017-06-23 21:02:54,993 Epoch[27] Batch [730]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105909,	
2017-06-23 21:03:01,020 Epoch[27] Batch [740]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.105843,	
2017-06-23 21:03:06,971 Epoch[27] Batch [750]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105871,	
2017-06-23 21:03:12,881 Epoch[27] Batch [760]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.105846,	
2017-06-23 21:03:18,676 Epoch[27] Batch [770]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.105888,	
2017-06-23 21:03:24,697 Epoch[27] Batch [780]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.105711,	
2017-06-23 21:03:30,814 Epoch[27] Batch [790]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.105692,	
2017-06-23 21:03:36,950 Epoch[27] Batch [800]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.105685,	
2017-06-23 21:03:43,047 Epoch[27] Batch [810]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.105624,	
2017-06-23 21:03:49,462 Epoch[27] Batch [820]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.105480,	
2017-06-23 21:03:55,805 Epoch[27] Batch [830]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.105495,	
2017-06-23 21:04:02,078 Epoch[27] Batch [840]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.105602,	
2017-06-23 21:04:08,169 Epoch[27] Batch [850]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.105686,	
2017-06-23 21:04:14,059 Epoch[27] Batch [860]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.105750,	
2017-06-23 21:04:20,060 Epoch[27] Batch [870]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.105624,	
2017-06-23 21:04:25,984 Epoch[27] Batch [880]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.105718,	
2017-06-23 21:04:31,928 Epoch[27] Batch [890]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.105710,	
2017-06-23 21:04:37,907 Epoch[27] Batch [900]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.105731,	
2017-06-23 21:04:43,884 Epoch[27] Batch [910]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.105643,	
2017-06-23 21:04:49,787 Epoch[27] Batch [920]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.105645,	
2017-06-23 21:04:55,762 Epoch[27] Batch [930]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.105679,	
2017-06-23 21:05:01,701 Epoch[27] Batch [940]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105639,	
2017-06-23 21:05:07,634 Epoch[27] Batch [950]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105595,	
2017-06-23 21:05:13,408 Epoch[27] Batch [960]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.105493,	
2017-06-23 21:05:19,183 Epoch[27] Batch [970]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.105536,	
2017-06-23 21:05:25,157 Epoch[27] Batch [980]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105722,	
2017-06-23 21:05:31,008 Epoch[27] Batch [990]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.105645,	
2017-06-23 21:05:37,176 Epoch[27] Batch [1000]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.105617,	
2017-06-23 21:05:43,452 Epoch[27] Batch [1010]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.105597,	
2017-06-23 21:05:49,520 Epoch[27] Batch [1020]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.105650,	
2017-06-23 21:05:55,940 Epoch[27] Batch [1030]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.105647,	
2017-06-23 21:06:02,123 Epoch[27] Batch [1040]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.105682,	
2017-06-23 21:06:08,249 Epoch[27] Batch [1050]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.105622,	
2017-06-23 21:06:14,212 Epoch[27] Batch [1060]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105567,	
2017-06-23 21:06:20,162 Epoch[27] Batch [1070]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105388,	
2017-06-23 21:06:26,229 Epoch[27] Batch [1080]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.105454,	
2017-06-23 21:06:33,087 Epoch[27] Batch [1090]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.105406,	
2017-06-23 21:06:39,020 Epoch[27] Batch [1100]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.105274,	
2017-06-23 21:06:45,032 Epoch[27] Batch [1110]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.105302,	
2017-06-23 21:06:50,989 Epoch[27] Batch [1120]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.105318,	
2017-06-23 21:06:57,620 Epoch[27] Batch [1130]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.105263,	
2017-06-23 21:07:03,816 Epoch[27] Batch [1140]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.105218,	
2017-06-23 21:07:09,785 Epoch[27] Batch [1150]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.105157,	
2017-06-23 21:07:15,858 Epoch[27] Batch [1160]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.105113,	
2017-06-23 21:07:22,199 Epoch[27] Batch [1170]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.105166,	
2017-06-23 21:07:28,518 Epoch[27] Batch [1180]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.105087,	
2017-06-23 21:07:34,271 Epoch[27] Batch [1190]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.105079,	
2017-06-23 21:07:40,327 Epoch[27] Batch [1200]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.105042,	
2017-06-23 21:07:46,594 Epoch[27] Batch [1210]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.104966,	
2017-06-23 21:07:53,215 Epoch[27] Batch [1220]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.104859,	
2017-06-23 21:07:59,196 Epoch[27] Batch [1230]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.104757,	
2017-06-23 21:08:05,128 Epoch[27] Batch [1240]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.104716,	
2017-06-23 21:08:11,134 Epoch[27] Batch [1250]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.104678,	
2017-06-23 21:08:16,953 Epoch[27] Batch [1260]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.104696,	
2017-06-23 21:08:22,873 Epoch[27] Batch [1270]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.104692,	
2017-06-23 21:08:28,814 Epoch[27] Batch [1280]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.104649,	
2017-06-23 21:08:34,874 Epoch[27] Batch [1290]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104664,	
2017-06-23 21:08:40,825 Epoch[27] Batch [1300]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104649,	
2017-06-23 21:08:46,721 Epoch[27] Batch [1310]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.104597,	
2017-06-23 21:08:52,696 Epoch[27] Batch [1320]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.104509,	
2017-06-23 21:08:58,574 Epoch[27] Batch [1330]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.104533,	
2017-06-23 21:09:04,350 Epoch[27] Batch [1340]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.104499,	
2017-06-23 21:09:10,239 Epoch[27] Batch [1350]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.104492,	
2017-06-23 21:09:16,200 Epoch[27] Batch [1360]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.104405,	
2017-06-23 21:09:22,122 Epoch[27] Batch [1370]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.104357,	
2017-06-23 21:09:28,027 Epoch[27] Batch [1380]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104304,	
2017-06-23 21:09:33,989 Epoch[27] Batch [1390]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.104344,	
2017-06-23 21:09:39,923 Epoch[27] Batch [1400]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.104384,	
2017-06-23 21:09:45,788 Epoch[27] Batch [1410]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.104337,	
2017-06-23 21:09:51,690 Epoch[27] Batch [1420]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.104315,	
2017-06-23 21:09:57,646 Epoch[27] Batch [1430]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104326,	
2017-06-23 21:10:03,591 Epoch[27] Batch [1440]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.104327,	
2017-06-23 21:10:09,500 Epoch[27] Batch [1450]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104319,	
2017-06-23 21:10:15,440 Epoch[27] Batch [1460]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.104407,	
2017-06-23 21:10:21,378 Epoch[27] Batch [1470]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.104414,	
2017-06-23 21:10:27,299 Epoch[27] Batch [1480]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.104402,	
2017-06-23 21:10:30,883 Epoch[27] Train-FCNLogLoss=0.104366
2017-06-23 21:10:30,884 Epoch[27] Time cost=892.943
2017-06-23 21:10:32,302 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0028.params"
2017-06-23 21:10:35,850 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0028.states"
2017-06-23 21:10:42,717 Epoch[28] Batch [10]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.098936,	
2017-06-23 21:10:48,634 Epoch[28] Batch [20]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101574,	
2017-06-23 21:10:54,584 Epoch[28] Batch [30]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.101011,	
2017-06-23 21:11:00,535 Epoch[28] Batch [40]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.100714,	
2017-06-23 21:11:06,445 Epoch[28] Batch [50]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.100175,	
2017-06-23 21:11:12,153 Epoch[28] Batch [60]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.101971,	
2017-06-23 21:11:18,115 Epoch[28] Batch [70]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.102524,	
2017-06-23 21:11:24,099 Epoch[28] Batch [80]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.102595,	
2017-06-23 21:11:30,193 Epoch[28] Batch [90]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102023,	
2017-06-23 21:11:35,879 Epoch[28] Batch [100]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.101973,	
2017-06-23 21:11:41,778 Epoch[28] Batch [110]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.101346,	
2017-06-23 21:11:47,741 Epoch[28] Batch [120]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.101470,	
2017-06-23 21:11:53,672 Epoch[28] Batch [130]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101827,	
2017-06-23 21:11:59,645 Epoch[28] Batch [140]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101616,	
2017-06-23 21:12:05,588 Epoch[28] Batch [150]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102369,	
2017-06-23 21:12:11,533 Epoch[28] Batch [160]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102195,	
2017-06-23 21:12:17,464 Epoch[28] Batch [170]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.102113,	
2017-06-23 21:12:23,440 Epoch[28] Batch [180]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102208,	
2017-06-23 21:12:29,454 Epoch[28] Batch [190]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102058,	
2017-06-23 21:12:35,352 Epoch[28] Batch [200]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.101607,	
2017-06-23 21:12:41,327 Epoch[28] Batch [210]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102161,	
2017-06-23 21:12:47,306 Epoch[28] Batch [220]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102040,	
2017-06-23 21:12:53,279 Epoch[28] Batch [230]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.102039,	
2017-06-23 21:12:59,204 Epoch[28] Batch [240]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.102320,	
2017-06-23 21:13:05,167 Epoch[28] Batch [250]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.102052,	
2017-06-23 21:13:11,119 Epoch[28] Batch [260]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.102111,	
2017-06-23 21:13:17,039 Epoch[28] Batch [270]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101749,	
2017-06-23 21:13:22,936 Epoch[28] Batch [280]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.101527,	
2017-06-23 21:13:28,941 Epoch[28] Batch [290]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101543,	
2017-06-23 21:13:34,835 Epoch[28] Batch [300]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.102910,	
2017-06-23 21:13:40,912 Epoch[28] Batch [310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102992,	
2017-06-23 21:13:47,313 Epoch[28] Batch [320]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.103301,	
2017-06-23 21:13:53,689 Epoch[28] Batch [330]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.102825,	
2017-06-23 21:13:59,964 Epoch[28] Batch [340]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.102807,	
2017-06-23 21:14:06,356 Epoch[28] Batch [350]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.102648,	
2017-06-23 21:14:12,673 Epoch[28] Batch [360]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.102640,	
2017-06-23 21:14:18,840 Epoch[28] Batch [370]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.102696,	
2017-06-23 21:14:25,060 Epoch[28] Batch [380]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.102806,	
2017-06-23 21:14:31,198 Epoch[28] Batch [390]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102526,	
2017-06-23 21:14:37,156 Epoch[28] Batch [400]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.102391,	
2017-06-23 21:14:43,006 Epoch[28] Batch [410]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.102503,	
2017-06-23 21:14:49,055 Epoch[28] Batch [420]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102534,	
2017-06-23 21:14:55,457 Epoch[28] Batch [430]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.102576,	
2017-06-23 21:15:01,692 Epoch[28] Batch [440]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.103218,	
2017-06-23 21:15:08,007 Epoch[28] Batch [450]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.103279,	
2017-06-23 21:15:14,466 Epoch[28] Batch [460]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.103444,	
2017-06-23 21:15:20,687 Epoch[28] Batch [470]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.103370,	
2017-06-23 21:15:26,632 Epoch[28] Batch [480]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.103293,	
2017-06-23 21:15:32,545 Epoch[28] Batch [490]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.103063,	
2017-06-23 21:15:38,569 Epoch[28] Batch [500]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103036,	
2017-06-23 21:15:44,491 Epoch[28] Batch [510]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.103467,	
2017-06-23 21:15:50,316 Epoch[28] Batch [520]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103343,	
2017-06-23 21:15:56,183 Epoch[28] Batch [530]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.103249,	
2017-06-23 21:16:02,105 Epoch[28] Batch [540]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103246,	
2017-06-23 21:16:07,913 Epoch[28] Batch [550]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103082,	
2017-06-23 21:16:14,089 Epoch[28] Batch [560]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.103201,	
2017-06-23 21:16:20,146 Epoch[28] Batch [570]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103208,	
2017-06-23 21:16:26,429 Epoch[28] Batch [580]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.103417,	
2017-06-23 21:16:32,513 Epoch[28] Batch [590]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103442,	
2017-06-23 21:16:38,414 Epoch[28] Batch [600]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.103422,	
2017-06-23 21:16:44,184 Epoch[28] Batch [610]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103374,	
2017-06-23 21:16:50,246 Epoch[28] Batch [620]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103304,	
2017-06-23 21:16:56,468 Epoch[28] Batch [630]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.103483,	
2017-06-23 21:17:02,563 Epoch[28] Batch [640]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103452,	
2017-06-23 21:17:08,930 Epoch[28] Batch [650]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.103368,	
2017-06-23 21:17:15,389 Epoch[28] Batch [660]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.103388,	
2017-06-23 21:17:21,361 Epoch[28] Batch [670]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.103348,	
2017-06-23 21:17:27,198 Epoch[28] Batch [680]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103367,	
2017-06-23 21:17:33,319 Epoch[28] Batch [690]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103281,	
2017-06-23 21:17:39,477 Epoch[28] Batch [700]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.103351,	
2017-06-23 21:17:45,636 Epoch[28] Batch [710]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.103330,	
2017-06-23 21:17:51,674 Epoch[28] Batch [720]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103320,	
2017-06-23 21:17:58,192 Epoch[28] Batch [730]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.103277,	
2017-06-23 21:18:04,526 Epoch[28] Batch [740]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.103207,	
2017-06-23 21:18:11,340 Epoch[28] Batch [750]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.103294,	
2017-06-23 21:18:17,771 Epoch[28] Batch [760]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.103548,	
2017-06-23 21:18:24,527 Epoch[28] Batch [770]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.103547,	
2017-06-23 21:18:30,791 Epoch[28] Batch [780]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.103411,	
2017-06-23 21:18:36,967 Epoch[28] Batch [790]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.103309,	
2017-06-23 21:18:42,872 Epoch[28] Batch [800]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.103422,	
2017-06-23 21:18:48,610 Epoch[28] Batch [810]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.103539,	
2017-06-23 21:18:55,397 Epoch[28] Batch [820]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.103602,	
2017-06-23 21:19:02,195 Epoch[28] Batch [830]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.103596,	
2017-06-23 21:19:08,829 Epoch[28] Batch [840]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.103649,	
2017-06-23 21:19:14,938 Epoch[28] Batch [850]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103617,	
2017-06-23 21:19:21,604 Epoch[28] Batch [860]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.103713,	
2017-06-23 21:19:28,283 Epoch[28] Batch [870]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.103664,	
2017-06-23 21:19:34,808 Epoch[28] Batch [880]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.103643,	
2017-06-23 21:19:41,431 Epoch[28] Batch [890]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.103683,	
2017-06-23 21:19:47,975 Epoch[28] Batch [900]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.103692,	
2017-06-23 21:19:54,059 Epoch[28] Batch [910]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103665,	
2017-06-23 21:20:00,099 Epoch[28] Batch [920]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103710,	
2017-06-23 21:20:06,516 Epoch[28] Batch [930]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.103776,	
2017-06-23 21:20:12,545 Epoch[28] Batch [940]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103838,	
2017-06-23 21:20:18,865 Epoch[28] Batch [950]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.103792,	
2017-06-23 21:20:25,266 Epoch[28] Batch [960]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.103803,	
2017-06-23 21:20:32,288 Epoch[28] Batch [970]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.103778,	
2017-06-23 21:20:39,076 Epoch[28] Batch [980]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.103761,	
2017-06-23 21:20:45,468 Epoch[28] Batch [990]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103684,	
2017-06-23 21:20:51,938 Epoch[28] Batch [1000]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.103658,	
2017-06-23 21:20:58,736 Epoch[28] Batch [1010]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.103626,	
2017-06-23 21:21:05,238 Epoch[28] Batch [1020]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.103583,	
2017-06-23 21:21:11,631 Epoch[28] Batch [1030]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103520,	
2017-06-23 21:21:18,047 Epoch[28] Batch [1040]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.103501,	
2017-06-23 21:21:24,176 Epoch[28] Batch [1050]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103496,	
2017-06-23 21:21:29,940 Epoch[28] Batch [1060]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.103574,	
2017-06-23 21:21:36,110 Epoch[28] Batch [1070]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.103687,	
2017-06-23 21:21:42,241 Epoch[28] Batch [1080]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.103646,	
2017-06-23 21:21:48,105 Epoch[28] Batch [1090]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.103663,	
2017-06-23 21:21:54,090 Epoch[28] Batch [1100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.103554,	
2017-06-23 21:21:59,890 Epoch[28] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103534,	
2017-06-23 21:22:05,671 Epoch[28] Batch [1120]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103467,	
2017-06-23 21:22:11,547 Epoch[28] Batch [1130]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.103542,	
2017-06-23 21:22:17,512 Epoch[28] Batch [1140]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.103611,	
2017-06-23 21:22:23,440 Epoch[28] Batch [1150]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103611,	
2017-06-23 21:22:29,446 Epoch[28] Batch [1160]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.103505,	
2017-06-23 21:22:35,535 Epoch[28] Batch [1170]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103521,	
2017-06-23 21:22:41,528 Epoch[28] Batch [1180]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.103410,	
2017-06-23 21:22:47,699 Epoch[28] Batch [1190]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.103382,	
2017-06-23 21:22:53,668 Epoch[28] Batch [1200]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.103422,	
2017-06-23 21:22:59,528 Epoch[28] Batch [1210]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.103457,	
2017-06-23 21:23:05,408 Epoch[28] Batch [1220]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.103498,	
2017-06-23 21:23:11,367 Epoch[28] Batch [1230]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.103531,	
2017-06-23 21:23:17,315 Epoch[28] Batch [1240]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.103492,	
2017-06-23 21:23:23,341 Epoch[28] Batch [1250]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103451,	
2017-06-23 21:23:28,776 Epoch[28] Batch [1260]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.103438,	
2017-06-23 21:23:34,798 Epoch[28] Batch [1270]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103483,	
2017-06-23 21:23:40,597 Epoch[28] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103383,	
2017-06-23 21:23:46,525 Epoch[28] Batch [1290]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103397,	
2017-06-23 21:23:52,450 Epoch[28] Batch [1300]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103386,	
2017-06-23 21:23:58,357 Epoch[28] Batch [1310]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.103321,	
2017-06-23 21:24:04,264 Epoch[28] Batch [1320]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.103312,	
2017-06-23 21:24:10,096 Epoch[28] Batch [1330]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103278,	
2017-06-23 21:24:16,027 Epoch[28] Batch [1340]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103265,	
2017-06-23 21:24:21,933 Epoch[28] Batch [1350]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.103292,	
2017-06-23 21:24:27,949 Epoch[28] Batch [1360]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.103230,	
2017-06-23 21:24:33,785 Epoch[28] Batch [1370]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103338,	
2017-06-23 21:24:39,758 Epoch[28] Batch [1380]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.103260,	
2017-06-23 21:24:45,640 Epoch[28] Batch [1390]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.103299,	
2017-06-23 21:24:51,560 Epoch[28] Batch [1400]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.103310,	
2017-06-23 21:24:57,499 Epoch[28] Batch [1410]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103373,	
2017-06-23 21:25:03,466 Epoch[28] Batch [1420]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.103445,	
2017-06-23 21:25:09,397 Epoch[28] Batch [1430]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103475,	
2017-06-23 21:25:15,435 Epoch[28] Batch [1440]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103406,	
2017-06-23 21:25:21,230 Epoch[28] Batch [1450]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103492,	
2017-06-23 21:25:27,378 Epoch[28] Batch [1460]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.103412,	
2017-06-23 21:25:33,452 Epoch[28] Batch [1470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103436,	
2017-06-23 21:25:39,247 Epoch[28] Batch [1480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103514,	
2017-06-23 21:25:42,794 Epoch[28] Train-FCNLogLoss=0.103508
2017-06-23 21:25:42,794 Epoch[28] Time cost=906.944
2017-06-23 21:25:43,693 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0029.params"
2017-06-23 21:25:47,382 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0029.states"
2017-06-23 21:25:54,220 Epoch[29] Batch [10]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.115225,	
2017-06-23 21:26:00,200 Epoch[29] Batch [20]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.105694,	
2017-06-23 21:26:06,129 Epoch[29] Batch [30]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.102868,	
2017-06-23 21:26:12,142 Epoch[29] Batch [40]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101088,	
2017-06-23 21:26:17,959 Epoch[29] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101026,	
2017-06-23 21:26:23,929 Epoch[29] Batch [60]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.103887,	
2017-06-23 21:26:29,904 Epoch[29] Batch [70]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.102254,	
2017-06-23 21:26:35,801 Epoch[29] Batch [80]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.102432,	
2017-06-23 21:26:41,851 Epoch[29] Batch [90]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102340,	
2017-06-23 21:26:47,803 Epoch[29] Batch [100]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.101753,	
2017-06-23 21:26:53,749 Epoch[29] Batch [110]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102613,	
2017-06-23 21:26:59,764 Epoch[29] Batch [120]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102808,	
2017-06-23 21:27:05,952 Epoch[29] Batch [130]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.102652,	
2017-06-23 21:27:12,506 Epoch[29] Batch [140]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.102349,	
2017-06-23 21:27:19,074 Epoch[29] Batch [150]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.102563,	
2017-06-23 21:27:25,687 Epoch[29] Batch [160]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.102756,	
2017-06-23 21:27:32,435 Epoch[29] Batch [170]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.103022,	
2017-06-23 21:27:38,899 Epoch[29] Batch [180]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.102650,	
2017-06-23 21:27:45,518 Epoch[29] Batch [190]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.103634,	
2017-06-23 21:27:51,867 Epoch[29] Batch [200]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.102859,	
2017-06-23 21:27:58,945 Epoch[29] Batch [210]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.102645,	
2017-06-23 21:28:05,657 Epoch[29] Batch [220]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.102961,	
2017-06-23 21:28:11,905 Epoch[29] Batch [230]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.102503,	
2017-06-23 21:28:18,507 Epoch[29] Batch [240]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.102765,	
2017-06-23 21:28:25,145 Epoch[29] Batch [250]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.102699,	
2017-06-23 21:28:31,763 Epoch[29] Batch [260]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.102482,	
2017-06-23 21:28:38,001 Epoch[29] Batch [270]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.102403,	
2017-06-23 21:28:44,004 Epoch[29] Batch [280]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102178,	
2017-06-23 21:28:50,286 Epoch[29] Batch [290]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.101664,	
2017-06-23 21:28:56,861 Epoch[29] Batch [300]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.101622,	
2017-06-23 21:29:03,361 Epoch[29] Batch [310]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.101306,	
2017-06-23 21:29:09,967 Epoch[29] Batch [320]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.101056,	
2017-06-23 21:29:16,422 Epoch[29] Batch [330]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.101172,	
2017-06-23 21:29:23,052 Epoch[29] Batch [340]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.101179,	
2017-06-23 21:29:29,702 Epoch[29] Batch [350]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.101078,	
2017-06-23 21:29:35,890 Epoch[29] Batch [360]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.101022,	
2017-06-23 21:29:42,209 Epoch[29] Batch [370]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.101446,	
2017-06-23 21:29:48,359 Epoch[29] Batch [380]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.101159,	
2017-06-23 21:29:54,921 Epoch[29] Batch [390]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.101462,	
2017-06-23 21:30:01,368 Epoch[29] Batch [400]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.101551,	
2017-06-23 21:30:07,666 Epoch[29] Batch [410]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.101818,	
2017-06-23 21:30:13,839 Epoch[29] Batch [420]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.101915,	
2017-06-23 21:30:20,841 Epoch[29] Batch [430]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.103506,	
2017-06-23 21:30:27,898 Epoch[29] Batch [440]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.104743,	
2017-06-23 21:30:34,303 Epoch[29] Batch [450]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.106535,	
2017-06-23 21:30:40,394 Epoch[29] Batch [460]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107353,	
2017-06-23 21:30:47,079 Epoch[29] Batch [470]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.109134,	
2017-06-23 21:30:53,726 Epoch[29] Batch [480]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.109805,	
2017-06-23 21:30:59,895 Epoch[29] Batch [490]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.110247,	
2017-06-23 21:31:06,184 Epoch[29] Batch [500]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.111002,	
2017-06-23 21:31:12,522 Epoch[29] Batch [510]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.111006,	
2017-06-23 21:31:18,610 Epoch[29] Batch [520]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.110897,	
2017-06-23 21:31:25,146 Epoch[29] Batch [530]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.111053,	
2017-06-23 21:31:31,832 Epoch[29] Batch [540]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.111058,	
2017-06-23 21:31:38,805 Epoch[29] Batch [550]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.111204,	
2017-06-23 21:31:45,141 Epoch[29] Batch [560]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.111417,	
2017-06-23 21:31:51,567 Epoch[29] Batch [570]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.111474,	
2017-06-23 21:31:57,593 Epoch[29] Batch [580]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.111523,	
2017-06-23 21:32:04,250 Epoch[29] Batch [590]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.111439,	
2017-06-23 21:32:11,058 Epoch[29] Batch [600]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.111467,	
2017-06-23 21:32:18,065 Epoch[29] Batch [610]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.111372,	
2017-06-23 21:32:25,070 Epoch[29] Batch [620]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.111277,	
2017-06-23 21:32:31,620 Epoch[29] Batch [630]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.111302,	
2017-06-23 21:32:38,430 Epoch[29] Batch [640]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.111357,	
2017-06-23 21:32:45,195 Epoch[29] Batch [650]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.111482,	
2017-06-23 21:32:52,111 Epoch[29] Batch [660]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.111199,	
2017-06-23 21:32:59,127 Epoch[29] Batch [670]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.111283,	
2017-06-23 21:33:06,101 Epoch[29] Batch [680]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.111150,	
2017-06-23 21:33:12,927 Epoch[29] Batch [690]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.111120,	
2017-06-23 21:33:19,518 Epoch[29] Batch [700]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.111218,	
2017-06-23 21:33:26,525 Epoch[29] Batch [710]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.111287,	
2017-06-23 21:33:33,204 Epoch[29] Batch [720]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.111374,	
2017-06-23 21:33:40,144 Epoch[29] Batch [730]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.111309,	
2017-06-23 21:33:46,975 Epoch[29] Batch [740]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.111121,	
2017-06-23 21:33:53,758 Epoch[29] Batch [750]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.110900,	
2017-06-23 21:34:00,131 Epoch[29] Batch [760]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.110870,	
2017-06-23 21:34:06,390 Epoch[29] Batch [770]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.110747,	
2017-06-23 21:34:12,627 Epoch[29] Batch [780]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.110697,	
2017-06-23 21:34:18,970 Epoch[29] Batch [790]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.110563,	
2017-06-23 21:34:25,363 Epoch[29] Batch [800]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.110536,	
2017-06-23 21:34:31,678 Epoch[29] Batch [810]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.110493,	
2017-06-23 21:34:37,972 Epoch[29] Batch [820]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.110461,	
2017-06-23 21:34:44,386 Epoch[29] Batch [830]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.110221,	
2017-06-23 21:34:50,421 Epoch[29] Batch [840]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.110216,	
2017-06-23 21:34:56,337 Epoch[29] Batch [850]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.110162,	
2017-06-23 21:35:02,097 Epoch[29] Batch [860]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.110121,	
2017-06-23 21:35:08,169 Epoch[29] Batch [870]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.110063,	
2017-06-23 21:35:13,965 Epoch[29] Batch [880]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.109960,	
2017-06-23 21:35:19,923 Epoch[29] Batch [890]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.109859,	
2017-06-23 21:35:25,832 Epoch[29] Batch [900]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.109732,	
2017-06-23 21:35:31,755 Epoch[29] Batch [910]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.109651,	
2017-06-23 21:35:37,731 Epoch[29] Batch [920]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.109723,	
2017-06-23 21:35:43,644 Epoch[29] Batch [930]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.109713,	
2017-06-23 21:35:49,586 Epoch[29] Batch [940]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109729,	
2017-06-23 21:35:55,529 Epoch[29] Batch [950]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109551,	
2017-06-23 21:36:01,464 Epoch[29] Batch [960]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.109530,	
2017-06-23 21:36:07,435 Epoch[29] Batch [970]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.109597,	
2017-06-23 21:36:13,310 Epoch[29] Batch [980]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.109557,	
2017-06-23 21:36:19,261 Epoch[29] Batch [990]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.109499,	
2017-06-23 21:36:25,156 Epoch[29] Batch [1000]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.109378,	
2017-06-23 21:36:31,125 Epoch[29] Batch [1010]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.109414,	
2017-06-23 21:36:37,128 Epoch[29] Batch [1020]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.109235,	
2017-06-23 21:36:42,958 Epoch[29] Batch [1030]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.109143,	
2017-06-23 21:36:48,999 Epoch[29] Batch [1040]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109056,	
2017-06-23 21:36:54,870 Epoch[29] Batch [1050]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.108919,	
2017-06-23 21:37:01,186 Epoch[29] Batch [1060]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.108824,	
2017-06-23 21:37:07,499 Epoch[29] Batch [1070]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.108901,	
2017-06-23 21:37:13,700 Epoch[29] Batch [1080]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.108950,	
2017-06-23 21:37:19,993 Epoch[29] Batch [1090]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.108898,	
2017-06-23 21:37:25,918 Epoch[29] Batch [1100]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.108789,	
2017-06-23 21:37:32,390 Epoch[29] Batch [1110]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.108701,	
2017-06-23 21:37:38,376 Epoch[29] Batch [1120]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.108633,	
2017-06-23 21:37:44,319 Epoch[29] Batch [1130]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.108502,	
2017-06-23 21:37:50,648 Epoch[29] Batch [1140]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.108527,	
2017-06-23 21:37:56,510 Epoch[29] Batch [1150]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.108469,	
2017-06-23 21:38:02,381 Epoch[29] Batch [1160]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.108345,	
2017-06-23 21:38:08,350 Epoch[29] Batch [1170]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.108483,	
2017-06-23 21:38:14,287 Epoch[29] Batch [1180]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108491,	
2017-06-23 21:38:20,182 Epoch[29] Batch [1190]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.108857,	
2017-06-23 21:38:26,086 Epoch[29] Batch [1200]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.109007,	
2017-06-23 21:38:31,772 Epoch[29] Batch [1210]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.109030,	
2017-06-23 21:38:37,582 Epoch[29] Batch [1220]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.109015,	
2017-06-23 21:38:43,426 Epoch[29] Batch [1230]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.108930,	
2017-06-23 21:38:48,881 Epoch[29] Batch [1240]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.108907,	
2017-06-23 21:38:55,568 Epoch[29] Batch [1250]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.108849,	
2017-06-23 21:39:01,965 Epoch[29] Batch [1260]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.108882,	
2017-06-23 21:39:08,293 Epoch[29] Batch [1270]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.108792,	
2017-06-23 21:39:14,469 Epoch[29] Batch [1280]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.108678,	
2017-06-23 21:39:20,433 Epoch[29] Batch [1290]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.108685,	
2017-06-23 21:39:26,331 Epoch[29] Batch [1300]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108596,	
2017-06-23 21:39:32,515 Epoch[29] Batch [1310]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.108516,	
2017-06-23 21:39:38,748 Epoch[29] Batch [1320]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.108398,	
2017-06-23 21:39:44,698 Epoch[29] Batch [1330]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.108250,	
2017-06-23 21:39:50,590 Epoch[29] Batch [1340]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.108200,	
2017-06-23 21:39:56,597 Epoch[29] Batch [1350]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.108221,	
2017-06-23 21:40:02,520 Epoch[29] Batch [1360]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.108168,	
2017-06-23 21:40:08,422 Epoch[29] Batch [1370]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.108190,	
2017-06-23 21:40:14,372 Epoch[29] Batch [1380]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.108147,	
2017-06-23 21:40:20,308 Epoch[29] Batch [1390]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108080,	
2017-06-23 21:40:26,997 Epoch[29] Batch [1400]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.107989,	
2017-06-23 21:40:32,991 Epoch[29] Batch [1410]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.108006,	
2017-06-23 21:40:38,916 Epoch[29] Batch [1420]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.107917,	
2017-06-23 21:40:44,974 Epoch[29] Batch [1430]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107878,	
2017-06-23 21:40:50,689 Epoch[29] Batch [1440]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.107785,	
2017-06-23 21:40:56,958 Epoch[29] Batch [1450]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.107794,	
2017-06-23 21:41:03,000 Epoch[29] Batch [1460]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.107741,	
2017-06-23 21:41:09,611 Epoch[29] Batch [1470]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.107700,	
2017-06-23 21:41:16,053 Epoch[29] Batch [1480]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.107646,	
2017-06-23 21:41:19,813 Epoch[29] Train-FCNLogLoss=0.107662
2017-06-23 21:41:19,813 Epoch[29] Time cost=932.431
2017-06-23 21:41:20,829 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0030.params"
2017-06-23 21:41:24,619 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0030.states"
2017-06-23 21:41:31,800 Epoch[30] Batch [10]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.096724,	
2017-06-23 21:41:38,417 Epoch[30] Batch [20]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.096759,	
2017-06-23 21:41:44,491 Epoch[30] Batch [30]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101908,	
2017-06-23 21:41:51,157 Epoch[30] Batch [40]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.100343,	
2017-06-23 21:41:57,708 Epoch[30] Batch [50]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.100755,	
2017-06-23 21:42:03,954 Epoch[30] Batch [60]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.102129,	
2017-06-23 21:42:10,315 Epoch[30] Batch [70]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.101606,	
2017-06-23 21:42:17,119 Epoch[30] Batch [80]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.100370,	
2017-06-23 21:42:23,646 Epoch[30] Batch [90]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.101156,	
2017-06-23 21:42:30,428 Epoch[30] Batch [100]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.101179,	
2017-06-23 21:42:37,414 Epoch[30] Batch [110]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.100742,	
2017-06-23 21:42:44,195 Epoch[30] Batch [120]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.101274,	
2017-06-23 21:42:51,281 Epoch[30] Batch [130]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.100913,	
2017-06-23 21:42:57,939 Epoch[30] Batch [140]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.100411,	
2017-06-23 21:43:04,594 Epoch[30] Batch [150]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.101084,	
2017-06-23 21:43:11,319 Epoch[30] Batch [160]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.102068,	
2017-06-23 21:43:18,443 Epoch[30] Batch [170]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.101578,	
2017-06-23 21:43:25,343 Epoch[30] Batch [180]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.101440,	
2017-06-23 21:43:32,665 Epoch[30] Batch [190]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.101220,	
2017-06-23 21:43:39,748 Epoch[30] Batch [200]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.101127,	
2017-06-23 21:43:46,229 Epoch[30] Batch [210]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.101086,	
2017-06-23 21:43:52,542 Epoch[30] Batch [220]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.100794,	
2017-06-23 21:43:59,326 Epoch[30] Batch [230]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.100447,	
2017-06-23 21:44:05,710 Epoch[30] Batch [240]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.099966,	
2017-06-23 21:44:11,900 Epoch[30] Batch [250]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.099858,	
2017-06-23 21:44:18,305 Epoch[30] Batch [260]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.099817,	
2017-06-23 21:44:24,795 Epoch[30] Batch [270]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.099716,	
2017-06-23 21:44:31,185 Epoch[30] Batch [280]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.100050,	
2017-06-23 21:44:37,594 Epoch[30] Batch [290]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.100214,	
2017-06-23 21:44:43,916 Epoch[30] Batch [300]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.100705,	
2017-06-23 21:44:49,874 Epoch[30] Batch [310]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.100714,	
2017-06-23 21:44:56,083 Epoch[30] Batch [320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.100567,	
2017-06-23 21:45:02,003 Epoch[30] Batch [330]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.100894,	
2017-06-23 21:45:07,926 Epoch[30] Batch [340]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.100936,	
2017-06-23 21:45:14,204 Epoch[30] Batch [350]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.101577,	
2017-06-23 21:45:20,183 Epoch[30] Batch [360]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.101680,	
2017-06-23 21:45:25,953 Epoch[30] Batch [370]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.101923,	
2017-06-23 21:45:31,891 Epoch[30] Batch [380]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.102431,	
2017-06-23 21:45:38,166 Epoch[30] Batch [390]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.102487,	
2017-06-23 21:45:44,503 Epoch[30] Batch [400]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.102618,	
2017-06-23 21:45:50,285 Epoch[30] Batch [410]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.102505,	
2017-06-23 21:45:56,639 Epoch[30] Batch [420]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.102406,	
2017-06-23 21:46:03,066 Epoch[30] Batch [430]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.102502,	
2017-06-23 21:46:09,158 Epoch[30] Batch [440]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102348,	
2017-06-23 21:46:15,586 Epoch[30] Batch [450]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.102389,	
2017-06-23 21:46:21,813 Epoch[30] Batch [460]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.102607,	
2017-06-23 21:46:28,010 Epoch[30] Batch [470]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.102902,	
2017-06-23 21:46:34,549 Epoch[30] Batch [480]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.103247,	
2017-06-23 21:46:41,242 Epoch[30] Batch [490]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.103423,	
2017-06-23 21:46:47,792 Epoch[30] Batch [500]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.103472,	
2017-06-23 21:46:54,474 Epoch[30] Batch [510]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.103271,	
2017-06-23 21:47:00,975 Epoch[30] Batch [520]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.103244,	
2017-06-23 21:47:07,611 Epoch[30] Batch [530]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.103250,	
2017-06-23 21:47:14,120 Epoch[30] Batch [540]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.103307,	
2017-06-23 21:47:20,614 Epoch[30] Batch [550]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.103059,	
2017-06-23 21:47:27,346 Epoch[30] Batch [560]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.103011,	
2017-06-23 21:47:33,833 Epoch[30] Batch [570]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.102971,	
2017-06-23 21:47:40,507 Epoch[30] Batch [580]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.102993,	
2017-06-23 21:47:46,829 Epoch[30] Batch [590]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.103049,	
2017-06-23 21:47:53,173 Epoch[30] Batch [600]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.103020,	
2017-06-23 21:47:59,660 Epoch[30] Batch [610]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.103040,	
2017-06-23 21:48:05,657 Epoch[30] Batch [620]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102955,	
2017-06-23 21:48:11,652 Epoch[30] Batch [630]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102942,	
2017-06-23 21:48:17,641 Epoch[30] Batch [640]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.102988,	
2017-06-23 21:48:23,741 Epoch[30] Batch [650]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103213,	
2017-06-23 21:48:29,585 Epoch[30] Batch [660]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.103022,	
2017-06-23 21:48:35,591 Epoch[30] Batch [670]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.103140,	
2017-06-23 21:48:41,527 Epoch[30] Batch [680]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.103038,	
2017-06-23 21:48:47,412 Epoch[30] Batch [690]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.103033,	
2017-06-23 21:48:53,613 Epoch[30] Batch [700]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.103028,	
2017-06-23 21:48:59,869 Epoch[30] Batch [710]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.102809,	
2017-06-23 21:49:05,839 Epoch[30] Batch [720]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.102743,	
2017-06-23 21:49:11,708 Epoch[30] Batch [730]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.102805,	
2017-06-23 21:49:17,691 Epoch[30] Batch [740]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102786,	
2017-06-23 21:49:23,583 Epoch[30] Batch [750]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.102662,	
2017-06-23 21:49:29,575 Epoch[30] Batch [760]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.102550,	
2017-06-23 21:49:35,583 Epoch[30] Batch [770]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102447,	
2017-06-23 21:49:41,553 Epoch[30] Batch [780]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.102367,	
2017-06-23 21:49:47,535 Epoch[30] Batch [790]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102389,	
2017-06-23 21:49:53,826 Epoch[30] Batch [800]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.102239,	
2017-06-23 21:49:59,830 Epoch[30] Batch [810]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102286,	
2017-06-23 21:50:06,523 Epoch[30] Batch [820]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.102259,	
2017-06-23 21:50:12,550 Epoch[30] Batch [830]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102231,	
2017-06-23 21:50:18,625 Epoch[30] Batch [840]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102220,	
2017-06-23 21:50:24,873 Epoch[30] Batch [850]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.102146,	
2017-06-23 21:50:30,871 Epoch[30] Batch [860]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102157,	
2017-06-23 21:50:36,777 Epoch[30] Batch [870]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.102099,	
2017-06-23 21:50:42,724 Epoch[30] Batch [880]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102197,	
2017-06-23 21:50:48,669 Epoch[30] Batch [890]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102242,	
2017-06-23 21:50:54,664 Epoch[30] Batch [900]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102166,	
2017-06-23 21:51:00,832 Epoch[30] Batch [910]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.102126,	
2017-06-23 21:51:07,181 Epoch[30] Batch [920]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.102103,	
2017-06-23 21:51:13,481 Epoch[30] Batch [930]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.102069,	
2017-06-23 21:51:19,825 Epoch[30] Batch [940]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.101918,	
2017-06-23 21:51:26,176 Epoch[30] Batch [950]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.101857,	
2017-06-23 21:51:32,494 Epoch[30] Batch [960]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.101822,	
2017-06-23 21:51:39,125 Epoch[30] Batch [970]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.101770,	
2017-06-23 21:51:45,095 Epoch[30] Batch [980]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101724,	
2017-06-23 21:51:50,912 Epoch[30] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101775,	
2017-06-23 21:51:57,030 Epoch[30] Batch [1000]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101686,	
2017-06-23 21:52:02,988 Epoch[30] Batch [1010]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.101674,	
2017-06-23 21:52:08,952 Epoch[30] Batch [1020]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.101727,	
2017-06-23 21:52:14,824 Epoch[30] Batch [1030]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.101812,	
2017-06-23 21:52:20,856 Epoch[30] Batch [1040]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101886,	
2017-06-23 21:52:26,767 Epoch[30] Batch [1050]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.101916,	
2017-06-23 21:52:32,705 Epoch[30] Batch [1060]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.102020,	
2017-06-23 21:52:38,640 Epoch[30] Batch [1070]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101950,	
2017-06-23 21:52:44,582 Epoch[30] Batch [1080]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102340,	
2017-06-23 21:52:50,587 Epoch[30] Batch [1090]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102407,	
2017-06-23 21:52:56,495 Epoch[30] Batch [1100]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.102511,	
2017-06-23 21:53:02,455 Epoch[30] Batch [1110]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.102525,	
2017-06-23 21:53:08,465 Epoch[30] Batch [1120]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102480,	
2017-06-23 21:53:14,406 Epoch[30] Batch [1130]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102560,	
2017-06-23 21:53:20,330 Epoch[30] Batch [1140]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.102566,	
2017-06-23 21:53:26,258 Epoch[30] Batch [1150]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.102628,	
2017-06-23 21:53:32,355 Epoch[30] Batch [1160]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102660,	
2017-06-23 21:53:38,158 Epoch[30] Batch [1170]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102572,	
2017-06-23 21:53:44,103 Epoch[30] Batch [1180]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102661,	
2017-06-23 21:53:50,389 Epoch[30] Batch [1190]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.102554,	
2017-06-23 21:53:56,528 Epoch[30] Batch [1200]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102589,	
2017-06-23 21:54:02,761 Epoch[30] Batch [1210]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.102565,	
2017-06-23 21:54:09,157 Epoch[30] Batch [1220]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.102559,	
2017-06-23 21:54:15,151 Epoch[30] Batch [1230]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102694,	
2017-06-23 21:54:20,872 Epoch[30] Batch [1240]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.102774,	
2017-06-23 21:54:27,184 Epoch[30] Batch [1250]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.102776,	
2017-06-23 21:54:33,414 Epoch[30] Batch [1260]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.102810,	
2017-06-23 21:54:39,874 Epoch[30] Batch [1270]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.102720,	
2017-06-23 21:54:45,930 Epoch[30] Batch [1280]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102710,	
2017-06-23 21:54:53,050 Epoch[30] Batch [1290]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.102703,	
2017-06-23 21:55:00,852 Epoch[30] Batch [1300]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.102701,	
2017-06-23 21:55:07,993 Epoch[30] Batch [1310]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.102772,	
2017-06-23 21:55:14,952 Epoch[30] Batch [1320]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.102848,	
2017-06-23 21:55:21,487 Epoch[30] Batch [1330]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.102818,	
2017-06-23 21:55:27,891 Epoch[30] Batch [1340]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.102725,	
2017-06-23 21:55:34,531 Epoch[30] Batch [1350]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.102795,	
2017-06-23 21:55:40,761 Epoch[30] Batch [1360]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.102847,	
2017-06-23 21:55:46,842 Epoch[30] Batch [1370]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102927,	
2017-06-23 21:55:52,974 Epoch[30] Batch [1380]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102961,	
2017-06-23 21:55:59,017 Epoch[30] Batch [1390]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102886,	
2017-06-23 21:56:05,730 Epoch[30] Batch [1400]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.102909,	
2017-06-23 21:56:11,761 Epoch[30] Batch [1410]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102893,	
2017-06-23 21:56:17,840 Epoch[30] Batch [1420]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102849,	
2017-06-23 21:56:24,472 Epoch[30] Batch [1430]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.102866,	
2017-06-23 21:56:30,724 Epoch[30] Batch [1440]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.102804,	
2017-06-23 21:56:36,965 Epoch[30] Batch [1450]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.102819,	
2017-06-23 21:56:43,236 Epoch[30] Batch [1460]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.102815,	
2017-06-23 21:56:50,226 Epoch[30] Batch [1470]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.102790,	
2017-06-23 21:56:57,023 Epoch[30] Batch [1480]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.102802,	
2017-06-23 21:57:01,358 Epoch[30] Train-FCNLogLoss=0.102880
2017-06-23 21:57:01,358 Epoch[30] Time cost=936.738
2017-06-23 21:57:02,583 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0031.params"
2017-06-23 21:57:06,361 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0031.states"
2017-06-23 21:57:13,978 Epoch[31] Batch [10]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.105075,	
2017-06-23 21:57:20,795 Epoch[31] Batch [20]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.100645,	
2017-06-23 21:57:27,211 Epoch[31] Batch [30]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.096321,	
2017-06-23 21:57:33,804 Epoch[31] Batch [40]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.096642,	
2017-06-23 21:57:40,227 Epoch[31] Batch [50]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.098621,	
2017-06-23 21:57:46,608 Epoch[31] Batch [60]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.100182,	
2017-06-23 21:57:53,346 Epoch[31] Batch [70]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.100740,	
2017-06-23 21:57:59,537 Epoch[31] Batch [80]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.101931,	
2017-06-23 21:58:06,206 Epoch[31] Batch [90]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.101668,	
2017-06-23 21:58:12,601 Epoch[31] Batch [100]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.101170,	
2017-06-23 21:58:19,195 Epoch[31] Batch [110]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.101070,	
2017-06-23 21:58:25,497 Epoch[31] Batch [120]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.100337,	
2017-06-23 21:58:31,364 Epoch[31] Batch [130]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.099160,	
2017-06-23 21:58:37,367 Epoch[31] Batch [140]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.099894,	
2017-06-23 21:58:43,638 Epoch[31] Batch [150]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.100202,	
2017-06-23 21:58:50,002 Epoch[31] Batch [160]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.099811,	
2017-06-23 21:58:55,827 Epoch[31] Batch [170]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.099855,	
2017-06-23 21:59:01,863 Epoch[31] Batch [180]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099584,	
2017-06-23 21:59:07,614 Epoch[31] Batch [190]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099753,	
2017-06-23 21:59:13,577 Epoch[31] Batch [200]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099703,	
2017-06-23 21:59:19,724 Epoch[31] Batch [210]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.099233,	
2017-06-23 21:59:26,014 Epoch[31] Batch [220]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.099124,	
2017-06-23 21:59:32,218 Epoch[31] Batch [230]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.098744,	
2017-06-23 21:59:39,029 Epoch[31] Batch [240]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.098487,	
2017-06-23 21:59:45,159 Epoch[31] Batch [250]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098567,	
2017-06-23 21:59:51,566 Epoch[31] Batch [260]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.098539,	
2017-06-23 21:59:58,578 Epoch[31] Batch [270]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.098326,	
2017-06-23 22:00:05,598 Epoch[31] Batch [280]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.097985,	
2017-06-23 22:00:11,900 Epoch[31] Batch [290]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.098141,	
2017-06-23 22:00:18,110 Epoch[31] Batch [300]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.098108,	
2017-06-23 22:00:24,477 Epoch[31] Batch [310]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.098226,	
2017-06-23 22:00:31,320 Epoch[31] Batch [320]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.098005,	
2017-06-23 22:00:37,884 Epoch[31] Batch [330]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.098158,	
2017-06-23 22:00:44,393 Epoch[31] Batch [340]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.097956,	
2017-06-23 22:00:51,129 Epoch[31] Batch [350]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.097650,	
2017-06-23 22:00:58,360 Epoch[31] Batch [360]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.097834,	
2017-06-23 22:01:05,048 Epoch[31] Batch [370]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.097555,	
2017-06-23 22:01:11,431 Epoch[31] Batch [380]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.098136,	
2017-06-23 22:01:17,888 Epoch[31] Batch [390]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.098028,	
2017-06-23 22:01:23,939 Epoch[31] Batch [400]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097830,	
2017-06-23 22:01:30,305 Epoch[31] Batch [410]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.097992,	
2017-06-23 22:01:36,245 Epoch[31] Batch [420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.097738,	
2017-06-23 22:01:42,051 Epoch[31] Batch [430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.098253,	
2017-06-23 22:01:47,998 Epoch[31] Batch [440]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.098183,	
2017-06-23 22:01:53,993 Epoch[31] Batch [450]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.098396,	
2017-06-23 22:02:00,158 Epoch[31] Batch [460]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.098562,	
2017-06-23 22:02:06,417 Epoch[31] Batch [470]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.098691,	
2017-06-23 22:02:12,306 Epoch[31] Batch [480]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.098937,	
2017-06-23 22:02:18,372 Epoch[31] Batch [490]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099154,	
2017-06-23 22:02:24,308 Epoch[31] Batch [500]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099237,	
2017-06-23 22:02:30,305 Epoch[31] Batch [510]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.099366,	
2017-06-23 22:02:36,483 Epoch[31] Batch [520]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.099610,	
2017-06-23 22:02:42,384 Epoch[31] Batch [530]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.099772,	
2017-06-23 22:02:48,350 Epoch[31] Batch [540]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099631,	
2017-06-23 22:02:54,242 Epoch[31] Batch [550]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.099587,	
2017-06-23 22:03:00,211 Epoch[31] Batch [560]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.099803,	
2017-06-23 22:03:06,137 Epoch[31] Batch [570]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.099796,	
2017-06-23 22:03:12,159 Epoch[31] Batch [580]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099784,	
2017-06-23 22:03:18,404 Epoch[31] Batch [590]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.099763,	
2017-06-23 22:03:25,087 Epoch[31] Batch [600]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.099519,	
2017-06-23 22:03:31,539 Epoch[31] Batch [610]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.099496,	
2017-06-23 22:03:38,105 Epoch[31] Batch [620]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.099638,	
2017-06-23 22:03:44,328 Epoch[31] Batch [630]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.099527,	
2017-06-23 22:03:50,718 Epoch[31] Batch [640]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.099441,	
2017-06-23 22:03:57,121 Epoch[31] Batch [650]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.099409,	
2017-06-23 22:04:03,391 Epoch[31] Batch [660]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.099220,	
2017-06-23 22:04:10,108 Epoch[31] Batch [670]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.099181,	
2017-06-23 22:04:16,267 Epoch[31] Batch [680]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.099424,	
2017-06-23 22:04:22,455 Epoch[31] Batch [690]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.099313,	
2017-06-23 22:04:29,157 Epoch[31] Batch [700]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.099528,	
2017-06-23 22:04:35,407 Epoch[31] Batch [710]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.099408,	
2017-06-23 22:04:41,920 Epoch[31] Batch [720]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.099590,	
2017-06-23 22:04:48,297 Epoch[31] Batch [730]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.099790,	
2017-06-23 22:04:54,430 Epoch[31] Batch [740]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.099631,	
2017-06-23 22:05:00,457 Epoch[31] Batch [750]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099625,	
2017-06-23 22:05:06,467 Epoch[31] Batch [760]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.099658,	
2017-06-23 22:05:12,270 Epoch[31] Batch [770]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099756,	
2017-06-23 22:05:18,276 Epoch[31] Batch [780]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.099636,	
2017-06-23 22:05:24,264 Epoch[31] Batch [790]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.099655,	
2017-06-23 22:05:30,152 Epoch[31] Batch [800]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.099757,	
2017-06-23 22:05:36,087 Epoch[31] Batch [810]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099781,	
2017-06-23 22:05:42,097 Epoch[31] Batch [820]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.099720,	
2017-06-23 22:05:47,936 Epoch[31] Batch [830]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.099741,	
2017-06-23 22:05:53,869 Epoch[31] Batch [840]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099724,	
2017-06-23 22:05:59,815 Epoch[31] Batch [850]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.099694,	
2017-06-23 22:06:05,745 Epoch[31] Batch [860]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.099680,	
2017-06-23 22:06:11,686 Epoch[31] Batch [870]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.099579,	
2017-06-23 22:06:17,650 Epoch[31] Batch [880]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099506,	
2017-06-23 22:06:23,504 Epoch[31] Batch [890]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.099494,	
2017-06-23 22:06:29,463 Epoch[31] Batch [900]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099501,	
2017-06-23 22:06:35,506 Epoch[31] Batch [910]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.099432,	
2017-06-23 22:06:41,542 Epoch[31] Batch [920]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099284,	
2017-06-23 22:06:47,810 Epoch[31] Batch [930]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.099332,	
2017-06-23 22:06:54,619 Epoch[31] Batch [940]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.099272,	
2017-06-23 22:07:00,944 Epoch[31] Batch [950]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.099345,	
2017-06-23 22:07:07,625 Epoch[31] Batch [960]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.099382,	
2017-06-23 22:07:13,719 Epoch[31] Batch [970]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099409,	
2017-06-23 22:07:20,306 Epoch[31] Batch [980]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.099409,	
2017-06-23 22:07:26,865 Epoch[31] Batch [990]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.099507,	
2017-06-23 22:07:32,968 Epoch[31] Batch [1000]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099524,	
2017-06-23 22:07:39,292 Epoch[31] Batch [1010]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.099411,	
2017-06-23 22:07:45,710 Epoch[31] Batch [1020]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.099429,	
2017-06-23 22:07:51,907 Epoch[31] Batch [1030]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.099385,	
2017-06-23 22:07:58,333 Epoch[31] Batch [1040]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.099517,	
2017-06-23 22:08:04,586 Epoch[31] Batch [1050]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.099501,	
2017-06-23 22:08:11,037 Epoch[31] Batch [1060]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.099410,	
2017-06-23 22:08:17,474 Epoch[31] Batch [1070]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.099739,	
2017-06-23 22:08:23,434 Epoch[31] Batch [1080]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099765,	
2017-06-23 22:08:29,346 Epoch[31] Batch [1090]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099781,	
2017-06-23 22:08:35,285 Epoch[31] Batch [1100]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099831,	
2017-06-23 22:08:41,093 Epoch[31] Batch [1110]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.099805,	
2017-06-23 22:08:46,886 Epoch[31] Batch [1120]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099773,	
2017-06-23 22:08:53,078 Epoch[31] Batch [1130]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.099783,	
2017-06-23 22:08:59,003 Epoch[31] Batch [1140]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.099827,	
2017-06-23 22:09:05,163 Epoch[31] Batch [1150]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.099771,	
2017-06-23 22:09:11,152 Epoch[31] Batch [1160]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.099728,	
2017-06-23 22:09:17,129 Epoch[31] Batch [1170]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.099774,	
2017-06-23 22:09:23,696 Epoch[31] Batch [1180]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.099759,	
2017-06-23 22:09:29,599 Epoch[31] Batch [1190]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.099772,	
2017-06-23 22:09:35,638 Epoch[31] Batch [1200]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.099895,	
2017-06-23 22:09:41,882 Epoch[31] Batch [1210]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.099853,	
2017-06-23 22:09:48,404 Epoch[31] Batch [1220]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.099915,	
2017-06-23 22:09:54,820 Epoch[31] Batch [1230]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.099993,	
2017-06-23 22:10:00,893 Epoch[31] Batch [1240]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100009,	
2017-06-23 22:10:07,367 Epoch[31] Batch [1250]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.099986,	
2017-06-23 22:10:13,460 Epoch[31] Batch [1260]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099953,	
2017-06-23 22:10:19,950 Epoch[31] Batch [1270]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.099863,	
2017-06-23 22:10:26,593 Epoch[31] Batch [1280]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.099876,	
2017-06-23 22:10:33,367 Epoch[31] Batch [1290]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.099880,	
2017-06-23 22:10:39,777 Epoch[31] Batch [1300]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.099924,	
2017-06-23 22:10:46,236 Epoch[31] Batch [1310]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.099950,	
2017-06-23 22:10:52,296 Epoch[31] Batch [1320]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099961,	
2017-06-23 22:10:58,941 Epoch[31] Batch [1330]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.099937,	
2017-06-23 22:11:05,610 Epoch[31] Batch [1340]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.099928,	
2017-06-23 22:11:12,385 Epoch[31] Batch [1350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.099918,	
2017-06-23 22:11:18,349 Epoch[31] Batch [1360]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099932,	
2017-06-23 22:11:24,552 Epoch[31] Batch [1370]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.099887,	
2017-06-23 22:11:30,788 Epoch[31] Batch [1380]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.099814,	
2017-06-23 22:11:36,651 Epoch[31] Batch [1390]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.099795,	
2017-06-23 22:11:42,510 Epoch[31] Batch [1400]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.099796,	
2017-06-23 22:11:48,443 Epoch[31] Batch [1410]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099974,	
2017-06-23 22:11:54,285 Epoch[31] Batch [1420]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.100018,	
2017-06-23 22:12:00,417 Epoch[31] Batch [1430]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.099978,	
2017-06-23 22:12:06,235 Epoch[31] Batch [1440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099919,	
2017-06-23 22:12:12,357 Epoch[31] Batch [1450]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.099887,	
2017-06-23 22:12:18,540 Epoch[31] Batch [1460]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.099854,	
2017-06-23 22:12:24,592 Epoch[31] Batch [1470]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099820,	
2017-06-23 22:12:31,035 Epoch[31] Batch [1480]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.099878,	
2017-06-23 22:12:34,938 Epoch[31] Train-FCNLogLoss=0.099887
2017-06-23 22:12:34,938 Epoch[31] Time cost=928.577
2017-06-23 22:12:35,984 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0032.params"
2017-06-23 22:12:39,785 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0032.states"
2017-06-23 22:12:47,982 Epoch[32] Batch [10]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.093955,	
2017-06-23 22:12:55,177 Epoch[32] Batch [20]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.096884,	
2017-06-23 22:13:01,498 Epoch[32] Batch [30]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.099125,	
2017-06-23 22:13:08,083 Epoch[32] Batch [40]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.098089,	
2017-06-23 22:13:14,962 Epoch[32] Batch [50]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.096699,	
2017-06-23 22:13:21,444 Epoch[32] Batch [60]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.097666,	
2017-06-23 22:13:28,359 Epoch[32] Batch [70]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.098757,	
2017-06-23 22:13:35,295 Epoch[32] Batch [80]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.097626,	
2017-06-23 22:13:42,469 Epoch[32] Batch [90]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.097262,	
2017-06-23 22:13:49,198 Epoch[32] Batch [100]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.096792,	
2017-06-23 22:13:56,111 Epoch[32] Batch [110]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.097247,	
2017-06-23 22:14:03,332 Epoch[32] Batch [120]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.097699,	
2017-06-23 22:14:10,036 Epoch[32] Batch [130]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.097759,	
2017-06-23 22:14:16,571 Epoch[32] Batch [140]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.097821,	
2017-06-23 22:14:22,804 Epoch[32] Batch [150]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.097862,	
2017-06-23 22:14:29,172 Epoch[32] Batch [160]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.097933,	
2017-06-23 22:14:35,653 Epoch[32] Batch [170]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.097267,	
2017-06-23 22:14:42,045 Epoch[32] Batch [180]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.096964,	
2017-06-23 22:14:48,145 Epoch[32] Batch [190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097570,	
2017-06-23 22:14:54,576 Epoch[32] Batch [200]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.097694,	
2017-06-23 22:15:00,631 Epoch[32] Batch [210]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097944,	
2017-06-23 22:15:06,651 Epoch[32] Batch [220]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097566,	
2017-06-23 22:15:12,366 Epoch[32] Batch [230]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.097747,	
2017-06-23 22:15:18,587 Epoch[32] Batch [240]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.098051,	
2017-06-23 22:15:24,457 Epoch[32] Batch [250]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.098082,	
2017-06-23 22:15:30,558 Epoch[32] Batch [260]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098361,	
2017-06-23 22:15:37,018 Epoch[32] Batch [270]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.098482,	
2017-06-23 22:15:43,414 Epoch[32] Batch [280]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.098488,	
2017-06-23 22:15:49,310 Epoch[32] Batch [290]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.098277,	
2017-06-23 22:15:55,264 Epoch[32] Batch [300]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.098662,	
2017-06-23 22:16:01,215 Epoch[32] Batch [310]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.098597,	
2017-06-23 22:16:07,154 Epoch[32] Batch [320]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.098690,	
2017-06-23 22:16:13,190 Epoch[32] Batch [330]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.098893,	
2017-06-23 22:16:19,067 Epoch[32] Batch [340]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.098953,	
2017-06-23 22:16:25,004 Epoch[32] Batch [350]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099113,	
2017-06-23 22:16:30,954 Epoch[32] Batch [360]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.099226,	
2017-06-23 22:16:37,001 Epoch[32] Batch [370]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.099128,	
2017-06-23 22:16:42,971 Epoch[32] Batch [380]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.099260,	
2017-06-23 22:16:48,898 Epoch[32] Batch [390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.099010,	
2017-06-23 22:16:55,387 Epoch[32] Batch [400]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.098969,	
2017-06-23 22:17:01,375 Epoch[32] Batch [410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.099135,	
2017-06-23 22:17:07,393 Epoch[32] Batch [420]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.099360,	
2017-06-23 22:17:13,332 Epoch[32] Batch [430]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099374,	
2017-06-23 22:17:19,148 Epoch[32] Batch [440]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099791,	
2017-06-23 22:17:25,064 Epoch[32] Batch [450]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.099681,	
2017-06-23 22:17:31,029 Epoch[32] Batch [460]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099404,	
2017-06-23 22:17:36,947 Epoch[32] Batch [470]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.099300,	
2017-06-23 22:17:42,848 Epoch[32] Batch [480]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.099794,	
2017-06-23 22:17:48,787 Epoch[32] Batch [490]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.099822,	
2017-06-23 22:17:54,786 Epoch[32] Batch [500]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.099767,	
2017-06-23 22:18:00,711 Epoch[32] Batch [510]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.099647,	
2017-06-23 22:18:06,557 Epoch[32] Batch [520]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.099855,	
2017-06-23 22:18:12,343 Epoch[32] Batch [530]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.099802,	
2017-06-23 22:18:18,232 Epoch[32] Batch [540]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.100029,	
2017-06-23 22:18:24,203 Epoch[32] Batch [550]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.100008,	
2017-06-23 22:18:29,954 Epoch[32] Batch [560]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.099874,	
2017-06-23 22:18:35,859 Epoch[32] Batch [570]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099777,	
2017-06-23 22:18:41,808 Epoch[32] Batch [580]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.099810,	
2017-06-23 22:18:47,808 Epoch[32] Batch [590]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.099867,	
2017-06-23 22:18:53,717 Epoch[32] Batch [600]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099965,	
2017-06-23 22:18:59,679 Epoch[32] Batch [610]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099929,	
2017-06-23 22:19:05,607 Epoch[32] Batch [620]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.100073,	
2017-06-23 22:19:11,524 Epoch[32] Batch [630]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.100162,	
2017-06-23 22:19:17,480 Epoch[32] Batch [640]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.099979,	
2017-06-23 22:19:23,430 Epoch[32] Batch [650]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.099929,	
2017-06-23 22:19:29,342 Epoch[32] Batch [660]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099895,	
2017-06-23 22:19:35,312 Epoch[32] Batch [670]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.099728,	
2017-06-23 22:19:41,223 Epoch[32] Batch [680]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.099594,	
2017-06-23 22:19:47,178 Epoch[32] Batch [690]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.099445,	
2017-06-23 22:19:53,121 Epoch[32] Batch [700]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.099283,	
2017-06-23 22:19:59,067 Epoch[32] Batch [710]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.099288,	
2017-06-23 22:20:05,013 Epoch[32] Batch [720]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.099282,	
2017-06-23 22:20:11,040 Epoch[32] Batch [730]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099088,	
2017-06-23 22:20:17,199 Epoch[32] Batch [740]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.099050,	
2017-06-23 22:20:23,245 Epoch[32] Batch [750]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.099028,	
2017-06-23 22:20:29,064 Epoch[32] Batch [760]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.099113,	
2017-06-23 22:20:35,377 Epoch[32] Batch [770]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.099063,	
2017-06-23 22:20:41,433 Epoch[32] Batch [780]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099031,	
2017-06-23 22:20:47,357 Epoch[32] Batch [790]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.098990,	
2017-06-23 22:20:53,352 Epoch[32] Batch [800]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.098934,	
2017-06-23 22:20:59,785 Epoch[32] Batch [810]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.098818,	
2017-06-23 22:21:05,805 Epoch[32] Batch [820]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.098771,	
2017-06-23 22:21:11,624 Epoch[32] Batch [830]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.098814,	
2017-06-23 22:21:17,801 Epoch[32] Batch [840]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.098837,	
2017-06-23 22:21:23,698 Epoch[32] Batch [850]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.098907,	
2017-06-23 22:21:29,824 Epoch[32] Batch [860]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098826,	
2017-06-23 22:21:35,827 Epoch[32] Batch [870]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.098771,	
2017-06-23 22:21:41,725 Epoch[32] Batch [880]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.098687,	
2017-06-23 22:21:47,674 Epoch[32] Batch [890]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.098672,	
2017-06-23 22:21:53,539 Epoch[32] Batch [900]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.098583,	
2017-06-23 22:21:59,652 Epoch[32] Batch [910]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098534,	
2017-06-23 22:22:05,657 Epoch[32] Batch [920]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.098516,	
2017-06-23 22:22:12,080 Epoch[32] Batch [930]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.098379,	
2017-06-23 22:22:18,263 Epoch[32] Batch [940]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.098300,	
2017-06-23 22:22:24,288 Epoch[32] Batch [950]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.098231,	
2017-06-23 22:22:30,883 Epoch[32] Batch [960]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.098299,	
2017-06-23 22:22:36,789 Epoch[32] Batch [970]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.098289,	
2017-06-23 22:22:42,553 Epoch[32] Batch [980]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.098423,	
2017-06-23 22:22:48,492 Epoch[32] Batch [990]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.098368,	
2017-06-23 22:22:54,408 Epoch[32] Batch [1000]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.098230,	
2017-06-23 22:23:00,376 Epoch[32] Batch [1010]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.098127,	
2017-06-23 22:23:06,972 Epoch[32] Batch [1020]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.098024,	
2017-06-23 22:23:13,143 Epoch[32] Batch [1030]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.097995,	
2017-06-23 22:23:19,792 Epoch[32] Batch [1040]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.097856,	
2017-06-23 22:23:26,688 Epoch[32] Batch [1050]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.098019,	
2017-06-23 22:23:33,209 Epoch[32] Batch [1060]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.098037,	
2017-06-23 22:23:39,696 Epoch[32] Batch [1070]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.098092,	
2017-06-23 22:23:45,997 Epoch[32] Batch [1080]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.098035,	
2017-06-23 22:23:52,256 Epoch[32] Batch [1090]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.097971,	
2017-06-23 22:23:58,511 Epoch[32] Batch [1100]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.098035,	
2017-06-23 22:24:04,886 Epoch[32] Batch [1110]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.098057,	
2017-06-23 22:24:11,487 Epoch[32] Batch [1120]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.097991,	
2017-06-23 22:24:18,135 Epoch[32] Batch [1130]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.097992,	
2017-06-23 22:24:24,679 Epoch[32] Batch [1140]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.097957,	
2017-06-23 22:24:31,827 Epoch[32] Batch [1150]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.097930,	
2017-06-23 22:24:38,420 Epoch[32] Batch [1160]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.097889,	
2017-06-23 22:24:44,824 Epoch[32] Batch [1170]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.097847,	
2017-06-23 22:24:51,169 Epoch[32] Batch [1180]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.097927,	
2017-06-23 22:24:57,895 Epoch[32] Batch [1190]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.097942,	
2017-06-23 22:25:04,512 Epoch[32] Batch [1200]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.097904,	
2017-06-23 22:25:10,392 Epoch[32] Batch [1210]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.098012,	
2017-06-23 22:25:16,161 Epoch[32] Batch [1220]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.098168,	
2017-06-23 22:25:22,193 Epoch[32] Batch [1230]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.098198,	
2017-06-23 22:25:27,804 Epoch[32] Batch [1240]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.098119,	
2017-06-23 22:25:33,807 Epoch[32] Batch [1250]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.098155,	
2017-06-23 22:25:39,974 Epoch[32] Batch [1260]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.098109,	
2017-06-23 22:25:45,884 Epoch[32] Batch [1270]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.098210,	
2017-06-23 22:25:51,862 Epoch[32] Batch [1280]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.098757,	
2017-06-23 22:25:58,216 Epoch[32] Batch [1290]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.099028,	
2017-06-23 22:26:04,236 Epoch[32] Batch [1300]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.099373,	
2017-06-23 22:26:10,285 Epoch[32] Batch [1310]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099405,	
2017-06-23 22:26:16,312 Epoch[32] Batch [1320]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099527,	
2017-06-23 22:26:22,864 Epoch[32] Batch [1330]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.099578,	
2017-06-23 22:26:29,195 Epoch[32] Batch [1340]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.099652,	
2017-06-23 22:26:35,782 Epoch[32] Batch [1350]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.099788,	
2017-06-23 22:26:42,104 Epoch[32] Batch [1360]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.099864,	
2017-06-23 22:26:48,267 Epoch[32] Batch [1370]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.099869,	
2017-06-23 22:26:54,965 Epoch[32] Batch [1380]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.100004,	
2017-06-23 22:27:01,438 Epoch[32] Batch [1390]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.100150,	
2017-06-23 22:27:08,042 Epoch[32] Batch [1400]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.100138,	
2017-06-23 22:27:14,733 Epoch[32] Batch [1410]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.100117,	
2017-06-23 22:27:20,906 Epoch[32] Batch [1420]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.100110,	
2017-06-23 22:27:26,895 Epoch[32] Batch [1430]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.100161,	
2017-06-23 22:27:32,886 Epoch[32] Batch [1440]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.100227,	
2017-06-23 22:27:39,469 Epoch[32] Batch [1450]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.100221,	
2017-06-23 22:27:46,351 Epoch[32] Batch [1460]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.100215,	
2017-06-23 22:27:52,584 Epoch[32] Batch [1470]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.100222,	
2017-06-23 22:27:59,217 Epoch[32] Batch [1480]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.100273,	
2017-06-23 22:28:03,170 Epoch[32] Train-FCNLogLoss=0.100296
2017-06-23 22:28:03,171 Epoch[32] Time cost=923.385
2017-06-23 22:28:04,103 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0033.params"
2017-06-23 22:28:08,050 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0033.states"
2017-06-23 22:28:15,761 Epoch[33] Batch [10]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.107904,	
2017-06-23 22:28:22,059 Epoch[33] Batch [20]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.102971,	
2017-06-23 22:28:28,211 Epoch[33] Batch [30]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.099026,	
2017-06-23 22:28:34,276 Epoch[33] Batch [40]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100650,	
2017-06-23 22:28:40,654 Epoch[33] Batch [50]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.101529,	
2017-06-23 22:28:47,157 Epoch[33] Batch [60]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.101862,	
2017-06-23 22:28:53,327 Epoch[33] Batch [70]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.101250,	
2017-06-23 22:29:00,053 Epoch[33] Batch [80]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.101485,	
2017-06-23 22:29:06,805 Epoch[33] Batch [90]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.100651,	
2017-06-23 22:29:13,464 Epoch[33] Batch [100]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.100148,	
2017-06-23 22:29:20,333 Epoch[33] Batch [110]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.101823,	
2017-06-23 22:29:26,629 Epoch[33] Batch [120]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.101218,	
2017-06-23 22:29:33,078 Epoch[33] Batch [130]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.100262,	
2017-06-23 22:29:39,095 Epoch[33] Batch [140]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.100447,	
2017-06-23 22:29:45,145 Epoch[33] Batch [150]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100575,	
2017-06-23 22:29:51,223 Epoch[33] Batch [160]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100953,	
2017-06-23 22:29:57,098 Epoch[33] Batch [170]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.101476,	
2017-06-23 22:30:03,066 Epoch[33] Batch [180]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101956,	
2017-06-23 22:30:09,048 Epoch[33] Batch [190]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.101926,	
2017-06-23 22:30:14,947 Epoch[33] Batch [200]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.101362,	
2017-06-23 22:30:20,881 Epoch[33] Batch [210]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101058,	
2017-06-23 22:30:26,815 Epoch[33] Batch [220]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101133,	
2017-06-23 22:30:32,818 Epoch[33] Batch [230]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.100897,	
2017-06-23 22:30:38,841 Epoch[33] Batch [240]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.101098,	
2017-06-23 22:30:44,834 Epoch[33] Batch [250]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.100993,	
2017-06-23 22:30:50,833 Epoch[33] Batch [260]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.100881,	
2017-06-23 22:30:56,721 Epoch[33] Batch [270]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.100411,	
2017-06-23 22:31:02,649 Epoch[33] Batch [280]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.100920,	
2017-06-23 22:31:08,662 Epoch[33] Batch [290]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101238,	
2017-06-23 22:31:14,580 Epoch[33] Batch [300]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101695,	
2017-06-23 22:31:20,451 Epoch[33] Batch [310]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.101537,	
2017-06-23 22:31:26,384 Epoch[33] Batch [320]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101356,	
2017-06-23 22:31:32,311 Epoch[33] Batch [330]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.101252,	
2017-06-23 22:31:38,330 Epoch[33] Batch [340]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101255,	
2017-06-23 22:31:44,626 Epoch[33] Batch [350]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.100807,	
2017-06-23 22:31:50,502 Epoch[33] Batch [360]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.100706,	
2017-06-23 22:31:56,501 Epoch[33] Batch [370]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.100705,	
2017-06-23 22:32:02,506 Epoch[33] Batch [380]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.100565,	
2017-06-23 22:32:08,536 Epoch[33] Batch [390]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100323,	
2017-06-23 22:32:14,641 Epoch[33] Batch [400]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100205,	
2017-06-23 22:32:20,291 Epoch[33] Batch [410]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.100358,	
2017-06-23 22:32:26,108 Epoch[33] Batch [420]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101086,	
2017-06-23 22:32:32,040 Epoch[33] Batch [430]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101901,	
2017-06-23 22:32:37,939 Epoch[33] Batch [440]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.102084,	
2017-06-23 22:32:44,021 Epoch[33] Batch [450]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102422,	
2017-06-23 22:32:49,989 Epoch[33] Batch [460]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.102388,	
2017-06-23 22:32:56,265 Epoch[33] Batch [470]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.102286,	
2017-06-23 22:33:02,631 Epoch[33] Batch [480]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.102311,	
2017-06-23 22:33:08,758 Epoch[33] Batch [490]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102174,	
2017-06-23 22:33:14,420 Epoch[33] Batch [500]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.102287,	
2017-06-23 22:33:20,482 Epoch[33] Batch [510]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102258,	
2017-06-23 22:33:26,314 Epoch[33] Batch [520]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.102476,	
2017-06-23 22:33:32,247 Epoch[33] Batch [530]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.102552,	
2017-06-23 22:33:38,186 Epoch[33] Batch [540]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.102695,	
2017-06-23 22:33:44,114 Epoch[33] Batch [550]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.102582,	
2017-06-23 22:33:50,158 Epoch[33] Batch [560]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102384,	
2017-06-23 22:33:56,530 Epoch[33] Batch [570]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.102478,	
2017-06-23 22:34:02,451 Epoch[33] Batch [580]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.102385,	
2017-06-23 22:34:08,418 Epoch[33] Batch [590]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.102348,	
2017-06-23 22:34:14,505 Epoch[33] Batch [600]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102214,	
2017-06-23 22:34:20,317 Epoch[33] Batch [610]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102079,	
2017-06-23 22:34:26,328 Epoch[33] Batch [620]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102054,	
2017-06-23 22:34:32,461 Epoch[33] Batch [630]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101958,	
2017-06-23 22:34:38,507 Epoch[33] Batch [640]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.101899,	
2017-06-23 22:34:44,427 Epoch[33] Batch [650]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101954,	
2017-06-23 22:34:50,341 Epoch[33] Batch [660]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101912,	
2017-06-23 22:34:56,312 Epoch[33] Batch [670]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101995,	
2017-06-23 22:35:02,277 Epoch[33] Batch [680]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.101884,	
2017-06-23 22:35:08,236 Epoch[33] Batch [690]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.101811,	
2017-06-23 22:35:14,139 Epoch[33] Batch [700]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.101759,	
2017-06-23 22:35:20,128 Epoch[33] Batch [710]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.101657,	
2017-06-23 22:35:25,979 Epoch[33] Batch [720]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.101593,	
2017-06-23 22:35:32,114 Epoch[33] Batch [730]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101425,	
2017-06-23 22:35:38,186 Epoch[33] Batch [740]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101482,	
2017-06-23 22:35:44,703 Epoch[33] Batch [750]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.101310,	
2017-06-23 22:35:51,030 Epoch[33] Batch [760]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.101191,	
2017-06-23 22:35:57,327 Epoch[33] Batch [770]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.101130,	
2017-06-23 22:36:03,437 Epoch[33] Batch [780]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101068,	
2017-06-23 22:36:09,765 Epoch[33] Batch [790]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.100838,	
2017-06-23 22:36:15,707 Epoch[33] Batch [800]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.100914,	
2017-06-23 22:36:21,645 Epoch[33] Batch [810]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.100911,	
2017-06-23 22:36:27,602 Epoch[33] Batch [820]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.100972,	
2017-06-23 22:36:33,690 Epoch[33] Batch [830]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100838,	
2017-06-23 22:36:39,608 Epoch[33] Batch [840]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.100845,	
2017-06-23 22:36:45,870 Epoch[33] Batch [850]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.100806,	
2017-06-23 22:36:52,059 Epoch[33] Batch [860]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.100931,	
2017-06-23 22:36:58,386 Epoch[33] Batch [870]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.100882,	
2017-06-23 22:37:04,451 Epoch[33] Batch [880]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100877,	
2017-06-23 22:37:10,713 Epoch[33] Batch [890]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.100894,	
2017-06-23 22:37:16,952 Epoch[33] Batch [900]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.100736,	
2017-06-23 22:37:22,846 Epoch[33] Batch [910]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.100650,	
2017-06-23 22:37:28,938 Epoch[33] Batch [920]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100734,	
2017-06-23 22:37:35,500 Epoch[33] Batch [930]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.100701,	
2017-06-23 22:37:41,880 Epoch[33] Batch [940]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.100753,	
2017-06-23 22:37:48,699 Epoch[33] Batch [950]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.100629,	
2017-06-23 22:37:54,962 Epoch[33] Batch [960]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.100791,	
2017-06-23 22:38:01,711 Epoch[33] Batch [970]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.100790,	
2017-06-23 22:38:08,168 Epoch[33] Batch [980]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.100619,	
2017-06-23 22:38:15,464 Epoch[33] Batch [990]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.100609,	
2017-06-23 22:38:22,436 Epoch[33] Batch [1000]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.100479,	
2017-06-23 22:38:29,279 Epoch[33] Batch [1010]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.100464,	
2017-06-23 22:38:35,524 Epoch[33] Batch [1020]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.100398,	
2017-06-23 22:38:42,057 Epoch[33] Batch [1030]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.100375,	
2017-06-23 22:38:48,511 Epoch[33] Batch [1040]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.100365,	
2017-06-23 22:38:55,131 Epoch[33] Batch [1050]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.100288,	
2017-06-23 22:39:01,593 Epoch[33] Batch [1060]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.100317,	
2017-06-23 22:39:07,998 Epoch[33] Batch [1070]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.100332,	
2017-06-23 22:39:14,355 Epoch[33] Batch [1080]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.100392,	
2017-06-23 22:39:20,773 Epoch[33] Batch [1090]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.100550,	
2017-06-23 22:39:27,104 Epoch[33] Batch [1100]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.100966,	
2017-06-23 22:39:33,667 Epoch[33] Batch [1110]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.101252,	
2017-06-23 22:39:40,570 Epoch[33] Batch [1120]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.101496,	
2017-06-23 22:39:47,567 Epoch[33] Batch [1130]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.101563,	
2017-06-23 22:39:54,502 Epoch[33] Batch [1140]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.101634,	
2017-06-23 22:40:00,917 Epoch[33] Batch [1150]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.101738,	
2017-06-23 22:40:07,703 Epoch[33] Batch [1160]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.101798,	
2017-06-23 22:40:14,359 Epoch[33] Batch [1170]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.101812,	
2017-06-23 22:40:21,239 Epoch[33] Batch [1180]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.101908,	
2017-06-23 22:40:28,213 Epoch[33] Batch [1190]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.101893,	
2017-06-23 22:40:35,798 Epoch[33] Batch [1200]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.101993,	
2017-06-23 22:40:43,149 Epoch[33] Batch [1210]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.101981,	
2017-06-23 22:40:49,816 Epoch[33] Batch [1220]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.102058,	
2017-06-23 22:40:56,833 Epoch[33] Batch [1230]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.102029,	
2017-06-23 22:41:03,878 Epoch[33] Batch [1240]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.102113,	
2017-06-23 22:41:11,232 Epoch[33] Batch [1250]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.102157,	
2017-06-23 22:41:18,190 Epoch[33] Batch [1260]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.102160,	
2017-06-23 22:41:25,065 Epoch[33] Batch [1270]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.102150,	
2017-06-23 22:41:32,114 Epoch[33] Batch [1280]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.102153,	
2017-06-23 22:41:39,207 Epoch[33] Batch [1290]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.102155,	
2017-06-23 22:41:46,014 Epoch[33] Batch [1300]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.102138,	
2017-06-23 22:41:52,910 Epoch[33] Batch [1310]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.102116,	
2017-06-23 22:41:59,365 Epoch[33] Batch [1320]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.102124,	
2017-06-23 22:42:05,436 Epoch[33] Batch [1330]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102145,	
2017-06-23 22:42:12,356 Epoch[33] Batch [1340]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.102102,	
2017-06-23 22:42:18,773 Epoch[33] Batch [1350]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.102071,	
2017-06-23 22:42:25,085 Epoch[33] Batch [1360]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.102073,	
2017-06-23 22:42:31,034 Epoch[33] Batch [1370]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.102086,	
2017-06-23 22:42:37,029 Epoch[33] Batch [1380]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102025,	
2017-06-23 22:42:43,080 Epoch[33] Batch [1390]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102061,	
2017-06-23 22:42:49,081 Epoch[33] Batch [1400]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102082,	
2017-06-23 22:42:55,110 Epoch[33] Batch [1410]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102137,	
2017-06-23 22:43:00,974 Epoch[33] Batch [1420]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.102208,	
2017-06-23 22:43:06,934 Epoch[33] Batch [1430]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.102238,	
2017-06-23 22:43:12,865 Epoch[33] Batch [1440]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.102345,	
2017-06-23 22:43:18,845 Epoch[33] Batch [1450]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102305,	
2017-06-23 22:43:24,825 Epoch[33] Batch [1460]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102539,	
2017-06-23 22:43:30,778 Epoch[33] Batch [1470]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.102552,	
2017-06-23 22:43:36,726 Epoch[33] Batch [1480]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.102538,	
2017-06-23 22:43:40,082 Epoch[33] Train-FCNLogLoss=0.102542
2017-06-23 22:43:40,082 Epoch[33] Time cost=932.032
2017-06-23 22:43:41,177 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0034.params"
2017-06-23 22:43:45,116 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0034.states"
2017-06-23 22:43:52,131 Epoch[34] Batch [10]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102286,	
2017-06-23 22:43:58,491 Epoch[34] Batch [20]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.108114,	
2017-06-23 22:44:05,033 Epoch[34] Batch [30]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.104202,	
2017-06-23 22:44:11,407 Epoch[34] Batch [40]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.103983,	
2017-06-23 22:44:18,031 Epoch[34] Batch [50]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.103164,	
2017-06-23 22:44:24,448 Epoch[34] Batch [60]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.104445,	
2017-06-23 22:44:30,630 Epoch[34] Batch [70]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.103768,	
2017-06-23 22:44:37,018 Epoch[34] Batch [80]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.103436,	
2017-06-23 22:44:43,308 Epoch[34] Batch [90]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.102842,	
2017-06-23 22:44:49,637 Epoch[34] Batch [100]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.102478,	
2017-06-23 22:44:56,092 Epoch[34] Batch [110]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.103364,	
2017-06-23 22:45:02,400 Epoch[34] Batch [120]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.103506,	
2017-06-23 22:45:08,563 Epoch[34] Batch [130]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.103579,	
2017-06-23 22:45:14,814 Epoch[34] Batch [140]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.103382,	
2017-06-23 22:45:21,035 Epoch[34] Batch [150]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.102488,	
2017-06-23 22:45:27,251 Epoch[34] Batch [160]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.102380,	
2017-06-23 22:45:33,565 Epoch[34] Batch [170]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.101879,	
2017-06-23 22:45:40,002 Epoch[34] Batch [180]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.101707,	
2017-06-23 22:45:45,888 Epoch[34] Batch [190]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.101782,	
2017-06-23 22:45:52,025 Epoch[34] Batch [200]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101624,	
2017-06-23 22:45:57,832 Epoch[34] Batch [210]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.101326,	
2017-06-23 22:46:03,707 Epoch[34] Batch [220]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.101757,	
2017-06-23 22:46:09,539 Epoch[34] Batch [230]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101603,	
2017-06-23 22:46:15,417 Epoch[34] Batch [240]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.101352,	
2017-06-23 22:46:21,386 Epoch[34] Batch [250]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.101323,	
2017-06-23 22:46:27,336 Epoch[34] Batch [260]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.100889,	
2017-06-23 22:46:33,249 Epoch[34] Batch [270]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.101121,	
2017-06-23 22:46:39,177 Epoch[34] Batch [280]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.100711,	
2017-06-23 22:46:45,186 Epoch[34] Batch [290]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.100504,	
2017-06-23 22:46:51,104 Epoch[34] Batch [300]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.099901,	
2017-06-23 22:46:57,026 Epoch[34] Batch [310]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.099683,	
2017-06-23 22:47:03,036 Epoch[34] Batch [320]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.099814,	
2017-06-23 22:47:08,912 Epoch[34] Batch [330]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.100047,	
2017-06-23 22:47:15,199 Epoch[34] Batch [340]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.100470,	
2017-06-23 22:47:21,880 Epoch[34] Batch [350]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.100313,	
2017-06-23 22:47:28,333 Epoch[34] Batch [360]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.100252,	
2017-06-23 22:47:34,654 Epoch[34] Batch [370]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.100329,	
2017-06-23 22:47:41,113 Epoch[34] Batch [380]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.100003,	
2017-06-23 22:47:47,712 Epoch[34] Batch [390]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.099889,	
2017-06-23 22:47:54,194 Epoch[34] Batch [400]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.100473,	
2017-06-23 22:48:01,164 Epoch[34] Batch [410]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.100154,	
2017-06-23 22:48:07,189 Epoch[34] Batch [420]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.100113,	
2017-06-23 22:48:13,568 Epoch[34] Batch [430]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.100042,	
2017-06-23 22:48:20,020 Epoch[34] Batch [440]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.099868,	
2017-06-23 22:48:26,526 Epoch[34] Batch [450]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.099878,	
2017-06-23 22:48:33,112 Epoch[34] Batch [460]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.099591,	
2017-06-23 22:48:39,495 Epoch[34] Batch [470]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.099355,	
2017-06-23 22:48:45,945 Epoch[34] Batch [480]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.099169,	
2017-06-23 22:48:52,199 Epoch[34] Batch [490]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.099150,	
2017-06-23 22:48:58,758 Epoch[34] Batch [500]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.098973,	
2017-06-23 22:49:04,813 Epoch[34] Batch [510]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098817,	
2017-06-23 22:49:10,795 Epoch[34] Batch [520]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.098764,	
2017-06-23 22:49:16,783 Epoch[34] Batch [530]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.098628,	
2017-06-23 22:49:22,602 Epoch[34] Batch [540]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.098752,	
2017-06-23 22:49:28,721 Epoch[34] Batch [550]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098582,	
2017-06-23 22:49:34,681 Epoch[34] Batch [560]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.098583,	
2017-06-23 22:49:40,578 Epoch[34] Batch [570]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.098751,	
2017-06-23 22:49:46,498 Epoch[34] Batch [580]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.098652,	
2017-06-23 22:49:52,339 Epoch[34] Batch [590]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.098744,	
2017-06-23 22:49:58,334 Epoch[34] Batch [600]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.098822,	
2017-06-23 22:50:04,258 Epoch[34] Batch [610]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.098803,	
2017-06-23 22:50:10,221 Epoch[34] Batch [620]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.098843,	
2017-06-23 22:50:16,188 Epoch[34] Batch [630]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.098756,	
2017-06-23 22:50:22,154 Epoch[34] Batch [640]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.098496,	
2017-06-23 22:50:28,199 Epoch[34] Batch [650]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098327,	
2017-06-23 22:50:34,215 Epoch[34] Batch [660]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.098443,	
2017-06-23 22:50:40,552 Epoch[34] Batch [670]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.098328,	
2017-06-23 22:50:46,939 Epoch[34] Batch [680]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.098235,	
2017-06-23 22:50:53,816 Epoch[34] Batch [690]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.098329,	
2017-06-23 22:51:00,555 Epoch[34] Batch [700]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.098269,	
2017-06-23 22:51:06,986 Epoch[34] Batch [710]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.098247,	
2017-06-23 22:51:13,645 Epoch[34] Batch [720]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.098227,	
2017-06-23 22:51:20,734 Epoch[34] Batch [730]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.098144,	
2017-06-23 22:51:27,798 Epoch[34] Batch [740]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.098240,	
2017-06-23 22:51:35,004 Epoch[34] Batch [750]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.098232,	
2017-06-23 22:51:41,703 Epoch[34] Batch [760]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.098094,	
2017-06-23 22:51:48,475 Epoch[34] Batch [770]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.098144,	
2017-06-23 22:51:55,183 Epoch[34] Batch [780]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.098064,	
2017-06-23 22:52:01,736 Epoch[34] Batch [790]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.098070,	
2017-06-23 22:52:07,536 Epoch[34] Batch [800]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098125,	
2017-06-23 22:52:13,937 Epoch[34] Batch [810]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.098312,	
2017-06-23 22:52:20,178 Epoch[34] Batch [820]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.098189,	
2017-06-23 22:52:26,285 Epoch[34] Batch [830]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098216,	
2017-06-23 22:52:32,671 Epoch[34] Batch [840]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.098240,	
2017-06-23 22:52:38,689 Epoch[34] Batch [850]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.098341,	
2017-06-23 22:52:45,420 Epoch[34] Batch [860]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.098334,	
2017-06-23 22:52:51,461 Epoch[34] Batch [870]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098349,	
2017-06-23 22:52:57,563 Epoch[34] Batch [880]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098453,	
2017-06-23 22:53:04,062 Epoch[34] Batch [890]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.098444,	
2017-06-23 22:53:10,543 Epoch[34] Batch [900]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.098445,	
2017-06-23 22:53:16,747 Epoch[34] Batch [910]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.098469,	
2017-06-23 22:53:22,824 Epoch[34] Batch [920]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098406,	
2017-06-23 22:53:28,948 Epoch[34] Batch [930]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098352,	
2017-06-23 22:53:35,642 Epoch[34] Batch [940]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.098466,	
2017-06-23 22:53:42,457 Epoch[34] Batch [950]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.098432,	
2017-06-23 22:53:48,862 Epoch[34] Batch [960]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.098395,	
2017-06-23 22:53:55,356 Epoch[34] Batch [970]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.098415,	
2017-06-23 22:54:02,360 Epoch[34] Batch [980]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.098329,	
2017-06-23 22:54:08,682 Epoch[34] Batch [990]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.098322,	
2017-06-23 22:54:15,159 Epoch[34] Batch [1000]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.098318,	
2017-06-23 22:54:21,570 Epoch[34] Batch [1010]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.098217,	
2017-06-23 22:54:27,957 Epoch[34] Batch [1020]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.098316,	
2017-06-23 22:54:34,751 Epoch[34] Batch [1030]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.098361,	
2017-06-23 22:54:41,292 Epoch[34] Batch [1040]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.098256,	
2017-06-23 22:54:48,026 Epoch[34] Batch [1050]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.098226,	
2017-06-23 22:54:54,500 Epoch[34] Batch [1060]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.098243,	
2017-06-23 22:55:00,999 Epoch[34] Batch [1070]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.098162,	
2017-06-23 22:55:07,433 Epoch[34] Batch [1080]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.098136,	
2017-06-23 22:55:13,683 Epoch[34] Batch [1090]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.098086,	
2017-06-23 22:55:19,965 Epoch[34] Batch [1100]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.098139,	
2017-06-23 22:55:25,951 Epoch[34] Batch [1110]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.098062,	
2017-06-23 22:55:31,794 Epoch[34] Batch [1120]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.098090,	
2017-06-23 22:55:37,076 Epoch[34] Batch [1130]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098045,	
2017-06-23 22:55:42,697 Epoch[34] Batch [1140]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.098034,	
2017-06-23 22:55:47,911 Epoch[34] Batch [1150]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.098025,	
2017-06-23 22:55:53,155 Epoch[34] Batch [1160]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097971,	
2017-06-23 22:55:58,316 Epoch[34] Batch [1170]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097938,	
2017-06-23 22:56:03,498 Epoch[34] Batch [1180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097867,	
2017-06-23 22:56:08,512 Epoch[34] Batch [1190]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.097830,	
2017-06-23 22:56:13,764 Epoch[34] Batch [1200]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097831,	
2017-06-23 22:56:19,109 Epoch[34] Batch [1210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097784,	
2017-06-23 22:56:24,868 Epoch[34] Batch [1220]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.097837,	
2017-06-23 22:56:29,994 Epoch[34] Batch [1230]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.097870,	
2017-06-23 22:56:35,221 Epoch[34] Batch [1240]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097828,	
2017-06-23 22:56:40,398 Epoch[34] Batch [1250]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.097771,	
2017-06-23 22:56:45,623 Epoch[34] Batch [1260]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.097737,	
2017-06-23 22:56:50,856 Epoch[34] Batch [1270]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097727,	
2017-06-23 22:56:56,001 Epoch[34] Batch [1280]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.097728,	
2017-06-23 22:57:01,228 Epoch[34] Batch [1290]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097701,	
2017-06-23 22:57:06,488 Epoch[34] Batch [1300]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097661,	
2017-06-23 22:57:11,688 Epoch[34] Batch [1310]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.097643,	
2017-06-23 22:57:16,868 Epoch[34] Batch [1320]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097639,	
2017-06-23 22:57:22,107 Epoch[34] Batch [1330]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097540,	
2017-06-23 22:57:27,301 Epoch[34] Batch [1340]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.097469,	
2017-06-23 22:57:32,462 Epoch[34] Batch [1350]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097420,	
2017-06-23 22:57:37,753 Epoch[34] Batch [1360]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097381,	
2017-06-23 22:57:42,897 Epoch[34] Batch [1370]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.097405,	
2017-06-23 22:57:48,129 Epoch[34] Batch [1380]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097402,	
2017-06-23 22:57:53,288 Epoch[34] Batch [1390]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.097384,	
2017-06-23 22:57:58,507 Epoch[34] Batch [1400]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.097322,	
2017-06-23 22:58:03,703 Epoch[34] Batch [1410]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.097315,	
2017-06-23 22:58:08,948 Epoch[34] Batch [1420]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097301,	
2017-06-23 22:58:14,132 Epoch[34] Batch [1430]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097288,	
2017-06-23 22:58:19,386 Epoch[34] Batch [1440]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.097292,	
2017-06-23 22:58:24,563 Epoch[34] Batch [1450]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.097344,	
2017-06-23 22:58:29,766 Epoch[34] Batch [1460]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.097299,	
2017-06-23 22:58:35,006 Epoch[34] Batch [1470]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.097266,	
2017-06-23 22:58:40,201 Epoch[34] Batch [1480]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.097331,	
2017-06-23 22:58:43,298 Epoch[34] Train-FCNLogLoss=0.097324
2017-06-23 22:58:43,298 Epoch[34] Time cost=898.182
2017-06-23 22:58:44,314 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0035.params"
2017-06-23 22:58:47,725 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0035.states"
2017-06-23 22:58:53,848 Epoch[35] Batch [10]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.102485,	
2017-06-23 22:58:59,097 Epoch[35] Batch [20]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096853,	
2017-06-23 22:59:04,312 Epoch[35] Batch [30]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094781,	
2017-06-23 22:59:09,498 Epoch[35] Batch [40]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.096287,	
2017-06-23 22:59:14,785 Epoch[35] Batch [50]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.100120,	
2017-06-23 22:59:20,032 Epoch[35] Batch [60]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098371,	
2017-06-23 22:59:25,222 Epoch[35] Batch [70]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.098430,	
2017-06-23 22:59:30,493 Epoch[35] Batch [80]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099590,	
2017-06-23 22:59:35,637 Epoch[35] Batch [90]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.099114,	
2017-06-23 22:59:40,929 Epoch[35] Batch [100]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097723,	
2017-06-23 22:59:46,102 Epoch[35] Batch [110]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.096992,	
2017-06-23 22:59:51,284 Epoch[35] Batch [120]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.096601,	
2017-06-23 22:59:56,538 Epoch[35] Batch [130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096175,	
2017-06-23 23:00:01,770 Epoch[35] Batch [140]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.095762,	
2017-06-23 23:00:06,980 Epoch[35] Batch [150]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095561,	
2017-06-23 23:00:12,190 Epoch[35] Batch [160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095216,	
2017-06-23 23:00:17,366 Epoch[35] Batch [170]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095207,	
2017-06-23 23:00:22,570 Epoch[35] Batch [180]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095224,	
2017-06-23 23:00:27,876 Epoch[35] Batch [190]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095055,	
2017-06-23 23:00:33,013 Epoch[35] Batch [200]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.095304,	
2017-06-23 23:00:38,248 Epoch[35] Batch [210]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.095362,	
2017-06-23 23:00:43,470 Epoch[35] Batch [220]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.097032,	
2017-06-23 23:00:48,719 Epoch[35] Batch [230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096838,	
2017-06-23 23:00:53,929 Epoch[35] Batch [240]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.097082,	
2017-06-23 23:00:59,178 Epoch[35] Batch [250]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097063,	
2017-06-23 23:01:04,396 Epoch[35] Batch [260]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096902,	
2017-06-23 23:01:09,658 Epoch[35] Batch [270]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.097264,	
2017-06-23 23:01:14,891 Epoch[35] Batch [280]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097187,	
2017-06-23 23:01:20,109 Epoch[35] Batch [290]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.097052,	
2017-06-23 23:01:25,333 Epoch[35] Batch [300]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.096751,	
2017-06-23 23:01:30,548 Epoch[35] Batch [310]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.097085,	
2017-06-23 23:01:35,805 Epoch[35] Batch [320]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096925,	
2017-06-23 23:01:41,084 Epoch[35] Batch [330]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096872,	
2017-06-23 23:01:46,262 Epoch[35] Batch [340]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.096786,	
2017-06-23 23:01:51,478 Epoch[35] Batch [350]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096724,	
2017-06-23 23:01:56,666 Epoch[35] Batch [360]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.096751,	
2017-06-23 23:02:01,887 Epoch[35] Batch [370]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.097176,	
2017-06-23 23:02:07,138 Epoch[35] Batch [380]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097138,	
2017-06-23 23:02:12,371 Epoch[35] Batch [390]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.097152,	
2017-06-23 23:02:17,583 Epoch[35] Batch [400]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.097097,	
2017-06-23 23:02:22,789 Epoch[35] Batch [410]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.096785,	
2017-06-23 23:02:28,018 Epoch[35] Batch [420]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.096588,	
2017-06-23 23:02:33,250 Epoch[35] Batch [430]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.096315,	
2017-06-23 23:02:38,458 Epoch[35] Batch [440]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.096342,	
2017-06-23 23:02:43,670 Epoch[35] Batch [450]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096198,	
2017-06-23 23:02:48,944 Epoch[35] Batch [460]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096114,	
2017-06-23 23:02:54,097 Epoch[35] Batch [470]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.096231,	
2017-06-23 23:02:59,293 Epoch[35] Batch [480]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.096438,	
2017-06-23 23:03:04,498 Epoch[35] Batch [490]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.096374,	
2017-06-23 23:03:09,749 Epoch[35] Batch [500]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096382,	
2017-06-23 23:03:14,971 Epoch[35] Batch [510]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.096333,	
2017-06-23 23:03:20,199 Epoch[35] Batch [520]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.096191,	
2017-06-23 23:03:25,422 Epoch[35] Batch [530]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.096253,	
2017-06-23 23:03:30,595 Epoch[35] Batch [540]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.096205,	
2017-06-23 23:03:35,807 Epoch[35] Batch [550]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.096366,	
2017-06-23 23:03:41,078 Epoch[35] Batch [560]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.096470,	
2017-06-23 23:03:46,296 Epoch[35] Batch [570]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096391,	
2017-06-23 23:03:51,508 Epoch[35] Batch [580]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.096448,	
2017-06-23 23:03:56,756 Epoch[35] Batch [590]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096338,	
2017-06-23 23:04:01,943 Epoch[35] Batch [600]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.096200,	
2017-06-23 23:04:07,123 Epoch[35] Batch [610]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.096297,	
2017-06-23 23:04:12,359 Epoch[35] Batch [620]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.096391,	
2017-06-23 23:04:17,606 Epoch[35] Batch [630]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.096320,	
2017-06-23 23:04:22,892 Epoch[35] Batch [640]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096272,	
2017-06-23 23:04:28,151 Epoch[35] Batch [650]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096333,	
2017-06-23 23:04:33,307 Epoch[35] Batch [660]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.096504,	
2017-06-23 23:04:38,534 Epoch[35] Batch [670]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.096312,	
2017-06-23 23:04:43,752 Epoch[35] Batch [680]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.096279,	
2017-06-23 23:04:48,955 Epoch[35] Batch [690]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.096097,	
2017-06-23 23:04:54,403 Epoch[35] Batch [700]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.095933,	
2017-06-23 23:04:59,572 Epoch[35] Batch [710]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.095985,	
2017-06-23 23:05:04,828 Epoch[35] Batch [720]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096825,	
2017-06-23 23:05:10,032 Epoch[35] Batch [730]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.097261,	
2017-06-23 23:05:15,643 Epoch[35] Batch [740]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.097594,	
2017-06-23 23:05:21,347 Epoch[35] Batch [750]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.097694,	
2017-06-23 23:05:26,839 Epoch[35] Batch [760]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.097920,	
2017-06-23 23:05:31,990 Epoch[35] Batch [770]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.098201,	
2017-06-23 23:05:37,184 Epoch[35] Batch [780]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098422,	
2017-06-23 23:05:42,379 Epoch[35] Batch [790]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098800,	
2017-06-23 23:05:47,628 Epoch[35] Batch [800]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098913,	
2017-06-23 23:05:52,862 Epoch[35] Batch [810]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099097,	
2017-06-23 23:05:58,058 Epoch[35] Batch [820]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.099298,	
2017-06-23 23:06:03,281 Epoch[35] Batch [830]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099511,	
2017-06-23 23:06:08,617 Epoch[35] Batch [840]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.099534,	
2017-06-23 23:06:13,822 Epoch[35] Batch [850]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099534,	
2017-06-23 23:06:19,108 Epoch[35] Batch [860]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099561,	
2017-06-23 23:06:24,301 Epoch[35] Batch [870]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.099565,	
2017-06-23 23:06:29,446 Epoch[35] Batch [880]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.099533,	
2017-06-23 23:06:34,685 Epoch[35] Batch [890]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099581,	
2017-06-23 23:06:39,851 Epoch[35] Batch [900]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.099636,	
2017-06-23 23:06:45,085 Epoch[35] Batch [910]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099608,	
2017-06-23 23:06:50,467 Epoch[35] Batch [920]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.099682,	
2017-06-23 23:06:55,743 Epoch[35] Batch [930]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099715,	
2017-06-23 23:07:00,921 Epoch[35] Batch [940]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.099725,	
2017-06-23 23:07:06,187 Epoch[35] Batch [950]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.099843,	
2017-06-23 23:07:11,365 Epoch[35] Batch [960]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.099731,	
2017-06-23 23:07:16,601 Epoch[35] Batch [970]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099703,	
2017-06-23 23:07:21,782 Epoch[35] Batch [980]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.099720,	
2017-06-23 23:07:27,108 Epoch[35] Batch [990]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099711,	
2017-06-23 23:07:32,314 Epoch[35] Batch [1000]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.099746,	
2017-06-23 23:07:37,426 Epoch[35] Batch [1010]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.099728,	
2017-06-23 23:07:42,894 Epoch[35] Batch [1020]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.099757,	
2017-06-23 23:07:48,130 Epoch[35] Batch [1030]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099870,	
2017-06-23 23:07:53,364 Epoch[35] Batch [1040]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099788,	
2017-06-23 23:07:58,563 Epoch[35] Batch [1050]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099775,	
2017-06-23 23:08:03,816 Epoch[35] Batch [1060]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099846,	
2017-06-23 23:08:09,109 Epoch[35] Batch [1070]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.099908,	
2017-06-23 23:08:14,313 Epoch[35] Batch [1080]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099916,	
2017-06-23 23:08:19,505 Epoch[35] Batch [1090]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.099848,	
2017-06-23 23:08:24,712 Epoch[35] Batch [1100]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.099824,	
2017-06-23 23:08:29,928 Epoch[35] Batch [1110]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.099852,	
2017-06-23 23:08:35,184 Epoch[35] Batch [1120]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099934,	
2017-06-23 23:08:40,359 Epoch[35] Batch [1130]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.099992,	
2017-06-23 23:08:45,573 Epoch[35] Batch [1140]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.100000,	
2017-06-23 23:08:50,825 Epoch[35] Batch [1150]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.099946,	
2017-06-23 23:08:56,004 Epoch[35] Batch [1160]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.099907,	
2017-06-23 23:09:01,185 Epoch[35] Batch [1170]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.100000,	
2017-06-23 23:09:06,419 Epoch[35] Batch [1180]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099982,	
2017-06-23 23:09:11,644 Epoch[35] Batch [1190]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099917,	
2017-06-23 23:09:16,590 Epoch[35] Batch [1200]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.099931,	
2017-06-23 23:09:22,504 Epoch[35] Batch [1210]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.099854,	
2017-06-23 23:09:27,705 Epoch[35] Batch [1220]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099837,	
2017-06-23 23:09:32,856 Epoch[35] Batch [1230]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.099801,	
2017-06-23 23:09:38,053 Epoch[35] Batch [1240]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.099869,	
2017-06-23 23:09:43,286 Epoch[35] Batch [1250]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099816,	
2017-06-23 23:09:48,479 Epoch[35] Batch [1260]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.099762,	
2017-06-23 23:09:53,713 Epoch[35] Batch [1270]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099701,	
2017-06-23 23:09:58,945 Epoch[35] Batch [1280]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.099697,	
2017-06-23 23:10:04,170 Epoch[35] Batch [1290]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099626,	
2017-06-23 23:10:09,388 Epoch[35] Batch [1300]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.099615,	
2017-06-23 23:10:14,649 Epoch[35] Batch [1310]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.099512,	
2017-06-23 23:10:19,880 Epoch[35] Batch [1320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.099627,	
2017-06-23 23:10:25,080 Epoch[35] Batch [1330]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099637,	
2017-06-23 23:10:30,345 Epoch[35] Batch [1340]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.099646,	
2017-06-23 23:10:35,565 Epoch[35] Batch [1350]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.099635,	
2017-06-23 23:10:40,776 Epoch[35] Batch [1360]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.099682,	
2017-06-23 23:10:45,963 Epoch[35] Batch [1370]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.099713,	
2017-06-23 23:10:51,127 Epoch[35] Batch [1380]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.099663,	
2017-06-23 23:10:56,443 Epoch[35] Batch [1390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099640,	
2017-06-23 23:11:01,689 Epoch[35] Batch [1400]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.099556,	
2017-06-23 23:11:07,043 Epoch[35] Batch [1410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.099516,	
2017-06-23 23:11:12,245 Epoch[35] Batch [1420]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099439,	
2017-06-23 23:11:17,431 Epoch[35] Batch [1430]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.099369,	
2017-06-23 23:11:22,754 Epoch[35] Batch [1440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099257,	
2017-06-23 23:11:27,898 Epoch[35] Batch [1450]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.099207,	
2017-06-23 23:11:33,176 Epoch[35] Batch [1460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.099218,	
2017-06-23 23:11:38,431 Epoch[35] Batch [1470]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099249,	
2017-06-23 23:11:43,561 Epoch[35] Batch [1480]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.099257,	
2017-06-23 23:11:46,675 Epoch[35] Train-FCNLogLoss=0.099243
2017-06-23 23:11:46,676 Epoch[35] Time cost=778.950
2017-06-23 23:11:47,613 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0036.params"
2017-06-23 23:11:51,280 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0036.states"
2017-06-23 23:11:57,539 Epoch[36] Batch [10]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.104707,	
2017-06-23 23:12:02,854 Epoch[36] Batch [20]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098379,	
2017-06-23 23:12:07,980 Epoch[36] Batch [30]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.105362,	
2017-06-23 23:12:13,241 Epoch[36] Batch [40]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.105604,	
2017-06-23 23:12:18,396 Epoch[36] Batch [50]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.101916,	
2017-06-23 23:12:23,628 Epoch[36] Batch [60]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.099213,	
2017-06-23 23:12:28,865 Epoch[36] Batch [70]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099058,	
2017-06-23 23:12:34,064 Epoch[36] Batch [80]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.098732,	
2017-06-23 23:12:39,619 Epoch[36] Batch [90]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.098344,	
2017-06-23 23:12:44,724 Epoch[36] Batch [100]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.097522,	
2017-06-23 23:12:49,900 Epoch[36] Batch [110]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.097174,	
2017-06-23 23:12:55,220 Epoch[36] Batch [120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096653,	
2017-06-23 23:13:00,355 Epoch[36] Batch [130]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.096345,	
2017-06-23 23:13:05,548 Epoch[36] Batch [140]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.096161,	
2017-06-23 23:13:10,829 Epoch[36] Batch [150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096197,	
2017-06-23 23:13:16,022 Epoch[36] Batch [160]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.096124,	
2017-06-23 23:13:21,212 Epoch[36] Batch [170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095507,	
2017-06-23 23:13:26,532 Epoch[36] Batch [180]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095692,	
2017-06-23 23:13:31,645 Epoch[36] Batch [190]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.095168,	
2017-06-23 23:13:36,870 Epoch[36] Batch [200]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094774,	
2017-06-23 23:13:42,102 Epoch[36] Batch [210]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.095021,	
2017-06-23 23:13:47,301 Epoch[36] Batch [220]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095058,	
2017-06-23 23:13:52,593 Epoch[36] Batch [230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095294,	
2017-06-23 23:13:57,707 Epoch[36] Batch [240]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.095515,	
2017-06-23 23:14:02,945 Epoch[36] Batch [250]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.095458,	
2017-06-23 23:14:08,120 Epoch[36] Batch [260]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095404,	
2017-06-23 23:14:13,327 Epoch[36] Batch [270]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095342,	
2017-06-23 23:14:18,529 Epoch[36] Batch [280]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095137,	
2017-06-23 23:14:23,719 Epoch[36] Batch [290]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095251,	
2017-06-23 23:14:28,887 Epoch[36] Batch [300]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.095246,	
2017-06-23 23:14:34,105 Epoch[36] Batch [310]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.095040,	
2017-06-23 23:14:39,334 Epoch[36] Batch [320]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.095324,	
2017-06-23 23:14:44,536 Epoch[36] Batch [330]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095476,	
2017-06-23 23:14:49,844 Epoch[36] Batch [340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095399,	
2017-06-23 23:14:55,036 Epoch[36] Batch [350]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095196,	
2017-06-23 23:15:00,259 Epoch[36] Batch [360]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.095105,	
2017-06-23 23:15:05,440 Epoch[36] Batch [370]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094921,	
2017-06-23 23:15:10,519 Epoch[36] Batch [380]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.094858,	
2017-06-23 23:15:15,700 Epoch[36] Batch [390]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.095002,	
2017-06-23 23:15:20,957 Epoch[36] Batch [400]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094965,	
2017-06-23 23:15:26,167 Epoch[36] Batch [410]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095065,	
2017-06-23 23:15:31,572 Epoch[36] Batch [420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.095023,	
2017-06-23 23:15:37,117 Epoch[36] Batch [430]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.095002,	
2017-06-23 23:15:42,560 Epoch[36] Batch [440]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.095244,	
2017-06-23 23:15:47,889 Epoch[36] Batch [450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095405,	
2017-06-23 23:15:53,041 Epoch[36] Batch [460]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.095475,	
2017-06-23 23:15:58,718 Epoch[36] Batch [470]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.095444,	
2017-06-23 23:16:04,665 Epoch[36] Batch [480]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.095537,	
2017-06-23 23:16:10,177 Epoch[36] Batch [490]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.095513,	
2017-06-23 23:16:15,523 Epoch[36] Batch [500]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095428,	
2017-06-23 23:16:21,232 Epoch[36] Batch [510]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.095646,	
2017-06-23 23:16:26,475 Epoch[36] Batch [520]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.095697,	
2017-06-23 23:16:31,836 Epoch[36] Batch [530]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095694,	
2017-06-23 23:16:37,402 Epoch[36] Batch [540]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.095724,	
2017-06-23 23:16:42,805 Epoch[36] Batch [550]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.095616,	
2017-06-23 23:16:48,115 Epoch[36] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095604,	
2017-06-23 23:16:53,674 Epoch[36] Batch [570]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.095479,	
2017-06-23 23:16:59,333 Epoch[36] Batch [580]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.095502,	
2017-06-23 23:17:04,342 Epoch[36] Batch [590]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.095465,	
2017-06-23 23:17:09,752 Epoch[36] Batch [600]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.095485,	
2017-06-23 23:17:15,018 Epoch[36] Batch [610]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.095432,	
2017-06-23 23:17:20,396 Epoch[36] Batch [620]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095586,	
2017-06-23 23:17:25,693 Epoch[36] Batch [630]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095445,	
2017-06-23 23:17:31,043 Epoch[36] Batch [640]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095383,	
2017-06-23 23:17:36,419 Epoch[36] Batch [650]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095392,	
2017-06-23 23:17:41,572 Epoch[36] Batch [660]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.095429,	
2017-06-23 23:17:46,864 Epoch[36] Batch [670]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095297,	
2017-06-23 23:17:52,144 Epoch[36] Batch [680]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095394,	
2017-06-23 23:17:57,405 Epoch[36] Batch [690]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.095607,	
2017-06-23 23:18:02,491 Epoch[36] Batch [700]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.095602,	
2017-06-23 23:18:07,555 Epoch[36] Batch [710]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.095552,	
2017-06-23 23:18:12,857 Epoch[36] Batch [720]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095558,	
2017-06-23 23:18:18,070 Epoch[36] Batch [730]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.095419,	
2017-06-23 23:18:23,316 Epoch[36] Batch [740]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.095374,	
2017-06-23 23:18:28,978 Epoch[36] Batch [750]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.095350,	
2017-06-23 23:18:34,753 Epoch[36] Batch [760]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.095263,	
2017-06-23 23:18:40,199 Epoch[36] Batch [770]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.095228,	
2017-06-23 23:18:45,783 Epoch[36] Batch [780]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.095160,	
2017-06-23 23:18:51,239 Epoch[36] Batch [790]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.095132,	
2017-06-23 23:18:56,786 Epoch[36] Batch [800]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.095155,	
2017-06-23 23:19:02,266 Epoch[36] Batch [810]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.095153,	
2017-06-23 23:19:07,788 Epoch[36] Batch [820]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.095210,	
2017-06-23 23:19:12,943 Epoch[36] Batch [830]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.095216,	
2017-06-23 23:19:18,157 Epoch[36] Batch [840]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.095186,	
2017-06-23 23:19:23,401 Epoch[36] Batch [850]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.095101,	
2017-06-23 23:19:28,602 Epoch[36] Batch [860]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095110,	
2017-06-23 23:19:33,749 Epoch[36] Batch [870]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.095235,	
2017-06-23 23:19:38,937 Epoch[36] Batch [880]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095179,	
2017-06-23 23:19:44,115 Epoch[36] Batch [890]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095201,	
2017-06-23 23:19:49,331 Epoch[36] Batch [900]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.095192,	
2017-06-23 23:19:54,507 Epoch[36] Batch [910]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095138,	
2017-06-23 23:19:59,955 Epoch[36] Batch [920]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.095100,	
2017-06-23 23:20:05,086 Epoch[36] Batch [930]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.095043,	
2017-06-23 23:20:10,331 Epoch[36] Batch [940]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.095102,	
2017-06-23 23:20:15,546 Epoch[36] Batch [950]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.095093,	
2017-06-23 23:20:20,701 Epoch[36] Batch [960]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.095103,	
2017-06-23 23:20:25,898 Epoch[36] Batch [970]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095128,	
2017-06-23 23:20:31,039 Epoch[36] Batch [980]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.095018,	
2017-06-23 23:20:36,286 Epoch[36] Batch [990]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094919,	
2017-06-23 23:20:41,585 Epoch[36] Batch [1000]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094836,	
2017-06-23 23:20:46,805 Epoch[36] Batch [1010]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094827,	
2017-06-23 23:20:51,896 Epoch[36] Batch [1020]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.094842,	
2017-06-23 23:20:57,095 Epoch[36] Batch [1030]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094878,	
2017-06-23 23:21:02,291 Epoch[36] Batch [1040]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094819,	
2017-06-23 23:21:07,540 Epoch[36] Batch [1050]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094736,	
2017-06-23 23:21:12,696 Epoch[36] Batch [1060]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094707,	
2017-06-23 23:21:17,941 Epoch[36] Batch [1070]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.094687,	
2017-06-23 23:21:23,104 Epoch[36] Batch [1080]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094763,	
2017-06-23 23:21:28,418 Epoch[36] Batch [1090]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094799,	
2017-06-23 23:21:33,493 Epoch[36] Batch [1100]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.094802,	
2017-06-23 23:21:38,920 Epoch[36] Batch [1110]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.094845,	
2017-06-23 23:21:44,138 Epoch[36] Batch [1120]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094888,	
2017-06-23 23:21:49,365 Epoch[36] Batch [1130]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094880,	
2017-06-23 23:21:54,550 Epoch[36] Batch [1140]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094875,	
2017-06-23 23:21:59,710 Epoch[36] Batch [1150]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094795,	
2017-06-23 23:22:05,019 Epoch[36] Batch [1160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094760,	
2017-06-23 23:22:09,639 Epoch[36] Batch [1170]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.094709,	
2017-06-23 23:22:14,786 Epoch[36] Batch [1180]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.094751,	
2017-06-23 23:22:19,994 Epoch[36] Batch [1190]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094824,	
2017-06-23 23:22:25,103 Epoch[36] Batch [1200]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.094878,	
2017-06-23 23:22:30,321 Epoch[36] Batch [1210]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094940,	
2017-06-23 23:22:35,499 Epoch[36] Batch [1220]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094915,	
2017-06-23 23:22:40,713 Epoch[36] Batch [1230]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094999,	
2017-06-23 23:22:45,943 Epoch[36] Batch [1240]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094943,	
2017-06-23 23:22:51,098 Epoch[36] Batch [1250]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.095010,	
2017-06-23 23:22:56,357 Epoch[36] Batch [1260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094995,	
2017-06-23 23:23:01,623 Epoch[36] Batch [1270]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.095063,	
2017-06-23 23:23:06,748 Epoch[36] Batch [1280]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.095062,	
2017-06-23 23:23:11,934 Epoch[36] Batch [1290]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095148,	
2017-06-23 23:23:17,122 Epoch[36] Batch [1300]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095182,	
2017-06-23 23:23:22,327 Epoch[36] Batch [1310]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095128,	
2017-06-23 23:23:27,508 Epoch[36] Batch [1320]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.095118,	
2017-06-23 23:23:32,696 Epoch[36] Batch [1330]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095024,	
2017-06-23 23:23:37,888 Epoch[36] Batch [1340]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095124,	
2017-06-23 23:23:43,087 Epoch[36] Batch [1350]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095132,	
2017-06-23 23:23:48,280 Epoch[36] Batch [1360]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095075,	
2017-06-23 23:23:53,503 Epoch[36] Batch [1370]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.095154,	
2017-06-23 23:23:58,705 Epoch[36] Batch [1380]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095243,	
2017-06-23 23:24:03,887 Epoch[36] Batch [1390]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.095306,	
2017-06-23 23:24:09,031 Epoch[36] Batch [1400]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.095373,	
2017-06-23 23:24:14,208 Epoch[36] Batch [1410]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095428,	
2017-06-23 23:24:19,382 Epoch[36] Batch [1420]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095411,	
2017-06-23 23:24:24,618 Epoch[36] Batch [1430]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.095396,	
2017-06-23 23:24:29,884 Epoch[36] Batch [1440]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.095356,	
2017-06-23 23:24:35,070 Epoch[36] Batch [1450]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095266,	
2017-06-23 23:24:40,298 Epoch[36] Batch [1460]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.095233,	
2017-06-23 23:24:45,713 Epoch[36] Batch [1470]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.095238,	
2017-06-23 23:24:51,567 Epoch[36] Batch [1480]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.095234,	
2017-06-23 23:24:54,907 Epoch[36] Train-FCNLogLoss=0.095285
2017-06-23 23:24:54,908 Epoch[36] Time cost=783.627
2017-06-23 23:24:55,848 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0037.params"
2017-06-23 23:24:59,591 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0037.states"
2017-06-23 23:25:05,812 Epoch[37] Batch [10]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.106971,	
2017-06-23 23:25:11,140 Epoch[37] Batch [20]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.100119,	
2017-06-23 23:25:16,497 Epoch[37] Batch [30]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096555,	
2017-06-23 23:25:21,645 Epoch[37] Batch [40]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.098554,	
2017-06-23 23:25:27,107 Epoch[37] Batch [50]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.098826,	
2017-06-23 23:25:32,368 Epoch[37] Batch [60]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.100105,	
2017-06-23 23:25:37,824 Epoch[37] Batch [70]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.099282,	
2017-06-23 23:25:43,202 Epoch[37] Batch [80]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098623,	
2017-06-23 23:25:48,476 Epoch[37] Batch [90]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097191,	
2017-06-23 23:25:53,896 Epoch[37] Batch [100]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.096421,	
2017-06-23 23:25:59,456 Epoch[37] Batch [110]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.097032,	
2017-06-23 23:26:05,083 Epoch[37] Batch [120]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.096610,	
2017-06-23 23:26:10,454 Epoch[37] Batch [130]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097025,	
2017-06-23 23:26:16,147 Epoch[37] Batch [140]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.096630,	
2017-06-23 23:26:21,890 Epoch[37] Batch [150]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.095369,	
2017-06-23 23:26:27,436 Epoch[37] Batch [160]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.095458,	
2017-06-23 23:26:33,129 Epoch[37] Batch [170]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.095344,	
2017-06-23 23:26:38,940 Epoch[37] Batch [180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.095448,	
2017-06-23 23:26:44,048 Epoch[37] Batch [190]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.095394,	
2017-06-23 23:26:49,325 Epoch[37] Batch [200]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095209,	
2017-06-23 23:26:55,063 Epoch[37] Batch [210]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.094695,	
2017-06-23 23:27:00,243 Epoch[37] Batch [220]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094606,	
2017-06-23 23:27:05,496 Epoch[37] Batch [230]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094299,	
2017-06-23 23:27:10,824 Epoch[37] Batch [240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093998,	
2017-06-23 23:27:16,264 Epoch[37] Batch [250]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.093949,	
2017-06-23 23:27:21,472 Epoch[37] Batch [260]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.093563,	
2017-06-23 23:27:26,666 Epoch[37] Batch [270]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093463,	
2017-06-23 23:27:31,870 Epoch[37] Batch [280]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093594,	
2017-06-23 23:27:37,067 Epoch[37] Batch [290]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093563,	
2017-06-23 23:27:42,257 Epoch[37] Batch [300]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093630,	
2017-06-23 23:27:47,744 Epoch[37] Batch [310]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093587,	
2017-06-23 23:27:53,541 Epoch[37] Batch [320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093888,	
2017-06-23 23:27:59,088 Epoch[37] Batch [330]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.094058,	
2017-06-23 23:28:04,608 Epoch[37] Batch [340]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094230,	
2017-06-23 23:28:10,144 Epoch[37] Batch [350]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.094473,	
2017-06-23 23:28:15,786 Epoch[37] Batch [360]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.094584,	
2017-06-23 23:28:21,550 Epoch[37] Batch [370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.094833,	
2017-06-23 23:28:27,024 Epoch[37] Batch [380]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.095000,	
2017-06-23 23:28:32,887 Epoch[37] Batch [390]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.094823,	
2017-06-23 23:28:38,370 Epoch[37] Batch [400]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.095135,	
2017-06-23 23:28:43,658 Epoch[37] Batch [410]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095215,	
2017-06-23 23:28:49,855 Epoch[37] Batch [420]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.095109,	
2017-06-23 23:28:55,883 Epoch[37] Batch [430]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.094849,	
2017-06-23 23:29:01,576 Epoch[37] Batch [440]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.094589,	
2017-06-23 23:29:07,440 Epoch[37] Batch [450]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.094512,	
2017-06-23 23:29:12,957 Epoch[37] Batch [460]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094903,	
2017-06-23 23:29:18,485 Epoch[37] Batch [470]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.095069,	
2017-06-23 23:29:23,879 Epoch[37] Batch [480]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095132,	
2017-06-23 23:29:29,553 Epoch[37] Batch [490]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.094880,	
2017-06-23 23:29:35,098 Epoch[37] Batch [500]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.095080,	
2017-06-23 23:29:41,009 Epoch[37] Batch [510]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.095193,	
2017-06-23 23:29:46,918 Epoch[37] Batch [520]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.095226,	
2017-06-23 23:29:52,447 Epoch[37] Batch [530]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.095301,	
2017-06-23 23:29:58,307 Epoch[37] Batch [540]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.095381,	
2017-06-23 23:30:03,500 Epoch[37] Batch [550]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095360,	
2017-06-23 23:30:08,694 Epoch[37] Batch [560]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095371,	
2017-06-23 23:30:13,910 Epoch[37] Batch [570]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.095291,	
2017-06-23 23:30:19,077 Epoch[37] Batch [580]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.095334,	
2017-06-23 23:30:24,291 Epoch[37] Batch [590]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.095255,	
2017-06-23 23:30:29,471 Epoch[37] Batch [600]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.095231,	
2017-06-23 23:30:34,679 Epoch[37] Batch [610]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095268,	
2017-06-23 23:30:40,155 Epoch[37] Batch [620]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.095217,	
2017-06-23 23:30:45,311 Epoch[37] Batch [630]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.095134,	
2017-06-23 23:30:50,487 Epoch[37] Batch [640]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095035,	
2017-06-23 23:30:55,692 Epoch[37] Batch [650]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.095268,	
2017-06-23 23:31:00,866 Epoch[37] Batch [660]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095432,	
2017-06-23 23:31:06,065 Epoch[37] Batch [670]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095501,	
2017-06-23 23:31:11,342 Epoch[37] Batch [680]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095448,	
2017-06-23 23:31:16,552 Epoch[37] Batch [690]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095463,	
2017-06-23 23:31:21,817 Epoch[37] Batch [700]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.095486,	
2017-06-23 23:31:26,980 Epoch[37] Batch [710]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.095365,	
2017-06-23 23:31:32,188 Epoch[37] Batch [720]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095348,	
2017-06-23 23:31:37,383 Epoch[37] Batch [730]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095364,	
2017-06-23 23:31:42,610 Epoch[37] Batch [740]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.095382,	
2017-06-23 23:31:47,807 Epoch[37] Batch [750]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095357,	
2017-06-23 23:31:53,032 Epoch[37] Batch [760]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.095384,	
2017-06-23 23:31:58,451 Epoch[37] Batch [770]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.095451,	
2017-06-23 23:32:03,635 Epoch[37] Batch [780]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.095432,	
2017-06-23 23:32:08,808 Epoch[37] Batch [790]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095422,	
2017-06-23 23:32:14,004 Epoch[37] Batch [800]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095320,	
2017-06-23 23:32:19,215 Epoch[37] Batch [810]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095188,	
2017-06-23 23:32:24,381 Epoch[37] Batch [820]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.095208,	
2017-06-23 23:32:29,546 Epoch[37] Batch [830]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.095281,	
2017-06-23 23:32:34,727 Epoch[37] Batch [840]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.095282,	
2017-06-23 23:32:39,913 Epoch[37] Batch [850]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095198,	
2017-06-23 23:32:45,100 Epoch[37] Batch [860]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095214,	
2017-06-23 23:32:50,291 Epoch[37] Batch [870]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.095208,	
2017-06-23 23:32:55,503 Epoch[37] Batch [880]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.095139,	
2017-06-23 23:33:01,208 Epoch[37] Batch [890]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.095143,	
2017-06-23 23:33:07,078 Epoch[37] Batch [900]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.095100,	
2017-06-23 23:33:13,079 Epoch[37] Batch [910]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.095105,	
2017-06-23 23:33:18,516 Epoch[37] Batch [920]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.095053,	
2017-06-23 23:33:23,951 Epoch[37] Batch [930]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.094976,	
2017-06-23 23:33:29,428 Epoch[37] Batch [940]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094800,	
2017-06-23 23:33:34,693 Epoch[37] Batch [950]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094810,	
2017-06-23 23:33:39,831 Epoch[37] Batch [960]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.094764,	
2017-06-23 23:33:45,452 Epoch[37] Batch [970]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.094833,	
2017-06-23 23:33:51,207 Epoch[37] Batch [980]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.094825,	
2017-06-23 23:33:56,313 Epoch[37] Batch [990]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.094793,	
2017-06-23 23:34:02,013 Epoch[37] Batch [1000]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.094853,	
2017-06-23 23:34:07,266 Epoch[37] Batch [1010]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094963,	
2017-06-23 23:34:12,488 Epoch[37] Batch [1020]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.095075,	
2017-06-23 23:34:17,663 Epoch[37] Batch [1030]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.095036,	
2017-06-23 23:34:22,832 Epoch[37] Batch [1040]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094918,	
2017-06-23 23:34:28,063 Epoch[37] Batch [1050]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094938,	
2017-06-23 23:34:33,250 Epoch[37] Batch [1060]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094908,	
2017-06-23 23:34:38,937 Epoch[37] Batch [1070]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.094834,	
2017-06-23 23:34:44,415 Epoch[37] Batch [1080]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094810,	
2017-06-23 23:34:49,878 Epoch[37] Batch [1090]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.094762,	
2017-06-23 23:34:54,557 Epoch[37] Batch [1100]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.094722,	
2017-06-23 23:34:59,707 Epoch[37] Batch [1110]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.094725,	
2017-06-23 23:35:04,903 Epoch[37] Batch [1120]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094734,	
2017-06-23 23:35:10,093 Epoch[37] Batch [1130]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094605,	
2017-06-23 23:35:15,293 Epoch[37] Batch [1140]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094630,	
2017-06-23 23:35:20,461 Epoch[37] Batch [1150]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094662,	
2017-06-23 23:35:25,649 Epoch[37] Batch [1160]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094650,	
2017-06-23 23:35:30,835 Epoch[37] Batch [1170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094550,	
2017-06-23 23:35:36,016 Epoch[37] Batch [1180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094578,	
2017-06-23 23:35:41,305 Epoch[37] Batch [1190]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094557,	
2017-06-23 23:35:46,407 Epoch[37] Batch [1200]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.094512,	
2017-06-23 23:35:51,621 Epoch[37] Batch [1210]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094530,	
2017-06-23 23:35:56,812 Epoch[37] Batch [1220]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094516,	
2017-06-23 23:36:01,975 Epoch[37] Batch [1230]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094445,	
2017-06-23 23:36:07,185 Epoch[37] Batch [1240]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094404,	
2017-06-23 23:36:12,388 Epoch[37] Batch [1250]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094356,	
2017-06-23 23:36:17,572 Epoch[37] Batch [1260]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094344,	
2017-06-23 23:36:22,791 Epoch[37] Batch [1270]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094305,	
2017-06-23 23:36:28,091 Epoch[37] Batch [1280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094368,	
2017-06-23 23:36:33,247 Epoch[37] Batch [1290]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094423,	
2017-06-23 23:36:38,473 Epoch[37] Batch [1300]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094473,	
2017-06-23 23:36:43,596 Epoch[37] Batch [1310]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094481,	
2017-06-23 23:36:48,814 Epoch[37] Batch [1320]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094468,	
2017-06-23 23:36:53,999 Epoch[37] Batch [1330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094436,	
2017-06-23 23:36:59,246 Epoch[37] Batch [1340]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094387,	
2017-06-23 23:37:04,441 Epoch[37] Batch [1350]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094417,	
2017-06-23 23:37:09,534 Epoch[37] Batch [1360]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.094374,	
2017-06-23 23:37:14,904 Epoch[37] Batch [1370]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094380,	
2017-06-23 23:37:20,115 Epoch[37] Batch [1380]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094349,	
2017-06-23 23:37:25,237 Epoch[37] Batch [1390]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094290,	
2017-06-23 23:37:30,481 Epoch[37] Batch [1400]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.094257,	
2017-06-23 23:37:35,673 Epoch[37] Batch [1410]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094227,	
2017-06-23 23:37:40,879 Epoch[37] Batch [1420]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094221,	
2017-06-23 23:37:46,066 Epoch[37] Batch [1430]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.094269,	
2017-06-23 23:37:51,494 Epoch[37] Batch [1440]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.094232,	
2017-06-23 23:37:56,686 Epoch[37] Batch [1450]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094109,	
2017-06-23 23:38:01,827 Epoch[37] Batch [1460]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.094101,	
2017-06-23 23:38:07,053 Epoch[37] Batch [1470]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094088,	
2017-06-23 23:38:12,278 Epoch[37] Batch [1480]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094100,	
2017-06-23 23:38:15,373 Epoch[37] Train-FCNLogLoss=0.094161
2017-06-23 23:38:15,374 Epoch[37] Time cost=795.782
2017-06-23 23:38:16,268 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0038.params"
2017-06-23 23:38:19,925 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0038.states"
2017-06-23 23:38:25,883 Epoch[38] Batch [10]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.097453,	
2017-06-23 23:38:31,065 Epoch[38] Batch [20]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098118,	
2017-06-23 23:38:36,517 Epoch[38] Batch [30]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.097068,	
2017-06-23 23:38:41,705 Epoch[38] Batch [40]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.096821,	
2017-06-23 23:38:47,200 Epoch[38] Batch [50]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.097442,	
2017-06-23 23:38:52,526 Epoch[38] Batch [60]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099231,	
2017-06-23 23:38:57,836 Epoch[38] Batch [70]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.099508,	
2017-06-23 23:39:02,906 Epoch[38] Batch [80]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.099482,	
2017-06-23 23:39:08,089 Epoch[38] Batch [90]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.099940,	
2017-06-23 23:39:13,301 Epoch[38] Batch [100]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.100145,	
2017-06-23 23:39:18,532 Epoch[38] Batch [110]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.100624,	
2017-06-23 23:39:23,710 Epoch[38] Batch [120]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.099438,	
2017-06-23 23:39:28,964 Epoch[38] Batch [130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.099269,	
2017-06-23 23:39:34,167 Epoch[38] Batch [140]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.099177,	
2017-06-23 23:39:39,358 Epoch[38] Batch [150]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.098957,	
2017-06-23 23:39:44,558 Epoch[38] Batch [160]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.098739,	
2017-06-23 23:39:49,702 Epoch[38] Batch [170]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.098571,	
2017-06-23 23:39:54,941 Epoch[38] Batch [180]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.098983,	
2017-06-23 23:40:00,060 Epoch[38] Batch [190]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.098406,	
2017-06-23 23:40:05,392 Epoch[38] Batch [200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098042,	
2017-06-23 23:40:10,528 Epoch[38] Batch [210]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.097665,	
2017-06-23 23:40:15,809 Epoch[38] Batch [220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097737,	
2017-06-23 23:40:21,025 Epoch[38] Batch [230]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.097701,	
2017-06-23 23:40:26,470 Epoch[38] Batch [240]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.097478,	
2017-06-23 23:40:31,721 Epoch[38] Batch [250]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.097288,	
2017-06-23 23:40:37,201 Epoch[38] Batch [260]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.096674,	
2017-06-23 23:40:42,717 Epoch[38] Batch [270]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.096453,	
2017-06-23 23:40:47,982 Epoch[38] Batch [280]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096299,	
2017-06-23 23:40:53,220 Epoch[38] Batch [290]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.095798,	
2017-06-23 23:40:58,463 Epoch[38] Batch [300]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.095722,	
2017-06-23 23:41:03,614 Epoch[38] Batch [310]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.095507,	
2017-06-23 23:41:08,871 Epoch[38] Batch [320]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.095031,	
2017-06-23 23:41:14,056 Epoch[38] Batch [330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.095106,	
2017-06-23 23:41:19,223 Epoch[38] Batch [340]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094759,	
2017-06-23 23:41:24,687 Epoch[38] Batch [350]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.095118,	
2017-06-23 23:41:29,924 Epoch[38] Batch [360]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.095079,	
2017-06-23 23:41:35,117 Epoch[38] Batch [370]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.095020,	
2017-06-23 23:41:40,263 Epoch[38] Batch [380]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.094889,	
2017-06-23 23:41:45,496 Epoch[38] Batch [390]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.094826,	
2017-06-23 23:41:50,655 Epoch[38] Batch [400]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.095057,	
2017-06-23 23:41:55,840 Epoch[38] Batch [410]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094781,	
2017-06-23 23:42:01,065 Epoch[38] Batch [420]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094385,	
2017-06-23 23:42:06,245 Epoch[38] Batch [430]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.094312,	
2017-06-23 23:42:11,498 Epoch[38] Batch [440]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094475,	
2017-06-23 23:42:16,609 Epoch[38] Batch [450]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.094543,	
2017-06-23 23:42:21,816 Epoch[38] Batch [460]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094777,	
2017-06-23 23:42:27,010 Epoch[38] Batch [470]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094733,	
2017-06-23 23:42:32,224 Epoch[38] Batch [480]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094782,	
2017-06-23 23:42:37,445 Epoch[38] Batch [490]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094668,	
2017-06-23 23:42:42,652 Epoch[38] Batch [500]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094586,	
2017-06-23 23:42:47,879 Epoch[38] Batch [510]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094519,	
2017-06-23 23:42:52,968 Epoch[38] Batch [520]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.094654,	
2017-06-23 23:42:58,182 Epoch[38] Batch [530]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094556,	
2017-06-23 23:43:03,439 Epoch[38] Batch [540]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094408,	
2017-06-23 23:43:08,596 Epoch[38] Batch [550]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094369,	
2017-06-23 23:43:13,736 Epoch[38] Batch [560]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.094438,	
2017-06-23 23:43:18,956 Epoch[38] Batch [570]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094236,	
2017-06-23 23:43:24,128 Epoch[38] Batch [580]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094212,	
2017-06-23 23:43:29,356 Epoch[38] Batch [590]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094175,	
2017-06-23 23:43:34,509 Epoch[38] Batch [600]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094140,	
2017-06-23 23:43:39,746 Epoch[38] Batch [610]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093987,	
2017-06-23 23:43:44,908 Epoch[38] Batch [620]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.093988,	
2017-06-23 23:43:50,090 Epoch[38] Batch [630]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093862,	
2017-06-23 23:43:55,260 Epoch[38] Batch [640]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093842,	
2017-06-23 23:44:00,492 Epoch[38] Batch [650]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093789,	
2017-06-23 23:44:05,624 Epoch[38] Batch [660]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093799,	
2017-06-23 23:44:10,807 Epoch[38] Batch [670]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093806,	
2017-06-23 23:44:15,990 Epoch[38] Batch [680]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093824,	
2017-06-23 23:44:21,207 Epoch[38] Batch [690]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094068,	
2017-06-23 23:44:26,376 Epoch[38] Batch [700]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094024,	
2017-06-23 23:44:31,576 Epoch[38] Batch [710]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094140,	
2017-06-23 23:44:36,831 Epoch[38] Batch [720]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094171,	
2017-06-23 23:44:41,995 Epoch[38] Batch [730]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094222,	
2017-06-23 23:44:47,160 Epoch[38] Batch [740]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094168,	
2017-06-23 23:44:52,334 Epoch[38] Batch [750]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094234,	
2017-06-23 23:44:57,562 Epoch[38] Batch [760]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094098,	
2017-06-23 23:45:02,728 Epoch[38] Batch [770]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093979,	
2017-06-23 23:45:07,958 Epoch[38] Batch [780]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093944,	
2017-06-23 23:45:13,179 Epoch[38] Batch [790]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.094072,	
2017-06-23 23:45:18,610 Epoch[38] Batch [800]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.094216,	
2017-06-23 23:45:23,673 Epoch[38] Batch [810]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.094197,	
2017-06-23 23:45:28,942 Epoch[38] Batch [820]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094169,	
2017-06-23 23:45:34,204 Epoch[38] Batch [830]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094139,	
2017-06-23 23:45:39,632 Epoch[38] Batch [840]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.094041,	
2017-06-23 23:45:44,808 Epoch[38] Batch [850]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094038,	
2017-06-23 23:45:49,965 Epoch[38] Batch [860]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094062,	
2017-06-23 23:45:55,191 Epoch[38] Batch [870]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094000,	
2017-06-23 23:46:00,451 Epoch[38] Batch [880]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094135,	
2017-06-23 23:46:05,620 Epoch[38] Batch [890]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094073,	
2017-06-23 23:46:10,797 Epoch[38] Batch [900]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094166,	
2017-06-23 23:46:16,011 Epoch[38] Batch [910]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094219,	
2017-06-23 23:46:21,228 Epoch[38] Batch [920]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.094297,	
2017-06-23 23:46:26,667 Epoch[38] Batch [930]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.094251,	
2017-06-23 23:46:32,028 Epoch[38] Batch [940]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094239,	
2017-06-23 23:46:38,198 Epoch[38] Batch [950]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.094203,	
2017-06-23 23:46:43,953 Epoch[38] Batch [960]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.094214,	
2017-06-23 23:46:50,104 Epoch[38] Batch [970]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.094210,	
2017-06-23 23:46:55,659 Epoch[38] Batch [980]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.094264,	
2017-06-23 23:47:00,869 Epoch[38] Batch [990]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094254,	
2017-06-23 23:47:06,707 Epoch[38] Batch [1000]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.094255,	
2017-06-23 23:47:12,367 Epoch[38] Batch [1010]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.094314,	
2017-06-23 23:47:18,429 Epoch[38] Batch [1020]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.094269,	
2017-06-23 23:47:24,072 Epoch[38] Batch [1030]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.094161,	
2017-06-23 23:47:29,599 Epoch[38] Batch [1040]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.094161,	
2017-06-23 23:47:35,469 Epoch[38] Batch [1050]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.094162,	
2017-06-23 23:47:40,965 Epoch[38] Batch [1060]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.094053,	
2017-06-23 23:47:46,734 Epoch[38] Batch [1070]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.094078,	
2017-06-23 23:47:52,578 Epoch[38] Batch [1080]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.094106,	
2017-06-23 23:47:58,251 Epoch[38] Batch [1090]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.094016,	
2017-06-23 23:48:04,559 Epoch[38] Batch [1100]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.094041,	
2017-06-23 23:48:11,238 Epoch[38] Batch [1110]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.094028,	
2017-06-23 23:48:17,308 Epoch[38] Batch [1120]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.094094,	
2017-06-23 23:48:23,490 Epoch[38] Batch [1130]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.094067,	
2017-06-23 23:48:29,173 Epoch[38] Batch [1140]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.094011,	
2017-06-23 23:48:34,809 Epoch[38] Batch [1150]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.093998,	
2017-06-23 23:48:40,544 Epoch[38] Batch [1160]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.093953,	
2017-06-23 23:48:45,929 Epoch[38] Batch [1170]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.093981,	
2017-06-23 23:48:51,845 Epoch[38] Batch [1180]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.093917,	
2017-06-23 23:48:57,519 Epoch[38] Batch [1190]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.093890,	
2017-06-23 23:49:03,215 Epoch[38] Batch [1200]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.093921,	
2017-06-23 23:49:08,575 Epoch[38] Batch [1210]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093940,	
2017-06-23 23:49:14,105 Epoch[38] Batch [1220]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.093876,	
2017-06-23 23:49:20,059 Epoch[38] Batch [1230]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.093805,	
2017-06-23 23:49:25,662 Epoch[38] Batch [1240]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.093816,	
2017-06-23 23:49:31,540 Epoch[38] Batch [1250]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.093767,	
2017-06-23 23:49:36,831 Epoch[38] Batch [1260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093752,	
2017-06-23 23:49:42,475 Epoch[38] Batch [1270]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.093829,	
2017-06-23 23:49:48,303 Epoch[38] Batch [1280]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.093823,	
2017-06-23 23:49:54,162 Epoch[38] Batch [1290]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.093923,	
2017-06-23 23:50:00,118 Epoch[38] Batch [1300]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.093961,	
2017-06-23 23:50:06,142 Epoch[38] Batch [1310]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.093969,	
2017-06-23 23:50:11,937 Epoch[38] Batch [1320]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093967,	
2017-06-23 23:50:17,822 Epoch[38] Batch [1330]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093964,	
2017-06-23 23:50:23,311 Epoch[38] Batch [1340]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093958,	
2017-06-23 23:50:28,661 Epoch[38] Batch [1350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093942,	
2017-06-23 23:50:34,124 Epoch[38] Batch [1360]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.093839,	
2017-06-23 23:50:39,907 Epoch[38] Batch [1370]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.093856,	
2017-06-23 23:50:45,387 Epoch[38] Batch [1380]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093863,	
2017-06-23 23:50:50,577 Epoch[38] Batch [1390]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093889,	
2017-06-23 23:50:55,744 Epoch[38] Batch [1400]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.093915,	
2017-06-23 23:51:01,234 Epoch[38] Batch [1410]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093949,	
2017-06-23 23:51:06,487 Epoch[38] Batch [1420]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.093948,	
2017-06-23 23:51:12,040 Epoch[38] Batch [1430]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.093966,	
2017-06-23 23:51:17,194 Epoch[38] Batch [1440]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093940,	
2017-06-23 23:51:22,811 Epoch[38] Batch [1450]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.093934,	
2017-06-23 23:51:28,314 Epoch[38] Batch [1460]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093897,	
2017-06-23 23:51:33,665 Epoch[38] Batch [1470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093903,	
2017-06-23 23:51:39,165 Epoch[38] Batch [1480]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093910,	
2017-06-23 23:51:42,490 Epoch[38] Train-FCNLogLoss=0.093939
2017-06-23 23:51:42,490 Epoch[38] Time cost=802.565
2017-06-23 23:51:43,414 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0039.params"
2017-06-23 23:51:46,921 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0039.states"
2017-06-23 23:51:53,112 Epoch[39] Batch [10]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.100112,	
2017-06-23 23:51:58,282 Epoch[39] Batch [20]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.096599,	
2017-06-23 23:52:03,556 Epoch[39] Batch [30]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096879,	
2017-06-23 23:52:09,307 Epoch[39] Batch [40]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.094739,	
2017-06-23 23:52:14,614 Epoch[39] Batch [50]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093182,	
2017-06-23 23:52:20,313 Epoch[39] Batch [60]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.095463,	
2017-06-23 23:52:25,750 Epoch[39] Batch [70]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.094997,	
2017-06-23 23:52:31,282 Epoch[39] Batch [80]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.092698,	
2017-06-23 23:52:37,254 Epoch[39] Batch [90]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.093581,	
2017-06-23 23:52:42,405 Epoch[39] Batch [100]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093063,	
2017-06-23 23:52:47,623 Epoch[39] Batch [110]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.092937,	
2017-06-23 23:52:52,827 Epoch[39] Batch [120]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092988,	
2017-06-23 23:52:58,000 Epoch[39] Batch [130]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093307,	
2017-06-23 23:53:03,212 Epoch[39] Batch [140]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.093449,	
2017-06-23 23:53:08,563 Epoch[39] Batch [150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093190,	
2017-06-23 23:53:14,110 Epoch[39] Batch [160]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.094217,	
2017-06-23 23:53:19,298 Epoch[39] Batch [170]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093974,	
2017-06-23 23:53:24,479 Epoch[39] Batch [180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093956,	
2017-06-23 23:53:29,736 Epoch[39] Batch [190]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.093659,	
2017-06-23 23:53:34,883 Epoch[39] Batch [200]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.093486,	
2017-06-23 23:53:40,041 Epoch[39] Batch [210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093256,	
2017-06-23 23:53:45,547 Epoch[39] Batch [220]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.093370,	
2017-06-23 23:53:50,997 Epoch[39] Batch [230]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093329,	
2017-06-23 23:53:56,190 Epoch[39] Batch [240]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.093880,	
2017-06-23 23:54:01,669 Epoch[39] Batch [250]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.094293,	
2017-06-23 23:54:07,105 Epoch[39] Batch [260]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.094528,	
2017-06-23 23:54:12,371 Epoch[39] Batch [270]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094691,	
2017-06-23 23:54:18,036 Epoch[39] Batch [280]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.094610,	
2017-06-23 23:54:23,200 Epoch[39] Batch [290]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.094674,	
2017-06-23 23:54:28,428 Epoch[39] Batch [300]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094834,	
2017-06-23 23:54:33,884 Epoch[39] Batch [310]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094748,	
2017-06-23 23:54:39,148 Epoch[39] Batch [320]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094869,	
2017-06-23 23:54:44,605 Epoch[39] Batch [330]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094934,	
2017-06-23 23:54:49,782 Epoch[39] Batch [340]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094941,	
2017-06-23 23:54:54,976 Epoch[39] Batch [350]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094813,	
2017-06-23 23:55:00,178 Epoch[39] Batch [360]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094485,	
2017-06-23 23:55:05,650 Epoch[39] Batch [370]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.094501,	
2017-06-23 23:55:11,623 Epoch[39] Batch [380]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.094693,	
2017-06-23 23:55:16,945 Epoch[39] Batch [390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094622,	
2017-06-23 23:55:22,117 Epoch[39] Batch [400]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094521,	
2017-06-23 23:55:27,270 Epoch[39] Batch [410]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.094560,	
2017-06-23 23:55:32,505 Epoch[39] Batch [420]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.094285,	
2017-06-23 23:55:37,717 Epoch[39] Batch [430]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094080,	
2017-06-23 23:55:42,898 Epoch[39] Batch [440]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093776,	
2017-06-23 23:55:48,686 Epoch[39] Batch [450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.093659,	
2017-06-23 23:55:53,939 Epoch[39] Batch [460]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.093478,	
2017-06-23 23:55:59,342 Epoch[39] Batch [470]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.093439,	
2017-06-23 23:56:04,518 Epoch[39] Batch [480]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093296,	
2017-06-23 23:56:10,006 Epoch[39] Batch [490]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092936,	
2017-06-23 23:56:15,196 Epoch[39] Batch [500]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092973,	
2017-06-23 23:56:20,401 Epoch[39] Batch [510]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092845,	
2017-06-23 23:56:25,591 Epoch[39] Batch [520]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092802,	
2017-06-23 23:56:30,818 Epoch[39] Batch [530]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.092716,	
2017-06-23 23:56:36,572 Epoch[39] Batch [540]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.092677,	
2017-06-23 23:56:42,369 Epoch[39] Batch [550]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.092787,	
2017-06-23 23:56:47,534 Epoch[39] Batch [560]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092749,	
2017-06-23 23:56:52,806 Epoch[39] Batch [570]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092621,	
2017-06-23 23:56:58,309 Epoch[39] Batch [580]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092707,	
2017-06-23 23:57:03,482 Epoch[39] Batch [590]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092642,	
2017-06-23 23:57:08,667 Epoch[39] Batch [600]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092800,	
2017-06-23 23:57:13,859 Epoch[39] Batch [610]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092948,	
2017-06-23 23:57:19,337 Epoch[39] Batch [620]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.092959,	
2017-06-23 23:57:25,770 Epoch[39] Batch [630]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.093078,	
2017-06-23 23:57:31,258 Epoch[39] Batch [640]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093027,	
2017-06-23 23:57:36,398 Epoch[39] Batch [650]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093069,	
2017-06-23 23:57:41,593 Epoch[39] Batch [660]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092837,	
2017-06-23 23:57:46,760 Epoch[39] Batch [670]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092833,	
2017-06-23 23:57:52,019 Epoch[39] Batch [680]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092911,	
2017-06-23 23:57:57,140 Epoch[39] Batch [690]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.092982,	
2017-06-23 23:58:02,613 Epoch[39] Batch [700]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.092805,	
2017-06-23 23:58:08,267 Epoch[39] Batch [710]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.093100,	
2017-06-23 23:58:13,599 Epoch[39] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093064,	
2017-06-23 23:58:18,931 Epoch[39] Batch [730]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092985,	
2017-06-23 23:58:24,164 Epoch[39] Batch [740]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093081,	
2017-06-23 23:58:29,733 Epoch[39] Batch [750]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.093057,	
2017-06-23 23:58:35,731 Epoch[39] Batch [760]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.093081,	
2017-06-23 23:58:41,458 Epoch[39] Batch [770]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.092964,	
2017-06-23 23:58:47,201 Epoch[39] Batch [780]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.093013,	
2017-06-23 23:58:53,533 Epoch[39] Batch [790]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.093124,	
2017-06-23 23:58:59,414 Epoch[39] Batch [800]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093025,	
2017-06-23 23:59:04,722 Epoch[39] Batch [810]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092946,	
2017-06-23 23:59:09,982 Epoch[39] Batch [820]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092972,	
2017-06-23 23:59:15,467 Epoch[39] Batch [830]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.093044,	
2017-06-23 23:59:20,695 Epoch[39] Batch [840]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.092955,	
2017-06-23 23:59:26,092 Epoch[39] Batch [850]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.092931,	
2017-06-23 23:59:31,456 Epoch[39] Batch [860]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092959,	
2017-06-23 23:59:36,793 Epoch[39] Batch [870]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092840,	
2017-06-23 23:59:42,080 Epoch[39] Batch [880]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092676,	
2017-06-23 23:59:47,565 Epoch[39] Batch [890]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092574,	
2017-06-23 23:59:52,894 Epoch[39] Batch [900]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092739,	
2017-06-23 23:59:58,079 Epoch[39] Batch [910]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092776,	
2017-06-24 00:00:03,847 Epoch[39] Batch [920]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.092811,	
2017-06-24 00:00:09,365 Epoch[39] Batch [930]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.092771,	
2017-06-24 00:00:15,124 Epoch[39] Batch [940]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.092715,	
2017-06-24 00:00:20,401 Epoch[39] Batch [950]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.092627,	
2017-06-24 00:00:26,175 Epoch[39] Batch [960]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.092521,	
2017-06-24 00:00:31,506 Epoch[39] Batch [970]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092397,	
2017-06-24 00:00:36,990 Epoch[39] Batch [980]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.092385,	
2017-06-24 00:00:42,177 Epoch[39] Batch [990]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092336,	
2017-06-24 00:00:47,321 Epoch[39] Batch [1000]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092305,	
2017-06-24 00:00:52,492 Epoch[39] Batch [1010]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092329,	
2017-06-24 00:00:57,877 Epoch[39] Batch [1020]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092306,	
2017-06-24 00:01:03,051 Epoch[39] Batch [1030]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092305,	
2017-06-24 00:01:08,283 Epoch[39] Batch [1040]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.092266,	
2017-06-24 00:01:13,574 Epoch[39] Batch [1050]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.092181,	
2017-06-24 00:01:18,751 Epoch[39] Batch [1060]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092075,	
2017-06-24 00:01:24,032 Epoch[39] Batch [1070]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.092090,	
2017-06-24 00:01:29,248 Epoch[39] Batch [1080]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.092099,	
2017-06-24 00:01:34,409 Epoch[39] Batch [1090]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.092143,	
2017-06-24 00:01:39,643 Epoch[39] Batch [1100]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.092143,	
2017-06-24 00:01:45,046 Epoch[39] Batch [1110]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092113,	
2017-06-24 00:01:50,271 Epoch[39] Batch [1120]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.092143,	
2017-06-24 00:01:55,423 Epoch[39] Batch [1130]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.092188,	
2017-06-24 00:02:00,705 Epoch[39] Batch [1140]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092158,	
2017-06-24 00:02:05,803 Epoch[39] Batch [1150]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.092146,	
2017-06-24 00:02:11,173 Epoch[39] Batch [1160]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092103,	
2017-06-24 00:02:16,313 Epoch[39] Batch [1170]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.092049,	
2017-06-24 00:02:21,497 Epoch[39] Batch [1180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.092093,	
2017-06-24 00:02:26,751 Epoch[39] Batch [1190]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092106,	
2017-06-24 00:02:31,971 Epoch[39] Batch [1200]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.092100,	
2017-06-24 00:02:37,559 Epoch[39] Batch [1210]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.092043,	
2017-06-24 00:02:43,164 Epoch[39] Batch [1220]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.092042,	
2017-06-24 00:02:48,919 Epoch[39] Batch [1230]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.092005,	
2017-06-24 00:02:54,512 Epoch[39] Batch [1240]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.092004,	
2017-06-24 00:02:59,718 Epoch[39] Batch [1250]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.092007,	
2017-06-24 00:03:04,837 Epoch[39] Batch [1260]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.092002,	
2017-06-24 00:03:10,080 Epoch[39] Batch [1270]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.092001,	
2017-06-24 00:03:15,237 Epoch[39] Batch [1280]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.092043,	
2017-06-24 00:03:20,475 Epoch[39] Batch [1290]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.092032,	
2017-06-24 00:03:25,668 Epoch[39] Batch [1300]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.092011,	
2017-06-24 00:03:30,895 Epoch[39] Batch [1310]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.091939,	
2017-06-24 00:03:36,060 Epoch[39] Batch [1320]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.092008,	
2017-06-24 00:03:41,635 Epoch[39] Batch [1330]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.092011,	
2017-06-24 00:03:47,065 Epoch[39] Batch [1340]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.092031,	
2017-06-24 00:03:52,525 Epoch[39] Batch [1350]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.092080,	
2017-06-24 00:03:57,784 Epoch[39] Batch [1360]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.092053,	
2017-06-24 00:04:02,921 Epoch[39] Batch [1370]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.091999,	
2017-06-24 00:04:08,096 Epoch[39] Batch [1380]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092002,	
2017-06-24 00:04:13,312 Epoch[39] Batch [1390]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.091968,	
2017-06-24 00:04:18,508 Epoch[39] Batch [1400]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.091992,	
2017-06-24 00:04:23,728 Epoch[39] Batch [1410]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.092003,	
2017-06-24 00:04:28,932 Epoch[39] Batch [1420]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092069,	
2017-06-24 00:04:34,132 Epoch[39] Batch [1430]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092123,	
2017-06-24 00:04:39,331 Epoch[39] Batch [1440]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092056,	
2017-06-24 00:04:44,809 Epoch[39] Batch [1450]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.092099,	
2017-06-24 00:04:49,996 Epoch[39] Batch [1460]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092048,	
2017-06-24 00:04:55,274 Epoch[39] Batch [1470]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.092031,	
2017-06-24 00:05:00,443 Epoch[39] Batch [1480]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.092055,	
2017-06-24 00:05:03,530 Epoch[39] Train-FCNLogLoss=0.092075
2017-06-24 00:05:03,531 Epoch[39] Time cost=796.609
2017-06-24 00:05:04,505 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0040.params"
2017-06-24 00:05:07,958 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0040.states"
2017-06-24 00:05:14,732 Epoch[40] Batch [10]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.095359,	
2017-06-24 00:05:19,858 Epoch[40] Batch [20]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.098644,	
2017-06-24 00:05:25,139 Epoch[40] Batch [30]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094498,	
2017-06-24 00:05:30,366 Epoch[40] Batch [40]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093579,	
2017-06-24 00:05:35,407 Epoch[40] Batch [50]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.094533,	
2017-06-24 00:05:40,627 Epoch[40] Batch [60]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093430,	
2017-06-24 00:05:45,848 Epoch[40] Batch [70]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093061,	
2017-06-24 00:05:51,020 Epoch[40] Batch [80]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.092552,	
2017-06-24 00:05:56,232 Epoch[40] Batch [90]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.092552,	
2017-06-24 00:06:01,436 Epoch[40] Batch [100]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093586,	
2017-06-24 00:06:06,632 Epoch[40] Batch [110]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094109,	
2017-06-24 00:06:11,811 Epoch[40] Batch [120]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093471,	
2017-06-24 00:06:17,038 Epoch[40] Batch [130]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.093742,	
2017-06-24 00:06:22,722 Epoch[40] Batch [140]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.094108,	
2017-06-24 00:06:27,997 Epoch[40] Batch [150]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093903,	
2017-06-24 00:06:33,168 Epoch[40] Batch [160]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094033,	
2017-06-24 00:06:38,412 Epoch[40] Batch [170]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.093643,	
2017-06-24 00:06:44,044 Epoch[40] Batch [180]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.094367,	
2017-06-24 00:06:49,244 Epoch[40] Batch [190]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094076,	
2017-06-24 00:06:54,778 Epoch[40] Batch [200]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.094317,	
2017-06-24 00:07:00,197 Epoch[40] Batch [210]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.094522,	
2017-06-24 00:07:05,526 Epoch[40] Batch [220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094733,	
2017-06-24 00:07:10,661 Epoch[40] Batch [230]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.094911,	
2017-06-24 00:07:15,892 Epoch[40] Batch [240]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094863,	
2017-06-24 00:07:21,018 Epoch[40] Batch [250]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.094646,	
2017-06-24 00:07:26,210 Epoch[40] Batch [260]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.094411,	
2017-06-24 00:07:31,437 Epoch[40] Batch [270]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.094537,	
2017-06-24 00:07:36,703 Epoch[40] Batch [280]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.094504,	
2017-06-24 00:07:42,034 Epoch[40] Batch [290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094565,	
2017-06-24 00:07:47,097 Epoch[40] Batch [300]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.094190,	
2017-06-24 00:07:52,227 Epoch[40] Batch [310]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.094159,	
2017-06-24 00:07:57,406 Epoch[40] Batch [320]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093976,	
2017-06-24 00:08:02,590 Epoch[40] Batch [330]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.093413,	
2017-06-24 00:08:07,734 Epoch[40] Batch [340]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.093358,	
2017-06-24 00:08:12,923 Epoch[40] Batch [350]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.093093,	
2017-06-24 00:08:18,160 Epoch[40] Batch [360]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.093258,	
2017-06-24 00:08:23,335 Epoch[40] Batch [370]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093235,	
2017-06-24 00:08:28,829 Epoch[40] Batch [380]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093490,	
2017-06-24 00:08:34,049 Epoch[40] Batch [390]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.093309,	
2017-06-24 00:08:39,211 Epoch[40] Batch [400]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.093327,	
2017-06-24 00:08:44,493 Epoch[40] Batch [410]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.093252,	
2017-06-24 00:08:49,698 Epoch[40] Batch [420]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093042,	
2017-06-24 00:08:54,901 Epoch[40] Batch [430]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.093055,	
2017-06-24 00:09:00,073 Epoch[40] Batch [440]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.093491,	
2017-06-24 00:09:05,528 Epoch[40] Batch [450]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.093463,	
2017-06-24 00:09:10,726 Epoch[40] Batch [460]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.093353,	
2017-06-24 00:09:16,493 Epoch[40] Batch [470]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.093639,	
2017-06-24 00:09:22,464 Epoch[40] Batch [480]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.093763,	
2017-06-24 00:09:28,490 Epoch[40] Batch [490]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.093848,	
2017-06-24 00:09:34,116 Epoch[40] Batch [500]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.093798,	
2017-06-24 00:09:40,158 Epoch[40] Batch [510]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.093642,	
2017-06-24 00:09:45,047 Update[60000]: Change learning rate to 5.00000e-05
2017-06-24 00:09:46,030 Epoch[40] Batch [520]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.093673,	
2017-06-24 00:09:51,911 Epoch[40] Batch [530]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.093742,	
2017-06-24 00:09:57,716 Epoch[40] Batch [540]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.093746,	
2017-06-24 00:10:03,148 Epoch[40] Batch [550]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093816,	
2017-06-24 00:10:08,571 Epoch[40] Batch [560]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.093778,	
2017-06-24 00:10:14,640 Epoch[40] Batch [570]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.093567,	
2017-06-24 00:10:20,734 Epoch[40] Batch [580]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.093599,	
2017-06-24 00:10:26,576 Epoch[40] Batch [590]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.093976,	
2017-06-24 00:10:32,772 Epoch[40] Batch [600]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.093772,	
2017-06-24 00:10:38,867 Epoch[40] Batch [610]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.093835,	
2017-06-24 00:10:45,218 Epoch[40] Batch [620]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.093751,	
2017-06-24 00:10:50,583 Epoch[40] Batch [630]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093585,	
2017-06-24 00:10:56,105 Epoch[40] Batch [640]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.093474,	
2017-06-24 00:11:01,602 Epoch[40] Batch [650]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093403,	
2017-06-24 00:11:07,227 Epoch[40] Batch [660]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.093267,	
2017-06-24 00:11:13,027 Epoch[40] Batch [670]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.093298,	
2017-06-24 00:11:18,480 Epoch[40] Batch [680]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.093171,	
2017-06-24 00:11:24,568 Epoch[40] Batch [690]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.093077,	
2017-06-24 00:11:30,272 Epoch[40] Batch [700]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.093037,	
2017-06-24 00:11:36,082 Epoch[40] Batch [710]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.092896,	
2017-06-24 00:11:42,209 Epoch[40] Batch [720]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.092824,	
2017-06-24 00:11:48,095 Epoch[40] Batch [730]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.092802,	
2017-06-24 00:11:53,754 Epoch[40] Batch [740]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.092665,	
2017-06-24 00:11:59,611 Epoch[40] Batch [750]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.092728,	
2017-06-24 00:12:04,947 Epoch[40] Batch [760]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092752,	
2017-06-24 00:12:10,224 Epoch[40] Batch [770]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.092693,	
2017-06-24 00:12:16,528 Epoch[40] Batch [780]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.092564,	
2017-06-24 00:12:21,665 Epoch[40] Batch [790]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.092440,	
2017-06-24 00:12:27,171 Epoch[40] Batch [800]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.092356,	
2017-06-24 00:12:32,624 Epoch[40] Batch [810]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092326,	
2017-06-24 00:12:38,074 Epoch[40] Batch [820]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.092284,	
2017-06-24 00:12:43,311 Epoch[40] Batch [830]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.092090,	
2017-06-24 00:12:49,131 Epoch[40] Batch [840]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.092142,	
2017-06-24 00:12:55,139 Epoch[40] Batch [850]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.092057,	
2017-06-24 00:13:00,970 Epoch[40] Batch [860]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.091965,	
2017-06-24 00:13:06,788 Epoch[40] Batch [870]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.092041,	
2017-06-24 00:13:12,762 Epoch[40] Batch [880]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.091991,	
2017-06-24 00:13:18,944 Epoch[40] Batch [890]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.091910,	
2017-06-24 00:13:25,101 Epoch[40] Batch [900]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.091893,	
2017-06-24 00:13:30,915 Epoch[40] Batch [910]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.091774,	
2017-06-24 00:13:36,441 Epoch[40] Batch [920]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.091744,	
2017-06-24 00:13:42,142 Epoch[40] Batch [930]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.091693,	
2017-06-24 00:13:47,945 Epoch[40] Batch [940]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.091669,	
2017-06-24 00:13:53,146 Epoch[40] Batch [950]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.091735,	
2017-06-24 00:13:58,349 Epoch[40] Batch [960]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.091684,	
2017-06-24 00:14:03,566 Epoch[40] Batch [970]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.091609,	
2017-06-24 00:14:09,233 Epoch[40] Batch [980]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.091631,	
2017-06-24 00:14:14,725 Epoch[40] Batch [990]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.091590,	
2017-06-24 00:14:20,193 Epoch[40] Batch [1000]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.091601,	
2017-06-24 00:14:25,514 Epoch[40] Batch [1010]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091515,	
2017-06-24 00:14:31,039 Epoch[40] Batch [1020]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.091614,	
2017-06-24 00:14:36,685 Epoch[40] Batch [1030]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.091529,	
2017-06-24 00:14:42,099 Epoch[40] Batch [1040]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.091538,	
2017-06-24 00:14:47,586 Epoch[40] Batch [1050]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.091520,	
2017-06-24 00:14:53,323 Epoch[40] Batch [1060]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.091450,	
2017-06-24 00:14:59,384 Epoch[40] Batch [1070]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.091469,	
2017-06-24 00:15:04,783 Epoch[40] Batch [1080]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.091446,	
2017-06-24 00:15:10,242 Epoch[40] Batch [1090]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091464,	
2017-06-24 00:15:15,646 Epoch[40] Batch [1100]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.091439,	
2017-06-24 00:15:21,022 Epoch[40] Batch [1110]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091379,	
2017-06-24 00:15:26,287 Epoch[40] Batch [1120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.091327,	
2017-06-24 00:15:31,525 Epoch[40] Batch [1130]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.091294,	
2017-06-24 00:15:36,718 Epoch[40] Batch [1140]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.091211,	
2017-06-24 00:15:41,880 Epoch[40] Batch [1150]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.091290,	
2017-06-24 00:15:47,091 Epoch[40] Batch [1160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.091271,	
2017-06-24 00:15:52,531 Epoch[40] Batch [1170]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091263,	
2017-06-24 00:15:57,967 Epoch[40] Batch [1180]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091122,	
2017-06-24 00:16:03,157 Epoch[40] Batch [1190]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.091062,	
2017-06-24 00:16:08,749 Epoch[40] Batch [1200]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.090986,	
2017-06-24 00:16:13,954 Epoch[40] Batch [1210]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.090879,	
2017-06-24 00:16:19,734 Epoch[40] Batch [1220]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.090875,	
2017-06-24 00:16:25,527 Epoch[40] Batch [1230]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.090994,	
2017-06-24 00:16:31,584 Epoch[40] Batch [1240]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.090965,	
2017-06-24 00:16:37,404 Epoch[40] Batch [1250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.090885,	
2017-06-24 00:16:42,783 Epoch[40] Batch [1260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090862,	
2017-06-24 00:16:48,273 Epoch[40] Batch [1270]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.090881,	
2017-06-24 00:16:53,548 Epoch[40] Batch [1280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090926,	
2017-06-24 00:16:58,633 Epoch[40] Batch [1290]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.090943,	
2017-06-24 00:17:04,001 Epoch[40] Batch [1300]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090914,	
2017-06-24 00:17:09,822 Epoch[40] Batch [1310]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.090985,	
2017-06-24 00:17:15,908 Epoch[40] Batch [1320]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.090976,	
2017-06-24 00:17:21,069 Epoch[40] Batch [1330]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090969,	
2017-06-24 00:17:26,272 Epoch[40] Batch [1340]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.090912,	
2017-06-24 00:17:31,996 Epoch[40] Batch [1350]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.090875,	
2017-06-24 00:17:37,493 Epoch[40] Batch [1360]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.090784,	
2017-06-24 00:17:42,672 Epoch[40] Batch [1370]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.090717,	
2017-06-24 00:17:48,043 Epoch[40] Batch [1380]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090645,	
2017-06-24 00:17:53,269 Epoch[40] Batch [1390]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090616,	
2017-06-24 00:17:58,438 Epoch[40] Batch [1400]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.090600,	
2017-06-24 00:18:03,876 Epoch[40] Batch [1410]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090561,	
2017-06-24 00:18:09,124 Epoch[40] Batch [1420]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090562,	
2017-06-24 00:18:14,287 Epoch[40] Batch [1430]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090498,	
2017-06-24 00:18:19,558 Epoch[40] Batch [1440]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090443,	
2017-06-24 00:18:24,760 Epoch[40] Batch [1450]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.090418,	
2017-06-24 00:18:30,001 Epoch[40] Batch [1460]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090410,	
2017-06-24 00:18:35,185 Epoch[40] Batch [1470]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.090397,	
2017-06-24 00:18:40,571 Epoch[40] Batch [1480]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090304,	
2017-06-24 00:18:43,615 Epoch[40] Train-FCNLogLoss=0.090271
2017-06-24 00:18:43,615 Epoch[40] Time cost=815.657
2017-06-24 00:18:44,564 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0041.params"
2017-06-24 00:18:48,115 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0041.states"
2017-06-24 00:18:54,605 Epoch[41] Batch [10]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.082133,	
2017-06-24 00:18:59,751 Epoch[41] Batch [20]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089031,	
2017-06-24 00:19:04,963 Epoch[41] Batch [30]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.089932,	
2017-06-24 00:19:10,165 Epoch[41] Batch [40]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088926,	
2017-06-24 00:19:16,013 Epoch[41] Batch [50]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.088450,	
2017-06-24 00:19:22,026 Epoch[41] Batch [60]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088553,	
2017-06-24 00:19:27,744 Epoch[41] Batch [70]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.087987,	
2017-06-24 00:19:33,615 Epoch[41] Batch [80]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-24 00:19:40,083 Epoch[41] Batch [90]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.087402,	
2017-06-24 00:19:46,309 Epoch[41] Batch [100]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087086,	
2017-06-24 00:19:52,792 Epoch[41] Batch [110]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.087077,	
2017-06-24 00:19:59,321 Epoch[41] Batch [120]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.086704,	
2017-06-24 00:20:05,344 Epoch[41] Batch [130]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.086718,	
2017-06-24 00:20:11,197 Epoch[41] Batch [140]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086852,	
2017-06-24 00:20:16,382 Epoch[41] Batch [150]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.087466,	
2017-06-24 00:20:22,160 Epoch[41] Batch [160]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087101,	
2017-06-24 00:20:28,161 Epoch[41] Batch [170]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087171,	
2017-06-24 00:20:34,284 Epoch[41] Batch [180]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.087321,	
2017-06-24 00:20:40,452 Epoch[41] Batch [190]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.086878,	
2017-06-24 00:20:46,533 Epoch[41] Batch [200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.086637,	
2017-06-24 00:20:53,591 Epoch[41] Batch [210]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.086803,	
2017-06-24 00:21:00,012 Epoch[41] Batch [220]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087078,	
2017-06-24 00:21:06,352 Epoch[41] Batch [230]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.087298,	
2017-06-24 00:21:12,705 Epoch[41] Batch [240]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.087097,	
2017-06-24 00:21:18,658 Epoch[41] Batch [250]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.087337,	
2017-06-24 00:21:24,979 Epoch[41] Batch [260]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087368,	
2017-06-24 00:21:31,376 Epoch[41] Batch [270]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087507,	
2017-06-24 00:21:37,920 Epoch[41] Batch [280]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.087768,	
2017-06-24 00:21:44,571 Epoch[41] Batch [290]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087587,	
2017-06-24 00:21:50,688 Epoch[41] Batch [300]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087919,	
2017-06-24 00:21:57,198 Epoch[41] Batch [310]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.087857,	
2017-06-24 00:22:03,798 Epoch[41] Batch [320]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.087840,	
2017-06-24 00:22:10,522 Epoch[41] Batch [330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.087663,	
2017-06-24 00:22:17,093 Epoch[41] Batch [340]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.087570,	
2017-06-24 00:22:23,617 Epoch[41] Batch [350]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.087495,	
2017-06-24 00:22:29,921 Epoch[41] Batch [360]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087671,	
2017-06-24 00:22:36,620 Epoch[41] Batch [370]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.087843,	
2017-06-24 00:22:42,788 Epoch[41] Batch [380]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.088008,	
2017-06-24 00:22:49,317 Epoch[41] Batch [390]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.087988,	
2017-06-24 00:22:55,825 Epoch[41] Batch [400]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.087995,	
2017-06-24 00:23:01,970 Epoch[41] Batch [410]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.087882,	
2017-06-24 00:23:08,342 Epoch[41] Batch [420]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087524,	
2017-06-24 00:23:15,201 Epoch[41] Batch [430]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.087727,	
2017-06-24 00:23:21,604 Epoch[41] Batch [440]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087711,	
2017-06-24 00:23:28,548 Epoch[41] Batch [450]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.087702,	
2017-06-24 00:23:35,257 Epoch[41] Batch [460]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.087647,	
2017-06-24 00:23:41,501 Epoch[41] Batch [470]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087833,	
2017-06-24 00:23:47,459 Epoch[41] Batch [480]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087869,	
2017-06-24 00:23:53,752 Epoch[41] Batch [490]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.087937,	
2017-06-24 00:23:59,801 Epoch[41] Batch [500]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.087850,	
2017-06-24 00:24:05,630 Epoch[41] Batch [510]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087937,	
2017-06-24 00:24:11,928 Epoch[41] Batch [520]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087988,	
2017-06-24 00:24:18,472 Epoch[41] Batch [530]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088008,	
2017-06-24 00:24:24,548 Epoch[41] Batch [540]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.088053,	
2017-06-24 00:24:30,595 Epoch[41] Batch [550]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.087899,	
2017-06-24 00:24:36,991 Epoch[41] Batch [560]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087893,	
2017-06-24 00:24:43,149 Epoch[41] Batch [570]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087864,	
2017-06-24 00:24:48,798 Epoch[41] Batch [580]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.087831,	
2017-06-24 00:24:54,330 Epoch[41] Batch [590]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.087991,	
2017-06-24 00:25:00,319 Epoch[41] Batch [600]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.088214,	
2017-06-24 00:25:06,259 Epoch[41] Batch [610]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.088300,	
2017-06-24 00:25:12,715 Epoch[41] Batch [620]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088366,	
2017-06-24 00:25:18,590 Epoch[41] Batch [630]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.088296,	
2017-06-24 00:25:25,124 Epoch[41] Batch [640]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.088171,	
2017-06-24 00:25:31,085 Epoch[41] Batch [650]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088250,	
2017-06-24 00:25:37,037 Epoch[41] Batch [660]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.088352,	
2017-06-24 00:25:43,142 Epoch[41] Batch [670]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.088469,	
2017-06-24 00:25:49,109 Epoch[41] Batch [680]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.088349,	
2017-06-24 00:25:55,901 Epoch[41] Batch [690]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.088322,	
2017-06-24 00:26:02,199 Epoch[41] Batch [700]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088295,	
2017-06-24 00:26:08,463 Epoch[41] Batch [710]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088220,	
2017-06-24 00:26:15,130 Epoch[41] Batch [720]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.088307,	
2017-06-24 00:26:21,601 Epoch[41] Batch [730]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.088409,	
2017-06-24 00:26:27,632 Epoch[41] Batch [740]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.088403,	
2017-06-24 00:26:33,044 Epoch[41] Batch [750]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088336,	
2017-06-24 00:26:39,215 Epoch[41] Batch [760]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.088217,	
2017-06-24 00:26:44,996 Epoch[41] Batch [770]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.088152,	
2017-06-24 00:26:50,355 Epoch[41] Batch [780]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088172,	
2017-06-24 00:26:56,178 Epoch[41] Batch [790]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088174,	
2017-06-24 00:27:02,365 Epoch[41] Batch [800]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.088061,	
2017-06-24 00:27:08,103 Epoch[41] Batch [810]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.088041,	
2017-06-24 00:27:14,270 Epoch[41] Batch [820]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.088136,	
2017-06-24 00:27:20,147 Epoch[41] Batch [830]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.088003,	
2017-06-24 00:27:26,432 Epoch[41] Batch [840]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.088003,	
2017-06-24 00:27:32,783 Epoch[41] Batch [850]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.087939,	
2017-06-24 00:27:38,962 Epoch[41] Batch [860]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.087985,	
2017-06-24 00:27:44,882 Epoch[41] Batch [870]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.087979,	
2017-06-24 00:27:51,038 Epoch[41] Batch [880]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087951,	
2017-06-24 00:27:57,194 Epoch[41] Batch [890]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087992,	
2017-06-24 00:28:03,580 Epoch[41] Batch [900]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.087991,	
2017-06-24 00:28:09,620 Epoch[41] Batch [910]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087982,	
2017-06-24 00:28:15,524 Epoch[41] Batch [920]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.087825,	
2017-06-24 00:28:21,167 Epoch[41] Batch [930]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.087708,	
2017-06-24 00:28:27,039 Epoch[41] Batch [940]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087668,	
2017-06-24 00:28:32,812 Epoch[41] Batch [950]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087642,	
2017-06-24 00:28:38,494 Epoch[41] Batch [960]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.087651,	
2017-06-24 00:28:43,798 Epoch[41] Batch [970]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087666,	
2017-06-24 00:28:49,246 Epoch[41] Batch [980]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.087692,	
2017-06-24 00:28:54,393 Epoch[41] Batch [990]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-24 00:28:59,685 Epoch[41] Batch [1000]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.087625,	
2017-06-24 00:29:04,878 Epoch[41] Batch [1010]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087654,	
2017-06-24 00:29:10,560 Epoch[41] Batch [1020]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.087660,	
2017-06-24 00:29:16,106 Epoch[41] Batch [1030]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087711,	
2017-06-24 00:29:21,582 Epoch[41] Batch [1040]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.087645,	
2017-06-24 00:29:27,369 Epoch[41] Batch [1050]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087628,	
2017-06-24 00:29:32,864 Epoch[41] Batch [1060]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.087654,	
2017-06-24 00:29:38,794 Epoch[41] Batch [1070]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087629,	
2017-06-24 00:29:44,838 Epoch[41] Batch [1080]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087587,	
2017-06-24 00:29:50,657 Epoch[41] Batch [1090]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.087568,	
2017-06-24 00:29:56,218 Epoch[41] Batch [1100]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.087517,	
2017-06-24 00:30:01,475 Epoch[41] Batch [1110]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087598,	
2017-06-24 00:30:06,835 Epoch[41] Batch [1120]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087563,	
2017-06-24 00:30:12,718 Epoch[41] Batch [1130]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087632,	
2017-06-24 00:30:18,692 Epoch[41] Batch [1140]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.087660,	
2017-06-24 00:30:24,452 Epoch[41] Batch [1150]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087669,	
2017-06-24 00:30:30,586 Epoch[41] Batch [1160]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.087614,	
2017-06-24 00:30:36,168 Epoch[41] Batch [1170]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.087682,	
2017-06-24 00:30:42,573 Epoch[41] Batch [1180]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-24 00:30:48,206 Epoch[41] Batch [1190]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.087565,	
2017-06-24 00:30:53,895 Epoch[41] Batch [1200]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087686,	
2017-06-24 00:31:00,042 Epoch[41] Batch [1210]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.087632,	
2017-06-24 00:31:06,195 Epoch[41] Batch [1220]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087547,	
2017-06-24 00:31:12,251 Epoch[41] Batch [1230]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.087471,	
2017-06-24 00:31:18,049 Epoch[41] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.087471,	
2017-06-24 00:31:23,874 Epoch[41] Batch [1250]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.087452,	
2017-06-24 00:31:29,333 Epoch[41] Batch [1260]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.087388,	
2017-06-24 00:31:35,779 Epoch[41] Batch [1270]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087329,	
2017-06-24 00:31:43,035 Epoch[41] Batch [1280]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.087353,	
2017-06-24 00:31:49,367 Epoch[41] Batch [1290]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.087335,	
2017-06-24 00:31:55,285 Epoch[41] Batch [1300]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.087388,	
2017-06-24 00:32:00,876 Epoch[41] Batch [1310]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087377,	
2017-06-24 00:32:06,461 Epoch[41] Batch [1320]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.087419,	
2017-06-24 00:32:12,217 Epoch[41] Batch [1330]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087431,	
2017-06-24 00:32:17,938 Epoch[41] Batch [1340]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.087385,	
2017-06-24 00:32:23,754 Epoch[41] Batch [1350]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087377,	
2017-06-24 00:32:29,796 Epoch[41] Batch [1360]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087375,	
2017-06-24 00:32:35,936 Epoch[41] Batch [1370]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.087401,	
2017-06-24 00:32:42,102 Epoch[41] Batch [1380]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087390,	
2017-06-24 00:32:48,095 Epoch[41] Batch [1390]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087328,	
2017-06-24 00:32:53,723 Epoch[41] Batch [1400]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.087335,	
2017-06-24 00:32:59,474 Epoch[41] Batch [1410]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.087343,	
2017-06-24 00:33:05,776 Epoch[41] Batch [1420]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087348,	
2017-06-24 00:33:11,772 Epoch[41] Batch [1430]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087371,	
2017-06-24 00:33:18,529 Epoch[41] Batch [1440]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-24 00:33:24,453 Epoch[41] Batch [1450]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087327,	
2017-06-24 00:33:30,635 Epoch[41] Batch [1460]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.087321,	
2017-06-24 00:33:36,686 Epoch[41] Batch [1470]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.087458,	
2017-06-24 00:33:42,885 Epoch[41] Batch [1480]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.087491,	
2017-06-24 00:33:46,401 Epoch[41] Train-FCNLogLoss=0.087491
2017-06-24 00:33:46,402 Epoch[41] Time cost=898.286
2017-06-24 00:33:47,347 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0042.params"
2017-06-24 00:33:51,039 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0042.states"
2017-06-24 00:33:57,687 Epoch[42] Batch [10]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.091944,	
2017-06-24 00:34:03,249 Epoch[42] Batch [20]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.089682,	
2017-06-24 00:34:09,264 Epoch[42] Batch [30]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.086380,	
2017-06-24 00:34:14,857 Epoch[42] Batch [40]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.085895,	
2017-06-24 00:34:20,401 Epoch[42] Batch [50]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.085952,	
2017-06-24 00:34:25,908 Epoch[42] Batch [60]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.084420,	
2017-06-24 00:34:31,700 Epoch[42] Batch [70]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.084318,	
2017-06-24 00:34:37,246 Epoch[42] Batch [80]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.084169,	
2017-06-24 00:34:43,234 Epoch[42] Batch [90]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.083906,	
2017-06-24 00:34:49,578 Epoch[42] Batch [100]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.084474,	
2017-06-24 00:34:55,164 Epoch[42] Batch [110]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.084897,	
2017-06-24 00:35:00,379 Epoch[42] Batch [120]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.085701,	
2017-06-24 00:35:06,118 Epoch[42] Batch [130]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.085485,	
2017-06-24 00:35:11,581 Epoch[42] Batch [140]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.084553,	
2017-06-24 00:35:17,339 Epoch[42] Batch [150]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.085036,	
2017-06-24 00:35:22,977 Epoch[42] Batch [160]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.085281,	
2017-06-24 00:35:28,533 Epoch[42] Batch [170]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.085951,	
2017-06-24 00:35:34,223 Epoch[42] Batch [180]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086336,	
2017-06-24 00:35:39,660 Epoch[42] Batch [190]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086706,	
2017-06-24 00:35:45,378 Epoch[42] Batch [200]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.086688,	
2017-06-24 00:35:50,922 Epoch[42] Batch [210]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.086793,	
2017-06-24 00:35:57,258 Epoch[42] Batch [220]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.086651,	
2017-06-24 00:36:02,906 Epoch[42] Batch [230]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086387,	
2017-06-24 00:36:08,778 Epoch[42] Batch [240]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086418,	
2017-06-24 00:36:14,631 Epoch[42] Batch [250]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086676,	
2017-06-24 00:36:20,438 Epoch[42] Batch [260]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086764,	
2017-06-24 00:36:25,985 Epoch[42] Batch [270]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087030,	
2017-06-24 00:36:31,813 Epoch[42] Batch [280]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.086897,	
2017-06-24 00:36:37,671 Epoch[42] Batch [290]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.087032,	
2017-06-24 00:36:43,611 Epoch[42] Batch [300]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.086714,	
2017-06-24 00:36:49,122 Epoch[42] Batch [310]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.086951,	
2017-06-24 00:36:54,835 Epoch[42] Batch [320]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.086754,	
2017-06-24 00:37:00,598 Epoch[42] Batch [330]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086827,	
2017-06-24 00:37:06,955 Epoch[42] Batch [340]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087062,	
2017-06-24 00:37:12,694 Epoch[42] Batch [350]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.086809,	
2017-06-24 00:37:18,237 Epoch[42] Batch [360]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.086634,	
2017-06-24 00:37:23,763 Epoch[42] Batch [370]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086739,	
2017-06-24 00:37:29,601 Epoch[42] Batch [380]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086565,	
2017-06-24 00:37:35,472 Epoch[42] Batch [390]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-24 00:37:41,721 Epoch[42] Batch [400]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.086739,	
2017-06-24 00:37:47,862 Epoch[42] Batch [410]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086669,	
2017-06-24 00:37:54,072 Epoch[42] Batch [420]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.086586,	
2017-06-24 00:37:59,695 Epoch[42] Batch [430]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.086581,	
2017-06-24 00:38:04,944 Epoch[42] Batch [440]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.086546,	
2017-06-24 00:38:10,688 Epoch[42] Batch [450]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086668,	
2017-06-24 00:38:16,011 Epoch[42] Batch [460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.086627,	
2017-06-24 00:38:21,483 Epoch[42] Batch [470]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.086462,	
2017-06-24 00:38:27,149 Epoch[42] Batch [480]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.086381,	
2017-06-24 00:38:32,697 Epoch[42] Batch [490]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.086280,	
2017-06-24 00:38:38,020 Epoch[42] Batch [500]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.086318,	
2017-06-24 00:38:43,732 Epoch[42] Batch [510]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.086370,	
2017-06-24 00:38:49,550 Epoch[42] Batch [520]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086445,	
2017-06-24 00:38:55,478 Epoch[42] Batch [530]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.086326,	
2017-06-24 00:39:01,681 Epoch[42] Batch [540]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086380,	
2017-06-24 00:39:07,563 Epoch[42] Batch [550]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.086462,	
2017-06-24 00:39:13,420 Epoch[42] Batch [560]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086644,	
2017-06-24 00:39:19,052 Epoch[42] Batch [570]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.086775,	
2017-06-24 00:39:24,841 Epoch[42] Batch [580]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.086866,	
2017-06-24 00:39:30,552 Epoch[42] Batch [590]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.087027,	
2017-06-24 00:39:36,368 Epoch[42] Batch [600]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087082,	
2017-06-24 00:39:42,028 Epoch[42] Batch [610]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.086914,	
2017-06-24 00:39:48,132 Epoch[42] Batch [620]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.086854,	
2017-06-24 00:39:53,764 Epoch[42] Batch [630]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.087076,	
2017-06-24 00:39:59,839 Epoch[42] Batch [640]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087068,	
2017-06-24 00:40:05,742 Epoch[42] Batch [650]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.087001,	
2017-06-24 00:40:11,873 Epoch[42] Batch [660]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.086943,	
2017-06-24 00:40:17,576 Epoch[42] Batch [670]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.086946,	
2017-06-24 00:40:23,225 Epoch[42] Batch [680]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086986,	
2017-06-24 00:40:29,048 Epoch[42] Batch [690]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086933,	
2017-06-24 00:40:35,255 Epoch[42] Batch [700]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086939,	
2017-06-24 00:40:40,986 Epoch[42] Batch [710]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087027,	
2017-06-24 00:40:46,814 Epoch[42] Batch [720]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087132,	
2017-06-24 00:40:52,157 Epoch[42] Batch [730]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087052,	
2017-06-24 00:40:57,919 Epoch[42] Batch [740]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086937,	
2017-06-24 00:41:03,643 Epoch[42] Batch [750]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086801,	
2017-06-24 00:41:09,784 Epoch[42] Batch [760]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086767,	
2017-06-24 00:41:15,453 Epoch[42] Batch [770]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.086764,	
2017-06-24 00:41:21,049 Epoch[42] Batch [780]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.086791,	
2017-06-24 00:41:26,745 Epoch[42] Batch [790]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.086802,	
2017-06-24 00:41:32,051 Epoch[42] Batch [800]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086717,	
2017-06-24 00:41:37,327 Epoch[42] Batch [810]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086716,	
2017-06-24 00:41:42,539 Epoch[42] Batch [820]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086726,	
2017-06-24 00:41:48,053 Epoch[42] Batch [830]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.086759,	
2017-06-24 00:41:53,893 Epoch[42] Batch [840]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086817,	
2017-06-24 00:41:59,930 Epoch[42] Batch [850]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086749,	
2017-06-24 00:42:05,418 Epoch[42] Batch [860]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.086698,	
2017-06-24 00:42:11,056 Epoch[42] Batch [870]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.086697,	
2017-06-24 00:42:16,971 Epoch[42] Batch [880]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086716,	
2017-06-24 00:42:23,221 Epoch[42] Batch [890]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.086699,	
2017-06-24 00:42:29,921 Epoch[42] Batch [900]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086670,	
2017-06-24 00:42:35,838 Epoch[42] Batch [910]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086676,	
2017-06-24 00:42:42,231 Epoch[42] Batch [920]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.086678,	
2017-06-24 00:42:48,238 Epoch[42] Batch [930]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.086668,	
2017-06-24 00:42:54,709 Epoch[42] Batch [940]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.086753,	
2017-06-24 00:43:00,635 Epoch[42] Batch [950]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.086770,	
2017-06-24 00:43:07,090 Epoch[42] Batch [960]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.086884,	
2017-06-24 00:43:12,607 Epoch[42] Batch [970]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.086967,	
2017-06-24 00:43:18,324 Epoch[42] Batch [980]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.087003,	
2017-06-24 00:43:24,135 Epoch[42] Batch [990]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087068,	
2017-06-24 00:43:29,910 Epoch[42] Batch [1000]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087084,	
2017-06-24 00:43:36,088 Epoch[42] Batch [1010]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087110,	
2017-06-24 00:43:41,980 Epoch[42] Batch [1020]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.087102,	
2017-06-24 00:43:48,004 Epoch[42] Batch [1030]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.087254,	
2017-06-24 00:43:53,806 Epoch[42] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.087273,	
2017-06-24 00:43:59,430 Epoch[42] Batch [1050]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.087255,	
2017-06-24 00:44:05,200 Epoch[42] Batch [1060]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087206,	
2017-06-24 00:44:11,232 Epoch[42] Batch [1070]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.087218,	
2017-06-24 00:44:17,547 Epoch[42] Batch [1080]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087216,	
2017-06-24 00:44:23,549 Epoch[42] Batch [1090]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087166,	
2017-06-24 00:44:29,813 Epoch[42] Batch [1100]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.087244,	
2017-06-24 00:44:35,560 Epoch[42] Batch [1110]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.087265,	
2017-06-24 00:44:41,246 Epoch[42] Batch [1120]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087312,	
2017-06-24 00:44:47,364 Epoch[42] Batch [1130]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087335,	
2017-06-24 00:44:53,599 Epoch[42] Batch [1140]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087363,	
2017-06-24 00:44:59,591 Epoch[42] Batch [1150]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087408,	
2017-06-24 00:45:05,615 Epoch[42] Batch [1160]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.087303,	
2017-06-24 00:45:11,428 Epoch[42] Batch [1170]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087239,	
2017-06-24 00:45:17,272 Epoch[42] Batch [1180]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.087272,	
2017-06-24 00:45:23,763 Epoch[42] Batch [1190]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.087299,	
2017-06-24 00:45:29,593 Epoch[42] Batch [1200]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087227,	
2017-06-24 00:45:35,321 Epoch[42] Batch [1210]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087197,	
2017-06-24 00:45:41,286 Epoch[42] Batch [1220]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087252,	
2017-06-24 00:45:47,774 Epoch[42] Batch [1230]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.087169,	
2017-06-24 00:45:54,461 Epoch[42] Batch [1240]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087215,	
2017-06-24 00:46:00,444 Epoch[42] Batch [1250]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087179,	
2017-06-24 00:46:06,646 Epoch[42] Batch [1260]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.087180,	
2017-06-24 00:46:12,809 Epoch[42] Batch [1270]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087145,	
2017-06-24 00:46:18,623 Epoch[42] Batch [1280]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087185,	
2017-06-24 00:46:24,525 Epoch[42] Batch [1290]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.087211,	
2017-06-24 00:46:30,313 Epoch[42] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087198,	
2017-06-24 00:46:36,101 Epoch[42] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087169,	
2017-06-24 00:46:42,080 Epoch[42] Batch [1320]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087123,	
2017-06-24 00:46:48,089 Epoch[42] Batch [1330]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.087081,	
2017-06-24 00:46:53,794 Epoch[42] Batch [1340]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.087118,	
2017-06-24 00:46:59,466 Epoch[42] Batch [1350]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087126,	
2017-06-24 00:47:05,119 Epoch[42] Batch [1360]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.087144,	
2017-06-24 00:47:11,239 Epoch[42] Batch [1370]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087155,	
2017-06-24 00:47:17,554 Epoch[42] Batch [1380]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087147,	
2017-06-24 00:47:23,762 Epoch[42] Batch [1390]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.087187,	
2017-06-24 00:47:29,585 Epoch[42] Batch [1400]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.087153,	
2017-06-24 00:47:35,338 Epoch[42] Batch [1410]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087157,	
2017-06-24 00:47:40,964 Epoch[42] Batch [1420]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.087174,	
2017-06-24 00:47:46,664 Epoch[42] Batch [1430]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.087201,	
2017-06-24 00:47:52,736 Epoch[42] Batch [1440]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087183,	
2017-06-24 00:47:58,732 Epoch[42] Batch [1450]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087209,	
2017-06-24 00:48:04,565 Epoch[42] Batch [1460]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087274,	
2017-06-24 00:48:10,304 Epoch[42] Batch [1470]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087287,	
2017-06-24 00:48:15,923 Epoch[42] Batch [1480]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.087262,	
2017-06-24 00:48:19,481 Epoch[42] Train-FCNLogLoss=0.087252
2017-06-24 00:48:19,481 Epoch[42] Time cost=868.442
2017-06-24 00:48:20,489 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0043.params"
2017-06-24 00:48:24,207 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0043.states"
2017-06-24 00:48:31,283 Epoch[43] Batch [10]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.093414,	
2017-06-24 00:48:37,797 Epoch[43] Batch [20]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.090547,	
2017-06-24 00:48:43,180 Epoch[43] Batch [30]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090789,	
2017-06-24 00:48:48,849 Epoch[43] Batch [40]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089925,	
2017-06-24 00:48:54,740 Epoch[43] Batch [50]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.089038,	
2017-06-24 00:49:00,326 Epoch[43] Batch [60]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.089638,	
2017-06-24 00:49:06,052 Epoch[43] Batch [70]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-24 00:49:11,513 Epoch[43] Batch [80]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.090035,	
2017-06-24 00:49:16,727 Epoch[43] Batch [90]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.090480,	
2017-06-24 00:49:22,498 Epoch[43] Batch [100]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.090341,	
2017-06-24 00:49:28,107 Epoch[43] Batch [110]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.089984,	
2017-06-24 00:49:33,543 Epoch[43] Batch [120]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.089083,	
2017-06-24 00:49:39,432 Epoch[43] Batch [130]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088454,	
2017-06-24 00:49:44,933 Epoch[43] Batch [140]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.088654,	
2017-06-24 00:49:50,665 Epoch[43] Batch [150]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.088512,	
2017-06-24 00:49:56,630 Epoch[43] Batch [160]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088146,	
2017-06-24 00:50:02,489 Epoch[43] Batch [170]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.088177,	
2017-06-24 00:50:08,042 Epoch[43] Batch [180]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088187,	
2017-06-24 00:50:13,835 Epoch[43] Batch [190]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.088008,	
2017-06-24 00:50:19,486 Epoch[43] Batch [200]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.088455,	
2017-06-24 00:50:25,065 Epoch[43] Batch [210]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088612,	
2017-06-24 00:50:30,627 Epoch[43] Batch [220]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088432,	
2017-06-24 00:50:36,772 Epoch[43] Batch [230]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.088337,	
2017-06-24 00:50:42,665 Epoch[43] Batch [240]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088464,	
2017-06-24 00:50:48,537 Epoch[43] Batch [250]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.088550,	
2017-06-24 00:50:53,912 Epoch[43] Batch [260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088569,	
2017-06-24 00:50:59,443 Epoch[43] Batch [270]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088628,	
2017-06-24 00:51:05,617 Epoch[43] Batch [280]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.088417,	
2017-06-24 00:51:11,090 Epoch[43] Batch [290]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088206,	
2017-06-24 00:51:16,982 Epoch[43] Batch [300]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088295,	
2017-06-24 00:51:23,025 Epoch[43] Batch [310]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087883,	
2017-06-24 00:51:29,060 Epoch[43] Batch [320]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.087802,	
2017-06-24 00:51:35,261 Epoch[43] Batch [330]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.087782,	
2017-06-24 00:51:40,933 Epoch[43] Batch [340]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087862,	
2017-06-24 00:51:46,845 Epoch[43] Batch [350]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087900,	
2017-06-24 00:51:52,531 Epoch[43] Batch [360]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087648,	
2017-06-24 00:51:58,298 Epoch[43] Batch [370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087567,	
2017-06-24 00:52:04,175 Epoch[43] Batch [380]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087636,	
2017-06-24 00:52:09,898 Epoch[43] Batch [390]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.087782,	
2017-06-24 00:52:15,927 Epoch[43] Batch [400]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.087709,	
2017-06-24 00:52:21,525 Epoch[43] Batch [410]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087748,	
2017-06-24 00:52:27,714 Epoch[43] Batch [420]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.087885,	
2017-06-24 00:52:33,292 Epoch[43] Batch [430]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.087888,	
2017-06-24 00:52:39,547 Epoch[43] Batch [440]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.088053,	
2017-06-24 00:52:45,867 Epoch[43] Batch [450]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087968,	
2017-06-24 00:52:52,429 Epoch[43] Batch [460]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.087868,	
2017-06-24 00:52:58,636 Epoch[43] Batch [470]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.088117,	
2017-06-24 00:53:04,720 Epoch[43] Batch [480]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.088102,	
2017-06-24 00:53:10,738 Epoch[43] Batch [490]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088046,	
2017-06-24 00:53:16,807 Epoch[43] Batch [500]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087951,	
2017-06-24 00:53:23,903 Epoch[43] Batch [510]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.087838,	
2017-06-24 00:53:29,993 Epoch[43] Batch [520]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.087859,	
2017-06-24 00:53:36,460 Epoch[43] Batch [530]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.087641,	
2017-06-24 00:53:42,984 Epoch[43] Batch [540]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.087736,	
2017-06-24 00:53:49,674 Epoch[43] Batch [550]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-24 00:53:55,930 Epoch[43] Batch [560]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.087817,	
2017-06-24 00:54:01,872 Epoch[43] Batch [570]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087709,	
2017-06-24 00:54:08,033 Epoch[43] Batch [580]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087670,	
2017-06-24 00:54:14,349 Epoch[43] Batch [590]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087595,	
2017-06-24 00:54:20,925 Epoch[43] Batch [600]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087622,	
2017-06-24 00:54:27,344 Epoch[43] Batch [610]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087433,	
2017-06-24 00:54:33,315 Epoch[43] Batch [620]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.087393,	
2017-06-24 00:54:39,537 Epoch[43] Batch [630]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.087478,	
2017-06-24 00:54:45,985 Epoch[43] Batch [640]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.087458,	
2017-06-24 00:54:52,046 Epoch[43] Batch [650]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.087373,	
2017-06-24 00:54:58,789 Epoch[43] Batch [660]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.087527,	
2017-06-24 00:55:04,951 Epoch[43] Batch [670]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087621,	
2017-06-24 00:55:10,981 Epoch[43] Batch [680]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.087610,	
2017-06-24 00:55:17,478 Epoch[43] Batch [690]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.087604,	
2017-06-24 00:55:23,381 Epoch[43] Batch [700]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.087540,	
2017-06-24 00:55:30,146 Epoch[43] Batch [710]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.087671,	
2017-06-24 00:55:36,678 Epoch[43] Batch [720]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-24 00:55:42,925 Epoch[43] Batch [730]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.087605,	
2017-06-24 00:55:49,147 Epoch[43] Batch [740]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.087648,	
2017-06-24 00:55:55,254 Epoch[43] Batch [750]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.087577,	
2017-06-24 00:56:00,925 Epoch[43] Batch [760]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087562,	
2017-06-24 00:56:07,078 Epoch[43] Batch [770]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087652,	
2017-06-24 00:56:13,515 Epoch[43] Batch [780]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087733,	
2017-06-24 00:56:20,521 Epoch[43] Batch [790]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.087834,	
2017-06-24 00:56:27,931 Epoch[43] Batch [800]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.087812,	
2017-06-24 00:56:34,695 Epoch[43] Batch [810]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-24 00:56:41,191 Epoch[43] Batch [820]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.087796,	
2017-06-24 00:56:47,934 Epoch[43] Batch [830]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.087792,	
2017-06-24 00:56:54,511 Epoch[43] Batch [840]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087881,	
2017-06-24 00:57:00,803 Epoch[43] Batch [850]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.087928,	
2017-06-24 00:57:07,359 Epoch[43] Batch [860]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.087950,	
2017-06-24 00:57:13,882 Epoch[43] Batch [870]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.087973,	
2017-06-24 00:57:20,419 Epoch[43] Batch [880]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.087994,	
2017-06-24 00:57:27,142 Epoch[43] Batch [890]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.088006,	
2017-06-24 00:57:33,840 Epoch[43] Batch [900]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.087999,	
2017-06-24 00:57:39,950 Epoch[43] Batch [910]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.087847,	
2017-06-24 00:57:46,237 Epoch[43] Batch [920]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.087855,	
2017-06-24 00:57:52,413 Epoch[43] Batch [930]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087815,	
2017-06-24 00:57:58,835 Epoch[43] Batch [940]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087847,	
2017-06-24 00:58:05,017 Epoch[43] Batch [950]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.087862,	
2017-06-24 00:58:11,088 Epoch[43] Batch [960]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087779,	
2017-06-24 00:58:17,209 Epoch[43] Batch [970]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087783,	
2017-06-24 00:58:23,728 Epoch[43] Batch [980]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.087718,	
2017-06-24 00:58:29,741 Epoch[43] Batch [990]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.087666,	
2017-06-24 00:58:35,585 Epoch[43] Batch [1000]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-24 00:58:41,755 Epoch[43] Batch [1010]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087579,	
2017-06-24 00:58:47,801 Epoch[43] Batch [1020]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087531,	
2017-06-24 00:58:53,853 Epoch[43] Batch [1030]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.087510,	
2017-06-24 00:58:59,815 Epoch[43] Batch [1040]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087497,	
2017-06-24 00:59:05,850 Epoch[43] Batch [1050]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.087571,	
2017-06-24 00:59:12,322 Epoch[43] Batch [1060]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.087539,	
2017-06-24 00:59:18,980 Epoch[43] Batch [1070]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087492,	
2017-06-24 00:59:25,062 Epoch[43] Batch [1080]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087477,	
2017-06-24 00:59:30,938 Epoch[43] Batch [1090]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087504,	
2017-06-24 00:59:37,269 Epoch[43] Batch [1100]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.087459,	
2017-06-24 00:59:43,672 Epoch[43] Batch [1110]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087409,	
2017-06-24 00:59:49,789 Epoch[43] Batch [1120]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087443,	
2017-06-24 00:59:56,364 Epoch[43] Batch [1130]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087478,	
2017-06-24 01:00:02,772 Epoch[43] Batch [1140]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.087434,	
2017-06-24 01:00:08,973 Epoch[43] Batch [1150]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.087457,	
2017-06-24 01:00:15,313 Epoch[43] Batch [1160]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.087517,	
2017-06-24 01:00:21,947 Epoch[43] Batch [1170]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.087615,	
2017-06-24 01:00:27,702 Epoch[43] Batch [1180]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087589,	
2017-06-24 01:00:34,193 Epoch[43] Batch [1190]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.087534,	
2017-06-24 01:00:40,252 Epoch[43] Batch [1200]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.087541,	
2017-06-24 01:00:46,668 Epoch[43] Batch [1210]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.087588,	
2017-06-24 01:00:53,125 Epoch[43] Batch [1220]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.087611,	
2017-06-24 01:00:59,492 Epoch[43] Batch [1230]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-24 01:01:05,672 Epoch[43] Batch [1240]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.087539,	
2017-06-24 01:01:11,605 Epoch[43] Batch [1250]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.087512,	
2017-06-24 01:01:17,540 Epoch[43] Batch [1260]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.087546,	
2017-06-24 01:01:23,607 Epoch[43] Batch [1270]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-24 01:01:30,165 Epoch[43] Batch [1280]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.087459,	
2017-06-24 01:01:36,248 Epoch[43] Batch [1290]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087524,	
2017-06-24 01:01:41,909 Epoch[43] Batch [1300]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-24 01:01:47,394 Epoch[43] Batch [1310]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.087523,	
2017-06-24 01:01:53,348 Epoch[43] Batch [1320]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.087462,	
2017-06-24 01:01:58,936 Epoch[43] Batch [1330]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.087481,	
2017-06-24 01:02:04,839 Epoch[43] Batch [1340]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.087454,	
2017-06-24 01:02:10,535 Epoch[43] Batch [1350]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-24 01:02:16,615 Epoch[43] Batch [1360]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087397,	
2017-06-24 01:02:22,083 Epoch[43] Batch [1370]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.087362,	
2017-06-24 01:02:27,225 Epoch[43] Batch [1380]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.087354,	
2017-06-24 01:02:33,210 Epoch[43] Batch [1390]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087387,	
2017-06-24 01:02:38,414 Epoch[43] Batch [1400]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087319,	
2017-06-24 01:02:43,868 Epoch[43] Batch [1410]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.087411,	
2017-06-24 01:02:49,410 Epoch[43] Batch [1420]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.087416,	
2017-06-24 01:02:54,545 Epoch[43] Batch [1430]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087447,	
2017-06-24 01:03:00,224 Epoch[43] Batch [1440]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.087398,	
2017-06-24 01:03:05,932 Epoch[43] Batch [1450]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.087416,	
2017-06-24 01:03:11,403 Epoch[43] Batch [1460]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.087406,	
2017-06-24 01:03:16,576 Epoch[43] Batch [1470]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087336,	
2017-06-24 01:03:21,825 Epoch[43] Batch [1480]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087325,	
2017-06-24 01:03:24,978 Epoch[43] Train-FCNLogLoss=0.087297
2017-06-24 01:03:24,978 Epoch[43] Time cost=900.771
2017-06-24 01:03:25,982 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0044.params"
2017-06-24 01:03:29,617 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0044.states"
2017-06-24 01:03:36,735 Epoch[44] Batch [10]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.082557,	
2017-06-24 01:03:42,879 Epoch[44] Batch [20]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.084235,	
2017-06-24 01:03:48,791 Epoch[44] Batch [30]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.083698,	
2017-06-24 01:03:54,836 Epoch[44] Batch [40]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.084592,	
2017-06-24 01:04:00,906 Epoch[44] Batch [50]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.085995,	
2017-06-24 01:04:06,920 Epoch[44] Batch [60]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088108,	
2017-06-24 01:04:12,829 Epoch[44] Batch [70]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087328,	
2017-06-24 01:04:18,519 Epoch[44] Batch [80]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087549,	
2017-06-24 01:04:24,333 Epoch[44] Batch [90]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088544,	
2017-06-24 01:04:30,251 Epoch[44] Batch [100]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.088206,	
2017-06-24 01:04:36,296 Epoch[44] Batch [110]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.088171,	
2017-06-24 01:04:41,896 Epoch[44] Batch [120]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.088088,	
2017-06-24 01:04:47,616 Epoch[44] Batch [130]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.088064,	
2017-06-24 01:04:53,353 Epoch[44] Batch [140]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.088288,	
2017-06-24 01:04:59,333 Epoch[44] Batch [150]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087670,	
2017-06-24 01:05:04,904 Epoch[44] Batch [160]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.087251,	
2017-06-24 01:05:10,757 Epoch[44] Batch [170]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.087255,	
2017-06-24 01:05:16,438 Epoch[44] Batch [180]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-24 01:05:22,556 Epoch[44] Batch [190]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087305,	
2017-06-24 01:05:28,319 Epoch[44] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087389,	
2017-06-24 01:05:34,204 Epoch[44] Batch [210]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.086845,	
2017-06-24 01:05:40,050 Epoch[44] Batch [220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086968,	
2017-06-24 01:05:45,988 Epoch[44] Batch [230]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.087495,	
2017-06-24 01:05:52,122 Epoch[44] Batch [240]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.087471,	
2017-06-24 01:05:58,215 Epoch[44] Batch [250]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.087302,	
2017-06-24 01:06:03,977 Epoch[44] Batch [260]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087349,	
2017-06-24 01:06:09,569 Epoch[44] Batch [270]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087479,	
2017-06-24 01:06:15,302 Epoch[44] Batch [280]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087526,	
2017-06-24 01:06:20,916 Epoch[44] Batch [290]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.087653,	
2017-06-24 01:06:26,692 Epoch[44] Batch [300]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087659,	
2017-06-24 01:06:32,508 Epoch[44] Batch [310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087816,	
2017-06-24 01:06:38,286 Epoch[44] Batch [320]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087780,	
2017-06-24 01:06:44,369 Epoch[44] Batch [330]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087860,	
2017-06-24 01:06:50,110 Epoch[44] Batch [340]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087620,	
2017-06-24 01:06:56,312 Epoch[44] Batch [350]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.087301,	
2017-06-24 01:07:01,767 Epoch[44] Batch [360]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.087226,	
2017-06-24 01:07:08,400 Epoch[44] Batch [370]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.087257,	
2017-06-24 01:07:14,988 Epoch[44] Batch [380]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.087093,	
2017-06-24 01:07:21,161 Epoch[44] Batch [390]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087007,	
2017-06-24 01:07:27,203 Epoch[44] Batch [400]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087076,	
2017-06-24 01:07:32,664 Epoch[44] Batch [410]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.087039,	
2017-06-24 01:07:38,199 Epoch[44] Batch [420]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.087047,	
2017-06-24 01:07:43,687 Epoch[44] Batch [430]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.086909,	
2017-06-24 01:07:49,195 Epoch[44] Batch [440]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.086966,	
2017-06-24 01:07:55,051 Epoch[44] Batch [450]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.087068,	
2017-06-24 01:08:00,759 Epoch[44] Batch [460]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.087051,	
2017-06-24 01:08:06,516 Epoch[44] Batch [470]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087072,	
2017-06-24 01:08:12,955 Epoch[44] Batch [480]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087033,	
2017-06-24 01:08:19,851 Epoch[44] Batch [490]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.087022,	
2017-06-24 01:08:26,072 Epoch[44] Batch [500]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.087027,	
2017-06-24 01:08:32,116 Epoch[44] Batch [510]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087072,	
2017-06-24 01:08:37,870 Epoch[44] Batch [520]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087117,	
2017-06-24 01:08:43,865 Epoch[44] Batch [530]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087130,	
2017-06-24 01:08:49,366 Epoch[44] Batch [540]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.087048,	
2017-06-24 01:08:54,711 Epoch[44] Batch [550]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.086987,	
2017-06-24 01:09:00,185 Epoch[44] Batch [560]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.087024,	
2017-06-24 01:09:06,027 Epoch[44] Batch [570]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.087077,	
2017-06-24 01:09:11,506 Epoch[44] Batch [580]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.086980,	
2017-06-24 01:09:17,503 Epoch[44] Batch [590]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087013,	
2017-06-24 01:09:23,098 Epoch[44] Batch [600]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087012,	
2017-06-24 01:09:29,240 Epoch[44] Batch [610]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086935,	
2017-06-24 01:09:35,412 Epoch[44] Batch [620]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.086923,	
2017-06-24 01:09:41,051 Epoch[44] Batch [630]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086944,	
2017-06-24 01:09:46,591 Epoch[44] Batch [640]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.086927,	
2017-06-24 01:09:51,753 Epoch[44] Batch [650]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.086900,	
2017-06-24 01:09:57,390 Epoch[44] Batch [660]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.086793,	
2017-06-24 01:10:02,995 Epoch[44] Batch [670]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.086857,	
2017-06-24 01:10:08,359 Epoch[44] Batch [680]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.086815,	
2017-06-24 01:10:14,501 Epoch[44] Batch [690]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086979,	
2017-06-24 01:10:19,801 Epoch[44] Batch [700]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.086957,	
2017-06-24 01:10:25,132 Epoch[44] Batch [710]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086942,	
2017-06-24 01:10:30,751 Epoch[44] Batch [720]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.086894,	
2017-06-24 01:10:36,777 Epoch[44] Batch [730]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.086775,	
2017-06-24 01:10:42,859 Epoch[44] Batch [740]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.086808,	
2017-06-24 01:10:48,890 Epoch[44] Batch [750]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086798,	
2017-06-24 01:10:54,160 Epoch[44] Batch [760]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086789,	
2017-06-24 01:10:59,846 Epoch[44] Batch [770]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086854,	
2017-06-24 01:11:05,282 Epoch[44] Batch [780]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086895,	
2017-06-24 01:11:10,561 Epoch[44] Batch [790]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086906,	
2017-06-24 01:11:15,664 Epoch[44] Batch [800]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.086939,	
2017-06-24 01:11:20,898 Epoch[44] Batch [810]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086948,	
2017-06-24 01:11:26,086 Epoch[44] Batch [820]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.087021,	
2017-06-24 01:11:31,297 Epoch[44] Batch [830]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.086913,	
2017-06-24 01:11:36,504 Epoch[44] Batch [840]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.086911,	
2017-06-24 01:11:41,685 Epoch[44] Batch [850]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.086992,	
2017-06-24 01:11:46,878 Epoch[44] Batch [860]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.086917,	
2017-06-24 01:11:52,143 Epoch[44] Batch [870]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086947,	
2017-06-24 01:11:57,299 Epoch[44] Batch [880]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.086918,	
2017-06-24 01:12:02,535 Epoch[44] Batch [890]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086965,	
2017-06-24 01:12:07,748 Epoch[44] Batch [900]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086964,	
2017-06-24 01:12:12,924 Epoch[44] Batch [910]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.086931,	
2017-06-24 01:12:18,111 Epoch[44] Batch [920]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.087011,	
2017-06-24 01:12:23,326 Epoch[44] Batch [930]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.087012,	
2017-06-24 01:12:28,529 Epoch[44] Batch [940]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087033,	
2017-06-24 01:12:33,781 Epoch[44] Batch [950]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.087114,	
2017-06-24 01:12:38,899 Epoch[44] Batch [960]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087141,	
2017-06-24 01:12:44,221 Epoch[44] Batch [970]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087123,	
2017-06-24 01:12:49,398 Epoch[44] Batch [980]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087132,	
2017-06-24 01:12:54,604 Epoch[44] Batch [990]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087128,	
2017-06-24 01:12:59,859 Epoch[44] Batch [1000]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087060,	
2017-06-24 01:13:05,067 Epoch[44] Batch [1010]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087005,	
2017-06-24 01:13:10,369 Epoch[44] Batch [1020]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.086966,	
2017-06-24 01:13:15,441 Epoch[44] Batch [1030]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.086980,	
2017-06-24 01:13:20,566 Epoch[44] Batch [1040]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.086938,	
2017-06-24 01:13:25,843 Epoch[44] Batch [1050]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086914,	
2017-06-24 01:13:30,978 Epoch[44] Batch [1060]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.086930,	
2017-06-24 01:13:36,212 Epoch[44] Batch [1070]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086936,	
2017-06-24 01:13:41,652 Epoch[44] Batch [1080]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.086931,	
2017-06-24 01:13:46,856 Epoch[44] Batch [1090]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.086918,	
2017-06-24 01:13:52,059 Epoch[44] Batch [1100]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.086886,	
2017-06-24 01:13:57,276 Epoch[44] Batch [1110]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086889,	
2017-06-24 01:14:02,520 Epoch[44] Batch [1120]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086840,	
2017-06-24 01:14:07,754 Epoch[44] Batch [1130]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.086914,	
2017-06-24 01:14:12,832 Epoch[44] Batch [1140]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.086998,	
2017-06-24 01:14:18,077 Epoch[44] Batch [1150]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.086984,	
2017-06-24 01:14:23,264 Epoch[44] Batch [1160]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.086961,	
2017-06-24 01:14:28,431 Epoch[44] Batch [1170]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.086947,	
2017-06-24 01:14:34,243 Epoch[44] Batch [1180]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.086860,	
2017-06-24 01:14:40,455 Epoch[44] Batch [1190]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.086875,	
2017-06-24 01:14:46,863 Epoch[44] Batch [1200]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.086922,	
2017-06-24 01:14:52,642 Epoch[44] Batch [1210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086923,	
2017-06-24 01:14:57,951 Epoch[44] Batch [1220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086916,	
2017-06-24 01:15:03,705 Epoch[44] Batch [1230]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086901,	
2017-06-24 01:15:09,230 Epoch[44] Batch [1240]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086937,	
2017-06-24 01:15:15,111 Epoch[44] Batch [1250]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.086923,	
2017-06-24 01:15:20,862 Epoch[44] Batch [1260]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086870,	
2017-06-24 01:15:26,593 Epoch[44] Batch [1270]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086886,	
2017-06-24 01:15:32,022 Epoch[44] Batch [1280]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.086865,	
2017-06-24 01:15:38,003 Epoch[44] Batch [1290]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087007,	
2017-06-24 01:15:43,572 Epoch[44] Batch [1300]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.087103,	
2017-06-24 01:15:49,364 Epoch[44] Batch [1310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087069,	
2017-06-24 01:15:55,180 Epoch[44] Batch [1320]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087059,	
2017-06-24 01:16:01,059 Epoch[44] Batch [1330]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087043,	
2017-06-24 01:16:06,482 Epoch[44] Batch [1340]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.087001,	
2017-06-24 01:16:12,110 Epoch[44] Batch [1350]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.087018,	
2017-06-24 01:16:17,938 Epoch[44] Batch [1360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087026,	
2017-06-24 01:16:23,690 Epoch[44] Batch [1370]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087050,	
2017-06-24 01:16:29,545 Epoch[44] Batch [1380]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.087036,	
2017-06-24 01:16:35,526 Epoch[44] Batch [1390]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087015,	
2017-06-24 01:16:41,269 Epoch[44] Batch [1400]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087022,	
2017-06-24 01:16:47,075 Epoch[44] Batch [1410]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086994,	
2017-06-24 01:16:52,957 Epoch[44] Batch [1420]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.086974,	
2017-06-24 01:16:58,869 Epoch[44] Batch [1430]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.086962,	
2017-06-24 01:17:04,224 Epoch[44] Batch [1440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.086893,	
2017-06-24 01:17:10,054 Epoch[44] Batch [1450]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.086943,	
2017-06-24 01:17:16,040 Epoch[44] Batch [1460]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086905,	
2017-06-24 01:17:21,899 Epoch[44] Batch [1470]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086907,	
2017-06-24 01:17:27,807 Epoch[44] Batch [1480]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.086876,	
2017-06-24 01:17:31,021 Epoch[44] Train-FCNLogLoss=0.086869
2017-06-24 01:17:31,021 Epoch[44] Time cost=841.404
2017-06-24 01:17:31,946 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0045.params"
2017-06-24 01:17:35,447 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0045.states"
2017-06-24 01:17:41,965 Epoch[45] Batch [10]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.090362,	
2017-06-24 01:17:47,428 Epoch[45] Batch [20]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.089714,	
2017-06-24 01:17:52,847 Epoch[45] Batch [30]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.086650,	
2017-06-24 01:17:58,600 Epoch[45] Batch [40]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087236,	
2017-06-24 01:18:04,703 Epoch[45] Batch [50]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.086809,	
2017-06-24 01:18:10,772 Epoch[45] Batch [60]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.086937,	
2017-06-24 01:18:17,257 Epoch[45] Batch [70]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.087577,	
2017-06-24 01:18:23,270 Epoch[45] Batch [80]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.086483,	
2017-06-24 01:18:29,001 Epoch[45] Batch [90]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086883,	
2017-06-24 01:18:35,341 Epoch[45] Batch [100]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.087177,	
2017-06-24 01:18:41,873 Epoch[45] Batch [110]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.086962,	
2017-06-24 01:18:48,011 Epoch[45] Batch [120]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.087088,	
2017-06-24 01:18:54,284 Epoch[45] Batch [130]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.086484,	
2017-06-24 01:19:00,898 Epoch[45] Batch [140]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.086508,	
2017-06-24 01:19:07,559 Epoch[45] Batch [150]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.086672,	
2017-06-24 01:19:13,806 Epoch[45] Batch [160]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.086616,	
2017-06-24 01:19:19,957 Epoch[45] Batch [170]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.086700,	
2017-06-24 01:19:26,379 Epoch[45] Batch [180]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.087296,	
2017-06-24 01:19:32,789 Epoch[45] Batch [190]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.087066,	
2017-06-24 01:19:38,634 Epoch[45] Batch [200]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086919,	
2017-06-24 01:19:44,551 Epoch[45] Batch [210]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.087386,	
2017-06-24 01:19:50,949 Epoch[45] Batch [220]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.087610,	
2017-06-24 01:19:56,823 Epoch[45] Batch [230]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087151,	
2017-06-24 01:20:02,767 Epoch[45] Batch [240]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087230,	
2017-06-24 01:20:09,325 Epoch[45] Batch [250]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.087252,	
2017-06-24 01:20:15,844 Epoch[45] Batch [260]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.087207,	
2017-06-24 01:20:22,159 Epoch[45] Batch [270]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.086620,	
2017-06-24 01:20:28,497 Epoch[45] Batch [280]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.086760,	
2017-06-24 01:20:34,868 Epoch[45] Batch [290]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086636,	
2017-06-24 01:20:41,313 Epoch[45] Batch [300]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.086689,	
2017-06-24 01:20:47,750 Epoch[45] Batch [310]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.086467,	
2017-06-24 01:20:54,023 Epoch[45] Batch [320]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.086383,	
2017-06-24 01:20:59,971 Epoch[45] Batch [330]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.086387,	
2017-06-24 01:21:06,189 Epoch[45] Batch [340]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.086488,	
2017-06-24 01:21:11,943 Epoch[45] Batch [350]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086427,	
2017-06-24 01:21:18,016 Epoch[45] Batch [360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.086530,	
2017-06-24 01:21:24,396 Epoch[45] Batch [370]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.086449,	
2017-06-24 01:21:30,813 Epoch[45] Batch [380]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086739,	
2017-06-24 01:21:36,755 Epoch[45] Batch [390]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.086537,	
2017-06-24 01:21:42,235 Epoch[45] Batch [400]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.086625,	
2017-06-24 01:21:48,226 Epoch[45] Batch [410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086352,	
2017-06-24 01:21:54,069 Epoch[45] Batch [420]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086334,	
2017-06-24 01:21:59,837 Epoch[45] Batch [430]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086296,	
2017-06-24 01:22:05,449 Epoch[45] Batch [440]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.086438,	
2017-06-24 01:22:11,350 Epoch[45] Batch [450]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.086567,	
2017-06-24 01:22:16,843 Epoch[45] Batch [460]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.086893,	
2017-06-24 01:22:22,739 Epoch[45] Batch [470]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.086764,	
2017-06-24 01:22:28,448 Epoch[45] Batch [480]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.086659,	
2017-06-24 01:22:34,607 Epoch[45] Batch [490]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.086689,	
2017-06-24 01:22:40,383 Epoch[45] Batch [500]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086653,	
2017-06-24 01:22:46,327 Epoch[45] Batch [510]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.086405,	
2017-06-24 01:22:52,122 Epoch[45] Batch [520]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086564,	
2017-06-24 01:22:57,606 Epoch[45] Batch [530]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.086714,	
2017-06-24 01:23:03,483 Epoch[45] Batch [540]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086736,	
2017-06-24 01:23:08,763 Epoch[45] Batch [550]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.086807,	
2017-06-24 01:23:14,789 Epoch[45] Batch [560]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.087104,	
2017-06-24 01:23:20,214 Epoch[45] Batch [570]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.087197,	
2017-06-24 01:23:25,969 Epoch[45] Batch [580]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087190,	
2017-06-24 01:23:31,613 Epoch[45] Batch [590]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.087265,	
2017-06-24 01:23:37,801 Epoch[45] Batch [600]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.087274,	
2017-06-24 01:23:43,542 Epoch[45] Batch [610]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087199,	
2017-06-24 01:23:49,213 Epoch[45] Batch [620]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087445,	
2017-06-24 01:23:54,966 Epoch[45] Batch [630]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.087482,	
2017-06-24 01:24:00,924 Epoch[45] Batch [640]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087412,	
2017-06-24 01:24:06,999 Epoch[45] Batch [650]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087436,	
2017-06-24 01:24:13,319 Epoch[45] Batch [660]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087293,	
2017-06-24 01:24:19,168 Epoch[45] Batch [670]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.087154,	
2017-06-24 01:24:25,102 Epoch[45] Batch [680]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.087255,	
2017-06-24 01:24:30,595 Epoch[45] Batch [690]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.087201,	
2017-06-24 01:24:36,369 Epoch[45] Batch [700]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087205,	
2017-06-24 01:24:42,280 Epoch[45] Batch [710]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087164,	
2017-06-24 01:24:48,203 Epoch[45] Batch [720]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087144,	
2017-06-24 01:24:54,062 Epoch[45] Batch [730]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.087102,	
2017-06-24 01:24:59,683 Epoch[45] Batch [740]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.087157,	
2017-06-24 01:25:05,201 Epoch[45] Batch [750]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.087182,	
2017-06-24 01:25:11,513 Epoch[45] Batch [760]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.087173,	
2017-06-24 01:25:17,438 Epoch[45] Batch [770]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087238,	
2017-06-24 01:25:23,749 Epoch[45] Batch [780]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.087153,	
2017-06-24 01:25:29,469 Epoch[45] Batch [790]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.087125,	
2017-06-24 01:25:35,082 Epoch[45] Batch [800]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.087080,	
2017-06-24 01:25:40,714 Epoch[45] Batch [810]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.087133,	
2017-06-24 01:25:46,192 Epoch[45] Batch [820]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.087103,	
2017-06-24 01:25:52,250 Epoch[45] Batch [830]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.087062,	
2017-06-24 01:25:57,521 Epoch[45] Batch [840]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.086991,	
2017-06-24 01:26:02,855 Epoch[45] Batch [850]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086952,	
2017-06-24 01:26:08,730 Epoch[45] Batch [860]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087036,	
2017-06-24 01:26:14,371 Epoch[45] Batch [870]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.087083,	
2017-06-24 01:26:20,571 Epoch[45] Batch [880]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.087254,	
2017-06-24 01:26:26,496 Epoch[45] Batch [890]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087342,	
2017-06-24 01:26:32,238 Epoch[45] Batch [900]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087286,	
2017-06-24 01:26:38,001 Epoch[45] Batch [910]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087264,	
2017-06-24 01:26:43,875 Epoch[45] Batch [920]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087290,	
2017-06-24 01:26:49,859 Epoch[45] Batch [930]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087359,	
2017-06-24 01:26:56,022 Epoch[45] Batch [940]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087212,	
2017-06-24 01:27:01,767 Epoch[45] Batch [950]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.087278,	
2017-06-24 01:27:07,700 Epoch[45] Batch [960]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.087228,	
2017-06-24 01:27:13,727 Epoch[45] Batch [970]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.087138,	
2017-06-24 01:27:19,862 Epoch[45] Batch [980]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.087191,	
2017-06-24 01:27:26,448 Epoch[45] Batch [990]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.087224,	
2017-06-24 01:27:32,979 Epoch[45] Batch [1000]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.087159,	
2017-06-24 01:27:39,373 Epoch[45] Batch [1010]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.087141,	
2017-06-24 01:27:45,338 Epoch[45] Batch [1020]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087172,	
2017-06-24 01:27:51,025 Epoch[45] Batch [1030]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087160,	
2017-06-24 01:27:56,530 Epoch[45] Batch [1040]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.087114,	
2017-06-24 01:28:02,344 Epoch[45] Batch [1050]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087120,	
2017-06-24 01:28:08,345 Epoch[45] Batch [1060]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087130,	
2017-06-24 01:28:14,121 Epoch[45] Batch [1070]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087012,	
2017-06-24 01:28:20,092 Epoch[45] Batch [1080]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086948,	
2017-06-24 01:28:26,416 Epoch[45] Batch [1090]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.086962,	
2017-06-24 01:28:32,506 Epoch[45] Batch [1100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.086915,	
2017-06-24 01:28:38,354 Epoch[45] Batch [1110]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086944,	
2017-06-24 01:28:44,499 Epoch[45] Batch [1120]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086937,	
2017-06-24 01:28:49,937 Epoch[45] Batch [1130]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086904,	
2017-06-24 01:28:55,510 Epoch[45] Batch [1140]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.086842,	
2017-06-24 01:29:01,245 Epoch[45] Batch [1150]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086872,	
2017-06-24 01:29:07,210 Epoch[45] Batch [1160]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086934,	
2017-06-24 01:29:13,119 Epoch[45] Batch [1170]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.086929,	
2017-06-24 01:29:19,575 Epoch[45] Batch [1180]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.086997,	
2017-06-24 01:29:25,299 Epoch[45] Batch [1190]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086982,	
2017-06-24 01:29:31,268 Epoch[45] Batch [1200]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086995,	
2017-06-24 01:29:36,945 Epoch[45] Batch [1210]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.086929,	
2017-06-24 01:29:42,798 Epoch[45] Batch [1220]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086937,	
2017-06-24 01:29:48,439 Epoch[45] Batch [1230]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086928,	
2017-06-24 01:29:54,586 Epoch[45] Batch [1240]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086948,	
2017-06-24 01:30:00,850 Epoch[45] Batch [1250]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.086922,	
2017-06-24 01:30:07,241 Epoch[45] Batch [1260]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.086887,	
2017-06-24 01:30:13,317 Epoch[45] Batch [1270]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.086935,	
2017-06-24 01:30:19,891 Epoch[45] Batch [1280]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.086967,	
2017-06-24 01:30:25,504 Epoch[45] Batch [1290]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.087014,	
2017-06-24 01:30:31,605 Epoch[45] Batch [1300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.086968,	
2017-06-24 01:30:37,782 Epoch[45] Batch [1310]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087054,	
2017-06-24 01:30:43,663 Epoch[45] Batch [1320]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087079,	
2017-06-24 01:30:49,434 Epoch[45] Batch [1330]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087110,	
2017-06-24 01:30:55,320 Epoch[45] Batch [1340]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087075,	
2017-06-24 01:31:01,458 Epoch[45] Batch [1350]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.087085,	
2017-06-24 01:31:07,468 Epoch[45] Batch [1360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.087037,	
2017-06-24 01:31:13,760 Epoch[45] Batch [1370]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.087062,	
2017-06-24 01:31:19,643 Epoch[45] Batch [1380]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087048,	
2017-06-24 01:31:25,868 Epoch[45] Batch [1390]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.087009,	
2017-06-24 01:31:31,811 Epoch[45] Batch [1400]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087046,	
2017-06-24 01:31:37,920 Epoch[45] Batch [1410]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.087032,	
2017-06-24 01:31:43,567 Epoch[45] Batch [1420]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.087049,	
2017-06-24 01:31:49,821 Epoch[45] Batch [1430]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.086963,	
2017-06-24 01:31:55,516 Epoch[45] Batch [1440]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.086904,	
2017-06-24 01:32:01,383 Epoch[45] Batch [1450]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.086967,	
2017-06-24 01:32:07,944 Epoch[45] Batch [1460]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.086958,	
2017-06-24 01:32:14,249 Epoch[45] Batch [1470]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.086946,	
2017-06-24 01:32:20,060 Epoch[45] Batch [1480]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.086935,	
2017-06-24 01:32:23,579 Epoch[45] Train-FCNLogLoss=0.086971
2017-06-24 01:32:23,579 Epoch[45] Time cost=888.132
2017-06-24 01:32:24,470 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0046.params"
2017-06-24 01:32:28,161 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0046.states"
2017-06-24 01:32:35,253 Epoch[46] Batch [10]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.084993,	
2017-06-24 01:32:40,697 Epoch[46] Batch [20]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.082202,	
2017-06-24 01:32:46,378 Epoch[46] Batch [30]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.083716,	
2017-06-24 01:32:52,345 Epoch[46] Batch [40]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.085109,	
2017-06-24 01:32:58,136 Epoch[46] Batch [50]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.084711,	
2017-06-24 01:33:03,825 Epoch[46] Batch [60]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.085120,	
2017-06-24 01:33:09,373 Epoch[46] Batch [70]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.084707,	
2017-06-24 01:33:14,990 Epoch[46] Batch [80]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.084832,	
2017-06-24 01:33:20,999 Epoch[46] Batch [90]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.085786,	
2017-06-24 01:33:26,196 Epoch[46] Batch [100]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.085352,	
2017-06-24 01:33:32,354 Epoch[46] Batch [110]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.085228,	
2017-06-24 01:33:38,390 Epoch[46] Batch [120]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.085432,	
2017-06-24 01:33:44,086 Epoch[46] Batch [130]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.085627,	
2017-06-24 01:33:49,857 Epoch[46] Batch [140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085696,	
2017-06-24 01:33:55,778 Epoch[46] Batch [150]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.085937,	
2017-06-24 01:34:01,814 Epoch[46] Batch [160]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086453,	
2017-06-24 01:34:07,732 Epoch[46] Batch [170]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086000,	
2017-06-24 01:34:13,491 Epoch[46] Batch [180]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.085827,	
2017-06-24 01:34:19,128 Epoch[46] Batch [190]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.085818,	
2017-06-24 01:34:25,497 Epoch[46] Batch [200]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086028,	
2017-06-24 01:34:31,024 Epoch[46] Batch [210]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086202,	
2017-06-24 01:34:36,439 Epoch[46] Batch [220]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.085913,	
2017-06-24 01:34:42,471 Epoch[46] Batch [230]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086216,	
2017-06-24 01:34:48,303 Epoch[46] Batch [240]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.086086,	
2017-06-24 01:34:54,287 Epoch[46] Batch [250]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086174,	
2017-06-24 01:34:59,674 Epoch[46] Batch [260]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.086337,	
2017-06-24 01:35:05,706 Epoch[46] Batch [270]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086029,	
2017-06-24 01:35:11,165 Epoch[46] Batch [280]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.085941,	
2017-06-24 01:35:17,124 Epoch[46] Batch [290]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086062,	
2017-06-24 01:35:22,755 Epoch[46] Batch [300]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.085824,	
2017-06-24 01:35:28,437 Epoch[46] Batch [310]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.085541,	
2017-06-24 01:35:33,966 Epoch[46] Batch [320]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.085623,	
2017-06-24 01:35:40,168 Epoch[46] Batch [330]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085509,	
2017-06-24 01:35:45,629 Epoch[46] Batch [340]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.085699,	
2017-06-24 01:35:51,450 Epoch[46] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.085857,	
2017-06-24 01:35:57,227 Epoch[46] Batch [360]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085752,	
2017-06-24 01:36:02,932 Epoch[46] Batch [370]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.085859,	
2017-06-24 01:36:08,321 Epoch[46] Batch [380]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.085829,	
2017-06-24 01:36:13,908 Epoch[46] Batch [390]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.086142,	
2017-06-24 01:36:19,665 Epoch[46] Batch [400]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086044,	
2017-06-24 01:36:25,718 Epoch[46] Batch [410]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.086112,	
2017-06-24 01:36:31,411 Epoch[46] Batch [420]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086277,	
2017-06-24 01:36:36,976 Epoch[46] Batch [430]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.086414,	
2017-06-24 01:36:42,609 Epoch[46] Batch [440]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.086413,	
2017-06-24 01:36:47,824 Epoch[46] Batch [450]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.086385,	
2017-06-24 01:36:53,331 Epoch[46] Batch [460]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.086472,	
2017-06-24 01:36:58,781 Epoch[46] Batch [470]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.086564,	
2017-06-24 01:37:04,509 Epoch[46] Batch [480]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086507,	
2017-06-24 01:37:10,541 Epoch[46] Batch [490]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086486,	
2017-06-24 01:37:17,135 Epoch[46] Batch [500]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.086552,	
2017-06-24 01:37:23,175 Epoch[46] Batch [510]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-24 01:37:28,771 Epoch[46] Batch [520]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.086709,	
2017-06-24 01:37:34,393 Epoch[46] Batch [530]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.086716,	
2017-06-24 01:37:40,144 Epoch[46] Batch [540]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086702,	
2017-06-24 01:37:46,012 Epoch[46] Batch [550]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.086749,	
2017-06-24 01:37:51,883 Epoch[46] Batch [560]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086847,	
2017-06-24 01:37:57,691 Epoch[46] Batch [570]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086851,	
2017-06-24 01:38:03,998 Epoch[46] Batch [580]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.086839,	
2017-06-24 01:38:09,796 Epoch[46] Batch [590]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086884,	
2017-06-24 01:38:15,474 Epoch[46] Batch [600]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086745,	
2017-06-24 01:38:21,506 Epoch[46] Batch [610]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086756,	
2017-06-24 01:38:27,017 Epoch[46] Batch [620]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.086845,	
2017-06-24 01:38:32,937 Epoch[46] Batch [630]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086706,	
2017-06-24 01:38:38,962 Epoch[46] Batch [640]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.086878,	
2017-06-24 01:38:45,059 Epoch[46] Batch [650]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.086871,	
2017-06-24 01:38:51,309 Epoch[46] Batch [660]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.086800,	
2017-06-24 01:38:56,994 Epoch[46] Batch [670]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086994,	
2017-06-24 01:39:02,977 Epoch[46] Batch [680]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086996,	
2017-06-24 01:39:08,797 Epoch[46] Batch [690]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086931,	
2017-06-24 01:39:14,061 Epoch[46] Batch [700]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.086883,	
2017-06-24 01:39:20,054 Epoch[46] Batch [710]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086758,	
2017-06-24 01:39:25,385 Epoch[46] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086738,	
2017-06-24 01:39:31,366 Epoch[46] Batch [730]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086692,	
2017-06-24 01:39:37,009 Epoch[46] Batch [740]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086585,	
2017-06-24 01:39:42,692 Epoch[46] Batch [750]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086547,	
2017-06-24 01:39:48,881 Epoch[46] Batch [760]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.086465,	
2017-06-24 01:39:55,298 Epoch[46] Batch [770]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086423,	
2017-06-24 01:40:00,980 Epoch[46] Batch [780]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086360,	
2017-06-24 01:40:06,946 Epoch[46] Batch [790]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086348,	
2017-06-24 01:40:13,145 Epoch[46] Batch [800]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086199,	
2017-06-24 01:40:18,865 Epoch[46] Batch [810]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086173,	
2017-06-24 01:40:25,142 Epoch[46] Batch [820]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.086226,	
2017-06-24 01:40:30,666 Epoch[46] Batch [830]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086238,	
2017-06-24 01:40:36,249 Epoch[46] Batch [840]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.086199,	
2017-06-24 01:40:42,554 Epoch[46] Batch [850]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.086161,	
2017-06-24 01:40:48,197 Epoch[46] Batch [860]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086128,	
2017-06-24 01:40:54,148 Epoch[46] Batch [870]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.086045,	
2017-06-24 01:41:00,057 Epoch[46] Batch [880]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085943,	
2017-06-24 01:41:06,128 Epoch[46] Batch [890]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.085866,	
2017-06-24 01:41:11,859 Epoch[46] Batch [900]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.085687,	
2017-06-24 01:41:17,890 Epoch[46] Batch [910]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.085674,	
2017-06-24 01:41:23,582 Epoch[46] Batch [920]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.085672,	
2017-06-24 01:41:29,663 Epoch[46] Batch [930]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.085668,	
2017-06-24 01:41:35,506 Epoch[46] Batch [940]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085672,	
2017-06-24 01:41:41,059 Epoch[46] Batch [950]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.085702,	
2017-06-24 01:41:47,193 Epoch[46] Batch [960]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.085666,	
2017-06-24 01:41:52,937 Epoch[46] Batch [970]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.085576,	
2017-06-24 01:41:58,731 Epoch[46] Batch [980]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.085560,	
2017-06-24 01:42:04,597 Epoch[46] Batch [990]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.085534,	
2017-06-24 01:42:10,597 Epoch[46] Batch [1000]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085587,	
2017-06-24 01:42:16,528 Epoch[46] Batch [1010]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.085613,	
2017-06-24 01:42:22,195 Epoch[46] Batch [1020]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.085599,	
2017-06-24 01:42:28,100 Epoch[46] Batch [1030]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085639,	
2017-06-24 01:42:33,681 Epoch[46] Batch [1040]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.085659,	
2017-06-24 01:42:39,563 Epoch[46] Batch [1050]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.085681,	
2017-06-24 01:42:45,521 Epoch[46] Batch [1060]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.085732,	
2017-06-24 01:42:51,372 Epoch[46] Batch [1070]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085766,	
2017-06-24 01:42:57,102 Epoch[46] Batch [1080]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.085841,	
2017-06-24 01:43:02,799 Epoch[46] Batch [1090]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.085875,	
2017-06-24 01:43:08,154 Epoch[46] Batch [1100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.085920,	
2017-06-24 01:43:13,859 Epoch[46] Batch [1110]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.085925,	
2017-06-24 01:43:19,277 Epoch[46] Batch [1120]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.085871,	
2017-06-24 01:43:25,078 Epoch[46] Batch [1130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.085855,	
2017-06-24 01:43:31,530 Epoch[46] Batch [1140]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.085833,	
2017-06-24 01:43:37,587 Epoch[46] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.085790,	
2017-06-24 01:43:43,473 Epoch[46] Batch [1160]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.085783,	
2017-06-24 01:43:49,319 Epoch[46] Batch [1170]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085892,	
2017-06-24 01:43:55,478 Epoch[46] Batch [1180]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.085866,	
2017-06-24 01:44:01,017 Epoch[46] Batch [1190]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.085903,	
2017-06-24 01:44:06,454 Epoch[46] Batch [1200]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085934,	
2017-06-24 01:44:12,365 Epoch[46] Batch [1210]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085945,	
2017-06-24 01:44:18,214 Epoch[46] Batch [1220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085917,	
2017-06-24 01:44:23,881 Epoch[46] Batch [1230]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.085905,	
2017-06-24 01:44:29,987 Epoch[46] Batch [1240]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.085921,	
2017-06-24 01:44:35,698 Epoch[46] Batch [1250]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.085835,	
2017-06-24 01:44:41,582 Epoch[46] Batch [1260]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.085823,	
2017-06-24 01:44:46,783 Epoch[46] Batch [1270]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.085845,	
2017-06-24 01:44:52,077 Epoch[46] Batch [1280]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.085880,	
2017-06-24 01:44:57,916 Epoch[46] Batch [1290]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085884,	
2017-06-24 01:45:04,234 Epoch[46] Batch [1300]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.085892,	
2017-06-24 01:45:10,531 Epoch[46] Batch [1310]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.085846,	
2017-06-24 01:45:16,276 Epoch[46] Batch [1320]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.085904,	
2017-06-24 01:45:22,445 Epoch[46] Batch [1330]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.085967,	
2017-06-24 01:45:28,960 Epoch[46] Batch [1340]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.085972,	
2017-06-24 01:45:34,811 Epoch[46] Batch [1350]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085926,	
2017-06-24 01:45:40,617 Epoch[46] Batch [1360]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.085956,	
2017-06-24 01:45:46,505 Epoch[46] Batch [1370]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085940,	
2017-06-24 01:45:52,331 Epoch[46] Batch [1380]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.085952,	
2017-06-24 01:45:57,854 Epoch[46] Batch [1390]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.085941,	
2017-06-24 01:46:03,765 Epoch[46] Batch [1400]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085954,	
2017-06-24 01:46:09,544 Epoch[46] Batch [1410]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085993,	
2017-06-24 01:46:15,195 Epoch[46] Batch [1420]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086007,	
2017-06-24 01:46:21,058 Epoch[46] Batch [1430]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.086032,	
2017-06-24 01:46:27,490 Epoch[46] Batch [1440]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.086052,	
2017-06-24 01:46:33,788 Epoch[46] Batch [1450]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.086049,	
2017-06-24 01:46:40,268 Epoch[46] Batch [1460]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.086025,	
2017-06-24 01:46:47,203 Epoch[46] Batch [1470]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.086024,	
2017-06-24 01:46:53,164 Epoch[46] Batch [1480]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.085994,	
2017-06-24 01:46:56,739 Epoch[46] Train-FCNLogLoss=0.086018
2017-06-24 01:46:56,739 Epoch[46] Time cost=868.578
2017-06-24 01:46:57,789 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0047.params"
2017-06-24 01:47:01,383 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0047.states"
2017-06-24 01:47:07,931 Epoch[47] Batch [10]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.078651,	
2017-06-24 01:47:13,645 Epoch[47] Batch [20]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.079635,	
2017-06-24 01:47:18,865 Epoch[47] Batch [30]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.083337,	
2017-06-24 01:47:24,981 Epoch[47] Batch [40]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.083459,	
2017-06-24 01:47:30,411 Epoch[47] Batch [50]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.085710,	
2017-06-24 01:47:36,185 Epoch[47] Batch [60]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085450,	
2017-06-24 01:47:41,947 Epoch[47] Batch [70]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086410,	
2017-06-24 01:47:47,638 Epoch[47] Batch [80]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086485,	
2017-06-24 01:47:53,402 Epoch[47] Batch [90]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086877,	
2017-06-24 01:47:59,123 Epoch[47] Batch [100]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086564,	
2017-06-24 01:48:05,107 Epoch[47] Batch [110]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086671,	
2017-06-24 01:48:10,586 Epoch[47] Batch [120]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.087491,	
2017-06-24 01:48:16,207 Epoch[47] Batch [130]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.087671,	
2017-06-24 01:48:22,079 Epoch[47] Batch [140]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087461,	
2017-06-24 01:48:28,245 Epoch[47] Batch [150]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087639,	
2017-06-24 01:48:34,920 Epoch[47] Batch [160]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.086803,	
2017-06-24 01:48:41,070 Epoch[47] Batch [170]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.086450,	
2017-06-24 01:48:46,561 Epoch[47] Batch [180]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.086332,	
2017-06-24 01:48:52,483 Epoch[47] Batch [190]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.086136,	
2017-06-24 01:48:58,163 Epoch[47] Batch [200]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086403,	
2017-06-24 01:49:04,550 Epoch[47] Batch [210]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.086301,	
2017-06-24 01:49:10,630 Epoch[47] Batch [220]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.086281,	
2017-06-24 01:49:16,438 Epoch[47] Batch [230]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086904,	
2017-06-24 01:49:22,108 Epoch[47] Batch [240]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.086778,	
2017-06-24 01:49:28,483 Epoch[47] Batch [250]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086869,	
2017-06-24 01:49:34,627 Epoch[47] Batch [260]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086686,	
2017-06-24 01:49:41,061 Epoch[47] Batch [270]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.086739,	
2017-06-24 01:49:47,778 Epoch[47] Batch [280]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.086522,	
2017-06-24 01:49:54,286 Epoch[47] Batch [290]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.087136,	
2017-06-24 01:50:00,235 Epoch[47] Batch [300]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.087202,	
2017-06-24 01:50:06,390 Epoch[47] Batch [310]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087252,	
2017-06-24 01:50:11,504 Epoch[47] Batch [320]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087317,	
2017-06-24 01:50:17,306 Epoch[47] Batch [330]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.087246,	
2017-06-24 01:50:22,832 Epoch[47] Batch [340]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.087392,	
2017-06-24 01:50:28,896 Epoch[47] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.087191,	
2017-06-24 01:50:34,757 Epoch[47] Batch [360]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.087202,	
2017-06-24 01:50:40,440 Epoch[47] Batch [370]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.087126,	
2017-06-24 01:50:46,276 Epoch[47] Batch [380]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087363,	
2017-06-24 01:50:51,986 Epoch[47] Batch [390]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.087174,	
2017-06-24 01:50:58,180 Epoch[47] Batch [400]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.087016,	
2017-06-24 01:51:03,557 Epoch[47] Batch [410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087016,	
2017-06-24 01:51:09,247 Epoch[47] Batch [420]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086723,	
2017-06-24 01:51:15,278 Epoch[47] Batch [430]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086616,	
2017-06-24 01:51:21,414 Epoch[47] Batch [440]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.086566,	
2017-06-24 01:51:27,184 Epoch[47] Batch [450]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086541,	
2017-06-24 01:51:33,214 Epoch[47] Batch [460]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086555,	
2017-06-24 01:51:38,704 Epoch[47] Batch [470]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.086753,	
2017-06-24 01:51:44,168 Epoch[47] Batch [480]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.086875,	
2017-06-24 01:51:50,097 Epoch[47] Batch [490]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.086894,	
2017-06-24 01:51:55,744 Epoch[47] Batch [500]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086896,	
2017-06-24 01:52:01,527 Epoch[47] Batch [510]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086888,	
2017-06-24 01:52:06,989 Epoch[47] Batch [520]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.086788,	
2017-06-24 01:52:13,214 Epoch[47] Batch [530]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.086576,	
2017-06-24 01:52:19,285 Epoch[47] Batch [540]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.086677,	
2017-06-24 01:52:25,409 Epoch[47] Batch [550]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.086713,	
2017-06-24 01:52:31,311 Epoch[47] Batch [560]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.086683,	
2017-06-24 01:52:36,843 Epoch[47] Batch [570]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.086781,	
2017-06-24 01:52:42,224 Epoch[47] Batch [580]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.086692,	
2017-06-24 01:52:47,736 Epoch[47] Batch [590]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.086531,	
2017-06-24 01:52:53,274 Epoch[47] Batch [600]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.086572,	
2017-06-24 01:52:59,131 Epoch[47] Batch [610]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086535,	
2017-06-24 01:53:05,116 Epoch[47] Batch [620]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086702,	
2017-06-24 01:53:11,104 Epoch[47] Batch [630]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086646,	
2017-06-24 01:53:17,215 Epoch[47] Batch [640]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.086637,	
2017-06-24 01:53:23,028 Epoch[47] Batch [650]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.086657,	
2017-06-24 01:53:29,097 Epoch[47] Batch [660]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.086660,	
2017-06-24 01:53:34,841 Epoch[47] Batch [670]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086731,	
2017-06-24 01:53:41,076 Epoch[47] Batch [680]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.086665,	
2017-06-24 01:53:46,930 Epoch[47] Batch [690]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086627,	
2017-06-24 01:53:52,608 Epoch[47] Batch [700]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086750,	
2017-06-24 01:53:58,223 Epoch[47] Batch [710]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.086829,	
2017-06-24 01:54:04,260 Epoch[47] Batch [720]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086666,	
2017-06-24 01:54:10,537 Epoch[47] Batch [730]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.086577,	
2017-06-24 01:54:16,305 Epoch[47] Batch [740]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086569,	
2017-06-24 01:54:22,300 Epoch[47] Batch [750]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.086655,	
2017-06-24 01:54:27,783 Epoch[47] Batch [760]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.086665,	
2017-06-24 01:54:33,620 Epoch[47] Batch [770]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086665,	
2017-06-24 01:54:39,287 Epoch[47] Batch [780]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.086701,	
2017-06-24 01:54:45,219 Epoch[47] Batch [790]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.086729,	
2017-06-24 01:54:50,911 Epoch[47] Batch [800]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086653,	
2017-06-24 01:54:56,400 Epoch[47] Batch [810]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.086627,	
2017-06-24 01:55:02,143 Epoch[47] Batch [820]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.086566,	
2017-06-24 01:55:07,743 Epoch[47] Batch [830]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.086472,	
2017-06-24 01:55:13,388 Epoch[47] Batch [840]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086507,	
2017-06-24 01:55:19,246 Epoch[47] Batch [850]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086558,	
2017-06-24 01:55:24,992 Epoch[47] Batch [860]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086663,	
2017-06-24 01:55:30,633 Epoch[47] Batch [870]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086623,	
2017-06-24 01:55:36,551 Epoch[47] Batch [880]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086512,	
2017-06-24 01:55:42,395 Epoch[47] Batch [890]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086411,	
2017-06-24 01:55:48,233 Epoch[47] Batch [900]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086447,	
2017-06-24 01:55:53,821 Epoch[47] Batch [910]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.086552,	
2017-06-24 01:55:59,605 Epoch[47] Batch [920]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086629,	
2017-06-24 01:56:05,133 Epoch[47] Batch [930]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-24 01:56:11,020 Epoch[47] Batch [940]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.086683,	
2017-06-24 01:56:16,895 Epoch[47] Batch [950]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086651,	
2017-06-24 01:56:22,597 Epoch[47] Batch [960]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.086672,	
2017-06-24 01:56:28,444 Epoch[47] Batch [970]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.086643,	
2017-06-24 01:56:34,241 Epoch[47] Batch [980]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086761,	
2017-06-24 01:56:40,018 Epoch[47] Batch [990]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086671,	
2017-06-24 01:56:45,912 Epoch[47] Batch [1000]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.086677,	
2017-06-24 01:56:51,456 Epoch[47] Batch [1010]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.086681,	
2017-06-24 01:56:57,330 Epoch[47] Batch [1020]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.086782,	
2017-06-24 01:57:02,700 Epoch[47] Batch [1030]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.086739,	
2017-06-24 01:57:08,538 Epoch[47] Batch [1040]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086699,	
2017-06-24 01:57:14,138 Epoch[47] Batch [1050]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.086620,	
2017-06-24 01:57:19,694 Epoch[47] Batch [1060]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.086641,	
2017-06-24 01:57:25,132 Epoch[47] Batch [1070]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086595,	
2017-06-24 01:57:30,853 Epoch[47] Batch [1080]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-24 01:57:36,359 Epoch[47] Batch [1090]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.086695,	
2017-06-24 01:57:41,566 Epoch[47] Batch [1100]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.086610,	
2017-06-24 01:57:46,992 Epoch[47] Batch [1110]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.086636,	
2017-06-24 01:57:52,560 Epoch[47] Batch [1120]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.086645,	
2017-06-24 01:57:58,466 Epoch[47] Batch [1130]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.086631,	
2017-06-24 01:58:04,186 Epoch[47] Batch [1140]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086623,	
2017-06-24 01:58:09,912 Epoch[47] Batch [1150]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086599,	
2017-06-24 01:58:15,344 Epoch[47] Batch [1160]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.086560,	
2017-06-24 01:58:20,574 Epoch[47] Batch [1170]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.086570,	
2017-06-24 01:58:26,569 Epoch[47] Batch [1180]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.086482,	
2017-06-24 01:58:32,083 Epoch[47] Batch [1190]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.086509,	
2017-06-24 01:58:37,919 Epoch[47] Batch [1200]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086518,	
2017-06-24 01:58:43,645 Epoch[47] Batch [1210]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086435,	
2017-06-24 01:58:49,289 Epoch[47] Batch [1220]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086395,	
2017-06-24 01:58:55,370 Epoch[47] Batch [1230]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.086418,	
2017-06-24 01:59:01,524 Epoch[47] Batch [1240]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.086451,	
2017-06-24 01:59:07,581 Epoch[47] Batch [1250]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.086410,	
2017-06-24 01:59:13,695 Epoch[47] Batch [1260]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.086379,	
2017-06-24 01:59:19,089 Epoch[47] Batch [1270]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.086310,	
2017-06-24 01:59:24,909 Epoch[47] Batch [1280]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086389,	
2017-06-24 01:59:30,479 Epoch[47] Batch [1290]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.086473,	
2017-06-24 01:59:36,224 Epoch[47] Batch [1300]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086527,	
2017-06-24 01:59:42,340 Epoch[47] Batch [1310]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.086536,	
2017-06-24 01:59:48,374 Epoch[47] Batch [1320]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086546,	
2017-06-24 01:59:54,107 Epoch[47] Batch [1330]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086534,	
2017-06-24 01:59:59,768 Epoch[47] Batch [1340]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.086528,	
2017-06-24 02:00:05,404 Epoch[47] Batch [1350]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.086510,	
2017-06-24 02:00:11,370 Epoch[47] Batch [1360]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086559,	
2017-06-24 02:00:17,571 Epoch[47] Batch [1370]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086611,	
2017-06-24 02:00:23,534 Epoch[47] Batch [1380]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086608,	
2017-06-24 02:00:29,579 Epoch[47] Batch [1390]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.086628,	
2017-06-24 02:00:35,677 Epoch[47] Batch [1400]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.086569,	
2017-06-24 02:00:41,668 Epoch[47] Batch [1410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086547,	
2017-06-24 02:00:47,433 Epoch[47] Batch [1420]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086563,	
2017-06-24 02:00:53,528 Epoch[47] Batch [1430]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.086533,	
2017-06-24 02:00:59,115 Epoch[47] Batch [1440]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.086541,	
2017-06-24 02:01:04,473 Epoch[47] Batch [1450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.086535,	
2017-06-24 02:01:10,087 Epoch[47] Batch [1460]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.086570,	
2017-06-24 02:01:15,787 Epoch[47] Batch [1470]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.086582,	
2017-06-24 02:01:21,907 Epoch[47] Batch [1480]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.086588,	
2017-06-24 02:01:25,465 Epoch[47] Train-FCNLogLoss=0.086605
2017-06-24 02:01:25,465 Epoch[47] Time cost=864.082
2017-06-24 02:01:26,567 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0048.params"
2017-06-24 02:01:30,084 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0048.states"
2017-06-24 02:01:36,701 Epoch[48] Batch [10]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086999,	
2017-06-24 02:01:42,417 Epoch[48] Batch [20]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.087681,	
2017-06-24 02:01:49,311 Epoch[48] Batch [30]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.086365,	
2017-06-24 02:01:55,380 Epoch[48] Batch [40]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.085807,	
2017-06-24 02:02:01,059 Epoch[48] Batch [50]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.083729,	
2017-06-24 02:02:06,949 Epoch[48] Batch [60]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.086051,	
2017-06-24 02:02:12,940 Epoch[48] Batch [70]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086190,	
2017-06-24 02:02:19,190 Epoch[48] Batch [80]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.087244,	
2017-06-24 02:02:25,138 Epoch[48] Batch [90]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087646,	
2017-06-24 02:02:31,310 Epoch[48] Batch [100]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.087355,	
2017-06-24 02:02:38,099 Epoch[48] Batch [110]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.087314,	
2017-06-24 02:02:44,394 Epoch[48] Batch [120]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.087313,	
2017-06-24 02:02:50,191 Epoch[48] Batch [130]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.087954,	
2017-06-24 02:02:56,073 Epoch[48] Batch [140]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087776,	
2017-06-24 02:03:01,735 Epoch[48] Batch [150]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.087914,	
2017-06-24 02:03:07,544 Epoch[48] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.089439,	
2017-06-24 02:03:13,585 Epoch[48] Batch [170]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.089706,	
2017-06-24 02:03:19,907 Epoch[48] Batch [180]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.089250,	
2017-06-24 02:03:26,229 Epoch[48] Batch [190]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.089472,	
2017-06-24 02:03:31,962 Epoch[48] Batch [200]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.088950,	
2017-06-24 02:03:37,675 Epoch[48] Batch [210]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.088424,	
2017-06-24 02:03:44,450 Epoch[48] Batch [220]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.088291,	
2017-06-24 02:03:50,976 Epoch[48] Batch [230]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.088150,	
2017-06-24 02:03:56,586 Epoch[48] Batch [240]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.087809,	
2017-06-24 02:04:02,667 Epoch[48] Batch [250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087716,	
2017-06-24 02:04:08,635 Epoch[48] Batch [260]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.088020,	
2017-06-24 02:04:14,580 Epoch[48] Batch [270]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087979,	
2017-06-24 02:04:20,357 Epoch[48] Batch [280]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087765,	
2017-06-24 02:04:26,333 Epoch[48] Batch [290]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087955,	
2017-06-24 02:04:32,327 Epoch[48] Batch [300]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087977,	
2017-06-24 02:04:38,119 Epoch[48] Batch [310]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087646,	
2017-06-24 02:04:43,982 Epoch[48] Batch [320]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.087592,	
2017-06-24 02:04:49,699 Epoch[48] Batch [330]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.087455,	
2017-06-24 02:04:55,440 Epoch[48] Batch [340]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087695,	
2017-06-24 02:05:01,332 Epoch[48] Batch [350]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.087600,	
2017-06-24 02:05:07,119 Epoch[48] Batch [360]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087706,	
2017-06-24 02:05:12,564 Epoch[48] Batch [370]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.087833,	
2017-06-24 02:05:17,914 Epoch[48] Batch [380]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087819,	
2017-06-24 02:05:23,708 Epoch[48] Batch [390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.087647,	
2017-06-24 02:05:29,576 Epoch[48] Batch [400]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.087685,	
2017-06-24 02:05:35,725 Epoch[48] Batch [410]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.087687,	
2017-06-24 02:05:42,039 Epoch[48] Batch [420]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087693,	
2017-06-24 02:05:47,937 Epoch[48] Batch [430]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.087682,	
2017-06-24 02:05:53,776 Epoch[48] Batch [440]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.087582,	
2017-06-24 02:05:59,762 Epoch[48] Batch [450]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087648,	
2017-06-24 02:06:05,672 Epoch[48] Batch [460]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087716,	
2017-06-24 02:06:11,599 Epoch[48] Batch [470]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087907,	
2017-06-24 02:06:17,436 Epoch[48] Batch [480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.087799,	
2017-06-24 02:06:23,601 Epoch[48] Batch [490]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087912,	
2017-06-24 02:06:29,487 Epoch[48] Batch [500]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-24 02:06:35,804 Epoch[48] Batch [510]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.087607,	
2017-06-24 02:06:41,600 Epoch[48] Batch [520]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.087688,	
2017-06-24 02:06:47,219 Epoch[48] Batch [530]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.087760,	
2017-06-24 02:06:52,921 Epoch[48] Batch [540]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.087636,	
2017-06-24 02:06:58,577 Epoch[48] Batch [550]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.087750,	
2017-06-24 02:07:04,572 Epoch[48] Batch [560]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087845,	
2017-06-24 02:07:10,423 Epoch[48] Batch [570]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.087802,	
2017-06-24 02:07:16,166 Epoch[48] Batch [580]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087882,	
2017-06-24 02:07:22,132 Epoch[48] Batch [590]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.087795,	
2017-06-24 02:07:28,059 Epoch[48] Batch [600]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087711,	
2017-06-24 02:07:34,515 Epoch[48] Batch [610]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.087495,	
2017-06-24 02:07:41,449 Epoch[48] Batch [620]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.087319,	
2017-06-24 02:07:48,141 Epoch[48] Batch [630]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.087417,	
2017-06-24 02:07:54,232 Epoch[48] Batch [640]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.087396,	
2017-06-24 02:08:00,386 Epoch[48] Batch [650]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087337,	
2017-06-24 02:08:06,745 Epoch[48] Batch [660]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087330,	
2017-06-24 02:08:12,290 Epoch[48] Batch [670]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087316,	
2017-06-24 02:08:17,863 Epoch[48] Batch [680]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.087290,	
2017-06-24 02:08:23,408 Epoch[48] Batch [690]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087378,	
2017-06-24 02:08:28,964 Epoch[48] Batch [700]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.087276,	
2017-06-24 02:08:34,913 Epoch[48] Batch [710]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.087410,	
2017-06-24 02:08:40,479 Epoch[48] Batch [720]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.087449,	
2017-06-24 02:08:46,710 Epoch[48] Batch [730]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087416,	
2017-06-24 02:08:53,051 Epoch[48] Batch [740]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.087555,	
2017-06-24 02:08:59,524 Epoch[48] Batch [750]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.087573,	
2017-06-24 02:09:05,073 Epoch[48] Batch [760]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087565,	
2017-06-24 02:09:11,330 Epoch[48] Batch [770]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.087564,	
2017-06-24 02:09:17,219 Epoch[48] Batch [780]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.087505,	
2017-06-24 02:09:23,798 Epoch[48] Batch [790]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087360,	
2017-06-24 02:09:29,741 Epoch[48] Batch [800]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087428,	
2017-06-24 02:09:35,908 Epoch[48] Batch [810]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087393,	
2017-06-24 02:09:41,750 Epoch[48] Batch [820]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.087335,	
2017-06-24 02:09:47,711 Epoch[48] Batch [830]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087326,	
2017-06-24 02:09:53,538 Epoch[48] Batch [840]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.087297,	
2017-06-24 02:09:59,613 Epoch[48] Batch [850]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087264,	
2017-06-24 02:10:05,825 Epoch[48] Batch [860]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.087175,	
2017-06-24 02:10:11,564 Epoch[48] Batch [870]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087171,	
2017-06-24 02:10:17,231 Epoch[48] Batch [880]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.087204,	
2017-06-24 02:10:22,700 Epoch[48] Batch [890]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.087140,	
2017-06-24 02:10:28,367 Epoch[48] Batch [900]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.087110,	
2017-06-24 02:10:33,968 Epoch[48] Batch [910]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.087174,	
2017-06-24 02:10:39,977 Epoch[48] Batch [920]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.087167,	
2017-06-24 02:10:45,949 Epoch[48] Batch [930]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.087084,	
2017-06-24 02:10:51,558 Epoch[48] Batch [940]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.087135,	
2017-06-24 02:10:57,426 Epoch[48] Batch [950]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.087195,	
2017-06-24 02:11:03,120 Epoch[48] Batch [960]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087256,	
2017-06-24 02:11:08,670 Epoch[48] Batch [970]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087141,	
2017-06-24 02:11:14,487 Epoch[48] Batch [980]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087134,	
2017-06-24 02:11:20,326 Epoch[48] Batch [990]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.087128,	
2017-06-24 02:11:26,492 Epoch[48] Batch [1000]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087086,	
2017-06-24 02:11:32,059 Epoch[48] Batch [1010]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.087097,	
2017-06-24 02:11:38,172 Epoch[48] Batch [1020]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087142,	
2017-06-24 02:11:44,405 Epoch[48] Batch [1030]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087117,	
2017-06-24 02:11:50,641 Epoch[48] Batch [1040]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087212,	
2017-06-24 02:11:57,268 Epoch[48] Batch [1050]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.087214,	
2017-06-24 02:12:03,191 Epoch[48] Batch [1060]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087179,	
2017-06-24 02:12:09,941 Epoch[48] Batch [1070]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.087157,	
2017-06-24 02:12:16,382 Epoch[48] Batch [1080]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.087135,	
2017-06-24 02:12:22,261 Epoch[48] Batch [1090]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087153,	
2017-06-24 02:12:28,246 Epoch[48] Batch [1100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087196,	
2017-06-24 02:12:34,624 Epoch[48] Batch [1110]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.087213,	
2017-06-24 02:12:41,384 Epoch[48] Batch [1120]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.087184,	
2017-06-24 02:12:47,168 Epoch[48] Batch [1130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087259,	
2017-06-24 02:12:53,847 Epoch[48] Batch [1140]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.087201,	
2017-06-24 02:13:00,074 Epoch[48] Batch [1150]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087261,	
2017-06-24 02:13:06,040 Epoch[48] Batch [1160]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087180,	
2017-06-24 02:13:12,033 Epoch[48] Batch [1170]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087254,	
2017-06-24 02:13:18,420 Epoch[48] Batch [1180]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.087248,	
2017-06-24 02:13:24,828 Epoch[48] Batch [1190]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.087202,	
2017-06-24 02:13:30,989 Epoch[48] Batch [1200]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.087241,	
2017-06-24 02:13:37,111 Epoch[48] Batch [1210]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.087221,	
2017-06-24 02:13:43,039 Epoch[48] Batch [1220]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087238,	
2017-06-24 02:13:49,399 Epoch[48] Batch [1230]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087269,	
2017-06-24 02:13:55,330 Epoch[48] Batch [1240]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.087286,	
2017-06-24 02:14:01,137 Epoch[48] Batch [1250]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.087215,	
2017-06-24 02:14:07,493 Epoch[48] Batch [1260]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087202,	
2017-06-24 02:14:13,608 Epoch[48] Batch [1270]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.087235,	
2017-06-24 02:14:19,406 Epoch[48] Batch [1280]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.087185,	
2017-06-24 02:14:25,176 Epoch[48] Batch [1290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.087256,	
2017-06-24 02:14:31,540 Epoch[48] Batch [1300]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087250,	
2017-06-24 02:14:37,606 Epoch[48] Batch [1310]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087218,	
2017-06-24 02:14:44,264 Epoch[48] Batch [1320]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.087264,	
2017-06-24 02:14:50,215 Epoch[48] Batch [1330]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.087300,	
2017-06-24 02:14:56,043 Epoch[48] Batch [1340]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087230,	
2017-06-24 02:15:02,072 Epoch[48] Batch [1350]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.087165,	
2017-06-24 02:15:08,060 Epoch[48] Batch [1360]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087107,	
2017-06-24 02:15:14,397 Epoch[48] Batch [1370]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.087057,	
2017-06-24 02:15:20,848 Epoch[48] Batch [1380]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.087015,	
2017-06-24 02:15:27,162 Epoch[48] Batch [1390]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.087007,	
2017-06-24 02:15:33,378 Epoch[48] Batch [1400]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.086955,	
2017-06-24 02:15:39,602 Epoch[48] Batch [1410]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.086965,	
2017-06-24 02:15:45,853 Epoch[48] Batch [1420]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.086959,	
2017-06-24 02:15:51,663 Epoch[48] Batch [1430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086920,	
2017-06-24 02:15:57,387 Epoch[48] Batch [1440]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086971,	
2017-06-24 02:16:03,168 Epoch[48] Batch [1450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086957,	
2017-06-24 02:16:09,108 Epoch[48] Batch [1460]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.086935,	
2017-06-24 02:16:15,491 Epoch[48] Batch [1470]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.086825,	
2017-06-24 02:16:20,955 Epoch[48] Batch [1480]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.086789,	
2017-06-24 02:16:24,856 Epoch[48] Train-FCNLogLoss=0.086749
2017-06-24 02:16:24,856 Epoch[48] Time cost=894.772
2017-06-24 02:16:25,811 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0049.params"
2017-06-24 02:16:29,401 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0049.states"
2017-06-24 02:16:36,550 Epoch[49] Batch [10]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087543,	
2017-06-24 02:16:42,087 Epoch[49] Batch [20]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.085230,	
2017-06-24 02:16:47,771 Epoch[49] Batch [30]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086066,	
2017-06-24 02:16:53,521 Epoch[49] Batch [40]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.087430,	
2017-06-24 02:16:59,414 Epoch[49] Batch [50]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.087007,	
2017-06-24 02:17:05,646 Epoch[49] Batch [60]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087257,	
2017-06-24 02:17:12,007 Epoch[49] Batch [70]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.087308,	
2017-06-24 02:17:18,351 Epoch[49] Batch [80]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.087789,	
2017-06-24 02:17:24,233 Epoch[49] Batch [90]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087034,	
2017-06-24 02:17:30,522 Epoch[49] Batch [100]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.087031,	
2017-06-24 02:17:36,442 Epoch[49] Batch [110]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086925,	
2017-06-24 02:17:42,151 Epoch[49] Batch [120]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-24 02:17:48,167 Epoch[49] Batch [130]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-24 02:17:53,948 Epoch[49] Batch [140]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.087291,	
2017-06-24 02:17:59,608 Epoch[49] Batch [150]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.087075,	
2017-06-24 02:18:05,353 Epoch[49] Batch [160]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.087282,	
2017-06-24 02:18:11,080 Epoch[49] Batch [170]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086667,	
2017-06-24 02:18:17,034 Epoch[49] Batch [180]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.087032,	
2017-06-24 02:18:23,116 Epoch[49] Batch [190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.087116,	
2017-06-24 02:18:29,357 Epoch[49] Batch [200]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.086867,	
2017-06-24 02:18:35,277 Epoch[49] Batch [210]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086863,	
2017-06-24 02:18:40,854 Epoch[49] Batch [220]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.086732,	
2017-06-24 02:18:46,624 Epoch[49] Batch [230]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086561,	
2017-06-24 02:18:52,146 Epoch[49] Batch [240]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.086493,	
2017-06-24 02:18:58,118 Epoch[49] Batch [250]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-24 02:19:04,087 Epoch[49] Batch [260]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086463,	
2017-06-24 02:19:09,476 Epoch[49] Batch [270]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.086571,	
2017-06-24 02:19:14,809 Epoch[49] Batch [280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086320,	
2017-06-24 02:19:20,839 Epoch[49] Batch [290]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086192,	
2017-06-24 02:19:26,863 Epoch[49] Batch [300]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.086301,	
2017-06-24 02:19:32,831 Epoch[49] Batch [310]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086355,	
2017-06-24 02:19:38,252 Epoch[49] Batch [320]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.086436,	
2017-06-24 02:19:43,848 Epoch[49] Batch [330]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.086319,	
2017-06-24 02:19:49,488 Epoch[49] Batch [340]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086664,	
2017-06-24 02:19:55,311 Epoch[49] Batch [350]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086624,	
2017-06-24 02:20:00,752 Epoch[49] Batch [360]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.086840,	
2017-06-24 02:20:06,262 Epoch[49] Batch [370]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.086872,	
2017-06-24 02:20:11,834 Epoch[49] Batch [380]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.087064,	
2017-06-24 02:20:17,658 Epoch[49] Batch [390]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086979,	
2017-06-24 02:20:23,780 Epoch[49] Batch [400]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.086956,	
2017-06-24 02:20:29,647 Epoch[49] Batch [410]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.086913,	
2017-06-24 02:20:35,126 Epoch[49] Batch [420]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.086869,	
2017-06-24 02:20:40,711 Epoch[49] Batch [430]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.086915,	
2017-06-24 02:20:47,118 Epoch[49] Batch [440]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.086688,	
2017-06-24 02:20:53,587 Epoch[49] Batch [450]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.086487,	
2017-06-24 02:20:59,382 Epoch[49] Batch [460]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.086367,	
2017-06-24 02:21:05,771 Epoch[49] Batch [470]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.086364,	
2017-06-24 02:21:11,733 Epoch[49] Batch [480]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086436,	
2017-06-24 02:21:17,939 Epoch[49] Batch [490]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086632,	
2017-06-24 02:21:23,978 Epoch[49] Batch [500]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.086485,	
2017-06-24 02:21:30,211 Epoch[49] Batch [510]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.086472,	
2017-06-24 02:21:36,047 Epoch[49] Batch [520]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.086454,	
2017-06-24 02:21:42,038 Epoch[49] Batch [530]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086553,	
2017-06-24 02:21:48,517 Epoch[49] Batch [540]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.086388,	
2017-06-24 02:21:54,630 Epoch[49] Batch [550]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.086411,	
2017-06-24 02:22:00,572 Epoch[49] Batch [560]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.086372,	
2017-06-24 02:22:06,721 Epoch[49] Batch [570]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086246,	
2017-06-24 02:22:12,930 Epoch[49] Batch [580]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.086179,	
2017-06-24 02:22:19,119 Epoch[49] Batch [590]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.086287,	
2017-06-24 02:22:25,136 Epoch[49] Batch [600]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.086308,	
2017-06-24 02:22:31,353 Epoch[49] Batch [610]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.086260,	
2017-06-24 02:22:37,918 Epoch[49] Batch [620]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.086279,	
2017-06-24 02:22:44,711 Epoch[49] Batch [630]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.086217,	
2017-06-24 02:22:51,494 Epoch[49] Batch [640]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.086149,	
2017-06-24 02:22:57,411 Epoch[49] Batch [650]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.086089,	
2017-06-24 02:23:03,441 Epoch[49] Batch [660]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.086125,	
2017-06-24 02:23:09,327 Epoch[49] Batch [670]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.086146,	
2017-06-24 02:23:15,145 Epoch[49] Batch [680]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086015,	
2017-06-24 02:23:20,902 Epoch[49] Batch [690]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086013,	
2017-06-24 02:23:27,732 Epoch[49] Batch [700]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.085958,	
2017-06-24 02:23:34,067 Epoch[49] Batch [710]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.085941,	
2017-06-24 02:23:40,249 Epoch[49] Batch [720]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085954,	
2017-06-24 02:23:46,430 Epoch[49] Batch [730]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085949,	
2017-06-24 02:23:52,349 Epoch[49] Batch [740]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.085869,	
2017-06-24 02:23:58,620 Epoch[49] Batch [750]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.085888,	
2017-06-24 02:24:04,643 Epoch[49] Batch [760]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.085806,	
2017-06-24 02:24:10,825 Epoch[49] Batch [770]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085758,	
2017-06-24 02:24:17,026 Epoch[49] Batch [780]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085771,	
2017-06-24 02:24:24,159 Epoch[49] Batch [790]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.085757,	
2017-06-24 02:24:29,780 Epoch[49] Batch [800]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.085721,	
2017-06-24 02:24:35,750 Epoch[49] Batch [810]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.085637,	
2017-06-24 02:24:41,637 Epoch[49] Batch [820]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085667,	
2017-06-24 02:24:47,443 Epoch[49] Batch [830]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.085670,	
2017-06-24 02:24:53,342 Epoch[49] Batch [840]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.085659,	
2017-06-24 02:24:59,415 Epoch[49] Batch [850]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.085676,	
2017-06-24 02:25:05,563 Epoch[49] Batch [860]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.085691,	
2017-06-24 02:25:11,511 Epoch[49] Batch [870]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.085729,	
2017-06-24 02:25:17,226 Epoch[49] Batch [880]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.085762,	
2017-06-24 02:25:23,072 Epoch[49] Batch [890]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085731,	
2017-06-24 02:25:28,624 Epoch[49] Batch [900]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.085767,	
2017-06-24 02:25:34,375 Epoch[49] Batch [910]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.085798,	
2017-06-24 02:25:40,473 Epoch[49] Batch [920]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085780,	
2017-06-24 02:25:46,322 Epoch[49] Batch [930]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085829,	
2017-06-24 02:25:52,172 Epoch[49] Batch [940]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085878,	
2017-06-24 02:25:58,336 Epoch[49] Batch [950]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.085846,	
2017-06-24 02:26:04,170 Epoch[49] Batch [960]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.085780,	
2017-06-24 02:26:10,274 Epoch[49] Batch [970]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.085759,	
2017-06-24 02:26:16,525 Epoch[49] Batch [980]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.085815,	
2017-06-24 02:26:22,789 Epoch[49] Batch [990]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.085727,	
2017-06-24 02:26:28,299 Epoch[49] Batch [1000]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.085682,	
2017-06-24 02:26:33,810 Epoch[49] Batch [1010]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.085614,	
2017-06-24 02:26:39,894 Epoch[49] Batch [1020]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.085656,	
2017-06-24 02:26:46,161 Epoch[49] Batch [1030]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.085638,	
2017-06-24 02:26:52,074 Epoch[49] Batch [1040]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.085529,	
2017-06-24 02:26:57,400 Epoch[49] Batch [1050]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.085533,	
2017-06-24 02:27:03,143 Epoch[49] Batch [1060]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.085501,	
2017-06-24 02:27:08,564 Epoch[49] Batch [1070]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.085494,	
2017-06-24 02:27:14,521 Epoch[49] Batch [1080]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.085502,	
2017-06-24 02:27:20,872 Epoch[49] Batch [1090]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.085577,	
2017-06-24 02:27:26,645 Epoch[49] Batch [1100]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085608,	
2017-06-24 02:27:32,329 Epoch[49] Batch [1110]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.085636,	
2017-06-24 02:27:38,138 Epoch[49] Batch [1120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.085694,	
2017-06-24 02:27:43,683 Epoch[49] Batch [1130]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.085672,	
2017-06-24 02:27:49,892 Epoch[49] Batch [1140]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.085592,	
2017-06-24 02:27:55,989 Epoch[49] Batch [1150]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085524,	
2017-06-24 02:28:02,185 Epoch[49] Batch [1160]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.085549,	
2017-06-24 02:28:08,168 Epoch[49] Batch [1170]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.085586,	
2017-06-24 02:28:14,420 Epoch[49] Batch [1180]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.085596,	
2017-06-24 02:28:19,884 Epoch[49] Batch [1190]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.085627,	
2017-06-24 02:28:25,302 Epoch[49] Batch [1200]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.085629,	
2017-06-24 02:28:31,512 Epoch[49] Batch [1210]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.085626,	
2017-06-24 02:28:37,422 Epoch[49] Batch [1220]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085627,	
2017-06-24 02:28:42,885 Epoch[49] Batch [1230]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.085598,	
2017-06-24 02:28:48,457 Epoch[49] Batch [1240]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.085616,	
2017-06-24 02:28:54,557 Epoch[49] Batch [1250]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085645,	
2017-06-24 02:29:00,551 Epoch[49] Batch [1260]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085621,	
2017-06-24 02:29:06,472 Epoch[49] Batch [1270]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.085630,	
2017-06-24 02:29:12,088 Epoch[49] Batch [1280]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.085670,	
2017-06-24 02:29:17,669 Epoch[49] Batch [1290]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.085630,	
2017-06-24 02:29:23,457 Epoch[49] Batch [1300]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.085679,	
2017-06-24 02:29:29,671 Epoch[49] Batch [1310]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.085671,	
2017-06-24 02:29:35,515 Epoch[49] Batch [1320]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085665,	
2017-06-24 02:29:41,478 Epoch[49] Batch [1330]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.085702,	
2017-06-24 02:29:47,981 Epoch[49] Batch [1340]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.085611,	
2017-06-24 02:29:54,081 Epoch[49] Batch [1350]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085589,	
2017-06-24 02:29:59,682 Epoch[49] Batch [1360]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.085541,	
2017-06-24 02:30:05,366 Epoch[49] Batch [1370]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.085464,	
2017-06-24 02:30:11,232 Epoch[49] Batch [1380]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.085445,	
2017-06-24 02:30:18,060 Epoch[49] Batch [1390]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.085426,	
2017-06-24 02:30:24,232 Epoch[49] Batch [1400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.085478,	
2017-06-24 02:30:30,558 Epoch[49] Batch [1410]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.085480,	
2017-06-24 02:30:36,884 Epoch[49] Batch [1420]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.085501,	
2017-06-24 02:30:43,259 Epoch[49] Batch [1430]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.085537,	
2017-06-24 02:30:49,392 Epoch[49] Batch [1440]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.085568,	
2017-06-24 02:30:55,571 Epoch[49] Batch [1450]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085548,	
2017-06-24 02:31:01,687 Epoch[49] Batch [1460]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.085562,	
2017-06-24 02:31:07,877 Epoch[49] Batch [1470]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.085521,	
2017-06-24 02:31:13,971 Epoch[49] Batch [1480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085502,	
2017-06-24 02:31:17,704 Epoch[49] Train-FCNLogLoss=0.085489
2017-06-24 02:31:17,704 Epoch[49] Time cost=888.303
2017-06-24 02:31:18,704 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0050.params"
2017-06-24 02:31:22,333 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0050.states"
2017-06-24 02:31:29,315 Epoch[50] Batch [10]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.092833,	
2017-06-24 02:31:35,313 Epoch[50] Batch [20]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087251,	
2017-06-24 02:31:41,721 Epoch[50] Batch [30]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.085451,	
2017-06-24 02:31:47,689 Epoch[50] Batch [40]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086827,	
2017-06-24 02:31:53,898 Epoch[50] Batch [50]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.084850,	
2017-06-24 02:32:00,375 Epoch[50] Batch [60]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.084096,	
2017-06-24 02:32:06,887 Epoch[50] Batch [70]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.083872,	
2017-06-24 02:32:13,157 Epoch[50] Batch [80]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.084053,	
2017-06-24 02:32:19,527 Epoch[50] Batch [90]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.084577,	
2017-06-24 02:32:25,616 Epoch[50] Batch [100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.085110,	
2017-06-24 02:32:32,728 Epoch[50] Batch [110]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.084244,	
2017-06-24 02:32:39,005 Epoch[50] Batch [120]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.084216,	
2017-06-24 02:32:45,360 Epoch[50] Batch [130]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.084081,	
2017-06-24 02:32:51,178 Epoch[50] Batch [140]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.084727,	
2017-06-24 02:32:56,805 Epoch[50] Batch [150]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.085100,	
2017-06-24 02:33:03,011 Epoch[50] Batch [160]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085030,	
2017-06-24 02:33:08,753 Epoch[50] Batch [170]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.085263,	
2017-06-24 02:33:14,749 Epoch[50] Batch [180]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085260,	
2017-06-24 02:33:21,091 Epoch[50] Batch [190]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.085334,	
2017-06-24 02:33:26,890 Epoch[50] Batch [200]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.085330,	
2017-06-24 02:33:33,063 Epoch[50] Batch [210]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.085381,	
2017-06-24 02:33:39,171 Epoch[50] Batch [220]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.085524,	
2017-06-24 02:33:45,172 Epoch[50] Batch [230]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085384,	
2017-06-24 02:33:50,695 Epoch[50] Batch [240]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.085323,	
2017-06-24 02:33:56,530 Epoch[50] Batch [250]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.085041,	
2017-06-24 02:34:02,612 Epoch[50] Batch [260]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.085440,	
2017-06-24 02:34:08,277 Epoch[50] Batch [270]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.085196,	
2017-06-24 02:34:14,000 Epoch[50] Batch [280]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.084865,	
2017-06-24 02:34:19,653 Epoch[50] Batch [290]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.084725,	
2017-06-24 02:34:25,751 Epoch[50] Batch [300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.084895,	
2017-06-24 02:34:31,762 Epoch[50] Batch [310]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.085181,	
2017-06-24 02:34:37,903 Epoch[50] Batch [320]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.085151,	
2017-06-24 02:34:44,122 Epoch[50] Batch [330]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.085357,	
2017-06-24 02:34:50,103 Epoch[50] Batch [340]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.085670,	
2017-06-24 02:34:56,690 Epoch[50] Batch [350]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.085329,	
2017-06-24 02:35:02,774 Epoch[50] Batch [360]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.085295,	
2017-06-24 02:35:09,144 Epoch[50] Batch [370]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.085178,	
2017-06-24 02:35:15,520 Epoch[50] Batch [380]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.085111,	
2017-06-24 02:35:21,454 Epoch[50] Batch [390]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.085014,	
2017-06-24 02:35:27,319 Epoch[50] Batch [400]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.084875,	
2017-06-24 02:35:33,403 Epoch[50] Batch [410]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.084948,	
2017-06-24 02:35:39,446 Epoch[50] Batch [420]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.085079,	
2017-06-24 02:35:45,781 Epoch[50] Batch [430]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.085381,	
2017-06-24 02:35:52,120 Epoch[50] Batch [440]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.085499,	
2017-06-24 02:35:58,318 Epoch[50] Batch [450]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085647,	
2017-06-24 02:36:04,923 Epoch[50] Batch [460]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.085591,	
2017-06-24 02:36:11,393 Epoch[50] Batch [470]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.085721,	
2017-06-24 02:36:17,733 Epoch[50] Batch [480]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.085501,	
2017-06-24 02:36:23,928 Epoch[50] Batch [490]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.085502,	
2017-06-24 02:36:30,118 Epoch[50] Batch [500]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.085508,	
2017-06-24 02:36:36,908 Epoch[50] Batch [510]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.085439,	
2017-06-24 02:36:43,842 Epoch[50] Batch [520]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.085509,	
2017-06-24 02:36:50,698 Epoch[50] Batch [530]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.085485,	
2017-06-24 02:36:57,084 Epoch[50] Batch [540]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.085675,	
2017-06-24 02:37:03,526 Epoch[50] Batch [550]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.085665,	
2017-06-24 02:37:09,779 Epoch[50] Batch [560]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.085700,	
2017-06-24 02:37:16,101 Epoch[50] Batch [570]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.085764,	
2017-06-24 02:37:22,541 Epoch[50] Batch [580]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.085634,	
2017-06-24 02:37:29,669 Epoch[50] Batch [590]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.085760,	
2017-06-24 02:37:36,322 Epoch[50] Batch [600]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.085649,	
2017-06-24 02:37:42,602 Epoch[50] Batch [610]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.085611,	
2017-06-24 02:37:49,142 Epoch[50] Batch [620]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.085556,	
2017-06-24 02:37:55,948 Epoch[50] Batch [630]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.085408,	
2017-06-24 02:38:02,239 Epoch[50] Batch [640]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.085275,	
2017-06-24 02:38:09,222 Epoch[50] Batch [650]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.085415,	
2017-06-24 02:38:15,354 Epoch[50] Batch [660]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.085502,	
2017-06-24 02:38:21,561 Epoch[50] Batch [670]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085443,	
2017-06-24 02:38:27,966 Epoch[50] Batch [680]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.085486,	
2017-06-24 02:38:34,861 Epoch[50] Batch [690]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.085459,	
2017-06-24 02:38:41,067 Epoch[50] Batch [700]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085520,	
2017-06-24 02:38:47,251 Epoch[50] Batch [710]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085541,	
2017-06-24 02:38:53,053 Epoch[50] Batch [720]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.085517,	
2017-06-24 02:38:59,215 Epoch[50] Batch [730]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.085462,	
2017-06-24 02:39:05,601 Epoch[50] Batch [740]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.085388,	
2017-06-24 02:39:11,222 Epoch[50] Batch [750]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.085492,	
2017-06-24 02:39:17,702 Epoch[50] Batch [760]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.085529,	
2017-06-24 02:39:23,728 Epoch[50] Batch [770]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.085573,	
2017-06-24 02:39:30,053 Epoch[50] Batch [780]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.085583,	
2017-06-24 02:39:37,024 Epoch[50] Batch [790]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.085511,	
2017-06-24 02:39:42,968 Epoch[50] Batch [800]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.085489,	
2017-06-24 02:39:49,064 Epoch[50] Batch [810]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085441,	
2017-06-24 02:39:55,507 Epoch[50] Batch [820]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.085402,	
2017-06-24 02:40:01,386 Epoch[50] Batch [830]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.085348,	
2017-06-24 02:40:07,475 Epoch[50] Batch [840]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.085401,	
2017-06-24 02:40:13,566 Epoch[50] Batch [850]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.085375,	
2017-06-24 02:40:19,616 Epoch[50] Batch [860]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.085257,	
2017-06-24 02:40:26,118 Epoch[50] Batch [870]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.085365,	
2017-06-24 02:40:32,476 Epoch[50] Batch [880]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.085297,	
2017-06-24 02:40:38,485 Epoch[50] Batch [890]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.085364,	
2017-06-24 02:40:44,121 Epoch[50] Batch [900]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.085430,	
2017-06-24 02:40:49,902 Epoch[50] Batch [910]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085532,	
2017-06-24 02:40:56,202 Epoch[50] Batch [920]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.085544,	
2017-06-24 02:41:02,397 Epoch[50] Batch [930]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.085578,	
2017-06-24 02:41:09,206 Epoch[50] Batch [940]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.085571,	
2017-06-24 02:41:15,343 Epoch[50] Batch [950]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.085682,	
2017-06-24 02:41:21,362 Epoch[50] Batch [960]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.085730,	
2017-06-24 02:41:27,098 Epoch[50] Batch [970]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.085677,	
2017-06-24 02:41:32,781 Epoch[50] Batch [980]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.085632,	
2017-06-24 02:41:38,182 Epoch[50] Batch [990]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.085546,	
2017-06-24 02:41:43,967 Epoch[50] Batch [1000]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.085584,	
2017-06-24 02:41:49,989 Epoch[50] Batch [1010]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.085598,	
2017-06-24 02:41:56,081 Epoch[50] Batch [1020]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.085663,	
2017-06-24 02:42:02,569 Epoch[50] Batch [1030]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.085737,	
2017-06-24 02:42:08,469 Epoch[50] Batch [1040]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.085683,	
2017-06-24 02:42:14,041 Epoch[50] Batch [1050]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.085641,	
2017-06-24 02:42:20,097 Epoch[50] Batch [1060]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.085667,	
2017-06-24 02:42:25,980 Epoch[50] Batch [1070]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.085712,	
2017-06-24 02:42:32,370 Epoch[50] Batch [1080]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.085687,	
2017-06-24 02:42:38,607 Epoch[50] Batch [1090]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.085688,	
2017-06-24 02:42:45,428 Epoch[50] Batch [1100]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.085653,	
2017-06-24 02:42:52,021 Epoch[50] Batch [1110]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.085591,	
2017-06-24 02:42:57,709 Epoch[50] Batch [1120]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.085559,	
2017-06-24 02:43:04,829 Epoch[50] Batch [1130]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.085455,	
2017-06-24 02:43:10,910 Epoch[50] Batch [1140]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.085446,	
2017-06-24 02:43:17,055 Epoch[50] Batch [1150]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.085411,	
2017-06-24 02:43:22,993 Epoch[50] Batch [1160]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.085463,	
2017-06-24 02:43:29,061 Epoch[50] Batch [1170]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.085413,	
2017-06-24 02:43:34,766 Epoch[50] Batch [1180]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.085428,	
2017-06-24 02:43:40,632 Epoch[50] Batch [1190]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.085474,	
2017-06-24 02:43:46,750 Epoch[50] Batch [1200]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.085401,	
2017-06-24 02:43:52,525 Epoch[50] Batch [1210]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085354,	
2017-06-24 02:43:58,169 Epoch[50] Batch [1220]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.085384,	
2017-06-24 02:44:04,263 Epoch[50] Batch [1230]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085393,	
2017-06-24 02:44:10,774 Epoch[50] Batch [1240]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.085414,	
2017-06-24 02:44:16,807 Epoch[50] Batch [1250]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.085416,	
2017-06-24 02:44:22,391 Epoch[50] Batch [1260]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.085382,	
2017-06-24 02:44:27,994 Epoch[50] Batch [1270]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.085420,	
2017-06-24 02:44:33,998 Epoch[50] Batch [1280]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.085438,	
2017-06-24 02:44:40,383 Epoch[50] Batch [1290]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.085423,	
2017-06-24 02:44:46,041 Epoch[50] Batch [1300]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.085416,	
2017-06-24 02:44:52,125 Epoch[50] Batch [1310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.085418,	
2017-06-24 02:44:58,336 Epoch[50] Batch [1320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.085408,	
2017-06-24 02:45:04,644 Epoch[50] Batch [1330]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.085473,	
2017-06-24 02:45:10,787 Epoch[50] Batch [1340]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.085501,	
2017-06-24 02:45:16,684 Epoch[50] Batch [1350]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.085491,	
2017-06-24 02:45:22,575 Epoch[50] Batch [1360]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085497,	
2017-06-24 02:45:28,780 Epoch[50] Batch [1370]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085436,	
2017-06-24 02:45:34,784 Epoch[50] Batch [1380]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.085379,	
2017-06-24 02:45:40,623 Epoch[50] Batch [1390]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085380,	
2017-06-24 02:45:46,797 Epoch[50] Batch [1400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.085335,	
2017-06-24 02:45:53,198 Epoch[50] Batch [1410]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.085335,	
2017-06-24 02:45:59,131 Epoch[50] Batch [1420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.085320,	
2017-06-24 02:46:05,408 Epoch[50] Batch [1430]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.085315,	
2017-06-24 02:46:11,070 Epoch[50] Batch [1440]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.085344,	
2017-06-24 02:46:17,108 Epoch[50] Batch [1450]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.085365,	
2017-06-24 02:46:22,963 Epoch[50] Batch [1460]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.085347,	
2017-06-24 02:46:28,630 Epoch[50] Batch [1470]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.085403,	
2017-06-24 02:46:34,426 Epoch[50] Batch [1480]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.085424,	
2017-06-24 02:46:38,136 Epoch[50] Train-FCNLogLoss=0.085456
2017-06-24 02:46:38,137 Epoch[50] Time cost=915.803
2017-06-24 02:46:39,061 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0051.params"
2017-06-24 02:46:42,784 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0051.states"
2017-06-24 02:46:49,887 Epoch[51] Batch [10]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.079779,	
2017-06-24 02:46:55,835 Epoch[51] Batch [20]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.084137,	
2017-06-24 02:47:01,803 Epoch[51] Batch [30]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.084672,	
2017-06-24 02:47:07,295 Epoch[51] Batch [40]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.086348,	
2017-06-24 02:47:12,815 Epoch[51] Batch [50]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.084533,	
2017-06-24 02:47:18,311 Epoch[51] Batch [60]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.085679,	
2017-06-24 02:47:24,065 Epoch[51] Batch [70]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086117,	
2017-06-24 02:47:29,431 Epoch[51] Batch [80]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.086544,	
2017-06-24 02:47:35,413 Epoch[51] Batch [90]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.085955,	
2017-06-24 02:47:41,444 Epoch[51] Batch [100]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.085332,	
2017-06-24 02:47:47,285 Epoch[51] Batch [110]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.084692,	
2017-06-24 02:47:53,539 Epoch[51] Batch [120]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.084486,	
2017-06-24 02:47:58,975 Epoch[51] Batch [130]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.084878,	
2017-06-24 02:48:04,587 Epoch[51] Batch [140]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.085507,	
2017-06-24 02:48:09,868 Epoch[51] Batch [150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.085957,	
2017-06-24 02:48:15,658 Epoch[51] Batch [160]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.086219,	
2017-06-24 02:48:21,066 Epoch[51] Batch [170]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.086114,	
2017-06-24 02:48:26,850 Epoch[51] Batch [180]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086357,	
2017-06-24 02:48:33,088 Epoch[51] Batch [190]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.086737,	
2017-06-24 02:48:38,643 Epoch[51] Batch [200]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.086493,	
2017-06-24 02:48:44,623 Epoch[51] Batch [210]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086172,	
2017-06-24 02:48:50,623 Epoch[51] Batch [220]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.086507,	
2017-06-24 02:48:56,156 Epoch[51] Batch [230]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.086685,	
2017-06-24 02:49:01,884 Epoch[51] Batch [240]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.086843,	
2017-06-24 02:49:07,535 Epoch[51] Batch [250]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.087003,	
2017-06-24 02:49:13,440 Epoch[51] Batch [260]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.087077,	
2017-06-24 02:49:18,979 Epoch[51] Batch [270]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.087072,	
2017-06-24 02:49:24,983 Epoch[51] Batch [280]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.087056,	
2017-06-24 02:49:30,848 Epoch[51] Batch [290]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.086856,	
2017-06-24 02:49:36,879 Epoch[51] Batch [300]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.086636,	
2017-06-24 02:49:42,228 Epoch[51] Batch [310]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.086686,	
2017-06-24 02:49:48,927 Epoch[51] Batch [320]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.086404,	
2017-06-24 02:49:55,284 Epoch[51] Batch [330]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.086384,	
2017-06-24 02:50:01,759 Epoch[51] Batch [340]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.086275,	
2017-06-24 02:50:08,033 Epoch[51] Batch [350]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.086124,	
2017-06-24 02:50:13,860 Epoch[51] Batch [360]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.086063,	
2017-06-24 02:50:19,234 Epoch[51] Batch [370]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.086258,	
2017-06-24 02:50:24,922 Epoch[51] Batch [380]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086354,	
2017-06-24 02:50:30,884 Epoch[51] Batch [390]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086254,	
2017-06-24 02:50:36,788 Epoch[51] Batch [400]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.086059,	
2017-06-24 02:50:42,119 Epoch[51] Batch [410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.086186,	
2017-06-24 02:50:48,268 Epoch[51] Batch [420]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086249,	
2017-06-24 02:50:54,073 Epoch[51] Batch [430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086050,	
2017-06-24 02:50:59,825 Epoch[51] Batch [440]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.086118,	
2017-06-24 02:51:05,803 Epoch[51] Batch [450]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086164,	
2017-06-24 02:51:11,475 Epoch[51] Batch [460]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.086016,	
2017-06-24 02:51:17,459 Epoch[51] Batch [470]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.086043,	
2017-06-24 02:51:23,139 Epoch[51] Batch [480]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.086023,	
2017-06-24 02:51:29,436 Epoch[51] Batch [490]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.086150,	
2017-06-24 02:51:34,926 Epoch[51] Batch [500]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.085983,	
2017-06-24 02:51:40,973 Epoch[51] Batch [510]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.085791,	
2017-06-24 02:51:46,758 Epoch[51] Batch [520]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.085646,	
2017-06-24 02:51:52,024 Epoch[51] Batch [530]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.085738,	
2017-06-24 02:51:57,508 Epoch[51] Batch [540]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.085827,	
2017-06-24 02:52:02,940 Epoch[51] Batch [550]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085890,	
2017-06-24 02:52:08,673 Epoch[51] Batch [560]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.085785,	
2017-06-24 02:52:15,201 Epoch[51] Batch [570]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.085892,	
2017-06-24 02:52:21,042 Epoch[51] Batch [580]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085999,	
2017-06-24 02:52:27,131 Epoch[51] Batch [590]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.085935,	
2017-06-24 02:52:33,133 Epoch[51] Batch [600]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085852,	
2017-06-24 02:52:38,705 Epoch[51] Batch [610]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.085882,	
2017-06-24 02:52:44,430 Epoch[51] Batch [620]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.085830,	
2017-06-24 02:52:50,194 Epoch[51] Batch [630]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.085782,	
2017-06-24 02:52:56,252 Epoch[51] Batch [640]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.085706,	
2017-06-24 02:53:02,301 Epoch[51] Batch [650]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.085796,	
2017-06-24 02:53:08,578 Epoch[51] Batch [660]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.085954,	
2017-06-24 02:53:15,096 Epoch[51] Batch [670]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.085986,	
2017-06-24 02:53:21,011 Epoch[51] Batch [680]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.085815,	
2017-06-24 02:53:27,091 Epoch[51] Batch [690]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.085675,	
2017-06-24 02:53:32,826 Epoch[51] Batch [700]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.085578,	
2017-06-24 02:53:38,324 Epoch[51] Batch [710]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.085631,	
2017-06-24 02:53:44,640 Epoch[51] Batch [720]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.085682,	
2017-06-24 02:53:50,317 Epoch[51] Batch [730]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.085686,	
2017-06-24 02:53:56,275 Epoch[51] Batch [740]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.085748,	
2017-06-24 02:54:02,914 Epoch[51] Batch [750]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.085761,	
2017-06-24 02:54:08,890 Epoch[51] Batch [760]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.085766,	
2017-06-24 02:54:15,024 Epoch[51] Batch [770]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.085905,	
2017-06-24 02:54:20,946 Epoch[51] Batch [780]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.086044,	
2017-06-24 02:54:27,115 Epoch[51] Batch [790]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.086110,	
2017-06-24 02:54:34,629 Epoch[51] Batch [800]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.086202,	
2017-06-24 02:54:41,052 Epoch[51] Batch [810]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.086253,	
2017-06-24 02:54:47,485 Epoch[51] Batch [820]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.086306,	
2017-06-24 02:54:53,854 Epoch[51] Batch [830]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.086282,	
2017-06-24 02:54:59,548 Epoch[51] Batch [840]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.086212,	
2017-06-24 02:55:05,539 Epoch[51] Batch [850]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086147,	
2017-06-24 02:55:11,506 Epoch[51] Batch [860]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.086144,	
2017-06-24 02:55:17,227 Epoch[51] Batch [870]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.086141,	
2017-06-24 02:55:22,972 Epoch[51] Batch [880]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086211,	
2017-06-24 02:55:29,087 Epoch[51] Batch [890]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.086186,	
2017-06-24 02:55:35,223 Epoch[51] Batch [900]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.086197,	
2017-06-24 02:55:41,358 Epoch[51] Batch [910]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.086198,	
2017-06-24 02:55:48,018 Epoch[51] Batch [920]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.086197,	
2017-06-24 02:55:53,877 Epoch[51] Batch [930]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.086078,	
2017-06-24 02:55:59,661 Epoch[51] Batch [940]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.086077,	
2017-06-24 02:56:05,619 Epoch[51] Batch [950]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.086152,	
2017-06-24 02:56:11,616 Epoch[51] Batch [960]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.086185,	
2017-06-24 02:56:17,378 Epoch[51] Batch [970]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.086153,	
2017-06-24 02:56:23,025 Epoch[51] Batch [980]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.086137,	
2017-06-24 02:56:29,286 Epoch[51] Batch [990]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.086150,	
2017-06-24 02:56:35,278 Epoch[51] Batch [1000]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.086208,	
2017-06-24 02:56:41,329 Epoch[51] Batch [1010]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.086214,	
2017-06-24 02:56:47,098 Epoch[51] Batch [1020]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.086214,	
2017-06-24 02:56:53,458 Epoch[51] Batch [1030]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.086203,	
2017-06-24 02:56:59,503 Epoch[51] Batch [1040]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.086209,	
2017-06-24 02:57:05,056 Epoch[51] Batch [1050]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.086068,	
2017-06-24 02:57:10,765 Epoch[51] Batch [1060]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.086084,	
2017-06-24 02:57:16,513 Epoch[51] Batch [1070]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.086228,	
2017-06-24 02:57:22,153 Epoch[51] Batch [1080]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.086109,	
2017-06-24 02:57:28,211 Epoch[51] Batch [1090]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.086113,	
2017-06-24 02:57:34,558 Epoch[51] Batch [1100]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.086119,	
2017-06-24 02:57:40,382 Epoch[51] Batch [1110]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.086035,	
2017-06-24 02:57:46,083 Epoch[51] Batch [1120]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.085941,	
2017-06-24 02:57:52,075 Epoch[51] Batch [1130]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.085972,	
2017-06-24 02:57:57,966 Epoch[51] Batch [1140]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085944,	
2017-06-24 02:58:03,595 Epoch[51] Batch [1150]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.086033,	
2017-06-24 02:58:09,410 Epoch[51] Batch [1160]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.085998,	
2017-06-24 02:58:15,021 Epoch[51] Batch [1170]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.085984,	
2017-06-24 02:58:20,829 Epoch[51] Batch [1180]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.086041,	
2017-06-24 02:58:27,370 Epoch[51] Batch [1190]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.085999,	
2017-06-24 02:58:33,575 Epoch[51] Batch [1200]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.086039,	
2017-06-24 02:58:39,719 Epoch[51] Batch [1210]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.086062,	
2017-06-24 02:58:45,983 Epoch[51] Batch [1220]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.086023,	
2017-06-24 02:58:51,709 Epoch[51] Batch [1230]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.085994,	
2017-06-24 02:58:57,334 Epoch[51] Batch [1240]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.086001,	
2017-06-24 02:59:02,965 Epoch[51] Batch [1250]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.085944,	
2017-06-24 02:59:08,849 Epoch[51] Batch [1260]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.085871,	
2017-06-24 02:59:14,742 Epoch[51] Batch [1270]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085905,	
2017-06-24 02:59:20,939 Epoch[51] Batch [1280]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085875,	
2017-06-24 02:59:26,725 Epoch[51] Batch [1290]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.085882,	
2017-06-24 02:59:32,857 Epoch[51] Batch [1300]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.085868,	
2017-06-24 02:59:38,499 Epoch[51] Batch [1310]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.085789,	
2017-06-24 02:59:44,822 Epoch[51] Batch [1320]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.085782,	
2017-06-24 02:59:50,818 Epoch[51] Batch [1330]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085803,	
2017-06-24 02:59:56,677 Epoch[51] Batch [1340]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.085772,	
2017-06-24 03:00:02,585 Epoch[51] Batch [1350]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085786,	
2017-06-24 03:00:08,092 Epoch[51] Batch [1360]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.085864,	
2017-06-24 03:00:13,438 Epoch[51] Batch [1370]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.085904,	
2017-06-24 03:00:19,535 Epoch[51] Batch [1380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085909,	
2017-06-24 03:00:25,096 Epoch[51] Batch [1390]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.085810,	
2017-06-24 03:00:30,643 Epoch[51] Batch [1400]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.085845,	
2017-06-24 03:00:36,116 Epoch[51] Batch [1410]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.085791,	
2017-06-24 03:00:42,481 Epoch[51] Batch [1420]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.085800,	
2017-06-24 03:00:47,992 Epoch[51] Batch [1430]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.085803,	
2017-06-24 03:00:53,844 Epoch[51] Batch [1440]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.085772,	
2017-06-24 03:00:59,864 Epoch[51] Batch [1450]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.085722,	
2017-06-24 03:01:06,034 Epoch[51] Batch [1460]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.085694,	
2017-06-24 03:01:11,824 Epoch[51] Batch [1470]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.085691,	
2017-06-24 03:01:17,717 Epoch[51] Batch [1480]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085687,	
2017-06-24 03:01:21,646 Epoch[51] Train-FCNLogLoss=0.085694
2017-06-24 03:01:21,646 Epoch[51] Time cost=878.862
2017-06-24 03:01:22,551 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0052.params"
2017-06-24 03:01:26,114 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0052.states"
2017-06-24 03:01:32,627 Epoch[52] Batch [10]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.085445,	
2017-06-24 03:01:38,093 Epoch[52] Batch [20]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.082243,	
2017-06-24 03:01:43,768 Epoch[52] Batch [30]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.080218,	
2017-06-24 03:01:49,636 Epoch[52] Batch [40]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.080809,	
2017-06-24 03:01:55,574 Epoch[52] Batch [50]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.081370,	
2017-06-24 03:02:01,578 Epoch[52] Batch [60]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.081722,	
2017-06-24 03:02:07,415 Epoch[52] Batch [70]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.080855,	
2017-06-24 03:02:13,903 Epoch[52] Batch [80]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.081628,	
2017-06-24 03:02:19,518 Epoch[52] Batch [90]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.082292,	
2017-06-24 03:02:25,623 Epoch[52] Batch [100]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.082813,	
2017-06-24 03:02:31,259 Epoch[52] Batch [110]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.082880,	
2017-06-24 03:02:36,620 Epoch[52] Batch [120]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.083494,	
2017-06-24 03:02:42,345 Epoch[52] Batch [130]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.083793,	
2017-06-24 03:02:48,707 Epoch[52] Batch [140]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.084077,	
2017-06-24 03:02:55,103 Epoch[52] Batch [150]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.083417,	
2017-06-24 03:03:00,907 Epoch[52] Batch [160]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.083539,	
2017-06-24 03:03:06,796 Epoch[52] Batch [170]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.083130,	
2017-06-24 03:03:12,090 Epoch[52] Batch [180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.083040,	
2017-06-24 03:03:17,675 Epoch[52] Batch [190]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.083236,	
2017-06-24 03:03:23,479 Epoch[52] Batch [200]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.082532,	
2017-06-24 03:03:29,236 Epoch[52] Batch [210]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.083208,	
2017-06-24 03:03:34,815 Epoch[52] Batch [220]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.083108,	
2017-06-24 03:03:40,557 Epoch[52] Batch [230]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.083419,	
2017-06-24 03:03:46,672 Epoch[52] Batch [240]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.083516,	
2017-06-24 03:03:52,414 Epoch[52] Batch [250]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.083408,	
2017-06-24 03:03:58,056 Epoch[52] Batch [260]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.083328,	
2017-06-24 03:04:04,587 Epoch[52] Batch [270]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.083365,	
2017-06-24 03:04:10,298 Epoch[52] Batch [280]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.083545,	
2017-06-24 03:04:15,946 Epoch[52] Batch [290]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.083395,	
2017-06-24 03:04:22,153 Epoch[52] Batch [300]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.083251,	
2017-06-24 03:04:27,986 Epoch[52] Batch [310]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.083234,	
2017-06-24 03:04:33,662 Epoch[52] Batch [320]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.083373,	
2017-06-24 03:04:39,404 Epoch[52] Batch [330]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.083366,	
2017-06-24 03:04:45,345 Epoch[52] Batch [340]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.083414,	
2017-06-24 03:04:51,664 Epoch[52] Batch [350]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.083377,	
2017-06-24 03:04:57,925 Epoch[52] Batch [360]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.083720,	
2017-06-24 03:05:03,690 Epoch[52] Batch [370]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.083741,	
2017-06-24 03:05:10,759 Epoch[52] Batch [380]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.084094,	
2017-06-24 03:05:16,718 Epoch[52] Batch [390]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.083898,	
2017-06-24 03:05:23,027 Epoch[52] Batch [400]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.083931,	
2017-06-24 03:05:28,861 Epoch[52] Batch [410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.084220,	
2017-06-24 03:05:34,797 Epoch[52] Batch [420]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.084247,	
2017-06-24 03:05:40,607 Epoch[52] Batch [430]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.084531,	
2017-06-24 03:05:46,625 Epoch[52] Batch [440]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.084394,	
2017-06-24 03:05:52,667 Epoch[52] Batch [450]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.084533,	
2017-06-24 03:05:58,710 Epoch[52] Batch [460]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.084480,	
2017-06-24 03:06:04,528 Epoch[52] Batch [470]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.084427,	
2017-06-24 03:06:10,570 Epoch[52] Batch [480]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.084386,	
2017-06-24 03:06:16,860 Epoch[52] Batch [490]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.084365,	
2017-06-24 03:06:23,093 Epoch[52] Batch [500]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.084328,	
2017-06-24 03:06:29,037 Epoch[52] Batch [510]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.084264,	
2017-06-24 03:06:35,044 Epoch[52] Batch [520]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.084172,	
2017-06-24 03:06:41,150 Epoch[52] Batch [530]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.084302,	
2017-06-24 03:06:47,346 Epoch[52] Batch [540]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.084200,	
2017-06-24 03:06:53,832 Epoch[52] Batch [550]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.084315,	
2017-06-24 03:06:59,735 Epoch[52] Batch [560]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.084225,	
2017-06-24 03:07:05,387 Epoch[52] Batch [570]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.084156,	
2017-06-24 03:07:11,264 Epoch[52] Batch [580]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.084199,	
2017-06-24 03:07:17,221 Epoch[52] Batch [590]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.084245,	
2017-06-24 03:07:23,086 Epoch[52] Batch [600]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.084215,	
2017-06-24 03:07:28,692 Epoch[52] Batch [610]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.084243,	
2017-06-24 03:07:34,748 Epoch[52] Batch [620]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.084416,	
2017-06-24 03:07:41,014 Epoch[52] Batch [630]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.084414,	
2017-06-24 03:07:46,493 Epoch[52] Batch [640]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.084672,	
2017-06-24 03:07:52,786 Epoch[52] Batch [650]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.084845,	
2017-06-24 03:07:59,470 Epoch[52] Batch [660]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.084924,	
2017-06-24 03:08:05,273 Epoch[52] Batch [670]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.084979,	
2017-06-24 03:08:11,838 Epoch[52] Batch [680]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.085004,	
2017-06-24 03:08:17,889 Epoch[52] Batch [690]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.085021,	
2017-06-24 03:08:24,283 Epoch[52] Batch [700]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.084987,	
2017-06-24 03:08:30,502 Epoch[52] Batch [710]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.084914,	
2017-06-24 03:08:36,893 Epoch[52] Batch [720]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.084966,	
2017-06-24 03:08:42,933 Epoch[52] Batch [730]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.085043,	
2017-06-24 03:08:49,416 Epoch[52] Batch [740]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.085120,	
2017-06-24 03:08:55,533 Epoch[52] Batch [750]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.085242,	
2017-06-24 03:09:02,187 Epoch[52] Batch [760]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.085229,	
2017-06-24 03:09:08,405 Epoch[52] Batch [770]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.085278,	
2017-06-24 03:09:13,933 Epoch[52] Batch [780]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.085268,	
2017-06-24 03:09:20,238 Epoch[52] Batch [790]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.085253,	
2017-06-24 03:09:25,994 Epoch[52] Batch [800]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.085214,	
2017-06-24 03:09:31,978 Epoch[52] Batch [810]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.085151,	
2017-06-24 03:09:37,971 Epoch[52] Batch [820]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.085270,	
2017-06-24 03:09:43,797 Epoch[52] Batch [830]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.085292,	
2017-06-24 03:09:49,311 Epoch[52] Batch [840]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.085255,	
2017-06-24 03:09:55,198 Epoch[52] Batch [850]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.085453,	
2017-06-24 03:10:01,261 Epoch[52] Batch [860]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.085440,	
2017-06-24 03:10:07,360 Epoch[52] Batch [870]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.085376,	
2017-06-24 03:10:13,033 Epoch[52] Batch [880]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.085409,	
2017-06-24 03:10:18,797 Epoch[52] Batch [890]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.085363,	
2017-06-24 03:10:24,932 Epoch[52] Batch [900]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.085322,	
2017-06-24 03:10:30,677 Epoch[52] Batch [910]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.085440,	
2017-06-24 03:10:36,068 Epoch[52] Batch [920]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.085567,	
2017-06-24 03:10:41,836 Epoch[52] Batch [930]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085487,	
2017-06-24 03:10:47,331 Epoch[52] Batch [940]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.085555,	
2017-06-24 03:10:52,636 Epoch[52] Batch [950]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.085551,	
2017-06-24 03:10:58,063 Epoch[52] Batch [960]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.085487,	
2017-06-24 03:11:04,098 Epoch[52] Batch [970]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.085487,	
2017-06-24 03:11:10,620 Epoch[52] Batch [980]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.085410,	
2017-06-24 03:11:16,450 Epoch[52] Batch [990]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.085495,	
2017-06-24 03:11:22,043 Epoch[52] Batch [1000]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.085439,	
2017-06-24 03:11:27,613 Epoch[52] Batch [1010]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.085581,	
2017-06-24 03:11:33,551 Epoch[52] Batch [1020]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.085596,	
2017-06-24 03:11:39,380 Epoch[52] Batch [1030]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.085630,	
2017-06-24 03:11:45,565 Epoch[52] Batch [1040]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.085720,	
2017-06-24 03:11:51,614 Epoch[52] Batch [1050]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.085741,	
2017-06-24 03:11:57,633 Epoch[52] Batch [1060]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.085732,	
2017-06-24 03:12:03,070 Epoch[52] Batch [1070]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085766,	
2017-06-24 03:12:08,908 Epoch[52] Batch [1080]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085764,	
2017-06-24 03:12:14,218 Epoch[52] Batch [1090]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.085797,	
2017-06-24 03:12:19,349 Epoch[52] Batch [1100]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.085778,	
2017-06-24 03:12:25,164 Epoch[52] Batch [1110]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.085697,	
2017-06-24 03:12:31,233 Epoch[52] Batch [1120]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.085738,	
2017-06-24 03:12:36,472 Epoch[52] Batch [1130]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.085676,	
2017-06-24 03:12:41,953 Epoch[52] Batch [1140]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.085672,	
2017-06-24 03:12:47,388 Epoch[52] Batch [1150]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.085507,	
2017-06-24 03:12:52,922 Epoch[52] Batch [1160]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.085508,	
2017-06-24 03:12:58,610 Epoch[52] Batch [1170]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.085491,	
2017-06-24 03:13:04,067 Epoch[52] Batch [1180]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.085574,	
2017-06-24 03:13:09,410 Epoch[52] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.085562,	
2017-06-24 03:13:15,174 Epoch[52] Batch [1200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.085558,	
2017-06-24 03:13:20,469 Epoch[52] Batch [1210]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.085559,	
2017-06-24 03:13:26,183 Epoch[52] Batch [1220]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.085673,	
2017-06-24 03:13:31,726 Epoch[52] Batch [1230]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.085696,	
2017-06-24 03:13:37,082 Epoch[52] Batch [1240]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.085641,	
2017-06-24 03:13:42,528 Epoch[52] Batch [1250]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.085614,	
2017-06-24 03:13:47,785 Epoch[52] Batch [1260]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.085640,	
2017-06-24 03:13:53,334 Epoch[52] Batch [1270]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.085673,	
2017-06-24 03:13:59,339 Epoch[52] Batch [1280]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.085582,	
2017-06-24 03:14:05,137 Epoch[52] Batch [1290]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.085570,	
2017-06-24 03:14:10,899 Epoch[52] Batch [1300]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.085572,	
2017-06-24 03:14:16,607 Epoch[52] Batch [1310]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.085543,	
2017-06-24 03:14:21,831 Epoch[52] Batch [1320]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.085590,	
2017-06-24 03:14:27,497 Epoch[52] Batch [1330]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.085606,	
2017-06-24 03:14:33,795 Epoch[52] Batch [1340]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.085611,	
2017-06-24 03:14:39,638 Epoch[52] Batch [1350]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.085592,	
2017-06-24 03:14:45,393 Epoch[52] Batch [1360]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.085620,	
2017-06-24 03:14:51,552 Epoch[52] Batch [1370]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.085674,	
2017-06-24 03:14:57,515 Epoch[52] Batch [1380]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.085623,	
2017-06-24 03:15:03,491 Epoch[52] Batch [1390]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.085595,	
2017-06-24 03:15:09,265 Epoch[52] Batch [1400]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.085570,	
2017-06-24 03:15:15,543 Epoch[52] Batch [1410]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.085663,	
2017-06-24 03:15:21,943 Epoch[52] Batch [1420]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.085639,	
2017-06-24 03:15:28,238 Epoch[52] Batch [1430]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.085671,	
2017-06-24 03:15:34,593 Epoch[52] Batch [1440]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.085649,	
2017-06-24 03:15:40,791 Epoch[52] Batch [1450]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.085595,	
2017-06-24 03:15:46,701 Epoch[52] Batch [1460]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.085608,	
2017-06-24 03:15:52,792 Epoch[52] Batch [1470]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.085535,	
2017-06-24 03:15:58,684 Epoch[52] Batch [1480]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.085499,	
2017-06-24 03:16:01,932 Epoch[52] Train-FCNLogLoss=0.085538
2017-06-24 03:16:01,933 Epoch[52] Time cost=875.818
2017-06-24 03:16:03,054 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0053.params"
2017-06-24 03:16:06,599 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3-0053.states"
2017-06-24 03:16:06,612 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate3x3',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '1,2,3,4',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate3x3'}

2017-06-24 03:16:18,749 testing 4/500 data 1.3777s net 0.2982s post 0.0087s
2017-06-24 03:16:20,023 testing 8/500 data 1.1806s net 0.2895s post 0.0092s
2017-06-24 03:16:21,444 testing 12/500 data 1.1457s net 0.3046s post 0.0097s
2017-06-24 03:16:22,757 testing 16/500 data 1.1156s net 0.2988s post 0.0088s
2017-06-24 03:16:23,968 testing 20/500 data 1.0845s net 0.2880s post 0.0083s
2017-06-24 03:16:25,229 testing 24/500 data 1.0650s net 0.2877s post 0.0081s
2017-06-24 03:16:26,463 testing 28/500 data 1.0532s net 0.2815s post 0.0079s
2017-06-24 03:16:27,783 testing 32/500 data 1.0470s net 0.2840s post 0.0087s
2017-06-24 03:16:29,018 testing 36/500 data 1.0401s net 0.2795s post 0.0086s
2017-06-24 03:16:30,392 testing 40/500 data 1.0374s net 0.2864s post 0.0089s
2017-06-24 03:16:31,619 testing 44/500 data 1.0314s net 0.2826s post 0.0092s
2017-06-24 03:16:32,893 testing 48/500 data 1.0289s net 0.2810s post 0.0092s
2017-06-24 03:16:34,287 testing 52/500 data 1.0302s net 0.2852s post 0.0094s
2017-06-24 03:16:35,561 testing 56/500 data 1.0250s net 0.2870s post 0.0092s
2017-06-24 03:16:36,790 testing 60/500 data 1.0214s net 0.2842s post 0.0094s
2017-06-24 03:16:38,090 testing 64/500 data 1.0200s net 0.2849s post 0.0092s
2017-06-24 03:16:39,354 testing 68/500 data 1.0178s net 0.2843s post 0.0091s
2017-06-24 03:16:40,749 testing 72/500 data 1.0180s net 0.2886s post 0.0092s
2017-06-24 03:16:41,884 testing 76/500 data 1.0106s net 0.2863s post 0.0094s
2017-06-24 03:16:43,222 testing 80/500 data 1.0128s net 0.2859s post 0.0093s
2017-06-24 03:16:44,664 testing 84/500 data 1.0192s net 0.2859s post 0.0091s
2017-06-24 03:16:45,989 testing 88/500 data 1.0211s net 0.2847s post 0.0090s
2017-06-24 03:16:47,299 testing 92/500 data 1.0219s net 0.2837s post 0.0089s
2017-06-24 03:16:48,691 testing 96/500 data 1.0238s net 0.2852s post 0.0088s
2017-06-24 03:16:50,086 testing 100/500 data 1.0243s net 0.2876s post 0.0089s
2017-06-24 03:16:51,368 testing 104/500 data 1.0218s net 0.2888s post 0.0088s
2017-06-24 03:16:52,670 testing 108/500 data 1.0206s net 0.2894s post 0.0088s
2017-06-24 03:16:53,878 testing 112/500 data 1.0173s net 0.2888s post 0.0087s
2017-06-24 03:16:55,306 testing 116/500 data 1.0192s net 0.2908s post 0.0087s
2017-06-24 03:16:56,641 testing 120/500 data 1.0175s net 0.2932s post 0.0086s
2017-06-24 03:16:57,908 testing 124/500 data 1.0134s net 0.2955s post 0.0086s
2017-06-24 03:16:59,146 testing 128/500 data 1.0125s net 0.2940s post 0.0085s
2017-06-24 03:17:00,419 testing 132/500 data 1.0127s net 0.2925s post 0.0086s
2017-06-24 03:17:01,669 testing 136/500 data 1.0114s net 0.2919s post 0.0086s
2017-06-24 03:17:02,965 testing 140/500 data 1.0102s net 0.2927s post 0.0085s
2017-06-24 03:17:04,172 testing 144/500 data 1.0077s net 0.2924s post 0.0084s
2017-06-24 03:17:05,425 testing 148/500 data 1.0063s net 0.2923s post 0.0084s
2017-06-24 03:17:06,769 testing 152/500 data 1.0064s net 0.2933s post 0.0083s
2017-06-24 03:17:08,092 testing 156/500 data 1.0063s net 0.2938s post 0.0083s
2017-06-24 03:17:09,348 testing 160/500 data 1.0051s net 0.2937s post 0.0083s
2017-06-24 03:17:10,711 testing 164/500 data 1.0052s net 0.2949s post 0.0083s
2017-06-24 03:17:11,995 testing 168/500 data 1.0057s net 0.2937s post 0.0084s
2017-06-24 03:17:13,265 testing 172/500 data 1.0061s net 0.2926s post 0.0084s
2017-06-24 03:17:14,610 testing 176/500 data 1.0080s net 0.2915s post 0.0084s
2017-06-24 03:17:16,148 testing 180/500 data 1.0110s net 0.2936s post 0.0083s
2017-06-24 03:17:17,295 testing 184/500 data 1.0082s net 0.2928s post 0.0083s
2017-06-24 03:17:18,690 testing 188/500 data 1.0088s net 0.2941s post 0.0083s
2017-06-24 03:17:19,873 testing 192/500 data 1.0070s net 0.2931s post 0.0083s
2017-06-24 03:17:21,201 testing 196/500 data 1.0057s net 0.2949s post 0.0083s
2017-06-24 03:17:22,394 testing 200/500 data 1.0042s net 0.2942s post 0.0083s
2017-06-24 03:17:23,658 testing 204/500 data 1.0036s net 0.2940s post 0.0082s
2017-06-24 03:17:25,120 testing 208/500 data 1.0069s net 0.2937s post 0.0082s
2017-06-24 03:17:26,528 testing 212/500 data 1.0083s net 0.2942s post 0.0082s
2017-06-24 03:17:27,884 testing 216/500 data 1.0087s net 0.2946s post 0.0081s
2017-06-24 03:17:29,086 testing 220/500 data 1.0076s net 0.2937s post 0.0082s
2017-06-24 03:17:30,358 testing 224/500 data 1.0072s net 0.2935s post 0.0082s
2017-06-24 03:17:31,600 testing 228/500 data 1.0064s net 0.2931s post 0.0082s
2017-06-24 03:17:32,875 testing 232/500 data 1.0060s net 0.2929s post 0.0082s
2017-06-24 03:17:34,221 testing 236/500 data 1.0052s net 0.2943s post 0.0083s
2017-06-24 03:17:35,394 testing 240/500 data 1.0028s net 0.2944s post 0.0083s
2017-06-24 03:17:36,715 testing 244/500 data 1.0034s net 0.2940s post 0.0083s
2017-06-24 03:17:38,133 testing 248/500 data 1.0054s net 0.2939s post 0.0083s
2017-06-24 03:17:39,439 testing 252/500 data 1.0041s net 0.2952s post 0.0082s
2017-06-24 03:17:40,623 testing 256/500 data 1.0030s net 0.2944s post 0.0082s
2017-06-24 03:17:41,995 testing 260/500 data 1.0043s net 0.2941s post 0.0082s
2017-06-24 03:17:43,364 testing 264/500 data 1.0044s net 0.2950s post 0.0082s
2017-06-24 03:17:44,525 testing 268/500 data 1.0024s net 0.2948s post 0.0082s
2017-06-24 03:17:45,784 testing 272/500 data 1.0021s net 0.2944s post 0.0082s
2017-06-24 03:17:47,138 testing 276/500 data 1.0033s net 0.2940s post 0.0081s
2017-06-24 03:17:48,581 testing 280/500 data 1.0049s net 0.2943s post 0.0081s
2017-06-24 03:17:49,797 testing 284/500 data 1.0030s net 0.2949s post 0.0082s
2017-06-24 03:17:51,054 testing 288/500 data 1.0028s net 0.2944s post 0.0082s
2017-06-24 03:17:52,293 testing 292/500 data 1.0021s net 0.2942s post 0.0082s
2017-06-24 03:17:53,659 testing 296/500 data 1.0024s net 0.2948s post 0.0082s
2017-06-24 03:17:54,893 testing 300/500 data 1.0016s net 0.2946s post 0.0082s
2017-06-24 03:17:56,279 testing 304/500 data 1.0022s net 0.2951s post 0.0081s
2017-06-24 03:17:57,493 testing 308/500 data 1.0014s net 0.2948s post 0.0081s
2017-06-24 03:17:58,864 testing 312/500 data 1.0023s net 0.2947s post 0.0081s
2017-06-24 03:18:00,171 testing 316/500 data 1.0023s net 0.2947s post 0.0081s
2017-06-24 03:18:01,499 testing 320/500 data 1.0021s net 0.2952s post 0.0081s
2017-06-24 03:18:02,813 testing 324/500 data 1.0023s net 0.2951s post 0.0081s
2017-06-24 03:18:04,182 testing 328/500 data 1.0038s net 0.2945s post 0.0081s
2017-06-24 03:18:05,705 testing 332/500 data 1.0065s net 0.2943s post 0.0081s
2017-06-24 03:18:06,968 testing 336/500 data 1.0063s net 0.2939s post 0.0081s
2017-06-24 03:18:08,241 testing 340/500 data 1.0063s net 0.2936s post 0.0081s
2017-06-24 03:18:09,676 testing 344/500 data 1.0074s net 0.2940s post 0.0080s
2017-06-24 03:18:10,984 testing 348/500 data 1.0072s net 0.2942s post 0.0080s
2017-06-24 03:18:12,319 testing 352/500 data 1.0066s net 0.2951s post 0.0080s
2017-06-24 03:18:13,582 testing 356/500 data 1.0051s net 0.2960s post 0.0080s
2017-06-24 03:18:14,809 testing 360/500 data 1.0044s net 0.2959s post 0.0080s
2017-06-24 03:18:16,111 testing 364/500 data 1.0046s net 0.2957s post 0.0080s
2017-06-24 03:18:17,469 testing 368/500 data 1.0052s net 0.2955s post 0.0080s
2017-06-24 03:18:19,024 testing 372/500 data 1.0071s net 0.2964s post 0.0079s
2017-06-24 03:18:20,337 testing 376/500 data 1.0070s net 0.2965s post 0.0079s
2017-06-24 03:18:21,552 testing 380/500 data 1.0063s net 0.2961s post 0.0079s
2017-06-24 03:18:23,143 testing 384/500 data 1.0088s net 0.2965s post 0.0080s
2017-06-24 03:18:24,458 testing 388/500 data 1.0089s net 0.2965s post 0.0079s
2017-06-24 03:18:25,796 testing 392/500 data 1.0090s net 0.2966s post 0.0080s
2017-06-24 03:18:27,067 testing 396/500 data 1.0090s net 0.2961s post 0.0080s
2017-06-24 03:18:28,452 testing 400/500 data 1.0100s net 0.2959s post 0.0080s
2017-06-24 03:18:29,855 testing 404/500 data 1.0114s net 0.2953s post 0.0080s
2017-06-24 03:18:31,153 testing 408/500 data 1.0115s net 0.2951s post 0.0080s
2017-06-24 03:18:32,595 testing 412/500 data 1.0131s net 0.2948s post 0.0079s
2017-06-24 03:18:33,988 testing 416/500 data 1.0134s net 0.2952s post 0.0079s
2017-06-24 03:18:35,135 testing 420/500 data 1.0120s net 0.2950s post 0.0080s
2017-06-24 03:18:36,542 testing 424/500 data 1.0126s net 0.2952s post 0.0079s
2017-06-24 03:18:37,935 testing 428/500 data 1.0132s net 0.2954s post 0.0079s
2017-06-24 03:18:39,319 testing 432/500 data 1.0136s net 0.2956s post 0.0079s
2017-06-24 03:18:40,649 testing 436/500 data 1.0140s net 0.2953s post 0.0080s
2017-06-24 03:18:42,092 testing 440/500 data 1.0153s net 0.2952s post 0.0079s
2017-06-24 03:18:43,620 testing 444/500 data 1.0168s net 0.2956s post 0.0079s
2017-06-24 03:18:44,834 testing 448/500 data 1.0157s net 0.2957s post 0.0079s
2017-06-24 03:18:46,212 testing 452/500 data 1.0161s net 0.2959s post 0.0079s
2017-06-24 03:18:47,491 testing 456/500 data 1.0159s net 0.2957s post 0.0079s
2017-06-24 03:18:48,780 testing 460/500 data 1.0157s net 0.2957s post 0.0079s
2017-06-24 03:18:50,141 testing 464/500 data 1.0162s net 0.2955s post 0.0079s
2017-06-24 03:18:51,555 testing 468/500 data 1.0172s net 0.2953s post 0.0079s
2017-06-24 03:18:52,876 testing 472/500 data 1.0169s net 0.2956s post 0.0079s
2017-06-24 03:18:54,048 testing 476/500 data 1.0159s net 0.2954s post 0.0079s
2017-06-24 03:18:55,460 testing 480/500 data 1.0161s net 0.2960s post 0.0079s
2017-06-24 03:18:56,751 testing 484/500 data 1.0162s net 0.2956s post 0.0079s
2017-06-24 03:18:58,099 testing 488/500 data 1.0160s net 0.2960s post 0.0079s
2017-06-24 03:18:59,569 testing 492/500 data 1.0166s net 0.2967s post 0.0079s
2017-06-24 03:19:00,808 testing 496/500 data 1.0164s net 0.2963s post 0.0079s
2017-06-24 03:19:02,133 testing 500/500 data 1.0165s net 0.2962s post 0.0078s
2017-06-24 03:20:56,934 evaluate segmentation: 

2017-06-24 03:20:56,934 IU_array:

2017-06-24 03:20:56,934 0.97696
2017-06-24 03:20:56,934 0.82272
2017-06-24 03:20:56,934 0.90931
2017-06-24 03:20:56,934 0.46277
2017-06-24 03:20:56,935 0.51430
2017-06-24 03:20:56,935 0.53052
2017-06-24 03:20:56,935 0.63787
2017-06-24 03:20:56,935 0.72876
2017-06-24 03:20:56,935 0.91361
2017-06-24 03:20:56,935 0.60332
2017-06-24 03:20:56,935 0.93494
2017-06-24 03:20:56,935 0.77488
2017-06-24 03:20:56,935 0.56150
2017-06-24 03:20:56,935 0.93259
2017-06-24 03:20:56,935 0.57548
2017-06-24 03:20:56,935 0.75110
2017-06-24 03:20:56,935 0.55040
2017-06-24 03:20:56,935 0.58892
2017-06-24 03:20:56,935 0.73525
2017-06-24 03:20:56,935 meanIU:0.71080

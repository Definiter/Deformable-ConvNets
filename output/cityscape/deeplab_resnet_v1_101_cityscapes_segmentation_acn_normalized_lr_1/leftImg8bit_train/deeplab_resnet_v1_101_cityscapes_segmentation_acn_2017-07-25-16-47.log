2017-07-25 16:47:09,216 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-25 16:47:51,102 Epoch[0] Batch [10]	Speed: 10.09 samples/sec	Train-FCNLogLoss=2.881244,	
2017-07-25 16:47:55,323 Epoch[0] Batch [20]	Speed: 9.48 samples/sec	Train-FCNLogLoss=2.750526,	
2017-07-25 16:47:59,269 Epoch[0] Batch [30]	Speed: 10.14 samples/sec	Train-FCNLogLoss=2.492086,	
2017-07-25 16:48:03,654 Epoch[0] Batch [40]	Speed: 9.12 samples/sec	Train-FCNLogLoss=2.270652,	
2017-07-25 16:48:07,626 Epoch[0] Batch [50]	Speed: 10.07 samples/sec	Train-FCNLogLoss=2.047626,	
2017-07-25 16:48:12,227 Epoch[0] Batch [60]	Speed: 8.69 samples/sec	Train-FCNLogLoss=1.881536,	
2017-07-25 16:48:16,492 Epoch[0] Batch [70]	Speed: 9.38 samples/sec	Train-FCNLogLoss=1.742641,	
2017-07-25 16:48:21,048 Epoch[0] Batch [80]	Speed: 8.78 samples/sec	Train-FCNLogLoss=1.627466,	
2017-07-25 16:48:25,392 Epoch[0] Batch [90]	Speed: 9.21 samples/sec	Train-FCNLogLoss=1.533094,	
2017-07-25 16:48:30,019 Epoch[0] Batch [100]	Speed: 8.64 samples/sec	Train-FCNLogLoss=1.457398,	
2017-07-25 16:48:34,663 Epoch[0] Batch [110]	Speed: 8.62 samples/sec	Train-FCNLogLoss=1.386300,	
2017-07-25 16:48:39,183 Epoch[0] Batch [120]	Speed: 8.85 samples/sec	Train-FCNLogLoss=1.323684,	
2017-07-25 16:48:43,666 Epoch[0] Batch [130]	Speed: 8.92 samples/sec	Train-FCNLogLoss=1.268276,	
2017-07-25 16:48:47,753 Epoch[0] Batch [140]	Speed: 9.79 samples/sec	Train-FCNLogLoss=1.224323,	
2017-07-25 16:48:52,092 Epoch[0] Batch [150]	Speed: 9.22 samples/sec	Train-FCNLogLoss=1.179747,	
2017-07-25 16:48:56,502 Epoch[0] Batch [160]	Speed: 9.07 samples/sec	Train-FCNLogLoss=1.138958,	
2017-07-25 16:49:00,467 Epoch[0] Batch [170]	Speed: 10.09 samples/sec	Train-FCNLogLoss=1.099378,	
2017-07-25 16:49:04,480 Epoch[0] Batch [180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=1.070243,	
2017-07-25 16:49:08,763 Epoch[0] Batch [190]	Speed: 9.34 samples/sec	Train-FCNLogLoss=1.038827,	
2017-07-25 16:49:12,952 Epoch[0] Batch [200]	Speed: 9.55 samples/sec	Train-FCNLogLoss=1.012335,	
2017-07-25 16:49:17,161 Epoch[0] Batch [210]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.988992,	
2017-07-25 16:49:21,480 Epoch[0] Batch [220]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.964789,	
2017-07-25 16:49:25,913 Epoch[0] Batch [230]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.944381,	
2017-07-25 16:49:30,305 Epoch[0] Batch [240]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.925127,	
2017-07-25 16:49:34,733 Epoch[0] Batch [250]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.905823,	
2017-07-25 16:49:39,100 Epoch[0] Batch [260]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.885464,	
2017-07-25 16:49:43,906 Epoch[0] Batch [270]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.868174,	
2017-07-25 16:49:48,317 Epoch[0] Batch [280]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.850912,	
2017-07-25 16:49:52,511 Epoch[0] Batch [290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.836297,	
2017-07-25 16:49:56,762 Epoch[0] Batch [300]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.822781,	
2017-07-25 16:50:01,110 Epoch[0] Batch [310]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.813748,	
2017-07-25 16:50:05,614 Epoch[0] Batch [320]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.801555,	
2017-07-25 16:50:10,183 Epoch[0] Batch [330]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.790133,	
2017-07-25 16:50:14,706 Epoch[0] Batch [340]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.780479,	
2017-07-25 16:50:18,903 Epoch[0] Batch [350]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.771355,	
2017-07-25 16:50:23,164 Epoch[0] Batch [360]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.762188,	
2017-07-25 16:50:27,247 Epoch[0] Batch [370]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.753019,	
2017-07-25 16:50:31,482 Epoch[0] Batch [380]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.744363,	
2017-07-25 16:50:35,508 Epoch[0] Batch [390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.737541,	
2017-07-25 16:50:39,666 Epoch[0] Batch [400]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.728960,	
2017-07-25 16:50:44,013 Epoch[0] Batch [410]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.720714,	
2017-07-25 16:50:48,471 Epoch[0] Batch [420]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.713287,	
2017-07-25 16:50:52,772 Epoch[0] Batch [430]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.706147,	
2017-07-25 16:50:56,914 Epoch[0] Batch [440]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.698682,	
2017-07-25 16:51:01,326 Epoch[0] Batch [450]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.693623,	
2017-07-25 16:51:05,554 Epoch[0] Batch [460]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.688029,	
2017-07-25 16:51:09,828 Epoch[0] Batch [470]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.681416,	
2017-07-25 16:51:13,962 Epoch[0] Batch [480]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.675537,	
2017-07-25 16:51:18,463 Epoch[0] Batch [490]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.671075,	
2017-07-25 16:51:22,795 Epoch[0] Batch [500]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.665074,	
2017-07-25 16:51:26,985 Epoch[0] Batch [510]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.662437,	
2017-07-25 16:51:31,451 Epoch[0] Batch [520]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.658295,	
2017-07-25 16:51:35,402 Epoch[0] Batch [530]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.652187,	
2017-07-25 16:51:39,907 Epoch[0] Batch [540]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.646823,	
2017-07-25 16:51:44,066 Epoch[0] Batch [550]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.641497,	
2017-07-25 16:51:48,731 Epoch[0] Batch [560]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.635700,	
2017-07-25 16:51:53,077 Epoch[0] Batch [570]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.632741,	
2017-07-25 16:51:57,819 Epoch[0] Batch [580]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.628843,	
2017-07-25 16:52:02,247 Epoch[0] Batch [590]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.625022,	
2017-07-25 16:52:06,625 Epoch[0] Batch [600]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.620616,	
2017-07-25 16:52:11,152 Epoch[0] Batch [610]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.618121,	
2017-07-25 16:52:15,959 Epoch[0] Batch [620]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.614588,	
2017-07-25 16:52:20,243 Epoch[0] Batch [630]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.611967,	
2017-07-25 16:52:24,441 Epoch[0] Batch [640]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.608630,	
2017-07-25 16:52:28,728 Epoch[0] Batch [650]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.606118,	
2017-07-25 16:52:32,894 Epoch[0] Batch [660]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.601314,	
2017-07-25 16:52:36,761 Epoch[0] Batch [670]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.597766,	
2017-07-25 16:52:41,146 Epoch[0] Batch [680]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.595037,	
2017-07-25 16:52:45,919 Epoch[0] Batch [690]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.591203,	
2017-07-25 16:52:50,279 Epoch[0] Batch [700]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.587482,	
2017-07-25 16:52:54,881 Epoch[0] Batch [710]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.585547,	
2017-07-25 16:52:59,442 Epoch[0] Batch [720]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.582763,	
2017-07-25 16:53:03,595 Epoch[0] Batch [730]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.579736,	
2017-07-25 16:53:07,903 Epoch[0] Batch [740]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.576733,	
2017-07-25 16:53:12,111 Epoch[0] Batch [750]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.574969,	
2017-07-25 16:53:16,644 Epoch[0] Batch [760]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.572486,	
2017-07-25 16:53:21,142 Epoch[0] Batch [770]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.568911,	
2017-07-25 16:53:25,195 Epoch[0] Batch [780]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.565928,	
2017-07-25 16:53:30,122 Epoch[0] Batch [790]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.563114,	
2017-07-25 16:53:34,766 Epoch[0] Batch [800]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.560497,	
2017-07-25 16:53:39,272 Epoch[0] Batch [810]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.557807,	
2017-07-25 16:53:43,423 Epoch[0] Batch [820]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.555372,	
2017-07-25 16:53:48,302 Epoch[0] Batch [830]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.553317,	
2017-07-25 16:53:52,513 Epoch[0] Batch [840]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.550290,	
2017-07-25 16:53:56,782 Epoch[0] Batch [850]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.547931,	
2017-07-25 16:54:01,108 Epoch[0] Batch [860]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.545218,	
2017-07-25 16:54:05,586 Epoch[0] Batch [870]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.543111,	
2017-07-25 16:54:10,113 Epoch[0] Batch [880]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.540697,	
2017-07-25 16:54:14,433 Epoch[0] Batch [890]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.538214,	
2017-07-25 16:54:18,678 Epoch[0] Batch [900]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.535423,	
2017-07-25 16:54:22,903 Epoch[0] Batch [910]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.533048,	
2017-07-25 16:54:27,274 Epoch[0] Batch [920]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.530552,	
2017-07-25 16:54:31,652 Epoch[0] Batch [930]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.527873,	
2017-07-25 16:54:35,757 Epoch[0] Batch [940]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.526505,	
2017-07-25 16:54:40,393 Epoch[0] Batch [950]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.524106,	
2017-07-25 16:54:44,748 Epoch[0] Batch [960]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.522120,	
2017-07-25 16:54:49,003 Epoch[0] Batch [970]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.519968,	
2017-07-25 16:54:53,192 Epoch[0] Batch [980]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.518299,	
2017-07-25 16:54:57,505 Epoch[0] Batch [990]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.517026,	
2017-07-25 16:55:02,358 Epoch[0] Batch [1000]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.514882,	
2017-07-25 16:55:06,836 Epoch[0] Batch [1010]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.512747,	
2017-07-25 16:55:10,992 Epoch[0] Batch [1020]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.511826,	
2017-07-25 16:55:15,501 Epoch[0] Batch [1030]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.511379,	
2017-07-25 16:55:19,606 Epoch[0] Batch [1040]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.511389,	
2017-07-25 16:55:23,751 Epoch[0] Batch [1050]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.511543,	
2017-07-25 16:55:28,181 Epoch[0] Batch [1060]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.511813,	
2017-07-25 16:55:32,218 Epoch[0] Batch [1070]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.511607,	
2017-07-25 16:55:36,333 Epoch[0] Batch [1080]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.510947,	
2017-07-25 16:55:40,574 Epoch[0] Batch [1090]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.509817,	
2017-07-25 16:55:45,168 Epoch[0] Batch [1100]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.508301,	
2017-07-25 16:55:49,672 Epoch[0] Batch [1110]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.507342,	
2017-07-25 16:55:54,023 Epoch[0] Batch [1120]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.505717,	
2017-07-25 16:55:58,492 Epoch[0] Batch [1130]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.505159,	
2017-07-25 16:56:02,642 Epoch[0] Batch [1140]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.504103,	
2017-07-25 16:56:06,752 Epoch[0] Batch [1150]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.503017,	
2017-07-25 16:56:10,975 Epoch[0] Batch [1160]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.502908,	
2017-07-25 16:56:14,891 Epoch[0] Batch [1170]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.502229,	
2017-07-25 16:56:19,165 Epoch[0] Batch [1180]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.500701,	
2017-07-25 16:56:23,703 Epoch[0] Batch [1190]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.498947,	
2017-07-25 16:56:27,721 Epoch[0] Batch [1200]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.497635,	
2017-07-25 16:56:32,023 Epoch[0] Batch [1210]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.496253,	
2017-07-25 16:56:36,077 Epoch[0] Batch [1220]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.494377,	
2017-07-25 16:56:40,321 Epoch[0] Batch [1230]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.493125,	
2017-07-25 16:56:44,523 Epoch[0] Batch [1240]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.492232,	
2017-07-25 16:56:48,852 Epoch[0] Batch [1250]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.491298,	
2017-07-25 16:56:53,356 Epoch[0] Batch [1260]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.490127,	
2017-07-25 16:56:57,632 Epoch[0] Batch [1270]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.489385,	
2017-07-25 16:57:02,188 Epoch[0] Batch [1280]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.487713,	
2017-07-25 16:57:06,612 Epoch[0] Batch [1290]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.486509,	
2017-07-25 16:57:11,232 Epoch[0] Batch [1300]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.485325,	
2017-07-25 16:57:15,334 Epoch[0] Batch [1310]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.483794,	
2017-07-25 16:57:19,457 Epoch[0] Batch [1320]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.482570,	
2017-07-25 16:57:24,038 Epoch[0] Batch [1330]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.481327,	
2017-07-25 16:57:28,701 Epoch[0] Batch [1340]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.480067,	
2017-07-25 16:57:32,818 Epoch[0] Batch [1350]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.479234,	
2017-07-25 16:57:37,136 Epoch[0] Batch [1360]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.478287,	
2017-07-25 16:57:41,425 Epoch[0] Batch [1370]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.477679,	
2017-07-25 16:57:45,569 Epoch[0] Batch [1380]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.476524,	
2017-07-25 16:57:50,030 Epoch[0] Batch [1390]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.475355,	
2017-07-25 16:57:54,196 Epoch[0] Batch [1400]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.473823,	
2017-07-25 16:57:58,395 Epoch[0] Batch [1410]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.472382,	
2017-07-25 16:58:03,171 Epoch[0] Batch [1420]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.471119,	
2017-07-25 16:58:07,316 Epoch[0] Batch [1430]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.471944,	
2017-07-25 16:58:11,809 Epoch[0] Batch [1440]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.471416,	
2017-07-25 16:58:16,271 Epoch[0] Batch [1450]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.470332,	
2017-07-25 16:58:20,730 Epoch[0] Batch [1460]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.469558,	
2017-07-25 16:58:25,117 Epoch[0] Batch [1470]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.468423,	
2017-07-25 16:58:29,572 Epoch[0] Batch [1480]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.466984,	
2017-07-25 16:58:32,178 Epoch[0] Train-FCNLogLoss=0.466447
2017-07-25 16:58:32,178 Epoch[0] Time cost=649.781
2017-07-25 16:58:32,936 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.params"
2017-07-25 16:58:34,590 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0001.states"
2017-07-25 16:58:39,190 Epoch[1] Batch [10]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.292811,	
2017-07-25 16:58:43,075 Epoch[1] Batch [20]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.304296,	
2017-07-25 16:58:46,997 Epoch[1] Batch [30]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.302732,	
2017-07-25 16:58:50,941 Epoch[1] Batch [40]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.289020,	
2017-07-25 16:58:54,799 Epoch[1] Batch [50]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.284078,	
2017-07-25 16:58:58,682 Epoch[1] Batch [60]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.283253,	
2017-07-25 16:59:02,483 Epoch[1] Batch [70]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.284318,	
2017-07-25 16:59:06,326 Epoch[1] Batch [80]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.283212,	
2017-07-25 16:59:10,215 Epoch[1] Batch [90]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.285177,	
2017-07-25 16:59:14,026 Epoch[1] Batch [100]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.282508,	
2017-07-25 16:59:17,858 Epoch[1] Batch [110]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.279446,	
2017-07-25 16:59:21,745 Epoch[1] Batch [120]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.276212,	
2017-07-25 16:59:25,603 Epoch[1] Batch [130]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.273152,	
2017-07-25 16:59:29,587 Epoch[1] Batch [140]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.273057,	
2017-07-25 16:59:33,491 Epoch[1] Batch [150]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.273305,	
2017-07-25 16:59:37,308 Epoch[1] Batch [160]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.271516,	
2017-07-25 16:59:41,155 Epoch[1] Batch [170]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.271870,	
2017-07-25 16:59:45,099 Epoch[1] Batch [180]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.274662,	
2017-07-25 16:59:49,049 Epoch[1] Batch [190]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.276016,	
2017-07-25 16:59:52,958 Epoch[1] Batch [200]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.277445,	
2017-07-25 16:59:56,840 Epoch[1] Batch [210]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.278728,	
2017-07-25 17:00:00,661 Epoch[1] Batch [220]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.278900,	
2017-07-25 17:00:04,421 Epoch[1] Batch [230]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.276289,	
2017-07-25 17:00:08,257 Epoch[1] Batch [240]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.275649,	
2017-07-25 17:00:12,092 Epoch[1] Batch [250]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.276509,	
2017-07-25 17:00:15,923 Epoch[1] Batch [260]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.277309,	
2017-07-25 17:00:19,678 Epoch[1] Batch [270]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.277455,	
2017-07-25 17:00:23,563 Epoch[1] Batch [280]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.277640,	
2017-07-25 17:00:27,431 Epoch[1] Batch [290]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.276545,	
2017-07-25 17:00:31,326 Epoch[1] Batch [300]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.277877,	
2017-07-25 17:00:35,191 Epoch[1] Batch [310]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.277580,	
2017-07-25 17:00:39,051 Epoch[1] Batch [320]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.279093,	
2017-07-25 17:00:42,839 Epoch[1] Batch [330]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.278807,	
2017-07-25 17:00:46,668 Epoch[1] Batch [340]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.277602,	
2017-07-25 17:00:50,571 Epoch[1] Batch [350]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.277048,	
2017-07-25 17:00:54,395 Epoch[1] Batch [360]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.277440,	
2017-07-25 17:00:58,269 Epoch[1] Batch [370]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.276303,	
2017-07-25 17:01:02,172 Epoch[1] Batch [380]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.277286,	
2017-07-25 17:01:06,019 Epoch[1] Batch [390]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.276566,	
2017-07-25 17:01:09,870 Epoch[1] Batch [400]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.277143,	
2017-07-25 17:01:13,792 Epoch[1] Batch [410]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.278202,	
2017-07-25 17:01:17,708 Epoch[1] Batch [420]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.277945,	
2017-07-25 17:01:21,520 Epoch[1] Batch [430]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.277744,	
2017-07-25 17:01:25,436 Epoch[1] Batch [440]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.276440,	
2017-07-25 17:01:29,209 Epoch[1] Batch [450]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.275564,	
2017-07-25 17:01:33,087 Epoch[1] Batch [460]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.275507,	
2017-07-25 17:01:36,911 Epoch[1] Batch [470]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.274727,	
2017-07-25 17:01:40,793 Epoch[1] Batch [480]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.274839,	
2017-07-25 17:01:44,602 Epoch[1] Batch [490]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.274851,	
2017-07-25 17:01:48,522 Epoch[1] Batch [500]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.275386,	
2017-07-25 17:01:52,458 Epoch[1] Batch [510]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.274741,	
2017-07-25 17:01:56,366 Epoch[1] Batch [520]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.274806,	
2017-07-25 17:02:00,424 Epoch[1] Batch [530]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.274657,	
2017-07-25 17:02:04,245 Epoch[1] Batch [540]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.273949,	
2017-07-25 17:02:08,084 Epoch[1] Batch [550]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.273231,	
2017-07-25 17:02:12,013 Epoch[1] Batch [560]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.272639,	
2017-07-25 17:02:15,820 Epoch[1] Batch [570]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.272055,	
2017-07-25 17:02:19,761 Epoch[1] Batch [580]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.271858,	
2017-07-25 17:02:23,646 Epoch[1] Batch [590]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.271817,	
2017-07-25 17:02:27,448 Epoch[1] Batch [600]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.271574,	
2017-07-25 17:02:31,299 Epoch[1] Batch [610]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.271784,	
2017-07-25 17:02:35,206 Epoch[1] Batch [620]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.270917,	
2017-07-25 17:02:39,015 Epoch[1] Batch [630]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.270068,	
2017-07-25 17:02:42,904 Epoch[1] Batch [640]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.269218,	
2017-07-25 17:02:46,731 Epoch[1] Batch [650]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.269109,	
2017-07-25 17:02:50,615 Epoch[1] Batch [660]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.276953,	
2017-07-25 17:02:54,530 Epoch[1] Batch [670]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.287628,	
2017-07-25 17:02:58,420 Epoch[1] Batch [680]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.294656,	
2017-07-25 17:03:02,285 Epoch[1] Batch [690]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.296583,	
2017-07-25 17:03:06,236 Epoch[1] Batch [700]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.299831,	
2017-07-25 17:03:10,135 Epoch[1] Batch [710]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.300535,	
2017-07-25 17:03:13,948 Epoch[1] Batch [720]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.301035,	
2017-07-25 17:03:17,913 Epoch[1] Batch [730]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.301144,	
2017-07-25 17:03:21,792 Epoch[1] Batch [740]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.301631,	
2017-07-25 17:03:25,734 Epoch[1] Batch [750]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.304289,	
2017-07-25 17:03:29,634 Epoch[1] Batch [760]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.304594,	
2017-07-25 17:03:33,619 Epoch[1] Batch [770]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.304796,	
2017-07-25 17:03:37,519 Epoch[1] Batch [780]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.304913,	
2017-07-25 17:03:41,559 Epoch[1] Batch [790]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.304336,	
2017-07-25 17:03:45,411 Epoch[1] Batch [800]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.303913,	
2017-07-25 17:03:49,273 Epoch[1] Batch [810]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.303804,	
2017-07-25 17:03:53,141 Epoch[1] Batch [820]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.303646,	
2017-07-25 17:03:57,058 Epoch[1] Batch [830]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.303394,	
2017-07-25 17:04:00,953 Epoch[1] Batch [840]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.305335,	
2017-07-25 17:04:04,785 Epoch[1] Batch [850]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.306112,	
2017-07-25 17:04:08,686 Epoch[1] Batch [860]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.307355,	
2017-07-25 17:04:12,482 Epoch[1] Batch [870]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.307334,	
2017-07-25 17:04:16,370 Epoch[1] Batch [880]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.307232,	
2017-07-25 17:04:20,347 Epoch[1] Batch [890]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.308318,	
2017-07-25 17:04:24,219 Epoch[1] Batch [900]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.308162,	
2017-07-25 17:04:28,097 Epoch[1] Batch [910]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.307624,	
2017-07-25 17:04:31,983 Epoch[1] Batch [920]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.308532,	
2017-07-25 17:04:35,856 Epoch[1] Batch [930]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.308900,	
2017-07-25 17:04:39,698 Epoch[1] Batch [940]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.308761,	
2017-07-25 17:04:43,685 Epoch[1] Batch [950]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.308567,	
2017-07-25 17:04:47,529 Epoch[1] Batch [960]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.308317,	
2017-07-25 17:04:51,466 Epoch[1] Batch [970]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.308298,	
2017-07-25 17:04:55,399 Epoch[1] Batch [980]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.308355,	
2017-07-25 17:04:59,337 Epoch[1] Batch [990]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.307963,	
2017-07-25 17:05:03,161 Epoch[1] Batch [1000]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.307510,	
2017-07-25 17:05:07,108 Epoch[1] Batch [1010]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.307258,	
2017-07-25 17:05:11,028 Epoch[1] Batch [1020]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.307165,	
2017-07-25 17:05:14,912 Epoch[1] Batch [1030]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.307152,	
2017-07-25 17:05:18,795 Epoch[1] Batch [1040]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.306569,	
2017-07-25 17:05:22,599 Epoch[1] Batch [1050]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.306632,	
2017-07-25 17:05:26,460 Epoch[1] Batch [1060]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.306119,	
2017-07-25 17:05:30,327 Epoch[1] Batch [1070]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.305586,	
2017-07-25 17:05:34,160 Epoch[1] Batch [1080]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.304881,	
2017-07-25 17:05:38,071 Epoch[1] Batch [1090]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.304347,	
2017-07-25 17:05:41,952 Epoch[1] Batch [1100]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.304052,	
2017-07-25 17:05:45,812 Epoch[1] Batch [1110]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.303387,	
2017-07-25 17:05:49,757 Epoch[1] Batch [1120]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.302942,	
2017-07-25 17:05:53,654 Epoch[1] Batch [1130]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.302870,	
2017-07-25 17:05:57,516 Epoch[1] Batch [1140]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.302503,	
2017-07-25 17:06:01,378 Epoch[1] Batch [1150]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.302416,	
2017-07-25 17:06:05,168 Epoch[1] Batch [1160]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.302297,	
2017-07-25 17:06:09,135 Epoch[1] Batch [1170]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.302087,	
2017-07-25 17:06:13,011 Epoch[1] Batch [1180]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.301516,	
2017-07-25 17:06:16,845 Epoch[1] Batch [1190]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.301050,	
2017-07-25 17:06:20,814 Epoch[1] Batch [1200]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.300520,	
2017-07-25 17:06:24,748 Epoch[1] Batch [1210]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.300022,	
2017-07-25 17:06:28,715 Epoch[1] Batch [1220]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.299579,	
2017-07-25 17:06:32,948 Epoch[1] Batch [1230]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.299398,	
2017-07-25 17:06:38,743 Epoch[1] Batch [1240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.299458,	
2017-07-25 17:06:44,267 Epoch[1] Batch [1250]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.299257,	
2017-07-25 17:06:48,146 Epoch[1] Batch [1260]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.299266,	
2017-07-25 17:06:51,992 Epoch[1] Batch [1270]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.299324,	
2017-07-25 17:06:55,894 Epoch[1] Batch [1280]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.299107,	
2017-07-25 17:06:59,769 Epoch[1] Batch [1290]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.298805,	
2017-07-25 17:07:03,661 Epoch[1] Batch [1300]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.298586,	
2017-07-25 17:07:07,444 Epoch[1] Batch [1310]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.298018,	
2017-07-25 17:07:11,435 Epoch[1] Batch [1320]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.297398,	
2017-07-25 17:07:15,302 Epoch[1] Batch [1330]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.297155,	
2017-07-25 17:07:19,157 Epoch[1] Batch [1340]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.296824,	
2017-07-25 17:07:22,995 Epoch[1] Batch [1350]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.297277,	
2017-07-25 17:07:26,940 Epoch[1] Batch [1360]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.297279,	
2017-07-25 17:07:30,706 Epoch[1] Batch [1370]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.296926,	
2017-07-25 17:07:34,591 Epoch[1] Batch [1380]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.296681,	
2017-07-25 17:07:38,466 Epoch[1] Batch [1390]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.296277,	
2017-07-25 17:07:42,289 Epoch[1] Batch [1400]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.295895,	
2017-07-25 17:07:46,220 Epoch[1] Batch [1410]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.295328,	
2017-07-25 17:07:49,958 Epoch[1] Batch [1420]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.294869,	
2017-07-25 17:07:53,809 Epoch[1] Batch [1430]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.294581,	
2017-07-25 17:07:57,574 Epoch[1] Batch [1440]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.294529,	
2017-07-25 17:08:01,468 Epoch[1] Batch [1450]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.294381,	
2017-07-25 17:08:05,325 Epoch[1] Batch [1460]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.293990,	
2017-07-25 17:08:09,127 Epoch[1] Batch [1470]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.293439,	
2017-07-25 17:08:12,951 Epoch[1] Batch [1480]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.293237,	
2017-07-25 17:08:15,276 Epoch[1] Train-FCNLogLoss=0.292912
2017-07-25 17:08:15,276 Epoch[1] Time cost=580.685
2017-07-25 17:08:16,054 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.params"
2017-07-25 17:08:17,654 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0002.states"
2017-07-25 17:08:22,294 Epoch[2] Batch [10]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.225058,	
2017-07-25 17:08:26,180 Epoch[2] Batch [20]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.241246,	
2017-07-25 17:08:30,079 Epoch[2] Batch [30]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.243532,	
2017-07-25 17:08:33,903 Epoch[2] Batch [40]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.234154,	
2017-07-25 17:08:37,823 Epoch[2] Batch [50]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.232387,	
2017-07-25 17:08:41,574 Epoch[2] Batch [60]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.235789,	
2017-07-25 17:08:45,396 Epoch[2] Batch [70]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.232876,	
2017-07-25 17:08:49,204 Epoch[2] Batch [80]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.235047,	
2017-07-25 17:08:53,112 Epoch[2] Batch [90]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.241103,	
2017-07-25 17:08:56,956 Epoch[2] Batch [100]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.242574,	
2017-07-25 17:09:00,710 Epoch[2] Batch [110]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.243645,	
2017-07-25 17:09:04,595 Epoch[2] Batch [120]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.243050,	
2017-07-25 17:09:08,465 Epoch[2] Batch [130]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.243658,	
2017-07-25 17:09:12,252 Epoch[2] Batch [140]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.245679,	
2017-07-25 17:09:16,037 Epoch[2] Batch [150]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.245448,	
2017-07-25 17:09:19,832 Epoch[2] Batch [160]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.241895,	
2017-07-25 17:09:23,670 Epoch[2] Batch [170]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.242158,	
2017-07-25 17:09:27,482 Epoch[2] Batch [180]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.240973,	
2017-07-25 17:09:31,332 Epoch[2] Batch [190]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.239229,	
2017-07-25 17:09:35,200 Epoch[2] Batch [200]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.237303,	
2017-07-25 17:09:39,004 Epoch[2] Batch [210]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.237058,	
2017-07-25 17:09:42,785 Epoch[2] Batch [220]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.235561,	
2017-07-25 17:09:46,546 Epoch[2] Batch [230]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.234710,	
2017-07-25 17:09:50,318 Epoch[2] Batch [240]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.234869,	
2017-07-25 17:09:54,084 Epoch[2] Batch [250]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.234969,	
2017-07-25 17:09:57,990 Epoch[2] Batch [260]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.235571,	
2017-07-25 17:10:01,726 Epoch[2] Batch [270]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.240614,	
2017-07-25 17:10:05,515 Epoch[2] Batch [280]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.240453,	
2017-07-25 17:10:09,310 Epoch[2] Batch [290]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.240694,	
2017-07-25 17:10:13,139 Epoch[2] Batch [300]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.240488,	
2017-07-25 17:10:16,983 Epoch[2] Batch [310]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.240937,	
2017-07-25 17:10:20,818 Epoch[2] Batch [320]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.241164,	
2017-07-25 17:10:24,647 Epoch[2] Batch [330]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.240032,	
2017-07-25 17:10:28,432 Epoch[2] Batch [340]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.239676,	
2017-07-25 17:10:32,297 Epoch[2] Batch [350]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.238740,	
2017-07-25 17:10:36,078 Epoch[2] Batch [360]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.238831,	
2017-07-25 17:10:39,980 Epoch[2] Batch [370]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.239673,	
2017-07-25 17:10:43,740 Epoch[2] Batch [380]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.239522,	
2017-07-25 17:10:47,509 Epoch[2] Batch [390]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.239208,	
2017-07-25 17:10:51,402 Epoch[2] Batch [400]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.238558,	
2017-07-25 17:10:55,306 Epoch[2] Batch [410]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.238252,	
2017-07-25 17:10:59,163 Epoch[2] Batch [420]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.238707,	
2017-07-25 17:11:02,993 Epoch[2] Batch [430]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.239725,	
2017-07-25 17:11:06,811 Epoch[2] Batch [440]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.240835,	
2017-07-25 17:11:10,591 Epoch[2] Batch [450]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.240841,	
2017-07-25 17:11:14,451 Epoch[2] Batch [460]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.242078,	
2017-07-25 17:11:18,341 Epoch[2] Batch [470]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.241719,	
2017-07-25 17:11:22,166 Epoch[2] Batch [480]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.242165,	
2017-07-25 17:11:26,090 Epoch[2] Batch [490]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.242420,	
2017-07-25 17:11:29,895 Epoch[2] Batch [500]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.242576,	
2017-07-25 17:11:33,695 Epoch[2] Batch [510]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.242589,	
2017-07-25 17:11:37,485 Epoch[2] Batch [520]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.243042,	
2017-07-25 17:11:41,302 Epoch[2] Batch [530]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.242529,	
2017-07-25 17:11:45,165 Epoch[2] Batch [540]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.242365,	
2017-07-25 17:11:48,917 Epoch[2] Batch [550]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.242765,	
2017-07-25 17:11:52,701 Epoch[2] Batch [560]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.242486,	
2017-07-25 17:11:56,414 Epoch[2] Batch [570]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.242402,	
2017-07-25 17:12:00,161 Epoch[2] Batch [580]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.242233,	
2017-07-25 17:12:04,005 Epoch[2] Batch [590]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.242088,	
2017-07-25 17:12:07,849 Epoch[2] Batch [600]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.242217,	
2017-07-25 17:12:11,771 Epoch[2] Batch [610]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.241899,	
2017-07-25 17:12:15,609 Epoch[2] Batch [620]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.241489,	
2017-07-25 17:12:19,435 Epoch[2] Batch [630]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.240732,	
2017-07-25 17:12:23,250 Epoch[2] Batch [640]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.241036,	
2017-07-25 17:12:27,151 Epoch[2] Batch [650]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.240770,	
2017-07-25 17:12:31,016 Epoch[2] Batch [660]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.240841,	
2017-07-25 17:12:34,832 Epoch[2] Batch [670]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.240189,	
2017-07-25 17:12:38,687 Epoch[2] Batch [680]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.239886,	
2017-07-25 17:12:42,537 Epoch[2] Batch [690]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.239276,	
2017-07-25 17:12:46,449 Epoch[2] Batch [700]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.238665,	
2017-07-25 17:12:50,293 Epoch[2] Batch [710]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.238510,	
2017-07-25 17:12:54,086 Epoch[2] Batch [720]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.238533,	
2017-07-25 17:12:57,941 Epoch[2] Batch [730]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.238468,	
2017-07-25 17:13:01,812 Epoch[2] Batch [740]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.238133,	
2017-07-25 17:13:05,704 Epoch[2] Batch [750]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.238042,	
2017-07-25 17:13:09,534 Epoch[2] Batch [760]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.237702,	
2017-07-25 17:13:13,419 Epoch[2] Batch [770]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.237489,	
2017-07-25 17:13:17,163 Epoch[2] Batch [780]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.237275,	
2017-07-25 17:13:21,025 Epoch[2] Batch [790]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.237463,	
2017-07-25 17:13:24,920 Epoch[2] Batch [800]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.238163,	
2017-07-25 17:13:28,810 Epoch[2] Batch [810]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.239484,	
2017-07-25 17:13:32,613 Epoch[2] Batch [820]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.239389,	
2017-07-25 17:13:36,469 Epoch[2] Batch [830]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.239440,	
2017-07-25 17:13:40,304 Epoch[2] Batch [840]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.239193,	
2017-07-25 17:13:44,121 Epoch[2] Batch [850]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.238705,	
2017-07-25 17:13:47,925 Epoch[2] Batch [860]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.238728,	
2017-07-25 17:13:51,797 Epoch[2] Batch [870]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.238007,	
2017-07-25 17:13:55,644 Epoch[2] Batch [880]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.238230,	
2017-07-25 17:13:59,471 Epoch[2] Batch [890]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.238246,	
2017-07-25 17:14:03,353 Epoch[2] Batch [900]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.238118,	
2017-07-25 17:14:07,210 Epoch[2] Batch [910]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.237685,	
2017-07-25 17:14:11,052 Epoch[2] Batch [920]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.237310,	
2017-07-25 17:14:14,980 Epoch[2] Batch [930]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.237258,	
2017-07-25 17:14:18,748 Epoch[2] Batch [940]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.236974,	
2017-07-25 17:14:22,646 Epoch[2] Batch [950]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.236810,	
2017-07-25 17:14:26,553 Epoch[2] Batch [960]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.236890,	
2017-07-25 17:14:30,358 Epoch[2] Batch [970]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.236386,	
2017-07-25 17:14:34,230 Epoch[2] Batch [980]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.236133,	
2017-07-25 17:14:38,091 Epoch[2] Batch [990]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.235817,	
2017-07-25 17:14:41,973 Epoch[2] Batch [1000]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.235537,	
2017-07-25 17:14:45,739 Epoch[2] Batch [1010]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.235760,	
2017-07-25 17:14:49,545 Epoch[2] Batch [1020]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.235654,	
2017-07-25 17:14:53,409 Epoch[2] Batch [1030]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.235489,	
2017-07-25 17:14:57,311 Epoch[2] Batch [1040]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.235257,	
2017-07-25 17:15:01,138 Epoch[2] Batch [1050]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.234707,	
2017-07-25 17:15:04,973 Epoch[2] Batch [1060]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.234624,	
2017-07-25 17:15:08,822 Epoch[2] Batch [1070]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.234652,	
2017-07-25 17:15:12,701 Epoch[2] Batch [1080]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.234640,	
2017-07-25 17:15:16,612 Epoch[2] Batch [1090]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.234589,	
2017-07-25 17:15:20,408 Epoch[2] Batch [1100]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.234552,	
2017-07-25 17:15:24,332 Epoch[2] Batch [1110]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.234280,	
2017-07-25 17:15:28,141 Epoch[2] Batch [1120]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.234778,	
2017-07-25 17:15:32,060 Epoch[2] Batch [1130]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.234831,	
2017-07-25 17:15:35,923 Epoch[2] Batch [1140]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.234596,	
2017-07-25 17:15:39,769 Epoch[2] Batch [1150]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.234640,	
2017-07-25 17:15:43,604 Epoch[2] Batch [1160]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.234494,	
2017-07-25 17:15:47,484 Epoch[2] Batch [1170]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.234309,	
2017-07-25 17:15:51,368 Epoch[2] Batch [1180]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.234154,	
2017-07-25 17:15:55,232 Epoch[2] Batch [1190]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.234044,	
2017-07-25 17:15:59,079 Epoch[2] Batch [1200]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.233680,	
2017-07-25 17:16:02,945 Epoch[2] Batch [1210]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.233465,	
2017-07-25 17:16:06,878 Epoch[2] Batch [1220]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.233406,	
2017-07-25 17:16:10,732 Epoch[2] Batch [1230]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.233233,	
2017-07-25 17:16:14,672 Epoch[2] Batch [1240]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.233221,	
2017-07-25 17:16:18,460 Epoch[2] Batch [1250]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.233095,	
2017-07-25 17:16:22,238 Epoch[2] Batch [1260]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.233037,	
2017-07-25 17:16:26,017 Epoch[2] Batch [1270]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.232608,	
2017-07-25 17:16:29,859 Epoch[2] Batch [1280]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.232783,	
2017-07-25 17:16:33,739 Epoch[2] Batch [1290]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.232774,	
2017-07-25 17:16:37,572 Epoch[2] Batch [1300]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.232587,	
2017-07-25 17:16:41,426 Epoch[2] Batch [1310]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.233024,	
2017-07-25 17:16:45,246 Epoch[2] Batch [1320]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.233118,	
2017-07-25 17:16:49,077 Epoch[2] Batch [1330]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.232952,	
2017-07-25 17:16:52,894 Epoch[2] Batch [1340]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.232955,	
2017-07-25 17:16:56,665 Epoch[2] Batch [1350]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.233237,	
2017-07-25 17:17:00,458 Epoch[2] Batch [1360]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.233086,	
2017-07-25 17:17:04,361 Epoch[2] Batch [1370]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.233058,	
2017-07-25 17:17:08,196 Epoch[2] Batch [1380]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.233272,	
2017-07-25 17:17:12,141 Epoch[2] Batch [1390]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.233056,	
2017-07-25 17:17:16,014 Epoch[2] Batch [1400]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.232861,	
2017-07-25 17:17:19,792 Epoch[2] Batch [1410]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.232534,	
2017-07-25 17:17:23,663 Epoch[2] Batch [1420]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.232136,	
2017-07-25 17:17:27,551 Epoch[2] Batch [1430]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.232171,	
2017-07-25 17:17:31,279 Epoch[2] Batch [1440]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.232767,	
2017-07-25 17:17:35,141 Epoch[2] Batch [1450]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.232874,	
2017-07-25 17:17:38,960 Epoch[2] Batch [1460]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.232723,	
2017-07-25 17:17:42,827 Epoch[2] Batch [1470]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.233144,	
2017-07-25 17:17:46,730 Epoch[2] Batch [1480]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.233316,	
2017-07-25 17:17:48,957 Epoch[2] Train-FCNLogLoss=0.233394
2017-07-25 17:17:48,957 Epoch[2] Time cost=571.302
2017-07-25 17:17:49,683 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.params"
2017-07-25 17:17:51,352 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0003.states"
2017-07-25 17:17:55,885 Epoch[3] Batch [10]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.258488,	
2017-07-25 17:17:59,772 Epoch[3] Batch [20]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.237550,	
2017-07-25 17:18:03,607 Epoch[3] Batch [30]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.235473,	
2017-07-25 17:18:07,485 Epoch[3] Batch [40]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.239872,	
2017-07-25 17:18:11,338 Epoch[3] Batch [50]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.239154,	
2017-07-25 17:18:15,196 Epoch[3] Batch [60]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.247029,	
2017-07-25 17:18:18,990 Epoch[3] Batch [70]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.242157,	
2017-07-25 17:18:22,777 Epoch[3] Batch [80]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.239183,	
2017-07-25 17:18:26,546 Epoch[3] Batch [90]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.240590,	
2017-07-25 17:18:30,371 Epoch[3] Batch [100]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.236687,	
2017-07-25 17:18:34,148 Epoch[3] Batch [110]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.235044,	
2017-07-25 17:18:37,969 Epoch[3] Batch [120]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.244236,	
2017-07-25 17:18:41,824 Epoch[3] Batch [130]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.257848,	
2017-07-25 17:18:45,630 Epoch[3] Batch [140]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.267281,	
2017-07-25 17:18:49,538 Epoch[3] Batch [150]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.270953,	
2017-07-25 17:18:53,344 Epoch[3] Batch [160]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.271503,	
2017-07-25 17:18:57,230 Epoch[3] Batch [170]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.269809,	
2017-07-25 17:19:01,100 Epoch[3] Batch [180]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.268081,	
2017-07-25 17:19:05,008 Epoch[3] Batch [190]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.264531,	
2017-07-25 17:19:08,826 Epoch[3] Batch [200]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.262494,	
2017-07-25 17:19:12,725 Epoch[3] Batch [210]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.261229,	
2017-07-25 17:19:16,566 Epoch[3] Batch [220]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.260246,	
2017-07-25 17:19:20,421 Epoch[3] Batch [230]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.258162,	
2017-07-25 17:19:24,301 Epoch[3] Batch [240]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.256435,	
2017-07-25 17:19:28,051 Epoch[3] Batch [250]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.254562,	
2017-07-25 17:19:31,907 Epoch[3] Batch [260]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.253864,	
2017-07-25 17:19:35,784 Epoch[3] Batch [270]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.253244,	
2017-07-25 17:19:39,610 Epoch[3] Batch [280]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.253528,	
2017-07-25 17:19:43,558 Epoch[3] Batch [290]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.252543,	
2017-07-25 17:19:47,386 Epoch[3] Batch [300]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.252853,	
2017-07-25 17:19:51,238 Epoch[3] Batch [310]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.251387,	
2017-07-25 17:19:55,269 Epoch[3] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.252210,	
2017-07-25 17:19:59,212 Epoch[3] Batch [330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.252332,	
2017-07-25 17:20:03,052 Epoch[3] Batch [340]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.251025,	
2017-07-25 17:20:06,889 Epoch[3] Batch [350]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.250081,	
2017-07-25 17:20:10,873 Epoch[3] Batch [360]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.249948,	
2017-07-25 17:20:14,677 Epoch[3] Batch [370]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.249230,	
2017-07-25 17:20:18,554 Epoch[3] Batch [380]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.248425,	
2017-07-25 17:20:22,428 Epoch[3] Batch [390]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.247911,	
2017-07-25 17:20:26,393 Epoch[3] Batch [400]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.247379,	
2017-07-25 17:20:30,238 Epoch[3] Batch [410]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.247072,	
2017-07-25 17:20:34,105 Epoch[3] Batch [420]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.245965,	
2017-07-25 17:20:38,002 Epoch[3] Batch [430]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.245364,	
2017-07-25 17:20:41,955 Epoch[3] Batch [440]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.243725,	
2017-07-25 17:20:45,730 Epoch[3] Batch [450]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.243813,	
2017-07-25 17:20:49,555 Epoch[3] Batch [460]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.242912,	
2017-07-25 17:20:53,464 Epoch[3] Batch [470]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.242509,	
2017-07-25 17:20:57,258 Epoch[3] Batch [480]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.242078,	
2017-07-25 17:21:01,139 Epoch[3] Batch [490]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.241748,	
2017-07-25 17:21:05,053 Epoch[3] Batch [500]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.241595,	
2017-07-25 17:21:08,958 Epoch[3] Batch [510]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.240888,	
2017-07-25 17:21:12,816 Epoch[3] Batch [520]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.240556,	
2017-07-25 17:21:16,677 Epoch[3] Batch [530]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.240698,	
2017-07-25 17:21:20,525 Epoch[3] Batch [540]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.239863,	
2017-07-25 17:21:24,364 Epoch[3] Batch [550]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.240126,	
2017-07-25 17:21:28,226 Epoch[3] Batch [560]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.239497,	
2017-07-25 17:21:32,028 Epoch[3] Batch [570]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.238562,	
2017-07-25 17:21:35,879 Epoch[3] Batch [580]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.237790,	
2017-07-25 17:21:39,680 Epoch[3] Batch [590]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.237452,	
2017-07-25 17:21:43,528 Epoch[3] Batch [600]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.237509,	
2017-07-25 17:21:47,441 Epoch[3] Batch [610]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.237263,	
2017-07-25 17:21:51,321 Epoch[3] Batch [620]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.236771,	
2017-07-25 17:21:55,172 Epoch[3] Batch [630]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.236913,	
2017-07-25 17:21:58,975 Epoch[3] Batch [640]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.236682,	
2017-07-25 17:22:02,786 Epoch[3] Batch [650]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.236410,	
2017-07-25 17:22:06,581 Epoch[3] Batch [660]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.235685,	
2017-07-25 17:22:10,463 Epoch[3] Batch [670]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.235164,	
2017-07-25 17:22:14,225 Epoch[3] Batch [680]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.235347,	
2017-07-25 17:22:18,030 Epoch[3] Batch [690]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.235235,	
2017-07-25 17:22:21,943 Epoch[3] Batch [700]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.235083,	
2017-07-25 17:22:25,737 Epoch[3] Batch [710]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.234790,	
2017-07-25 17:22:29,606 Epoch[3] Batch [720]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.235267,	
2017-07-25 17:22:33,481 Epoch[3] Batch [730]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.234732,	
2017-07-25 17:22:37,296 Epoch[3] Batch [740]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.234482,	
2017-07-25 17:22:41,170 Epoch[3] Batch [750]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.234472,	
2017-07-25 17:22:45,123 Epoch[3] Batch [760]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.234273,	
2017-07-25 17:22:49,004 Epoch[3] Batch [770]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.234271,	
2017-07-25 17:22:52,938 Epoch[3] Batch [780]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.234970,	
2017-07-25 17:22:56,807 Epoch[3] Batch [790]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.234368,	
2017-07-25 17:23:00,781 Epoch[3] Batch [800]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.233915,	
2017-07-25 17:23:04,595 Epoch[3] Batch [810]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.233419,	
2017-07-25 17:23:08,413 Epoch[3] Batch [820]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.233321,	
2017-07-25 17:23:12,486 Epoch[3] Batch [830]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.232804,	
2017-07-25 17:23:16,386 Epoch[3] Batch [840]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.232395,	
2017-07-25 17:23:20,289 Epoch[3] Batch [850]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.231948,	
2017-07-25 17:23:24,204 Epoch[3] Batch [860]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.231433,	
2017-07-25 17:23:28,202 Epoch[3] Batch [870]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.230768,	
2017-07-25 17:23:32,058 Epoch[3] Batch [880]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.230947,	
2017-07-25 17:23:35,981 Epoch[3] Batch [890]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.230913,	
2017-07-25 17:23:39,808 Epoch[3] Batch [900]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.230788,	
2017-07-25 17:23:43,753 Epoch[3] Batch [910]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.231000,	
2017-07-25 17:23:47,721 Epoch[3] Batch [920]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.230909,	
2017-07-25 17:23:51,575 Epoch[3] Batch [930]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.230576,	
2017-07-25 17:23:55,397 Epoch[3] Batch [940]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.230311,	
2017-07-25 17:23:59,307 Epoch[3] Batch [950]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.230421,	
2017-07-25 17:24:03,195 Epoch[3] Batch [960]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.230481,	
2017-07-25 17:24:07,129 Epoch[3] Batch [970]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.230023,	
2017-07-25 17:24:11,105 Epoch[3] Batch [980]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.229780,	
2017-07-25 17:24:15,017 Epoch[3] Batch [990]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.229374,	
2017-07-25 17:24:18,923 Epoch[3] Batch [1000]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.228950,	
2017-07-25 17:24:22,716 Epoch[3] Batch [1010]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.228905,	
2017-07-25 17:24:26,546 Epoch[3] Batch [1020]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.228348,	
2017-07-25 17:24:30,450 Epoch[3] Batch [1030]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.228102,	
2017-07-25 17:24:34,292 Epoch[3] Batch [1040]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.228137,	
2017-07-25 17:24:38,174 Epoch[3] Batch [1050]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.227926,	
2017-07-25 17:24:41,985 Epoch[3] Batch [1060]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.227762,	
2017-07-25 17:24:45,803 Epoch[3] Batch [1070]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.228001,	
2017-07-25 17:24:49,633 Epoch[3] Batch [1080]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.227522,	
2017-07-25 17:24:53,533 Epoch[3] Batch [1090]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.227518,	
2017-07-25 17:24:57,357 Epoch[3] Batch [1100]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.227238,	
2017-07-25 17:25:01,159 Epoch[3] Batch [1110]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.227266,	
2017-07-25 17:25:05,041 Epoch[3] Batch [1120]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.226917,	
2017-07-25 17:25:09,071 Epoch[3] Batch [1130]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.226779,	
2017-07-25 17:25:12,940 Epoch[3] Batch [1140]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.226646,	
2017-07-25 17:25:16,719 Epoch[3] Batch [1150]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.226623,	
2017-07-25 17:25:20,614 Epoch[3] Batch [1160]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.226600,	
2017-07-25 17:25:24,407 Epoch[3] Batch [1170]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.226652,	
2017-07-25 17:25:28,266 Epoch[3] Batch [1180]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.226378,	
2017-07-25 17:25:32,126 Epoch[3] Batch [1190]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.226522,	
2017-07-25 17:25:36,018 Epoch[3] Batch [1200]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.226627,	
2017-07-25 17:25:39,928 Epoch[3] Batch [1210]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.226571,	
2017-07-25 17:25:43,804 Epoch[3] Batch [1220]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.226539,	
2017-07-25 17:25:47,760 Epoch[3] Batch [1230]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.226718,	
2017-07-25 17:25:51,563 Epoch[3] Batch [1240]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.226459,	
2017-07-25 17:25:55,508 Epoch[3] Batch [1250]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.226212,	
2017-07-25 17:25:59,406 Epoch[3] Batch [1260]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.226134,	
2017-07-25 17:26:03,286 Epoch[3] Batch [1270]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.225941,	
2017-07-25 17:26:07,213 Epoch[3] Batch [1280]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.225634,	
2017-07-25 17:26:11,242 Epoch[3] Batch [1290]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.225315,	
2017-07-25 17:26:15,066 Epoch[3] Batch [1300]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.225254,	
2017-07-25 17:26:18,925 Epoch[3] Batch [1310]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.224997,	
2017-07-25 17:26:22,840 Epoch[3] Batch [1320]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.224716,	
2017-07-25 17:26:26,790 Epoch[3] Batch [1330]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.224602,	
2017-07-25 17:26:30,798 Epoch[3] Batch [1340]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.224308,	
2017-07-25 17:26:34,768 Epoch[3] Batch [1350]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.224025,	
2017-07-25 17:26:38,687 Epoch[3] Batch [1360]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.223889,	
2017-07-25 17:26:42,585 Epoch[3] Batch [1370]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.223761,	
2017-07-25 17:26:46,579 Epoch[3] Batch [1380]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.223617,	
2017-07-25 17:26:50,509 Epoch[3] Batch [1390]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.223427,	
2017-07-25 17:26:54,380 Epoch[3] Batch [1400]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.223134,	
2017-07-25 17:26:58,233 Epoch[3] Batch [1410]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.223196,	
2017-07-25 17:27:02,101 Epoch[3] Batch [1420]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.223112,	
2017-07-25 17:27:05,978 Epoch[3] Batch [1430]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.222839,	
2017-07-25 17:27:09,922 Epoch[3] Batch [1440]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.222516,	
2017-07-25 17:27:13,753 Epoch[3] Batch [1450]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.222288,	
2017-07-25 17:27:17,572 Epoch[3] Batch [1460]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.222025,	
2017-07-25 17:27:21,404 Epoch[3] Batch [1470]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.221803,	
2017-07-25 17:27:25,296 Epoch[3] Batch [1480]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.221552,	
2017-07-25 17:27:27,640 Epoch[3] Train-FCNLogLoss=0.221349
2017-07-25 17:27:27,641 Epoch[3] Time cost=576.288
2017-07-25 17:27:28,358 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.params"
2017-07-25 17:27:30,100 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0004.states"
2017-07-25 17:27:34,789 Epoch[4] Batch [10]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.202201,	
2017-07-25 17:27:38,747 Epoch[4] Batch [20]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.222307,	
2017-07-25 17:27:42,622 Epoch[4] Batch [30]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.210133,	
2017-07-25 17:27:46,475 Epoch[4] Batch [40]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.214423,	
2017-07-25 17:27:50,419 Epoch[4] Batch [50]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.212620,	
2017-07-25 17:27:54,355 Epoch[4] Batch [60]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.212894,	
2017-07-25 17:27:58,201 Epoch[4] Batch [70]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.211531,	
2017-07-25 17:28:02,158 Epoch[4] Batch [80]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.210063,	
2017-07-25 17:28:05,934 Epoch[4] Batch [90]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.207287,	
2017-07-25 17:28:09,882 Epoch[4] Batch [100]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.207483,	
2017-07-25 17:28:13,744 Epoch[4] Batch [110]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.206171,	
2017-07-25 17:28:17,665 Epoch[4] Batch [120]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.203899,	
2017-07-25 17:28:21,527 Epoch[4] Batch [130]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.204586,	
2017-07-25 17:28:25,337 Epoch[4] Batch [140]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.206237,	
2017-07-25 17:28:29,215 Epoch[4] Batch [150]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.204239,	
2017-07-25 17:28:33,174 Epoch[4] Batch [160]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.202818,	
2017-07-25 17:28:37,056 Epoch[4] Batch [170]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.203271,	
2017-07-25 17:28:41,037 Epoch[4] Batch [180]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.203685,	
2017-07-25 17:28:44,933 Epoch[4] Batch [190]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.204158,	
2017-07-25 17:28:48,892 Epoch[4] Batch [200]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.203750,	
2017-07-25 17:28:52,872 Epoch[4] Batch [210]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.204135,	
2017-07-25 17:28:56,720 Epoch[4] Batch [220]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.203787,	
2017-07-25 17:29:00,630 Epoch[4] Batch [230]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.202702,	
2017-07-25 17:29:04,584 Epoch[4] Batch [240]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.202525,	
2017-07-25 17:29:08,464 Epoch[4] Batch [250]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.202429,	
2017-07-25 17:29:12,376 Epoch[4] Batch [260]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.203049,	
2017-07-25 17:29:16,229 Epoch[4] Batch [270]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.203681,	
2017-07-25 17:29:20,044 Epoch[4] Batch [280]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.203225,	
2017-07-25 17:29:23,909 Epoch[4] Batch [290]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.203921,	
2017-07-25 17:29:27,773 Epoch[4] Batch [300]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.202919,	
2017-07-25 17:29:31,672 Epoch[4] Batch [310]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.202721,	
2017-07-25 17:29:35,490 Epoch[4] Batch [320]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.203869,	
2017-07-25 17:29:39,411 Epoch[4] Batch [330]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.203642,	
2017-07-25 17:29:43,272 Epoch[4] Batch [340]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.203945,	
2017-07-25 17:29:47,184 Epoch[4] Batch [350]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.203941,	
2017-07-25 17:29:51,145 Epoch[4] Batch [360]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.203571,	
2017-07-25 17:29:55,149 Epoch[4] Batch [370]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.203617,	
2017-07-25 17:29:59,065 Epoch[4] Batch [380]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.203146,	
2017-07-25 17:30:02,946 Epoch[4] Batch [390]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.202669,	
2017-07-25 17:30:06,872 Epoch[4] Batch [400]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.203084,	
2017-07-25 17:30:10,831 Epoch[4] Batch [410]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.202850,	
2017-07-25 17:30:14,663 Epoch[4] Batch [420]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.204052,	
2017-07-25 17:30:18,699 Epoch[4] Batch [430]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.203373,	
2017-07-25 17:30:22,634 Epoch[4] Batch [440]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.203085,	
2017-07-25 17:30:26,725 Epoch[4] Batch [450]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.203559,	
2017-07-25 17:30:30,646 Epoch[4] Batch [460]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.203404,	
2017-07-25 17:30:34,540 Epoch[4] Batch [470]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.203164,	
2017-07-25 17:30:38,368 Epoch[4] Batch [480]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.202925,	
2017-07-25 17:30:42,374 Epoch[4] Batch [490]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.204084,	
2017-07-25 17:30:46,248 Epoch[4] Batch [500]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.204748,	
2017-07-25 17:30:50,168 Epoch[4] Batch [510]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.204250,	
2017-07-25 17:30:53,943 Epoch[4] Batch [520]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.205087,	
2017-07-25 17:30:57,839 Epoch[4] Batch [530]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.205185,	
2017-07-25 17:31:01,682 Epoch[4] Batch [540]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.204425,	
2017-07-25 17:31:05,596 Epoch[4] Batch [550]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.204814,	
2017-07-25 17:31:09,483 Epoch[4] Batch [560]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.204524,	
2017-07-25 17:31:13,371 Epoch[4] Batch [570]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.204391,	
2017-07-25 17:31:17,244 Epoch[4] Batch [580]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.204437,	
2017-07-25 17:31:21,098 Epoch[4] Batch [590]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.204944,	
2017-07-25 17:31:24,980 Epoch[4] Batch [600]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.204531,	
2017-07-25 17:31:28,872 Epoch[4] Batch [610]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.204789,	
2017-07-25 17:31:32,862 Epoch[4] Batch [620]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.204600,	
2017-07-25 17:31:36,776 Epoch[4] Batch [630]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.204880,	
2017-07-25 17:31:40,598 Epoch[4] Batch [640]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.204397,	
2017-07-25 17:31:44,446 Epoch[4] Batch [650]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.204031,	
2017-07-25 17:31:48,300 Epoch[4] Batch [660]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.203510,	
2017-07-25 17:31:52,131 Epoch[4] Batch [670]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.203564,	
2017-07-25 17:31:56,062 Epoch[4] Batch [680]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.202925,	
2017-07-25 17:31:59,892 Epoch[4] Batch [690]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.202840,	
2017-07-25 17:32:03,780 Epoch[4] Batch [700]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.202569,	
2017-07-25 17:32:07,648 Epoch[4] Batch [710]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.202104,	
2017-07-25 17:32:11,534 Epoch[4] Batch [720]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.202151,	
2017-07-25 17:32:15,453 Epoch[4] Batch [730]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.202409,	
2017-07-25 17:32:19,405 Epoch[4] Batch [740]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.202303,	
2017-07-25 17:32:23,338 Epoch[4] Batch [750]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.201929,	
2017-07-25 17:32:27,204 Epoch[4] Batch [760]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.201784,	
2017-07-25 17:32:31,141 Epoch[4] Batch [770]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.201671,	
2017-07-25 17:32:34,977 Epoch[4] Batch [780]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.201599,	
2017-07-25 17:32:38,910 Epoch[4] Batch [790]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.201338,	
2017-07-25 17:32:42,744 Epoch[4] Batch [800]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.200890,	
2017-07-25 17:32:46,668 Epoch[4] Batch [810]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.200727,	
2017-07-25 17:32:50,620 Epoch[4] Batch [820]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.200649,	
2017-07-25 17:32:54,516 Epoch[4] Batch [830]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.201038,	
2017-07-25 17:32:58,465 Epoch[4] Batch [840]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.200985,	
2017-07-25 17:33:02,379 Epoch[4] Batch [850]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.201793,	
2017-07-25 17:33:06,303 Epoch[4] Batch [860]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.202348,	
2017-07-25 17:33:10,207 Epoch[4] Batch [870]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.202924,	
2017-07-25 17:33:14,113 Epoch[4] Batch [880]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.203429,	
2017-07-25 17:33:18,001 Epoch[4] Batch [890]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.203790,	
2017-07-25 17:33:21,854 Epoch[4] Batch [900]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.204553,	
2017-07-25 17:33:25,703 Epoch[4] Batch [910]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.204846,	
2017-07-25 17:33:29,519 Epoch[4] Batch [920]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.205106,	
2017-07-25 17:33:33,412 Epoch[4] Batch [930]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.205343,	
2017-07-25 17:33:37,241 Epoch[4] Batch [940]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.205171,	
2017-07-25 17:33:41,128 Epoch[4] Batch [950]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.205083,	
2017-07-25 17:33:45,013 Epoch[4] Batch [960]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.205154,	
2017-07-25 17:33:48,893 Epoch[4] Batch [970]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.205469,	
2017-07-25 17:33:52,744 Epoch[4] Batch [980]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.205479,	
2017-07-25 17:33:56,685 Epoch[4] Batch [990]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.205256,	
2017-07-25 17:34:00,900 Epoch[4] Batch [1000]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.205060,	
2017-07-25 17:34:05,288 Epoch[4] Batch [1010]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.204705,	
2017-07-25 17:34:09,608 Epoch[4] Batch [1020]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.204508,	
2017-07-25 17:34:13,777 Epoch[4] Batch [1030]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.204237,	
2017-07-25 17:34:17,677 Epoch[4] Batch [1040]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.203891,	
2017-07-25 17:34:21,564 Epoch[4] Batch [1050]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.203619,	
2017-07-25 17:34:25,477 Epoch[4] Batch [1060]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.203761,	
2017-07-25 17:34:29,467 Epoch[4] Batch [1070]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.203610,	
2017-07-25 17:34:33,336 Epoch[4] Batch [1080]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.203852,	
2017-07-25 17:34:37,267 Epoch[4] Batch [1090]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.203574,	
2017-07-25 17:34:41,213 Epoch[4] Batch [1100]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.203596,	
2017-07-25 17:34:45,041 Epoch[4] Batch [1110]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.203782,	
2017-07-25 17:34:48,995 Epoch[4] Batch [1120]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.203636,	
2017-07-25 17:34:52,779 Epoch[4] Batch [1130]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.203451,	
2017-07-25 17:34:56,671 Epoch[4] Batch [1140]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.203342,	
2017-07-25 17:35:00,563 Epoch[4] Batch [1150]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.203004,	
2017-07-25 17:35:04,437 Epoch[4] Batch [1160]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.202850,	
2017-07-25 17:35:08,276 Epoch[4] Batch [1170]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.202582,	
2017-07-25 17:35:12,137 Epoch[4] Batch [1180]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.203096,	
2017-07-25 17:35:15,894 Epoch[4] Batch [1190]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.203298,	
2017-07-25 17:35:19,829 Epoch[4] Batch [1200]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.203291,	
2017-07-25 17:35:23,780 Epoch[4] Batch [1210]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.203221,	
2017-07-25 17:35:27,723 Epoch[4] Batch [1220]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.203025,	
2017-07-25 17:35:31,531 Epoch[4] Batch [1230]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.202899,	
2017-07-25 17:35:35,474 Epoch[4] Batch [1240]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.202641,	
2017-07-25 17:35:39,315 Epoch[4] Batch [1250]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.202432,	
2017-07-25 17:35:43,244 Epoch[4] Batch [1260]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.202280,	
2017-07-25 17:35:47,146 Epoch[4] Batch [1270]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.202320,	
2017-07-25 17:35:51,019 Epoch[4] Batch [1280]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.202465,	
2017-07-25 17:35:54,878 Epoch[4] Batch [1290]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.202703,	
2017-07-25 17:35:58,838 Epoch[4] Batch [1300]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.202417,	
2017-07-25 17:36:02,725 Epoch[4] Batch [1310]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.202412,	
2017-07-25 17:36:06,565 Epoch[4] Batch [1320]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.202248,	
2017-07-25 17:36:10,481 Epoch[4] Batch [1330]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.202039,	
2017-07-25 17:36:14,452 Epoch[4] Batch [1340]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.202053,	
2017-07-25 17:36:18,318 Epoch[4] Batch [1350]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.202093,	
2017-07-25 17:36:22,253 Epoch[4] Batch [1360]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.202030,	
2017-07-25 17:36:26,115 Epoch[4] Batch [1370]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.201871,	
2017-07-25 17:36:30,177 Epoch[4] Batch [1380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.201866,	
2017-07-25 17:36:34,123 Epoch[4] Batch [1390]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.202019,	
2017-07-25 17:36:38,067 Epoch[4] Batch [1400]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.201838,	
2017-07-25 17:36:41,969 Epoch[4] Batch [1410]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.201693,	
2017-07-25 17:36:45,815 Epoch[4] Batch [1420]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.201684,	
2017-07-25 17:36:49,617 Epoch[4] Batch [1430]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.201558,	
2017-07-25 17:36:53,500 Epoch[4] Batch [1440]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.201637,	
2017-07-25 17:36:57,392 Epoch[4] Batch [1450]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.201584,	
2017-07-25 17:37:01,236 Epoch[4] Batch [1460]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.201540,	
2017-07-25 17:37:05,180 Epoch[4] Batch [1470]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.201437,	
2017-07-25 17:37:08,981 Epoch[4] Batch [1480]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.201373,	
2017-07-25 17:37:11,278 Epoch[4] Train-FCNLogLoss=0.201396
2017-07-25 17:37:11,279 Epoch[4] Time cost=581.178
2017-07-25 17:37:12,016 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.params"
2017-07-25 17:37:13,673 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0005.states"
2017-07-25 17:37:18,300 Epoch[5] Batch [10]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.173144,	
2017-07-25 17:37:22,151 Epoch[5] Batch [20]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.170528,	
2017-07-25 17:37:25,970 Epoch[5] Batch [30]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.183548,	
2017-07-25 17:37:29,849 Epoch[5] Batch [40]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.198115,	
2017-07-25 17:37:33,786 Epoch[5] Batch [50]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.211747,	
2017-07-25 17:37:37,698 Epoch[5] Batch [60]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.219221,	
2017-07-25 17:37:41,528 Epoch[5] Batch [70]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.217892,	
2017-07-25 17:37:45,343 Epoch[5] Batch [80]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.217834,	
2017-07-25 17:37:49,271 Epoch[5] Batch [90]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.215562,	
2017-07-25 17:37:53,066 Epoch[5] Batch [100]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.210995,	
2017-07-25 17:37:57,023 Epoch[5] Batch [110]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.213267,	
2017-07-25 17:38:00,869 Epoch[5] Batch [120]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.209040,	
2017-07-25 17:38:04,845 Epoch[5] Batch [130]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.207477,	
2017-07-25 17:38:08,621 Epoch[5] Batch [140]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.205163,	
2017-07-25 17:38:12,585 Epoch[5] Batch [150]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.203168,	
2017-07-25 17:38:16,392 Epoch[5] Batch [160]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.201904,	
2017-07-25 17:38:20,431 Epoch[5] Batch [170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.203177,	
2017-07-25 17:38:24,374 Epoch[5] Batch [180]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.203494,	
2017-07-25 17:38:28,323 Epoch[5] Batch [190]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.202980,	
2017-07-25 17:38:32,041 Epoch[5] Batch [200]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.202430,	
2017-07-25 17:38:35,897 Epoch[5] Batch [210]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.202116,	
2017-07-25 17:38:39,745 Epoch[5] Batch [220]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.200444,	
2017-07-25 17:38:43,581 Epoch[5] Batch [230]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.198618,	
2017-07-25 17:38:47,488 Epoch[5] Batch [240]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.199975,	
2017-07-25 17:38:51,427 Epoch[5] Batch [250]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.200482,	
2017-07-25 17:38:55,375 Epoch[5] Batch [260]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.202378,	
2017-07-25 17:38:59,324 Epoch[5] Batch [270]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.203085,	
2017-07-25 17:39:03,276 Epoch[5] Batch [280]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.202521,	
2017-07-25 17:39:07,176 Epoch[5] Batch [290]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.202888,	
2017-07-25 17:39:11,095 Epoch[5] Batch [300]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.202335,	
2017-07-25 17:39:15,011 Epoch[5] Batch [310]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.203085,	
2017-07-25 17:39:18,940 Epoch[5] Batch [320]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.202717,	
2017-07-25 17:39:22,880 Epoch[5] Batch [330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.202289,	
2017-07-25 17:39:26,780 Epoch[5] Batch [340]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.201769,	
2017-07-25 17:39:30,692 Epoch[5] Batch [350]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.202043,	
2017-07-25 17:39:34,549 Epoch[5] Batch [360]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.201346,	
2017-07-25 17:39:38,414 Epoch[5] Batch [370]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.200854,	
2017-07-25 17:39:42,372 Epoch[5] Batch [380]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.200247,	
2017-07-25 17:39:46,328 Epoch[5] Batch [390]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.199825,	
2017-07-25 17:39:50,175 Epoch[5] Batch [400]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.199420,	
2017-07-25 17:39:54,087 Epoch[5] Batch [410]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.199659,	
2017-07-25 17:39:57,978 Epoch[5] Batch [420]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.199960,	
2017-07-25 17:40:01,931 Epoch[5] Batch [430]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.199359,	
2017-07-25 17:40:05,797 Epoch[5] Batch [440]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.199533,	
2017-07-25 17:40:09,651 Epoch[5] Batch [450]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.199440,	
2017-07-25 17:40:13,514 Epoch[5] Batch [460]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.200355,	
2017-07-25 17:40:17,433 Epoch[5] Batch [470]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.199779,	
2017-07-25 17:40:21,340 Epoch[5] Batch [480]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.199830,	
2017-07-25 17:40:25,208 Epoch[5] Batch [490]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.199508,	
2017-07-25 17:40:29,062 Epoch[5] Batch [500]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.199097,	
2017-07-25 17:40:32,911 Epoch[5] Batch [510]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.199636,	
2017-07-25 17:40:36,776 Epoch[5] Batch [520]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.199959,	
2017-07-25 17:40:40,704 Epoch[5] Batch [530]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.199951,	
2017-07-25 17:40:44,533 Epoch[5] Batch [540]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.200575,	
2017-07-25 17:40:48,362 Epoch[5] Batch [550]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.200425,	
2017-07-25 17:40:52,190 Epoch[5] Batch [560]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.200414,	
2017-07-25 17:40:56,104 Epoch[5] Batch [570]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.200546,	
2017-07-25 17:41:00,025 Epoch[5] Batch [580]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.200648,	
2017-07-25 17:41:03,964 Epoch[5] Batch [590]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.200174,	
2017-07-25 17:41:07,858 Epoch[5] Batch [600]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.199734,	
2017-07-25 17:41:11,652 Epoch[5] Batch [610]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.198855,	
2017-07-25 17:41:15,667 Epoch[5] Batch [620]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.198653,	
2017-07-25 17:41:19,558 Epoch[5] Batch [630]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.198071,	
2017-07-25 17:41:23,481 Epoch[5] Batch [640]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.198256,	
2017-07-25 17:41:27,412 Epoch[5] Batch [650]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.198079,	
2017-07-25 17:41:31,373 Epoch[5] Batch [660]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.197658,	
2017-07-25 17:41:35,282 Epoch[5] Batch [670]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.197217,	
2017-07-25 17:41:39,160 Epoch[5] Batch [680]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.197694,	
2017-07-25 17:41:43,033 Epoch[5] Batch [690]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.197584,	
2017-07-25 17:41:46,936 Epoch[5] Batch [700]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.197678,	
2017-07-25 17:41:50,860 Epoch[5] Batch [710]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.197656,	
2017-07-25 17:41:54,852 Epoch[5] Batch [720]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.197582,	
2017-07-25 17:41:58,759 Epoch[5] Batch [730]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.197448,	
2017-07-25 17:42:02,670 Epoch[5] Batch [740]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.196874,	
2017-07-25 17:42:06,520 Epoch[5] Batch [750]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.196516,	
2017-07-25 17:42:10,430 Epoch[5] Batch [760]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.196649,	
2017-07-25 17:42:14,275 Epoch[5] Batch [770]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.196778,	
2017-07-25 17:42:18,175 Epoch[5] Batch [780]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.196844,	
2017-07-25 17:42:22,039 Epoch[5] Batch [790]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.196690,	
2017-07-25 17:42:26,000 Epoch[5] Batch [800]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.196487,	
2017-07-25 17:42:29,871 Epoch[5] Batch [810]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.196274,	
2017-07-25 17:42:33,773 Epoch[5] Batch [820]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.196041,	
2017-07-25 17:42:37,673 Epoch[5] Batch [830]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.195889,	
2017-07-25 17:42:41,464 Epoch[5] Batch [840]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.195635,	
2017-07-25 17:42:45,550 Epoch[5] Batch [850]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.195275,	
2017-07-25 17:42:49,430 Epoch[5] Batch [860]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.195243,	
2017-07-25 17:42:53,345 Epoch[5] Batch [870]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.195370,	
2017-07-25 17:42:57,273 Epoch[5] Batch [880]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.195307,	
2017-07-25 17:43:01,177 Epoch[5] Batch [890]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.195195,	
2017-07-25 17:43:04,990 Epoch[5] Batch [900]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.195128,	
2017-07-25 17:43:08,797 Epoch[5] Batch [910]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.194948,	
2017-07-25 17:43:12,650 Epoch[5] Batch [920]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.194877,	
2017-07-25 17:43:16,546 Epoch[5] Batch [930]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.194819,	
2017-07-25 17:43:20,462 Epoch[5] Batch [940]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.194675,	
2017-07-25 17:43:24,357 Epoch[5] Batch [950]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.194820,	
2017-07-25 17:43:28,255 Epoch[5] Batch [960]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.194920,	
2017-07-25 17:43:32,092 Epoch[5] Batch [970]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.194852,	
2017-07-25 17:43:35,976 Epoch[5] Batch [980]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.194549,	
2017-07-25 17:43:39,940 Epoch[5] Batch [990]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.194181,	
2017-07-25 17:43:43,818 Epoch[5] Batch [1000]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.194224,	
2017-07-25 17:43:47,753 Epoch[5] Batch [1010]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.194239,	
2017-07-25 17:43:51,627 Epoch[5] Batch [1020]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.194085,	
2017-07-25 17:43:55,509 Epoch[5] Batch [1030]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.193985,	
2017-07-25 17:43:59,308 Epoch[5] Batch [1040]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.194092,	
2017-07-25 17:44:03,101 Epoch[5] Batch [1050]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.193987,	
2017-07-25 17:44:06,975 Epoch[5] Batch [1060]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.193909,	
2017-07-25 17:44:10,848 Epoch[5] Batch [1070]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.193816,	
2017-07-25 17:44:14,774 Epoch[5] Batch [1080]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.193739,	
2017-07-25 17:44:18,777 Epoch[5] Batch [1090]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.193464,	
2017-07-25 17:44:22,618 Epoch[5] Batch [1100]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.193276,	
2017-07-25 17:44:26,532 Epoch[5] Batch [1110]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.192997,	
2017-07-25 17:44:30,404 Epoch[5] Batch [1120]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.192811,	
2017-07-25 17:44:34,237 Epoch[5] Batch [1130]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.192739,	
2017-07-25 17:44:38,229 Epoch[5] Batch [1140]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.192562,	
2017-07-25 17:44:42,093 Epoch[5] Batch [1150]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.192352,	
2017-07-25 17:44:46,018 Epoch[5] Batch [1160]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.192336,	
2017-07-25 17:44:49,967 Epoch[5] Batch [1170]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.192311,	
2017-07-25 17:44:53,814 Epoch[5] Batch [1180]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.192139,	
2017-07-25 17:44:57,695 Epoch[5] Batch [1190]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.192424,	
2017-07-25 17:45:01,564 Epoch[5] Batch [1200]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.192421,	
2017-07-25 17:45:05,449 Epoch[5] Batch [1210]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.192493,	
2017-07-25 17:45:09,363 Epoch[5] Batch [1220]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.192489,	
2017-07-25 17:45:13,120 Epoch[5] Batch [1230]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.192450,	
2017-07-25 17:45:17,076 Epoch[5] Batch [1240]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.192422,	
2017-07-25 17:45:21,030 Epoch[5] Batch [1250]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.192469,	
2017-07-25 17:45:24,995 Epoch[5] Batch [1260]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.192495,	
2017-07-25 17:45:28,941 Epoch[5] Batch [1270]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.192341,	
2017-07-25 17:45:32,834 Epoch[5] Batch [1280]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.192439,	
2017-07-25 17:45:36,765 Epoch[5] Batch [1290]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.192396,	
2017-07-25 17:45:40,709 Epoch[5] Batch [1300]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.192340,	
2017-07-25 17:45:44,570 Epoch[5] Batch [1310]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.192145,	
2017-07-25 17:45:48,486 Epoch[5] Batch [1320]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.192257,	
2017-07-25 17:45:52,359 Epoch[5] Batch [1330]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.192326,	
2017-07-25 17:45:56,270 Epoch[5] Batch [1340]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.192553,	
2017-07-25 17:46:00,069 Epoch[5] Batch [1350]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.192575,	
2017-07-25 17:46:03,822 Epoch[5] Batch [1360]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.192865,	
2017-07-25 17:46:07,748 Epoch[5] Batch [1370]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.192604,	
2017-07-25 17:46:11,676 Epoch[5] Batch [1380]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.192780,	
2017-07-25 17:46:15,569 Epoch[5] Batch [1390]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.192783,	
2017-07-25 17:46:19,460 Epoch[5] Batch [1400]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.192635,	
2017-07-25 17:46:23,423 Epoch[5] Batch [1410]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.192643,	
2017-07-25 17:46:27,343 Epoch[5] Batch [1420]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.192735,	
2017-07-25 17:46:31,294 Epoch[5] Batch [1430]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.192605,	
2017-07-25 17:46:35,160 Epoch[5] Batch [1440]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.192491,	
2017-07-25 17:46:38,926 Epoch[5] Batch [1450]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.192460,	
2017-07-25 17:46:42,922 Epoch[5] Batch [1460]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.192397,	
2017-07-25 17:46:46,877 Epoch[5] Batch [1470]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.192435,	
2017-07-25 17:46:50,804 Epoch[5] Batch [1480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.192198,	
2017-07-25 17:46:53,214 Epoch[5] Train-FCNLogLoss=0.192199
2017-07-25 17:46:53,214 Epoch[5] Time cost=579.540
2017-07-25 17:46:53,925 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.params"
2017-07-25 17:46:55,497 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0006.states"
2017-07-25 17:47:00,186 Epoch[6] Batch [10]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.183881,	
2017-07-25 17:47:04,053 Epoch[6] Batch [20]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.179060,	
2017-07-25 17:47:07,973 Epoch[6] Batch [30]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.176247,	
2017-07-25 17:47:11,858 Epoch[6] Batch [40]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.166866,	
2017-07-25 17:47:15,736 Epoch[6] Batch [50]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.185756,	
2017-07-25 17:47:19,732 Epoch[6] Batch [60]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.192515,	
2017-07-25 17:47:23,558 Epoch[6] Batch [70]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.198972,	
2017-07-25 17:47:27,470 Epoch[6] Batch [80]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.198580,	
2017-07-25 17:47:31,325 Epoch[6] Batch [90]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.194839,	
2017-07-25 17:47:35,249 Epoch[6] Batch [100]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.193365,	
2017-07-25 17:47:39,083 Epoch[6] Batch [110]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.190914,	
2017-07-25 17:47:43,020 Epoch[6] Batch [120]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.191925,	
2017-07-25 17:47:46,902 Epoch[6] Batch [130]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.190525,	
2017-07-25 17:47:50,860 Epoch[6] Batch [140]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.191512,	
2017-07-25 17:47:54,711 Epoch[6] Batch [150]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.189547,	
2017-07-25 17:47:58,576 Epoch[6] Batch [160]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.189638,	
2017-07-25 17:48:02,606 Epoch[6] Batch [170]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.189803,	
2017-07-25 17:48:06,482 Epoch[6] Batch [180]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.189144,	
2017-07-25 17:48:10,377 Epoch[6] Batch [190]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.188319,	
2017-07-25 17:48:14,180 Epoch[6] Batch [200]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.188025,	
2017-07-25 17:48:18,014 Epoch[6] Batch [210]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.188439,	
2017-07-25 17:48:22,013 Epoch[6] Batch [220]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.188052,	
2017-07-25 17:48:25,957 Epoch[6] Batch [230]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.188127,	
2017-07-25 17:48:29,902 Epoch[6] Batch [240]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.187325,	
2017-07-25 17:48:33,826 Epoch[6] Batch [250]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.187233,	
2017-07-25 17:48:37,768 Epoch[6] Batch [260]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.188135,	
2017-07-25 17:48:41,697 Epoch[6] Batch [270]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.188517,	
2017-07-25 17:48:45,626 Epoch[6] Batch [280]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.188259,	
2017-07-25 17:48:49,479 Epoch[6] Batch [290]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.187707,	
2017-07-25 17:48:53,364 Epoch[6] Batch [300]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.188828,	
2017-07-25 17:48:57,265 Epoch[6] Batch [310]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.188303,	
2017-07-25 17:49:01,099 Epoch[6] Batch [320]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.188517,	
2017-07-25 17:49:05,016 Epoch[6] Batch [330]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.187576,	
2017-07-25 17:49:08,960 Epoch[6] Batch [340]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.187534,	
2017-07-25 17:49:12,850 Epoch[6] Batch [350]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.187675,	
2017-07-25 17:49:16,776 Epoch[6] Batch [360]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.187729,	
2017-07-25 17:49:20,659 Epoch[6] Batch [370]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.187222,	
2017-07-25 17:49:24,590 Epoch[6] Batch [380]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.186862,	
2017-07-25 17:49:28,567 Epoch[6] Batch [390]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.187872,	
2017-07-25 17:49:32,512 Epoch[6] Batch [400]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.187807,	
2017-07-25 17:49:36,516 Epoch[6] Batch [410]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.187397,	
2017-07-25 17:49:40,361 Epoch[6] Batch [420]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.187488,	
2017-07-25 17:49:44,374 Epoch[6] Batch [430]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.186852,	
2017-07-25 17:49:48,270 Epoch[6] Batch [440]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.186844,	
2017-07-25 17:49:52,186 Epoch[6] Batch [450]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.187269,	
2017-07-25 17:49:56,051 Epoch[6] Batch [460]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.187534,	
2017-07-25 17:49:59,937 Epoch[6] Batch [470]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.186648,	
2017-07-25 17:50:03,830 Epoch[6] Batch [480]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.186530,	
2017-07-25 17:50:07,821 Epoch[6] Batch [490]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.186080,	
2017-07-25 17:50:11,754 Epoch[6] Batch [500]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.185659,	
2017-07-25 17:50:15,743 Epoch[6] Batch [510]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.185731,	
2017-07-25 17:50:19,616 Epoch[6] Batch [520]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.185384,	
2017-07-25 17:50:23,469 Epoch[6] Batch [530]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.185403,	
2017-07-25 17:50:27,513 Epoch[6] Batch [540]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.185117,	
2017-07-25 17:50:31,420 Epoch[6] Batch [550]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.185620,	
2017-07-25 17:50:35,316 Epoch[6] Batch [560]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.185838,	
2017-07-25 17:50:39,204 Epoch[6] Batch [570]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.185528,	
2017-07-25 17:50:43,157 Epoch[6] Batch [580]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.185158,	
2017-07-25 17:50:47,039 Epoch[6] Batch [590]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.185236,	
2017-07-25 17:50:50,877 Epoch[6] Batch [600]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.184755,	
2017-07-25 17:50:54,724 Epoch[6] Batch [610]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.184589,	
2017-07-25 17:50:58,592 Epoch[6] Batch [620]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.184157,	
2017-07-25 17:51:02,418 Epoch[6] Batch [630]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.184020,	
2017-07-25 17:51:06,468 Epoch[6] Batch [640]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.184040,	
2017-07-25 17:51:10,231 Epoch[6] Batch [650]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.183826,	
2017-07-25 17:51:14,141 Epoch[6] Batch [660]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.183941,	
2017-07-25 17:51:18,102 Epoch[6] Batch [670]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.183274,	
2017-07-25 17:51:21,954 Epoch[6] Batch [680]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.183486,	
2017-07-25 17:51:25,881 Epoch[6] Batch [690]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.183797,	
2017-07-25 17:51:29,792 Epoch[6] Batch [700]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.184096,	
2017-07-25 17:51:33,717 Epoch[6] Batch [710]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.183909,	
2017-07-25 17:51:37,577 Epoch[6] Batch [720]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.184404,	
2017-07-25 17:51:41,478 Epoch[6] Batch [730]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.184142,	
2017-07-25 17:51:45,304 Epoch[6] Batch [740]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.183856,	
2017-07-25 17:51:49,223 Epoch[6] Batch [750]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.183787,	
2017-07-25 17:51:53,174 Epoch[6] Batch [760]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.183821,	
2017-07-25 17:51:57,107 Epoch[6] Batch [770]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.183803,	
2017-07-25 17:52:01,036 Epoch[6] Batch [780]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.183471,	
2017-07-25 17:52:04,883 Epoch[6] Batch [790]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.183297,	
2017-07-25 17:52:08,865 Epoch[6] Batch [800]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.183203,	
2017-07-25 17:52:12,713 Epoch[6] Batch [810]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.183011,	
2017-07-25 17:52:16,685 Epoch[6] Batch [820]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.183350,	
2017-07-25 17:52:20,574 Epoch[6] Batch [830]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.183279,	
2017-07-25 17:52:24,483 Epoch[6] Batch [840]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.183555,	
2017-07-25 17:52:28,384 Epoch[6] Batch [850]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.183698,	
2017-07-25 17:52:32,253 Epoch[6] Batch [860]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.183727,	
2017-07-25 17:52:36,112 Epoch[6] Batch [870]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.183552,	
2017-07-25 17:52:39,974 Epoch[6] Batch [880]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.183609,	
2017-07-25 17:52:43,858 Epoch[6] Batch [890]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.183434,	
2017-07-25 17:52:47,901 Epoch[6] Batch [900]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.183201,	
2017-07-25 17:52:51,858 Epoch[6] Batch [910]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.182922,	
2017-07-25 17:52:55,768 Epoch[6] Batch [920]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.182933,	
2017-07-25 17:52:59,642 Epoch[6] Batch [930]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.182965,	
2017-07-25 17:53:03,552 Epoch[6] Batch [940]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.182788,	
2017-07-25 17:53:07,423 Epoch[6] Batch [950]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.182832,	
2017-07-25 17:53:11,372 Epoch[6] Batch [960]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.182783,	
2017-07-25 17:53:15,309 Epoch[6] Batch [970]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.183051,	
2017-07-25 17:53:19,270 Epoch[6] Batch [980]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.183425,	
2017-07-25 17:53:23,164 Epoch[6] Batch [990]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.183773,	
2017-07-25 17:53:27,076 Epoch[6] Batch [1000]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.183735,	
2017-07-25 17:53:30,884 Epoch[6] Batch [1010]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.183734,	
2017-07-25 17:53:34,782 Epoch[6] Batch [1020]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.183386,	
2017-07-25 17:53:38,627 Epoch[6] Batch [1030]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.183388,	
2017-07-25 17:53:42,591 Epoch[6] Batch [1040]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.183308,	
2017-07-25 17:53:46,418 Epoch[6] Batch [1050]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.183140,	
2017-07-25 17:53:50,273 Epoch[6] Batch [1060]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.183030,	
2017-07-25 17:53:54,234 Epoch[6] Batch [1070]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.182774,	
2017-07-25 17:53:58,153 Epoch[6] Batch [1080]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.182649,	
2017-07-25 17:54:01,994 Epoch[6] Batch [1090]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.182543,	
2017-07-25 17:54:06,056 Epoch[6] Batch [1100]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.182590,	
2017-07-25 17:54:09,916 Epoch[6] Batch [1110]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.182369,	
2017-07-25 17:54:13,797 Epoch[6] Batch [1120]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.182593,	
2017-07-25 17:54:17,758 Epoch[6] Batch [1130]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.182549,	
2017-07-25 17:54:21,652 Epoch[6] Batch [1140]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.182294,	
2017-07-25 17:54:25,628 Epoch[6] Batch [1150]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.182179,	
2017-07-25 17:54:29,520 Epoch[6] Batch [1160]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.181924,	
2017-07-25 17:54:33,364 Epoch[6] Batch [1170]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.182049,	
2017-07-25 17:54:37,302 Epoch[6] Batch [1180]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.182161,	
2017-07-25 17:54:41,187 Epoch[6] Batch [1190]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.182043,	
2017-07-25 17:54:45,068 Epoch[6] Batch [1200]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.181987,	
2017-07-25 17:54:48,945 Epoch[6] Batch [1210]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.182271,	
2017-07-25 17:54:52,793 Epoch[6] Batch [1220]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.182845,	
2017-07-25 17:54:56,662 Epoch[6] Batch [1230]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.182950,	
2017-07-25 17:55:00,484 Epoch[6] Batch [1240]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.182885,	
2017-07-25 17:55:04,335 Epoch[6] Batch [1250]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.182740,	
2017-07-25 17:55:08,253 Epoch[6] Batch [1260]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.182558,	
2017-07-25 17:55:12,139 Epoch[6] Batch [1270]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.182623,	
2017-07-25 17:55:16,196 Epoch[6] Batch [1280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.182644,	
2017-07-25 17:55:20,043 Epoch[6] Batch [1290]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.182822,	
2017-07-25 17:55:23,933 Epoch[6] Batch [1300]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.182766,	
2017-07-25 17:55:27,898 Epoch[6] Batch [1310]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.182875,	
2017-07-25 17:55:31,773 Epoch[6] Batch [1320]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.182637,	
2017-07-25 17:55:35,605 Epoch[6] Batch [1330]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.182569,	
2017-07-25 17:55:39,473 Epoch[6] Batch [1340]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.182372,	
2017-07-25 17:55:43,435 Epoch[6] Batch [1350]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.182420,	
2017-07-25 17:55:47,294 Epoch[6] Batch [1360]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.182396,	
2017-07-25 17:55:51,156 Epoch[6] Batch [1370]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.182470,	
2017-07-25 17:55:55,067 Epoch[6] Batch [1380]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.182440,	
2017-07-25 17:55:58,971 Epoch[6] Batch [1390]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.182573,	
2017-07-25 17:56:02,861 Epoch[6] Batch [1400]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.182568,	
2017-07-25 17:56:06,765 Epoch[6] Batch [1410]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.182324,	
2017-07-25 17:56:10,716 Epoch[6] Batch [1420]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.182468,	
2017-07-25 17:56:14,570 Epoch[6] Batch [1430]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.182391,	
2017-07-25 17:56:18,406 Epoch[6] Batch [1440]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.182228,	
2017-07-25 17:56:22,380 Epoch[6] Batch [1450]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.182038,	
2017-07-25 17:56:26,282 Epoch[6] Batch [1460]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.181874,	
2017-07-25 17:56:30,168 Epoch[6] Batch [1470]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.181679,	
2017-07-25 17:56:34,088 Epoch[6] Batch [1480]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.181572,	
2017-07-25 17:56:36,474 Epoch[6] Train-FCNLogLoss=0.181489
2017-07-25 17:56:36,474 Epoch[6] Time cost=580.976
2017-07-25 17:56:37,177 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.params"
2017-07-25 17:56:38,738 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0007.states"
2017-07-25 17:56:43,351 Epoch[7] Batch [10]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.153184,	
2017-07-25 17:56:47,225 Epoch[7] Batch [20]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.159890,	
2017-07-25 17:56:51,130 Epoch[7] Batch [30]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.160305,	
2017-07-25 17:56:55,134 Epoch[7] Batch [40]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.160898,	
2017-07-25 17:56:58,893 Epoch[7] Batch [50]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.166079,	
2017-07-25 17:57:02,842 Epoch[7] Batch [60]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.168440,	
2017-07-25 17:57:06,763 Epoch[7] Batch [70]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.164492,	
2017-07-25 17:57:10,621 Epoch[7] Batch [80]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.170947,	
2017-07-25 17:57:14,509 Epoch[7] Batch [90]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.172047,	
2017-07-25 17:57:18,477 Epoch[7] Batch [100]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.172165,	
2017-07-25 17:57:22,414 Epoch[7] Batch [110]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.178050,	
2017-07-25 17:57:26,442 Epoch[7] Batch [120]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.179094,	
2017-07-25 17:57:30,398 Epoch[7] Batch [130]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.179211,	
2017-07-25 17:57:34,360 Epoch[7] Batch [140]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.179460,	
2017-07-25 17:57:38,440 Epoch[7] Batch [150]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.178882,	
2017-07-25 17:57:42,346 Epoch[7] Batch [160]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.177392,	
2017-07-25 17:57:46,321 Epoch[7] Batch [170]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.176493,	
2017-07-25 17:57:50,285 Epoch[7] Batch [180]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.176760,	
2017-07-25 17:57:54,412 Epoch[7] Batch [190]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.176891,	
2017-07-25 17:57:58,314 Epoch[7] Batch [200]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.176746,	
2017-07-25 17:58:02,300 Epoch[7] Batch [210]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.175852,	
2017-07-25 17:58:06,286 Epoch[7] Batch [220]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.176792,	
2017-07-25 17:58:10,317 Epoch[7] Batch [230]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.176849,	
2017-07-25 17:58:14,349 Epoch[7] Batch [240]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.175981,	
2017-07-25 17:58:18,307 Epoch[7] Batch [250]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.175529,	
2017-07-25 17:58:22,212 Epoch[7] Batch [260]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.176031,	
2017-07-25 17:58:26,194 Epoch[7] Batch [270]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.176686,	
2017-07-25 17:58:30,090 Epoch[7] Batch [280]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.175758,	
2017-07-25 17:58:34,096 Epoch[7] Batch [290]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.176475,	
2017-07-25 17:58:38,044 Epoch[7] Batch [300]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.177012,	
2017-07-25 17:58:42,006 Epoch[7] Batch [310]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.177341,	
2017-07-25 17:58:46,038 Epoch[7] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.177768,	
2017-07-25 17:58:49,965 Epoch[7] Batch [330]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.177290,	
2017-07-25 17:58:54,108 Epoch[7] Batch [340]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.178144,	
2017-07-25 17:58:58,021 Epoch[7] Batch [350]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.178477,	
2017-07-25 17:59:02,016 Epoch[7] Batch [360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.178740,	
2017-07-25 17:59:05,898 Epoch[7] Batch [370]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.177953,	
2017-07-25 17:59:09,926 Epoch[7] Batch [380]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.178622,	
2017-07-25 17:59:13,904 Epoch[7] Batch [390]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.179036,	
2017-07-25 17:59:17,891 Epoch[7] Batch [400]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.178700,	
2017-07-25 17:59:21,826 Epoch[7] Batch [410]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.179569,	
2017-07-25 17:59:25,847 Epoch[7] Batch [420]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.179230,	
2017-07-25 17:59:29,818 Epoch[7] Batch [430]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.178917,	
2017-07-25 17:59:33,848 Epoch[7] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.178488,	
2017-07-25 17:59:37,833 Epoch[7] Batch [450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.177788,	
2017-07-25 17:59:41,806 Epoch[7] Batch [460]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.177550,	
2017-07-25 17:59:45,827 Epoch[7] Batch [470]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.178034,	
2017-07-25 17:59:49,760 Epoch[7] Batch [480]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.178757,	
2017-07-25 17:59:53,705 Epoch[7] Batch [490]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.178223,	
2017-07-25 17:59:57,641 Epoch[7] Batch [500]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.178471,	
2017-07-25 18:00:01,683 Epoch[7] Batch [510]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.178886,	
2017-07-25 18:00:05,506 Epoch[7] Batch [520]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.179420,	
2017-07-25 18:00:09,538 Epoch[7] Batch [530]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.179607,	
2017-07-25 18:00:13,329 Epoch[7] Batch [540]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.179329,	
2017-07-25 18:00:17,314 Epoch[7] Batch [550]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.179564,	
2017-07-25 18:00:21,211 Epoch[7] Batch [560]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.179622,	
2017-07-25 18:00:25,105 Epoch[7] Batch [570]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.179386,	
2017-07-25 18:00:29,193 Epoch[7] Batch [580]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.178696,	
2017-07-25 18:00:33,155 Epoch[7] Batch [590]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.178694,	
2017-07-25 18:00:37,221 Epoch[7] Batch [600]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.178477,	
2017-07-25 18:00:41,147 Epoch[7] Batch [610]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.177815,	
2017-07-25 18:00:45,212 Epoch[7] Batch [620]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.177615,	
2017-07-25 18:00:49,242 Epoch[7] Batch [630]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.177655,	
2017-07-25 18:00:53,209 Epoch[7] Batch [640]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.177555,	
2017-07-25 18:00:57,163 Epoch[7] Batch [650]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.177254,	
2017-07-25 18:01:01,057 Epoch[7] Batch [660]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.177559,	
2017-07-25 18:01:04,995 Epoch[7] Batch [670]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.177534,	
2017-07-25 18:01:08,951 Epoch[7] Batch [680]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.177635,	
2017-07-25 18:01:12,793 Epoch[7] Batch [690]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.177499,	
2017-07-25 18:01:16,783 Epoch[7] Batch [700]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.177201,	
2017-07-25 18:01:20,734 Epoch[7] Batch [710]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.176864,	
2017-07-25 18:01:24,668 Epoch[7] Batch [720]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.177298,	
2017-07-25 18:01:28,595 Epoch[7] Batch [730]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.177754,	
2017-07-25 18:01:32,461 Epoch[7] Batch [740]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.177581,	
2017-07-25 18:01:36,349 Epoch[7] Batch [750]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.177218,	
2017-07-25 18:01:40,362 Epoch[7] Batch [760]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.177059,	
2017-07-25 18:01:44,332 Epoch[7] Batch [770]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.176914,	
2017-07-25 18:01:48,368 Epoch[7] Batch [780]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.177221,	
2017-07-25 18:01:52,280 Epoch[7] Batch [790]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.177457,	
2017-07-25 18:01:56,352 Epoch[7] Batch [800]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.177492,	
2017-07-25 18:02:00,387 Epoch[7] Batch [810]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.177824,	
2017-07-25 18:02:04,400 Epoch[7] Batch [820]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.177952,	
2017-07-25 18:02:08,381 Epoch[7] Batch [830]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.177833,	
2017-07-25 18:02:12,345 Epoch[7] Batch [840]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.178087,	
2017-07-25 18:02:16,252 Epoch[7] Batch [850]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.178196,	
2017-07-25 18:02:20,225 Epoch[7] Batch [860]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.178232,	
2017-07-25 18:02:24,161 Epoch[7] Batch [870]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.178311,	
2017-07-25 18:02:28,074 Epoch[7] Batch [880]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.178521,	
2017-07-25 18:02:32,069 Epoch[7] Batch [890]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.178210,	
2017-07-25 18:02:35,963 Epoch[7] Batch [900]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.177950,	
2017-07-25 18:02:39,917 Epoch[7] Batch [910]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.177762,	
2017-07-25 18:02:43,815 Epoch[7] Batch [920]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.177555,	
2017-07-25 18:02:47,795 Epoch[7] Batch [930]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.177523,	
2017-07-25 18:02:51,775 Epoch[7] Batch [940]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.177652,	
2017-07-25 18:02:55,653 Epoch[7] Batch [950]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.177829,	
2017-07-25 18:02:59,675 Epoch[7] Batch [960]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.177527,	
2017-07-25 18:03:03,635 Epoch[7] Batch [970]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.177527,	
2017-07-25 18:03:07,570 Epoch[7] Batch [980]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.177187,	
2017-07-25 18:03:11,492 Epoch[7] Batch [990]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.177417,	
2017-07-25 18:03:15,507 Epoch[7] Batch [1000]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.177249,	
2017-07-25 18:03:19,623 Epoch[7] Batch [1010]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.177177,	
2017-07-25 18:03:23,568 Epoch[7] Batch [1020]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.177301,	
2017-07-25 18:03:27,481 Epoch[7] Batch [1030]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.177292,	
2017-07-25 18:03:31,424 Epoch[7] Batch [1040]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.177019,	
2017-07-25 18:03:35,409 Epoch[7] Batch [1050]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.177022,	
2017-07-25 18:03:39,411 Epoch[7] Batch [1060]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.177317,	
2017-07-25 18:03:43,296 Epoch[7] Batch [1070]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.177371,	
2017-07-25 18:03:47,200 Epoch[7] Batch [1080]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.177896,	
2017-07-25 18:03:51,126 Epoch[7] Batch [1090]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.178192,	
2017-07-25 18:03:55,123 Epoch[7] Batch [1100]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.178331,	
2017-07-25 18:03:59,125 Epoch[7] Batch [1110]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.178079,	
2017-07-25 18:04:03,084 Epoch[7] Batch [1120]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.178149,	
2017-07-25 18:04:06,993 Epoch[7] Batch [1130]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.178290,	
2017-07-25 18:04:10,777 Epoch[7] Batch [1140]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.178253,	
2017-07-25 18:04:14,808 Epoch[7] Batch [1150]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.178390,	
2017-07-25 18:04:18,756 Epoch[7] Batch [1160]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.178408,	
2017-07-25 18:04:22,685 Epoch[7] Batch [1170]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.178484,	
2017-07-25 18:04:26,591 Epoch[7] Batch [1180]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.178308,	
2017-07-25 18:04:30,682 Epoch[7] Batch [1190]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.178046,	
2017-07-25 18:04:34,701 Epoch[7] Batch [1200]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.177935,	
2017-07-25 18:04:38,719 Epoch[7] Batch [1210]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.177801,	
2017-07-25 18:04:42,674 Epoch[7] Batch [1220]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.177841,	
2017-07-25 18:04:46,736 Epoch[7] Batch [1230]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.177705,	
2017-07-25 18:04:50,717 Epoch[7] Batch [1240]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.177457,	
2017-07-25 18:04:54,657 Epoch[7] Batch [1250]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.177630,	
2017-07-25 18:04:58,534 Epoch[7] Batch [1260]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.177575,	
2017-07-25 18:05:02,499 Epoch[7] Batch [1270]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.177468,	
2017-07-25 18:05:06,436 Epoch[7] Batch [1280]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.177374,	
2017-07-25 18:05:10,416 Epoch[7] Batch [1290]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.177409,	
2017-07-25 18:05:14,213 Epoch[7] Batch [1300]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.177380,	
2017-07-25 18:05:18,176 Epoch[7] Batch [1310]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.177442,	
2017-07-25 18:05:22,102 Epoch[7] Batch [1320]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.177422,	
2017-07-25 18:05:25,985 Epoch[7] Batch [1330]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.177247,	
2017-07-25 18:05:29,901 Epoch[7] Batch [1340]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.177140,	
2017-07-25 18:05:33,821 Epoch[7] Batch [1350]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.177152,	
2017-07-25 18:05:37,913 Epoch[7] Batch [1360]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.177002,	
2017-07-25 18:05:41,775 Epoch[7] Batch [1370]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.177002,	
2017-07-25 18:05:45,642 Epoch[7] Batch [1380]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.177051,	
2017-07-25 18:05:49,565 Epoch[7] Batch [1390]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.177236,	
2017-07-25 18:05:53,458 Epoch[7] Batch [1400]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.177297,	
2017-07-25 18:05:57,406 Epoch[7] Batch [1410]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.177587,	
2017-07-25 18:06:01,447 Epoch[7] Batch [1420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.177821,	
2017-07-25 18:06:05,280 Epoch[7] Batch [1430]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.177813,	
2017-07-25 18:06:09,173 Epoch[7] Batch [1440]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.177919,	
2017-07-25 18:06:13,077 Epoch[7] Batch [1450]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.177974,	
2017-07-25 18:06:17,015 Epoch[7] Batch [1460]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.177869,	
2017-07-25 18:06:20,940 Epoch[7] Batch [1470]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.178100,	
2017-07-25 18:06:24,985 Epoch[7] Batch [1480]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.178096,	
2017-07-25 18:06:27,289 Epoch[7] Train-FCNLogLoss=0.177957
2017-07-25 18:06:27,290 Epoch[7] Time cost=588.551
2017-07-25 18:06:28,015 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.params"
2017-07-25 18:06:29,601 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0008.states"
2017-07-25 18:06:34,187 Epoch[8] Batch [10]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.158897,	
2017-07-25 18:06:38,155 Epoch[8] Batch [20]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.157652,	
2017-07-25 18:06:42,111 Epoch[8] Batch [30]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.153748,	
2017-07-25 18:06:46,053 Epoch[8] Batch [40]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.153266,	
2017-07-25 18:06:49,902 Epoch[8] Batch [50]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.154851,	
2017-07-25 18:06:53,923 Epoch[8] Batch [60]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.157961,	
2017-07-25 18:06:57,941 Epoch[8] Batch [70]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.160857,	
2017-07-25 18:07:01,874 Epoch[8] Batch [80]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.158370,	
2017-07-25 18:07:05,760 Epoch[8] Batch [90]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.158430,	
2017-07-25 18:07:09,679 Epoch[8] Batch [100]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.160392,	
2017-07-25 18:07:13,548 Epoch[8] Batch [110]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.162184,	
2017-07-25 18:07:17,441 Epoch[8] Batch [120]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.163279,	
2017-07-25 18:07:21,327 Epoch[8] Batch [130]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.162703,	
2017-07-25 18:07:25,183 Epoch[8] Batch [140]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.161709,	
2017-07-25 18:07:29,184 Epoch[8] Batch [150]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.159875,	
2017-07-25 18:07:33,075 Epoch[8] Batch [160]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.160773,	
2017-07-25 18:07:37,038 Epoch[8] Batch [170]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.162115,	
2017-07-25 18:07:40,886 Epoch[8] Batch [180]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.162520,	
2017-07-25 18:07:44,760 Epoch[8] Batch [190]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.163181,	
2017-07-25 18:07:48,668 Epoch[8] Batch [200]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.164040,	
2017-07-25 18:07:52,653 Epoch[8] Batch [210]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.164838,	
2017-07-25 18:07:56,739 Epoch[8] Batch [220]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.166428,	
2017-07-25 18:08:00,534 Epoch[8] Batch [230]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.166300,	
2017-07-25 18:08:04,408 Epoch[8] Batch [240]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.167475,	
2017-07-25 18:08:08,269 Epoch[8] Batch [250]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.168256,	
2017-07-25 18:08:12,199 Epoch[8] Batch [260]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.168955,	
2017-07-25 18:08:16,253 Epoch[8] Batch [270]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.168626,	
2017-07-25 18:08:20,172 Epoch[8] Batch [280]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.168336,	
2017-07-25 18:08:24,008 Epoch[8] Batch [290]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.168199,	
2017-07-25 18:08:28,091 Epoch[8] Batch [300]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.168901,	
2017-07-25 18:08:32,078 Epoch[8] Batch [310]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.169754,	
2017-07-25 18:08:36,109 Epoch[8] Batch [320]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.169589,	
2017-07-25 18:08:40,007 Epoch[8] Batch [330]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.169416,	
2017-07-25 18:08:43,958 Epoch[8] Batch [340]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.168810,	
2017-07-25 18:08:47,961 Epoch[8] Batch [350]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.168107,	
2017-07-25 18:08:51,770 Epoch[8] Batch [360]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.167785,	
2017-07-25 18:08:55,699 Epoch[8] Batch [370]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.168322,	
2017-07-25 18:08:59,555 Epoch[8] Batch [380]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.167865,	
2017-07-25 18:09:03,556 Epoch[8] Batch [390]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.168326,	
2017-07-25 18:09:07,382 Epoch[8] Batch [400]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.168469,	
2017-07-25 18:09:11,356 Epoch[8] Batch [410]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.169791,	
2017-07-25 18:09:15,193 Epoch[8] Batch [420]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.170337,	
2017-07-25 18:09:19,124 Epoch[8] Batch [430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.170540,	
2017-07-25 18:09:23,074 Epoch[8] Batch [440]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.170680,	
2017-07-25 18:09:27,012 Epoch[8] Batch [450]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.170517,	
2017-07-25 18:09:31,026 Epoch[8] Batch [460]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.170127,	
2017-07-25 18:09:34,982 Epoch[8] Batch [470]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.169925,	
2017-07-25 18:09:38,978 Epoch[8] Batch [480]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.169705,	
2017-07-25 18:09:42,991 Epoch[8] Batch [490]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.169622,	
2017-07-25 18:09:47,065 Epoch[8] Batch [500]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.169714,	
2017-07-25 18:09:50,963 Epoch[8] Batch [510]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.170269,	
2017-07-25 18:09:55,058 Epoch[8] Batch [520]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.170231,	
2017-07-25 18:09:59,176 Epoch[8] Batch [530]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.169872,	
2017-07-25 18:10:03,161 Epoch[8] Batch [540]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.169826,	
2017-07-25 18:10:07,097 Epoch[8] Batch [550]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.169767,	
2017-07-25 18:10:11,106 Epoch[8] Batch [560]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.169324,	
2017-07-25 18:10:15,080 Epoch[8] Batch [570]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.169034,	
2017-07-25 18:10:19,020 Epoch[8] Batch [580]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.168793,	
2017-07-25 18:10:22,843 Epoch[8] Batch [590]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.168690,	
2017-07-25 18:10:26,748 Epoch[8] Batch [600]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.168526,	
2017-07-25 18:10:30,699 Epoch[8] Batch [610]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.168219,	
2017-07-25 18:10:34,627 Epoch[8] Batch [620]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.168056,	
2017-07-25 18:10:38,540 Epoch[8] Batch [630]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.167540,	
2017-07-25 18:10:42,631 Epoch[8] Batch [640]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.167448,	
2017-07-25 18:10:46,461 Epoch[8] Batch [650]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.167128,	
2017-07-25 18:10:50,362 Epoch[8] Batch [660]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.167470,	
2017-07-25 18:10:54,331 Epoch[8] Batch [670]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.167414,	
2017-07-25 18:10:58,349 Epoch[8] Batch [680]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.167587,	
2017-07-25 18:11:02,194 Epoch[8] Batch [690]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.167288,	
2017-07-25 18:11:06,195 Epoch[8] Batch [700]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.167781,	
2017-07-25 18:11:10,110 Epoch[8] Batch [710]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.168291,	
2017-07-25 18:11:14,041 Epoch[8] Batch [720]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.167898,	
2017-07-25 18:11:17,948 Epoch[8] Batch [730]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.168048,	
2017-07-25 18:11:21,884 Epoch[8] Batch [740]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.167728,	
2017-07-25 18:11:25,854 Epoch[8] Batch [750]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.167882,	
2017-07-25 18:11:29,898 Epoch[8] Batch [760]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.168356,	
2017-07-25 18:11:33,814 Epoch[8] Batch [770]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.168212,	
2017-07-25 18:11:37,810 Epoch[8] Batch [780]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.168092,	
2017-07-25 18:11:41,680 Epoch[8] Batch [790]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.168463,	
2017-07-25 18:11:45,640 Epoch[8] Batch [800]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.168449,	
2017-07-25 18:11:49,630 Epoch[8] Batch [810]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.168578,	
2017-07-25 18:11:53,536 Epoch[8] Batch [820]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.169102,	
2017-07-25 18:11:57,588 Epoch[8] Batch [830]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.169199,	
2017-07-25 18:12:01,530 Epoch[8] Batch [840]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.170124,	
2017-07-25 18:12:05,366 Epoch[8] Batch [850]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.170581,	
2017-07-25 18:12:09,314 Epoch[8] Batch [860]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.170819,	
2017-07-25 18:12:13,138 Epoch[8] Batch [870]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.171179,	
2017-07-25 18:12:17,079 Epoch[8] Batch [880]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.171673,	
2017-07-25 18:12:21,038 Epoch[8] Batch [890]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.171586,	
2017-07-25 18:12:25,069 Epoch[8] Batch [900]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.171612,	
2017-07-25 18:12:28,970 Epoch[8] Batch [910]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.171702,	
2017-07-25 18:12:32,863 Epoch[8] Batch [920]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.171914,	
2017-07-25 18:12:36,772 Epoch[8] Batch [930]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.172220,	
2017-07-25 18:12:40,672 Epoch[8] Batch [940]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.172301,	
2017-07-25 18:12:44,532 Epoch[8] Batch [950]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.172432,	
2017-07-25 18:12:48,580 Epoch[8] Batch [960]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.172351,	
2017-07-25 18:12:52,543 Epoch[8] Batch [970]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.172033,	
2017-07-25 18:12:56,541 Epoch[8] Batch [980]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.171805,	
2017-07-25 18:13:00,443 Epoch[8] Batch [990]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.171625,	
2017-07-25 18:13:04,393 Epoch[8] Batch [1000]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.171362,	
2017-07-25 18:13:08,311 Epoch[8] Batch [1010]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.171194,	
2017-07-25 18:13:12,431 Epoch[8] Batch [1020]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.170927,	
2017-07-25 18:13:16,353 Epoch[8] Batch [1030]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.170945,	
2017-07-25 18:13:20,334 Epoch[8] Batch [1040]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.170775,	
2017-07-25 18:13:24,314 Epoch[8] Batch [1050]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.170786,	
2017-07-25 18:13:28,190 Epoch[8] Batch [1060]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.170555,	
2017-07-25 18:13:32,081 Epoch[8] Batch [1070]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.170771,	
2017-07-25 18:13:36,002 Epoch[8] Batch [1080]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.170786,	
2017-07-25 18:13:39,938 Epoch[8] Batch [1090]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.171316,	
2017-07-25 18:13:43,798 Epoch[8] Batch [1100]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.171352,	
2017-07-25 18:13:47,763 Epoch[8] Batch [1110]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.171466,	
2017-07-25 18:13:51,836 Epoch[8] Batch [1120]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.171372,	
2017-07-25 18:13:55,709 Epoch[8] Batch [1130]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.171325,	
2017-07-25 18:13:59,499 Epoch[8] Batch [1140]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.171270,	
2017-07-25 18:14:03,498 Epoch[8] Batch [1150]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.171201,	
2017-07-25 18:14:07,429 Epoch[8] Batch [1160]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.171207,	
2017-07-25 18:14:11,455 Epoch[8] Batch [1170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.171008,	
2017-07-25 18:14:15,356 Epoch[8] Batch [1180]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.171063,	
2017-07-25 18:14:19,203 Epoch[8] Batch [1190]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.171052,	
2017-07-25 18:14:23,194 Epoch[8] Batch [1200]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.171156,	
2017-07-25 18:14:27,152 Epoch[8] Batch [1210]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.171189,	
2017-07-25 18:14:31,078 Epoch[8] Batch [1220]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.171054,	
2017-07-25 18:14:34,927 Epoch[8] Batch [1230]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.170943,	
2017-07-25 18:14:38,809 Epoch[8] Batch [1240]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.171109,	
2017-07-25 18:14:42,792 Epoch[8] Batch [1250]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.171109,	
2017-07-25 18:14:46,798 Epoch[8] Batch [1260]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.171387,	
2017-07-25 18:14:50,674 Epoch[8] Batch [1270]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.171414,	
2017-07-25 18:14:54,578 Epoch[8] Batch [1280]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.171361,	
2017-07-25 18:14:58,580 Epoch[8] Batch [1290]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.171323,	
2017-07-25 18:15:02,640 Epoch[8] Batch [1300]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.171444,	
2017-07-25 18:15:06,556 Epoch[8] Batch [1310]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.171834,	
2017-07-25 18:15:10,567 Epoch[8] Batch [1320]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.171769,	
2017-07-25 18:15:14,605 Epoch[8] Batch [1330]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.171840,	
2017-07-25 18:15:18,527 Epoch[8] Batch [1340]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.171809,	
2017-07-25 18:15:22,493 Epoch[8] Batch [1350]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.171592,	
2017-07-25 18:15:26,400 Epoch[8] Batch [1360]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.171493,	
2017-07-25 18:15:30,277 Epoch[8] Batch [1370]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.171381,	
2017-07-25 18:15:34,178 Epoch[8] Batch [1380]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.171363,	
2017-07-25 18:15:38,127 Epoch[8] Batch [1390]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.171389,	
2017-07-25 18:15:41,976 Epoch[8] Batch [1400]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.171454,	
2017-07-25 18:15:45,839 Epoch[8] Batch [1410]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.171400,	
2017-07-25 18:15:49,875 Epoch[8] Batch [1420]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.171348,	
2017-07-25 18:15:53,714 Epoch[8] Batch [1430]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.171389,	
2017-07-25 18:15:57,721 Epoch[8] Batch [1440]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.171188,	
2017-07-25 18:16:01,797 Epoch[8] Batch [1450]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.171322,	
2017-07-25 18:16:05,749 Epoch[8] Batch [1460]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.171161,	
2017-07-25 18:16:09,682 Epoch[8] Batch [1470]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.171163,	
2017-07-25 18:16:13,607 Epoch[8] Batch [1480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.171093,	
2017-07-25 18:16:15,937 Epoch[8] Train-FCNLogLoss=0.171028
2017-07-25 18:16:15,938 Epoch[8] Time cost=586.336
2017-07-25 18:16:16,715 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.params"
2017-07-25 18:16:18,320 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0009.states"
2017-07-25 18:16:22,943 Epoch[9] Batch [10]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.175485,	
2017-07-25 18:16:26,867 Epoch[9] Batch [20]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.161696,	
2017-07-25 18:16:30,883 Epoch[9] Batch [30]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.159318,	
2017-07-25 18:16:34,812 Epoch[9] Batch [40]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.157984,	
2017-07-25 18:16:38,709 Epoch[9] Batch [50]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.159241,	
2017-07-25 18:16:42,508 Epoch[9] Batch [60]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.162134,	
2017-07-25 18:16:46,434 Epoch[9] Batch [70]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.162143,	
2017-07-25 18:16:50,362 Epoch[9] Batch [80]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.161861,	
2017-07-25 18:16:54,199 Epoch[9] Batch [90]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.159632,	
2017-07-25 18:16:58,061 Epoch[9] Batch [100]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.159808,	
2017-07-25 18:17:01,955 Epoch[9] Batch [110]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.160645,	
2017-07-25 18:17:05,876 Epoch[9] Batch [120]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.161180,	
2017-07-25 18:17:09,976 Epoch[9] Batch [130]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.159557,	
2017-07-25 18:17:13,928 Epoch[9] Batch [140]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.160640,	
2017-07-25 18:17:17,787 Epoch[9] Batch [150]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.161662,	
2017-07-25 18:17:21,714 Epoch[9] Batch [160]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.163349,	
2017-07-25 18:17:25,607 Epoch[9] Batch [170]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.163637,	
2017-07-25 18:17:29,396 Epoch[9] Batch [180]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.163778,	
2017-07-25 18:17:33,361 Epoch[9] Batch [190]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.162762,	
2017-07-25 18:17:37,318 Epoch[9] Batch [200]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.162773,	
2017-07-25 18:17:41,303 Epoch[9] Batch [210]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.162777,	
2017-07-25 18:17:45,129 Epoch[9] Batch [220]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.163765,	
2017-07-25 18:17:49,049 Epoch[9] Batch [230]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.163577,	
2017-07-25 18:17:52,918 Epoch[9] Batch [240]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.163125,	
2017-07-25 18:17:56,745 Epoch[9] Batch [250]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.164028,	
2017-07-25 18:18:00,641 Epoch[9] Batch [260]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.164373,	
2017-07-25 18:18:04,451 Epoch[9] Batch [270]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.165214,	
2017-07-25 18:18:08,358 Epoch[9] Batch [280]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.165432,	
2017-07-25 18:18:12,290 Epoch[9] Batch [290]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.164451,	
2017-07-25 18:18:16,178 Epoch[9] Batch [300]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.164100,	
2017-07-25 18:18:20,079 Epoch[9] Batch [310]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.163797,	
2017-07-25 18:18:24,053 Epoch[9] Batch [320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.164252,	
2017-07-25 18:18:27,883 Epoch[9] Batch [330]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.163617,	
2017-07-25 18:18:31,796 Epoch[9] Batch [340]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.163136,	
2017-07-25 18:18:35,592 Epoch[9] Batch [350]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.163181,	
2017-07-25 18:18:39,469 Epoch[9] Batch [360]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.162961,	
2017-07-25 18:18:43,503 Epoch[9] Batch [370]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.162444,	
2017-07-25 18:18:47,373 Epoch[9] Batch [380]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.163272,	
2017-07-25 18:18:51,310 Epoch[9] Batch [390]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.163162,	
2017-07-25 18:18:55,237 Epoch[9] Batch [400]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.163724,	
2017-07-25 18:18:59,132 Epoch[9] Batch [410]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.163346,	
2017-07-25 18:19:02,946 Epoch[9] Batch [420]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.163614,	
2017-07-25 18:19:06,878 Epoch[9] Batch [430]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.162794,	
2017-07-25 18:19:10,747 Epoch[9] Batch [440]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.163036,	
2017-07-25 18:19:14,627 Epoch[9] Batch [450]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.162987,	
2017-07-25 18:19:18,565 Epoch[9] Batch [460]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.163099,	
2017-07-25 18:19:22,378 Epoch[9] Batch [470]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.162699,	
2017-07-25 18:19:26,401 Epoch[9] Batch [480]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.163295,	
2017-07-25 18:19:30,402 Epoch[9] Batch [490]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.163414,	
2017-07-25 18:19:34,309 Epoch[9] Batch [500]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.163767,	
2017-07-25 18:19:38,216 Epoch[9] Batch [510]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.164240,	
2017-07-25 18:19:42,169 Epoch[9] Batch [520]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.164422,	
2017-07-25 18:19:46,060 Epoch[9] Batch [530]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.164545,	
2017-07-25 18:19:49,930 Epoch[9] Batch [540]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.164093,	
2017-07-25 18:19:53,801 Epoch[9] Batch [550]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.163822,	
2017-07-25 18:19:57,591 Epoch[9] Batch [560]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.163706,	
2017-07-25 18:20:01,625 Epoch[9] Batch [570]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.163628,	
2017-07-25 18:20:05,411 Epoch[9] Batch [580]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.163728,	
2017-07-25 18:20:09,328 Epoch[9] Batch [590]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.163715,	
2017-07-25 18:20:13,213 Epoch[9] Batch [600]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.163277,	
2017-07-25 18:20:17,078 Epoch[9] Batch [610]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.162776,	
2017-07-25 18:20:20,990 Epoch[9] Batch [620]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.162473,	
2017-07-25 18:20:24,950 Epoch[9] Batch [630]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.162279,	
2017-07-25 18:20:28,767 Epoch[9] Batch [640]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.161677,	
2017-07-25 18:20:32,565 Epoch[9] Batch [650]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.161674,	
2017-07-25 18:20:36,397 Epoch[9] Batch [660]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.161810,	
2017-07-25 18:20:40,346 Epoch[9] Batch [670]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.161731,	
2017-07-25 18:20:44,242 Epoch[9] Batch [680]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.161892,	
2017-07-25 18:20:48,128 Epoch[9] Batch [690]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.162121,	
2017-07-25 18:20:52,193 Epoch[9] Batch [700]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.161930,	
2017-07-25 18:20:56,089 Epoch[9] Batch [710]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.161850,	
2017-07-25 18:20:59,978 Epoch[9] Batch [720]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.161815,	
2017-07-25 18:21:03,827 Epoch[9] Batch [730]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.162158,	
2017-07-25 18:21:07,618 Epoch[9] Batch [740]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.162096,	
2017-07-25 18:21:11,481 Epoch[9] Batch [750]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.161815,	
2017-07-25 18:21:15,316 Epoch[9] Batch [760]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.161506,	
2017-07-25 18:21:19,111 Epoch[9] Batch [770]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.161177,	
2017-07-25 18:21:22,954 Epoch[9] Batch [780]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.160862,	
2017-07-25 18:21:26,828 Epoch[9] Batch [790]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.160818,	
2017-07-25 18:21:30,787 Epoch[9] Batch [800]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.160648,	
2017-07-25 18:21:34,635 Epoch[9] Batch [810]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.160416,	
2017-07-25 18:21:38,490 Epoch[9] Batch [820]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.160212,	
2017-07-25 18:21:42,358 Epoch[9] Batch [830]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.160272,	
2017-07-25 18:21:46,213 Epoch[9] Batch [840]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.160238,	
2017-07-25 18:21:50,082 Epoch[9] Batch [850]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.160045,	
2017-07-25 18:21:54,012 Epoch[9] Batch [860]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.160006,	
2017-07-25 18:21:57,928 Epoch[9] Batch [870]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.160273,	
2017-07-25 18:22:01,840 Epoch[9] Batch [880]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.160237,	
2017-07-25 18:22:05,735 Epoch[9] Batch [890]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.160446,	
2017-07-25 18:22:09,700 Epoch[9] Batch [900]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.160657,	
2017-07-25 18:22:13,524 Epoch[9] Batch [910]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.160808,	
2017-07-25 18:22:17,475 Epoch[9] Batch [920]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.160843,	
2017-07-25 18:22:21,454 Epoch[9] Batch [930]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.160718,	
2017-07-25 18:22:25,358 Epoch[9] Batch [940]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.160581,	
2017-07-25 18:22:29,339 Epoch[9] Batch [950]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.161392,	
2017-07-25 18:22:33,404 Epoch[9] Batch [960]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.161586,	
2017-07-25 18:22:37,387 Epoch[9] Batch [970]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.161756,	
2017-07-25 18:22:41,222 Epoch[9] Batch [980]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.162189,	
2017-07-25 18:22:45,181 Epoch[9] Batch [990]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.162617,	
2017-07-25 18:22:49,127 Epoch[9] Batch [1000]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.162828,	
2017-07-25 18:22:53,028 Epoch[9] Batch [1010]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.163013,	
2017-07-25 18:22:57,003 Epoch[9] Batch [1020]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.163242,	
2017-07-25 18:23:01,150 Epoch[9] Batch [1030]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.163645,	
2017-07-25 18:23:05,042 Epoch[9] Batch [1040]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.163638,	
2017-07-25 18:23:09,036 Epoch[9] Batch [1050]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.163718,	
2017-07-25 18:23:13,000 Epoch[9] Batch [1060]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.163989,	
2017-07-25 18:23:16,980 Epoch[9] Batch [1070]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.164068,	
2017-07-25 18:23:20,991 Epoch[9] Batch [1080]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.163984,	
2017-07-25 18:23:24,836 Epoch[9] Batch [1090]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.164036,	
2017-07-25 18:23:28,847 Epoch[9] Batch [1100]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.163761,	
2017-07-25 18:23:32,847 Epoch[9] Batch [1110]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.163985,	
2017-07-25 18:23:36,888 Epoch[9] Batch [1120]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.163710,	
2017-07-25 18:23:40,941 Epoch[9] Batch [1130]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.163624,	
2017-07-25 18:23:44,897 Epoch[9] Batch [1140]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.163719,	
2017-07-25 18:23:48,857 Epoch[9] Batch [1150]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.163613,	
2017-07-25 18:23:52,726 Epoch[9] Batch [1160]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.163618,	
2017-07-25 18:23:56,622 Epoch[9] Batch [1170]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.163518,	
2017-07-25 18:24:00,612 Epoch[9] Batch [1180]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.163527,	
2017-07-25 18:24:04,644 Epoch[9] Batch [1190]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.163300,	
2017-07-25 18:24:08,799 Epoch[9] Batch [1200]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.163381,	
2017-07-25 18:24:12,817 Epoch[9] Batch [1210]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.163351,	
2017-07-25 18:24:16,907 Epoch[9] Batch [1220]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.163467,	
2017-07-25 18:24:20,793 Epoch[9] Batch [1230]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.163373,	
2017-07-25 18:24:24,749 Epoch[9] Batch [1240]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.163311,	
2017-07-25 18:24:28,818 Epoch[9] Batch [1250]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.163125,	
2017-07-25 18:24:32,752 Epoch[9] Batch [1260]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.163127,	
2017-07-25 18:24:36,692 Epoch[9] Batch [1270]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.163366,	
2017-07-25 18:24:40,663 Epoch[9] Batch [1280]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.163450,	
2017-07-25 18:24:44,562 Epoch[9] Batch [1290]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.163506,	
2017-07-25 18:24:48,534 Epoch[9] Batch [1300]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.163396,	
2017-07-25 18:24:52,457 Epoch[9] Batch [1310]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.163451,	
2017-07-25 18:24:56,477 Epoch[9] Batch [1320]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.163384,	
2017-07-25 18:25:00,410 Epoch[9] Batch [1330]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.163139,	
2017-07-25 18:25:04,380 Epoch[9] Batch [1340]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.162909,	
2017-07-25 18:25:08,335 Epoch[9] Batch [1350]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.162894,	
2017-07-25 18:25:12,204 Epoch[9] Batch [1360]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.162784,	
2017-07-25 18:25:16,167 Epoch[9] Batch [1370]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.163218,	
2017-07-25 18:25:20,273 Epoch[9] Batch [1380]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.163292,	
2017-07-25 18:25:24,306 Epoch[9] Batch [1390]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.163252,	
2017-07-25 18:25:28,312 Epoch[9] Batch [1400]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.163344,	
2017-07-25 18:25:32,191 Epoch[9] Batch [1410]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.163318,	
2017-07-25 18:25:36,168 Epoch[9] Batch [1420]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.163224,	
2017-07-25 18:25:40,149 Epoch[9] Batch [1430]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.163485,	
2017-07-25 18:25:44,066 Epoch[9] Batch [1440]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.163703,	
2017-07-25 18:25:48,050 Epoch[9] Batch [1450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.163773,	
2017-07-25 18:25:52,070 Epoch[9] Batch [1460]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.163760,	
2017-07-25 18:25:55,970 Epoch[9] Batch [1470]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.163898,	
2017-07-25 18:25:59,904 Epoch[9] Batch [1480]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.163959,	
2017-07-25 18:26:02,328 Epoch[9] Train-FCNLogLoss=0.163880
2017-07-25 18:26:02,328 Epoch[9] Time cost=584.007
2017-07-25 18:26:03,030 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.params"
2017-07-25 18:26:04,568 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0010.states"
2017-07-25 18:26:09,351 Epoch[10] Batch [10]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.155316,	
2017-07-25 18:26:13,365 Epoch[10] Batch [20]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.162389,	
2017-07-25 18:26:17,263 Epoch[10] Batch [30]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.170413,	
2017-07-25 18:26:21,184 Epoch[10] Batch [40]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.175151,	
2017-07-25 18:26:25,207 Epoch[10] Batch [50]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.167902,	
2017-07-25 18:26:29,234 Epoch[10] Batch [60]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.161730,	
2017-07-25 18:26:33,218 Epoch[10] Batch [70]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.159368,	
2017-07-25 18:26:37,211 Epoch[10] Batch [80]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.160341,	
2017-07-25 18:26:41,252 Epoch[10] Batch [90]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.161062,	
2017-07-25 18:26:45,235 Epoch[10] Batch [100]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.158377,	
2017-07-25 18:26:49,239 Epoch[10] Batch [110]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.157887,	
2017-07-25 18:26:53,241 Epoch[10] Batch [120]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.157054,	
2017-07-25 18:26:57,229 Epoch[10] Batch [130]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.156030,	
2017-07-25 18:27:01,269 Epoch[10] Batch [140]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.156525,	
2017-07-25 18:27:05,241 Epoch[10] Batch [150]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.156410,	
2017-07-25 18:27:09,198 Epoch[10] Batch [160]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.156487,	
2017-07-25 18:27:13,225 Epoch[10] Batch [170]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.157230,	
2017-07-25 18:27:17,237 Epoch[10] Batch [180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.157461,	
2017-07-25 18:27:21,269 Epoch[10] Batch [190]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.160979,	
2017-07-25 18:27:25,155 Epoch[10] Batch [200]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.162378,	
2017-07-25 18:27:29,219 Epoch[10] Batch [210]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.165816,	
2017-07-25 18:27:33,146 Epoch[10] Batch [220]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.168507,	
2017-07-25 18:27:37,108 Epoch[10] Batch [230]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.169221,	
2017-07-25 18:27:40,930 Epoch[10] Batch [240]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.168945,	
2017-07-25 18:27:44,851 Epoch[10] Batch [250]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.168518,	
2017-07-25 18:27:48,768 Epoch[10] Batch [260]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.168064,	
2017-07-25 18:27:52,689 Epoch[10] Batch [270]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.167475,	
2017-07-25 18:27:56,704 Epoch[10] Batch [280]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.167049,	
2017-07-25 18:28:00,681 Epoch[10] Batch [290]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.167560,	
2017-07-25 18:28:04,666 Epoch[10] Batch [300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.166852,	
2017-07-25 18:28:08,623 Epoch[10] Batch [310]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.166572,	
2017-07-25 18:28:12,576 Epoch[10] Batch [320]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.166031,	
2017-07-25 18:28:16,478 Epoch[10] Batch [330]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.165836,	
2017-07-25 18:28:20,476 Epoch[10] Batch [340]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.165938,	
2017-07-25 18:28:24,393 Epoch[10] Batch [350]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.165790,	
2017-07-25 18:28:28,366 Epoch[10] Batch [360]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.165359,	
2017-07-25 18:28:32,303 Epoch[10] Batch [370]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.164930,	
2017-07-25 18:28:36,264 Epoch[10] Batch [380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.164848,	
2017-07-25 18:28:40,322 Epoch[10] Batch [390]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.164312,	
2017-07-25 18:28:44,302 Epoch[10] Batch [400]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.164051,	
2017-07-25 18:28:48,165 Epoch[10] Batch [410]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.164071,	
2017-07-25 18:28:52,100 Epoch[10] Batch [420]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.163347,	
2017-07-25 18:28:56,047 Epoch[10] Batch [430]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.162667,	
2017-07-25 18:28:59,987 Epoch[10] Batch [440]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.162289,	
2017-07-25 18:29:04,024 Epoch[10] Batch [450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.162071,	
2017-07-25 18:29:08,044 Epoch[10] Batch [460]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.161927,	
2017-07-25 18:29:12,012 Epoch[10] Batch [470]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.161650,	
2017-07-25 18:29:15,970 Epoch[10] Batch [480]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.161378,	
2017-07-25 18:29:19,991 Epoch[10] Batch [490]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.160927,	
2017-07-25 18:29:23,882 Epoch[10] Batch [500]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.161084,	
2017-07-25 18:29:27,787 Epoch[10] Batch [510]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.161280,	
2017-07-25 18:29:31,773 Epoch[10] Batch [520]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.161060,	
2017-07-25 18:29:35,716 Epoch[10] Batch [530]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.161189,	
2017-07-25 18:29:39,686 Epoch[10] Batch [540]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.161001,	
2017-07-25 18:29:43,619 Epoch[10] Batch [550]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.160600,	
2017-07-25 18:29:47,645 Epoch[10] Batch [560]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.160993,	
2017-07-25 18:29:51,714 Epoch[10] Batch [570]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.160920,	
2017-07-25 18:29:55,621 Epoch[10] Batch [580]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.160537,	
2017-07-25 18:29:59,652 Epoch[10] Batch [590]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.160388,	
2017-07-25 18:30:03,729 Epoch[10] Batch [600]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.160108,	
2017-07-25 18:30:07,897 Epoch[10] Batch [610]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.159878,	
2017-07-25 18:30:11,792 Epoch[10] Batch [620]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.159736,	
2017-07-25 18:30:15,745 Epoch[10] Batch [630]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.159882,	
2017-07-25 18:30:19,694 Epoch[10] Batch [640]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.160122,	
2017-07-25 18:30:23,643 Epoch[10] Batch [650]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.160139,	
2017-07-25 18:30:27,575 Epoch[10] Batch [660]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.160135,	
2017-07-25 18:30:31,552 Epoch[10] Batch [670]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.160247,	
2017-07-25 18:30:35,536 Epoch[10] Batch [680]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.160154,	
2017-07-25 18:30:39,533 Epoch[10] Batch [690]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.160250,	
2017-07-25 18:30:43,571 Epoch[10] Batch [700]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.160345,	
2017-07-25 18:30:47,494 Epoch[10] Batch [710]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.160541,	
2017-07-25 18:30:51,486 Epoch[10] Batch [720]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.160699,	
2017-07-25 18:30:55,486 Epoch[10] Batch [730]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.160396,	
2017-07-25 18:30:59,504 Epoch[10] Batch [740]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.160408,	
2017-07-25 18:31:03,388 Epoch[10] Batch [750]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.160515,	
2017-07-25 18:31:07,454 Epoch[10] Batch [760]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.160520,	
2017-07-25 18:31:11,372 Epoch[10] Batch [770]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.161104,	
2017-07-25 18:31:15,276 Epoch[10] Batch [780]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.162570,	
2017-07-25 18:31:19,208 Epoch[10] Batch [790]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.163293,	
2017-07-25 18:31:23,058 Epoch[10] Batch [800]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.163293,	
2017-07-25 18:31:26,903 Epoch[10] Batch [810]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.163868,	
2017-07-25 18:31:30,859 Epoch[10] Batch [820]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.163821,	
2017-07-25 18:31:34,752 Epoch[10] Batch [830]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.163971,	
2017-07-25 18:31:38,583 Epoch[10] Batch [840]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.163676,	
2017-07-25 18:31:42,506 Epoch[10] Batch [850]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.163634,	
2017-07-25 18:31:46,385 Epoch[10] Batch [860]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.163779,	
2017-07-25 18:31:50,431 Epoch[10] Batch [870]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.163723,	
2017-07-25 18:31:54,341 Epoch[10] Batch [880]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.163541,	
2017-07-25 18:31:58,273 Epoch[10] Batch [890]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.163382,	
2017-07-25 18:32:02,150 Epoch[10] Batch [900]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.163413,	
2017-07-25 18:32:06,110 Epoch[10] Batch [910]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.163121,	
2017-07-25 18:32:10,023 Epoch[10] Batch [920]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.163200,	
2017-07-25 18:32:13,940 Epoch[10] Batch [930]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.163027,	
2017-07-25 18:32:17,808 Epoch[10] Batch [940]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.162896,	
2017-07-25 18:32:21,702 Epoch[10] Batch [950]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.162920,	
2017-07-25 18:32:25,587 Epoch[10] Batch [960]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.162826,	
2017-07-25 18:32:29,558 Epoch[10] Batch [970]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.162663,	
2017-07-25 18:32:33,407 Epoch[10] Batch [980]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.162457,	
2017-07-25 18:32:37,385 Epoch[10] Batch [990]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.162299,	
2017-07-25 18:32:41,334 Epoch[10] Batch [1000]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.162368,	
2017-07-25 18:32:45,249 Epoch[10] Batch [1010]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.162188,	
2017-07-25 18:32:49,199 Epoch[10] Batch [1020]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.162163,	
2017-07-25 18:32:53,008 Epoch[10] Batch [1030]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.162185,	
2017-07-25 18:32:56,980 Epoch[10] Batch [1040]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.162071,	
2017-07-25 18:33:00,881 Epoch[10] Batch [1050]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.161829,	
2017-07-25 18:33:04,771 Epoch[10] Batch [1060]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.161881,	
2017-07-25 18:33:08,634 Epoch[10] Batch [1070]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.161902,	
2017-07-25 18:33:12,580 Epoch[10] Batch [1080]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.162037,	
2017-07-25 18:33:16,490 Epoch[10] Batch [1090]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.162160,	
2017-07-25 18:33:20,491 Epoch[10] Batch [1100]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.162265,	
2017-07-25 18:33:24,434 Epoch[10] Batch [1110]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.162037,	
2017-07-25 18:33:28,384 Epoch[10] Batch [1120]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.162124,	
2017-07-25 18:33:32,294 Epoch[10] Batch [1130]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.161920,	
2017-07-25 18:33:36,172 Epoch[10] Batch [1140]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.161764,	
2017-07-25 18:33:40,092 Epoch[10] Batch [1150]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.161930,	
2017-07-25 18:33:44,012 Epoch[10] Batch [1160]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.161803,	
2017-07-25 18:33:47,905 Epoch[10] Batch [1170]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.161840,	
2017-07-25 18:33:51,819 Epoch[10] Batch [1180]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.161838,	
2017-07-25 18:33:55,756 Epoch[10] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.161828,	
2017-07-25 18:33:59,717 Epoch[10] Batch [1200]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.161704,	
2017-07-25 18:34:03,569 Epoch[10] Batch [1210]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.161467,	
2017-07-25 18:34:07,494 Epoch[10] Batch [1220]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.161602,	
2017-07-25 18:34:11,397 Epoch[10] Batch [1230]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.161553,	
2017-07-25 18:34:15,305 Epoch[10] Batch [1240]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.161810,	
2017-07-25 18:34:19,067 Epoch[10] Batch [1250]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.161777,	
2017-07-25 18:34:22,959 Epoch[10] Batch [1260]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.162034,	
2017-07-25 18:34:26,968 Epoch[10] Batch [1270]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.161950,	
2017-07-25 18:34:30,839 Epoch[10] Batch [1280]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.161849,	
2017-07-25 18:34:34,819 Epoch[10] Batch [1290]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.161757,	
2017-07-25 18:34:38,658 Epoch[10] Batch [1300]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.161710,	
2017-07-25 18:34:42,547 Epoch[10] Batch [1310]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.161453,	
2017-07-25 18:34:46,459 Epoch[10] Batch [1320]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.161196,	
2017-07-25 18:34:50,501 Epoch[10] Batch [1330]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.161063,	
2017-07-25 18:34:54,364 Epoch[10] Batch [1340]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.160954,	
2017-07-25 18:34:58,391 Epoch[10] Batch [1350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.160829,	
2017-07-25 18:35:02,321 Epoch[10] Batch [1360]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.160786,	
2017-07-25 18:35:06,286 Epoch[10] Batch [1370]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.160764,	
2017-07-25 18:35:10,195 Epoch[10] Batch [1380]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.160682,	
2017-07-25 18:35:14,098 Epoch[10] Batch [1390]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.160748,	
2017-07-25 18:35:18,108 Epoch[10] Batch [1400]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.160709,	
2017-07-25 18:35:21,984 Epoch[10] Batch [1410]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.160788,	
2017-07-25 18:35:25,879 Epoch[10] Batch [1420]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.160697,	
2017-07-25 18:35:29,807 Epoch[10] Batch [1430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.160760,	
2017-07-25 18:35:33,620 Epoch[10] Batch [1440]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.160977,	
2017-07-25 18:35:37,515 Epoch[10] Batch [1450]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.161067,	
2017-07-25 18:35:41,292 Epoch[10] Batch [1460]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.160938,	
2017-07-25 18:35:45,130 Epoch[10] Batch [1470]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.160842,	
2017-07-25 18:35:48,962 Epoch[10] Batch [1480]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.160898,	
2017-07-25 18:35:51,269 Epoch[10] Train-FCNLogLoss=0.160925
2017-07-25 18:35:51,269 Epoch[10] Time cost=586.701
2017-07-25 18:35:51,967 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.params"
2017-07-25 18:35:53,408 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0011.states"
2017-07-25 18:35:58,064 Epoch[11] Batch [10]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.182300,	
2017-07-25 18:36:01,990 Epoch[11] Batch [20]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.187881,	
2017-07-25 18:36:05,848 Epoch[11] Batch [30]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.189061,	
2017-07-25 18:36:09,797 Epoch[11] Batch [40]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.184038,	
2017-07-25 18:36:13,723 Epoch[11] Batch [50]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.185564,	
2017-07-25 18:36:17,649 Epoch[11] Batch [60]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.181980,	
2017-07-25 18:36:21,567 Epoch[11] Batch [70]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.180967,	
2017-07-25 18:36:25,528 Epoch[11] Batch [80]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.180177,	
2017-07-25 18:36:29,435 Epoch[11] Batch [90]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.179503,	
2017-07-25 18:36:33,379 Epoch[11] Batch [100]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.179545,	
2017-07-25 18:36:37,320 Epoch[11] Batch [110]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.177793,	
2017-07-25 18:36:41,215 Epoch[11] Batch [120]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.175051,	
2017-07-25 18:36:45,116 Epoch[11] Batch [130]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.175725,	
2017-07-25 18:36:48,970 Epoch[11] Batch [140]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.176545,	
2017-07-25 18:36:52,861 Epoch[11] Batch [150]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.177621,	
2017-07-25 18:36:56,656 Epoch[11] Batch [160]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.177020,	
2017-07-25 18:37:00,532 Epoch[11] Batch [170]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.176510,	
2017-07-25 18:37:04,411 Epoch[11] Batch [180]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.175629,	
2017-07-25 18:37:08,469 Epoch[11] Batch [190]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.174435,	
2017-07-25 18:37:12,312 Epoch[11] Batch [200]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.172478,	
2017-07-25 18:37:16,222 Epoch[11] Batch [210]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.171020,	
2017-07-25 18:37:20,086 Epoch[11] Batch [220]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.170373,	
2017-07-25 18:37:23,918 Epoch[11] Batch [230]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.169219,	
2017-07-25 18:37:27,851 Epoch[11] Batch [240]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.168508,	
2017-07-25 18:37:31,749 Epoch[11] Batch [250]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.169036,	
2017-07-25 18:37:35,764 Epoch[11] Batch [260]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.168969,	
2017-07-25 18:37:39,714 Epoch[11] Batch [270]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.169199,	
2017-07-25 18:37:43,666 Epoch[11] Batch [280]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.167984,	
2017-07-25 18:37:47,552 Epoch[11] Batch [290]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.166776,	
2017-07-25 18:37:51,504 Epoch[11] Batch [300]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.167697,	
2017-07-25 18:37:55,395 Epoch[11] Batch [310]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.167096,	
2017-07-25 18:37:59,281 Epoch[11] Batch [320]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.166392,	
2017-07-25 18:38:03,241 Epoch[11] Batch [330]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.166362,	
2017-07-25 18:38:07,135 Epoch[11] Batch [340]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.165982,	
2017-07-25 18:38:11,051 Epoch[11] Batch [350]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.165620,	
2017-07-25 18:38:15,008 Epoch[11] Batch [360]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.165560,	
2017-07-25 18:38:18,943 Epoch[11] Batch [370]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.165093,	
2017-07-25 18:38:22,813 Epoch[11] Batch [380]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.164723,	
2017-07-25 18:38:26,655 Epoch[11] Batch [390]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.164527,	
2017-07-25 18:38:30,593 Epoch[11] Batch [400]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.163518,	
2017-07-25 18:38:34,450 Epoch[11] Batch [410]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.163735,	
2017-07-25 18:38:38,246 Epoch[11] Batch [420]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.163428,	
2017-07-25 18:38:42,195 Epoch[11] Batch [430]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.163149,	
2017-07-25 18:38:46,145 Epoch[11] Batch [440]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.163104,	
2017-07-25 18:38:49,988 Epoch[11] Batch [450]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.162973,	
2017-07-25 18:38:53,918 Epoch[11] Batch [460]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.162527,	
2017-07-25 18:38:57,850 Epoch[11] Batch [470]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.162250,	
2017-07-25 18:39:01,760 Epoch[11] Batch [480]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.161959,	
2017-07-25 18:39:05,713 Epoch[11] Batch [490]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.161972,	
2017-07-25 18:39:09,650 Epoch[11] Batch [500]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.161650,	
2017-07-25 18:39:13,524 Epoch[11] Batch [510]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.161046,	
2017-07-25 18:39:17,351 Epoch[11] Batch [520]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.161054,	
2017-07-25 18:39:21,297 Epoch[11] Batch [530]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.161013,	
2017-07-25 18:39:25,202 Epoch[11] Batch [540]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.161379,	
2017-07-25 18:39:29,140 Epoch[11] Batch [550]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.161545,	
2017-07-25 18:39:33,046 Epoch[11] Batch [560]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.161491,	
2017-07-25 18:39:37,031 Epoch[11] Batch [570]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.161476,	
2017-07-25 18:39:40,897 Epoch[11] Batch [580]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.161160,	
2017-07-25 18:39:44,892 Epoch[11] Batch [590]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.161120,	
2017-07-25 18:39:48,819 Epoch[11] Batch [600]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.160668,	
2017-07-25 18:39:52,841 Epoch[11] Batch [610]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.160747,	
2017-07-25 18:39:56,802 Epoch[11] Batch [620]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.160483,	
2017-07-25 18:40:00,750 Epoch[11] Batch [630]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.160390,	
2017-07-25 18:40:04,617 Epoch[11] Batch [640]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.160764,	
2017-07-25 18:40:08,582 Epoch[11] Batch [650]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.160818,	
2017-07-25 18:40:12,573 Epoch[11] Batch [660]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.160850,	
2017-07-25 18:40:16,557 Epoch[11] Batch [670]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.160707,	
2017-07-25 18:40:20,542 Epoch[11] Batch [680]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.160739,	
2017-07-25 18:40:24,370 Epoch[11] Batch [690]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.161070,	
2017-07-25 18:40:28,313 Epoch[11] Batch [700]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.160893,	
2017-07-25 18:40:32,199 Epoch[11] Batch [710]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.161377,	
2017-07-25 18:40:36,099 Epoch[11] Batch [720]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.161335,	
2017-07-25 18:40:39,986 Epoch[11] Batch [730]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.161025,	
2017-07-25 18:40:43,874 Epoch[11] Batch [740]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.161019,	
2017-07-25 18:40:47,806 Epoch[11] Batch [750]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.161463,	
2017-07-25 18:40:51,705 Epoch[11] Batch [760]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.162190,	
2017-07-25 18:40:55,479 Epoch[11] Batch [770]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.161989,	
2017-07-25 18:40:59,348 Epoch[11] Batch [780]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.161877,	
2017-07-25 18:41:03,315 Epoch[11] Batch [790]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.161708,	
2017-07-25 18:41:07,343 Epoch[11] Batch [800]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.161766,	
2017-07-25 18:41:11,345 Epoch[11] Batch [810]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.161747,	
2017-07-25 18:41:15,351 Epoch[11] Batch [820]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.161447,	
2017-07-25 18:41:19,373 Epoch[11] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.161186,	
2017-07-25 18:41:23,327 Epoch[11] Batch [840]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.160863,	
2017-07-25 18:41:27,235 Epoch[11] Batch [850]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.160889,	
2017-07-25 18:41:31,137 Epoch[11] Batch [860]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.160803,	
2017-07-25 18:41:35,172 Epoch[11] Batch [870]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.160839,	
2017-07-25 18:41:39,021 Epoch[11] Batch [880]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.161011,	
2017-07-25 18:41:42,970 Epoch[11] Batch [890]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.160703,	
2017-07-25 18:41:46,853 Epoch[11] Batch [900]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.160584,	
2017-07-25 18:41:50,759 Epoch[11] Batch [910]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.160317,	
2017-07-25 18:41:54,620 Epoch[11] Batch [920]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.160152,	
2017-07-25 18:41:58,578 Epoch[11] Batch [930]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.159958,	
2017-07-25 18:42:02,376 Epoch[11] Batch [940]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.159784,	
2017-07-25 18:42:06,271 Epoch[11] Batch [950]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.159818,	
2017-07-25 18:42:10,192 Epoch[11] Batch [960]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.159573,	
2017-07-25 18:42:14,030 Epoch[11] Batch [970]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.159379,	
2017-07-25 18:42:18,014 Epoch[11] Batch [980]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.159360,	
2017-07-25 18:42:21,877 Epoch[11] Batch [990]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.159332,	
2017-07-25 18:42:25,836 Epoch[11] Batch [1000]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.159451,	
2017-07-25 18:42:29,780 Epoch[11] Batch [1010]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.159413,	
2017-07-25 18:42:33,702 Epoch[11] Batch [1020]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.159207,	
2017-07-25 18:42:37,607 Epoch[11] Batch [1030]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.159136,	
2017-07-25 18:42:41,562 Epoch[11] Batch [1040]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.159134,	
2017-07-25 18:42:45,379 Epoch[11] Batch [1050]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.159175,	
2017-07-25 18:42:49,448 Epoch[11] Batch [1060]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.159032,	
2017-07-25 18:42:53,409 Epoch[11] Batch [1070]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.158943,	
2017-07-25 18:42:57,415 Epoch[11] Batch [1080]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.158896,	
2017-07-25 18:43:01,267 Epoch[11] Batch [1090]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.158757,	
2017-07-25 18:43:05,258 Epoch[11] Batch [1100]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.158747,	
2017-07-25 18:43:09,180 Epoch[11] Batch [1110]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.158783,	
2017-07-25 18:43:13,021 Epoch[11] Batch [1120]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.158692,	
2017-07-25 18:43:16,833 Epoch[11] Batch [1130]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.158541,	
2017-07-25 18:43:20,758 Epoch[11] Batch [1140]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.158686,	
2017-07-25 18:43:24,575 Epoch[11] Batch [1150]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.158727,	
2017-07-25 18:43:28,531 Epoch[11] Batch [1160]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.158625,	
2017-07-25 18:43:32,401 Epoch[11] Batch [1170]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.158749,	
2017-07-25 18:43:36,242 Epoch[11] Batch [1180]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.158778,	
2017-07-25 18:43:40,142 Epoch[11] Batch [1190]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.158639,	
2017-07-25 18:43:44,025 Epoch[11] Batch [1200]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.158511,	
2017-07-25 18:43:47,891 Epoch[11] Batch [1210]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.158673,	
2017-07-25 18:43:51,744 Epoch[11] Batch [1220]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.158810,	
2017-07-25 18:43:55,700 Epoch[11] Batch [1230]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.158749,	
2017-07-25 18:43:59,738 Epoch[11] Batch [1240]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.158687,	
2017-07-25 18:44:03,743 Epoch[11] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.158816,	
2017-07-25 18:44:07,645 Epoch[11] Batch [1260]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.158721,	
2017-07-25 18:44:11,582 Epoch[11] Batch [1270]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.158565,	
2017-07-25 18:44:15,505 Epoch[11] Batch [1280]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.158290,	
2017-07-25 18:44:19,369 Epoch[11] Batch [1290]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.158864,	
2017-07-25 18:44:23,291 Epoch[11] Batch [1300]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.159150,	
2017-07-25 18:44:27,334 Epoch[11] Batch [1310]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.159399,	
2017-07-25 18:44:31,237 Epoch[11] Batch [1320]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.159501,	
2017-07-25 18:44:35,142 Epoch[11] Batch [1330]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.159459,	
2017-07-25 18:44:39,008 Epoch[11] Batch [1340]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.159343,	
2017-07-25 18:44:42,907 Epoch[11] Batch [1350]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.159379,	
2017-07-25 18:44:46,720 Epoch[11] Batch [1360]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.159306,	
2017-07-25 18:44:50,521 Epoch[11] Batch [1370]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.159458,	
2017-07-25 18:44:54,487 Epoch[11] Batch [1380]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.159458,	
2017-07-25 18:44:58,457 Epoch[11] Batch [1390]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.159414,	
2017-07-25 18:45:02,307 Epoch[11] Batch [1400]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.159424,	
2017-07-25 18:45:06,164 Epoch[11] Batch [1410]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.159418,	
2017-07-25 18:45:10,013 Epoch[11] Batch [1420]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.159392,	
2017-07-25 18:45:13,941 Epoch[11] Batch [1430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.159416,	
2017-07-25 18:45:17,890 Epoch[11] Batch [1440]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.159553,	
2017-07-25 18:45:21,764 Epoch[11] Batch [1450]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.159725,	
2017-07-25 18:45:25,648 Epoch[11] Batch [1460]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.159575,	
2017-07-25 18:45:29,513 Epoch[11] Batch [1470]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.159629,	
2017-07-25 18:45:33,436 Epoch[11] Batch [1480]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.159822,	
2017-07-25 18:45:35,721 Epoch[11] Train-FCNLogLoss=0.159754
2017-07-25 18:45:35,721 Epoch[11] Time cost=582.312
2017-07-25 18:45:36,439 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.params"
2017-07-25 18:45:37,893 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0012.states"
2017-07-25 18:45:42,639 Epoch[12] Batch [10]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.142959,	
2017-07-25 18:45:46,602 Epoch[12] Batch [20]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.147515,	
2017-07-25 18:45:50,521 Epoch[12] Batch [30]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.140772,	
2017-07-25 18:45:54,413 Epoch[12] Batch [40]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.142932,	
2017-07-25 18:45:58,311 Epoch[12] Batch [50]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.143850,	
2017-07-25 18:46:02,260 Epoch[12] Batch [60]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.143159,	
2017-07-25 18:46:06,269 Epoch[12] Batch [70]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.143389,	
2017-07-25 18:46:10,185 Epoch[12] Batch [80]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.145685,	
2017-07-25 18:46:14,141 Epoch[12] Batch [90]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.144544,	
2017-07-25 18:46:18,169 Epoch[12] Batch [100]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.145237,	
2017-07-25 18:46:22,043 Epoch[12] Batch [110]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.146261,	
2017-07-25 18:46:26,042 Epoch[12] Batch [120]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.147351,	
2017-07-25 18:46:29,866 Epoch[12] Batch [130]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.146734,	
2017-07-25 18:46:33,775 Epoch[12] Batch [140]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.145889,	
2017-07-25 18:46:37,655 Epoch[12] Batch [150]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.144862,	
2017-07-25 18:46:41,582 Epoch[12] Batch [160]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.144237,	
2017-07-25 18:46:45,515 Epoch[12] Batch [170]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.144214,	
2017-07-25 18:46:49,423 Epoch[12] Batch [180]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.144757,	
2017-07-25 18:46:53,272 Epoch[12] Batch [190]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.145826,	
2017-07-25 18:46:57,163 Epoch[12] Batch [200]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.145984,	
2017-07-25 18:47:01,099 Epoch[12] Batch [210]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.146486,	
2017-07-25 18:47:04,933 Epoch[12] Batch [220]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.147036,	
2017-07-25 18:47:08,902 Epoch[12] Batch [230]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.146621,	
2017-07-25 18:47:13,016 Epoch[12] Batch [240]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.146071,	
2017-07-25 18:47:16,896 Epoch[12] Batch [250]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.146936,	
2017-07-25 18:47:20,784 Epoch[12] Batch [260]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.146761,	
2017-07-25 18:47:24,726 Epoch[12] Batch [270]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.146875,	
2017-07-25 18:47:28,578 Epoch[12] Batch [280]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.147574,	
2017-07-25 18:47:32,442 Epoch[12] Batch [290]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.147876,	
2017-07-25 18:47:36,584 Epoch[12] Batch [300]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.148003,	
2017-07-25 18:47:40,541 Epoch[12] Batch [310]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.148432,	
2017-07-25 18:47:44,367 Epoch[12] Batch [320]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.148390,	
2017-07-25 18:47:48,401 Epoch[12] Batch [330]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.148590,	
2017-07-25 18:47:52,471 Epoch[12] Batch [340]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.148281,	
2017-07-25 18:47:56,437 Epoch[12] Batch [350]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.148235,	
2017-07-25 18:48:00,304 Epoch[12] Batch [360]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.147746,	
2017-07-25 18:48:04,264 Epoch[12] Batch [370]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.148614,	
2017-07-25 18:48:08,176 Epoch[12] Batch [380]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.149180,	
2017-07-25 18:48:12,164 Epoch[12] Batch [390]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.149311,	
2017-07-25 18:48:16,102 Epoch[12] Batch [400]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.149830,	
2017-07-25 18:48:19,949 Epoch[12] Batch [410]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.150032,	
2017-07-25 18:48:23,877 Epoch[12] Batch [420]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.150712,	
2017-07-25 18:48:27,812 Epoch[12] Batch [430]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.151443,	
2017-07-25 18:48:31,754 Epoch[12] Batch [440]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.151753,	
2017-07-25 18:48:35,738 Epoch[12] Batch [450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.151884,	
2017-07-25 18:48:39,733 Epoch[12] Batch [460]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.151962,	
2017-07-25 18:48:43,626 Epoch[12] Batch [470]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.151917,	
2017-07-25 18:48:47,461 Epoch[12] Batch [480]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.152531,	
2017-07-25 18:48:51,427 Epoch[12] Batch [490]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.152637,	
2017-07-25 18:48:55,329 Epoch[12] Batch [500]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.152451,	
2017-07-25 18:48:59,322 Epoch[12] Batch [510]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.152402,	
2017-07-25 18:49:03,220 Epoch[12] Batch [520]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.152213,	
2017-07-25 18:49:07,161 Epoch[12] Batch [530]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.151952,	
2017-07-25 18:49:11,089 Epoch[12] Batch [540]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.152927,	
2017-07-25 18:49:15,034 Epoch[12] Batch [550]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.153030,	
2017-07-25 18:49:18,987 Epoch[12] Batch [560]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.153026,	
2017-07-25 18:49:22,974 Epoch[12] Batch [570]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.152831,	
2017-07-25 18:49:26,939 Epoch[12] Batch [580]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.152780,	
2017-07-25 18:49:30,892 Epoch[12] Batch [590]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.152777,	
2017-07-25 18:49:34,809 Epoch[12] Batch [600]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.152331,	
2017-07-25 18:49:38,722 Epoch[12] Batch [610]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.152076,	
2017-07-25 18:49:42,772 Epoch[12] Batch [620]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.151702,	
2017-07-25 18:49:46,830 Epoch[12] Batch [630]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.151737,	
2017-07-25 18:49:50,809 Epoch[12] Batch [640]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.152022,	
2017-07-25 18:49:54,845 Epoch[12] Batch [650]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.152246,	
2017-07-25 18:49:58,777 Epoch[12] Batch [660]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.152109,	
2017-07-25 18:50:02,711 Epoch[12] Batch [670]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.151935,	
2017-07-25 18:50:06,675 Epoch[12] Batch [680]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.151862,	
2017-07-25 18:50:10,599 Epoch[12] Batch [690]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.152230,	
2017-07-25 18:50:14,425 Epoch[12] Batch [700]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.152488,	
2017-07-25 18:50:18,345 Epoch[12] Batch [710]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.152563,	
2017-07-25 18:50:22,311 Epoch[12] Batch [720]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.152634,	
2017-07-25 18:50:26,212 Epoch[12] Batch [730]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.152289,	
2017-07-25 18:50:30,157 Epoch[12] Batch [740]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.152549,	
2017-07-25 18:50:34,103 Epoch[12] Batch [750]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.152310,	
2017-07-25 18:50:38,006 Epoch[12] Batch [760]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.152125,	
2017-07-25 18:50:41,865 Epoch[12] Batch [770]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.151909,	
2017-07-25 18:50:45,816 Epoch[12] Batch [780]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.151645,	
2017-07-25 18:50:49,762 Epoch[12] Batch [790]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.151567,	
2017-07-25 18:50:53,656 Epoch[12] Batch [800]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.151494,	
2017-07-25 18:50:57,605 Epoch[12] Batch [810]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.151612,	
2017-07-25 18:51:01,563 Epoch[12] Batch [820]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.152068,	
2017-07-25 18:51:05,450 Epoch[12] Batch [830]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.151933,	
2017-07-25 18:51:09,390 Epoch[12] Batch [840]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.151835,	
2017-07-25 18:51:13,382 Epoch[12] Batch [850]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.151690,	
2017-07-25 18:51:17,295 Epoch[12] Batch [860]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.151968,	
2017-07-25 18:51:21,194 Epoch[12] Batch [870]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.151905,	
2017-07-25 18:51:25,152 Epoch[12] Batch [880]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.151802,	
2017-07-25 18:51:29,021 Epoch[12] Batch [890]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.151913,	
2017-07-25 18:51:33,101 Epoch[12] Batch [900]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.152074,	
2017-07-25 18:51:37,061 Epoch[12] Batch [910]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.151949,	
2017-07-25 18:51:40,898 Epoch[12] Batch [920]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.151951,	
2017-07-25 18:51:44,830 Epoch[12] Batch [930]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.152248,	
2017-07-25 18:51:48,771 Epoch[12] Batch [940]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.152778,	
2017-07-25 18:51:52,669 Epoch[12] Batch [950]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.152689,	
2017-07-25 18:51:56,523 Epoch[12] Batch [960]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.152746,	
2017-07-25 18:52:00,367 Epoch[12] Batch [970]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.153049,	
2017-07-25 18:52:04,227 Epoch[12] Batch [980]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.153212,	
2017-07-25 18:52:08,195 Epoch[12] Batch [990]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.153273,	
2017-07-25 18:52:12,092 Epoch[12] Batch [1000]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.153312,	
2017-07-25 18:52:15,918 Epoch[12] Batch [1010]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.153226,	
2017-07-25 18:52:19,758 Epoch[12] Batch [1020]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.153230,	
2017-07-25 18:52:23,655 Epoch[12] Batch [1030]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.153173,	
2017-07-25 18:52:27,620 Epoch[12] Batch [1040]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.153045,	
2017-07-25 18:52:31,578 Epoch[12] Batch [1050]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.153199,	
2017-07-25 18:52:35,355 Epoch[12] Batch [1060]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.153095,	
2017-07-25 18:52:39,273 Epoch[12] Batch [1070]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.153149,	
2017-07-25 18:52:43,231 Epoch[12] Batch [1080]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.153107,	
2017-07-25 18:52:47,098 Epoch[12] Batch [1090]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.152969,	
2017-07-25 18:52:51,062 Epoch[12] Batch [1100]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.152805,	
2017-07-25 18:52:55,026 Epoch[12] Batch [1110]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.152666,	
2017-07-25 18:52:58,920 Epoch[12] Batch [1120]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.152548,	
2017-07-25 18:53:02,821 Epoch[12] Batch [1130]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.152538,	
2017-07-25 18:53:06,744 Epoch[12] Batch [1140]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.152425,	
2017-07-25 18:53:10,666 Epoch[12] Batch [1150]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.152480,	
2017-07-25 18:53:14,509 Epoch[12] Batch [1160]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.152734,	
2017-07-25 18:53:18,445 Epoch[12] Batch [1170]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.152561,	
2017-07-25 18:53:22,301 Epoch[12] Batch [1180]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.152784,	
2017-07-25 18:53:26,239 Epoch[12] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.152837,	
2017-07-25 18:53:30,109 Epoch[12] Batch [1200]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.152714,	
2017-07-25 18:53:34,125 Epoch[12] Batch [1210]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.152774,	
2017-07-25 18:53:38,110 Epoch[12] Batch [1220]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.152685,	
2017-07-25 18:53:42,044 Epoch[12] Batch [1230]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.152587,	
2017-07-25 18:53:45,986 Epoch[12] Batch [1240]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.152746,	
2017-07-25 18:53:49,902 Epoch[12] Batch [1250]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.152721,	
2017-07-25 18:53:53,740 Epoch[12] Batch [1260]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.152681,	
2017-07-25 18:53:57,598 Epoch[12] Batch [1270]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.152569,	
2017-07-25 18:54:01,425 Epoch[12] Batch [1280]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.152390,	
2017-07-25 18:54:05,393 Epoch[12] Batch [1290]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.152288,	
2017-07-25 18:54:09,259 Epoch[12] Batch [1300]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.152021,	
2017-07-25 18:54:13,285 Epoch[12] Batch [1310]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.151828,	
2017-07-25 18:54:17,237 Epoch[12] Batch [1320]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.151825,	
2017-07-25 18:54:21,244 Epoch[12] Batch [1330]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.151845,	
2017-07-25 18:54:25,081 Epoch[12] Batch [1340]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.151749,	
2017-07-25 18:54:29,134 Epoch[12] Batch [1350]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.151666,	
2017-07-25 18:54:33,005 Epoch[12] Batch [1360]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.151726,	
2017-07-25 18:54:36,850 Epoch[12] Batch [1370]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.151723,	
2017-07-25 18:54:40,700 Epoch[12] Batch [1380]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.151715,	
2017-07-25 18:54:44,741 Epoch[12] Batch [1390]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.151798,	
2017-07-25 18:54:48,685 Epoch[12] Batch [1400]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.151710,	
2017-07-25 18:54:52,630 Epoch[12] Batch [1410]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.151637,	
2017-07-25 18:54:56,550 Epoch[12] Batch [1420]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.151591,	
2017-07-25 18:55:00,552 Epoch[12] Batch [1430]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.151522,	
2017-07-25 18:55:04,533 Epoch[12] Batch [1440]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.151502,	
2017-07-25 18:55:08,536 Epoch[12] Batch [1450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.151425,	
2017-07-25 18:55:12,462 Epoch[12] Batch [1460]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.151257,	
2017-07-25 18:55:16,391 Epoch[12] Batch [1470]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.151244,	
2017-07-25 18:55:20,333 Epoch[12] Batch [1480]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.151379,	
2017-07-25 18:55:22,730 Epoch[12] Train-FCNLogLoss=0.151394
2017-07-25 18:55:22,731 Epoch[12] Time cost=584.837
2017-07-25 18:55:23,506 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.params"
2017-07-25 18:55:25,251 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0013.states"
2017-07-25 18:55:29,935 Epoch[13] Batch [10]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.152915,	
2017-07-25 18:55:33,839 Epoch[13] Batch [20]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.157531,	
2017-07-25 18:55:37,764 Epoch[13] Batch [30]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.158871,	
2017-07-25 18:55:41,658 Epoch[13] Batch [40]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.153394,	
2017-07-25 18:55:45,522 Epoch[13] Batch [50]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.147456,	
2017-07-25 18:55:49,444 Epoch[13] Batch [60]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.147476,	
2017-07-25 18:55:53,355 Epoch[13] Batch [70]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.149614,	
2017-07-25 18:55:57,255 Epoch[13] Batch [80]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.149591,	
2017-07-25 18:56:01,098 Epoch[13] Batch [90]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.149374,	
2017-07-25 18:56:05,053 Epoch[13] Batch [100]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.148184,	
2017-07-25 18:56:08,991 Epoch[13] Batch [110]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.146258,	
2017-07-25 18:56:12,929 Epoch[13] Batch [120]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.145106,	
2017-07-25 18:56:16,825 Epoch[13] Batch [130]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.144437,	
2017-07-25 18:56:20,749 Epoch[13] Batch [140]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.143617,	
2017-07-25 18:56:24,578 Epoch[13] Batch [150]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.142772,	
2017-07-25 18:56:28,482 Epoch[13] Batch [160]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.142060,	
2017-07-25 18:56:32,367 Epoch[13] Batch [170]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.143308,	
2017-07-25 18:56:36,397 Epoch[13] Batch [180]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.143877,	
2017-07-25 18:56:40,234 Epoch[13] Batch [190]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.143821,	
2017-07-25 18:56:44,198 Epoch[13] Batch [200]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.144550,	
2017-07-25 18:56:48,077 Epoch[13] Batch [210]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.144530,	
2017-07-25 18:56:51,968 Epoch[13] Batch [220]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.144300,	
2017-07-25 18:56:55,848 Epoch[13] Batch [230]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.144179,	
2017-07-25 18:56:59,820 Epoch[13] Batch [240]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.143741,	
2017-07-25 18:57:03,740 Epoch[13] Batch [250]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.143616,	
2017-07-25 18:57:07,506 Epoch[13] Batch [260]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.143049,	
2017-07-25 18:57:11,458 Epoch[13] Batch [270]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.143221,	
2017-07-25 18:57:15,423 Epoch[13] Batch [280]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.143163,	
2017-07-25 18:57:19,355 Epoch[13] Batch [290]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.143015,	
2017-07-25 18:57:23,442 Epoch[13] Batch [300]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.144235,	
2017-07-25 18:57:27,262 Epoch[13] Batch [310]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.144620,	
2017-07-25 18:57:31,196 Epoch[13] Batch [320]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.144515,	
2017-07-25 18:57:35,067 Epoch[13] Batch [330]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.144318,	
2017-07-25 18:57:39,077 Epoch[13] Batch [340]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.144235,	
2017-07-25 18:57:43,012 Epoch[13] Batch [350]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.144156,	
2017-07-25 18:57:46,930 Epoch[13] Batch [360]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.145206,	
2017-07-25 18:57:50,830 Epoch[13] Batch [370]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.145578,	
2017-07-25 18:57:54,801 Epoch[13] Batch [380]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.146828,	
2017-07-25 18:57:58,771 Epoch[13] Batch [390]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.146789,	
2017-07-25 18:58:02,797 Epoch[13] Batch [400]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.146339,	
2017-07-25 18:58:06,710 Epoch[13] Batch [410]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.146236,	
2017-07-25 18:58:10,589 Epoch[13] Batch [420]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.146710,	
2017-07-25 18:58:14,427 Epoch[13] Batch [430]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.146961,	
2017-07-25 18:58:18,247 Epoch[13] Batch [440]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.147000,	
2017-07-25 18:58:22,103 Epoch[13] Batch [450]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.147385,	
2017-07-25 18:58:26,027 Epoch[13] Batch [460]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.147946,	
2017-07-25 18:58:29,985 Epoch[13] Batch [470]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.147866,	
2017-07-25 18:58:34,022 Epoch[13] Batch [480]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.147367,	
2017-07-25 18:58:37,965 Epoch[13] Batch [490]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.147195,	
2017-07-25 18:58:41,839 Epoch[13] Batch [500]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.147262,	
2017-07-25 18:58:45,749 Epoch[13] Batch [510]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.147751,	
2017-07-25 18:58:49,612 Epoch[13] Batch [520]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.147650,	
2017-07-25 18:58:53,631 Epoch[13] Batch [530]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.147388,	
2017-07-25 18:58:57,511 Epoch[13] Batch [540]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.146900,	
2017-07-25 18:59:01,333 Epoch[13] Batch [550]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.146891,	
2017-07-25 18:59:05,226 Epoch[13] Batch [560]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.146758,	
2017-07-25 18:59:09,102 Epoch[13] Batch [570]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.146622,	
2017-07-25 18:59:13,083 Epoch[13] Batch [580]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.146736,	
2017-07-25 18:59:17,032 Epoch[13] Batch [590]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.146789,	
2017-07-25 18:59:20,988 Epoch[13] Batch [600]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.146683,	
2017-07-25 18:59:24,993 Epoch[13] Batch [610]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.146280,	
2017-07-25 18:59:28,958 Epoch[13] Batch [620]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.146254,	
2017-07-25 18:59:32,904 Epoch[13] Batch [630]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.146234,	
2017-07-25 18:59:36,874 Epoch[13] Batch [640]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.146105,	
2017-07-25 18:59:40,724 Epoch[13] Batch [650]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.146103,	
2017-07-25 18:59:44,690 Epoch[13] Batch [660]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.146053,	
2017-07-25 18:59:48,792 Epoch[13] Batch [670]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.146013,	
2017-07-25 18:59:52,668 Epoch[13] Batch [680]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.145812,	
2017-07-25 18:59:56,635 Epoch[13] Batch [690]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.145694,	
2017-07-25 19:00:00,549 Epoch[13] Batch [700]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.145974,	
2017-07-25 19:00:04,501 Epoch[13] Batch [710]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.146492,	
2017-07-25 19:00:08,364 Epoch[13] Batch [720]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.146484,	
2017-07-25 19:00:12,230 Epoch[13] Batch [730]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.146775,	
2017-07-25 19:00:16,265 Epoch[13] Batch [740]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.146921,	
2017-07-25 19:00:20,259 Epoch[13] Batch [750]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.147166,	
2017-07-25 19:00:24,286 Epoch[13] Batch [760]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.147235,	
2017-07-25 19:00:28,202 Epoch[13] Batch [770]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.147909,	
2017-07-25 19:00:32,152 Epoch[13] Batch [780]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.148558,	
2017-07-25 19:00:36,132 Epoch[13] Batch [790]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.148606,	
2017-07-25 19:00:40,036 Epoch[13] Batch [800]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.148635,	
2017-07-25 19:00:43,992 Epoch[13] Batch [810]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.148694,	
2017-07-25 19:00:47,889 Epoch[13] Batch [820]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.149141,	
2017-07-25 19:00:51,797 Epoch[13] Batch [830]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.149091,	
2017-07-25 19:00:55,779 Epoch[13] Batch [840]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.149059,	
2017-07-25 19:00:59,719 Epoch[13] Batch [850]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.149028,	
2017-07-25 19:01:03,675 Epoch[13] Batch [860]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.149166,	
2017-07-25 19:01:07,665 Epoch[13] Batch [870]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.149219,	
2017-07-25 19:01:11,591 Epoch[13] Batch [880]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.149117,	
2017-07-25 19:01:15,524 Epoch[13] Batch [890]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.149336,	
2017-07-25 19:01:19,404 Epoch[13] Batch [900]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.149505,	
2017-07-25 19:01:23,321 Epoch[13] Batch [910]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.149463,	
2017-07-25 19:01:27,116 Epoch[13] Batch [920]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.149401,	
2017-07-25 19:01:31,080 Epoch[13] Batch [930]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.149111,	
2017-07-25 19:01:35,100 Epoch[13] Batch [940]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.149128,	
2017-07-25 19:01:38,929 Epoch[13] Batch [950]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.149211,	
2017-07-25 19:01:42,863 Epoch[13] Batch [960]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.149200,	
2017-07-25 19:01:46,739 Epoch[13] Batch [970]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.149230,	
2017-07-25 19:01:50,657 Epoch[13] Batch [980]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.149108,	
2017-07-25 19:01:54,530 Epoch[13] Batch [990]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.149150,	
2017-07-25 19:01:58,380 Epoch[13] Batch [1000]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.148983,	
2017-07-25 19:02:02,303 Epoch[13] Batch [1010]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.149502,	
2017-07-25 19:02:06,284 Epoch[13] Batch [1020]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.149418,	
2017-07-25 19:02:10,188 Epoch[13] Batch [1030]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.149542,	
2017-07-25 19:02:14,111 Epoch[13] Batch [1040]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.149583,	
2017-07-25 19:02:18,098 Epoch[13] Batch [1050]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.149766,	
2017-07-25 19:02:21,950 Epoch[13] Batch [1060]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.149699,	
2017-07-25 19:02:25,810 Epoch[13] Batch [1070]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.149543,	
2017-07-25 19:02:29,585 Epoch[13] Batch [1080]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.149281,	
2017-07-25 19:02:33,594 Epoch[13] Batch [1090]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.149192,	
2017-07-25 19:02:37,556 Epoch[13] Batch [1100]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.149111,	
2017-07-25 19:02:41,531 Epoch[13] Batch [1110]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.148996,	
2017-07-25 19:02:45,507 Epoch[13] Batch [1120]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.148881,	
2017-07-25 19:02:49,422 Epoch[13] Batch [1130]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.148951,	
2017-07-25 19:02:53,301 Epoch[13] Batch [1140]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.148940,	
2017-07-25 19:02:57,250 Epoch[13] Batch [1150]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.149065,	
2017-07-25 19:03:01,247 Epoch[13] Batch [1160]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.148977,	
2017-07-25 19:03:05,211 Epoch[13] Batch [1170]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.148934,	
2017-07-25 19:03:09,152 Epoch[13] Batch [1180]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.149042,	
2017-07-25 19:03:13,040 Epoch[13] Batch [1190]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.148942,	
2017-07-25 19:03:16,884 Epoch[13] Batch [1200]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.148809,	
2017-07-25 19:03:20,850 Epoch[13] Batch [1210]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.148696,	
2017-07-25 19:03:24,863 Epoch[13] Batch [1220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.148699,	
2017-07-25 19:03:28,830 Epoch[13] Batch [1230]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.148781,	
2017-07-25 19:03:32,750 Epoch[13] Batch [1240]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.148695,	
2017-07-25 19:03:36,664 Epoch[13] Batch [1250]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.148626,	
2017-07-25 19:03:40,681 Epoch[13] Batch [1260]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.148565,	
2017-07-25 19:03:44,633 Epoch[13] Batch [1270]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.148263,	
2017-07-25 19:03:48,586 Epoch[13] Batch [1280]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.148457,	
2017-07-25 19:03:52,579 Epoch[13] Batch [1290]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.148304,	
2017-07-25 19:03:56,512 Epoch[13] Batch [1300]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.148136,	
2017-07-25 19:04:00,515 Epoch[13] Batch [1310]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.148148,	
2017-07-25 19:04:04,465 Epoch[13] Batch [1320]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.148191,	
2017-07-25 19:04:08,378 Epoch[13] Batch [1330]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.148039,	
2017-07-25 19:04:12,159 Epoch[13] Batch [1340]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.148049,	
2017-07-25 19:04:16,153 Epoch[13] Batch [1350]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.147911,	
2017-07-25 19:04:20,029 Epoch[13] Batch [1360]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.147969,	
2017-07-25 19:04:23,844 Epoch[13] Batch [1370]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.147916,	
2017-07-25 19:04:27,806 Epoch[13] Batch [1380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.147986,	
2017-07-25 19:04:31,736 Epoch[13] Batch [1390]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.148159,	
2017-07-25 19:04:35,588 Epoch[13] Batch [1400]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.147948,	
2017-07-25 19:04:39,643 Epoch[13] Batch [1410]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.148050,	
2017-07-25 19:04:43,638 Epoch[13] Batch [1420]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.148183,	
2017-07-25 19:04:47,658 Epoch[13] Batch [1430]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.148529,	
2017-07-25 19:04:51,420 Epoch[13] Batch [1440]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.148573,	
2017-07-25 19:04:55,490 Epoch[13] Batch [1450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.148875,	
2017-07-25 19:04:59,498 Epoch[13] Batch [1460]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.148825,	
2017-07-25 19:05:03,338 Epoch[13] Batch [1470]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.148698,	
2017-07-25 19:05:07,216 Epoch[13] Batch [1480]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.148768,	
2017-07-25 19:05:09,555 Epoch[13] Train-FCNLogLoss=0.148776
2017-07-25 19:05:09,556 Epoch[13] Time cost=584.304
2017-07-25 19:05:10,232 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.params"
2017-07-25 19:05:11,804 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0014.states"
2017-07-25 19:05:16,475 Epoch[14] Batch [10]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.127214,	
2017-07-25 19:05:20,421 Epoch[14] Batch [20]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.135324,	
2017-07-25 19:05:24,397 Epoch[14] Batch [30]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.137676,	
2017-07-25 19:05:28,284 Epoch[14] Batch [40]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.147417,	
2017-07-25 19:05:32,184 Epoch[14] Batch [50]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.148892,	
2017-07-25 19:05:35,975 Epoch[14] Batch [60]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.150040,	
2017-07-25 19:05:39,930 Epoch[14] Batch [70]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.148972,	
2017-07-25 19:05:43,791 Epoch[14] Batch [80]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.149530,	
2017-07-25 19:05:47,667 Epoch[14] Batch [90]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.149736,	
2017-07-25 19:05:51,493 Epoch[14] Batch [100]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.150697,	
2017-07-25 19:05:55,473 Epoch[14] Batch [110]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.148722,	
2017-07-25 19:05:59,349 Epoch[14] Batch [120]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.147935,	
2017-07-25 19:06:03,270 Epoch[14] Batch [130]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.147763,	
2017-07-25 19:06:07,237 Epoch[14] Batch [140]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.147816,	
2017-07-25 19:06:11,206 Epoch[14] Batch [150]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.146622,	
2017-07-25 19:06:15,095 Epoch[14] Batch [160]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.148376,	
2017-07-25 19:06:19,039 Epoch[14] Batch [170]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.149340,	
2017-07-25 19:06:22,907 Epoch[14] Batch [180]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.149124,	
2017-07-25 19:06:26,746 Epoch[14] Batch [190]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.149045,	
2017-07-25 19:06:30,716 Epoch[14] Batch [200]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.149596,	
2017-07-25 19:06:34,598 Epoch[14] Batch [210]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.149067,	
2017-07-25 19:06:38,439 Epoch[14] Batch [220]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.149568,	
2017-07-25 19:06:42,446 Epoch[14] Batch [230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.149999,	
2017-07-25 19:06:46,403 Epoch[14] Batch [240]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.149604,	
2017-07-25 19:06:50,318 Epoch[14] Batch [250]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.149662,	
2017-07-25 19:06:54,219 Epoch[14] Batch [260]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.149628,	
2017-07-25 19:06:58,131 Epoch[14] Batch [270]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.148747,	
2017-07-25 19:07:02,026 Epoch[14] Batch [280]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.148257,	
2017-07-25 19:07:05,974 Epoch[14] Batch [290]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.148846,	
2017-07-25 19:07:09,854 Epoch[14] Batch [300]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.149352,	
2017-07-25 19:07:13,754 Epoch[14] Batch [310]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.149807,	
2017-07-25 19:07:17,659 Epoch[14] Batch [320]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.149519,	
2017-07-25 19:07:21,549 Epoch[14] Batch [330]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.149446,	
2017-07-25 19:07:25,565 Epoch[14] Batch [340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.149717,	
2017-07-25 19:07:29,528 Epoch[14] Batch [350]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.149228,	
2017-07-25 19:07:33,421 Epoch[14] Batch [360]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.148746,	
2017-07-25 19:07:37,321 Epoch[14] Batch [370]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.148616,	
2017-07-25 19:07:41,229 Epoch[14] Batch [380]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.147655,	
2017-07-25 19:07:45,139 Epoch[14] Batch [390]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.147672,	
2017-07-25 19:07:49,121 Epoch[14] Batch [400]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.147403,	
2017-07-25 19:07:53,054 Epoch[14] Batch [410]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.147220,	
2017-07-25 19:07:56,947 Epoch[14] Batch [420]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.147418,	
2017-07-25 19:08:00,949 Epoch[14] Batch [430]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.147075,	
2017-07-25 19:08:04,839 Epoch[14] Batch [440]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.146769,	
2017-07-25 19:08:08,718 Epoch[14] Batch [450]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.147140,	
2017-07-25 19:08:12,729 Epoch[14] Batch [460]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.146859,	
2017-07-25 19:08:16,609 Epoch[14] Batch [470]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.146632,	
2017-07-25 19:08:20,489 Epoch[14] Batch [480]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.146560,	
2017-07-25 19:08:24,411 Epoch[14] Batch [490]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.146433,	
2017-07-25 19:08:28,378 Epoch[14] Batch [500]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.146420,	
2017-07-25 19:08:32,333 Epoch[14] Batch [510]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.145747,	
2017-07-25 19:08:36,319 Epoch[14] Batch [520]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.145134,	
2017-07-25 19:08:40,307 Epoch[14] Batch [530]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.145231,	
2017-07-25 19:08:44,257 Epoch[14] Batch [540]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.145213,	
2017-07-25 19:08:48,192 Epoch[14] Batch [550]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.144918,	
2017-07-25 19:08:52,106 Epoch[14] Batch [560]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.144494,	
2017-07-25 19:08:55,958 Epoch[14] Batch [570]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.144554,	
2017-07-25 19:08:59,872 Epoch[14] Batch [580]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.144896,	
2017-07-25 19:09:03,868 Epoch[14] Batch [590]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.145067,	
2017-07-25 19:09:07,887 Epoch[14] Batch [600]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.144895,	
2017-07-25 19:09:11,981 Epoch[14] Batch [610]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.144907,	
2017-07-25 19:09:16,025 Epoch[14] Batch [620]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.145511,	
2017-07-25 19:09:19,822 Epoch[14] Batch [630]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.146177,	
2017-07-25 19:09:23,814 Epoch[14] Batch [640]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.145896,	
2017-07-25 19:09:27,758 Epoch[14] Batch [650]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.146348,	
2017-07-25 19:09:31,680 Epoch[14] Batch [660]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.146451,	
2017-07-25 19:09:35,525 Epoch[14] Batch [670]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.146540,	
2017-07-25 19:09:39,504 Epoch[14] Batch [680]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.146470,	
2017-07-25 19:09:43,424 Epoch[14] Batch [690]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.146245,	
2017-07-25 19:09:47,223 Epoch[14] Batch [700]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.146211,	
2017-07-25 19:09:51,126 Epoch[14] Batch [710]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.146100,	
2017-07-25 19:09:54,998 Epoch[14] Batch [720]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.145857,	
2017-07-25 19:09:58,899 Epoch[14] Batch [730]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.145734,	
2017-07-25 19:10:02,871 Epoch[14] Batch [740]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.145536,	
2017-07-25 19:10:06,787 Epoch[14] Batch [750]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.145146,	
2017-07-25 19:10:10,618 Epoch[14] Batch [760]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.144935,	
2017-07-25 19:10:14,532 Epoch[14] Batch [770]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.145029,	
2017-07-25 19:10:18,481 Epoch[14] Batch [780]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.144937,	
2017-07-25 19:10:22,399 Epoch[14] Batch [790]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.144792,	
2017-07-25 19:10:26,397 Epoch[14] Batch [800]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.144798,	
2017-07-25 19:10:30,289 Epoch[14] Batch [810]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.144728,	
2017-07-25 19:10:34,153 Epoch[14] Batch [820]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.144879,	
2017-07-25 19:10:38,073 Epoch[14] Batch [830]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.144781,	
2017-07-25 19:10:42,042 Epoch[14] Batch [840]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.144692,	
2017-07-25 19:10:45,948 Epoch[14] Batch [850]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.144848,	
2017-07-25 19:10:50,003 Epoch[14] Batch [860]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.145118,	
2017-07-25 19:10:53,944 Epoch[14] Batch [870]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.145469,	
2017-07-25 19:10:58,006 Epoch[14] Batch [880]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.145563,	
2017-07-25 19:11:02,001 Epoch[14] Batch [890]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.145560,	
2017-07-25 19:11:05,808 Epoch[14] Batch [900]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.145339,	
2017-07-25 19:11:09,757 Epoch[14] Batch [910]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.145424,	
2017-07-25 19:11:13,633 Epoch[14] Batch [920]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.145598,	
2017-07-25 19:11:17,619 Epoch[14] Batch [930]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.145468,	
2017-07-25 19:11:21,555 Epoch[14] Batch [940]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.145629,	
2017-07-25 19:11:25,462 Epoch[14] Batch [950]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.145602,	
2017-07-25 19:11:29,371 Epoch[14] Batch [960]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.145518,	
2017-07-25 19:11:33,337 Epoch[14] Batch [970]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.145318,	
2017-07-25 19:11:37,186 Epoch[14] Batch [980]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.145211,	
2017-07-25 19:11:41,100 Epoch[14] Batch [990]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.145114,	
2017-07-25 19:11:45,103 Epoch[14] Batch [1000]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.145187,	
2017-07-25 19:11:49,027 Epoch[14] Batch [1010]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.145227,	
2017-07-25 19:11:52,869 Epoch[14] Batch [1020]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.145049,	
2017-07-25 19:11:56,794 Epoch[14] Batch [1030]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.145135,	
2017-07-25 19:12:00,642 Epoch[14] Batch [1040]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.144981,	
2017-07-25 19:12:04,534 Epoch[14] Batch [1050]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.144760,	
2017-07-25 19:12:08,571 Epoch[14] Batch [1060]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.144673,	
2017-07-25 19:12:12,467 Epoch[14] Batch [1070]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.144545,	
2017-07-25 19:12:16,407 Epoch[14] Batch [1080]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.144643,	
2017-07-25 19:12:20,439 Epoch[14] Batch [1090]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.144503,	
2017-07-25 19:12:24,394 Epoch[14] Batch [1100]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.144659,	
2017-07-25 19:12:28,294 Epoch[14] Batch [1110]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.144638,	
2017-07-25 19:12:32,234 Epoch[14] Batch [1120]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.144490,	
2017-07-25 19:12:36,173 Epoch[14] Batch [1130]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.144522,	
2017-07-25 19:12:40,139 Epoch[14] Batch [1140]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.144401,	
2017-07-25 19:12:43,994 Epoch[14] Batch [1150]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.144194,	
2017-07-25 19:12:47,984 Epoch[14] Batch [1160]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.144001,	
2017-07-25 19:12:51,945 Epoch[14] Batch [1170]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.143839,	
2017-07-25 19:12:55,903 Epoch[14] Batch [1180]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.143806,	
2017-07-25 19:12:59,800 Epoch[14] Batch [1190]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.143761,	
2017-07-25 19:13:03,750 Epoch[14] Batch [1200]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.143641,	
2017-07-25 19:13:07,732 Epoch[14] Batch [1210]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.143820,	
2017-07-25 19:13:11,647 Epoch[14] Batch [1220]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.143897,	
2017-07-25 19:13:15,477 Epoch[14] Batch [1230]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.143979,	
2017-07-25 19:13:19,437 Epoch[14] Batch [1240]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.144042,	
2017-07-25 19:13:23,297 Epoch[14] Batch [1250]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.144110,	
2017-07-25 19:13:27,133 Epoch[14] Batch [1260]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.144168,	
2017-07-25 19:13:30,994 Epoch[14] Batch [1270]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.144298,	
2017-07-25 19:13:34,972 Epoch[14] Batch [1280]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.144377,	
2017-07-25 19:13:38,834 Epoch[14] Batch [1290]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.144321,	
2017-07-25 19:13:42,795 Epoch[14] Batch [1300]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.144193,	
2017-07-25 19:13:46,731 Epoch[14] Batch [1310]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.144183,	
2017-07-25 19:13:50,635 Epoch[14] Batch [1320]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.144292,	
2017-07-25 19:13:54,574 Epoch[14] Batch [1330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.144469,	
2017-07-25 19:13:58,549 Epoch[14] Batch [1340]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.144404,	
2017-07-25 19:14:02,414 Epoch[14] Batch [1350]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.144398,	
2017-07-25 19:14:06,262 Epoch[14] Batch [1360]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.144293,	
2017-07-25 19:14:10,229 Epoch[14] Batch [1370]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.144227,	
2017-07-25 19:14:14,087 Epoch[14] Batch [1380]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.144024,	
2017-07-25 19:14:18,047 Epoch[14] Batch [1390]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.144013,	
2017-07-25 19:14:21,902 Epoch[14] Batch [1400]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.144066,	
2017-07-25 19:14:25,852 Epoch[14] Batch [1410]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.144164,	
2017-07-25 19:14:29,811 Epoch[14] Batch [1420]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.144016,	
2017-07-25 19:14:33,658 Epoch[14] Batch [1430]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.143872,	
2017-07-25 19:14:37,608 Epoch[14] Batch [1440]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.143836,	
2017-07-25 19:14:41,482 Epoch[14] Batch [1450]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.143707,	
2017-07-25 19:14:45,390 Epoch[14] Batch [1460]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.143596,	
2017-07-25 19:14:49,308 Epoch[14] Batch [1470]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.143712,	
2017-07-25 19:14:53,260 Epoch[14] Batch [1480]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.143772,	
2017-07-25 19:14:55,629 Epoch[14] Train-FCNLogLoss=0.143692
2017-07-25 19:14:55,629 Epoch[14] Time cost=583.824
2017-07-25 19:14:56,303 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.params"
2017-07-25 19:14:57,841 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0015.states"
2017-07-25 19:15:02,565 Epoch[15] Batch [10]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.149954,	
2017-07-25 19:15:06,472 Epoch[15] Batch [20]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.144713,	
2017-07-25 19:15:10,414 Epoch[15] Batch [30]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.142155,	
2017-07-25 19:15:14,328 Epoch[15] Batch [40]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.139098,	
2017-07-25 19:15:18,225 Epoch[15] Batch [50]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.135299,	
2017-07-25 19:15:22,121 Epoch[15] Batch [60]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.134201,	
2017-07-25 19:15:26,068 Epoch[15] Batch [70]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.134351,	
2017-07-25 19:15:29,988 Epoch[15] Batch [80]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.133945,	
2017-07-25 19:15:33,917 Epoch[15] Batch [90]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.135686,	
2017-07-25 19:15:37,853 Epoch[15] Batch [100]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.134901,	
2017-07-25 19:15:41,972 Epoch[15] Batch [110]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.135807,	
2017-07-25 19:15:46,252 Epoch[15] Batch [120]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.137494,	
2017-07-25 19:15:50,590 Epoch[15] Batch [130]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.137783,	
2017-07-25 19:15:55,095 Epoch[15] Batch [140]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.138184,	
2017-07-25 19:15:59,123 Epoch[15] Batch [150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.138243,	
2017-07-25 19:16:02,929 Epoch[15] Batch [160]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.140275,	
2017-07-25 19:16:06,876 Epoch[15] Batch [170]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.144052,	
2017-07-25 19:16:10,778 Epoch[15] Batch [180]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.144675,	
2017-07-25 19:16:14,696 Epoch[15] Batch [190]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.145709,	
2017-07-25 19:16:18,691 Epoch[15] Batch [200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.146117,	
2017-07-25 19:16:22,645 Epoch[15] Batch [210]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.147947,	
2017-07-25 19:16:26,550 Epoch[15] Batch [220]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.148179,	
2017-07-25 19:16:30,439 Epoch[15] Batch [230]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.147228,	
2017-07-25 19:16:34,288 Epoch[15] Batch [240]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.146345,	
2017-07-25 19:16:38,228 Epoch[15] Batch [250]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.147174,	
2017-07-25 19:16:42,041 Epoch[15] Batch [260]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.147651,	
2017-07-25 19:16:45,907 Epoch[15] Batch [270]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.146696,	
2017-07-25 19:16:49,907 Epoch[15] Batch [280]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.147017,	
2017-07-25 19:16:53,774 Epoch[15] Batch [290]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.147673,	
2017-07-25 19:16:57,631 Epoch[15] Batch [300]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.147917,	
2017-07-25 19:17:01,616 Epoch[15] Batch [310]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.147218,	
2017-07-25 19:17:05,555 Epoch[15] Batch [320]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.146782,	
2017-07-25 19:17:09,432 Epoch[15] Batch [330]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.146246,	
2017-07-25 19:17:13,355 Epoch[15] Batch [340]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.147235,	
2017-07-25 19:17:17,342 Epoch[15] Batch [350]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.146427,	
2017-07-25 19:17:21,348 Epoch[15] Batch [360]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.146077,	
2017-07-25 19:17:25,270 Epoch[15] Batch [370]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.146311,	
2017-07-25 19:17:29,173 Epoch[15] Batch [380]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.146206,	
2017-07-25 19:17:33,153 Epoch[15] Batch [390]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.146037,	
2017-07-25 19:17:37,028 Epoch[15] Batch [400]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.145938,	
2017-07-25 19:17:40,896 Epoch[15] Batch [410]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.146230,	
2017-07-25 19:17:44,746 Epoch[15] Batch [420]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.145888,	
2017-07-25 19:17:48,724 Epoch[15] Batch [430]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.145570,	
2017-07-25 19:17:52,646 Epoch[15] Batch [440]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.145482,	
2017-07-25 19:17:56,713 Epoch[15] Batch [450]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.145641,	
2017-07-25 19:18:00,740 Epoch[15] Batch [460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.145636,	
2017-07-25 19:18:04,604 Epoch[15] Batch [470]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.145451,	
2017-07-25 19:18:08,528 Epoch[15] Batch [480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.144986,	
2017-07-25 19:18:12,426 Epoch[15] Batch [490]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.144527,	
2017-07-25 19:18:16,358 Epoch[15] Batch [500]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.144411,	
2017-07-25 19:18:20,225 Epoch[15] Batch [510]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.144267,	
2017-07-25 19:18:24,134 Epoch[15] Batch [520]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.144766,	
2017-07-25 19:18:28,011 Epoch[15] Batch [530]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.144815,	
2017-07-25 19:18:31,946 Epoch[15] Batch [540]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.145364,	
2017-07-25 19:18:35,884 Epoch[15] Batch [550]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.145307,	
2017-07-25 19:18:39,763 Epoch[15] Batch [560]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.145426,	
2017-07-25 19:18:43,712 Epoch[15] Batch [570]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.145751,	
2017-07-25 19:18:47,578 Epoch[15] Batch [580]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.145932,	
2017-07-25 19:18:51,528 Epoch[15] Batch [590]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.146078,	
2017-07-25 19:18:55,373 Epoch[15] Batch [600]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.146068,	
2017-07-25 19:18:59,294 Epoch[15] Batch [610]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.146318,	
2017-07-25 19:19:03,304 Epoch[15] Batch [620]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.146003,	
2017-07-25 19:19:07,178 Epoch[15] Batch [630]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.146069,	
2017-07-25 19:19:11,119 Epoch[15] Batch [640]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.146196,	
2017-07-25 19:19:15,007 Epoch[15] Batch [650]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.146147,	
2017-07-25 19:19:18,797 Epoch[15] Batch [660]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.146173,	
2017-07-25 19:19:22,790 Epoch[15] Batch [670]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.146095,	
2017-07-25 19:19:26,641 Epoch[15] Batch [680]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.145930,	
2017-07-25 19:19:30,424 Epoch[15] Batch [690]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.145782,	
2017-07-25 19:19:34,387 Epoch[15] Batch [700]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.145420,	
2017-07-25 19:19:38,289 Epoch[15] Batch [710]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.145595,	
2017-07-25 19:19:42,276 Epoch[15] Batch [720]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.145573,	
2017-07-25 19:19:46,194 Epoch[15] Batch [730]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.145259,	
2017-07-25 19:19:50,046 Epoch[15] Batch [740]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.145221,	
2017-07-25 19:19:54,088 Epoch[15] Batch [750]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.145065,	
2017-07-25 19:19:58,109 Epoch[15] Batch [760]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.145128,	
2017-07-25 19:20:02,055 Epoch[15] Batch [770]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.145031,	
2017-07-25 19:20:05,878 Epoch[15] Batch [780]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.144993,	
2017-07-25 19:20:09,729 Epoch[15] Batch [790]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.144906,	
2017-07-25 19:20:13,634 Epoch[15] Batch [800]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.144802,	
2017-07-25 19:20:17,610 Epoch[15] Batch [810]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.144296,	
2017-07-25 19:20:21,524 Epoch[15] Batch [820]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.144253,	
2017-07-25 19:20:25,442 Epoch[15] Batch [830]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.144012,	
2017-07-25 19:20:29,404 Epoch[15] Batch [840]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.144057,	
2017-07-25 19:20:33,390 Epoch[15] Batch [850]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.143923,	
2017-07-25 19:20:37,307 Epoch[15] Batch [860]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.143583,	
2017-07-25 19:20:41,316 Epoch[15] Batch [870]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.143345,	
2017-07-25 19:20:45,279 Epoch[15] Batch [880]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.143240,	
2017-07-25 19:20:49,238 Epoch[15] Batch [890]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.143202,	
2017-07-25 19:20:53,083 Epoch[15] Batch [900]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.143334,	
2017-07-25 19:20:56,948 Epoch[15] Batch [910]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.143132,	
2017-07-25 19:21:00,917 Epoch[15] Batch [920]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.142986,	
2017-07-25 19:21:04,865 Epoch[15] Batch [930]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.142779,	
2017-07-25 19:21:08,875 Epoch[15] Batch [940]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.142692,	
2017-07-25 19:21:12,760 Epoch[15] Batch [950]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.142648,	
2017-07-25 19:21:16,649 Epoch[15] Batch [960]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.142491,	
2017-07-25 19:21:20,462 Epoch[15] Batch [970]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.142379,	
2017-07-25 19:21:24,377 Epoch[15] Batch [980]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.142466,	
2017-07-25 19:21:28,288 Epoch[15] Batch [990]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.142497,	
2017-07-25 19:21:32,188 Epoch[15] Batch [1000]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.142699,	
2017-07-25 19:21:36,052 Epoch[15] Batch [1010]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.142546,	
2017-07-25 19:21:39,890 Epoch[15] Batch [1020]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.142416,	
2017-07-25 19:21:43,760 Epoch[15] Batch [1030]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.142275,	
2017-07-25 19:21:47,630 Epoch[15] Batch [1040]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.142260,	
2017-07-25 19:21:51,620 Epoch[15] Batch [1050]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.142144,	
2017-07-25 19:21:55,567 Epoch[15] Batch [1060]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.142155,	
2017-07-25 19:21:59,471 Epoch[15] Batch [1070]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.142203,	
2017-07-25 19:22:03,481 Epoch[15] Batch [1080]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.142409,	
2017-07-25 19:22:07,398 Epoch[15] Batch [1090]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.142459,	
2017-07-25 19:22:11,252 Epoch[15] Batch [1100]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.142436,	
2017-07-25 19:22:15,307 Epoch[15] Batch [1110]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.142269,	
2017-07-25 19:22:19,271 Epoch[15] Batch [1120]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.142398,	
2017-07-25 19:22:23,235 Epoch[15] Batch [1130]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.142570,	
2017-07-25 19:22:27,041 Epoch[15] Batch [1140]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.142637,	
2017-07-25 19:22:30,981 Epoch[15] Batch [1150]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.142538,	
2017-07-25 19:22:34,774 Epoch[15] Batch [1160]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.142466,	
2017-07-25 19:22:38,726 Epoch[15] Batch [1170]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.142486,	
2017-07-25 19:22:42,639 Epoch[15] Batch [1180]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.142427,	
2017-07-25 19:22:46,530 Epoch[15] Batch [1190]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.142539,	
2017-07-25 19:22:50,363 Epoch[15] Batch [1200]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.142565,	
2017-07-25 19:22:54,301 Epoch[15] Batch [1210]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.142558,	
2017-07-25 19:22:58,167 Epoch[15] Batch [1220]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.142557,	
2017-07-25 19:23:02,083 Epoch[15] Batch [1230]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.142459,	
2017-07-25 19:23:05,948 Epoch[15] Batch [1240]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.142553,	
2017-07-25 19:23:09,888 Epoch[15] Batch [1250]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.143161,	
2017-07-25 19:23:13,842 Epoch[15] Batch [1260]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.143241,	
2017-07-25 19:23:17,843 Epoch[15] Batch [1270]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.143161,	
2017-07-25 19:23:21,773 Epoch[15] Batch [1280]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.143065,	
2017-07-25 19:23:25,710 Epoch[15] Batch [1290]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.143050,	
2017-07-25 19:23:29,675 Epoch[15] Batch [1300]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.143099,	
2017-07-25 19:23:33,532 Epoch[15] Batch [1310]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.142893,	
2017-07-25 19:23:37,468 Epoch[15] Batch [1320]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.142982,	
2017-07-25 19:23:41,284 Epoch[15] Batch [1330]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.143100,	
2017-07-25 19:23:45,199 Epoch[15] Batch [1340]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.143270,	
2017-07-25 19:23:49,042 Epoch[15] Batch [1350]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.143434,	
2017-07-25 19:23:52,982 Epoch[15] Batch [1360]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.143441,	
2017-07-25 19:23:56,819 Epoch[15] Batch [1370]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.143761,	
2017-07-25 19:24:00,707 Epoch[15] Batch [1380]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.143810,	
2017-07-25 19:24:04,557 Epoch[15] Batch [1390]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.143880,	
2017-07-25 19:24:08,408 Epoch[15] Batch [1400]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.143754,	
2017-07-25 19:24:12,354 Epoch[15] Batch [1410]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.143747,	
2017-07-25 19:24:16,253 Epoch[15] Batch [1420]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.143841,	
2017-07-25 19:24:20,182 Epoch[15] Batch [1430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.143717,	
2017-07-25 19:24:24,009 Epoch[15] Batch [1440]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.143742,	
2017-07-25 19:24:28,002 Epoch[15] Batch [1450]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.143782,	
2017-07-25 19:24:31,899 Epoch[15] Batch [1460]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.143718,	
2017-07-25 19:24:35,791 Epoch[15] Batch [1470]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.143744,	
2017-07-25 19:24:39,649 Epoch[15] Batch [1480]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.143745,	
2017-07-25 19:24:41,991 Epoch[15] Train-FCNLogLoss=0.143699
2017-07-25 19:24:41,991 Epoch[15] Time cost=584.150
2017-07-25 19:24:42,707 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.params"
2017-07-25 19:24:44,165 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0016.states"
2017-07-25 19:24:48,775 Epoch[16] Batch [10]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.136855,	
2017-07-25 19:24:52,770 Epoch[16] Batch [20]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.140278,	
2017-07-25 19:24:56,648 Epoch[16] Batch [30]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.138088,	
2017-07-25 19:25:00,514 Epoch[16] Batch [40]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.135782,	
2017-07-25 19:25:04,374 Epoch[16] Batch [50]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.132915,	
2017-07-25 19:25:08,278 Epoch[16] Batch [60]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.131323,	
2017-07-25 19:25:12,175 Epoch[16] Batch [70]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.132283,	
2017-07-25 19:25:16,030 Epoch[16] Batch [80]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.130933,	
2017-07-25 19:25:19,866 Epoch[16] Batch [90]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.134785,	
2017-07-25 19:25:23,708 Epoch[16] Batch [100]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.134040,	
2017-07-25 19:25:27,669 Epoch[16] Batch [110]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.133367,	
2017-07-25 19:25:31,639 Epoch[16] Batch [120]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.134215,	
2017-07-25 19:25:35,585 Epoch[16] Batch [130]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.135078,	
2017-07-25 19:25:39,603 Epoch[16] Batch [140]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.135159,	
2017-07-25 19:25:43,552 Epoch[16] Batch [150]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.135161,	
2017-07-25 19:25:47,483 Epoch[16] Batch [160]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.135555,	
2017-07-25 19:25:51,427 Epoch[16] Batch [170]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.135425,	
2017-07-25 19:25:55,346 Epoch[16] Batch [180]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.136004,	
2017-07-25 19:25:59,292 Epoch[16] Batch [190]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.136626,	
2017-07-25 19:26:03,131 Epoch[16] Batch [200]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.138593,	
2017-07-25 19:26:07,100 Epoch[16] Batch [210]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.139967,	
2017-07-25 19:26:10,992 Epoch[16] Batch [220]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.140006,	
2017-07-25 19:26:14,949 Epoch[16] Batch [230]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.139833,	
2017-07-25 19:26:18,850 Epoch[16] Batch [240]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.139598,	
2017-07-25 19:26:22,722 Epoch[16] Batch [250]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.139197,	
2017-07-25 19:26:26,677 Epoch[16] Batch [260]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.139129,	
2017-07-25 19:26:30,504 Epoch[16] Batch [270]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.139184,	
2017-07-25 19:26:34,463 Epoch[16] Batch [280]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.138809,	
2017-07-25 19:26:38,420 Epoch[16] Batch [290]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.138507,	
2017-07-25 19:26:42,350 Epoch[16] Batch [300]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.137686,	
2017-07-25 19:26:46,439 Epoch[16] Batch [310]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.137637,	
2017-07-25 19:26:50,393 Epoch[16] Batch [320]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.137278,	
2017-07-25 19:26:54,260 Epoch[16] Batch [330]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.137926,	
2017-07-25 19:26:58,188 Epoch[16] Batch [340]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.137898,	
2017-07-25 19:27:02,209 Epoch[16] Batch [350]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.137823,	
2017-07-25 19:27:06,182 Epoch[16] Batch [360]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.138684,	
2017-07-25 19:27:10,075 Epoch[16] Batch [370]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.138573,	
2017-07-25 19:27:13,925 Epoch[16] Batch [380]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.138230,	
2017-07-25 19:27:17,835 Epoch[16] Batch [390]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.137937,	
2017-07-25 19:27:21,784 Epoch[16] Batch [400]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.137252,	
2017-07-25 19:27:25,606 Epoch[16] Batch [410]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.136796,	
2017-07-25 19:27:29,566 Epoch[16] Batch [420]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.137196,	
2017-07-25 19:27:33,550 Epoch[16] Batch [430]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.137412,	
2017-07-25 19:27:37,502 Epoch[16] Batch [440]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.137249,	
2017-07-25 19:27:41,421 Epoch[16] Batch [450]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.139898,	
2017-07-25 19:27:45,322 Epoch[16] Batch [460]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.141362,	
2017-07-25 19:27:49,173 Epoch[16] Batch [470]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.142736,	
2017-07-25 19:27:53,207 Epoch[16] Batch [480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.143754,	
2017-07-25 19:27:57,173 Epoch[16] Batch [490]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.144661,	
2017-07-25 19:28:01,137 Epoch[16] Batch [500]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.144863,	
2017-07-25 19:28:05,129 Epoch[16] Batch [510]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.145015,	
2017-07-25 19:28:09,072 Epoch[16] Batch [520]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.145114,	
2017-07-25 19:28:13,042 Epoch[16] Batch [530]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.144918,	
2017-07-25 19:28:16,901 Epoch[16] Batch [540]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.144908,	
2017-07-25 19:28:20,797 Epoch[16] Batch [550]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.144813,	
2017-07-25 19:28:24,674 Epoch[16] Batch [560]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.144425,	
2017-07-25 19:28:28,639 Epoch[16] Batch [570]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.144629,	
2017-07-25 19:28:32,521 Epoch[16] Batch [580]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.144302,	
2017-07-25 19:28:36,496 Epoch[16] Batch [590]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.144355,	
2017-07-25 19:28:40,480 Epoch[16] Batch [600]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.144259,	
2017-07-25 19:28:44,483 Epoch[16] Batch [610]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.144673,	
2017-07-25 19:28:48,256 Epoch[16] Batch [620]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.144798,	
2017-07-25 19:28:52,123 Epoch[16] Batch [630]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.144739,	
2017-07-25 19:28:56,041 Epoch[16] Batch [640]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.145001,	
2017-07-25 19:29:00,026 Epoch[16] Batch [650]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.144843,	
2017-07-25 19:29:03,941 Epoch[16] Batch [660]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.144541,	
2017-07-25 19:29:07,761 Epoch[16] Batch [670]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.144469,	
2017-07-25 19:29:11,754 Epoch[16] Batch [680]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.144547,	
2017-07-25 19:29:15,731 Epoch[16] Batch [690]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.144724,	
2017-07-25 19:29:19,576 Epoch[16] Batch [700]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.144520,	
2017-07-25 19:29:23,557 Epoch[16] Batch [710]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.144242,	
2017-07-25 19:29:27,515 Epoch[16] Batch [720]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.143853,	
2017-07-25 19:29:31,447 Epoch[16] Batch [730]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.143841,	
2017-07-25 19:29:35,422 Epoch[16] Batch [740]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.143899,	
2017-07-25 19:29:39,300 Epoch[16] Batch [750]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.143855,	
2017-07-25 19:29:43,247 Epoch[16] Batch [760]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.143609,	
2017-07-25 19:29:47,175 Epoch[16] Batch [770]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.143383,	
2017-07-25 19:29:51,137 Epoch[16] Batch [780]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.143371,	
2017-07-25 19:29:55,139 Epoch[16] Batch [790]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.143373,	
2017-07-25 19:29:59,209 Epoch[16] Batch [800]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.143500,	
2017-07-25 19:30:03,026 Epoch[16] Batch [810]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.143459,	
2017-07-25 19:30:06,967 Epoch[16] Batch [820]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.143457,	
2017-07-25 19:30:10,903 Epoch[16] Batch [830]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.143514,	
2017-07-25 19:30:14,779 Epoch[16] Batch [840]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.143460,	
2017-07-25 19:30:18,623 Epoch[16] Batch [850]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.143330,	
2017-07-25 19:30:22,516 Epoch[16] Batch [860]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.143206,	
2017-07-25 19:30:26,408 Epoch[16] Batch [870]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.143576,	
2017-07-25 19:30:30,363 Epoch[16] Batch [880]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.143421,	
2017-07-25 19:30:34,270 Epoch[16] Batch [890]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.143297,	
2017-07-25 19:30:38,176 Epoch[16] Batch [900]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.143235,	
2017-07-25 19:30:42,227 Epoch[16] Batch [910]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.143146,	
2017-07-25 19:30:46,232 Epoch[16] Batch [920]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.142876,	
2017-07-25 19:30:50,184 Epoch[16] Batch [930]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.142580,	
2017-07-25 19:30:54,097 Epoch[16] Batch [940]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.142425,	
2017-07-25 19:30:58,104 Epoch[16] Batch [950]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.142224,	
2017-07-25 19:31:02,028 Epoch[16] Batch [960]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.141999,	
2017-07-25 19:31:05,917 Epoch[16] Batch [970]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.141815,	
2017-07-25 19:31:09,825 Epoch[16] Batch [980]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.141603,	
2017-07-25 19:31:13,817 Epoch[16] Batch [990]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.141633,	
2017-07-25 19:31:17,716 Epoch[16] Batch [1000]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.141488,	
2017-07-25 19:31:21,742 Epoch[16] Batch [1010]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.141377,	
2017-07-25 19:31:25,618 Epoch[16] Batch [1020]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.141278,	
2017-07-25 19:31:29,589 Epoch[16] Batch [1030]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.141097,	
2017-07-25 19:31:33,483 Epoch[16] Batch [1040]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.140952,	
2017-07-25 19:31:37,444 Epoch[16] Batch [1050]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.140846,	
2017-07-25 19:31:41,325 Epoch[16] Batch [1060]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.141011,	
2017-07-25 19:31:45,371 Epoch[16] Batch [1070]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.141002,	
2017-07-25 19:31:49,239 Epoch[16] Batch [1080]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.141338,	
2017-07-25 19:31:53,226 Epoch[16] Batch [1090]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.141655,	
2017-07-25 19:31:57,150 Epoch[16] Batch [1100]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.141593,	
2017-07-25 19:32:01,154 Epoch[16] Batch [1110]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.141526,	
2017-07-25 19:32:04,980 Epoch[16] Batch [1120]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.141605,	
2017-07-25 19:32:08,926 Epoch[16] Batch [1130]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.141602,	
2017-07-25 19:32:12,783 Epoch[16] Batch [1140]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.141381,	
2017-07-25 19:32:16,694 Epoch[16] Batch [1150]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.141543,	
2017-07-25 19:32:20,564 Epoch[16] Batch [1160]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.141546,	
2017-07-25 19:32:24,494 Epoch[16] Batch [1170]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.141438,	
2017-07-25 19:32:28,475 Epoch[16] Batch [1180]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.141269,	
2017-07-25 19:32:32,463 Epoch[16] Batch [1190]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.141228,	
2017-07-25 19:32:36,354 Epoch[16] Batch [1200]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.141238,	
2017-07-25 19:32:40,255 Epoch[16] Batch [1210]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.141053,	
2017-07-25 19:32:44,126 Epoch[16] Batch [1220]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.140923,	
2017-07-25 19:32:48,099 Epoch[16] Batch [1230]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.140788,	
2017-07-25 19:32:51,956 Epoch[16] Batch [1240]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.140730,	
2017-07-25 19:32:55,856 Epoch[16] Batch [1250]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.140511,	
2017-07-25 19:32:59,696 Epoch[16] Batch [1260]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.140366,	
2017-07-25 19:33:03,619 Epoch[16] Batch [1270]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.140280,	
2017-07-25 19:33:07,476 Epoch[16] Batch [1280]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.140196,	
2017-07-25 19:33:11,468 Epoch[16] Batch [1290]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.140060,	
2017-07-25 19:33:15,496 Epoch[16] Batch [1300]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.140091,	
2017-07-25 19:33:19,498 Epoch[16] Batch [1310]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.139935,	
2017-07-25 19:33:23,346 Epoch[16] Batch [1320]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.140061,	
2017-07-25 19:33:27,215 Epoch[16] Batch [1330]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.140024,	
2017-07-25 19:33:31,163 Epoch[16] Batch [1340]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.140036,	
2017-07-25 19:33:35,168 Epoch[16] Batch [1350]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.139961,	
2017-07-25 19:33:39,134 Epoch[16] Batch [1360]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.140053,	
2017-07-25 19:33:43,017 Epoch[16] Batch [1370]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.140013,	
2017-07-25 19:33:46,961 Epoch[16] Batch [1380]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.140024,	
2017-07-25 19:33:50,865 Epoch[16] Batch [1390]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.139998,	
2017-07-25 19:33:54,776 Epoch[16] Batch [1400]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.139992,	
2017-07-25 19:33:58,715 Epoch[16] Batch [1410]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.139938,	
2017-07-25 19:34:02,598 Epoch[16] Batch [1420]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.139782,	
2017-07-25 19:34:06,444 Epoch[16] Batch [1430]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.139843,	
2017-07-25 19:34:10,464 Epoch[16] Batch [1440]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.139837,	
2017-07-25 19:34:14,338 Epoch[16] Batch [1450]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.139884,	
2017-07-25 19:34:18,264 Epoch[16] Batch [1460]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.139924,	
2017-07-25 19:34:22,154 Epoch[16] Batch [1470]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.139907,	
2017-07-25 19:34:26,195 Epoch[16] Batch [1480]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.139701,	
2017-07-25 19:34:28,505 Epoch[16] Train-FCNLogLoss=0.139646
2017-07-25 19:34:28,505 Epoch[16] Time cost=584.339
2017-07-25 19:34:29,239 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.params"
2017-07-25 19:34:30,776 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0017.states"
2017-07-25 19:34:35,469 Epoch[17] Batch [10]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.136346,	
2017-07-25 19:34:39,375 Epoch[17] Batch [20]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.145432,	
2017-07-25 19:34:43,368 Epoch[17] Batch [30]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.149433,	
2017-07-25 19:34:47,217 Epoch[17] Batch [40]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.153459,	
2017-07-25 19:34:51,158 Epoch[17] Batch [50]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.154380,	
2017-07-25 19:34:55,023 Epoch[17] Batch [60]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.154684,	
2017-07-25 19:34:58,979 Epoch[17] Batch [70]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.149511,	
2017-07-25 19:35:03,010 Epoch[17] Batch [80]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.147938,	
2017-07-25 19:35:06,922 Epoch[17] Batch [90]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.147108,	
2017-07-25 19:35:10,793 Epoch[17] Batch [100]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.145704,	
2017-07-25 19:35:14,748 Epoch[17] Batch [110]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.144621,	
2017-07-25 19:35:18,497 Epoch[17] Batch [120]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.142667,	
2017-07-25 19:35:22,432 Epoch[17] Batch [130]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.142371,	
2017-07-25 19:35:26,346 Epoch[17] Batch [140]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.143066,	
2017-07-25 19:35:30,208 Epoch[17] Batch [150]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.142829,	
2017-07-25 19:35:34,159 Epoch[17] Batch [160]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.143355,	
2017-07-25 19:35:38,054 Epoch[17] Batch [170]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.141784,	
2017-07-25 19:35:41,950 Epoch[17] Batch [180]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.141122,	
2017-07-25 19:35:45,880 Epoch[17] Batch [190]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.141093,	
2017-07-25 19:35:49,907 Epoch[17] Batch [200]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.140459,	
2017-07-25 19:35:53,775 Epoch[17] Batch [210]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.140307,	
2017-07-25 19:35:57,726 Epoch[17] Batch [220]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.140710,	
2017-07-25 19:36:01,745 Epoch[17] Batch [230]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.140967,	
2017-07-25 19:36:05,722 Epoch[17] Batch [240]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.140750,	
2017-07-25 19:36:09,550 Epoch[17] Batch [250]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.140535,	
2017-07-25 19:36:13,471 Epoch[17] Batch [260]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.140447,	
2017-07-25 19:36:17,298 Epoch[17] Batch [270]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.141155,	
2017-07-25 19:36:21,277 Epoch[17] Batch [280]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.140714,	
2017-07-25 19:36:25,202 Epoch[17] Batch [290]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.140538,	
2017-07-25 19:36:29,148 Epoch[17] Batch [300]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.140794,	
2017-07-25 19:36:33,062 Epoch[17] Batch [310]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.140093,	
2017-07-25 19:36:37,024 Epoch[17] Batch [320]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.140071,	
2017-07-25 19:36:40,948 Epoch[17] Batch [330]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.140044,	
2017-07-25 19:36:44,979 Epoch[17] Batch [340]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.139720,	
2017-07-25 19:36:48,994 Epoch[17] Batch [350]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.139599,	
2017-07-25 19:36:53,048 Epoch[17] Batch [360]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.139502,	
2017-07-25 19:36:57,000 Epoch[17] Batch [370]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.140325,	
2017-07-25 19:37:00,895 Epoch[17] Batch [380]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.140350,	
2017-07-25 19:37:04,809 Epoch[17] Batch [390]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.140803,	
2017-07-25 19:37:08,806 Epoch[17] Batch [400]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.140649,	
2017-07-25 19:37:12,773 Epoch[17] Batch [410]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.140175,	
2017-07-25 19:37:16,779 Epoch[17] Batch [420]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.139814,	
2017-07-25 19:37:20,786 Epoch[17] Batch [430]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.139735,	
2017-07-25 19:37:24,736 Epoch[17] Batch [440]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.139593,	
2017-07-25 19:37:28,696 Epoch[17] Batch [450]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.139490,	
2017-07-25 19:37:32,687 Epoch[17] Batch [460]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.139024,	
2017-07-25 19:37:36,660 Epoch[17] Batch [470]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.138713,	
2017-07-25 19:37:40,664 Epoch[17] Batch [480]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.138455,	
2017-07-25 19:37:44,693 Epoch[17] Batch [490]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.138710,	
2017-07-25 19:37:48,598 Epoch[17] Batch [500]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.138467,	
2017-07-25 19:37:52,530 Epoch[17] Batch [510]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.138459,	
2017-07-25 19:37:56,545 Epoch[17] Batch [520]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.138723,	
2017-07-25 19:38:00,621 Epoch[17] Batch [530]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.139088,	
2017-07-25 19:38:04,656 Epoch[17] Batch [540]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.139158,	
2017-07-25 19:38:08,510 Epoch[17] Batch [550]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.139365,	
2017-07-25 19:38:12,465 Epoch[17] Batch [560]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.139795,	
2017-07-25 19:38:16,335 Epoch[17] Batch [570]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.139751,	
2017-07-25 19:38:20,352 Epoch[17] Batch [580]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.139906,	
2017-07-25 19:38:24,333 Epoch[17] Batch [590]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.139540,	
2017-07-25 19:38:28,192 Epoch[17] Batch [600]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.139498,	
2017-07-25 19:38:32,314 Epoch[17] Batch [610]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.139541,	
2017-07-25 19:38:36,308 Epoch[17] Batch [620]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.139214,	
2017-07-25 19:38:40,447 Epoch[17] Batch [630]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.138989,	
2017-07-25 19:38:44,457 Epoch[17] Batch [640]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.138717,	
2017-07-25 19:38:48,433 Epoch[17] Batch [650]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.138761,	
2017-07-25 19:38:52,332 Epoch[17] Batch [660]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.138362,	
2017-07-25 19:38:56,263 Epoch[17] Batch [670]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.138406,	
2017-07-25 19:39:00,231 Epoch[17] Batch [680]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.138790,	
2017-07-25 19:39:04,179 Epoch[17] Batch [690]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.138839,	
2017-07-25 19:39:08,218 Epoch[17] Batch [700]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.138894,	
2017-07-25 19:39:12,186 Epoch[17] Batch [710]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.138881,	
2017-07-25 19:39:16,246 Epoch[17] Batch [720]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.138742,	
2017-07-25 19:39:20,275 Epoch[17] Batch [730]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.138459,	
2017-07-25 19:39:24,196 Epoch[17] Batch [740]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.138613,	
2017-07-25 19:39:28,245 Epoch[17] Batch [750]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.138638,	
2017-07-25 19:39:32,117 Epoch[17] Batch [760]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.138667,	
2017-07-25 19:39:36,156 Epoch[17] Batch [770]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.138603,	
2017-07-25 19:39:40,088 Epoch[17] Batch [780]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.138478,	
2017-07-25 19:39:44,017 Epoch[17] Batch [790]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.138548,	
2017-07-25 19:39:48,023 Epoch[17] Batch [800]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.138532,	
2017-07-25 19:39:52,048 Epoch[17] Batch [810]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.138715,	
2017-07-25 19:39:56,056 Epoch[17] Batch [820]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.138667,	
2017-07-25 19:40:00,105 Epoch[17] Batch [830]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.138461,	
2017-07-25 19:40:04,103 Epoch[17] Batch [840]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.138307,	
2017-07-25 19:40:08,017 Epoch[17] Batch [850]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.138213,	
2017-07-25 19:40:12,023 Epoch[17] Batch [860]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.138459,	
2017-07-25 19:40:15,981 Epoch[17] Batch [870]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.138355,	
2017-07-25 19:40:20,013 Epoch[17] Batch [880]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.138324,	
2017-07-25 19:40:24,063 Epoch[17] Batch [890]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.138287,	
2017-07-25 19:40:27,992 Epoch[17] Batch [900]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.138296,	
2017-07-25 19:40:31,991 Epoch[17] Batch [910]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.138315,	
2017-07-25 19:40:36,003 Epoch[17] Batch [920]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.138084,	
2017-07-25 19:40:39,821 Epoch[17] Batch [930]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.138178,	
2017-07-25 19:40:43,704 Epoch[17] Batch [940]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.137983,	
2017-07-25 19:40:47,603 Epoch[17] Batch [950]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.138065,	
2017-07-25 19:40:51,555 Epoch[17] Batch [960]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.138002,	
2017-07-25 19:40:55,689 Epoch[17] Batch [970]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.137955,	
2017-07-25 19:40:59,606 Epoch[17] Batch [980]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.137809,	
2017-07-25 19:41:03,726 Epoch[17] Batch [990]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.137777,	
2017-07-25 19:41:07,732 Epoch[17] Batch [1000]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.137701,	
2017-07-25 19:41:11,668 Epoch[17] Batch [1010]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.137651,	
2017-07-25 19:41:15,559 Epoch[17] Batch [1020]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.137646,	
2017-07-25 19:41:19,616 Epoch[17] Batch [1030]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.137744,	
2017-07-25 19:41:23,595 Epoch[17] Batch [1040]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.137717,	
2017-07-25 19:41:27,530 Epoch[17] Batch [1050]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.137864,	
2017-07-25 19:41:31,437 Epoch[17] Batch [1060]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.137782,	
2017-07-25 19:41:35,337 Epoch[17] Batch [1070]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.137978,	
2017-07-25 19:41:39,257 Epoch[17] Batch [1080]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.137942,	
2017-07-25 19:41:43,285 Epoch[17] Batch [1090]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.137927,	
2017-07-25 19:41:47,260 Epoch[17] Batch [1100]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.137940,	
2017-07-25 19:41:51,209 Epoch[17] Batch [1110]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.137844,	
2017-07-25 19:41:55,154 Epoch[17] Batch [1120]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.137762,	
2017-07-25 19:41:59,277 Epoch[17] Batch [1130]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.137676,	
2017-07-25 19:42:03,306 Epoch[17] Batch [1140]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.137711,	
2017-07-25 19:42:07,398 Epoch[17] Batch [1150]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.137752,	
2017-07-25 19:42:11,512 Epoch[17] Batch [1160]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.137731,	
2017-07-25 19:42:15,473 Epoch[17] Batch [1170]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.137678,	
2017-07-25 19:42:19,465 Epoch[17] Batch [1180]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.137565,	
2017-07-25 19:42:23,412 Epoch[17] Batch [1190]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.137388,	
2017-07-25 19:42:27,323 Epoch[17] Batch [1200]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.137259,	
2017-07-25 19:42:31,233 Epoch[17] Batch [1210]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.137326,	
2017-07-25 19:42:35,123 Epoch[17] Batch [1220]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.137255,	
2017-07-25 19:42:38,961 Epoch[17] Batch [1230]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.137346,	
2017-07-25 19:42:43,036 Epoch[17] Batch [1240]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.137528,	
2017-07-25 19:42:47,142 Epoch[17] Batch [1250]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.137726,	
2017-07-25 19:42:51,139 Epoch[17] Batch [1260]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.137899,	
2017-07-25 19:42:54,992 Epoch[17] Batch [1270]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.137865,	
2017-07-25 19:42:58,909 Epoch[17] Batch [1280]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.137831,	
2017-07-25 19:43:03,007 Epoch[17] Batch [1290]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.137883,	
2017-07-25 19:43:06,925 Epoch[17] Batch [1300]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.137779,	
2017-07-25 19:43:10,778 Epoch[17] Batch [1310]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.137655,	
2017-07-25 19:43:14,850 Epoch[17] Batch [1320]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.137737,	
2017-07-25 19:43:18,804 Epoch[17] Batch [1330]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.137623,	
2017-07-25 19:43:22,844 Epoch[17] Batch [1340]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.137573,	
2017-07-25 19:43:26,774 Epoch[17] Batch [1350]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.137558,	
2017-07-25 19:43:30,790 Epoch[17] Batch [1360]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.137434,	
2017-07-25 19:43:34,683 Epoch[17] Batch [1370]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.137334,	
2017-07-25 19:43:38,639 Epoch[17] Batch [1380]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.137294,	
2017-07-25 19:43:42,718 Epoch[17] Batch [1390]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.137183,	
2017-07-25 19:43:46,746 Epoch[17] Batch [1400]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.136948,	
2017-07-25 19:43:50,752 Epoch[17] Batch [1410]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.136853,	
2017-07-25 19:43:54,687 Epoch[17] Batch [1420]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.136832,	
2017-07-25 19:43:58,671 Epoch[17] Batch [1430]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.136771,	
2017-07-25 19:44:02,686 Epoch[17] Batch [1440]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.136705,	
2017-07-25 19:44:06,575 Epoch[17] Batch [1450]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.136681,	
2017-07-25 19:44:10,645 Epoch[17] Batch [1460]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.136569,	
2017-07-25 19:44:14,675 Epoch[17] Batch [1470]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.136400,	
2017-07-25 19:44:18,666 Epoch[17] Batch [1480]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.136309,	
2017-07-25 19:44:21,050 Epoch[17] Train-FCNLogLoss=0.136433
2017-07-25 19:44:21,050 Epoch[17] Time cost=590.274
2017-07-25 19:44:21,732 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.params"
2017-07-25 19:44:23,314 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0018.states"
2017-07-25 19:44:28,160 Epoch[18] Batch [10]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.142770,	
2017-07-25 19:44:32,079 Epoch[18] Batch [20]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.142042,	
2017-07-25 19:44:35,938 Epoch[18] Batch [30]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.134727,	
2017-07-25 19:44:39,939 Epoch[18] Batch [40]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.136094,	
2017-07-25 19:44:43,806 Epoch[18] Batch [50]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.133307,	
2017-07-25 19:44:47,835 Epoch[18] Batch [60]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.138294,	
2017-07-25 19:44:51,852 Epoch[18] Batch [70]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.140717,	
2017-07-25 19:44:55,740 Epoch[18] Batch [80]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.143019,	
2017-07-25 19:44:59,644 Epoch[18] Batch [90]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.145196,	
2017-07-25 19:45:03,643 Epoch[18] Batch [100]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.144572,	
2017-07-25 19:45:07,636 Epoch[18] Batch [110]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.142765,	
2017-07-25 19:45:11,614 Epoch[18] Batch [120]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.143218,	
2017-07-25 19:45:15,555 Epoch[18] Batch [130]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.143987,	
2017-07-25 19:45:19,440 Epoch[18] Batch [140]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.142805,	
2017-07-25 19:45:23,339 Epoch[18] Batch [150]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.141600,	
2017-07-25 19:45:27,300 Epoch[18] Batch [160]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.140739,	
2017-07-25 19:45:31,217 Epoch[18] Batch [170]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.139909,	
2017-07-25 19:45:35,228 Epoch[18] Batch [180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.138768,	
2017-07-25 19:45:39,175 Epoch[18] Batch [190]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.138652,	
2017-07-25 19:45:43,144 Epoch[18] Batch [200]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.137599,	
2017-07-25 19:45:47,115 Epoch[18] Batch [210]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.136992,	
2017-07-25 19:45:51,136 Epoch[18] Batch [220]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.136625,	
2017-07-25 19:45:55,085 Epoch[18] Batch [230]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.136065,	
2017-07-25 19:45:59,061 Epoch[18] Batch [240]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.136576,	
2017-07-25 19:46:02,947 Epoch[18] Batch [250]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.135868,	
2017-07-25 19:46:06,843 Epoch[18] Batch [260]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.135727,	
2017-07-25 19:46:10,823 Epoch[18] Batch [270]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.136581,	
2017-07-25 19:46:14,776 Epoch[18] Batch [280]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.136088,	
2017-07-25 19:46:18,752 Epoch[18] Batch [290]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.135797,	
2017-07-25 19:46:22,718 Epoch[18] Batch [300]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.135873,	
2017-07-25 19:46:26,684 Epoch[18] Batch [310]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.136102,	
2017-07-25 19:46:30,690 Epoch[18] Batch [320]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.136146,	
2017-07-25 19:46:34,622 Epoch[18] Batch [330]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.135518,	
2017-07-25 19:46:38,548 Epoch[18] Batch [340]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.135374,	
2017-07-25 19:46:42,522 Epoch[18] Batch [350]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.135300,	
2017-07-25 19:46:46,541 Epoch[18] Batch [360]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.135083,	
2017-07-25 19:46:50,563 Epoch[18] Batch [370]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.134823,	
2017-07-25 19:46:54,561 Epoch[18] Batch [380]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.134451,	
2017-07-25 19:46:58,420 Epoch[18] Batch [390]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.134117,	
2017-07-25 19:47:02,304 Epoch[18] Batch [400]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.134269,	
2017-07-25 19:47:06,338 Epoch[18] Batch [410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.133934,	
2017-07-25 19:47:10,354 Epoch[18] Batch [420]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.134118,	
2017-07-25 19:47:14,463 Epoch[18] Batch [430]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.134363,	
2017-07-25 19:47:18,552 Epoch[18] Batch [440]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.134589,	
2017-07-25 19:47:22,464 Epoch[18] Batch [450]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.134810,	
2017-07-25 19:47:26,428 Epoch[18] Batch [460]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.134543,	
2017-07-25 19:47:30,400 Epoch[18] Batch [470]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.134622,	
2017-07-25 19:47:34,427 Epoch[18] Batch [480]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.134365,	
2017-07-25 19:47:38,431 Epoch[18] Batch [490]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.134304,	
2017-07-25 19:47:42,455 Epoch[18] Batch [500]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.134514,	
2017-07-25 19:47:46,396 Epoch[18] Batch [510]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.134635,	
2017-07-25 19:47:50,384 Epoch[18] Batch [520]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.134491,	
2017-07-25 19:47:54,317 Epoch[18] Batch [530]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.134561,	
2017-07-25 19:47:58,367 Epoch[18] Batch [540]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.134493,	
2017-07-25 19:48:02,364 Epoch[18] Batch [550]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.134486,	
2017-07-25 19:48:06,435 Epoch[18] Batch [560]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.134330,	
2017-07-25 19:48:10,406 Epoch[18] Batch [570]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.134009,	
2017-07-25 19:48:14,459 Epoch[18] Batch [580]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.133977,	
2017-07-25 19:48:18,446 Epoch[18] Batch [590]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.133825,	
2017-07-25 19:48:22,486 Epoch[18] Batch [600]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.133747,	
2017-07-25 19:48:26,525 Epoch[18] Batch [610]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.133804,	
2017-07-25 19:48:30,461 Epoch[18] Batch [620]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.133867,	
2017-07-25 19:48:34,541 Epoch[18] Batch [630]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.133833,	
2017-07-25 19:48:38,625 Epoch[18] Batch [640]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.133838,	
2017-07-25 19:48:42,486 Epoch[18] Batch [650]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.133810,	
2017-07-25 19:48:46,603 Epoch[18] Batch [660]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.133696,	
2017-07-25 19:48:50,562 Epoch[18] Batch [670]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.133658,	
2017-07-25 19:48:54,421 Epoch[18] Batch [680]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.133431,	
2017-07-25 19:48:58,480 Epoch[18] Batch [690]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.133216,	
2017-07-25 19:49:02,373 Epoch[18] Batch [700]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.133350,	
2017-07-25 19:49:06,351 Epoch[18] Batch [710]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.133556,	
2017-07-25 19:49:10,477 Epoch[18] Batch [720]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.133492,	
2017-07-25 19:49:14,572 Epoch[18] Batch [730]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.133630,	
2017-07-25 19:49:18,521 Epoch[18] Batch [740]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.133564,	
2017-07-25 19:49:22,481 Epoch[18] Batch [750]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.133583,	
2017-07-25 19:49:26,497 Epoch[18] Batch [760]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.133494,	
2017-07-25 19:49:30,323 Epoch[18] Batch [770]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.133256,	
2017-07-25 19:49:34,261 Epoch[18] Batch [780]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.133382,	
2017-07-25 19:49:38,243 Epoch[18] Batch [790]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.133575,	
2017-07-25 19:49:42,220 Epoch[18] Batch [800]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.133535,	
2017-07-25 19:49:46,181 Epoch[18] Batch [810]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.133511,	
2017-07-25 19:49:50,118 Epoch[18] Batch [820]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.133644,	
2017-07-25 19:49:54,133 Epoch[18] Batch [830]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.133578,	
2017-07-25 19:49:58,185 Epoch[18] Batch [840]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.133692,	
2017-07-25 19:50:02,175 Epoch[18] Batch [850]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.133712,	
2017-07-25 19:50:06,153 Epoch[18] Batch [860]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.133492,	
2017-07-25 19:50:10,178 Epoch[18] Batch [870]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.133268,	
2017-07-25 19:50:14,091 Epoch[18] Batch [880]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.133055,	
2017-07-25 19:50:17,901 Epoch[18] Batch [890]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.133006,	
2017-07-25 19:50:21,960 Epoch[18] Batch [900]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.133526,	
2017-07-25 19:50:26,004 Epoch[18] Batch [910]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.133734,	
2017-07-25 19:50:30,063 Epoch[18] Batch [920]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.133743,	
2017-07-25 19:50:33,977 Epoch[18] Batch [930]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.133648,	
2017-07-25 19:50:37,822 Epoch[18] Batch [940]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.133532,	
2017-07-25 19:50:41,739 Epoch[18] Batch [950]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.133376,	
2017-07-25 19:50:45,644 Epoch[18] Batch [960]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.133490,	
2017-07-25 19:50:49,653 Epoch[18] Batch [970]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.133659,	
2017-07-25 19:50:53,662 Epoch[18] Batch [980]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.133638,	
2017-07-25 19:50:57,674 Epoch[18] Batch [990]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.133703,	
2017-07-25 19:51:01,716 Epoch[18] Batch [1000]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.133745,	
2017-07-25 19:51:05,642 Epoch[18] Batch [1010]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.133839,	
2017-07-25 19:51:09,493 Epoch[18] Batch [1020]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.133906,	
2017-07-25 19:51:13,348 Epoch[18] Batch [1030]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.133834,	
2017-07-25 19:51:17,457 Epoch[18] Batch [1040]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.133813,	
2017-07-25 19:51:21,599 Epoch[18] Batch [1050]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.133714,	
2017-07-25 19:51:25,516 Epoch[18] Batch [1060]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.133616,	
2017-07-25 19:51:29,488 Epoch[18] Batch [1070]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.133802,	
2017-07-25 19:51:33,408 Epoch[18] Batch [1080]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.133754,	
2017-07-25 19:51:37,276 Epoch[18] Batch [1090]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.133750,	
2017-07-25 19:51:41,415 Epoch[18] Batch [1100]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.133735,	
2017-07-25 19:51:45,424 Epoch[18] Batch [1110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.133609,	
2017-07-25 19:51:49,504 Epoch[18] Batch [1120]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.133471,	
2017-07-25 19:51:53,489 Epoch[18] Batch [1130]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.133429,	
2017-07-25 19:51:57,546 Epoch[18] Batch [1140]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.133458,	
2017-07-25 19:52:01,629 Epoch[18] Batch [1150]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.133337,	
2017-07-25 19:52:05,569 Epoch[18] Batch [1160]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.133293,	
2017-07-25 19:52:09,606 Epoch[18] Batch [1170]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.133153,	
2017-07-25 19:52:13,571 Epoch[18] Batch [1180]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.133178,	
2017-07-25 19:52:17,468 Epoch[18] Batch [1190]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.133074,	
2017-07-25 19:52:21,483 Epoch[18] Batch [1200]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.132990,	
2017-07-25 19:52:25,585 Epoch[18] Batch [1210]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.133095,	
2017-07-25 19:52:29,560 Epoch[18] Batch [1220]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.133121,	
2017-07-25 19:52:33,650 Epoch[18] Batch [1230]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.132961,	
2017-07-25 19:52:37,570 Epoch[18] Batch [1240]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.132914,	
2017-07-25 19:52:41,485 Epoch[18] Batch [1250]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.132922,	
2017-07-25 19:52:45,512 Epoch[18] Batch [1260]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.132929,	
2017-07-25 19:52:49,441 Epoch[18] Batch [1270]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.132882,	
2017-07-25 19:52:53,394 Epoch[18] Batch [1280]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.132834,	
2017-07-25 19:52:57,452 Epoch[18] Batch [1290]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.132883,	
2017-07-25 19:53:01,464 Epoch[18] Batch [1300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.132829,	
2017-07-25 19:53:05,602 Epoch[18] Batch [1310]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.132772,	
2017-07-25 19:53:09,720 Epoch[18] Batch [1320]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.133151,	
2017-07-25 19:53:13,742 Epoch[18] Batch [1330]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.133390,	
2017-07-25 19:53:17,838 Epoch[18] Batch [1340]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.133520,	
2017-07-25 19:53:21,804 Epoch[18] Batch [1350]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.133414,	
2017-07-25 19:53:25,839 Epoch[18] Batch [1360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.133392,	
2017-07-25 19:53:29,782 Epoch[18] Batch [1370]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.133531,	
2017-07-25 19:53:33,744 Epoch[18] Batch [1380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.133560,	
2017-07-25 19:53:37,810 Epoch[18] Batch [1390]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.133782,	
2017-07-25 19:53:41,650 Epoch[18] Batch [1400]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.133844,	
2017-07-25 19:53:45,705 Epoch[18] Batch [1410]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.133948,	
2017-07-25 19:53:49,678 Epoch[18] Batch [1420]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.133913,	
2017-07-25 19:53:53,757 Epoch[18] Batch [1430]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.133898,	
2017-07-25 19:53:57,659 Epoch[18] Batch [1440]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.133891,	
2017-07-25 19:54:01,652 Epoch[18] Batch [1450]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.134013,	
2017-07-25 19:54:05,530 Epoch[18] Batch [1460]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.134013,	
2017-07-25 19:54:09,552 Epoch[18] Batch [1470]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.134057,	
2017-07-25 19:54:13,562 Epoch[18] Batch [1480]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.134153,	
2017-07-25 19:54:15,824 Epoch[18] Train-FCNLogLoss=0.134227
2017-07-25 19:54:15,825 Epoch[18] Time cost=592.510
2017-07-25 19:54:16,509 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.params"
2017-07-25 19:54:18,209 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0019.states"
2017-07-25 19:54:22,990 Epoch[19] Batch [10]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.142387,	
2017-07-25 19:54:26,959 Epoch[19] Batch [20]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.148435,	
2017-07-25 19:54:30,886 Epoch[19] Batch [30]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.137774,	
2017-07-25 19:54:34,895 Epoch[19] Batch [40]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.133291,	
2017-07-25 19:54:38,877 Epoch[19] Batch [50]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.129509,	
2017-07-25 19:54:42,789 Epoch[19] Batch [60]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.128330,	
2017-07-25 19:54:46,872 Epoch[19] Batch [70]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.126962,	
2017-07-25 19:54:50,883 Epoch[19] Batch [80]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.127361,	
2017-07-25 19:54:54,840 Epoch[19] Batch [90]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.128845,	
2017-07-25 19:54:58,835 Epoch[19] Batch [100]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.127072,	
2017-07-25 19:55:02,770 Epoch[19] Batch [110]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.126431,	
2017-07-25 19:55:06,758 Epoch[19] Batch [120]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.126535,	
2017-07-25 19:55:10,664 Epoch[19] Batch [130]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.127342,	
2017-07-25 19:55:14,562 Epoch[19] Batch [140]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.126990,	
2017-07-25 19:55:18,482 Epoch[19] Batch [150]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.126312,	
2017-07-25 19:55:22,550 Epoch[19] Batch [160]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.126336,	
2017-07-25 19:55:26,548 Epoch[19] Batch [170]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.126068,	
2017-07-25 19:55:30,614 Epoch[19] Batch [180]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.126313,	
2017-07-25 19:55:34,677 Epoch[19] Batch [190]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.128149,	
2017-07-25 19:55:38,665 Epoch[19] Batch [200]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.127947,	
2017-07-25 19:55:42,591 Epoch[19] Batch [210]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.127679,	
2017-07-25 19:55:46,576 Epoch[19] Batch [220]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.127703,	
2017-07-25 19:55:50,696 Epoch[19] Batch [230]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.127914,	
2017-07-25 19:55:54,736 Epoch[19] Batch [240]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.127880,	
2017-07-25 19:55:58,860 Epoch[19] Batch [250]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.128449,	
2017-07-25 19:56:02,780 Epoch[19] Batch [260]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.128495,	
2017-07-25 19:56:06,689 Epoch[19] Batch [270]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.128562,	
2017-07-25 19:56:10,681 Epoch[19] Batch [280]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.129006,	
2017-07-25 19:56:14,620 Epoch[19] Batch [290]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.129686,	
2017-07-25 19:56:18,540 Epoch[19] Batch [300]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.129460,	
2017-07-25 19:56:22,453 Epoch[19] Batch [310]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.129062,	
2017-07-25 19:56:26,543 Epoch[19] Batch [320]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.128534,	
2017-07-25 19:56:30,494 Epoch[19] Batch [330]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.128617,	
2017-07-25 19:56:34,392 Epoch[19] Batch [340]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.129070,	
2017-07-25 19:56:38,337 Epoch[19] Batch [350]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.128994,	
2017-07-25 19:56:42,241 Epoch[19] Batch [360]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.129235,	
2017-07-25 19:56:46,236 Epoch[19] Batch [370]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.128922,	
2017-07-25 19:56:50,166 Epoch[19] Batch [380]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.128835,	
2017-07-25 19:56:54,113 Epoch[19] Batch [390]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.128569,	
2017-07-25 19:56:58,128 Epoch[19] Batch [400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.128184,	
2017-07-25 19:57:02,108 Epoch[19] Batch [410]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.128329,	
2017-07-25 19:57:06,018 Epoch[19] Batch [420]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.128325,	
2017-07-25 19:57:10,017 Epoch[19] Batch [430]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.128201,	
2017-07-25 19:57:14,036 Epoch[19] Batch [440]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.128577,	
2017-07-25 19:57:18,006 Epoch[19] Batch [450]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.128702,	
2017-07-25 19:57:21,969 Epoch[19] Batch [460]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129022,	
2017-07-25 19:57:25,967 Epoch[19] Batch [470]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.129188,	
2017-07-25 19:57:29,929 Epoch[19] Batch [480]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129019,	
2017-07-25 19:57:33,824 Epoch[19] Batch [490]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.128735,	
2017-07-25 19:57:37,741 Epoch[19] Batch [500]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.128468,	
2017-07-25 19:57:41,718 Epoch[19] Batch [510]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.128542,	
2017-07-25 19:57:45,699 Epoch[19] Batch [520]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.128988,	
2017-07-25 19:57:49,606 Epoch[19] Batch [530]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.128897,	
2017-07-25 19:57:53,535 Epoch[19] Batch [540]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.129795,	
2017-07-25 19:57:57,564 Epoch[19] Batch [550]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.129519,	
2017-07-25 19:58:01,646 Epoch[19] Batch [560]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.129647,	
2017-07-25 19:58:05,699 Epoch[19] Batch [570]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.129537,	
2017-07-25 19:58:09,521 Epoch[19] Batch [580]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.129757,	
2017-07-25 19:58:13,522 Epoch[19] Batch [590]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.129765,	
2017-07-25 19:58:17,521 Epoch[19] Batch [600]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.129731,	
2017-07-25 19:58:21,465 Epoch[19] Batch [610]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.129755,	
2017-07-25 19:58:25,478 Epoch[19] Batch [620]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.129524,	
2017-07-25 19:58:29,453 Epoch[19] Batch [630]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.129539,	
2017-07-25 19:58:33,425 Epoch[19] Batch [640]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.129820,	
2017-07-25 19:58:37,446 Epoch[19] Batch [650]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.129806,	
2017-07-25 19:58:41,372 Epoch[19] Batch [660]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.129712,	
2017-07-25 19:58:45,300 Epoch[19] Batch [670]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.129600,	
2017-07-25 19:58:49,377 Epoch[19] Batch [680]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.129753,	
2017-07-25 19:58:53,475 Epoch[19] Batch [690]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.130028,	
2017-07-25 19:58:57,484 Epoch[19] Batch [700]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.129939,	
2017-07-25 19:59:01,469 Epoch[19] Batch [710]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.130072,	
2017-07-25 19:59:05,385 Epoch[19] Batch [720]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.130002,	
2017-07-25 19:59:09,267 Epoch[19] Batch [730]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.130050,	
2017-07-25 19:59:13,271 Epoch[19] Batch [740]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.129802,	
2017-07-25 19:59:17,218 Epoch[19] Batch [750]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.129813,	
2017-07-25 19:59:21,203 Epoch[19] Batch [760]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.129673,	
2017-07-25 19:59:25,118 Epoch[19] Batch [770]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.129901,	
2017-07-25 19:59:29,179 Epoch[19] Batch [780]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.129828,	
2017-07-25 19:59:33,191 Epoch[19] Batch [790]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.129678,	
2017-07-25 19:59:37,121 Epoch[19] Batch [800]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.129706,	
2017-07-25 19:59:41,210 Epoch[19] Batch [810]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.129689,	
2017-07-25 19:59:45,137 Epoch[19] Batch [820]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.129576,	
2017-07-25 19:59:49,181 Epoch[19] Batch [830]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.129494,	
2017-07-25 19:59:53,150 Epoch[19] Batch [840]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.129328,	
2017-07-25 19:59:57,088 Epoch[19] Batch [850]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.129088,	
2017-07-25 20:00:01,002 Epoch[19] Batch [860]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.128919,	
2017-07-25 20:00:04,915 Epoch[19] Batch [870]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.128747,	
2017-07-25 20:00:08,865 Epoch[19] Batch [880]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.128844,	
2017-07-25 20:00:12,801 Epoch[19] Batch [890]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.128858,	
2017-07-25 20:00:16,708 Epoch[19] Batch [900]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.128965,	
2017-07-25 20:00:20,694 Epoch[19] Batch [910]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.129024,	
2017-07-25 20:00:24,647 Epoch[19] Batch [920]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.128840,	
2017-07-25 20:00:28,627 Epoch[19] Batch [930]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.128946,	
2017-07-25 20:00:32,619 Epoch[19] Batch [940]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.129034,	
2017-07-25 20:00:36,671 Epoch[19] Batch [950]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.128954,	
2017-07-25 20:00:40,662 Epoch[19] Batch [960]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.128983,	
2017-07-25 20:00:44,648 Epoch[19] Batch [970]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.129004,	
2017-07-25 20:00:48,592 Epoch[19] Batch [980]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.129042,	
2017-07-25 20:00:52,535 Epoch[19] Batch [990]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.129081,	
2017-07-25 20:00:56,609 Epoch[19] Batch [1000]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.129182,	
2017-07-25 20:01:00,597 Epoch[19] Batch [1010]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.129303,	
2017-07-25 20:01:04,577 Epoch[19] Batch [1020]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.129425,	
2017-07-25 20:01:08,608 Epoch[19] Batch [1030]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.129565,	
2017-07-25 20:01:12,588 Epoch[19] Batch [1040]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.129609,	
2017-07-25 20:01:16,585 Epoch[19] Batch [1050]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.129605,	
2017-07-25 20:01:20,545 Epoch[19] Batch [1060]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129573,	
2017-07-25 20:01:24,509 Epoch[19] Batch [1070]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.129644,	
2017-07-25 20:01:28,352 Epoch[19] Batch [1080]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.129702,	
2017-07-25 20:01:32,321 Epoch[19] Batch [1090]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.129898,	
2017-07-25 20:01:36,292 Epoch[19] Batch [1100]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.130243,	
2017-07-25 20:01:40,318 Epoch[19] Batch [1110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.130315,	
2017-07-25 20:01:44,274 Epoch[19] Batch [1120]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.130222,	
2017-07-25 20:01:48,224 Epoch[19] Batch [1130]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.130322,	
2017-07-25 20:01:52,147 Epoch[19] Batch [1140]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.130371,	
2017-07-25 20:01:56,112 Epoch[19] Batch [1150]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.130447,	
2017-07-25 20:02:00,098 Epoch[19] Batch [1160]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.130551,	
2017-07-25 20:02:04,043 Epoch[19] Batch [1170]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.130568,	
2017-07-25 20:02:08,064 Epoch[19] Batch [1180]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.130626,	
2017-07-25 20:02:11,894 Epoch[19] Batch [1190]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.130585,	
2017-07-25 20:02:15,778 Epoch[19] Batch [1200]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.130576,	
2017-07-25 20:02:19,717 Epoch[19] Batch [1210]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.130569,	
2017-07-25 20:02:23,635 Epoch[19] Batch [1220]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.130562,	
2017-07-25 20:02:27,593 Epoch[19] Batch [1230]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.130582,	
2017-07-25 20:02:31,644 Epoch[19] Batch [1240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.130760,	
2017-07-25 20:02:35,621 Epoch[19] Batch [1250]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.130748,	
2017-07-25 20:02:39,636 Epoch[19] Batch [1260]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.130811,	
2017-07-25 20:02:43,658 Epoch[19] Batch [1270]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.130801,	
2017-07-25 20:02:47,682 Epoch[19] Batch [1280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.130804,	
2017-07-25 20:02:51,670 Epoch[19] Batch [1290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.130704,	
2017-07-25 20:02:55,622 Epoch[19] Batch [1300]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.130562,	
2017-07-25 20:02:59,610 Epoch[19] Batch [1310]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.130579,	
2017-07-25 20:03:03,695 Epoch[19] Batch [1320]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.130612,	
2017-07-25 20:03:07,705 Epoch[19] Batch [1330]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.130701,	
2017-07-25 20:03:11,779 Epoch[19] Batch [1340]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.130741,	
2017-07-25 20:03:15,738 Epoch[19] Batch [1350]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.130638,	
2017-07-25 20:03:19,677 Epoch[19] Batch [1360]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.130533,	
2017-07-25 20:03:23,609 Epoch[19] Batch [1370]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.130486,	
2017-07-25 20:03:27,748 Epoch[19] Batch [1380]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.130446,	
2017-07-25 20:03:31,857 Epoch[19] Batch [1390]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.130340,	
2017-07-25 20:03:35,843 Epoch[19] Batch [1400]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.130341,	
2017-07-25 20:03:39,797 Epoch[19] Batch [1410]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.130243,	
2017-07-25 20:03:43,797 Epoch[19] Batch [1420]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.130141,	
2017-07-25 20:03:47,801 Epoch[19] Batch [1430]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.130173,	
2017-07-25 20:03:51,886 Epoch[19] Batch [1440]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.130173,	
2017-07-25 20:03:55,833 Epoch[19] Batch [1450]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.130224,	
2017-07-25 20:03:59,747 Epoch[19] Batch [1460]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.130177,	
2017-07-25 20:04:03,625 Epoch[19] Batch [1470]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.130095,	
2017-07-25 20:04:07,559 Epoch[19] Batch [1480]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.130008,	
2017-07-25 20:04:10,010 Epoch[19] Train-FCNLogLoss=0.129986
2017-07-25 20:04:10,010 Epoch[19] Time cost=591.800
2017-07-25 20:04:10,729 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.params"
2017-07-25 20:04:12,481 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0020.states"
2017-07-25 20:04:17,175 Epoch[20] Batch [10]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.120116,	
2017-07-25 20:04:21,140 Epoch[20] Batch [20]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.126233,	
2017-07-25 20:04:25,103 Epoch[20] Batch [30]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.126487,	
2017-07-25 20:04:29,079 Epoch[20] Batch [40]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.131879,	
2017-07-25 20:04:33,150 Epoch[20] Batch [50]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.128855,	
2017-07-25 20:04:37,277 Epoch[20] Batch [60]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.126983,	
2017-07-25 20:04:41,220 Epoch[20] Batch [70]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.125632,	
2017-07-25 20:04:45,203 Epoch[20] Batch [80]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.125062,	
2017-07-25 20:04:49,225 Epoch[20] Batch [90]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.124641,	
2017-07-25 20:04:53,219 Epoch[20] Batch [100]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.125192,	
2017-07-25 20:04:57,113 Epoch[20] Batch [110]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.125040,	
2017-07-25 20:05:01,029 Epoch[20] Batch [120]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.126294,	
2017-07-25 20:05:04,880 Epoch[20] Batch [130]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.126093,	
2017-07-25 20:05:08,973 Epoch[20] Batch [140]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.126175,	
2017-07-25 20:05:13,093 Epoch[20] Batch [150]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.126755,	
2017-07-25 20:05:17,041 Epoch[20] Batch [160]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.126511,	
2017-07-25 20:05:20,974 Epoch[20] Batch [170]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.126043,	
2017-07-25 20:05:24,997 Epoch[20] Batch [180]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126584,	
2017-07-25 20:05:28,989 Epoch[20] Batch [190]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.126260,	
2017-07-25 20:05:32,973 Epoch[20] Batch [200]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.126985,	
2017-07-25 20:05:37,090 Epoch[20] Batch [210]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.126597,	
2017-07-25 20:05:40,949 Epoch[20] Batch [220]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.125445,	
2017-07-25 20:05:44,764 Epoch[20] Batch [230]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.126331,	
2017-07-25 20:05:48,793 Epoch[20] Batch [240]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.126276,	
2017-07-25 20:05:52,784 Epoch[20] Batch [250]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.126844,	
2017-07-25 20:05:56,846 Epoch[20] Batch [260]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.126581,	
2017-07-25 20:06:00,786 Epoch[20] Batch [270]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.126577,	
2017-07-25 20:06:04,763 Epoch[20] Batch [280]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.126083,	
2017-07-25 20:06:08,752 Epoch[20] Batch [290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.126044,	
2017-07-25 20:06:12,855 Epoch[20] Batch [300]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.125957,	
2017-07-25 20:06:16,728 Epoch[20] Batch [310]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.126541,	
2017-07-25 20:06:20,780 Epoch[20] Batch [320]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.126614,	
2017-07-25 20:06:24,730 Epoch[20] Batch [330]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.126492,	
2017-07-25 20:06:28,662 Epoch[20] Batch [340]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.126732,	
2017-07-25 20:06:32,747 Epoch[20] Batch [350]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.126469,	
2017-07-25 20:06:36,897 Epoch[20] Batch [360]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.126456,	
2017-07-25 20:06:40,863 Epoch[20] Batch [370]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.126246,	
2017-07-25 20:06:44,832 Epoch[20] Batch [380]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.126027,	
2017-07-25 20:06:48,792 Epoch[20] Batch [390]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.126014,	
2017-07-25 20:06:52,747 Epoch[20] Batch [400]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.125886,	
2017-07-25 20:06:56,676 Epoch[20] Batch [410]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.125824,	
2017-07-25 20:07:00,691 Epoch[20] Batch [420]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.125826,	
2017-07-25 20:07:04,607 Epoch[20] Batch [430]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.125987,	
2017-07-25 20:07:08,552 Epoch[20] Batch [440]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.125755,	
2017-07-25 20:07:12,408 Epoch[20] Batch [450]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.125545,	
2017-07-25 20:07:16,342 Epoch[20] Batch [460]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.125735,	
2017-07-25 20:07:20,378 Epoch[20] Batch [470]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.125720,	
2017-07-25 20:07:24,364 Epoch[20] Batch [480]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.126070,	
2017-07-25 20:07:28,298 Epoch[20] Batch [490]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.126160,	
2017-07-25 20:07:32,191 Epoch[20] Batch [500]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.126196,	
2017-07-25 20:07:36,050 Epoch[20] Batch [510]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.126132,	
2017-07-25 20:07:40,075 Epoch[20] Batch [520]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126081,	
2017-07-25 20:07:44,009 Epoch[20] Batch [530]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.126430,	
2017-07-25 20:07:47,913 Epoch[20] Batch [540]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.126441,	
2017-07-25 20:07:51,871 Epoch[20] Batch [550]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.126407,	
2017-07-25 20:07:55,749 Epoch[20] Batch [560]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.126451,	
2017-07-25 20:07:59,622 Epoch[20] Batch [570]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.126665,	
2017-07-25 20:08:03,548 Epoch[20] Batch [580]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.127009,	
2017-07-25 20:08:07,518 Epoch[20] Batch [590]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.126919,	
2017-07-25 20:08:11,579 Epoch[20] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.126627,	
2017-07-25 20:08:15,603 Epoch[20] Batch [610]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126773,	
2017-07-25 20:08:19,546 Epoch[20] Batch [620]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.126804,	
2017-07-25 20:08:23,454 Epoch[20] Batch [630]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.126587,	
2017-07-25 20:08:27,412 Epoch[20] Batch [640]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.126790,	
2017-07-25 20:08:31,351 Epoch[20] Batch [650]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.126756,	
2017-07-25 20:08:35,401 Epoch[20] Batch [660]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.126970,	
2017-07-25 20:08:39,307 Epoch[20] Batch [670]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.127116,	
2017-07-25 20:08:43,101 Epoch[20] Batch [680]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.126940,	
2017-07-25 20:08:47,126 Epoch[20] Batch [690]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126656,	
2017-07-25 20:08:51,035 Epoch[20] Batch [700]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.126609,	
2017-07-25 20:08:55,003 Epoch[20] Batch [710]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.126439,	
2017-07-25 20:08:59,012 Epoch[20] Batch [720]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.126667,	
2017-07-25 20:09:02,992 Epoch[20] Batch [730]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.126790,	
2017-07-25 20:09:06,782 Epoch[20] Batch [740]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.126710,	
2017-07-25 20:09:10,816 Epoch[20] Batch [750]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.126822,	
2017-07-25 20:09:14,839 Epoch[20] Batch [760]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.127056,	
2017-07-25 20:09:18,791 Epoch[20] Batch [770]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.127191,	
2017-07-25 20:09:22,626 Epoch[20] Batch [780]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.127296,	
2017-07-25 20:09:26,553 Epoch[20] Batch [790]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.127292,	
2017-07-25 20:09:30,575 Epoch[20] Batch [800]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.127208,	
2017-07-25 20:09:34,680 Epoch[20] Batch [810]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.127047,	
2017-07-25 20:09:38,564 Epoch[20] Batch [820]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.127105,	
2017-07-25 20:09:42,576 Epoch[20] Batch [830]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.126971,	
2017-07-25 20:09:46,499 Epoch[20] Batch [840]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.127188,	
2017-07-25 20:09:50,540 Epoch[20] Batch [850]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.127241,	
2017-07-25 20:09:54,546 Epoch[20] Batch [860]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.128026,	
2017-07-25 20:09:58,471 Epoch[20] Batch [870]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.128609,	
2017-07-25 20:10:02,359 Epoch[20] Batch [880]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.128906,	
2017-07-25 20:10:06,265 Epoch[20] Batch [890]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.129124,	
2017-07-25 20:10:10,217 Epoch[20] Batch [900]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.129182,	
2017-07-25 20:10:14,219 Epoch[20] Batch [910]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.129271,	
2017-07-25 20:10:18,201 Epoch[20] Batch [920]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.129347,	
2017-07-25 20:10:22,096 Epoch[20] Batch [930]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.129566,	
2017-07-25 20:10:26,089 Epoch[20] Batch [940]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.129473,	
2017-07-25 20:10:30,062 Epoch[20] Batch [950]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.129734,	
2017-07-25 20:10:34,084 Epoch[20] Batch [960]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.129785,	
2017-07-25 20:10:38,035 Epoch[20] Batch [970]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.129877,	
2017-07-25 20:10:41,972 Epoch[20] Batch [980]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.130157,	
2017-07-25 20:10:45,910 Epoch[20] Batch [990]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.130165,	
2017-07-25 20:10:49,877 Epoch[20] Batch [1000]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.130037,	
2017-07-25 20:10:53,686 Epoch[20] Batch [1010]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.129868,	
2017-07-25 20:10:57,567 Epoch[20] Batch [1020]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.129748,	
2017-07-25 20:11:01,490 Epoch[20] Batch [1030]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.129756,	
2017-07-25 20:11:05,499 Epoch[20] Batch [1040]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.129610,	
2017-07-25 20:11:09,510 Epoch[20] Batch [1050]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.129641,	
2017-07-25 20:11:13,488 Epoch[20] Batch [1060]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.129750,	
2017-07-25 20:11:17,448 Epoch[20] Batch [1070]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129841,	
2017-07-25 20:11:21,368 Epoch[20] Batch [1080]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.130067,	
2017-07-25 20:11:25,292 Epoch[20] Batch [1090]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.129864,	
2017-07-25 20:11:29,294 Epoch[20] Batch [1100]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.129885,	
2017-07-25 20:11:33,125 Epoch[20] Batch [1110]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.129994,	
2017-07-25 20:11:37,152 Epoch[20] Batch [1120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.129984,	
2017-07-25 20:11:41,218 Epoch[20] Batch [1130]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.129856,	
2017-07-25 20:11:45,249 Epoch[20] Batch [1140]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.129767,	
2017-07-25 20:11:49,265 Epoch[20] Batch [1150]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.129738,	
2017-07-25 20:11:53,319 Epoch[20] Batch [1160]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.129743,	
2017-07-25 20:11:57,355 Epoch[20] Batch [1170]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.129556,	
2017-07-25 20:12:01,221 Epoch[20] Batch [1180]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.129479,	
2017-07-25 20:12:05,174 Epoch[20] Batch [1190]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.129422,	
2017-07-25 20:12:09,280 Epoch[20] Batch [1200]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.129295,	
2017-07-25 20:12:13,141 Epoch[20] Batch [1210]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.129340,	
2017-07-25 20:12:17,194 Epoch[20] Batch [1220]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.129328,	
2017-07-25 20:12:21,114 Epoch[20] Batch [1230]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.129409,	
2017-07-25 20:12:25,043 Epoch[20] Batch [1240]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.129267,	
2017-07-25 20:12:28,898 Epoch[20] Batch [1250]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.129198,	
2017-07-25 20:12:32,844 Epoch[20] Batch [1260]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.129413,	
2017-07-25 20:12:36,887 Epoch[20] Batch [1270]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.129347,	
2017-07-25 20:12:40,800 Epoch[20] Batch [1280]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.129296,	
2017-07-25 20:12:44,915 Epoch[20] Batch [1290]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.129434,	
2017-07-25 20:12:48,910 Epoch[20] Batch [1300]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.129657,	
2017-07-25 20:12:52,907 Epoch[20] Batch [1310]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.129886,	
2017-07-25 20:12:56,770 Epoch[20] Batch [1320]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.129977,	
2017-07-25 20:13:00,692 Epoch[20] Batch [1330]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.130348,	
2017-07-25 20:13:04,708 Epoch[20] Batch [1340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.130334,	
2017-07-25 20:13:08,737 Epoch[20] Batch [1350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.130344,	
2017-07-25 20:13:12,620 Epoch[20] Batch [1360]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.130394,	
2017-07-25 20:13:16,556 Epoch[20] Batch [1370]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.130473,	
2017-07-25 20:13:20,476 Epoch[20] Batch [1380]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.130529,	
2017-07-25 20:13:24,420 Epoch[20] Batch [1390]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.130494,	
2017-07-25 20:13:28,437 Epoch[20] Batch [1400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.130520,	
2017-07-25 20:13:32,419 Epoch[20] Batch [1410]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.130318,	
2017-07-25 20:13:36,377 Epoch[20] Batch [1420]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.130243,	
2017-07-25 20:13:40,406 Epoch[20] Batch [1430]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.130224,	
2017-07-25 20:13:44,349 Epoch[20] Batch [1440]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.130129,	
2017-07-25 20:13:48,386 Epoch[20] Batch [1450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.130189,	
2017-07-25 20:13:52,409 Epoch[20] Batch [1460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.130190,	
2017-07-25 20:13:56,410 Epoch[20] Batch [1470]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.130128,	
2017-07-25 20:14:00,292 Epoch[20] Batch [1480]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.130086,	
2017-07-25 20:14:02,606 Epoch[20] Train-FCNLogLoss=0.130058
2017-07-25 20:14:02,606 Epoch[20] Time cost=590.124
2017-07-25 20:14:03,308 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.params"
2017-07-25 20:14:04,847 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0021.states"
2017-07-25 20:14:09,621 Epoch[21] Batch [10]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.105777,	
2017-07-25 20:14:13,640 Epoch[21] Batch [20]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.118490,	
2017-07-25 20:14:17,645 Epoch[21] Batch [30]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.119918,	
2017-07-25 20:14:21,726 Epoch[21] Batch [40]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118386,	
2017-07-25 20:14:25,670 Epoch[21] Batch [50]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.119255,	
2017-07-25 20:14:29,740 Epoch[21] Batch [60]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.120400,	
2017-07-25 20:14:33,663 Epoch[21] Batch [70]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.118827,	
2017-07-25 20:14:37,676 Epoch[21] Batch [80]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.120195,	
2017-07-25 20:14:41,702 Epoch[21] Batch [90]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.122103,	
2017-07-25 20:14:45,586 Epoch[21] Batch [100]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.125361,	
2017-07-25 20:14:49,492 Epoch[21] Batch [110]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.125377,	
2017-07-25 20:14:53,381 Epoch[21] Batch [120]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.125373,	
2017-07-25 20:14:57,347 Epoch[21] Batch [130]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.126630,	
2017-07-25 20:15:01,354 Epoch[21] Batch [140]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.127698,	
2017-07-25 20:15:05,372 Epoch[21] Batch [150]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.127165,	
2017-07-25 20:15:09,385 Epoch[21] Batch [160]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.126902,	
2017-07-25 20:15:13,410 Epoch[21] Batch [170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126586,	
2017-07-25 20:15:17,359 Epoch[21] Batch [180]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.126896,	
2017-07-25 20:15:21,328 Epoch[21] Batch [190]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.127674,	
2017-07-25 20:15:25,328 Epoch[21] Batch [200]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.127367,	
2017-07-25 20:15:29,238 Epoch[21] Batch [210]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.129657,	
2017-07-25 20:15:33,245 Epoch[21] Batch [220]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.128929,	
2017-07-25 20:15:37,223 Epoch[21] Batch [230]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.129111,	
2017-07-25 20:15:41,181 Epoch[21] Batch [240]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.131718,	
2017-07-25 20:15:45,280 Epoch[21] Batch [250]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.132966,	
2017-07-25 20:15:49,258 Epoch[21] Batch [260]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.133582,	
2017-07-25 20:15:53,257 Epoch[21] Batch [270]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.135598,	
2017-07-25 20:15:57,192 Epoch[21] Batch [280]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.137015,	
2017-07-25 20:16:01,087 Epoch[21] Batch [290]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.137712,	
2017-07-25 20:16:04,953 Epoch[21] Batch [300]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.138004,	
2017-07-25 20:16:08,871 Epoch[21] Batch [310]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.138499,	
2017-07-25 20:16:12,716 Epoch[21] Batch [320]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.138185,	
2017-07-25 20:16:16,670 Epoch[21] Batch [330]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.138182,	
2017-07-25 20:16:20,519 Epoch[21] Batch [340]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.137674,	
2017-07-25 20:16:24,425 Epoch[21] Batch [350]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.137591,	
2017-07-25 20:16:28,386 Epoch[21] Batch [360]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.136795,	
2017-07-25 20:16:32,343 Epoch[21] Batch [370]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.136264,	
2017-07-25 20:16:36,326 Epoch[21] Batch [380]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.135978,	
2017-07-25 20:16:40,361 Epoch[21] Batch [390]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.135723,	
2017-07-25 20:16:44,337 Epoch[21] Batch [400]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.135557,	
2017-07-25 20:16:48,300 Epoch[21] Batch [410]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.135385,	
2017-07-25 20:16:52,281 Epoch[21] Batch [420]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.134852,	
2017-07-25 20:16:56,238 Epoch[21] Batch [430]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.134345,	
2017-07-25 20:17:00,303 Epoch[21] Batch [440]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.133989,	
2017-07-25 20:17:04,262 Epoch[21] Batch [450]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.133992,	
2017-07-25 20:17:08,373 Epoch[21] Batch [460]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.133904,	
2017-07-25 20:17:12,371 Epoch[21] Batch [470]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.133743,	
2017-07-25 20:17:16,422 Epoch[21] Batch [480]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.133728,	
2017-07-25 20:17:20,256 Epoch[21] Batch [490]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.133566,	
2017-07-25 20:17:24,306 Epoch[21] Batch [500]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.133651,	
2017-07-25 20:17:28,272 Epoch[21] Batch [510]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.133558,	
2017-07-25 20:17:32,267 Epoch[21] Batch [520]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.133475,	
2017-07-25 20:17:36,173 Epoch[21] Batch [530]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.133251,	
2017-07-25 20:17:40,151 Epoch[21] Batch [540]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.132611,	
2017-07-25 20:17:44,140 Epoch[21] Batch [550]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.132128,	
2017-07-25 20:17:48,197 Epoch[21] Batch [560]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.132174,	
2017-07-25 20:17:52,212 Epoch[21] Batch [570]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.132179,	
2017-07-25 20:17:56,219 Epoch[21] Batch [580]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.132394,	
2017-07-25 20:18:00,336 Epoch[21] Batch [590]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.132246,	
2017-07-25 20:18:04,306 Epoch[21] Batch [600]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.131916,	
2017-07-25 20:18:08,381 Epoch[21] Batch [610]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.131971,	
2017-07-25 20:18:12,494 Epoch[21] Batch [620]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.131736,	
2017-07-25 20:18:16,538 Epoch[21] Batch [630]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.131325,	
2017-07-25 20:18:20,351 Epoch[21] Batch [640]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.131053,	
2017-07-25 20:18:24,317 Epoch[21] Batch [650]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.130891,	
2017-07-25 20:18:28,345 Epoch[21] Batch [660]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.130770,	
2017-07-25 20:18:32,373 Epoch[21] Batch [670]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.130443,	
2017-07-25 20:18:36,422 Epoch[21] Batch [680]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.130310,	
2017-07-25 20:18:40,505 Epoch[21] Batch [690]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.130120,	
2017-07-25 20:18:44,370 Epoch[21] Batch [700]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.130102,	
2017-07-25 20:18:48,295 Epoch[21] Batch [710]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.130171,	
2017-07-25 20:18:52,164 Epoch[21] Batch [720]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.130372,	
2017-07-25 20:18:56,232 Epoch[21] Batch [730]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.130070,	
2017-07-25 20:19:00,204 Epoch[21] Batch [740]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.129906,	
2017-07-25 20:19:04,260 Epoch[21] Batch [750]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.130049,	
2017-07-25 20:19:08,132 Epoch[21] Batch [760]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.129762,	
2017-07-25 20:19:12,155 Epoch[21] Batch [770]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.129618,	
2017-07-25 20:19:16,079 Epoch[21] Batch [780]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.129492,	
2017-07-25 20:19:20,184 Epoch[21] Batch [790]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.129513,	
2017-07-25 20:19:24,267 Epoch[21] Batch [800]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.129453,	
2017-07-25 20:19:28,255 Epoch[21] Batch [810]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.129595,	
2017-07-25 20:19:32,137 Epoch[21] Batch [820]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.129521,	
2017-07-25 20:19:36,098 Epoch[21] Batch [830]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.129524,	
2017-07-25 20:19:40,092 Epoch[21] Batch [840]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.129356,	
2017-07-25 20:19:44,283 Epoch[21] Batch [850]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.129195,	
2017-07-25 20:19:48,351 Epoch[21] Batch [860]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.129050,	
2017-07-25 20:19:52,288 Epoch[21] Batch [870]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.129139,	
2017-07-25 20:19:56,456 Epoch[21] Batch [880]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.129053,	
2017-07-25 20:20:00,359 Epoch[21] Batch [890]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.128943,	
2017-07-25 20:20:04,330 Epoch[21] Batch [900]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.128850,	
2017-07-25 20:20:08,265 Epoch[21] Batch [910]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.129009,	
2017-07-25 20:20:12,123 Epoch[21] Batch [920]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.128928,	
2017-07-25 20:20:16,124 Epoch[21] Batch [930]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.128639,	
2017-07-25 20:20:20,048 Epoch[21] Batch [940]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.128641,	
2017-07-25 20:20:23,968 Epoch[21] Batch [950]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.128711,	
2017-07-25 20:20:28,011 Epoch[21] Batch [960]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.128646,	
2017-07-25 20:20:31,978 Epoch[21] Batch [970]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.128793,	
2017-07-25 20:20:36,050 Epoch[21] Batch [980]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.128751,	
2017-07-25 20:20:40,047 Epoch[21] Batch [990]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.129029,	
2017-07-25 20:20:44,027 Epoch[21] Batch [1000]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.129004,	
2017-07-25 20:20:48,082 Epoch[21] Batch [1010]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.129187,	
2017-07-25 20:20:51,952 Epoch[21] Batch [1020]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.129238,	
2017-07-25 20:20:55,904 Epoch[21] Batch [1030]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.129211,	
2017-07-25 20:20:59,789 Epoch[21] Batch [1040]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.129102,	
2017-07-25 20:21:03,645 Epoch[21] Batch [1050]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.129048,	
2017-07-25 20:21:07,558 Epoch[21] Batch [1060]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.129186,	
2017-07-25 20:21:11,550 Epoch[21] Batch [1070]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.129148,	
2017-07-25 20:21:15,562 Epoch[21] Batch [1080]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.129120,	
2017-07-25 20:21:19,548 Epoch[21] Batch [1090]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.129118,	
2017-07-25 20:21:23,603 Epoch[21] Batch [1100]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.129030,	
2017-07-25 20:21:27,623 Epoch[21] Batch [1110]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.128984,	
2017-07-25 20:21:31,540 Epoch[21] Batch [1120]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.129112,	
2017-07-25 20:21:35,518 Epoch[21] Batch [1130]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.128968,	
2017-07-25 20:21:39,497 Epoch[21] Batch [1140]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.128882,	
2017-07-25 20:21:43,551 Epoch[21] Batch [1150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.128780,	
2017-07-25 20:21:47,523 Epoch[21] Batch [1160]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.128738,	
2017-07-25 20:21:51,478 Epoch[21] Batch [1170]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.128637,	
2017-07-25 20:21:55,480 Epoch[21] Batch [1180]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.128557,	
2017-07-25 20:21:59,527 Epoch[21] Batch [1190]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.128622,	
2017-07-25 20:22:03,450 Epoch[21] Batch [1200]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.128569,	
2017-07-25 20:22:07,393 Epoch[21] Batch [1210]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.128625,	
2017-07-25 20:22:11,404 Epoch[21] Batch [1220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.128630,	
2017-07-25 20:22:15,418 Epoch[21] Batch [1230]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.128524,	
2017-07-25 20:22:19,351 Epoch[21] Batch [1240]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.128357,	
2017-07-25 20:22:23,357 Epoch[21] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.128417,	
2017-07-25 20:22:27,291 Epoch[21] Batch [1260]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.128320,	
2017-07-25 20:22:31,255 Epoch[21] Batch [1270]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.128350,	
2017-07-25 20:22:35,243 Epoch[21] Batch [1280]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.128293,	
2017-07-25 20:22:39,204 Epoch[21] Batch [1290]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.128320,	
2017-07-25 20:22:43,104 Epoch[21] Batch [1300]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.128273,	
2017-07-25 20:22:47,047 Epoch[21] Batch [1310]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.128214,	
2017-07-25 20:22:50,901 Epoch[21] Batch [1320]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.128215,	
2017-07-25 20:22:55,005 Epoch[21] Batch [1330]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.128336,	
2017-07-25 20:22:58,987 Epoch[21] Batch [1340]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.128319,	
2017-07-25 20:23:02,908 Epoch[21] Batch [1350]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.128319,	
2017-07-25 20:23:06,819 Epoch[21] Batch [1360]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.128385,	
2017-07-25 20:23:10,795 Epoch[21] Batch [1370]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.128394,	
2017-07-25 20:23:14,756 Epoch[21] Batch [1380]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.128374,	
2017-07-25 20:23:18,824 Epoch[21] Batch [1390]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.128374,	
2017-07-25 20:23:22,778 Epoch[21] Batch [1400]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.128258,	
2017-07-25 20:23:26,752 Epoch[21] Batch [1410]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.128122,	
2017-07-25 20:23:30,762 Epoch[21] Batch [1420]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.127998,	
2017-07-25 20:23:34,727 Epoch[21] Batch [1430]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.128001,	
2017-07-25 20:23:38,700 Epoch[21] Batch [1440]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.127941,	
2017-07-25 20:23:42,638 Epoch[21] Batch [1450]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.127933,	
2017-07-25 20:23:46,527 Epoch[21] Batch [1460]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.127956,	
2017-07-25 20:23:50,489 Epoch[21] Batch [1470]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.127940,	
2017-07-25 20:23:54,533 Epoch[21] Batch [1480]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.127961,	
2017-07-25 20:23:56,938 Epoch[21] Train-FCNLogLoss=0.128000
2017-07-25 20:23:56,938 Epoch[21] Time cost=592.091
2017-07-25 20:23:57,680 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.params"
2017-07-25 20:23:59,226 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0022.states"
2017-07-25 20:24:03,873 Epoch[22] Batch [10]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.121300,	
2017-07-25 20:24:07,999 Epoch[22] Batch [20]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.116121,	
2017-07-25 20:24:11,969 Epoch[22] Batch [30]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.119784,	
2017-07-25 20:24:15,941 Epoch[22] Batch [40]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.121859,	
2017-07-25 20:24:19,917 Epoch[22] Batch [50]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.123995,	
2017-07-25 20:24:23,827 Epoch[22] Batch [60]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.129284,	
2017-07-25 20:24:27,838 Epoch[22] Batch [70]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.127070,	
2017-07-25 20:24:31,842 Epoch[22] Batch [80]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.126430,	
2017-07-25 20:24:35,948 Epoch[22] Batch [90]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.125494,	
2017-07-25 20:24:39,837 Epoch[22] Batch [100]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.127315,	
2017-07-25 20:24:43,815 Epoch[22] Batch [110]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.126337,	
2017-07-25 20:24:47,887 Epoch[22] Batch [120]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.125570,	
2017-07-25 20:24:51,916 Epoch[22] Batch [130]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.125020,	
2017-07-25 20:24:55,903 Epoch[22] Batch [140]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.124906,	
2017-07-25 20:24:59,934 Epoch[22] Batch [150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.125101,	
2017-07-25 20:25:03,903 Epoch[22] Batch [160]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.124458,	
2017-07-25 20:25:07,829 Epoch[22] Batch [170]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.124297,	
2017-07-25 20:25:11,743 Epoch[22] Batch [180]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.123560,	
2017-07-25 20:25:15,706 Epoch[22] Batch [190]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.123499,	
2017-07-25 20:25:19,695 Epoch[22] Batch [200]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.123001,	
2017-07-25 20:25:23,654 Epoch[22] Batch [210]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.123587,	
2017-07-25 20:25:27,659 Epoch[22] Batch [220]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.123558,	
2017-07-25 20:25:31,594 Epoch[22] Batch [230]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.123449,	
2017-07-25 20:25:35,583 Epoch[22] Batch [240]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.123373,	
2017-07-25 20:25:39,486 Epoch[22] Batch [250]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.123009,	
2017-07-25 20:25:43,496 Epoch[22] Batch [260]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.123129,	
2017-07-25 20:25:47,506 Epoch[22] Batch [270]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.122981,	
2017-07-25 20:25:51,375 Epoch[22] Batch [280]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.123466,	
2017-07-25 20:25:55,243 Epoch[22] Batch [290]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.123191,	
2017-07-25 20:25:59,153 Epoch[22] Batch [300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.123396,	
2017-07-25 20:26:03,167 Epoch[22] Batch [310]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.123413,	
2017-07-25 20:26:07,141 Epoch[22] Batch [320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.123647,	
2017-07-25 20:26:11,052 Epoch[22] Batch [330]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.123739,	
2017-07-25 20:26:15,119 Epoch[22] Batch [340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.123788,	
2017-07-25 20:26:19,080 Epoch[22] Batch [350]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.123568,	
2017-07-25 20:26:23,080 Epoch[22] Batch [360]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.123271,	
2017-07-25 20:26:27,075 Epoch[22] Batch [370]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.123061,	
2017-07-25 20:26:31,124 Epoch[22] Batch [380]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.122962,	
2017-07-25 20:26:35,208 Epoch[22] Batch [390]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.122708,	
2017-07-25 20:26:39,118 Epoch[22] Batch [400]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.122911,	
2017-07-25 20:26:43,052 Epoch[22] Batch [410]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.123275,	
2017-07-25 20:26:47,004 Epoch[22] Batch [420]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.123242,	
2017-07-25 20:26:51,020 Epoch[22] Batch [430]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.123605,	
2017-07-25 20:26:54,961 Epoch[22] Batch [440]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.123455,	
2017-07-25 20:26:59,021 Epoch[22] Batch [450]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.123290,	
2017-07-25 20:27:03,043 Epoch[22] Batch [460]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.123409,	
2017-07-25 20:27:07,082 Epoch[22] Batch [470]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.123341,	
2017-07-25 20:27:10,980 Epoch[22] Batch [480]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.123274,	
2017-07-25 20:27:15,080 Epoch[22] Batch [490]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.122962,	
2017-07-25 20:27:19,105 Epoch[22] Batch [500]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.123213,	
2017-07-25 20:27:23,118 Epoch[22] Batch [510]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.123632,	
2017-07-25 20:27:27,233 Epoch[22] Batch [520]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.123714,	
2017-07-25 20:27:31,237 Epoch[22] Batch [530]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.123558,	
2017-07-25 20:27:35,180 Epoch[22] Batch [540]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.123361,	
2017-07-25 20:27:39,178 Epoch[22] Batch [550]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.123367,	
2017-07-25 20:27:43,257 Epoch[22] Batch [560]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.123211,	
2017-07-25 20:27:47,237 Epoch[22] Batch [570]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.123132,	
2017-07-25 20:27:51,305 Epoch[22] Batch [580]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.123170,	
2017-07-25 20:27:55,225 Epoch[22] Batch [590]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.123175,	
2017-07-25 20:27:59,132 Epoch[22] Batch [600]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.123366,	
2017-07-25 20:28:03,013 Epoch[22] Batch [610]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.123638,	
2017-07-25 20:28:07,022 Epoch[22] Batch [620]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.123461,	
2017-07-25 20:28:11,011 Epoch[22] Batch [630]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.123207,	
2017-07-25 20:28:15,043 Epoch[22] Batch [640]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.124398,	
2017-07-25 20:28:19,024 Epoch[22] Batch [650]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.124835,	
2017-07-25 20:28:23,047 Epoch[22] Batch [660]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.125397,	
2017-07-25 20:28:26,913 Epoch[22] Batch [670]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.126100,	
2017-07-25 20:28:30,838 Epoch[22] Batch [680]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.126688,	
2017-07-25 20:28:34,852 Epoch[22] Batch [690]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.126755,	
2017-07-25 20:28:38,783 Epoch[22] Batch [700]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.126918,	
2017-07-25 20:28:42,753 Epoch[22] Batch [710]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.126821,	
2017-07-25 20:28:46,813 Epoch[22] Batch [720]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.126906,	
2017-07-25 20:28:50,732 Epoch[22] Batch [730]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.126836,	
2017-07-25 20:28:54,840 Epoch[22] Batch [740]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.126727,	
2017-07-25 20:28:58,836 Epoch[22] Batch [750]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.126908,	
2017-07-25 20:29:02,835 Epoch[22] Batch [760]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.126785,	
2017-07-25 20:29:06,680 Epoch[22] Batch [770]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.126732,	
2017-07-25 20:29:10,577 Epoch[22] Batch [780]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.126591,	
2017-07-25 20:29:14,601 Epoch[22] Batch [790]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.126661,	
2017-07-25 20:29:18,536 Epoch[22] Batch [800]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.126716,	
2017-07-25 20:29:22,552 Epoch[22] Batch [810]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.126621,	
2017-07-25 20:29:26,488 Epoch[22] Batch [820]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.126584,	
2017-07-25 20:29:30,466 Epoch[22] Batch [830]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.126356,	
2017-07-25 20:29:34,554 Epoch[22] Batch [840]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.126213,	
2017-07-25 20:29:38,500 Epoch[22] Batch [850]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.125946,	
2017-07-25 20:29:42,587 Epoch[22] Batch [860]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.125950,	
2017-07-25 20:29:46,577 Epoch[22] Batch [870]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.126286,	
2017-07-25 20:29:50,550 Epoch[22] Batch [880]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.126244,	
2017-07-25 20:29:54,495 Epoch[22] Batch [890]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.126175,	
2017-07-25 20:29:58,439 Epoch[22] Batch [900]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.126187,	
2017-07-25 20:30:02,403 Epoch[22] Batch [910]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.126210,	
2017-07-25 20:30:06,343 Epoch[22] Batch [920]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.126185,	
2017-07-25 20:30:10,159 Epoch[22] Batch [930]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.126075,	
2017-07-25 20:30:14,003 Epoch[22] Batch [940]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.126166,	
2017-07-25 20:30:17,983 Epoch[22] Batch [950]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.126192,	
2017-07-25 20:30:21,982 Epoch[22] Batch [960]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.126066,	
2017-07-25 20:30:25,976 Epoch[22] Batch [970]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.125991,	
2017-07-25 20:30:30,089 Epoch[22] Batch [980]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.126070,	
2017-07-25 20:30:34,033 Epoch[22] Batch [990]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.126062,	
2017-07-25 20:30:38,044 Epoch[22] Batch [1000]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.125931,	
2017-07-25 20:30:42,002 Epoch[22] Batch [1010]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.125774,	
2017-07-25 20:30:45,939 Epoch[22] Batch [1020]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.125812,	
2017-07-25 20:30:49,930 Epoch[22] Batch [1030]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.125871,	
2017-07-25 20:30:53,955 Epoch[22] Batch [1040]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.125899,	
2017-07-25 20:30:58,100 Epoch[22] Batch [1050]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.125769,	
2017-07-25 20:31:02,024 Epoch[22] Batch [1060]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.125767,	
2017-07-25 20:31:06,067 Epoch[22] Batch [1070]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.125781,	
2017-07-25 20:31:09,988 Epoch[22] Batch [1080]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.125772,	
2017-07-25 20:31:13,996 Epoch[22] Batch [1090]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.125794,	
2017-07-25 20:31:17,973 Epoch[22] Batch [1100]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.125688,	
2017-07-25 20:31:21,865 Epoch[22] Batch [1110]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.125582,	
2017-07-25 20:31:25,850 Epoch[22] Batch [1120]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.125596,	
2017-07-25 20:31:29,837 Epoch[22] Batch [1130]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.125470,	
2017-07-25 20:31:33,718 Epoch[22] Batch [1140]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.125505,	
2017-07-25 20:31:37,745 Epoch[22] Batch [1150]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.125389,	
2017-07-25 20:31:41,677 Epoch[22] Batch [1160]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.125470,	
2017-07-25 20:31:45,613 Epoch[22] Batch [1170]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.125574,	
2017-07-25 20:31:49,568 Epoch[22] Batch [1180]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.125410,	
2017-07-25 20:31:53,584 Epoch[22] Batch [1190]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.125423,	
2017-07-25 20:31:57,423 Epoch[22] Batch [1200]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.125428,	
2017-07-25 20:32:01,323 Epoch[22] Batch [1210]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.125302,	
2017-07-25 20:32:05,279 Epoch[22] Batch [1220]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.125277,	
2017-07-25 20:32:09,403 Epoch[22] Batch [1230]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.125195,	
2017-07-25 20:32:13,348 Epoch[22] Batch [1240]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.125130,	
2017-07-25 20:32:17,384 Epoch[22] Batch [1250]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.125087,	
2017-07-25 20:32:21,445 Epoch[22] Batch [1260]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.124944,	
2017-07-25 20:32:25,555 Epoch[22] Batch [1270]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.124872,	
2017-07-25 20:32:29,579 Epoch[22] Batch [1280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.124709,	
2017-07-25 20:32:33,457 Epoch[22] Batch [1290]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.124771,	
2017-07-25 20:32:37,497 Epoch[22] Batch [1300]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.124756,	
2017-07-25 20:32:41,447 Epoch[22] Batch [1310]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.124707,	
2017-07-25 20:32:45,398 Epoch[22] Batch [1320]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.124774,	
2017-07-25 20:32:49,373 Epoch[22] Batch [1330]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.124759,	
2017-07-25 20:32:53,361 Epoch[22] Batch [1340]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.124780,	
2017-07-25 20:32:57,368 Epoch[22] Batch [1350]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.124781,	
2017-07-25 20:33:01,375 Epoch[22] Batch [1360]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.124667,	
2017-07-25 20:33:05,422 Epoch[22] Batch [1370]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.124854,	
2017-07-25 20:33:09,391 Epoch[22] Batch [1380]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.124890,	
2017-07-25 20:33:13,422 Epoch[22] Batch [1390]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.124799,	
2017-07-25 20:33:17,579 Epoch[22] Batch [1400]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.124919,	
2017-07-25 20:33:21,595 Epoch[22] Batch [1410]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.124863,	
2017-07-25 20:33:25,551 Epoch[22] Batch [1420]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.124790,	
2017-07-25 20:33:29,535 Epoch[22] Batch [1430]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.124729,	
2017-07-25 20:33:33,619 Epoch[22] Batch [1440]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.124666,	
2017-07-25 20:33:37,615 Epoch[22] Batch [1450]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.124758,	
2017-07-25 20:33:41,701 Epoch[22] Batch [1460]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.124797,	
2017-07-25 20:33:45,658 Epoch[22] Batch [1470]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.124787,	
2017-07-25 20:33:49,642 Epoch[22] Batch [1480]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.124757,	
2017-07-25 20:33:52,085 Epoch[22] Train-FCNLogLoss=0.124757
2017-07-25 20:33:52,085 Epoch[22] Time cost=592.859
2017-07-25 20:33:52,806 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.params"
2017-07-25 20:33:54,393 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0023.states"
2017-07-25 20:33:59,199 Epoch[23] Batch [10]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117452,	
2017-07-25 20:34:03,130 Epoch[23] Batch [20]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116754,	
2017-07-25 20:34:07,195 Epoch[23] Batch [30]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.114739,	
2017-07-25 20:34:11,235 Epoch[23] Batch [40]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.116111,	
2017-07-25 20:34:15,188 Epoch[23] Batch [50]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.116022,	
2017-07-25 20:34:19,281 Epoch[23] Batch [60]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.115156,	
2017-07-25 20:34:23,363 Epoch[23] Batch [70]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114818,	
2017-07-25 20:34:27,282 Epoch[23] Batch [80]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.115212,	
2017-07-25 20:34:31,268 Epoch[23] Batch [90]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.115092,	
2017-07-25 20:34:35,301 Epoch[23] Batch [100]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116000,	
2017-07-25 20:34:39,277 Epoch[23] Batch [110]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.114757,	
2017-07-25 20:34:43,343 Epoch[23] Batch [120]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.115272,	
2017-07-25 20:34:47,258 Epoch[23] Batch [130]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.117955,	
2017-07-25 20:34:51,325 Epoch[23] Batch [140]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.118895,	
2017-07-25 20:34:55,304 Epoch[23] Batch [150]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.119026,	
2017-07-25 20:34:59,169 Epoch[23] Batch [160]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.119108,	
2017-07-25 20:35:03,181 Epoch[23] Batch [170]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.119086,	
2017-07-25 20:35:07,167 Epoch[23] Batch [180]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.119298,	
2017-07-25 20:35:11,163 Epoch[23] Batch [190]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.121071,	
2017-07-25 20:35:15,324 Epoch[23] Batch [200]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.121824,	
2017-07-25 20:35:19,323 Epoch[23] Batch [210]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.122206,	
2017-07-25 20:35:23,297 Epoch[23] Batch [220]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.121841,	
2017-07-25 20:35:27,302 Epoch[23] Batch [230]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.122029,	
2017-07-25 20:35:31,306 Epoch[23] Batch [240]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.121618,	
2017-07-25 20:35:35,205 Epoch[23] Batch [250]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.121157,	
2017-07-25 20:35:39,248 Epoch[23] Batch [260]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.121631,	
2017-07-25 20:35:43,228 Epoch[23] Batch [270]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.121530,	
2017-07-25 20:35:47,090 Epoch[23] Batch [280]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.121144,	
2017-07-25 20:35:51,094 Epoch[23] Batch [290]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.120776,	
2017-07-25 20:35:55,188 Epoch[23] Batch [300]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.120545,	
2017-07-25 20:35:59,154 Epoch[23] Batch [310]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.120896,	
2017-07-25 20:36:03,132 Epoch[23] Batch [320]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.120557,	
2017-07-25 20:36:07,049 Epoch[23] Batch [330]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.120889,	
2017-07-25 20:36:11,120 Epoch[23] Batch [340]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.121139,	
2017-07-25 20:36:15,090 Epoch[23] Batch [350]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.121350,	
2017-07-25 20:36:18,963 Epoch[23] Batch [360]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.121338,	
2017-07-25 20:36:23,065 Epoch[23] Batch [370]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.121619,	
2017-07-25 20:36:27,046 Epoch[23] Batch [380]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.121418,	
2017-07-25 20:36:31,024 Epoch[23] Batch [390]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121362,	
2017-07-25 20:36:34,964 Epoch[23] Batch [400]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.121619,	
2017-07-25 20:36:38,942 Epoch[23] Batch [410]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121373,	
2017-07-25 20:36:42,830 Epoch[23] Batch [420]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.121219,	
2017-07-25 20:36:46,718 Epoch[23] Batch [430]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.121060,	
2017-07-25 20:36:50,727 Epoch[23] Batch [440]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.121138,	
2017-07-25 20:36:54,711 Epoch[23] Batch [450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.121053,	
2017-07-25 20:36:58,648 Epoch[23] Batch [460]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.121381,	
2017-07-25 20:37:02,660 Epoch[23] Batch [470]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.121348,	
2017-07-25 20:37:06,676 Epoch[23] Batch [480]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.121362,	
2017-07-25 20:37:10,623 Epoch[23] Batch [490]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.121583,	
2017-07-25 20:37:14,524 Epoch[23] Batch [500]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.121979,	
2017-07-25 20:37:18,562 Epoch[23] Batch [510]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.122354,	
2017-07-25 20:37:22,561 Epoch[23] Batch [520]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.122198,	
2017-07-25 20:37:26,630 Epoch[23] Batch [530]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.122190,	
2017-07-25 20:37:30,607 Epoch[23] Batch [540]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.122375,	
2017-07-25 20:37:34,616 Epoch[23] Batch [550]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.122141,	
2017-07-25 20:37:38,650 Epoch[23] Batch [560]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.122320,	
2017-07-25 20:37:42,626 Epoch[23] Batch [570]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.122110,	
2017-07-25 20:37:46,640 Epoch[23] Batch [580]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.122059,	
2017-07-25 20:37:50,701 Epoch[23] Batch [590]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.121613,	
2017-07-25 20:37:54,719 Epoch[23] Batch [600]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.121558,	
2017-07-25 20:37:58,733 Epoch[23] Batch [610]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.121399,	
2017-07-25 20:38:02,710 Epoch[23] Batch [620]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121696,	
2017-07-25 20:38:06,538 Epoch[23] Batch [630]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.121566,	
2017-07-25 20:38:10,484 Epoch[23] Batch [640]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.121419,	
2017-07-25 20:38:14,463 Epoch[23] Batch [650]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.121263,	
2017-07-25 20:38:18,513 Epoch[23] Batch [660]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.121185,	
2017-07-25 20:38:22,533 Epoch[23] Batch [670]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.121254,	
2017-07-25 20:38:26,578 Epoch[23] Batch [680]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.121403,	
2017-07-25 20:38:30,541 Epoch[23] Batch [690]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.121428,	
2017-07-25 20:38:34,425 Epoch[23] Batch [700]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.121533,	
2017-07-25 20:38:38,391 Epoch[23] Batch [710]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.121696,	
2017-07-25 20:38:42,328 Epoch[23] Batch [720]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.121545,	
2017-07-25 20:38:46,306 Epoch[23] Batch [730]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121612,	
2017-07-25 20:38:50,316 Epoch[23] Batch [740]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.121633,	
2017-07-25 20:38:54,246 Epoch[23] Batch [750]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.121567,	
2017-07-25 20:38:58,237 Epoch[23] Batch [760]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.121455,	
2017-07-25 20:39:02,227 Epoch[23] Batch [770]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.121470,	
2017-07-25 20:39:06,315 Epoch[23] Batch [780]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.121555,	
2017-07-25 20:39:10,330 Epoch[23] Batch [790]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.121618,	
2017-07-25 20:39:14,278 Epoch[23] Batch [800]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.121760,	
2017-07-25 20:39:18,225 Epoch[23] Batch [810]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.121857,	
2017-07-25 20:39:22,159 Epoch[23] Batch [820]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.121818,	
2017-07-25 20:39:26,185 Epoch[23] Batch [830]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.121628,	
2017-07-25 20:39:30,208 Epoch[23] Batch [840]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.121703,	
2017-07-25 20:39:34,120 Epoch[23] Batch [850]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.121562,	
2017-07-25 20:39:38,094 Epoch[23] Batch [860]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.121680,	
2017-07-25 20:39:42,113 Epoch[23] Batch [870]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.121595,	
2017-07-25 20:39:46,258 Epoch[23] Batch [880]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.121561,	
2017-07-25 20:39:50,223 Epoch[23] Batch [890]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.121490,	
2017-07-25 20:39:54,144 Epoch[23] Batch [900]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.121658,	
2017-07-25 20:39:58,079 Epoch[23] Batch [910]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.121444,	
2017-07-25 20:40:01,934 Epoch[23] Batch [920]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.121515,	
2017-07-25 20:40:05,890 Epoch[23] Batch [930]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.121591,	
2017-07-25 20:40:09,891 Epoch[23] Batch [940]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.121637,	
2017-07-25 20:40:13,770 Epoch[23] Batch [950]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.121565,	
2017-07-25 20:40:17,712 Epoch[23] Batch [960]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.121430,	
2017-07-25 20:40:21,736 Epoch[23] Batch [970]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.121468,	
2017-07-25 20:40:25,628 Epoch[23] Batch [980]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.121419,	
2017-07-25 20:40:29,683 Epoch[23] Batch [990]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.121495,	
2017-07-25 20:40:33,736 Epoch[23] Batch [1000]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.121425,	
2017-07-25 20:40:37,814 Epoch[23] Batch [1010]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.121433,	
2017-07-25 20:40:41,838 Epoch[23] Batch [1020]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.121522,	
2017-07-25 20:40:45,815 Epoch[23] Batch [1030]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121529,	
2017-07-25 20:40:49,673 Epoch[23] Batch [1040]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.121711,	
2017-07-25 20:40:53,746 Epoch[23] Batch [1050]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.121822,	
2017-07-25 20:40:57,698 Epoch[23] Batch [1060]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.121753,	
2017-07-25 20:41:01,733 Epoch[23] Batch [1070]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.121817,	
2017-07-25 20:41:05,758 Epoch[23] Batch [1080]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.121773,	
2017-07-25 20:41:09,725 Epoch[23] Batch [1090]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.121744,	
2017-07-25 20:41:13,689 Epoch[23] Batch [1100]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.121837,	
2017-07-25 20:41:17,575 Epoch[23] Batch [1110]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.121671,	
2017-07-25 20:41:21,505 Epoch[23] Batch [1120]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.121670,	
2017-07-25 20:41:25,508 Epoch[23] Batch [1130]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.121637,	
2017-07-25 20:41:29,401 Epoch[23] Batch [1140]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.121581,	
2017-07-25 20:41:33,351 Epoch[23] Batch [1150]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.121617,	
2017-07-25 20:41:37,196 Epoch[23] Batch [1160]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.121472,	
2017-07-25 20:41:41,184 Epoch[23] Batch [1170]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.121718,	
2017-07-25 20:41:45,230 Epoch[23] Batch [1180]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.121589,	
2017-07-25 20:41:49,188 Epoch[23] Batch [1190]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.121741,	
2017-07-25 20:41:53,022 Epoch[23] Batch [1200]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.121735,	
2017-07-25 20:41:57,010 Epoch[23] Batch [1210]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.121743,	
2017-07-25 20:42:00,923 Epoch[23] Batch [1220]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.121652,	
2017-07-25 20:42:04,883 Epoch[23] Batch [1230]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.121506,	
2017-07-25 20:42:08,930 Epoch[23] Batch [1240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.121418,	
2017-07-25 20:42:12,933 Epoch[23] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.121469,	
2017-07-25 20:42:16,908 Epoch[23] Batch [1260]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.121454,	
2017-07-25 20:42:20,844 Epoch[23] Batch [1270]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.121597,	
2017-07-25 20:42:24,799 Epoch[23] Batch [1280]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.121565,	
2017-07-25 20:42:28,805 Epoch[23] Batch [1290]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.121432,	
2017-07-25 20:42:32,591 Epoch[23] Batch [1300]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.121316,	
2017-07-25 20:42:36,588 Epoch[23] Batch [1310]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.121237,	
2017-07-25 20:42:40,670 Epoch[23] Batch [1320]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.121191,	
2017-07-25 20:42:44,700 Epoch[23] Batch [1330]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.121189,	
2017-07-25 20:42:48,717 Epoch[23] Batch [1340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.121158,	
2017-07-25 20:42:52,635 Epoch[23] Batch [1350]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.121138,	
2017-07-25 20:42:56,667 Epoch[23] Batch [1360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.121233,	
2017-07-25 20:43:00,736 Epoch[23] Batch [1370]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.121270,	
2017-07-25 20:43:04,771 Epoch[23] Batch [1380]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.121314,	
2017-07-25 20:43:08,854 Epoch[23] Batch [1390]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.121378,	
2017-07-25 20:43:12,922 Epoch[23] Batch [1400]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.121358,	
2017-07-25 20:43:16,921 Epoch[23] Batch [1410]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.121452,	
2017-07-25 20:43:20,767 Epoch[23] Batch [1420]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.121317,	
2017-07-25 20:43:24,749 Epoch[23] Batch [1430]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.121300,	
2017-07-25 20:43:28,750 Epoch[23] Batch [1440]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.121245,	
2017-07-25 20:43:32,609 Epoch[23] Batch [1450]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.121206,	
2017-07-25 20:43:36,552 Epoch[23] Batch [1460]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.121207,	
2017-07-25 20:43:40,516 Epoch[23] Batch [1470]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.121191,	
2017-07-25 20:43:44,546 Epoch[23] Batch [1480]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.121241,	
2017-07-25 20:43:46,934 Epoch[23] Train-FCNLogLoss=0.121320
2017-07-25 20:43:46,935 Epoch[23] Time cost=592.541
2017-07-25 20:43:47,639 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.params"
2017-07-25 20:43:49,316 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0024.states"
2017-07-25 20:43:53,932 Epoch[24] Batch [10]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.114713,	
2017-07-25 20:43:57,947 Epoch[24] Batch [20]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113234,	
2017-07-25 20:44:01,879 Epoch[24] Batch [30]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.113499,	
2017-07-25 20:44:05,782 Epoch[24] Batch [40]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.112584,	
2017-07-25 20:44:09,748 Epoch[24] Batch [50]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.113916,	
2017-07-25 20:44:13,752 Epoch[24] Batch [60]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.111340,	
2017-07-25 20:44:17,807 Epoch[24] Batch [70]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.111946,	
2017-07-25 20:44:21,760 Epoch[24] Batch [80]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.112504,	
2017-07-25 20:44:25,612 Epoch[24] Batch [90]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.112043,	
2017-07-25 20:44:29,518 Epoch[24] Batch [100]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.113465,	
2017-07-25 20:44:33,429 Epoch[24] Batch [110]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.115704,	
2017-07-25 20:44:37,413 Epoch[24] Batch [120]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.115557,	
2017-07-25 20:44:41,326 Epoch[24] Batch [130]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.116652,	
2017-07-25 20:44:45,228 Epoch[24] Batch [140]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.115675,	
2017-07-25 20:44:49,163 Epoch[24] Batch [150]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.114301,	
2017-07-25 20:44:53,180 Epoch[24] Batch [160]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.115070,	
2017-07-25 20:44:57,128 Epoch[24] Batch [170]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.116007,	
2017-07-25 20:45:01,274 Epoch[24] Batch [180]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.116953,	
2017-07-25 20:45:05,196 Epoch[24] Batch [190]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.117231,	
2017-07-25 20:45:09,288 Epoch[24] Batch [200]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.117098,	
2017-07-25 20:45:13,406 Epoch[24] Batch [210]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.117091,	
2017-07-25 20:45:17,386 Epoch[24] Batch [220]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.116859,	
2017-07-25 20:45:21,510 Epoch[24] Batch [230]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117149,	
2017-07-25 20:45:25,578 Epoch[24] Batch [240]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117205,	
2017-07-25 20:45:29,664 Epoch[24] Batch [250]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.117237,	
2017-07-25 20:45:33,631 Epoch[24] Batch [260]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.117582,	
2017-07-25 20:45:37,558 Epoch[24] Batch [270]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.117959,	
2017-07-25 20:45:41,531 Epoch[24] Batch [280]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118339,	
2017-07-25 20:45:45,393 Epoch[24] Batch [290]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.117828,	
2017-07-25 20:45:49,329 Epoch[24] Batch [300]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.118117,	
2017-07-25 20:45:53,304 Epoch[24] Batch [310]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.117776,	
2017-07-25 20:45:57,287 Epoch[24] Batch [320]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.117412,	
2017-07-25 20:46:01,271 Epoch[24] Batch [330]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.117347,	
2017-07-25 20:46:05,305 Epoch[24] Batch [340]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.117404,	
2017-07-25 20:46:09,376 Epoch[24] Batch [350]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117598,	
2017-07-25 20:46:13,273 Epoch[24] Batch [360]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.118003,	
2017-07-25 20:46:17,209 Epoch[24] Batch [370]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.117724,	
2017-07-25 20:46:21,143 Epoch[24] Batch [380]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.117551,	
2017-07-25 20:46:25,166 Epoch[24] Batch [390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117875,	
2017-07-25 20:46:29,275 Epoch[24] Batch [400]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117760,	
2017-07-25 20:46:33,257 Epoch[24] Batch [410]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117665,	
2017-07-25 20:46:37,236 Epoch[24] Batch [420]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117948,	
2017-07-25 20:46:41,204 Epoch[24] Batch [430]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.118004,	
2017-07-25 20:46:45,155 Epoch[24] Batch [440]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.119264,	
2017-07-25 20:46:49,013 Epoch[24] Batch [450]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.119676,	
2017-07-25 20:46:53,003 Epoch[24] Batch [460]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119754,	
2017-07-25 20:46:57,004 Epoch[24] Batch [470]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.119759,	
2017-07-25 20:47:01,029 Epoch[24] Batch [480]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.119764,	
2017-07-25 20:47:05,017 Epoch[24] Batch [490]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119556,	
2017-07-25 20:47:09,051 Epoch[24] Batch [500]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.119790,	
2017-07-25 20:47:12,976 Epoch[24] Batch [510]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.119781,	
2017-07-25 20:47:17,061 Epoch[24] Batch [520]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.119525,	
2017-07-25 20:47:21,058 Epoch[24] Batch [530]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.119640,	
2017-07-25 20:47:24,966 Epoch[24] Batch [540]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.119698,	
2017-07-25 20:47:28,994 Epoch[24] Batch [550]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.119472,	
2017-07-25 20:47:33,000 Epoch[24] Batch [560]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.119481,	
2017-07-25 20:47:36,964 Epoch[24] Batch [570]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.119297,	
2017-07-25 20:47:41,074 Epoch[24] Batch [580]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.119176,	
2017-07-25 20:47:45,102 Epoch[24] Batch [590]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.118955,	
2017-07-25 20:47:49,040 Epoch[24] Batch [600]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.118839,	
2017-07-25 20:47:53,057 Epoch[24] Batch [610]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.118617,	
2017-07-25 20:47:57,155 Epoch[24] Batch [620]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118485,	
2017-07-25 20:48:01,130 Epoch[24] Batch [630]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118468,	
2017-07-25 20:48:05,003 Epoch[24] Batch [640]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.118427,	
2017-07-25 20:48:08,973 Epoch[24] Batch [650]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.118483,	
2017-07-25 20:48:12,858 Epoch[24] Batch [660]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.118618,	
2017-07-25 20:48:16,834 Epoch[24] Batch [670]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.118655,	
2017-07-25 20:48:20,860 Epoch[24] Batch [680]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.118604,	
2017-07-25 20:48:24,739 Epoch[24] Batch [690]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.118367,	
2017-07-25 20:48:28,781 Epoch[24] Batch [700]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.118246,	
2017-07-25 20:48:32,777 Epoch[24] Batch [710]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118062,	
2017-07-25 20:48:36,853 Epoch[24] Batch [720]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118041,	
2017-07-25 20:48:40,707 Epoch[24] Batch [730]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.118110,	
2017-07-25 20:48:44,821 Epoch[24] Batch [740]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.118107,	
2017-07-25 20:48:48,742 Epoch[24] Batch [750]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.118080,	
2017-07-25 20:48:52,644 Epoch[24] Batch [760]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.118120,	
2017-07-25 20:48:56,545 Epoch[24] Batch [770]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.118094,	
2017-07-25 20:49:00,495 Epoch[24] Batch [780]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.118174,	
2017-07-25 20:49:04,377 Epoch[24] Batch [790]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.118011,	
2017-07-25 20:49:08,430 Epoch[24] Batch [800]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.117861,	
2017-07-25 20:49:12,334 Epoch[24] Batch [810]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.117901,	
2017-07-25 20:49:16,276 Epoch[24] Batch [820]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.118026,	
2017-07-25 20:49:20,257 Epoch[24] Batch [830]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117937,	
2017-07-25 20:49:24,175 Epoch[24] Batch [840]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.118214,	
2017-07-25 20:49:28,070 Epoch[24] Batch [850]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.118424,	
2017-07-25 20:49:32,010 Epoch[24] Batch [860]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.118475,	
2017-07-25 20:49:35,932 Epoch[24] Batch [870]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.118378,	
2017-07-25 20:49:39,851 Epoch[24] Batch [880]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.118301,	
2017-07-25 20:49:43,824 Epoch[24] Batch [890]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118446,	
2017-07-25 20:49:47,871 Epoch[24] Batch [900]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.118406,	
2017-07-25 20:49:51,857 Epoch[24] Batch [910]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118373,	
2017-07-25 20:49:55,863 Epoch[24] Batch [920]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.118426,	
2017-07-25 20:49:59,810 Epoch[24] Batch [930]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.118231,	
2017-07-25 20:50:03,791 Epoch[24] Batch [940]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.118208,	
2017-07-25 20:50:07,901 Epoch[24] Batch [950]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.118134,	
2017-07-25 20:50:11,864 Epoch[24] Batch [960]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.118148,	
2017-07-25 20:50:15,891 Epoch[24] Batch [970]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.118053,	
2017-07-25 20:50:19,888 Epoch[24] Batch [980]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118064,	
2017-07-25 20:50:23,943 Epoch[24] Batch [990]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.118072,	
2017-07-25 20:50:27,847 Epoch[24] Batch [1000]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.118130,	
2017-07-25 20:50:31,837 Epoch[24] Batch [1010]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.118297,	
2017-07-25 20:50:35,734 Epoch[24] Batch [1020]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.118167,	
2017-07-25 20:50:39,783 Epoch[24] Batch [1030]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.118342,	
2017-07-25 20:50:43,688 Epoch[24] Batch [1040]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.118538,	
2017-07-25 20:50:47,607 Epoch[24] Batch [1050]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.118452,	
2017-07-25 20:50:51,561 Epoch[24] Batch [1060]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.118586,	
2017-07-25 20:50:55,549 Epoch[24] Batch [1070]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.118598,	
2017-07-25 20:50:59,404 Epoch[24] Batch [1080]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.118613,	
2017-07-25 20:51:03,340 Epoch[24] Batch [1090]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.118729,	
2017-07-25 20:51:07,395 Epoch[24] Batch [1100]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.118865,	
2017-07-25 20:51:11,368 Epoch[24] Batch [1110]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118911,	
2017-07-25 20:51:15,290 Epoch[24] Batch [1120]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.118907,	
2017-07-25 20:51:19,321 Epoch[24] Batch [1130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.118865,	
2017-07-25 20:51:23,146 Epoch[24] Batch [1140]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.118914,	
2017-07-25 20:51:27,034 Epoch[24] Batch [1150]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.118897,	
2017-07-25 20:51:30,837 Epoch[24] Batch [1160]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.118888,	
2017-07-25 20:51:34,800 Epoch[24] Batch [1170]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.118904,	
2017-07-25 20:51:38,652 Epoch[24] Batch [1180]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.118852,	
2017-07-25 20:51:42,649 Epoch[24] Batch [1190]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118909,	
2017-07-25 20:51:46,568 Epoch[24] Batch [1200]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.118928,	
2017-07-25 20:51:50,535 Epoch[24] Batch [1210]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.118913,	
2017-07-25 20:51:54,435 Epoch[24] Batch [1220]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.118922,	
2017-07-25 20:51:58,324 Epoch[24] Batch [1230]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.118989,	
2017-07-25 20:52:02,313 Epoch[24] Batch [1240]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119097,	
2017-07-25 20:52:06,316 Epoch[24] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.119251,	
2017-07-25 20:52:10,386 Epoch[24] Batch [1260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.119152,	
2017-07-25 20:52:14,381 Epoch[24] Batch [1270]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.119304,	
2017-07-25 20:52:18,309 Epoch[24] Batch [1280]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.119339,	
2017-07-25 20:52:22,297 Epoch[24] Batch [1290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119386,	
2017-07-25 20:52:26,240 Epoch[24] Batch [1300]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.119680,	
2017-07-25 20:52:30,136 Epoch[24] Batch [1310]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.119581,	
2017-07-25 20:52:34,186 Epoch[24] Batch [1320]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.119749,	
2017-07-25 20:52:38,257 Epoch[24] Batch [1330]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.119655,	
2017-07-25 20:52:42,168 Epoch[24] Batch [1340]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.119679,	
2017-07-25 20:52:46,106 Epoch[24] Batch [1350]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.119644,	
2017-07-25 20:52:50,077 Epoch[24] Batch [1360]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.119588,	
2017-07-25 20:52:54,005 Epoch[24] Batch [1370]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.119514,	
2017-07-25 20:52:57,945 Epoch[24] Batch [1380]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.119528,	
2017-07-25 20:53:01,948 Epoch[24] Batch [1390]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.119423,	
2017-07-25 20:53:05,828 Epoch[24] Batch [1400]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.119439,	
2017-07-25 20:53:09,815 Epoch[24] Batch [1410]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119431,	
2017-07-25 20:53:13,890 Epoch[24] Batch [1420]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.119463,	
2017-07-25 20:53:17,877 Epoch[24] Batch [1430]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119332,	
2017-07-25 20:53:21,882 Epoch[24] Batch [1440]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.119272,	
2017-07-25 20:53:25,837 Epoch[24] Batch [1450]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.119197,	
2017-07-25 20:53:30,008 Epoch[24] Batch [1460]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.119201,	
2017-07-25 20:53:34,027 Epoch[24] Batch [1470]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.119154,	
2017-07-25 20:53:37,903 Epoch[24] Batch [1480]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.119339,	
2017-07-25 20:53:40,312 Epoch[24] Train-FCNLogLoss=0.119344
2017-07-25 20:53:40,312 Epoch[24] Time cost=590.996
2017-07-25 20:53:41,022 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.params"
2017-07-25 20:53:42,693 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0025.states"
2017-07-25 20:53:47,493 Epoch[25] Batch [10]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.136450,	
2017-07-25 20:53:51,396 Epoch[25] Batch [20]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.128804,	
2017-07-25 20:53:55,439 Epoch[25] Batch [30]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.123172,	
2017-07-25 20:53:59,489 Epoch[25] Batch [40]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.120848,	
2017-07-25 20:54:03,617 Epoch[25] Batch [50]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.123021,	
2017-07-25 20:54:07,673 Epoch[25] Batch [60]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.121387,	
2017-07-25 20:54:11,665 Epoch[25] Batch [70]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.121068,	
2017-07-25 20:54:15,669 Epoch[25] Batch [80]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.119250,	
2017-07-25 20:54:19,614 Epoch[25] Batch [90]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.119281,	
2017-07-25 20:54:23,452 Epoch[25] Batch [100]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.119434,	
2017-07-25 20:54:27,447 Epoch[25] Batch [110]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.120409,	
2017-07-25 20:54:31,460 Epoch[25] Batch [120]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.119875,	
2017-07-25 20:54:35,442 Epoch[25] Batch [130]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.120801,	
2017-07-25 20:54:39,464 Epoch[25] Batch [140]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.120051,	
2017-07-25 20:54:43,478 Epoch[25] Batch [150]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.120106,	
2017-07-25 20:54:47,368 Epoch[25] Batch [160]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.120341,	
2017-07-25 20:54:51,354 Epoch[25] Batch [170]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.120187,	
2017-07-25 20:54:55,386 Epoch[25] Batch [180]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.119439,	
2017-07-25 20:54:59,448 Epoch[25] Batch [190]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.119223,	
2017-07-25 20:55:03,319 Epoch[25] Batch [200]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.119154,	
2017-07-25 20:55:07,314 Epoch[25] Batch [210]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.119583,	
2017-07-25 20:55:11,328 Epoch[25] Batch [220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.119752,	
2017-07-25 20:55:15,294 Epoch[25] Batch [230]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.119009,	
2017-07-25 20:55:19,258 Epoch[25] Batch [240]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.119136,	
2017-07-25 20:55:23,247 Epoch[25] Batch [250]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119071,	
2017-07-25 20:55:27,276 Epoch[25] Batch [260]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.119446,	
2017-07-25 20:55:31,169 Epoch[25] Batch [270]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.119295,	
2017-07-25 20:55:35,095 Epoch[25] Batch [280]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.118801,	
2017-07-25 20:55:39,004 Epoch[25] Batch [290]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.118842,	
2017-07-25 20:55:43,032 Epoch[25] Batch [300]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.118472,	
2017-07-25 20:55:47,005 Epoch[25] Batch [310]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118501,	
2017-07-25 20:55:51,068 Epoch[25] Batch [320]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.118114,	
2017-07-25 20:55:54,965 Epoch[25] Batch [330]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.117712,	
2017-07-25 20:55:58,946 Epoch[25] Batch [340]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117999,	
2017-07-25 20:56:02,961 Epoch[25] Batch [350]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.118114,	
2017-07-25 20:56:07,019 Epoch[25] Batch [360]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.117657,	
2017-07-25 20:56:10,919 Epoch[25] Batch [370]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.117797,	
2017-07-25 20:56:14,882 Epoch[25] Batch [380]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.117705,	
2017-07-25 20:56:18,833 Epoch[25] Batch [390]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.118062,	
2017-07-25 20:56:22,848 Epoch[25] Batch [400]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.118085,	
2017-07-25 20:56:26,981 Epoch[25] Batch [410]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.118243,	
2017-07-25 20:56:31,012 Epoch[25] Batch [420]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117997,	
2017-07-25 20:56:34,972 Epoch[25] Batch [430]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.117613,	
2017-07-25 20:56:38,951 Epoch[25] Batch [440]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117615,	
2017-07-25 20:56:42,969 Epoch[25] Batch [450]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.117206,	
2017-07-25 20:56:47,043 Epoch[25] Batch [460]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.117425,	
2017-07-25 20:56:51,075 Epoch[25] Batch [470]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.117325,	
2017-07-25 20:56:55,113 Epoch[25] Batch [480]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.117267,	
2017-07-25 20:56:59,093 Epoch[25] Batch [490]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117196,	
2017-07-25 20:57:03,003 Epoch[25] Batch [500]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.117134,	
2017-07-25 20:57:06,902 Epoch[25] Batch [510]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.117134,	
2017-07-25 20:57:10,925 Epoch[25] Batch [520]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.116877,	
2017-07-25 20:57:14,808 Epoch[25] Batch [530]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.116953,	
2017-07-25 20:57:18,807 Epoch[25] Batch [540]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116750,	
2017-07-25 20:57:22,763 Epoch[25] Batch [550]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.116600,	
2017-07-25 20:57:26,752 Epoch[25] Batch [560]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116685,	
2017-07-25 20:57:30,676 Epoch[25] Batch [570]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.116502,	
2017-07-25 20:57:34,766 Epoch[25] Batch [580]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116499,	
2017-07-25 20:57:38,812 Epoch[25] Batch [590]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116485,	
2017-07-25 20:57:42,843 Epoch[25] Batch [600]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116289,	
2017-07-25 20:57:46,859 Epoch[25] Batch [610]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116163,	
2017-07-25 20:57:50,838 Epoch[25] Batch [620]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.116159,	
2017-07-25 20:57:54,775 Epoch[25] Batch [630]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.116087,	
2017-07-25 20:57:58,632 Epoch[25] Batch [640]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.115967,	
2017-07-25 20:58:02,713 Epoch[25] Batch [650]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.115706,	
2017-07-25 20:58:06,576 Epoch[25] Batch [660]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.115624,	
2017-07-25 20:58:10,513 Epoch[25] Batch [670]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.115632,	
2017-07-25 20:58:14,511 Epoch[25] Batch [680]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.115717,	
2017-07-25 20:58:18,329 Epoch[25] Batch [690]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.115933,	
2017-07-25 20:58:22,272 Epoch[25] Batch [700]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.115752,	
2017-07-25 20:58:26,193 Epoch[25] Batch [710]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.115726,	
2017-07-25 20:58:30,153 Epoch[25] Batch [720]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.115873,	
2017-07-25 20:58:34,239 Epoch[25] Batch [730]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116094,	
2017-07-25 20:58:38,174 Epoch[25] Batch [740]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.116034,	
2017-07-25 20:58:42,315 Epoch[25] Batch [750]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116396,	
2017-07-25 20:58:46,335 Epoch[25] Batch [760]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116384,	
2017-07-25 20:58:50,210 Epoch[25] Batch [770]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.116586,	
2017-07-25 20:58:54,152 Epoch[25] Batch [780]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.116506,	
2017-07-25 20:58:58,153 Epoch[25] Batch [790]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116445,	
2017-07-25 20:59:02,120 Epoch[25] Batch [800]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.116379,	
2017-07-25 20:59:06,138 Epoch[25] Batch [810]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116328,	
2017-07-25 20:59:10,142 Epoch[25] Batch [820]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.116365,	
2017-07-25 20:59:14,085 Epoch[25] Batch [830]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.116314,	
2017-07-25 20:59:18,112 Epoch[25] Batch [840]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116418,	
2017-07-25 20:59:22,084 Epoch[25] Batch [850]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.116476,	
2017-07-25 20:59:26,027 Epoch[25] Batch [860]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.116423,	
2017-07-25 20:59:30,013 Epoch[25] Batch [870]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116448,	
2017-07-25 20:59:34,008 Epoch[25] Batch [880]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.116450,	
2017-07-25 20:59:38,107 Epoch[25] Batch [890]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.116600,	
2017-07-25 20:59:42,292 Epoch[25] Batch [900]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.116572,	
2017-07-25 20:59:46,260 Epoch[25] Batch [910]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.116616,	
2017-07-25 20:59:50,229 Epoch[25] Batch [920]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.116706,	
2017-07-25 20:59:54,310 Epoch[25] Batch [930]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116608,	
2017-07-25 20:59:58,408 Epoch[25] Batch [940]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.116580,	
2017-07-25 21:00:02,295 Epoch[25] Batch [950]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.116524,	
2017-07-25 21:00:06,316 Epoch[25] Batch [960]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116475,	
2017-07-25 21:00:10,213 Epoch[25] Batch [970]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.116584,	
2017-07-25 21:00:14,078 Epoch[25] Batch [980]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.116530,	
2017-07-25 21:00:18,153 Epoch[25] Batch [990]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116494,	
2017-07-25 21:00:22,109 Epoch[25] Batch [1000]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.116326,	
2017-07-25 21:00:26,016 Epoch[25] Batch [1010]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.116396,	
2017-07-25 21:00:30,004 Epoch[25] Batch [1020]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116405,	
2017-07-25 21:00:33,922 Epoch[25] Batch [1030]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.116422,	
2017-07-25 21:00:37,985 Epoch[25] Batch [1040]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116592,	
2017-07-25 21:00:42,015 Epoch[25] Batch [1050]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116786,	
2017-07-25 21:00:46,093 Epoch[25] Batch [1060]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116996,	
2017-07-25 21:00:50,102 Epoch[25] Batch [1070]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.117011,	
2017-07-25 21:00:54,189 Epoch[25] Batch [1080]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116935,	
2017-07-25 21:00:58,102 Epoch[25] Batch [1090]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.116918,	
2017-07-25 21:01:02,037 Epoch[25] Batch [1100]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.117004,	
2017-07-25 21:01:06,101 Epoch[25] Batch [1110]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117208,	
2017-07-25 21:01:10,224 Epoch[25] Batch [1120]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117198,	
2017-07-25 21:01:14,133 Epoch[25] Batch [1130]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.117201,	
2017-07-25 21:01:18,182 Epoch[25] Batch [1140]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.117665,	
2017-07-25 21:01:22,315 Epoch[25] Batch [1150]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.117645,	
2017-07-25 21:01:26,246 Epoch[25] Batch [1160]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.117549,	
2017-07-25 21:01:30,307 Epoch[25] Batch [1170]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117594,	
2017-07-25 21:01:34,264 Epoch[25] Batch [1180]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.117762,	
2017-07-25 21:01:38,335 Epoch[25] Batch [1190]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117936,	
2017-07-25 21:01:42,422 Epoch[25] Batch [1200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.118080,	
2017-07-25 21:01:46,479 Epoch[25] Batch [1210]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.118043,	
2017-07-25 21:01:50,478 Epoch[25] Batch [1220]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.118146,	
2017-07-25 21:01:54,318 Epoch[25] Batch [1230]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.118155,	
2017-07-25 21:01:58,320 Epoch[25] Batch [1240]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.118195,	
2017-07-25 21:02:02,260 Epoch[25] Batch [1250]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.118220,	
2017-07-25 21:02:06,314 Epoch[25] Batch [1260]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.118254,	
2017-07-25 21:02:10,246 Epoch[25] Batch [1270]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.118155,	
2017-07-25 21:02:14,166 Epoch[25] Batch [1280]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.118085,	
2017-07-25 21:02:18,152 Epoch[25] Batch [1290]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118217,	
2017-07-25 21:02:22,135 Epoch[25] Batch [1300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118362,	
2017-07-25 21:02:26,133 Epoch[25] Batch [1310]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118279,	
2017-07-25 21:02:30,092 Epoch[25] Batch [1320]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.118321,	
2017-07-25 21:02:34,152 Epoch[25] Batch [1330]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.118293,	
2017-07-25 21:02:38,178 Epoch[25] Batch [1340]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.118349,	
2017-07-25 21:02:42,173 Epoch[25] Batch [1350]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118353,	
2017-07-25 21:02:46,173 Epoch[25] Batch [1360]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.118359,	
2017-07-25 21:02:50,267 Epoch[25] Batch [1370]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.118332,	
2017-07-25 21:02:54,217 Epoch[25] Batch [1380]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.118271,	
2017-07-25 21:02:58,178 Epoch[25] Batch [1390]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.118240,	
2017-07-25 21:03:02,152 Epoch[25] Batch [1400]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118252,	
2017-07-25 21:03:06,161 Epoch[25] Batch [1410]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.118338,	
2017-07-25 21:03:10,123 Epoch[25] Batch [1420]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.118318,	
2017-07-25 21:03:14,067 Epoch[25] Batch [1430]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.118358,	
2017-07-25 21:03:18,006 Epoch[25] Batch [1440]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.118358,	
2017-07-25 21:03:22,085 Epoch[25] Batch [1450]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118451,	
2017-07-25 21:03:26,100 Epoch[25] Batch [1460]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.118668,	
2017-07-25 21:03:30,100 Epoch[25] Batch [1470]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.118633,	
2017-07-25 21:03:34,049 Epoch[25] Batch [1480]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.118724,	
2017-07-25 21:03:36,385 Epoch[25] Train-FCNLogLoss=0.118706
2017-07-25 21:03:36,385 Epoch[25] Time cost=593.691
2017-07-25 21:03:37,114 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.params"
2017-07-25 21:03:38,724 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0026.states"
2017-07-25 21:03:43,428 Epoch[26] Batch [10]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.128741,	
2017-07-25 21:03:47,407 Epoch[26] Batch [20]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.113638,	
2017-07-25 21:03:51,314 Epoch[26] Batch [30]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.113739,	
2017-07-25 21:03:55,249 Epoch[26] Batch [40]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.113237,	
2017-07-25 21:03:59,234 Epoch[26] Batch [50]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116506,	
2017-07-25 21:04:03,144 Epoch[26] Batch [60]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.116748,	
2017-07-25 21:04:07,063 Epoch[26] Batch [70]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.117425,	
2017-07-25 21:04:11,072 Epoch[26] Batch [80]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.115933,	
2017-07-25 21:04:15,117 Epoch[26] Batch [90]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116111,	
2017-07-25 21:04:19,141 Epoch[26] Batch [100]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.115288,	
2017-07-25 21:04:23,191 Epoch[26] Batch [110]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.115109,	
2017-07-25 21:04:27,184 Epoch[26] Batch [120]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.115523,	
2017-07-25 21:04:31,045 Epoch[26] Batch [130]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.114806,	
2017-07-25 21:04:34,982 Epoch[26] Batch [140]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.114943,	
2017-07-25 21:04:38,909 Epoch[26] Batch [150]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.114689,	
2017-07-25 21:04:42,791 Epoch[26] Batch [160]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.114667,	
2017-07-25 21:04:46,696 Epoch[26] Batch [170]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.115229,	
2017-07-25 21:04:50,683 Epoch[26] Batch [180]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.115497,	
2017-07-25 21:04:54,530 Epoch[26] Batch [190]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.115336,	
2017-07-25 21:04:58,485 Epoch[26] Batch [200]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.115275,	
2017-07-25 21:05:02,498 Epoch[26] Batch [210]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.114751,	
2017-07-25 21:05:06,507 Epoch[26] Batch [220]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114778,	
2017-07-25 21:05:10,433 Epoch[26] Batch [230]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.114955,	
2017-07-25 21:05:14,399 Epoch[26] Batch [240]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.115193,	
2017-07-25 21:05:18,449 Epoch[26] Batch [250]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.114934,	
2017-07-25 21:05:22,431 Epoch[26] Batch [260]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.115031,	
2017-07-25 21:05:26,448 Epoch[26] Batch [270]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.115117,	
2017-07-25 21:05:30,491 Epoch[26] Batch [280]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.115192,	
2017-07-25 21:05:34,354 Epoch[26] Batch [290]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.115316,	
2017-07-25 21:05:38,316 Epoch[26] Batch [300]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.115334,	
2017-07-25 21:05:42,311 Epoch[26] Batch [310]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.115594,	
2017-07-25 21:05:46,285 Epoch[26] Batch [320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.115437,	
2017-07-25 21:05:50,199 Epoch[26] Batch [330]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.115932,	
2017-07-25 21:05:54,236 Epoch[26] Batch [340]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.115830,	
2017-07-25 21:05:58,243 Epoch[26] Batch [350]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.116262,	
2017-07-25 21:06:02,238 Epoch[26] Batch [360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.116360,	
2017-07-25 21:06:06,217 Epoch[26] Batch [370]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.116184,	
2017-07-25 21:06:10,118 Epoch[26] Batch [380]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.116117,	
2017-07-25 21:06:14,107 Epoch[26] Batch [390]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116445,	
2017-07-25 21:06:17,976 Epoch[26] Batch [400]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.116455,	
2017-07-25 21:06:22,042 Epoch[26] Batch [410]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116623,	
2017-07-25 21:06:26,072 Epoch[26] Batch [420]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116736,	
2017-07-25 21:06:29,939 Epoch[26] Batch [430]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.116796,	
2017-07-25 21:06:33,927 Epoch[26] Batch [440]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116498,	
2017-07-25 21:06:37,864 Epoch[26] Batch [450]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.116507,	
2017-07-25 21:06:41,867 Epoch[26] Batch [460]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.116597,	
2017-07-25 21:06:45,796 Epoch[26] Batch [470]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116426,	
2017-07-25 21:06:49,632 Epoch[26] Batch [480]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.116253,	
2017-07-25 21:06:53,721 Epoch[26] Batch [490]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.115980,	
2017-07-25 21:06:57,728 Epoch[26] Batch [500]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.116006,	
2017-07-25 21:07:01,672 Epoch[26] Batch [510]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.116208,	
2017-07-25 21:07:05,695 Epoch[26] Batch [520]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.116535,	
2017-07-25 21:07:09,679 Epoch[26] Batch [530]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116591,	
2017-07-25 21:07:13,747 Epoch[26] Batch [540]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.116636,	
2017-07-25 21:07:17,834 Epoch[26] Batch [550]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116670,	
2017-07-25 21:07:21,709 Epoch[26] Batch [560]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.116650,	
2017-07-25 21:07:25,672 Epoch[26] Batch [570]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.116663,	
2017-07-25 21:07:29,587 Epoch[26] Batch [580]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.116681,	
2017-07-25 21:07:33,366 Epoch[26] Batch [590]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.116489,	
2017-07-25 21:07:37,358 Epoch[26] Batch [600]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.116234,	
2017-07-25 21:07:41,232 Epoch[26] Batch [610]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.116315,	
2017-07-25 21:07:45,373 Epoch[26] Batch [620]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116403,	
2017-07-25 21:07:49,257 Epoch[26] Batch [630]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.116369,	
2017-07-25 21:07:53,256 Epoch[26] Batch [640]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116218,	
2017-07-25 21:07:57,174 Epoch[26] Batch [650]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.116458,	
2017-07-25 21:08:01,219 Epoch[26] Batch [660]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116282,	
2017-07-25 21:08:05,195 Epoch[26] Batch [670]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.116066,	
2017-07-25 21:08:09,087 Epoch[26] Batch [680]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.116147,	
2017-07-25 21:08:13,112 Epoch[26] Batch [690]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.116135,	
2017-07-25 21:08:17,209 Epoch[26] Batch [700]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116120,	
2017-07-25 21:08:21,236 Epoch[26] Batch [710]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.116261,	
2017-07-25 21:08:25,158 Epoch[26] Batch [720]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.116257,	
2017-07-25 21:08:29,180 Epoch[26] Batch [730]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116193,	
2017-07-25 21:08:33,080 Epoch[26] Batch [740]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.116243,	
2017-07-25 21:08:37,016 Epoch[26] Batch [750]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.116466,	
2017-07-25 21:08:41,079 Epoch[26] Batch [760]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.116474,	
2017-07-25 21:08:44,933 Epoch[26] Batch [770]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.116494,	
2017-07-25 21:08:48,992 Epoch[26] Batch [780]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116424,	
2017-07-25 21:08:52,921 Epoch[26] Batch [790]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116242,	
2017-07-25 21:08:56,867 Epoch[26] Batch [800]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.116185,	
2017-07-25 21:09:00,861 Epoch[26] Batch [810]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.116232,	
2017-07-25 21:09:04,834 Epoch[26] Batch [820]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.116156,	
2017-07-25 21:09:08,963 Epoch[26] Batch [830]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.116443,	
2017-07-25 21:09:12,983 Epoch[26] Batch [840]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116573,	
2017-07-25 21:09:17,026 Epoch[26] Batch [850]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116594,	
2017-07-25 21:09:21,032 Epoch[26] Batch [860]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.116920,	
2017-07-25 21:09:25,193 Epoch[26] Batch [870]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.116957,	
2017-07-25 21:09:29,269 Epoch[26] Batch [880]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116959,	
2017-07-25 21:09:33,086 Epoch[26] Batch [890]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.117001,	
2017-07-25 21:09:37,048 Epoch[26] Batch [900]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.117003,	
2017-07-25 21:09:40,946 Epoch[26] Batch [910]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.116975,	
2017-07-25 21:09:45,100 Epoch[26] Batch [920]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.117230,	
2017-07-25 21:09:49,086 Epoch[26] Batch [930]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.117273,	
2017-07-25 21:09:53,042 Epoch[26] Batch [940]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.117257,	
2017-07-25 21:09:57,041 Epoch[26] Batch [950]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.117609,	
2017-07-25 21:10:00,899 Epoch[26] Batch [960]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.117631,	
2017-07-25 21:10:04,797 Epoch[26] Batch [970]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.117835,	
2017-07-25 21:10:08,817 Epoch[26] Batch [980]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.117672,	
2017-07-25 21:10:12,678 Epoch[26] Batch [990]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.117818,	
2017-07-25 21:10:16,651 Epoch[26] Batch [1000]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.117789,	
2017-07-25 21:10:20,571 Epoch[26] Batch [1010]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.118002,	
2017-07-25 21:10:24,706 Epoch[26] Batch [1020]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.118054,	
2017-07-25 21:10:28,676 Epoch[26] Batch [1030]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.118007,	
2017-07-25 21:10:32,689 Epoch[26] Batch [1040]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.118215,	
2017-07-25 21:10:36,723 Epoch[26] Batch [1050]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.118175,	
2017-07-25 21:10:40,664 Epoch[26] Batch [1060]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.118259,	
2017-07-25 21:10:44,561 Epoch[26] Batch [1070]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.118328,	
2017-07-25 21:10:48,535 Epoch[26] Batch [1080]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118250,	
2017-07-25 21:10:52,510 Epoch[26] Batch [1090]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.118274,	
2017-07-25 21:10:56,503 Epoch[26] Batch [1100]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.118145,	
2017-07-25 21:11:00,540 Epoch[26] Batch [1110]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.118118,	
2017-07-25 21:11:04,557 Epoch[26] Batch [1120]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.118194,	
2017-07-25 21:11:08,590 Epoch[26] Batch [1130]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.118397,	
2017-07-25 21:11:12,555 Epoch[26] Batch [1140]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.118291,	
2017-07-25 21:11:16,535 Epoch[26] Batch [1150]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.118286,	
2017-07-25 21:11:20,617 Epoch[26] Batch [1160]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118212,	
2017-07-25 21:11:24,558 Epoch[26] Batch [1170]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.118159,	
2017-07-25 21:11:28,537 Epoch[26] Batch [1180]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.118144,	
2017-07-25 21:11:32,509 Epoch[26] Batch [1190]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118121,	
2017-07-25 21:11:36,512 Epoch[26] Batch [1200]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.118099,	
2017-07-25 21:11:40,510 Epoch[26] Batch [1210]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.118092,	
2017-07-25 21:11:44,511 Epoch[26] Batch [1220]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.118119,	
2017-07-25 21:11:48,657 Epoch[26] Batch [1230]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.118135,	
2017-07-25 21:11:52,535 Epoch[26] Batch [1240]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.118166,	
2017-07-25 21:11:56,414 Epoch[26] Batch [1250]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.118225,	
2017-07-25 21:12:00,429 Epoch[26] Batch [1260]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.118314,	
2017-07-25 21:12:04,386 Epoch[26] Batch [1270]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.118391,	
2017-07-25 21:12:08,275 Epoch[26] Batch [1280]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.118520,	
2017-07-25 21:12:12,176 Epoch[26] Batch [1290]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.118450,	
2017-07-25 21:12:16,162 Epoch[26] Batch [1300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118436,	
2017-07-25 21:12:20,146 Epoch[26] Batch [1310]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118494,	
2017-07-25 21:12:24,030 Epoch[26] Batch [1320]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.118597,	
2017-07-25 21:12:27,932 Epoch[26] Batch [1330]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.118606,	
2017-07-25 21:12:31,842 Epoch[26] Batch [1340]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.118650,	
2017-07-25 21:12:35,826 Epoch[26] Batch [1350]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118790,	
2017-07-25 21:12:39,824 Epoch[26] Batch [1360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118901,	
2017-07-25 21:12:43,837 Epoch[26] Batch [1370]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.119142,	
2017-07-25 21:12:47,838 Epoch[26] Batch [1380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.119167,	
2017-07-25 21:12:51,821 Epoch[26] Batch [1390]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.119224,	
2017-07-25 21:12:55,813 Epoch[26] Batch [1400]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.119104,	
2017-07-25 21:12:59,767 Epoch[26] Batch [1410]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.119111,	
2017-07-25 21:13:03,728 Epoch[26] Batch [1420]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.119126,	
2017-07-25 21:13:07,787 Epoch[26] Batch [1430]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.119152,	
2017-07-25 21:13:11,785 Epoch[26] Batch [1440]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.119230,	
2017-07-25 21:13:15,748 Epoch[26] Batch [1450]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.119196,	
2017-07-25 21:13:19,703 Epoch[26] Batch [1460]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.119316,	
2017-07-25 21:13:23,713 Epoch[26] Batch [1470]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.119351,	
2017-07-25 21:13:27,770 Epoch[26] Batch [1480]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.119286,	
2017-07-25 21:13:30,114 Epoch[26] Train-FCNLogLoss=0.119274
2017-07-25 21:13:30,114 Epoch[26] Time cost=591.390
2017-07-25 21:13:30,828 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.params"
2017-07-25 21:13:32,320 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0027.states"
2017-07-25 21:13:37,137 Epoch[27] Batch [10]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.115290,	
2017-07-25 21:13:41,106 Epoch[27] Batch [20]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.118144,	
2017-07-25 21:13:45,139 Epoch[27] Batch [30]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.115641,	
2017-07-25 21:13:49,117 Epoch[27] Batch [40]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.114245,	
2017-07-25 21:13:53,282 Epoch[27] Batch [50]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.113282,	
2017-07-25 21:13:57,110 Epoch[27] Batch [60]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.111593,	
2017-07-25 21:14:01,052 Epoch[27] Batch [70]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.112334,	
2017-07-25 21:14:05,053 Epoch[27] Batch [80]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.111371,	
2017-07-25 21:14:09,053 Epoch[27] Batch [90]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.111032,	
2017-07-25 21:14:12,987 Epoch[27] Batch [100]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.110769,	
2017-07-25 21:14:16,994 Epoch[27] Batch [110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.111071,	
2017-07-25 21:14:20,856 Epoch[27] Batch [120]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.111491,	
2017-07-25 21:14:24,722 Epoch[27] Batch [130]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.111912,	
2017-07-25 21:14:28,617 Epoch[27] Batch [140]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.112594,	
2017-07-25 21:14:32,582 Epoch[27] Batch [150]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.113018,	
2017-07-25 21:14:36,549 Epoch[27] Batch [160]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.113986,	
2017-07-25 21:14:40,489 Epoch[27] Batch [170]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.113640,	
2017-07-25 21:14:44,443 Epoch[27] Batch [180]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.113771,	
2017-07-25 21:14:48,352 Epoch[27] Batch [190]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.113255,	
2017-07-25 21:14:52,440 Epoch[27] Batch [200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.113364,	
2017-07-25 21:14:56,376 Epoch[27] Batch [210]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.114287,	
2017-07-25 21:15:00,387 Epoch[27] Batch [220]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.114530,	
2017-07-25 21:15:04,191 Epoch[27] Batch [230]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.113767,	
2017-07-25 21:15:08,125 Epoch[27] Batch [240]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.114126,	
2017-07-25 21:15:12,051 Epoch[27] Batch [250]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.114188,	
2017-07-25 21:15:16,132 Epoch[27] Batch [260]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114855,	
2017-07-25 21:15:20,139 Epoch[27] Batch [270]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114636,	
2017-07-25 21:15:24,134 Epoch[27] Batch [280]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.115138,	
2017-07-25 21:15:27,942 Epoch[27] Batch [290]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.115260,	
2017-07-25 21:15:31,820 Epoch[27] Batch [300]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.115500,	
2017-07-25 21:15:35,870 Epoch[27] Batch [310]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.115345,	
2017-07-25 21:15:39,882 Epoch[27] Batch [320]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.115628,	
2017-07-25 21:15:43,842 Epoch[27] Batch [330]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.115056,	
2017-07-25 21:15:47,762 Epoch[27] Batch [340]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.114858,	
2017-07-25 21:15:51,561 Epoch[27] Batch [350]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.114904,	
2017-07-25 21:15:55,632 Epoch[27] Batch [360]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.114831,	
2017-07-25 21:15:59,671 Epoch[27] Batch [370]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114987,	
2017-07-25 21:16:03,531 Epoch[27] Batch [380]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.114532,	
2017-07-25 21:16:07,502 Epoch[27] Batch [390]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.114661,	
2017-07-25 21:16:11,552 Epoch[27] Batch [400]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.114732,	
2017-07-25 21:16:15,537 Epoch[27] Batch [410]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.114625,	
2017-07-25 21:16:19,527 Epoch[27] Batch [420]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.114421,	
2017-07-25 21:16:23,601 Epoch[27] Batch [430]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.114419,	
2017-07-25 21:16:27,517 Epoch[27] Batch [440]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.114380,	
2017-07-25 21:16:31,470 Epoch[27] Batch [450]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.114863,	
2017-07-25 21:16:35,402 Epoch[27] Batch [460]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.115261,	
2017-07-25 21:16:39,473 Epoch[27] Batch [470]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.115402,	
2017-07-25 21:16:43,399 Epoch[27] Batch [480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.115562,	
2017-07-25 21:16:47,494 Epoch[27] Batch [490]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116051,	
2017-07-25 21:16:51,450 Epoch[27] Batch [500]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.116311,	
2017-07-25 21:16:55,402 Epoch[27] Batch [510]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.116457,	
2017-07-25 21:16:59,402 Epoch[27] Batch [520]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116616,	
2017-07-25 21:17:03,214 Epoch[27] Batch [530]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.117333,	
2017-07-25 21:17:07,152 Epoch[27] Batch [540]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.117297,	
2017-07-25 21:17:11,136 Epoch[27] Batch [550]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.117188,	
2017-07-25 21:17:15,100 Epoch[27] Batch [560]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.117090,	
2017-07-25 21:17:19,079 Epoch[27] Batch [570]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117006,	
2017-07-25 21:17:23,131 Epoch[27] Batch [580]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.117021,	
2017-07-25 21:17:27,036 Epoch[27] Batch [590]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.116945,	
2017-07-25 21:17:31,055 Epoch[27] Batch [600]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.116841,	
2017-07-25 21:17:35,099 Epoch[27] Batch [610]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116709,	
2017-07-25 21:17:39,116 Epoch[27] Batch [620]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116573,	
2017-07-25 21:17:43,056 Epoch[27] Batch [630]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.116676,	
2017-07-25 21:17:47,012 Epoch[27] Batch [640]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.116557,	
2017-07-25 21:17:50,986 Epoch[27] Batch [650]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.116655,	
2017-07-25 21:17:54,951 Epoch[27] Batch [660]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.116617,	
2017-07-25 21:17:58,794 Epoch[27] Batch [670]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.116976,	
2017-07-25 21:18:02,850 Epoch[27] Batch [680]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116892,	
2017-07-25 21:18:06,740 Epoch[27] Batch [690]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.116959,	
2017-07-25 21:18:10,684 Epoch[27] Batch [700]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.117043,	
2017-07-25 21:18:14,596 Epoch[27] Batch [710]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.117097,	
2017-07-25 21:18:18,481 Epoch[27] Batch [720]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.117041,	
2017-07-25 21:18:22,434 Epoch[27] Batch [730]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.117104,	
2017-07-25 21:18:26,422 Epoch[27] Batch [740]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.117072,	
2017-07-25 21:18:30,405 Epoch[27] Batch [750]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116955,	
2017-07-25 21:18:34,344 Epoch[27] Batch [760]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.117067,	
2017-07-25 21:18:38,321 Epoch[27] Batch [770]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.116956,	
2017-07-25 21:18:42,221 Epoch[27] Batch [780]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.117050,	
2017-07-25 21:18:46,174 Epoch[27] Batch [790]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.117057,	
2017-07-25 21:18:50,212 Epoch[27] Batch [800]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.117088,	
2017-07-25 21:18:54,257 Epoch[27] Batch [810]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.117102,	
2017-07-25 21:18:58,291 Epoch[27] Batch [820]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116901,	
2017-07-25 21:19:02,250 Epoch[27] Batch [830]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.116913,	
2017-07-25 21:19:06,216 Epoch[27] Batch [840]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.116798,	
2017-07-25 21:19:10,303 Epoch[27] Batch [850]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116679,	
2017-07-25 21:19:14,272 Epoch[27] Batch [860]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.116698,	
2017-07-25 21:19:18,269 Epoch[27] Batch [870]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.116631,	
2017-07-25 21:19:22,182 Epoch[27] Batch [880]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.116635,	
2017-07-25 21:19:26,272 Epoch[27] Batch [890]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.116643,	
2017-07-25 21:19:30,255 Epoch[27] Batch [900]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116756,	
2017-07-25 21:19:34,120 Epoch[27] Batch [910]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.116797,	
2017-07-25 21:19:38,027 Epoch[27] Batch [920]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.116873,	
2017-07-25 21:19:42,074 Epoch[27] Batch [930]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.116832,	
2017-07-25 21:19:46,071 Epoch[27] Batch [940]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.116926,	
2017-07-25 21:19:50,082 Epoch[27] Batch [950]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116808,	
2017-07-25 21:19:54,001 Epoch[27] Batch [960]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.117019,	
2017-07-25 21:19:57,883 Epoch[27] Batch [970]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.117074,	
2017-07-25 21:20:01,946 Epoch[27] Batch [980]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.117156,	
2017-07-25 21:20:06,060 Epoch[27] Batch [990]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117251,	
2017-07-25 21:20:10,072 Epoch[27] Batch [1000]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.117250,	
2017-07-25 21:20:13,910 Epoch[27] Batch [1010]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.117297,	
2017-07-25 21:20:17,830 Epoch[27] Batch [1020]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.117343,	
2017-07-25 21:20:21,780 Epoch[27] Batch [1030]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.117381,	
2017-07-25 21:20:25,759 Epoch[27] Batch [1040]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117495,	
2017-07-25 21:20:29,777 Epoch[27] Batch [1050]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117511,	
2017-07-25 21:20:33,861 Epoch[27] Batch [1060]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117543,	
2017-07-25 21:20:37,879 Epoch[27] Batch [1070]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117526,	
2017-07-25 21:20:41,815 Epoch[27] Batch [1080]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.117422,	
2017-07-25 21:20:45,764 Epoch[27] Batch [1090]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.117399,	
2017-07-25 21:20:49,863 Epoch[27] Batch [1100]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117346,	
2017-07-25 21:20:54,089 Epoch[27] Batch [1110]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.117428,	
2017-07-25 21:20:58,056 Epoch[27] Batch [1120]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.117459,	
2017-07-25 21:21:02,029 Epoch[27] Batch [1130]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.117514,	
2017-07-25 21:21:06,008 Epoch[27] Batch [1140]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117444,	
2017-07-25 21:21:09,930 Epoch[27] Batch [1150]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.117520,	
2017-07-25 21:21:13,829 Epoch[27] Batch [1160]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.117423,	
2017-07-25 21:21:17,821 Epoch[27] Batch [1170]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.117487,	
2017-07-25 21:21:21,737 Epoch[27] Batch [1180]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.117448,	
2017-07-25 21:21:25,666 Epoch[27] Batch [1190]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.117396,	
2017-07-25 21:21:29,632 Epoch[27] Batch [1200]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.117403,	
2017-07-25 21:21:33,731 Epoch[27] Batch [1210]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.117283,	
2017-07-25 21:21:37,602 Epoch[27] Batch [1220]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.117227,	
2017-07-25 21:21:41,707 Epoch[27] Batch [1230]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117310,	
2017-07-25 21:21:45,803 Epoch[27] Batch [1240]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117422,	
2017-07-25 21:21:49,801 Epoch[27] Batch [1250]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.117403,	
2017-07-25 21:21:53,870 Epoch[27] Batch [1260]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117411,	
2017-07-25 21:21:57,833 Epoch[27] Batch [1270]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.117458,	
2017-07-25 21:22:01,898 Epoch[27] Batch [1280]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.117650,	
2017-07-25 21:22:05,847 Epoch[27] Batch [1290]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.117696,	
2017-07-25 21:22:09,877 Epoch[27] Batch [1300]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.117828,	
2017-07-25 21:22:13,899 Epoch[27] Batch [1310]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.117915,	
2017-07-25 21:22:17,806 Epoch[27] Batch [1320]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.117979,	
2017-07-25 21:22:21,804 Epoch[27] Batch [1330]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.117845,	
2017-07-25 21:22:25,770 Epoch[27] Batch [1340]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.117835,	
2017-07-25 21:22:29,859 Epoch[27] Batch [1350]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.117787,	
2017-07-25 21:22:33,813 Epoch[27] Batch [1360]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.117734,	
2017-07-25 21:22:37,941 Epoch[27] Batch [1370]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.117763,	
2017-07-25 21:22:41,917 Epoch[27] Batch [1380]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.117735,	
2017-07-25 21:22:45,828 Epoch[27] Batch [1390]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.117694,	
2017-07-25 21:22:49,907 Epoch[27] Batch [1400]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117710,	
2017-07-25 21:22:53,833 Epoch[27] Batch [1410]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.117722,	
2017-07-25 21:22:57,821 Epoch[27] Batch [1420]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.117721,	
2017-07-25 21:23:01,915 Epoch[27] Batch [1430]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.117694,	
2017-07-25 21:23:05,788 Epoch[27] Batch [1440]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.117803,	
2017-07-25 21:23:09,859 Epoch[27] Batch [1450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117823,	
2017-07-25 21:23:13,837 Epoch[27] Batch [1460]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117917,	
2017-07-25 21:23:17,833 Epoch[27] Batch [1470]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.117865,	
2017-07-25 21:23:21,911 Epoch[27] Batch [1480]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117772,	
2017-07-25 21:23:24,263 Epoch[27] Train-FCNLogLoss=0.117741
2017-07-25 21:23:24,263 Epoch[27] Time cost=591.942
2017-07-25 21:23:24,980 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.params"
2017-07-25 21:23:26,644 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0028.states"
2017-07-25 21:23:31,395 Epoch[28] Batch [10]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.096926,	
2017-07-25 21:23:35,317 Epoch[28] Batch [20]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.110032,	
2017-07-25 21:23:39,239 Epoch[28] Batch [30]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112058,	
2017-07-25 21:23:43,248 Epoch[28] Batch [40]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112272,	
2017-07-25 21:23:47,213 Epoch[28] Batch [50]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.111872,	
2017-07-25 21:23:51,182 Epoch[28] Batch [60]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.112509,	
2017-07-25 21:23:55,155 Epoch[28] Batch [70]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.114140,	
2017-07-25 21:23:59,226 Epoch[28] Batch [80]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.113366,	
2017-07-25 21:24:03,266 Epoch[28] Batch [90]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112854,	
2017-07-25 21:24:07,168 Epoch[28] Batch [100]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.112166,	
2017-07-25 21:24:11,114 Epoch[28] Batch [110]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.113751,	
2017-07-25 21:24:15,019 Epoch[28] Batch [120]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.114751,	
2017-07-25 21:24:19,004 Epoch[28] Batch [130]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.115644,	
2017-07-25 21:24:22,987 Epoch[28] Batch [140]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.115448,	
2017-07-25 21:24:26,985 Epoch[28] Batch [150]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.114948,	
2017-07-25 21:24:30,870 Epoch[28] Batch [160]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.114722,	
2017-07-25 21:24:34,894 Epoch[28] Batch [170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114573,	
2017-07-25 21:24:38,829 Epoch[28] Batch [180]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.114291,	
2017-07-25 21:24:42,860 Epoch[28] Batch [190]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.114578,	
2017-07-25 21:24:46,875 Epoch[28] Batch [200]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.114259,	
2017-07-25 21:24:50,799 Epoch[28] Batch [210]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.114151,	
2017-07-25 21:24:54,827 Epoch[28] Batch [220]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.114585,	
2017-07-25 21:24:58,814 Epoch[28] Batch [230]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.114430,	
2017-07-25 21:25:02,656 Epoch[28] Batch [240]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.114442,	
2017-07-25 21:25:06,782 Epoch[28] Batch [250]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.114793,	
2017-07-25 21:25:10,731 Epoch[28] Batch [260]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.116041,	
2017-07-25 21:25:14,849 Epoch[28] Batch [270]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.116098,	
2017-07-25 21:25:18,904 Epoch[28] Batch [280]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.117209,	
2017-07-25 21:25:22,867 Epoch[28] Batch [290]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.117288,	
2017-07-25 21:25:26,964 Epoch[28] Batch [300]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118441,	
2017-07-25 21:25:30,953 Epoch[28] Batch [310]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.118732,	
2017-07-25 21:25:34,955 Epoch[28] Batch [320]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.119077,	
2017-07-25 21:25:38,922 Epoch[28] Batch [330]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.119050,	
2017-07-25 21:25:42,894 Epoch[28] Batch [340]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.118836,	
2017-07-25 21:25:46,817 Epoch[28] Batch [350]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.118804,	
2017-07-25 21:25:50,774 Epoch[28] Batch [360]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.118750,	
2017-07-25 21:25:54,845 Epoch[28] Batch [370]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.118366,	
2017-07-25 21:25:58,869 Epoch[28] Batch [380]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.117914,	
2017-07-25 21:26:02,772 Epoch[28] Batch [390]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.117350,	
2017-07-25 21:26:06,849 Epoch[28] Batch [400]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.117021,	
2017-07-25 21:26:10,863 Epoch[28] Batch [410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116921,	
2017-07-25 21:26:14,916 Epoch[28] Batch [420]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.116353,	
2017-07-25 21:26:18,893 Epoch[28] Batch [430]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.116101,	
2017-07-25 21:26:22,934 Epoch[28] Batch [440]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.115929,	
2017-07-25 21:26:26,765 Epoch[28] Batch [450]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.115835,	
2017-07-25 21:26:30,657 Epoch[28] Batch [460]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.115685,	
2017-07-25 21:26:34,520 Epoch[28] Batch [470]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.115356,	
2017-07-25 21:26:38,510 Epoch[28] Batch [480]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.115406,	
2017-07-25 21:26:42,530 Epoch[28] Batch [490]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.115243,	
2017-07-25 21:26:46,427 Epoch[28] Batch [500]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.115161,	
2017-07-25 21:26:50,252 Epoch[28] Batch [510]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.114980,	
2017-07-25 21:26:54,195 Epoch[28] Batch [520]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.114904,	
2017-07-25 21:26:58,097 Epoch[28] Batch [530]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.114802,	
2017-07-25 21:27:02,111 Epoch[28] Batch [540]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.114567,	
2017-07-25 21:27:06,061 Epoch[28] Batch [550]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.114570,	
2017-07-25 21:27:10,080 Epoch[28] Batch [560]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.114241,	
2017-07-25 21:27:13,972 Epoch[28] Batch [570]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.114106,	
2017-07-25 21:27:17,938 Epoch[28] Batch [580]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.114607,	
2017-07-25 21:27:21,897 Epoch[28] Batch [590]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.115043,	
2017-07-25 21:27:25,831 Epoch[28] Batch [600]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.115601,	
2017-07-25 21:27:29,790 Epoch[28] Batch [610]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.115665,	
2017-07-25 21:27:33,805 Epoch[28] Batch [620]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116093,	
2017-07-25 21:27:37,746 Epoch[28] Batch [630]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.116241,	
2017-07-25 21:27:41,733 Epoch[28] Batch [640]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116270,	
2017-07-25 21:27:45,573 Epoch[28] Batch [650]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.116298,	
2017-07-25 21:27:49,537 Epoch[28] Batch [660]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.116230,	
2017-07-25 21:27:53,593 Epoch[28] Batch [670]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116296,	
2017-07-25 21:27:57,944 Epoch[28] Batch [680]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.116354,	
2017-07-25 21:28:02,265 Epoch[28] Batch [690]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.116469,	
2017-07-25 21:28:06,400 Epoch[28] Batch [700]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.116503,	
2017-07-25 21:28:10,300 Epoch[28] Batch [710]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.116516,	
2017-07-25 21:28:14,274 Epoch[28] Batch [720]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.116293,	
2017-07-25 21:28:18,260 Epoch[28] Batch [730]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116335,	
2017-07-25 21:28:22,262 Epoch[28] Batch [740]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116309,	
2017-07-25 21:28:26,212 Epoch[28] Batch [750]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.116518,	
2017-07-25 21:28:30,277 Epoch[28] Batch [760]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116519,	
2017-07-25 21:28:34,112 Epoch[28] Batch [770]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.116704,	
2017-07-25 21:28:38,022 Epoch[28] Batch [780]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.116708,	
2017-07-25 21:28:41,992 Epoch[28] Batch [790]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.116725,	
2017-07-25 21:28:45,984 Epoch[28] Batch [800]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.116900,	
2017-07-25 21:28:49,998 Epoch[28] Batch [810]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116891,	
2017-07-25 21:28:53,878 Epoch[28] Batch [820]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.117467,	
2017-07-25 21:28:57,919 Epoch[28] Batch [830]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.117743,	
2017-07-25 21:29:01,897 Epoch[28] Batch [840]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117715,	
2017-07-25 21:29:05,886 Epoch[28] Batch [850]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.117826,	
2017-07-25 21:29:09,762 Epoch[28] Batch [860]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.117777,	
2017-07-25 21:29:13,830 Epoch[28] Batch [870]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.117740,	
2017-07-25 21:29:17,795 Epoch[28] Batch [880]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.117635,	
2017-07-25 21:29:21,734 Epoch[28] Batch [890]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.117563,	
2017-07-25 21:29:25,693 Epoch[28] Batch [900]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.117421,	
2017-07-25 21:29:29,696 Epoch[28] Batch [910]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.117243,	
2017-07-25 21:29:33,798 Epoch[28] Batch [920]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.117153,	
2017-07-25 21:29:37,779 Epoch[28] Batch [930]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.117116,	
2017-07-25 21:29:41,744 Epoch[28] Batch [940]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.117050,	
2017-07-25 21:29:45,634 Epoch[28] Batch [950]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.117033,	
2017-07-25 21:29:49,550 Epoch[28] Batch [960]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.117015,	
2017-07-25 21:29:53,630 Epoch[28] Batch [970]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.117036,	
2017-07-25 21:29:57,772 Epoch[28] Batch [980]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116998,	
2017-07-25 21:30:01,825 Epoch[28] Batch [990]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.116939,	
2017-07-25 21:30:05,902 Epoch[28] Batch [1000]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.116847,	
2017-07-25 21:30:09,847 Epoch[28] Batch [1010]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.116817,	
2017-07-25 21:30:13,935 Epoch[28] Batch [1020]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.116618,	
2017-07-25 21:30:17,952 Epoch[28] Batch [1030]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.116587,	
2017-07-25 21:30:21,966 Epoch[28] Batch [1040]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116464,	
2017-07-25 21:30:25,945 Epoch[28] Batch [1050]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.116376,	
2017-07-25 21:30:29,959 Epoch[28] Batch [1060]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116390,	
2017-07-25 21:30:33,898 Epoch[28] Batch [1070]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.116423,	
2017-07-25 21:30:37,872 Epoch[28] Batch [1080]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.116363,	
2017-07-25 21:30:41,794 Epoch[28] Batch [1090]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.116315,	
2017-07-25 21:30:45,714 Epoch[28] Batch [1100]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.116349,	
2017-07-25 21:30:49,618 Epoch[28] Batch [1110]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.116279,	
2017-07-25 21:30:53,619 Epoch[28] Batch [1120]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116402,	
2017-07-25 21:30:57,631 Epoch[28] Batch [1130]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.116446,	
2017-07-25 21:31:01,695 Epoch[28] Batch [1140]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116370,	
2017-07-25 21:31:05,733 Epoch[28] Batch [1150]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.116369,	
2017-07-25 21:31:09,724 Epoch[28] Batch [1160]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.116378,	
2017-07-25 21:31:13,817 Epoch[28] Batch [1170]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.116303,	
2017-07-25 21:31:17,962 Epoch[28] Batch [1180]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.116160,	
2017-07-25 21:31:21,923 Epoch[28] Batch [1190]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.116110,	
2017-07-25 21:31:25,998 Epoch[28] Batch [1200]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.116421,	
2017-07-25 21:31:30,079 Epoch[28] Batch [1210]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.116734,	
2017-07-25 21:31:34,006 Epoch[28] Batch [1220]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116881,	
2017-07-25 21:31:38,064 Epoch[28] Batch [1230]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.116947,	
2017-07-25 21:31:42,108 Epoch[28] Batch [1240]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.116895,	
2017-07-25 21:31:46,142 Epoch[28] Batch [1250]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116919,	
2017-07-25 21:31:50,119 Epoch[28] Batch [1260]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.116848,	
2017-07-25 21:31:54,105 Epoch[28] Batch [1270]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116891,	
2017-07-25 21:31:58,050 Epoch[28] Batch [1280]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.116871,	
2017-07-25 21:32:01,984 Epoch[28] Batch [1290]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.116965,	
2017-07-25 21:32:06,050 Epoch[28] Batch [1300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.116947,	
2017-07-25 21:32:10,083 Epoch[28] Batch [1310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116861,	
2017-07-25 21:32:14,014 Epoch[28] Batch [1320]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.116789,	
2017-07-25 21:32:17,849 Epoch[28] Batch [1330]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.116723,	
2017-07-25 21:32:21,770 Epoch[28] Batch [1340]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.116692,	
2017-07-25 21:32:25,732 Epoch[28] Batch [1350]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.116684,	
2017-07-25 21:32:29,763 Epoch[28] Batch [1360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116650,	
2017-07-25 21:32:33,802 Epoch[28] Batch [1370]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.116586,	
2017-07-25 21:32:37,850 Epoch[28] Batch [1380]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.116521,	
2017-07-25 21:32:41,852 Epoch[28] Batch [1390]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116514,	
2017-07-25 21:32:45,837 Epoch[28] Batch [1400]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.116514,	
2017-07-25 21:32:49,872 Epoch[28] Batch [1410]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.116521,	
2017-07-25 21:32:53,851 Epoch[28] Batch [1420]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.116484,	
2017-07-25 21:32:57,847 Epoch[28] Batch [1430]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.116422,	
2017-07-25 21:33:01,880 Epoch[28] Batch [1440]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116474,	
2017-07-25 21:33:05,881 Epoch[28] Batch [1450]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.116444,	
2017-07-25 21:33:09,771 Epoch[28] Batch [1460]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.116396,	
2017-07-25 21:33:13,778 Epoch[28] Batch [1470]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.116389,	
2017-07-25 21:33:17,914 Epoch[28] Batch [1480]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.116541,	
2017-07-25 21:33:20,295 Epoch[28] Train-FCNLogLoss=0.116505
2017-07-25 21:33:20,295 Epoch[28] Time cost=593.651
2017-07-25 21:33:21,104 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.params"
2017-07-25 21:33:22,680 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0029.states"
2017-07-25 21:33:27,506 Epoch[29] Batch [10]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.110953,	
2017-07-25 21:33:31,494 Epoch[29] Batch [20]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.111106,	
2017-07-25 21:33:35,476 Epoch[29] Batch [30]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.116304,	
2017-07-25 21:33:39,351 Epoch[29] Batch [40]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.118730,	
2017-07-25 21:33:43,415 Epoch[29] Batch [50]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.119941,	
2017-07-25 21:33:47,598 Epoch[29] Batch [60]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.116246,	
2017-07-25 21:33:51,600 Epoch[29] Batch [70]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.115900,	
2017-07-25 21:33:55,612 Epoch[29] Batch [80]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.114035,	
2017-07-25 21:33:59,654 Epoch[29] Batch [90]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112519,	
2017-07-25 21:34:03,662 Epoch[29] Batch [100]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112140,	
2017-07-25 21:34:07,584 Epoch[29] Batch [110]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112255,	
2017-07-25 21:34:11,511 Epoch[29] Batch [120]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.113614,	
2017-07-25 21:34:15,428 Epoch[29] Batch [130]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.114661,	
2017-07-25 21:34:19,540 Epoch[29] Batch [140]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.114643,	
2017-07-25 21:34:23,581 Epoch[29] Batch [150]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114998,	
2017-07-25 21:34:27,557 Epoch[29] Batch [160]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.115186,	
2017-07-25 21:34:31,595 Epoch[29] Batch [170]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.114589,	
2017-07-25 21:34:35,772 Epoch[29] Batch [180]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.114100,	
2017-07-25 21:34:39,674 Epoch[29] Batch [190]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.114134,	
2017-07-25 21:34:43,698 Epoch[29] Batch [200]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114319,	
2017-07-25 21:34:47,619 Epoch[29] Batch [210]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.113706,	
2017-07-25 21:34:51,590 Epoch[29] Batch [220]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.113260,	
2017-07-25 21:34:55,555 Epoch[29] Batch [230]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.113444,	
2017-07-25 21:34:59,636 Epoch[29] Batch [240]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.113693,	
2017-07-25 21:35:03,657 Epoch[29] Batch [250]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113290,	
2017-07-25 21:35:07,637 Epoch[29] Batch [260]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113772,	
2017-07-25 21:35:11,610 Epoch[29] Batch [270]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.115237,	
2017-07-25 21:35:15,613 Epoch[29] Batch [280]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.116999,	
2017-07-25 21:35:19,692 Epoch[29] Batch [290]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.118823,	
2017-07-25 21:35:23,569 Epoch[29] Batch [300]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.119436,	
2017-07-25 21:35:27,512 Epoch[29] Batch [310]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.121014,	
2017-07-25 21:35:31,509 Epoch[29] Batch [320]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.120936,	
2017-07-25 21:35:35,605 Epoch[29] Batch [330]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.121715,	
2017-07-25 21:35:39,760 Epoch[29] Batch [340]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.122115,	
2017-07-25 21:35:43,643 Epoch[29] Batch [350]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.122365,	
2017-07-25 21:35:47,614 Epoch[29] Batch [360]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.122804,	
2017-07-25 21:35:51,570 Epoch[29] Batch [370]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.123042,	
2017-07-25 21:35:55,471 Epoch[29] Batch [380]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.123083,	
2017-07-25 21:35:59,437 Epoch[29] Batch [390]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.122863,	
2017-07-25 21:36:03,349 Epoch[29] Batch [400]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.123260,	
2017-07-25 21:36:07,313 Epoch[29] Batch [410]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.122965,	
2017-07-25 21:36:11,301 Epoch[29] Batch [420]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.122908,	
2017-07-25 21:36:15,225 Epoch[29] Batch [430]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.122822,	
2017-07-25 21:36:19,127 Epoch[29] Batch [440]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.122781,	
2017-07-25 21:36:23,034 Epoch[29] Batch [450]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.122562,	
2017-07-25 21:36:27,121 Epoch[29] Batch [460]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.122378,	
2017-07-25 21:36:31,004 Epoch[29] Batch [470]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.122203,	
2017-07-25 21:36:34,998 Epoch[29] Batch [480]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.121663,	
2017-07-25 21:36:39,117 Epoch[29] Batch [490]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.121795,	
2017-07-25 21:36:43,061 Epoch[29] Batch [500]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.121882,	
2017-07-25 21:36:46,968 Epoch[29] Batch [510]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.122263,	
2017-07-25 21:36:50,909 Epoch[29] Batch [520]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.122545,	
2017-07-25 21:36:54,933 Epoch[29] Batch [530]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.123040,	
2017-07-25 21:36:58,809 Epoch[29] Batch [540]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.122969,	
2017-07-25 21:37:02,763 Epoch[29] Batch [550]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.122732,	
2017-07-25 21:37:06,755 Epoch[29] Batch [560]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.122827,	
2017-07-25 21:37:10,823 Epoch[29] Batch [570]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.122971,	
2017-07-25 21:37:14,740 Epoch[29] Batch [580]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.123022,	
2017-07-25 21:37:18,777 Epoch[29] Batch [590]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.123198,	
2017-07-25 21:37:22,769 Epoch[29] Batch [600]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.123049,	
2017-07-25 21:37:26,804 Epoch[29] Batch [610]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.123015,	
2017-07-25 21:37:30,782 Epoch[29] Batch [620]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.123027,	
2017-07-25 21:37:34,753 Epoch[29] Batch [630]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.122842,	
2017-07-25 21:37:38,788 Epoch[29] Batch [640]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.122672,	
2017-07-25 21:37:42,719 Epoch[29] Batch [650]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.122439,	
2017-07-25 21:37:46,675 Epoch[29] Batch [660]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.122574,	
2017-07-25 21:37:50,661 Epoch[29] Batch [670]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.122609,	
2017-07-25 21:37:54,614 Epoch[29] Batch [680]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.122776,	
2017-07-25 21:37:58,608 Epoch[29] Batch [690]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.122555,	
2017-07-25 21:38:02,666 Epoch[29] Batch [700]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.122474,	
2017-07-25 21:38:06,640 Epoch[29] Batch [710]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.122809,	
2017-07-25 21:38:10,752 Epoch[29] Batch [720]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.122842,	
2017-07-25 21:38:14,775 Epoch[29] Batch [730]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.122948,	
2017-07-25 21:38:18,751 Epoch[29] Batch [740]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.123015,	
2017-07-25 21:38:22,760 Epoch[29] Batch [750]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.122858,	
2017-07-25 21:38:26,773 Epoch[29] Batch [760]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.122761,	
2017-07-25 21:38:30,751 Epoch[29] Batch [770]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.122638,	
2017-07-25 21:38:34,847 Epoch[29] Batch [780]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.122518,	
2017-07-25 21:38:38,935 Epoch[29] Batch [790]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.122380,	
2017-07-25 21:38:42,942 Epoch[29] Batch [800]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.122298,	
2017-07-25 21:38:46,991 Epoch[29] Batch [810]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.122245,	
2017-07-25 21:38:51,007 Epoch[29] Batch [820]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.122141,	
2017-07-25 21:38:55,026 Epoch[29] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.121884,	
2017-07-25 21:38:58,933 Epoch[29] Batch [840]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.121751,	
2017-07-25 21:39:02,997 Epoch[29] Batch [850]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.121646,	
2017-07-25 21:39:07,053 Epoch[29] Batch [860]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.121498,	
2017-07-25 21:39:11,054 Epoch[29] Batch [870]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.121353,	
2017-07-25 21:39:14,929 Epoch[29] Batch [880]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.121343,	
2017-07-25 21:39:18,964 Epoch[29] Batch [890]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.121442,	
2017-07-25 21:39:22,999 Epoch[29] Batch [900]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.121409,	
2017-07-25 21:39:26,948 Epoch[29] Batch [910]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.121471,	
2017-07-25 21:39:30,848 Epoch[29] Batch [920]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.121392,	
2017-07-25 21:39:34,663 Epoch[29] Batch [930]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.121281,	
2017-07-25 21:39:38,613 Epoch[29] Batch [940]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.121431,	
2017-07-25 21:39:42,590 Epoch[29] Batch [950]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.121461,	
2017-07-25 21:39:46,499 Epoch[29] Batch [960]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.121337,	
2017-07-25 21:39:50,528 Epoch[29] Batch [970]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.121142,	
2017-07-25 21:39:54,581 Epoch[29] Batch [980]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.121050,	
2017-07-25 21:39:58,456 Epoch[29] Batch [990]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.120974,	
2017-07-25 21:40:02,360 Epoch[29] Batch [1000]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.120946,	
2017-07-25 21:40:06,344 Epoch[29] Batch [1010]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.120943,	
2017-07-25 21:40:10,315 Epoch[29] Batch [1020]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.120746,	
2017-07-25 21:40:14,205 Epoch[29] Batch [1030]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.120677,	
2017-07-25 21:40:18,144 Epoch[29] Batch [1040]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.120536,	
2017-07-25 21:40:22,057 Epoch[29] Batch [1050]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.120438,	
2017-07-25 21:40:26,064 Epoch[29] Batch [1060]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.120400,	
2017-07-25 21:40:30,044 Epoch[29] Batch [1070]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.120330,	
2017-07-25 21:40:34,103 Epoch[29] Batch [1080]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.120466,	
2017-07-25 21:40:38,050 Epoch[29] Batch [1090]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.120355,	
2017-07-25 21:40:42,183 Epoch[29] Batch [1100]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.120373,	
2017-07-25 21:40:46,087 Epoch[29] Batch [1110]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.120287,	
2017-07-25 21:40:50,100 Epoch[29] Batch [1120]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.120239,	
2017-07-25 21:40:54,030 Epoch[29] Batch [1130]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.120172,	
2017-07-25 21:40:57,913 Epoch[29] Batch [1140]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.120035,	
2017-07-25 21:41:01,815 Epoch[29] Batch [1150]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.119893,	
2017-07-25 21:41:05,784 Epoch[29] Batch [1160]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.119957,	
2017-07-25 21:41:09,772 Epoch[29] Batch [1170]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119804,	
2017-07-25 21:41:13,759 Epoch[29] Batch [1180]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.119776,	
2017-07-25 21:41:17,787 Epoch[29] Batch [1190]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.119700,	
2017-07-25 21:41:21,817 Epoch[29] Batch [1200]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.119683,	
2017-07-25 21:41:25,670 Epoch[29] Batch [1210]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.119640,	
2017-07-25 21:41:29,632 Epoch[29] Batch [1220]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.119522,	
2017-07-25 21:41:33,664 Epoch[29] Batch [1230]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.119463,	
2017-07-25 21:41:37,570 Epoch[29] Batch [1240]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.119508,	
2017-07-25 21:41:41,600 Epoch[29] Batch [1250]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.119430,	
2017-07-25 21:41:45,565 Epoch[29] Batch [1260]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.119413,	
2017-07-25 21:41:49,550 Epoch[29] Batch [1270]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.119410,	
2017-07-25 21:41:53,414 Epoch[29] Batch [1280]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.119374,	
2017-07-25 21:41:57,380 Epoch[29] Batch [1290]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.119353,	
2017-07-25 21:42:01,366 Epoch[29] Batch [1300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.119257,	
2017-07-25 21:42:05,386 Epoch[29] Batch [1310]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.119139,	
2017-07-25 21:42:09,335 Epoch[29] Batch [1320]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.119284,	
2017-07-25 21:42:13,329 Epoch[29] Batch [1330]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.119181,	
2017-07-25 21:42:17,254 Epoch[29] Batch [1340]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.119153,	
2017-07-25 21:42:21,249 Epoch[29] Batch [1350]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.119056,	
2017-07-25 21:42:25,261 Epoch[29] Batch [1360]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.119016,	
2017-07-25 21:42:29,078 Epoch[29] Batch [1370]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.119086,	
2017-07-25 21:42:33,126 Epoch[29] Batch [1380]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.119095,	
2017-07-25 21:42:37,075 Epoch[29] Batch [1390]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.119118,	
2017-07-25 21:42:41,156 Epoch[29] Batch [1400]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.118960,	
2017-07-25 21:42:45,106 Epoch[29] Batch [1410]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.118999,	
2017-07-25 21:42:49,100 Epoch[29] Batch [1420]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.119033,	
2017-07-25 21:42:53,193 Epoch[29] Batch [1430]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.118976,	
2017-07-25 21:42:57,176 Epoch[29] Batch [1440]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.118935,	
2017-07-25 21:43:01,247 Epoch[29] Batch [1450]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.118820,	
2017-07-25 21:43:05,274 Epoch[29] Batch [1460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.118791,	
2017-07-25 21:43:09,254 Epoch[29] Batch [1470]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.118797,	
2017-07-25 21:43:13,266 Epoch[29] Batch [1480]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.118801,	
2017-07-25 21:43:15,723 Epoch[29] Train-FCNLogLoss=0.118753
2017-07-25 21:43:15,723 Epoch[29] Time cost=593.043
2017-07-25 21:43:16,457 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.params"
2017-07-25 21:43:18,006 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0030.states"
2017-07-25 21:43:22,656 Epoch[30] Batch [10]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107425,	
2017-07-25 21:43:26,700 Epoch[30] Batch [20]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.108179,	
2017-07-25 21:43:30,801 Epoch[30] Batch [30]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.104996,	
2017-07-25 21:43:34,740 Epoch[30] Batch [40]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.101039,	
2017-07-25 21:43:38,686 Epoch[30] Batch [50]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.100888,	
2017-07-25 21:43:42,660 Epoch[30] Batch [60]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.100227,	
2017-07-25 21:43:46,698 Epoch[30] Batch [70]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.102497,	
2017-07-25 21:43:50,692 Epoch[30] Batch [80]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.104353,	
2017-07-25 21:43:54,775 Epoch[30] Batch [90]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103971,	
2017-07-25 21:43:58,693 Epoch[30] Batch [100]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.103747,	
2017-07-25 21:44:02,698 Epoch[30] Batch [110]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.104265,	
2017-07-25 21:44:06,614 Epoch[30] Batch [120]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.106976,	
2017-07-25 21:44:10,643 Epoch[30] Batch [130]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108126,	
2017-07-25 21:44:14,648 Epoch[30] Batch [140]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.108039,	
2017-07-25 21:44:18,713 Epoch[30] Batch [150]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.107141,	
2017-07-25 21:44:22,695 Epoch[30] Batch [160]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.107201,	
2017-07-25 21:44:26,665 Epoch[30] Batch [170]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.107584,	
2017-07-25 21:44:30,715 Epoch[30] Batch [180]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.107660,	
2017-07-25 21:44:34,740 Epoch[30] Batch [190]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.108298,	
2017-07-25 21:44:38,721 Epoch[30] Batch [200]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.108034,	
2017-07-25 21:44:42,739 Epoch[30] Batch [210]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.108582,	
2017-07-25 21:44:46,716 Epoch[30] Batch [220]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.108923,	
2017-07-25 21:44:50,723 Epoch[30] Batch [230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109463,	
2017-07-25 21:44:54,746 Epoch[30] Batch [240]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.109528,	
2017-07-25 21:44:58,756 Epoch[30] Batch [250]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109379,	
2017-07-25 21:45:02,836 Epoch[30] Batch [260]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.109298,	
2017-07-25 21:45:06,942 Epoch[30] Batch [270]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.109562,	
2017-07-25 21:45:11,008 Epoch[30] Batch [280]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.109891,	
2017-07-25 21:45:14,996 Epoch[30] Batch [290]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.109647,	
2017-07-25 21:45:18,868 Epoch[30] Batch [300]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.109975,	
2017-07-25 21:45:22,871 Epoch[30] Batch [310]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109626,	
2017-07-25 21:45:26,869 Epoch[30] Batch [320]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.109609,	
2017-07-25 21:45:30,843 Epoch[30] Batch [330]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.109605,	
2017-07-25 21:45:34,941 Epoch[30] Batch [340]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.109631,	
2017-07-25 21:45:38,919 Epoch[30] Batch [350]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.109547,	
2017-07-25 21:45:42,801 Epoch[30] Batch [360]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.109610,	
2017-07-25 21:45:46,847 Epoch[30] Batch [370]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109616,	
2017-07-25 21:45:50,849 Epoch[30] Batch [380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109774,	
2017-07-25 21:45:54,791 Epoch[30] Batch [390]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.109843,	
2017-07-25 21:45:58,885 Epoch[30] Batch [400]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.109998,	
2017-07-25 21:46:02,852 Epoch[30] Batch [410]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.110041,	
2017-07-25 21:46:06,812 Epoch[30] Batch [420]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.109829,	
2017-07-25 21:46:10,835 Epoch[30] Batch [430]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.110275,	
2017-07-25 21:46:14,857 Epoch[30] Batch [440]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110113,	
2017-07-25 21:46:18,845 Epoch[30] Batch [450]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.110216,	
2017-07-25 21:46:22,821 Epoch[30] Batch [460]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.110510,	
2017-07-25 21:46:26,855 Epoch[30] Batch [470]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110417,	
2017-07-25 21:46:30,862 Epoch[30] Batch [480]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.110474,	
2017-07-25 21:46:34,789 Epoch[30] Batch [490]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.110458,	
2017-07-25 21:46:38,718 Epoch[30] Batch [500]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110380,	
2017-07-25 21:46:42,720 Epoch[30] Batch [510]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.110496,	
2017-07-25 21:46:46,597 Epoch[30] Batch [520]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.110426,	
2017-07-25 21:46:50,531 Epoch[30] Batch [530]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.110226,	
2017-07-25 21:46:54,425 Epoch[30] Batch [540]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.110054,	
2017-07-25 21:46:58,585 Epoch[30] Batch [550]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.109989,	
2017-07-25 21:47:02,677 Epoch[30] Batch [560]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.110261,	
2017-07-25 21:47:06,753 Epoch[30] Batch [570]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.110162,	
2017-07-25 21:47:10,691 Epoch[30] Batch [580]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.110243,	
2017-07-25 21:47:14,719 Epoch[30] Batch [590]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.109953,	
2017-07-25 21:47:18,630 Epoch[30] Batch [600]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.109812,	
2017-07-25 21:47:22,648 Epoch[30] Batch [610]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.109802,	
2017-07-25 21:47:26,686 Epoch[30] Batch [620]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.109607,	
2017-07-25 21:47:30,651 Epoch[30] Batch [630]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.109664,	
2017-07-25 21:47:34,696 Epoch[30] Batch [640]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109746,	
2017-07-25 21:47:38,692 Epoch[30] Batch [650]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.109938,	
2017-07-25 21:47:42,574 Epoch[30] Batch [660]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.110015,	
2017-07-25 21:47:46,597 Epoch[30] Batch [670]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.110028,	
2017-07-25 21:47:50,592 Epoch[30] Batch [680]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.110105,	
2017-07-25 21:47:54,635 Epoch[30] Batch [690]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110019,	
2017-07-25 21:47:58,675 Epoch[30] Batch [700]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109994,	
2017-07-25 21:48:02,646 Epoch[30] Batch [710]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.109947,	
2017-07-25 21:48:06,707 Epoch[30] Batch [720]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110182,	
2017-07-25 21:48:10,658 Epoch[30] Batch [730]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.110028,	
2017-07-25 21:48:14,726 Epoch[30] Batch [740]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.109931,	
2017-07-25 21:48:18,655 Epoch[30] Batch [750]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110180,	
2017-07-25 21:48:22,606 Epoch[30] Batch [760]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.110019,	
2017-07-25 21:48:26,560 Epoch[30] Batch [770]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.110313,	
2017-07-25 21:48:30,562 Epoch[30] Batch [780]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.110400,	
2017-07-25 21:48:34,492 Epoch[30] Batch [790]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110538,	
2017-07-25 21:48:38,554 Epoch[30] Batch [800]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110439,	
2017-07-25 21:48:42,567 Epoch[30] Batch [810]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.110559,	
2017-07-25 21:48:46,583 Epoch[30] Batch [820]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110654,	
2017-07-25 21:48:50,605 Epoch[30] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110734,	
2017-07-25 21:48:54,592 Epoch[30] Batch [840]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.110925,	
2017-07-25 21:48:58,522 Epoch[30] Batch [850]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110957,	
2017-07-25 21:49:02,558 Epoch[30] Batch [860]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.111081,	
2017-07-25 21:49:06,527 Epoch[30] Batch [870]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.111021,	
2017-07-25 21:49:10,553 Epoch[30] Batch [880]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111071,	
2017-07-25 21:49:14,538 Epoch[30] Batch [890]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.111184,	
2017-07-25 21:49:18,520 Epoch[30] Batch [900]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.111401,	
2017-07-25 21:49:22,460 Epoch[30] Batch [910]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111406,	
2017-07-25 21:49:26,546 Epoch[30] Batch [920]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.111499,	
2017-07-25 21:49:30,641 Epoch[30] Batch [930]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.111519,	
2017-07-25 21:49:34,501 Epoch[30] Batch [940]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.111631,	
2017-07-25 21:49:38,470 Epoch[30] Batch [950]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.111484,	
2017-07-25 21:49:42,367 Epoch[30] Batch [960]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.111486,	
2017-07-25 21:49:46,345 Epoch[30] Batch [970]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111378,	
2017-07-25 21:49:50,282 Epoch[30] Batch [980]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.111375,	
2017-07-25 21:49:54,280 Epoch[30] Batch [990]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.111458,	
2017-07-25 21:49:58,246 Epoch[30] Batch [1000]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.111514,	
2017-07-25 21:50:02,274 Epoch[30] Batch [1010]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111486,	
2017-07-25 21:50:06,318 Epoch[30] Batch [1020]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111870,	
2017-07-25 21:50:10,220 Epoch[30] Batch [1030]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.111979,	
2017-07-25 21:50:14,140 Epoch[30] Batch [1040]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.111959,	
2017-07-25 21:50:18,109 Epoch[30] Batch [1050]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.111978,	
2017-07-25 21:50:22,056 Epoch[30] Batch [1060]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.112064,	
2017-07-25 21:50:25,979 Epoch[30] Batch [1070]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112122,	
2017-07-25 21:50:29,897 Epoch[30] Batch [1080]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112191,	
2017-07-25 21:50:33,842 Epoch[30] Batch [1090]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.112192,	
2017-07-25 21:50:37,850 Epoch[30] Batch [1100]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112167,	
2017-07-25 21:50:41,900 Epoch[30] Batch [1110]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112112,	
2017-07-25 21:50:45,845 Epoch[30] Batch [1120]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.111995,	
2017-07-25 21:50:49,862 Epoch[30] Batch [1130]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.111902,	
2017-07-25 21:50:53,875 Epoch[30] Batch [1140]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111939,	
2017-07-25 21:50:57,928 Epoch[30] Batch [1150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112023,	
2017-07-25 21:51:02,004 Epoch[30] Batch [1160]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.111936,	
2017-07-25 21:51:06,069 Epoch[30] Batch [1170]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.111903,	
2017-07-25 21:51:10,211 Epoch[30] Batch [1180]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.111857,	
2017-07-25 21:51:14,205 Epoch[30] Batch [1190]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.111760,	
2017-07-25 21:51:18,213 Epoch[30] Batch [1200]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.111830,	
2017-07-25 21:51:22,187 Epoch[30] Batch [1210]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.111850,	
2017-07-25 21:51:26,213 Epoch[30] Batch [1220]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111862,	
2017-07-25 21:51:30,263 Epoch[30] Batch [1230]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.111868,	
2017-07-25 21:51:34,164 Epoch[30] Batch [1240]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.111829,	
2017-07-25 21:51:38,209 Epoch[30] Batch [1250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111840,	
2017-07-25 21:51:42,215 Epoch[30] Batch [1260]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.111757,	
2017-07-25 21:51:46,108 Epoch[30] Batch [1270]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.111744,	
2017-07-25 21:51:50,133 Epoch[30] Batch [1280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111793,	
2017-07-25 21:51:54,112 Epoch[30] Batch [1290]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.111893,	
2017-07-25 21:51:58,175 Epoch[30] Batch [1300]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111931,	
2017-07-25 21:52:02,085 Epoch[30] Batch [1310]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.112013,	
2017-07-25 21:52:06,120 Epoch[30] Batch [1320]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.112075,	
2017-07-25 21:52:10,295 Epoch[30] Batch [1330]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112146,	
2017-07-25 21:52:14,314 Epoch[30] Batch [1340]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112305,	
2017-07-25 21:52:18,347 Epoch[30] Batch [1350]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112226,	
2017-07-25 21:52:22,316 Epoch[30] Batch [1360]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.112164,	
2017-07-25 21:52:26,233 Epoch[30] Batch [1370]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112070,	
2017-07-25 21:52:30,156 Epoch[30] Batch [1380]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112032,	
2017-07-25 21:52:34,152 Epoch[30] Batch [1390]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.112101,	
2017-07-25 21:52:38,065 Epoch[30] Batch [1400]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.112404,	
2017-07-25 21:52:42,048 Epoch[30] Batch [1410]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.112404,	
2017-07-25 21:52:45,955 Epoch[30] Batch [1420]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.112541,	
2017-07-25 21:52:49,786 Epoch[30] Batch [1430]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.112511,	
2017-07-25 21:52:53,821 Epoch[30] Batch [1440]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.112478,	
2017-07-25 21:52:57,799 Epoch[30] Batch [1450]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.112461,	
2017-07-25 21:53:01,820 Epoch[30] Batch [1460]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112442,	
2017-07-25 21:53:05,840 Epoch[30] Batch [1470]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112402,	
2017-07-25 21:53:09,799 Epoch[30] Batch [1480]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.112381,	
2017-07-25 21:53:12,251 Epoch[30] Train-FCNLogLoss=0.112339
2017-07-25 21:53:12,251 Epoch[30] Time cost=594.244
2017-07-25 21:53:12,989 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.params"
2017-07-25 21:53:15,630 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0031.states"
2017-07-25 21:53:20,384 Epoch[31] Batch [10]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.109669,	
2017-07-25 21:53:24,299 Epoch[31] Batch [20]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.111137,	
2017-07-25 21:53:28,254 Epoch[31] Batch [30]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.111087,	
2017-07-25 21:53:32,246 Epoch[31] Batch [40]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.114293,	
2017-07-25 21:53:36,200 Epoch[31] Batch [50]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.115760,	
2017-07-25 21:53:40,202 Epoch[31] Batch [60]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112104,	
2017-07-25 21:53:44,254 Epoch[31] Batch [70]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.109944,	
2017-07-25 21:53:48,233 Epoch[31] Batch [80]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.109391,	
2017-07-25 21:53:52,197 Epoch[31] Batch [90]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.108439,	
2017-07-25 21:53:56,351 Epoch[31] Batch [100]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.108473,	
2017-07-25 21:54:00,414 Epoch[31] Batch [110]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.107743,	
2017-07-25 21:54:04,407 Epoch[31] Batch [120]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.108511,	
2017-07-25 21:54:08,588 Epoch[31] Batch [130]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.108658,	
2017-07-25 21:54:12,617 Epoch[31] Batch [140]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108368,	
2017-07-25 21:54:16,549 Epoch[31] Batch [150]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.107540,	
2017-07-25 21:54:20,498 Epoch[31] Batch [160]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.107093,	
2017-07-25 21:54:24,370 Epoch[31] Batch [170]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.107709,	
2017-07-25 21:54:28,391 Epoch[31] Batch [180]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.107878,	
2017-07-25 21:54:32,311 Epoch[31] Batch [190]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.108122,	
2017-07-25 21:54:36,214 Epoch[31] Batch [200]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.108448,	
2017-07-25 21:54:40,168 Epoch[31] Batch [210]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.108810,	
2017-07-25 21:54:44,137 Epoch[31] Batch [220]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.108444,	
2017-07-25 21:54:48,043 Epoch[31] Batch [230]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.108850,	
2017-07-25 21:54:52,027 Epoch[31] Batch [240]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.108806,	
2017-07-25 21:54:56,090 Epoch[31] Batch [250]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109062,	
2017-07-25 21:55:00,025 Epoch[31] Batch [260]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.108612,	
2017-07-25 21:55:04,007 Epoch[31] Batch [270]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.108416,	
2017-07-25 21:55:08,035 Epoch[31] Batch [280]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108730,	
2017-07-25 21:55:12,089 Epoch[31] Batch [290]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108556,	
2017-07-25 21:55:15,955 Epoch[31] Batch [300]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.108261,	
2017-07-25 21:55:20,003 Epoch[31] Batch [310]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.108597,	
2017-07-25 21:55:24,034 Epoch[31] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.108784,	
2017-07-25 21:55:28,027 Epoch[31] Batch [330]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.109072,	
2017-07-25 21:55:31,966 Epoch[31] Batch [340]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.108932,	
2017-07-25 21:55:36,008 Epoch[31] Batch [350]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109306,	
2017-07-25 21:55:40,008 Epoch[31] Batch [360]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109537,	
2017-07-25 21:55:43,955 Epoch[31] Batch [370]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.109495,	
2017-07-25 21:55:48,006 Epoch[31] Batch [380]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.110154,	
2017-07-25 21:55:52,029 Epoch[31] Batch [390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.110941,	
2017-07-25 21:55:56,051 Epoch[31] Batch [400]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110906,	
2017-07-25 21:55:59,965 Epoch[31] Batch [410]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.112082,	
2017-07-25 21:56:03,853 Epoch[31] Batch [420]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.112389,	
2017-07-25 21:56:07,810 Epoch[31] Batch [430]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.112238,	
2017-07-25 21:56:11,702 Epoch[31] Batch [440]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.112088,	
2017-07-25 21:56:15,723 Epoch[31] Batch [450]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112076,	
2017-07-25 21:56:19,831 Epoch[31] Batch [460]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112398,	
2017-07-25 21:56:23,744 Epoch[31] Batch [470]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.112057,	
2017-07-25 21:56:27,705 Epoch[31] Batch [480]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.112009,	
2017-07-25 21:56:31,667 Epoch[31] Batch [490]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.112184,	
2017-07-25 21:56:35,533 Epoch[31] Batch [500]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.112330,	
2017-07-25 21:56:39,552 Epoch[31] Batch [510]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112585,	
2017-07-25 21:56:43,439 Epoch[31] Batch [520]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.112564,	
2017-07-25 21:56:47,634 Epoch[31] Batch [530]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.112358,	
2017-07-25 21:56:51,679 Epoch[31] Batch [540]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112239,	
2017-07-25 21:56:55,617 Epoch[31] Batch [550]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.111954,	
2017-07-25 21:56:59,539 Epoch[31] Batch [560]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.111720,	
2017-07-25 21:57:03,456 Epoch[31] Batch [570]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111718,	
2017-07-25 21:57:07,430 Epoch[31] Batch [580]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111880,	
2017-07-25 21:57:11,392 Epoch[31] Batch [590]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.112039,	
2017-07-25 21:57:15,314 Epoch[31] Batch [600]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112041,	
2017-07-25 21:57:19,232 Epoch[31] Batch [610]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112081,	
2017-07-25 21:57:23,219 Epoch[31] Batch [620]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.112090,	
2017-07-25 21:57:27,179 Epoch[31] Batch [630]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.112042,	
2017-07-25 21:57:31,096 Epoch[31] Batch [640]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111972,	
2017-07-25 21:57:35,044 Epoch[31] Batch [650]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.111935,	
2017-07-25 21:57:39,009 Epoch[31] Batch [660]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.111815,	
2017-07-25 21:57:42,980 Epoch[31] Batch [670]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.111865,	
2017-07-25 21:57:47,025 Epoch[31] Batch [680]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112018,	
2017-07-25 21:57:51,063 Epoch[31] Batch [690]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.111910,	
2017-07-25 21:57:55,035 Epoch[31] Batch [700]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.111968,	
2017-07-25 21:57:58,970 Epoch[31] Batch [710]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.111946,	
2017-07-25 21:58:02,879 Epoch[31] Batch [720]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.111994,	
2017-07-25 21:58:06,771 Epoch[31] Batch [730]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.112002,	
2017-07-25 21:58:10,814 Epoch[31] Batch [740]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111796,	
2017-07-25 21:58:14,836 Epoch[31] Batch [750]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112014,	
2017-07-25 21:58:18,776 Epoch[31] Batch [760]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111930,	
2017-07-25 21:58:22,667 Epoch[31] Batch [770]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.111929,	
2017-07-25 21:58:26,609 Epoch[31] Batch [780]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.112016,	
2017-07-25 21:58:30,546 Epoch[31] Batch [790]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.112047,	
2017-07-25 21:58:34,607 Epoch[31] Batch [800]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112206,	
2017-07-25 21:58:38,631 Epoch[31] Batch [810]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112213,	
2017-07-25 21:58:42,714 Epoch[31] Batch [820]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112160,	
2017-07-25 21:58:46,809 Epoch[31] Batch [830]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112168,	
2017-07-25 21:58:50,731 Epoch[31] Batch [840]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112007,	
2017-07-25 21:58:54,760 Epoch[31] Batch [850]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111956,	
2017-07-25 21:58:58,725 Epoch[31] Batch [860]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.112323,	
2017-07-25 21:59:02,655 Epoch[31] Batch [870]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.112532,	
2017-07-25 21:59:06,527 Epoch[31] Batch [880]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.112688,	
2017-07-25 21:59:10,553 Epoch[31] Batch [890]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112819,	
2017-07-25 21:59:14,537 Epoch[31] Batch [900]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.112931,	
2017-07-25 21:59:18,450 Epoch[31] Batch [910]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.112812,	
2017-07-25 21:59:22,348 Epoch[31] Batch [920]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.112816,	
2017-07-25 21:59:26,354 Epoch[31] Batch [930]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113295,	
2017-07-25 21:59:30,358 Epoch[31] Batch [940]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.113507,	
2017-07-25 21:59:34,287 Epoch[31] Batch [950]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.113730,	
2017-07-25 21:59:38,203 Epoch[31] Batch [960]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.113922,	
2017-07-25 21:59:42,165 Epoch[31] Batch [970]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.113970,	
2017-07-25 21:59:46,142 Epoch[31] Batch [980]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.113954,	
2017-07-25 21:59:50,022 Epoch[31] Batch [990]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.114003,	
2017-07-25 21:59:54,131 Epoch[31] Batch [1000]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.114070,	
2017-07-25 21:59:58,025 Epoch[31] Batch [1010]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.113956,	
2017-07-25 22:00:01,965 Epoch[31] Batch [1020]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.113932,	
2017-07-25 22:00:05,888 Epoch[31] Batch [1030]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.113935,	
2017-07-25 22:00:09,999 Epoch[31] Batch [1040]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.113992,	
2017-07-25 22:00:13,931 Epoch[31] Batch [1050]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.114003,	
2017-07-25 22:00:17,943 Epoch[31] Batch [1060]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.113953,	
2017-07-25 22:00:21,938 Epoch[31] Batch [1070]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.113876,	
2017-07-25 22:00:25,892 Epoch[31] Batch [1080]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.113907,	
2017-07-25 22:00:29,950 Epoch[31] Batch [1090]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.113814,	
2017-07-25 22:00:33,905 Epoch[31] Batch [1100]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.113731,	
2017-07-25 22:00:37,786 Epoch[31] Batch [1110]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.113647,	
2017-07-25 22:00:41,752 Epoch[31] Batch [1120]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.113919,	
2017-07-25 22:00:45,602 Epoch[31] Batch [1130]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.113839,	
2017-07-25 22:00:49,539 Epoch[31] Batch [1140]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.113884,	
2017-07-25 22:00:53,497 Epoch[31] Batch [1150]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.113785,	
2017-07-25 22:00:57,362 Epoch[31] Batch [1160]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.113742,	
2017-07-25 22:01:01,320 Epoch[31] Batch [1170]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.113819,	
2017-07-25 22:01:05,355 Epoch[31] Batch [1180]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113822,	
2017-07-25 22:01:09,484 Epoch[31] Batch [1190]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.113790,	
2017-07-25 22:01:13,465 Epoch[31] Batch [1200]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113745,	
2017-07-25 22:01:17,487 Epoch[31] Batch [1210]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113731,	
2017-07-25 22:01:21,529 Epoch[31] Batch [1220]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113752,	
2017-07-25 22:01:25,604 Epoch[31] Batch [1230]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113869,	
2017-07-25 22:01:29,555 Epoch[31] Batch [1240]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.113881,	
2017-07-25 22:01:33,583 Epoch[31] Batch [1250]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113857,	
2017-07-25 22:01:37,514 Epoch[31] Batch [1260]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.113838,	
2017-07-25 22:01:41,571 Epoch[31] Batch [1270]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.113892,	
2017-07-25 22:01:45,485 Epoch[31] Batch [1280]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.113852,	
2017-07-25 22:01:49,467 Epoch[31] Batch [1290]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113934,	
2017-07-25 22:01:53,393 Epoch[31] Batch [1300]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.113979,	
2017-07-25 22:01:57,543 Epoch[31] Batch [1310]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.113959,	
2017-07-25 22:02:01,553 Epoch[31] Batch [1320]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114136,	
2017-07-25 22:02:05,403 Epoch[31] Batch [1330]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.114110,	
2017-07-25 22:02:09,409 Epoch[31] Batch [1340]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.114106,	
2017-07-25 22:02:13,327 Epoch[31] Batch [1350]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.114248,	
2017-07-25 22:02:17,342 Epoch[31] Batch [1360]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.114377,	
2017-07-25 22:02:21,398 Epoch[31] Batch [1370]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.114362,	
2017-07-25 22:02:25,304 Epoch[31] Batch [1380]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.114376,	
2017-07-25 22:02:29,217 Epoch[31] Batch [1390]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.114376,	
2017-07-25 22:02:33,146 Epoch[31] Batch [1400]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.114323,	
2017-07-25 22:02:37,159 Epoch[31] Batch [1410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.114259,	
2017-07-25 22:02:41,241 Epoch[31] Batch [1420]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.114187,	
2017-07-25 22:02:45,180 Epoch[31] Batch [1430]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.114178,	
2017-07-25 22:02:49,100 Epoch[31] Batch [1440]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.114040,	
2017-07-25 22:02:52,995 Epoch[31] Batch [1450]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.114151,	
2017-07-25 22:02:56,924 Epoch[31] Batch [1460]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.114090,	
2017-07-25 22:03:00,943 Epoch[31] Batch [1470]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.114164,	
2017-07-25 22:03:04,811 Epoch[31] Batch [1480]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.114190,	
2017-07-25 22:03:07,130 Epoch[31] Train-FCNLogLoss=0.114125
2017-07-25 22:03:07,131 Epoch[31] Time cost=591.500
2017-07-25 22:03:07,861 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.params"
2017-07-25 22:03:10,014 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0032.states"
2017-07-25 22:03:14,605 Epoch[32] Batch [10]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.127086,	
2017-07-25 22:03:18,620 Epoch[32] Batch [20]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.117267,	
2017-07-25 22:03:22,555 Epoch[32] Batch [30]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.109320,	
2017-07-25 22:03:26,515 Epoch[32] Batch [40]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.104617,	
2017-07-25 22:03:30,478 Epoch[32] Batch [50]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.108748,	
2017-07-25 22:03:34,361 Epoch[32] Batch [60]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.115959,	
2017-07-25 22:03:38,282 Epoch[32] Batch [70]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.116403,	
2017-07-25 22:03:42,204 Epoch[32] Batch [80]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.115193,	
2017-07-25 22:03:46,149 Epoch[32] Batch [90]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.114622,	
2017-07-25 22:03:50,137 Epoch[32] Batch [100]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.114566,	
2017-07-25 22:03:54,210 Epoch[32] Batch [110]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113217,	
2017-07-25 22:03:58,158 Epoch[32] Batch [120]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.113563,	
2017-07-25 22:04:02,281 Epoch[32] Batch [130]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113094,	
2017-07-25 22:04:06,296 Epoch[32] Batch [140]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113491,	
2017-07-25 22:04:10,234 Epoch[32] Batch [150]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.112698,	
2017-07-25 22:04:14,210 Epoch[32] Batch [160]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.112482,	
2017-07-25 22:04:18,229 Epoch[32] Batch [170]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112768,	
2017-07-25 22:04:22,266 Epoch[32] Batch [180]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113534,	
2017-07-25 22:04:26,371 Epoch[32] Batch [190]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113894,	
2017-07-25 22:04:30,449 Epoch[32] Batch [200]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.114167,	
2017-07-25 22:04:34,306 Epoch[32] Batch [210]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.113611,	
2017-07-25 22:04:38,277 Epoch[32] Batch [220]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.113710,	
2017-07-25 22:04:42,257 Epoch[32] Batch [230]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113223,	
2017-07-25 22:04:46,236 Epoch[32] Batch [240]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113482,	
2017-07-25 22:04:50,225 Epoch[32] Batch [250]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.113074,	
2017-07-25 22:04:54,168 Epoch[32] Batch [260]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.112717,	
2017-07-25 22:04:58,197 Epoch[32] Batch [270]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112996,	
2017-07-25 22:05:02,141 Epoch[32] Batch [280]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.112807,	
2017-07-25 22:05:06,158 Epoch[32] Batch [290]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112943,	
2017-07-25 22:05:10,162 Epoch[32] Batch [300]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.112556,	
2017-07-25 22:05:14,164 Epoch[32] Batch [310]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112328,	
2017-07-25 22:05:18,333 Epoch[32] Batch [320]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.112023,	
2017-07-25 22:05:22,333 Epoch[32] Batch [330]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112189,	
2017-07-25 22:05:26,274 Epoch[32] Batch [340]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111758,	
2017-07-25 22:05:30,165 Epoch[32] Batch [350]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.111737,	
2017-07-25 22:05:34,043 Epoch[32] Batch [360]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.111394,	
2017-07-25 22:05:38,130 Epoch[32] Batch [370]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.111484,	
2017-07-25 22:05:42,189 Epoch[32] Batch [380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111408,	
2017-07-25 22:05:46,200 Epoch[32] Batch [390]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111325,	
2017-07-25 22:05:50,205 Epoch[32] Batch [400]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.110737,	
2017-07-25 22:05:54,185 Epoch[32] Batch [410]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.110788,	
2017-07-25 22:05:58,113 Epoch[32] Batch [420]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110561,	
2017-07-25 22:06:02,113 Epoch[32] Batch [430]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.110557,	
2017-07-25 22:06:06,044 Epoch[32] Batch [440]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110302,	
2017-07-25 22:06:09,963 Epoch[32] Batch [450]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111071,	
2017-07-25 22:06:13,906 Epoch[32] Batch [460]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111219,	
2017-07-25 22:06:17,820 Epoch[32] Batch [470]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.111541,	
2017-07-25 22:06:21,746 Epoch[32] Batch [480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.111758,	
2017-07-25 22:06:25,736 Epoch[32] Batch [490]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.111970,	
2017-07-25 22:06:29,781 Epoch[32] Batch [500]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111666,	
2017-07-25 22:06:33,799 Epoch[32] Batch [510]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.111811,	
2017-07-25 22:06:37,644 Epoch[32] Batch [520]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.111801,	
2017-07-25 22:06:41,547 Epoch[32] Batch [530]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.111887,	
2017-07-25 22:06:45,469 Epoch[32] Batch [540]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.111711,	
2017-07-25 22:06:49,545 Epoch[32] Batch [550]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.111527,	
2017-07-25 22:06:53,554 Epoch[32] Batch [560]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.111882,	
2017-07-25 22:06:57,491 Epoch[32] Batch [570]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.111993,	
2017-07-25 22:07:01,434 Epoch[32] Batch [580]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111959,	
2017-07-25 22:07:05,449 Epoch[32] Batch [590]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.111760,	
2017-07-25 22:07:09,422 Epoch[32] Batch [600]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.111811,	
2017-07-25 22:07:13,272 Epoch[32] Batch [610]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.111606,	
2017-07-25 22:07:17,196 Epoch[32] Batch [620]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.111532,	
2017-07-25 22:07:21,273 Epoch[32] Batch [630]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.111640,	
2017-07-25 22:07:25,230 Epoch[32] Batch [640]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.111671,	
2017-07-25 22:07:29,111 Epoch[32] Batch [650]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.111581,	
2017-07-25 22:07:33,049 Epoch[32] Batch [660]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.111498,	
2017-07-25 22:07:37,073 Epoch[32] Batch [670]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.111528,	
2017-07-25 22:07:40,954 Epoch[32] Batch [680]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.111766,	
2017-07-25 22:07:44,959 Epoch[32] Batch [690]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.111770,	
2017-07-25 22:07:49,021 Epoch[32] Batch [700]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.111852,	
2017-07-25 22:07:53,127 Epoch[32] Batch [710]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.111736,	
2017-07-25 22:07:57,185 Epoch[32] Batch [720]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.111579,	
2017-07-25 22:08:01,143 Epoch[32] Batch [730]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.111465,	
2017-07-25 22:08:05,170 Epoch[32] Batch [740]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111297,	
2017-07-25 22:08:09,214 Epoch[32] Batch [750]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111238,	
2017-07-25 22:08:13,212 Epoch[32] Batch [760]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.111272,	
2017-07-25 22:08:17,198 Epoch[32] Batch [770]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.111277,	
2017-07-25 22:08:21,199 Epoch[32] Batch [780]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.111411,	
2017-07-25 22:08:25,139 Epoch[32] Batch [790]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111699,	
2017-07-25 22:08:29,088 Epoch[32] Batch [800]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.111650,	
2017-07-25 22:08:33,047 Epoch[32] Batch [810]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.111686,	
2017-07-25 22:08:36,937 Epoch[32] Batch [820]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.111889,	
2017-07-25 22:08:40,846 Epoch[32] Batch [830]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.112470,	
2017-07-25 22:08:44,810 Epoch[32] Batch [840]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.112820,	
2017-07-25 22:08:48,797 Epoch[32] Batch [850]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.112976,	
2017-07-25 22:08:52,780 Epoch[32] Batch [860]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.112990,	
2017-07-25 22:08:56,778 Epoch[32] Batch [870]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.113221,	
2017-07-25 22:09:00,818 Epoch[32] Batch [880]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113254,	
2017-07-25 22:09:04,866 Epoch[32] Batch [890]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.113259,	
2017-07-25 22:09:08,886 Epoch[32] Batch [900]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113197,	
2017-07-25 22:09:12,930 Epoch[32] Batch [910]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.113218,	
2017-07-25 22:09:16,826 Epoch[32] Batch [920]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.113035,	
2017-07-25 22:09:20,677 Epoch[32] Batch [930]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.113149,	
2017-07-25 22:09:24,668 Epoch[32] Batch [940]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.113034,	
2017-07-25 22:09:28,607 Epoch[32] Batch [950]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.113005,	
2017-07-25 22:09:32,693 Epoch[32] Batch [960]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.112948,	
2017-07-25 22:09:36,680 Epoch[32] Batch [970]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.112761,	
2017-07-25 22:09:40,603 Epoch[32] Batch [980]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.112607,	
2017-07-25 22:09:44,494 Epoch[32] Batch [990]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.112463,	
2017-07-25 22:09:48,344 Epoch[32] Batch [1000]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.112295,	
2017-07-25 22:09:52,433 Epoch[32] Batch [1010]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112317,	
2017-07-25 22:09:56,473 Epoch[32] Batch [1020]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.112261,	
2017-07-25 22:10:00,586 Epoch[32] Batch [1030]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.112227,	
2017-07-25 22:10:04,587 Epoch[32] Batch [1040]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112210,	
2017-07-25 22:10:08,609 Epoch[32] Batch [1050]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112180,	
2017-07-25 22:10:12,559 Epoch[32] Batch [1060]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.112104,	
2017-07-25 22:10:16,624 Epoch[32] Batch [1070]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.112035,	
2017-07-25 22:10:20,598 Epoch[32] Batch [1080]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.112087,	
2017-07-25 22:10:24,442 Epoch[32] Batch [1090]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.111873,	
2017-07-25 22:10:28,360 Epoch[32] Batch [1100]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111870,	
2017-07-25 22:10:32,380 Epoch[32] Batch [1110]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.111838,	
2017-07-25 22:10:36,376 Epoch[32] Batch [1120]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.111871,	
2017-07-25 22:10:40,349 Epoch[32] Batch [1130]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.111802,	
2017-07-25 22:10:44,248 Epoch[32] Batch [1140]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.111833,	
2017-07-25 22:10:48,167 Epoch[32] Batch [1150]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111804,	
2017-07-25 22:10:52,148 Epoch[32] Batch [1160]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.111668,	
2017-07-25 22:10:56,101 Epoch[32] Batch [1170]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.111658,	
2017-07-25 22:10:59,953 Epoch[32] Batch [1180]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.111625,	
2017-07-25 22:11:03,833 Epoch[32] Batch [1190]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.111585,	
2017-07-25 22:11:07,811 Epoch[32] Batch [1200]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111681,	
2017-07-25 22:11:11,765 Epoch[32] Batch [1210]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.111691,	
2017-07-25 22:11:15,868 Epoch[32] Batch [1220]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.111675,	
2017-07-25 22:11:19,944 Epoch[32] Batch [1230]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.111626,	
2017-07-25 22:11:23,957 Epoch[32] Batch [1240]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111645,	
2017-07-25 22:11:28,031 Epoch[32] Batch [1250]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.111842,	
2017-07-25 22:11:32,009 Epoch[32] Batch [1260]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.111791,	
2017-07-25 22:11:36,176 Epoch[32] Batch [1270]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.111796,	
2017-07-25 22:11:40,193 Epoch[32] Batch [1280]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.111802,	
2017-07-25 22:11:44,203 Epoch[32] Batch [1290]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.111835,	
2017-07-25 22:11:48,108 Epoch[32] Batch [1300]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.111777,	
2017-07-25 22:11:52,086 Epoch[32] Batch [1310]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111771,	
2017-07-25 22:11:56,004 Epoch[32] Batch [1320]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111683,	
2017-07-25 22:11:59,995 Epoch[32] Batch [1330]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.111763,	
2017-07-25 22:12:03,969 Epoch[32] Batch [1340]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.111793,	
2017-07-25 22:12:07,933 Epoch[32] Batch [1350]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.111734,	
2017-07-25 22:12:11,830 Epoch[32] Batch [1360]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.111693,	
2017-07-25 22:12:15,824 Epoch[32] Batch [1370]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.111642,	
2017-07-25 22:12:19,736 Epoch[32] Batch [1380]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.111598,	
2017-07-25 22:12:23,587 Epoch[32] Batch [1390]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.111754,	
2017-07-25 22:12:27,622 Epoch[32] Batch [1400]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.111843,	
2017-07-25 22:12:31,607 Epoch[32] Batch [1410]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.111985,	
2017-07-25 22:12:35,617 Epoch[32] Batch [1420]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112079,	
2017-07-25 22:12:39,664 Epoch[32] Batch [1430]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112110,	
2017-07-25 22:12:43,748 Epoch[32] Batch [1440]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112111,	
2017-07-25 22:12:47,776 Epoch[32] Batch [1450]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112070,	
2017-07-25 22:12:51,596 Epoch[32] Batch [1460]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.112009,	
2017-07-25 22:12:55,623 Epoch[32] Batch [1470]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111951,	
2017-07-25 22:12:59,486 Epoch[32] Batch [1480]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.111962,	
2017-07-25 22:13:01,804 Epoch[32] Train-FCNLogLoss=0.112035
2017-07-25 22:13:01,805 Epoch[32] Time cost=591.790
2017-07-25 22:13:02,619 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.params"
2017-07-25 22:13:06,283 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0033.states"
2017-07-25 22:13:10,937 Epoch[33] Batch [10]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094815,	
2017-07-25 22:13:14,829 Epoch[33] Batch [20]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.107228,	
2017-07-25 22:13:18,810 Epoch[33] Batch [30]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.110538,	
2017-07-25 22:13:22,775 Epoch[33] Batch [40]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.114031,	
2017-07-25 22:13:26,808 Epoch[33] Batch [50]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.113450,	
2017-07-25 22:13:30,947 Epoch[33] Batch [60]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.116501,	
2017-07-25 22:13:35,089 Epoch[33] Batch [70]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115463,	
2017-07-25 22:13:39,131 Epoch[33] Batch [80]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.116008,	
2017-07-25 22:13:43,065 Epoch[33] Batch [90]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.114743,	
2017-07-25 22:13:47,021 Epoch[33] Batch [100]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.113565,	
2017-07-25 22:13:51,105 Epoch[33] Batch [110]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.113221,	
2017-07-25 22:13:55,154 Epoch[33] Batch [120]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112338,	
2017-07-25 22:13:59,021 Epoch[33] Batch [130]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.111404,	
2017-07-25 22:14:02,892 Epoch[33] Batch [140]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.111481,	
2017-07-25 22:14:06,699 Epoch[33] Batch [150]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.111850,	
2017-07-25 22:14:10,661 Epoch[33] Batch [160]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.111512,	
2017-07-25 22:14:14,592 Epoch[33] Batch [170]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.111332,	
2017-07-25 22:14:18,540 Epoch[33] Batch [180]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.111073,	
2017-07-25 22:14:22,451 Epoch[33] Batch [190]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.111880,	
2017-07-25 22:14:26,445 Epoch[33] Batch [200]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112100,	
2017-07-25 22:14:30,384 Epoch[33] Batch [210]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.112259,	
2017-07-25 22:14:34,490 Epoch[33] Batch [220]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.112323,	
2017-07-25 22:14:38,497 Epoch[33] Batch [230]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112079,	
2017-07-25 22:14:42,426 Epoch[33] Batch [240]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.111762,	
2017-07-25 22:14:46,439 Epoch[33] Batch [250]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111613,	
2017-07-25 22:14:50,395 Epoch[33] Batch [260]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.111431,	
2017-07-25 22:14:54,391 Epoch[33] Batch [270]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.111098,	
2017-07-25 22:14:58,391 Epoch[33] Batch [280]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.110677,	
2017-07-25 22:15:02,131 Epoch[33] Batch [290]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.110553,	
2017-07-25 22:15:06,080 Epoch[33] Batch [300]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.109972,	
2017-07-25 22:15:10,165 Epoch[33] Batch [310]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.109999,	
2017-07-25 22:15:14,142 Epoch[33] Batch [320]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.109862,	
2017-07-25 22:15:18,267 Epoch[33] Batch [330]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110301,	
2017-07-25 22:15:22,337 Epoch[33] Batch [340]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110385,	
2017-07-25 22:15:26,437 Epoch[33] Batch [350]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.110739,	
2017-07-25 22:15:30,639 Epoch[33] Batch [360]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.111052,	
2017-07-25 22:15:34,757 Epoch[33] Batch [370]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.111891,	
2017-07-25 22:15:38,812 Epoch[33] Batch [380]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112361,	
2017-07-25 22:15:42,793 Epoch[33] Batch [390]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.113693,	
2017-07-25 22:15:46,805 Epoch[33] Batch [400]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.114462,	
2017-07-25 22:15:50,955 Epoch[33] Batch [410]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.114703,	
2017-07-25 22:15:55,010 Epoch[33] Batch [420]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.114753,	
2017-07-25 22:15:59,051 Epoch[33] Batch [430]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114677,	
2017-07-25 22:16:03,080 Epoch[33] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.115194,	
2017-07-25 22:16:06,973 Epoch[33] Batch [450]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.115299,	
2017-07-25 22:16:10,915 Epoch[33] Batch [460]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.115390,	
2017-07-25 22:16:14,839 Epoch[33] Batch [470]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.115349,	
2017-07-25 22:16:18,672 Epoch[33] Batch [480]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.115269,	
2017-07-25 22:16:22,706 Epoch[33] Batch [490]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.114901,	
2017-07-25 22:16:26,697 Epoch[33] Batch [500]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.114751,	
2017-07-25 22:16:30,657 Epoch[33] Batch [510]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.114601,	
2017-07-25 22:16:34,680 Epoch[33] Batch [520]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114608,	
2017-07-25 22:16:38,563 Epoch[33] Batch [530]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.114394,	
2017-07-25 22:16:42,525 Epoch[33] Batch [540]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.114217,	
2017-07-25 22:16:46,539 Epoch[33] Batch [550]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.114074,	
2017-07-25 22:16:50,550 Epoch[33] Batch [560]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114169,	
2017-07-25 22:16:54,766 Epoch[33] Batch [570]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.114345,	
2017-07-25 22:16:58,808 Epoch[33] Batch [580]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114285,	
2017-07-25 22:17:02,774 Epoch[33] Batch [590]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.114182,	
2017-07-25 22:17:06,814 Epoch[33] Batch [600]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.114467,	
2017-07-25 22:17:10,917 Epoch[33] Batch [610]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.114400,	
2017-07-25 22:17:14,898 Epoch[33] Batch [620]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.114540,	
2017-07-25 22:17:18,817 Epoch[33] Batch [630]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.114810,	
2017-07-25 22:17:22,869 Epoch[33] Batch [640]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.114808,	
2017-07-25 22:17:26,818 Epoch[33] Batch [650]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.114798,	
2017-07-25 22:17:30,875 Epoch[33] Batch [660]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.114635,	
2017-07-25 22:17:34,963 Epoch[33] Batch [670]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.114404,	
2017-07-25 22:17:39,028 Epoch[33] Batch [680]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.114350,	
2017-07-25 22:17:43,133 Epoch[33] Batch [690]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.114291,	
2017-07-25 22:17:47,093 Epoch[33] Batch [700]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.114025,	
2017-07-25 22:17:50,965 Epoch[33] Batch [710]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.113953,	
2017-07-25 22:17:54,823 Epoch[33] Batch [720]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.113943,	
2017-07-25 22:17:58,793 Epoch[33] Batch [730]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.113824,	
2017-07-25 22:18:02,812 Epoch[33] Batch [740]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113987,	
2017-07-25 22:18:06,781 Epoch[33] Batch [750]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.114014,	
2017-07-25 22:18:10,688 Epoch[33] Batch [760]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.113915,	
2017-07-25 22:18:14,743 Epoch[33] Batch [770]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.113968,	
2017-07-25 22:18:18,580 Epoch[33] Batch [780]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.113879,	
2017-07-25 22:18:22,482 Epoch[33] Batch [790]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.113826,	
2017-07-25 22:18:26,334 Epoch[33] Batch [800]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.113639,	
2017-07-25 22:18:30,244 Epoch[33] Batch [810]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.113644,	
2017-07-25 22:18:34,297 Epoch[33] Batch [820]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113511,	
2017-07-25 22:18:38,351 Epoch[33] Batch [830]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.113550,	
2017-07-25 22:18:42,393 Epoch[33] Batch [840]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113495,	
2017-07-25 22:18:46,396 Epoch[33] Batch [850]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.113471,	
2017-07-25 22:18:50,340 Epoch[33] Batch [860]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.113347,	
2017-07-25 22:18:54,212 Epoch[33] Batch [870]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.113345,	
2017-07-25 22:18:58,232 Epoch[33] Batch [880]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113135,	
2017-07-25 22:19:02,141 Epoch[33] Batch [890]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.113208,	
2017-07-25 22:19:06,237 Epoch[33] Batch [900]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113071,	
2017-07-25 22:19:10,196 Epoch[33] Batch [910]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.113088,	
2017-07-25 22:19:14,132 Epoch[33] Batch [920]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.113003,	
2017-07-25 22:19:17,984 Epoch[33] Batch [930]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.112953,	
2017-07-25 22:19:21,992 Epoch[33] Batch [940]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113054,	
2017-07-25 22:19:25,854 Epoch[33] Batch [950]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.113129,	
2017-07-25 22:19:29,831 Epoch[33] Batch [960]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.113056,	
2017-07-25 22:19:33,892 Epoch[33] Batch [970]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112998,	
2017-07-25 22:19:37,818 Epoch[33] Batch [980]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.112934,	
2017-07-25 22:19:41,801 Epoch[33] Batch [990]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.112975,	
2017-07-25 22:19:45,750 Epoch[33] Batch [1000]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.112975,	
2017-07-25 22:19:49,848 Epoch[33] Batch [1010]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112887,	
2017-07-25 22:19:53,925 Epoch[33] Batch [1020]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.112861,	
2017-07-25 22:19:57,978 Epoch[33] Batch [1030]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.112908,	
2017-07-25 22:20:01,973 Epoch[33] Batch [1040]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.112916,	
2017-07-25 22:20:05,921 Epoch[33] Batch [1050]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.112882,	
2017-07-25 22:20:09,928 Epoch[33] Batch [1060]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112877,	
2017-07-25 22:20:13,862 Epoch[33] Batch [1070]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.112874,	
2017-07-25 22:20:17,839 Epoch[33] Batch [1080]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.112944,	
2017-07-25 22:20:21,758 Epoch[33] Batch [1090]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112921,	
2017-07-25 22:20:25,701 Epoch[33] Batch [1100]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.112878,	
2017-07-25 22:20:29,605 Epoch[33] Batch [1110]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.112898,	
2017-07-25 22:20:33,475 Epoch[33] Batch [1120]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.112941,	
2017-07-25 22:20:37,377 Epoch[33] Batch [1130]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.112859,	
2017-07-25 22:20:41,320 Epoch[33] Batch [1140]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.112861,	
2017-07-25 22:20:45,337 Epoch[33] Batch [1150]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112856,	
2017-07-25 22:20:49,387 Epoch[33] Batch [1160]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112890,	
2017-07-25 22:20:53,340 Epoch[33] Batch [1170]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.112807,	
2017-07-25 22:20:57,444 Epoch[33] Batch [1180]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.112779,	
2017-07-25 22:21:01,450 Epoch[33] Batch [1190]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.112802,	
2017-07-25 22:21:05,425 Epoch[33] Batch [1200]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.112742,	
2017-07-25 22:21:09,422 Epoch[33] Batch [1210]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.112656,	
2017-07-25 22:21:13,341 Epoch[33] Batch [1220]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112708,	
2017-07-25 22:21:17,320 Epoch[33] Batch [1230]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.112776,	
2017-07-25 22:21:21,267 Epoch[33] Batch [1240]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.112899,	
2017-07-25 22:21:25,336 Epoch[33] Batch [1250]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.112906,	
2017-07-25 22:21:29,368 Epoch[33] Batch [1260]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.112920,	
2017-07-25 22:21:33,325 Epoch[33] Batch [1270]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.112848,	
2017-07-25 22:21:37,386 Epoch[33] Batch [1280]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.112835,	
2017-07-25 22:21:41,287 Epoch[33] Batch [1290]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.112912,	
2017-07-25 22:21:45,313 Epoch[33] Batch [1300]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112964,	
2017-07-25 22:21:49,359 Epoch[33] Batch [1310]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112928,	
2017-07-25 22:21:53,302 Epoch[33] Batch [1320]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.113001,	
2017-07-25 22:21:57,251 Epoch[33] Batch [1330]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.113038,	
2017-07-25 22:22:01,252 Epoch[33] Batch [1340]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.113090,	
2017-07-25 22:22:05,120 Epoch[33] Batch [1350]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.113011,	
2017-07-25 22:22:08,983 Epoch[33] Batch [1360]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.112965,	
2017-07-25 22:22:12,970 Epoch[33] Batch [1370]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.112856,	
2017-07-25 22:22:16,844 Epoch[33] Batch [1380]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.112767,	
2017-07-25 22:22:20,750 Epoch[33] Batch [1390]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.112697,	
2017-07-25 22:22:24,711 Epoch[33] Batch [1400]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.112778,	
2017-07-25 22:22:28,835 Epoch[33] Batch [1410]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112763,	
2017-07-25 22:22:33,033 Epoch[33] Batch [1420]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112716,	
2017-07-25 22:22:37,029 Epoch[33] Batch [1430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.112727,	
2017-07-25 22:22:41,017 Epoch[33] Batch [1440]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.112721,	
2017-07-25 22:22:45,099 Epoch[33] Batch [1450]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.112897,	
2017-07-25 22:22:49,089 Epoch[33] Batch [1460]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.112826,	
2017-07-25 22:22:53,056 Epoch[33] Batch [1470]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.112861,	
2017-07-25 22:22:56,847 Epoch[33] Batch [1480]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.112904,	
2017-07-25 22:22:59,218 Epoch[33] Train-FCNLogLoss=0.112927
2017-07-25 22:22:59,218 Epoch[33] Time cost=592.934
2017-07-25 22:23:00,091 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.params"
2017-07-25 22:23:03,902 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0034.states"
2017-07-25 22:23:08,680 Epoch[34] Batch [10]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.109648,	
2017-07-25 22:23:12,689 Epoch[34] Batch [20]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112394,	
2017-07-25 22:23:16,708 Epoch[34] Batch [30]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.107239,	
2017-07-25 22:23:20,560 Epoch[34] Batch [40]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.109224,	
2017-07-25 22:23:24,456 Epoch[34] Batch [50]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.109031,	
2017-07-25 22:23:28,400 Epoch[34] Batch [60]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.107070,	
2017-07-25 22:23:32,482 Epoch[34] Batch [70]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.106319,	
2017-07-25 22:23:36,407 Epoch[34] Batch [80]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.107053,	
2017-07-25 22:23:40,483 Epoch[34] Batch [90]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.108740,	
2017-07-25 22:23:44,479 Epoch[34] Batch [100]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.108407,	
2017-07-25 22:23:48,489 Epoch[34] Batch [110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.108052,	
2017-07-25 22:23:52,463 Epoch[34] Batch [120]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.107142,	
2017-07-25 22:23:56,537 Epoch[34] Batch [130]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.107807,	
2017-07-25 22:24:00,444 Epoch[34] Batch [140]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.108057,	
2017-07-25 22:24:04,494 Epoch[34] Batch [150]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.108034,	
2017-07-25 22:24:08,434 Epoch[34] Batch [160]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.107614,	
2017-07-25 22:24:12,394 Epoch[34] Batch [170]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.106924,	
2017-07-25 22:24:16,404 Epoch[34] Batch [180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.107203,	
2017-07-25 22:24:20,406 Epoch[34] Batch [190]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.106865,	
2017-07-25 22:24:24,391 Epoch[34] Batch [200]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.106518,	
2017-07-25 22:24:28,396 Epoch[34] Batch [210]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.106052,	
2017-07-25 22:24:32,333 Epoch[34] Batch [220]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.105782,	
2017-07-25 22:24:36,303 Epoch[34] Batch [230]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.105986,	
2017-07-25 22:24:40,294 Epoch[34] Batch [240]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.106637,	
2017-07-25 22:24:44,321 Epoch[34] Batch [250]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107646,	
2017-07-25 22:24:48,440 Epoch[34] Batch [260]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.111282,	
2017-07-25 22:24:52,510 Epoch[34] Batch [270]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.112943,	
2017-07-25 22:24:56,344 Epoch[34] Batch [280]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.113485,	
2017-07-25 22:25:00,342 Epoch[34] Batch [290]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.113473,	
2017-07-25 22:25:04,311 Epoch[34] Batch [300]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.113645,	
2017-07-25 22:25:08,455 Epoch[34] Batch [310]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113737,	
2017-07-25 22:25:12,518 Epoch[34] Batch [320]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113902,	
2017-07-25 22:25:16,495 Epoch[34] Batch [330]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.113741,	
2017-07-25 22:25:20,565 Epoch[34] Batch [340]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.114128,	
2017-07-25 22:25:24,680 Epoch[34] Batch [350]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.113792,	
2017-07-25 22:25:28,778 Epoch[34] Batch [360]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.113793,	
2017-07-25 22:25:32,784 Epoch[34] Batch [370]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114218,	
2017-07-25 22:25:36,833 Epoch[34] Batch [380]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.114232,	
2017-07-25 22:25:40,735 Epoch[34] Batch [390]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.114043,	
2017-07-25 22:25:44,709 Epoch[34] Batch [400]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.113631,	
2017-07-25 22:25:48,683 Epoch[34] Batch [410]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.113329,	
2017-07-25 22:25:52,691 Epoch[34] Batch [420]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.113237,	
2017-07-25 22:25:56,702 Epoch[34] Batch [430]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.112784,	
2017-07-25 22:26:00,723 Epoch[34] Batch [440]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.112744,	
2017-07-25 22:26:04,731 Epoch[34] Batch [450]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.112694,	
2017-07-25 22:26:08,780 Epoch[34] Batch [460]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.112724,	
2017-07-25 22:26:12,769 Epoch[34] Batch [470]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.112582,	
2017-07-25 22:26:16,663 Epoch[34] Batch [480]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.112419,	
2017-07-25 22:26:20,678 Epoch[34] Batch [490]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.112439,	
2017-07-25 22:26:24,608 Epoch[34] Batch [500]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.112423,	
2017-07-25 22:26:28,566 Epoch[34] Batch [510]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.112057,	
2017-07-25 22:26:32,657 Epoch[34] Batch [520]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.111949,	
2017-07-25 22:26:36,639 Epoch[34] Batch [530]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.112090,	
2017-07-25 22:26:40,594 Epoch[34] Batch [540]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.112107,	
2017-07-25 22:26:44,509 Epoch[34] Batch [550]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.112208,	
2017-07-25 22:26:48,367 Epoch[34] Batch [560]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.112387,	
2017-07-25 22:26:52,331 Epoch[34] Batch [570]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.112507,	
2017-07-25 22:26:56,422 Epoch[34] Batch [580]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112513,	
2017-07-25 22:27:00,549 Epoch[34] Batch [590]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.112273,	
2017-07-25 22:27:04,647 Epoch[34] Batch [600]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112247,	
2017-07-25 22:27:08,647 Epoch[34] Batch [610]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.112103,	
2017-07-25 22:27:12,629 Epoch[34] Batch [620]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.112175,	
2017-07-25 22:27:16,727 Epoch[34] Batch [630]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.112040,	
2017-07-25 22:27:20,693 Epoch[34] Batch [640]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.111783,	
2017-07-25 22:27:24,902 Epoch[34] Batch [650]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.111941,	
2017-07-25 22:27:28,862 Epoch[34] Batch [660]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.111990,	
2017-07-25 22:27:32,958 Epoch[34] Batch [670]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112067,	
2017-07-25 22:27:36,838 Epoch[34] Batch [680]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.112093,	
2017-07-25 22:27:40,863 Epoch[34] Batch [690]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.112016,	
2017-07-25 22:27:44,906 Epoch[34] Batch [700]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111897,	
2017-07-25 22:27:48,986 Epoch[34] Batch [710]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.111844,	
2017-07-25 22:27:52,837 Epoch[34] Batch [720]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.111767,	
2017-07-25 22:27:56,830 Epoch[34] Batch [730]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.111800,	
2017-07-25 22:28:00,860 Epoch[34] Batch [740]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111675,	
2017-07-25 22:28:04,808 Epoch[34] Batch [750]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.111655,	
2017-07-25 22:28:08,865 Epoch[34] Batch [760]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.111675,	
2017-07-25 22:28:12,955 Epoch[34] Batch [770]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.111672,	
2017-07-25 22:28:16,820 Epoch[34] Batch [780]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.111640,	
2017-07-25 22:28:20,857 Epoch[34] Batch [790]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.111539,	
2017-07-25 22:28:24,938 Epoch[34] Batch [800]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.111515,	
2017-07-25 22:28:28,880 Epoch[34] Batch [810]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111303,	
2017-07-25 22:28:32,856 Epoch[34] Batch [820]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111357,	
2017-07-25 22:28:36,798 Epoch[34] Batch [830]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111211,	
2017-07-25 22:28:40,829 Epoch[34] Batch [840]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111139,	
2017-07-25 22:28:44,866 Epoch[34] Batch [850]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.111048,	
2017-07-25 22:28:48,747 Epoch[34] Batch [860]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.110950,	
2017-07-25 22:28:52,721 Epoch[34] Batch [870]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.110983,	
2017-07-25 22:28:56,677 Epoch[34] Batch [880]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.110952,	
2017-07-25 22:29:00,542 Epoch[34] Batch [890]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.111071,	
2017-07-25 22:29:04,513 Epoch[34] Batch [900]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.110986,	
2017-07-25 22:29:08,439 Epoch[34] Batch [910]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.110926,	
2017-07-25 22:29:12,440 Epoch[34] Batch [920]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.110787,	
2017-07-25 22:29:16,365 Epoch[34] Batch [930]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.110767,	
2017-07-25 22:29:20,329 Epoch[34] Batch [940]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.110802,	
2017-07-25 22:29:24,239 Epoch[34] Batch [950]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.110761,	
2017-07-25 22:29:28,315 Epoch[34] Batch [960]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.110573,	
2017-07-25 22:29:32,228 Epoch[34] Batch [970]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.110489,	
2017-07-25 22:29:36,294 Epoch[34] Batch [980]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.110526,	
2017-07-25 22:29:40,229 Epoch[34] Batch [990]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.110488,	
2017-07-25 22:29:44,290 Epoch[34] Batch [1000]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.110526,	
2017-07-25 22:29:48,388 Epoch[34] Batch [1010]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.110444,	
2017-07-25 22:29:52,424 Epoch[34] Batch [1020]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.110509,	
2017-07-25 22:29:56,480 Epoch[34] Batch [1030]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110644,	
2017-07-25 22:30:00,391 Epoch[34] Batch [1040]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.110675,	
2017-07-25 22:30:04,226 Epoch[34] Batch [1050]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.110709,	
2017-07-25 22:30:08,343 Epoch[34] Batch [1060]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110672,	
2017-07-25 22:30:12,297 Epoch[34] Batch [1070]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.110530,	
2017-07-25 22:30:16,151 Epoch[34] Batch [1080]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.110575,	
2017-07-25 22:30:19,995 Epoch[34] Batch [1090]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.110527,	
2017-07-25 22:30:23,920 Epoch[34] Batch [1100]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.110561,	
2017-07-25 22:30:27,755 Epoch[34] Batch [1110]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.110475,	
2017-07-25 22:30:31,728 Epoch[34] Batch [1120]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.110388,	
2017-07-25 22:30:35,613 Epoch[34] Batch [1130]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.110373,	
2017-07-25 22:30:39,599 Epoch[34] Batch [1140]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110326,	
2017-07-25 22:30:43,535 Epoch[34] Batch [1150]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.110174,	
2017-07-25 22:30:47,523 Epoch[34] Batch [1160]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.110078,	
2017-07-25 22:30:51,556 Epoch[34] Batch [1170]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110034,	
2017-07-25 22:30:55,509 Epoch[34] Batch [1180]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.109955,	
2017-07-25 22:30:59,486 Epoch[34] Batch [1190]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.109878,	
2017-07-25 22:31:03,544 Epoch[34] Batch [1200]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.109886,	
2017-07-25 22:31:07,719 Epoch[34] Batch [1210]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109837,	
2017-07-25 22:31:11,546 Epoch[34] Batch [1220]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.109868,	
2017-07-25 22:31:15,484 Epoch[34] Batch [1230]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.109824,	
2017-07-25 22:31:19,446 Epoch[34] Batch [1240]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.109897,	
2017-07-25 22:31:23,348 Epoch[34] Batch [1250]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.109900,	
2017-07-25 22:31:27,400 Epoch[34] Batch [1260]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.110024,	
2017-07-25 22:31:31,398 Epoch[34] Batch [1270]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110002,	
2017-07-25 22:31:35,378 Epoch[34] Batch [1280]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.109911,	
2017-07-25 22:31:39,274 Epoch[34] Batch [1290]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.109895,	
2017-07-25 22:31:43,196 Epoch[34] Batch [1300]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.109955,	
2017-07-25 22:31:47,212 Epoch[34] Batch [1310]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.109951,	
2017-07-25 22:31:51,092 Epoch[34] Batch [1320]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.109964,	
2017-07-25 22:31:55,083 Epoch[34] Batch [1330]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.109935,	
2017-07-25 22:31:59,087 Epoch[34] Batch [1340]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.109907,	
2017-07-25 22:32:03,102 Epoch[34] Batch [1350]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110017,	
2017-07-25 22:32:07,126 Epoch[34] Batch [1360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.109988,	
2017-07-25 22:32:11,096 Epoch[34] Batch [1370]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.109934,	
2017-07-25 22:32:15,140 Epoch[34] Batch [1380]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109943,	
2017-07-25 22:32:19,208 Epoch[34] Batch [1390]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.109969,	
2017-07-25 22:32:23,197 Epoch[34] Batch [1400]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.109900,	
2017-07-25 22:32:27,102 Epoch[34] Batch [1410]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.109847,	
2017-07-25 22:32:31,045 Epoch[34] Batch [1420]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.109890,	
2017-07-25 22:32:35,011 Epoch[34] Batch [1430]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.110051,	
2017-07-25 22:32:39,067 Epoch[34] Batch [1440]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.110135,	
2017-07-25 22:32:42,979 Epoch[34] Batch [1450]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.110305,	
2017-07-25 22:32:47,019 Epoch[34] Batch [1460]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.110359,	
2017-07-25 22:32:50,916 Epoch[34] Batch [1470]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.110338,	
2017-07-25 22:32:54,855 Epoch[34] Batch [1480]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.110270,	
2017-07-25 22:32:57,230 Epoch[34] Train-FCNLogLoss=0.110303
2017-07-25 22:32:57,230 Epoch[34] Time cost=593.328
2017-07-25 22:32:57,948 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.params"
2017-07-25 22:33:00,718 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0035.states"
2017-07-25 22:33:05,240 Epoch[35] Batch [10]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.112505,	
2017-07-25 22:33:09,225 Epoch[35] Batch [20]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.108827,	
2017-07-25 22:33:13,229 Epoch[35] Batch [30]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.103450,	
2017-07-25 22:33:17,081 Epoch[35] Batch [40]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.102152,	
2017-07-25 22:33:21,099 Epoch[35] Batch [50]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.103581,	
2017-07-25 22:33:25,173 Epoch[35] Batch [60]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.104287,	
2017-07-25 22:33:29,292 Epoch[35] Batch [70]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105204,	
2017-07-25 22:33:33,275 Epoch[35] Batch [80]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.105445,	
2017-07-25 22:33:37,252 Epoch[35] Batch [90]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.105205,	
2017-07-25 22:33:41,156 Epoch[35] Batch [100]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.105068,	
2017-07-25 22:33:45,116 Epoch[35] Batch [110]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.105083,	
2017-07-25 22:33:49,121 Epoch[35] Batch [120]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.106511,	
2017-07-25 22:33:52,967 Epoch[35] Batch [130]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.106046,	
2017-07-25 22:33:56,808 Epoch[35] Batch [140]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.105267,	
2017-07-25 22:34:00,859 Epoch[35] Batch [150]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106002,	
2017-07-25 22:34:04,804 Epoch[35] Batch [160]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.105651,	
2017-07-25 22:34:08,809 Epoch[35] Batch [170]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.105852,	
2017-07-25 22:34:12,743 Epoch[35] Batch [180]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.105597,	
2017-07-25 22:34:16,847 Epoch[35] Batch [190]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104852,	
2017-07-25 22:34:20,806 Epoch[35] Batch [200]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.104428,	
2017-07-25 22:34:24,838 Epoch[35] Batch [210]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.104741,	
2017-07-25 22:34:28,555 Epoch[35] Batch [220]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.104372,	
2017-07-25 22:34:32,484 Epoch[35] Batch [230]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105087,	
2017-07-25 22:34:36,332 Epoch[35] Batch [240]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.105291,	
2017-07-25 22:34:40,308 Epoch[35] Batch [250]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.105950,	
2017-07-25 22:34:44,510 Epoch[35] Batch [260]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.105911,	
2017-07-25 22:34:48,569 Epoch[35] Batch [270]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.105682,	
2017-07-25 22:34:52,495 Epoch[35] Batch [280]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.105898,	
2017-07-25 22:34:56,330 Epoch[35] Batch [290]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.106122,	
2017-07-25 22:35:00,421 Epoch[35] Batch [300]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.106423,	
2017-07-25 22:35:04,473 Epoch[35] Batch [310]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.106352,	
2017-07-25 22:35:08,379 Epoch[35] Batch [320]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.106364,	
2017-07-25 22:35:12,407 Epoch[35] Batch [330]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.106761,	
2017-07-25 22:35:16,461 Epoch[35] Batch [340]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.107001,	
2017-07-25 22:35:20,330 Epoch[35] Batch [350]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.107021,	
2017-07-25 22:35:24,355 Epoch[35] Batch [360]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.107005,	
2017-07-25 22:35:28,389 Epoch[35] Batch [370]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.107004,	
2017-07-25 22:35:32,402 Epoch[35] Batch [380]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.106734,	
2017-07-25 22:35:36,357 Epoch[35] Batch [390]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.106452,	
2017-07-25 22:35:40,472 Epoch[35] Batch [400]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.106473,	
2017-07-25 22:35:44,431 Epoch[35] Batch [410]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.106488,	
2017-07-25 22:35:48,431 Epoch[35] Batch [420]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.106407,	
2017-07-25 22:35:52,420 Epoch[35] Batch [430]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.106281,	
2017-07-25 22:35:56,460 Epoch[35] Batch [440]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.106694,	
2017-07-25 22:36:00,356 Epoch[35] Batch [450]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.107235,	
2017-07-25 22:36:04,330 Epoch[35] Batch [460]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.107544,	
2017-07-25 22:36:08,344 Epoch[35] Batch [470]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.107656,	
2017-07-25 22:36:12,167 Epoch[35] Batch [480]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.107822,	
2017-07-25 22:36:16,165 Epoch[35] Batch [490]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.107667,	
2017-07-25 22:36:20,024 Epoch[35] Batch [500]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.107924,	
2017-07-25 22:36:23,973 Epoch[35] Batch [510]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.108093,	
2017-07-25 22:36:28,062 Epoch[35] Batch [520]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.108253,	
2017-07-25 22:36:31,956 Epoch[35] Batch [530]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.108094,	
2017-07-25 22:36:35,955 Epoch[35] Batch [540]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.108007,	
2017-07-25 22:36:39,924 Epoch[35] Batch [550]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.107935,	
2017-07-25 22:36:43,851 Epoch[35] Batch [560]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.108002,	
2017-07-25 22:36:47,844 Epoch[35] Batch [570]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.107797,	
2017-07-25 22:36:51,777 Epoch[35] Batch [580]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.107749,	
2017-07-25 22:36:55,744 Epoch[35] Batch [590]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.107954,	
2017-07-25 22:36:59,670 Epoch[35] Batch [600]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.107953,	
2017-07-25 22:37:03,746 Epoch[35] Batch [610]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.107966,	
2017-07-25 22:37:07,712 Epoch[35] Batch [620]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.107937,	
2017-07-25 22:37:11,799 Epoch[35] Batch [630]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.107945,	
2017-07-25 22:37:15,717 Epoch[35] Batch [640]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.107863,	
2017-07-25 22:37:19,657 Epoch[35] Batch [650]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.107832,	
2017-07-25 22:37:23,645 Epoch[35] Batch [660]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.107742,	
2017-07-25 22:37:27,689 Epoch[35] Batch [670]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.107589,	
2017-07-25 22:37:31,553 Epoch[35] Batch [680]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.107711,	
2017-07-25 22:37:35,448 Epoch[35] Batch [690]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.107681,	
2017-07-25 22:37:39,360 Epoch[35] Batch [700]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.107673,	
2017-07-25 22:37:43,254 Epoch[35] Batch [710]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.107798,	
2017-07-25 22:37:47,196 Epoch[35] Batch [720]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.107837,	
2017-07-25 22:37:51,134 Epoch[35] Batch [730]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.107800,	
2017-07-25 22:37:55,101 Epoch[35] Batch [740]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.107771,	
2017-07-25 22:37:58,969 Epoch[35] Batch [750]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.108063,	
2017-07-25 22:38:02,952 Epoch[35] Batch [760]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.108165,	
2017-07-25 22:38:06,996 Epoch[35] Batch [770]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.108492,	
2017-07-25 22:38:10,878 Epoch[35] Batch [780]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.108739,	
2017-07-25 22:38:14,933 Epoch[35] Batch [790]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108794,	
2017-07-25 22:38:18,936 Epoch[35] Batch [800]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.109142,	
2017-07-25 22:38:23,012 Epoch[35] Batch [810]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109201,	
2017-07-25 22:38:27,052 Epoch[35] Batch [820]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109287,	
2017-07-25 22:38:31,036 Epoch[35] Batch [830]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.109489,	
2017-07-25 22:38:35,123 Epoch[35] Batch [840]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.109940,	
2017-07-25 22:38:39,117 Epoch[35] Batch [850]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110216,	
2017-07-25 22:38:43,048 Epoch[35] Batch [860]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110327,	
2017-07-25 22:38:47,038 Epoch[35] Batch [870]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.110488,	
2017-07-25 22:38:50,988 Epoch[35] Batch [880]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.110366,	
2017-07-25 22:38:55,009 Epoch[35] Batch [890]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110273,	
2017-07-25 22:38:59,015 Epoch[35] Batch [900]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.110384,	
2017-07-25 22:39:02,966 Epoch[35] Batch [910]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.110424,	
2017-07-25 22:39:06,958 Epoch[35] Batch [920]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110357,	
2017-07-25 22:39:10,875 Epoch[35] Batch [930]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.110249,	
2017-07-25 22:39:14,871 Epoch[35] Batch [940]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.110256,	
2017-07-25 22:39:18,889 Epoch[35] Batch [950]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110446,	
2017-07-25 22:39:22,859 Epoch[35] Batch [960]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.110475,	
2017-07-25 22:39:26,905 Epoch[35] Batch [970]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.110304,	
2017-07-25 22:39:30,880 Epoch[35] Batch [980]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.110232,	
2017-07-25 22:39:34,917 Epoch[35] Batch [990]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.110319,	
2017-07-25 22:39:38,908 Epoch[35] Batch [1000]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110391,	
2017-07-25 22:39:42,927 Epoch[35] Batch [1010]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.110447,	
2017-07-25 22:39:46,930 Epoch[35] Batch [1020]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.110326,	
2017-07-25 22:39:51,058 Epoch[35] Batch [1030]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.110372,	
2017-07-25 22:39:54,968 Epoch[35] Batch [1040]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.111238,	
2017-07-25 22:39:58,918 Epoch[35] Batch [1050]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.111836,	
2017-07-25 22:40:02,902 Epoch[35] Batch [1060]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.112433,	
2017-07-25 22:40:06,995 Epoch[35] Batch [1070]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.112658,	
2017-07-25 22:40:10,843 Epoch[35] Batch [1080]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.112798,	
2017-07-25 22:40:14,738 Epoch[35] Batch [1090]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.112902,	
2017-07-25 22:40:18,656 Epoch[35] Batch [1100]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.112995,	
2017-07-25 22:40:22,664 Epoch[35] Batch [1110]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.113036,	
2017-07-25 22:40:26,576 Epoch[35] Batch [1120]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.113071,	
2017-07-25 22:40:30,578 Epoch[35] Batch [1130]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.113150,	
2017-07-25 22:40:34,568 Epoch[35] Batch [1140]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.113169,	
2017-07-25 22:40:38,627 Epoch[35] Batch [1150]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113174,	
2017-07-25 22:40:42,692 Epoch[35] Batch [1160]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113329,	
2017-07-25 22:40:46,639 Epoch[35] Batch [1170]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.113352,	
2017-07-25 22:40:50,643 Epoch[35] Batch [1180]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.113287,	
2017-07-25 22:40:54,662 Epoch[35] Batch [1190]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113386,	
2017-07-25 22:40:58,593 Epoch[35] Batch [1200]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.113473,	
2017-07-25 22:41:02,448 Epoch[35] Batch [1210]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.113509,	
2017-07-25 22:41:06,383 Epoch[35] Batch [1220]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.113649,	
2017-07-25 22:41:10,521 Epoch[35] Batch [1230]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113709,	
2017-07-25 22:41:14,558 Epoch[35] Batch [1240]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113535,	
2017-07-25 22:41:18,570 Epoch[35] Batch [1250]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.113500,	
2017-07-25 22:41:22,673 Epoch[35] Batch [1260]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.113567,	
2017-07-25 22:41:26,689 Epoch[35] Batch [1270]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.113564,	
2017-07-25 22:41:30,673 Epoch[35] Batch [1280]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.113498,	
2017-07-25 22:41:34,636 Epoch[35] Batch [1290]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.113403,	
2017-07-25 22:41:38,678 Epoch[35] Batch [1300]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113732,	
2017-07-25 22:41:42,821 Epoch[35] Batch [1310]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.113766,	
2017-07-25 22:41:46,792 Epoch[35] Batch [1320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.113772,	
2017-07-25 22:41:50,796 Epoch[35] Batch [1330]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.113736,	
2017-07-25 22:41:54,817 Epoch[35] Batch [1340]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.113746,	
2017-07-25 22:41:58,750 Epoch[35] Batch [1350]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.113731,	
2017-07-25 22:42:02,747 Epoch[35] Batch [1360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.113666,	
2017-07-25 22:42:06,824 Epoch[35] Batch [1370]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113826,	
2017-07-25 22:42:10,763 Epoch[35] Batch [1380]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.113918,	
2017-07-25 22:42:14,830 Epoch[35] Batch [1390]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113840,	
2017-07-25 22:42:18,799 Epoch[35] Batch [1400]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.113772,	
2017-07-25 22:42:22,650 Epoch[35] Batch [1410]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.113664,	
2017-07-25 22:42:26,639 Epoch[35] Batch [1420]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.113600,	
2017-07-25 22:42:30,676 Epoch[35] Batch [1430]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.113709,	
2017-07-25 22:42:34,715 Epoch[35] Batch [1440]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.113702,	
2017-07-25 22:42:38,744 Epoch[35] Batch [1450]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.113801,	
2017-07-25 22:42:42,652 Epoch[35] Batch [1460]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.113780,	
2017-07-25 22:42:46,710 Epoch[35] Batch [1470]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.113782,	
2017-07-25 22:42:50,744 Epoch[35] Batch [1480]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.113819,	
2017-07-25 22:42:53,121 Epoch[35] Train-FCNLogLoss=0.113816
2017-07-25 22:42:53,121 Epoch[35] Time cost=592.403
2017-07-25 22:42:53,942 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.params"
2017-07-25 22:42:57,211 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0036.states"
2017-07-25 22:43:01,876 Epoch[36] Batch [10]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.098931,	
2017-07-25 22:43:05,708 Epoch[36] Batch [20]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.110131,	
2017-07-25 22:43:09,738 Epoch[36] Batch [30]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110398,	
2017-07-25 22:43:13,767 Epoch[36] Batch [40]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110134,	
2017-07-25 22:43:17,767 Epoch[36] Batch [50]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109232,	
2017-07-25 22:43:21,667 Epoch[36] Batch [60]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.108555,	
2017-07-25 22:43:25,583 Epoch[36] Batch [70]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.108013,	
2017-07-25 22:43:29,536 Epoch[36] Batch [80]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.106218,	
2017-07-25 22:43:33,450 Epoch[36] Batch [90]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.106407,	
2017-07-25 22:43:37,396 Epoch[36] Batch [100]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.107763,	
2017-07-25 22:43:41,359 Epoch[36] Batch [110]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.107801,	
2017-07-25 22:43:45,269 Epoch[36] Batch [120]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.109103,	
2017-07-25 22:43:49,238 Epoch[36] Batch [130]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.108823,	
2017-07-25 22:43:53,328 Epoch[36] Batch [140]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.109696,	
2017-07-25 22:43:57,654 Epoch[36] Batch [150]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.109447,	
2017-07-25 22:44:01,735 Epoch[36] Batch [160]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.109494,	
2017-07-25 22:44:05,892 Epoch[36] Batch [170]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.110462,	
2017-07-25 22:44:09,886 Epoch[36] Batch [180]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110132,	
2017-07-25 22:44:13,836 Epoch[36] Batch [190]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.109913,	
2017-07-25 22:44:17,922 Epoch[36] Batch [200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.110682,	
2017-07-25 22:44:21,897 Epoch[36] Batch [210]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.110494,	
2017-07-25 22:44:26,324 Epoch[36] Batch [220]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.110215,	
2017-07-25 22:44:30,644 Epoch[36] Batch [230]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110034,	
2017-07-25 22:44:34,589 Epoch[36] Batch [240]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.110229,	
2017-07-25 22:44:38,548 Epoch[36] Batch [250]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.110575,	
2017-07-25 22:44:42,532 Epoch[36] Batch [260]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110643,	
2017-07-25 22:44:46,614 Epoch[36] Batch [270]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.110306,	
2017-07-25 22:44:50,935 Epoch[36] Batch [280]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.110373,	
2017-07-25 22:44:55,125 Epoch[36] Batch [290]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.110277,	
2017-07-25 22:44:59,085 Epoch[36] Batch [300]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.109954,	
2017-07-25 22:45:03,138 Epoch[36] Batch [310]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.109633,	
2017-07-25 22:45:07,106 Epoch[36] Batch [320]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.109544,	
2017-07-25 22:45:10,932 Epoch[36] Batch [330]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.109104,	
2017-07-25 22:45:14,868 Epoch[36] Batch [340]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.108776,	
2017-07-25 22:45:18,850 Epoch[36] Batch [350]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.109132,	
2017-07-25 22:45:22,827 Epoch[36] Batch [360]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.108881,	
2017-07-25 22:45:26,900 Epoch[36] Batch [370]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.109048,	
2017-07-25 22:45:30,881 Epoch[36] Batch [380]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.109158,	
2017-07-25 22:45:34,741 Epoch[36] Batch [390]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.108710,	
2017-07-25 22:45:38,767 Epoch[36] Batch [400]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.108651,	
2017-07-25 22:45:42,735 Epoch[36] Batch [410]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.108607,	
2017-07-25 22:45:47,103 Epoch[36] Batch [420]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.108445,	
2017-07-25 22:45:51,128 Epoch[36] Batch [430]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.108738,	
2017-07-25 22:45:55,158 Epoch[36] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108484,	
2017-07-25 22:45:59,190 Epoch[36] Batch [450]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.108421,	
2017-07-25 22:46:03,292 Epoch[36] Batch [460]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.108474,	
2017-07-25 22:46:07,197 Epoch[36] Batch [470]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.108612,	
2017-07-25 22:46:11,044 Epoch[36] Batch [480]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.108653,	
2017-07-25 22:46:14,997 Epoch[36] Batch [490]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.108525,	
2017-07-25 22:46:18,919 Epoch[36] Batch [500]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.108365,	
2017-07-25 22:46:22,882 Epoch[36] Batch [510]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.108444,	
2017-07-25 22:46:26,796 Epoch[36] Batch [520]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.108409,	
2017-07-25 22:46:30,736 Epoch[36] Batch [530]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.108480,	
2017-07-25 22:46:34,698 Epoch[36] Batch [540]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.108426,	
2017-07-25 22:46:38,662 Epoch[36] Batch [550]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.108812,	
2017-07-25 22:46:42,642 Epoch[36] Batch [560]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.108711,	
2017-07-25 22:46:46,629 Epoch[36] Batch [570]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.108582,	
2017-07-25 22:46:50,548 Epoch[36] Batch [580]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.108562,	
2017-07-25 22:46:54,468 Epoch[36] Batch [590]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.108651,	
2017-07-25 22:46:58,524 Epoch[36] Batch [600]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.108756,	
2017-07-25 22:47:02,524 Epoch[36] Batch [610]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.108814,	
2017-07-25 22:47:06,552 Epoch[36] Batch [620]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.108897,	
2017-07-25 22:47:10,621 Epoch[36] Batch [630]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.108733,	
2017-07-25 22:47:14,591 Epoch[36] Batch [640]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.108762,	
2017-07-25 22:47:18,728 Epoch[36] Batch [650]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.108732,	
2017-07-25 22:47:22,638 Epoch[36] Batch [660]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.108491,	
2017-07-25 22:47:26,887 Epoch[36] Batch [670]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.108487,	
2017-07-25 22:47:30,819 Epoch[36] Batch [680]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.108479,	
2017-07-25 22:47:35,164 Epoch[36] Batch [690]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108525,	
2017-07-25 22:47:39,318 Epoch[36] Batch [700]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.108451,	
2017-07-25 22:47:43,283 Epoch[36] Batch [710]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.108272,	
2017-07-25 22:47:47,282 Epoch[36] Batch [720]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.108174,	
2017-07-25 22:47:51,293 Epoch[36] Batch [730]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.108019,	
2017-07-25 22:47:55,085 Epoch[36] Batch [740]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.108211,	
2017-07-25 22:47:59,097 Epoch[36] Batch [750]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.108092,	
2017-07-25 22:48:02,998 Epoch[36] Batch [760]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.108199,	
2017-07-25 22:48:06,954 Epoch[36] Batch [770]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.108428,	
2017-07-25 22:48:11,154 Epoch[36] Batch [780]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.108282,	
2017-07-25 22:48:15,081 Epoch[36] Batch [790]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.108460,	
2017-07-25 22:48:19,256 Epoch[36] Batch [800]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.108699,	
2017-07-25 22:48:23,437 Epoch[36] Batch [810]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.108899,	
2017-07-25 22:48:27,623 Epoch[36] Batch [820]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.108830,	
2017-07-25 22:48:31,937 Epoch[36] Batch [830]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.109091,	
2017-07-25 22:48:35,874 Epoch[36] Batch [840]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.109120,	
2017-07-25 22:48:40,009 Epoch[36] Batch [850]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.109218,	
2017-07-25 22:48:44,018 Epoch[36] Batch [860]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109308,	
2017-07-25 22:48:48,333 Epoch[36] Batch [870]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.109408,	
2017-07-25 22:48:52,494 Epoch[36] Batch [880]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.109413,	
2017-07-25 22:48:56,299 Epoch[36] Batch [890]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.109454,	
2017-07-25 22:49:00,352 Epoch[36] Batch [900]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.109561,	
2017-07-25 22:49:04,434 Epoch[36] Batch [910]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.109639,	
2017-07-25 22:49:08,439 Epoch[36] Batch [920]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.110108,	
2017-07-25 22:49:12,577 Epoch[36] Batch [930]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.110595,	
2017-07-25 22:49:16,593 Epoch[36] Batch [940]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110642,	
2017-07-25 22:49:20,646 Epoch[36] Batch [950]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.111105,	
2017-07-25 22:49:24,633 Epoch[36] Batch [960]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.111442,	
2017-07-25 22:49:28,675 Epoch[36] Batch [970]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111642,	
2017-07-25 22:49:32,688 Epoch[36] Batch [980]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111606,	
2017-07-25 22:49:36,728 Epoch[36] Batch [990]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111685,	
2017-07-25 22:49:40,593 Epoch[36] Batch [1000]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.111886,	
2017-07-25 22:49:44,755 Epoch[36] Batch [1010]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.112019,	
2017-07-25 22:49:48,657 Epoch[36] Batch [1020]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.112135,	
2017-07-25 22:49:52,753 Epoch[36] Batch [1030]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.112208,	
2017-07-25 22:49:56,780 Epoch[36] Batch [1040]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112207,	
2017-07-25 22:50:00,836 Epoch[36] Batch [1050]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.112171,	
2017-07-25 22:50:04,863 Epoch[36] Batch [1060]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.112193,	
2017-07-25 22:50:08,932 Epoch[36] Batch [1070]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.112157,	
2017-07-25 22:50:13,209 Epoch[36] Batch [1080]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.112218,	
2017-07-25 22:50:17,467 Epoch[36] Batch [1090]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.112131,	
2017-07-25 22:50:21,478 Epoch[36] Batch [1100]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.112142,	
2017-07-25 22:50:25,521 Epoch[36] Batch [1110]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.112329,	
2017-07-25 22:50:29,597 Epoch[36] Batch [1120]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.112166,	
2017-07-25 22:50:33,747 Epoch[36] Batch [1130]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.112098,	
2017-07-25 22:50:37,688 Epoch[36] Batch [1140]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111967,	
2017-07-25 22:50:41,816 Epoch[36] Batch [1150]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112035,	
2017-07-25 22:50:45,793 Epoch[36] Batch [1160]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.112076,	
2017-07-25 22:50:49,762 Epoch[36] Batch [1170]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.112051,	
2017-07-25 22:50:53,758 Epoch[36] Batch [1180]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.112044,	
2017-07-25 22:50:57,686 Epoch[36] Batch [1190]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.111969,	
2017-07-25 22:51:01,853 Epoch[36] Batch [1200]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.111999,	
2017-07-25 22:51:06,032 Epoch[36] Batch [1210]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.111989,	
2017-07-25 22:51:10,636 Epoch[36] Batch [1220]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.111855,	
2017-07-25 22:51:14,885 Epoch[36] Batch [1230]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.111853,	
2017-07-25 22:51:18,917 Epoch[36] Batch [1240]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.111817,	
2017-07-25 22:51:22,772 Epoch[36] Batch [1250]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.111716,	
2017-07-25 22:51:26,749 Epoch[36] Batch [1260]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.111687,	
2017-07-25 22:51:30,708 Epoch[36] Batch [1270]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.111580,	
2017-07-25 22:51:34,736 Epoch[36] Batch [1280]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111549,	
2017-07-25 22:51:38,648 Epoch[36] Batch [1290]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.111504,	
2017-07-25 22:51:42,609 Epoch[36] Batch [1300]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.111437,	
2017-07-25 22:51:46,527 Epoch[36] Batch [1310]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111477,	
2017-07-25 22:51:50,596 Epoch[36] Batch [1320]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.111381,	
2017-07-25 22:51:54,544 Epoch[36] Batch [1330]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.111435,	
2017-07-25 22:51:58,546 Epoch[36] Batch [1340]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.111401,	
2017-07-25 22:52:02,436 Epoch[36] Batch [1350]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.111308,	
2017-07-25 22:52:06,487 Epoch[36] Batch [1360]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.111222,	
2017-07-25 22:52:10,393 Epoch[36] Batch [1370]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.111193,	
2017-07-25 22:52:14,410 Epoch[36] Batch [1380]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.111269,	
2017-07-25 22:52:18,324 Epoch[36] Batch [1390]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.111211,	
2017-07-25 22:52:22,264 Epoch[36] Batch [1400]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.111333,	
2017-07-25 22:52:26,172 Epoch[36] Batch [1410]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.111289,	
2017-07-25 22:52:30,214 Epoch[36] Batch [1420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.111270,	
2017-07-25 22:52:34,132 Epoch[36] Batch [1430]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.111354,	
2017-07-25 22:52:38,145 Epoch[36] Batch [1440]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111383,	
2017-07-25 22:52:42,022 Epoch[36] Batch [1450]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.111302,	
2017-07-25 22:52:46,036 Epoch[36] Batch [1460]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.111330,	
2017-07-25 22:52:49,994 Epoch[36] Batch [1470]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.111307,	
2017-07-25 22:52:53,848 Epoch[36] Batch [1480]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.111248,	
2017-07-25 22:52:56,233 Epoch[36] Train-FCNLogLoss=0.111296
2017-07-25 22:52:56,233 Epoch[36] Time cost=599.021
2017-07-25 22:52:57,017 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.params"
2017-07-25 22:53:00,140 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0037.states"
2017-07-25 22:53:04,820 Epoch[37] Batch [10]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.104135,	
2017-07-25 22:53:08,726 Epoch[37] Batch [20]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.103006,	
2017-07-25 22:53:12,705 Epoch[37] Batch [30]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.106330,	
2017-07-25 22:53:16,613 Epoch[37] Batch [40]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.104629,	
2017-07-25 22:53:20,648 Epoch[37] Batch [50]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.105107,	
2017-07-25 22:53:24,569 Epoch[37] Batch [60]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.105347,	
2017-07-25 22:53:28,641 Epoch[37] Batch [70]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.106171,	
2017-07-25 22:53:32,669 Epoch[37] Batch [80]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107086,	
2017-07-25 22:53:36,503 Epoch[37] Batch [90]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.107939,	
2017-07-25 22:53:40,448 Epoch[37] Batch [100]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.107273,	
2017-07-25 22:53:44,551 Epoch[37] Batch [110]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.106189,	
2017-07-25 22:53:48,547 Epoch[37] Batch [120]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.107109,	
2017-07-25 22:53:52,402 Epoch[37] Batch [130]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.108339,	
2017-07-25 22:53:56,424 Epoch[37] Batch [140]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.107767,	
2017-07-25 22:54:00,434 Epoch[37] Batch [150]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.108448,	
2017-07-25 22:54:04,410 Epoch[37] Batch [160]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.108319,	
2017-07-25 22:54:08,414 Epoch[37] Batch [170]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.107603,	
2017-07-25 22:54:12,244 Epoch[37] Batch [180]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.107683,	
2017-07-25 22:54:16,254 Epoch[37] Batch [190]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.107357,	
2017-07-25 22:54:20,223 Epoch[37] Batch [200]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.106811,	
2017-07-25 22:54:24,210 Epoch[37] Batch [210]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.106679,	
2017-07-25 22:54:28,280 Epoch[37] Batch [220]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106791,	
2017-07-25 22:54:32,323 Epoch[37] Batch [230]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.106876,	
2017-07-25 22:54:36,315 Epoch[37] Batch [240]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.106824,	
2017-07-25 22:54:40,287 Epoch[37] Batch [250]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.106545,	
2017-07-25 22:54:44,274 Epoch[37] Batch [260]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.106358,	
2017-07-25 22:54:48,222 Epoch[37] Batch [270]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.106283,	
2017-07-25 22:54:52,284 Epoch[37] Batch [280]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.105973,	
2017-07-25 22:54:56,335 Epoch[37] Batch [290]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105841,	
2017-07-25 22:55:00,336 Epoch[37] Batch [300]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.106000,	
2017-07-25 22:55:04,392 Epoch[37] Batch [310]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.105818,	
2017-07-25 22:55:08,218 Epoch[37] Batch [320]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.105326,	
2017-07-25 22:55:12,166 Epoch[37] Batch [330]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105283,	
2017-07-25 22:55:16,183 Epoch[37] Batch [340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105091,	
2017-07-25 22:55:20,252 Epoch[37] Batch [350]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105304,	
2017-07-25 22:55:24,210 Epoch[37] Batch [360]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.105714,	
2017-07-25 22:55:28,244 Epoch[37] Batch [370]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105515,	
2017-07-25 22:55:32,325 Epoch[37] Batch [380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.105631,	
2017-07-25 22:55:36,264 Epoch[37] Batch [390]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.105351,	
2017-07-25 22:55:40,234 Epoch[37] Batch [400]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.105925,	
2017-07-25 22:55:44,177 Epoch[37] Batch [410]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.105650,	
2017-07-25 22:55:48,078 Epoch[37] Batch [420]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.105669,	
2017-07-25 22:55:52,005 Epoch[37] Batch [430]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.105741,	
2017-07-25 22:55:55,975 Epoch[37] Batch [440]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.105793,	
2017-07-25 22:56:00,137 Epoch[37] Batch [450]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.105984,	
2017-07-25 22:56:04,167 Epoch[37] Batch [460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.106280,	
2017-07-25 22:56:08,146 Epoch[37] Batch [470]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.106017,	
2017-07-25 22:56:12,191 Epoch[37] Batch [480]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.106202,	
2017-07-25 22:56:16,290 Epoch[37] Batch [490]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.106448,	
2017-07-25 22:56:20,168 Epoch[37] Batch [500]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.106367,	
2017-07-25 22:56:24,170 Epoch[37] Batch [510]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.106334,	
2017-07-25 22:56:28,178 Epoch[37] Batch [520]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.106395,	
2017-07-25 22:56:32,017 Epoch[37] Batch [530]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.106330,	
2017-07-25 22:56:36,048 Epoch[37] Batch [540]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.106269,	
2017-07-25 22:56:39,892 Epoch[37] Batch [550]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.106324,	
2017-07-25 22:56:43,749 Epoch[37] Batch [560]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.106170,	
2017-07-25 22:56:47,645 Epoch[37] Batch [570]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.106142,	
2017-07-25 22:56:51,590 Epoch[37] Batch [580]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.106018,	
2017-07-25 22:56:55,527 Epoch[37] Batch [590]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.106016,	
2017-07-25 22:56:59,427 Epoch[37] Batch [600]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.106158,	
2017-07-25 22:57:03,359 Epoch[37] Batch [610]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.106298,	
2017-07-25 22:57:07,257 Epoch[37] Batch [620]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.106388,	
2017-07-25 22:57:11,255 Epoch[37] Batch [630]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.106395,	
2017-07-25 22:57:15,200 Epoch[37] Batch [640]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.106451,	
2017-07-25 22:57:19,208 Epoch[37] Batch [650]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.106500,	
2017-07-25 22:57:23,220 Epoch[37] Batch [660]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.106499,	
2017-07-25 22:57:27,142 Epoch[37] Batch [670]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.106448,	
2017-07-25 22:57:31,154 Epoch[37] Batch [680]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.106505,	
2017-07-25 22:57:35,220 Epoch[37] Batch [690]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.106387,	
2017-07-25 22:57:39,134 Epoch[37] Batch [700]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.106437,	
2017-07-25 22:57:43,090 Epoch[37] Batch [710]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.106185,	
2017-07-25 22:57:47,069 Epoch[37] Batch [720]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.106249,	
2017-07-25 22:57:50,934 Epoch[37] Batch [730]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.106203,	
2017-07-25 22:57:54,941 Epoch[37] Batch [740]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.106339,	
2017-07-25 22:57:59,022 Epoch[37] Batch [750]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.106319,	
2017-07-25 22:58:03,049 Epoch[37] Batch [760]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.106252,	
2017-07-25 22:58:07,039 Epoch[37] Batch [770]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.106405,	
2017-07-25 22:58:10,920 Epoch[37] Batch [780]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.106349,	
2017-07-25 22:58:14,888 Epoch[37] Batch [790]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.106264,	
2017-07-25 22:58:18,884 Epoch[37] Batch [800]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.106263,	
2017-07-25 22:58:22,786 Epoch[37] Batch [810]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.106248,	
2017-07-25 22:58:26,805 Epoch[37] Batch [820]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.106387,	
2017-07-25 22:58:30,829 Epoch[37] Batch [830]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.106282,	
2017-07-25 22:58:34,763 Epoch[37] Batch [840]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.106037,	
2017-07-25 22:58:38,892 Epoch[37] Batch [850]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.105988,	
2017-07-25 22:58:43,080 Epoch[37] Batch [860]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.105949,	
2017-07-25 22:58:46,968 Epoch[37] Batch [870]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.105857,	
2017-07-25 22:58:50,894 Epoch[37] Batch [880]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.106045,	
2017-07-25 22:58:55,102 Epoch[37] Batch [890]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.105962,	
2017-07-25 22:58:59,233 Epoch[37] Batch [900]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.106011,	
2017-07-25 22:59:03,320 Epoch[37] Batch [910]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.106016,	
2017-07-25 22:59:07,283 Epoch[37] Batch [920]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.105989,	
2017-07-25 22:59:11,339 Epoch[37] Batch [930]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.105891,	
2017-07-25 22:59:15,402 Epoch[37] Batch [940]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.105898,	
2017-07-25 22:59:19,247 Epoch[37] Batch [950]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.105890,	
2017-07-25 22:59:23,318 Epoch[37] Batch [960]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105777,	
2017-07-25 22:59:27,338 Epoch[37] Batch [970]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.105946,	
2017-07-25 22:59:31,376 Epoch[37] Batch [980]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.106019,	
2017-07-25 22:59:35,446 Epoch[37] Batch [990]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.106038,	
2017-07-25 22:59:39,445 Epoch[37] Batch [1000]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105960,	
2017-07-25 22:59:43,494 Epoch[37] Batch [1010]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.106130,	
2017-07-25 22:59:47,420 Epoch[37] Batch [1020]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.106109,	
2017-07-25 22:59:51,306 Epoch[37] Batch [1030]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.106218,	
2017-07-25 22:59:55,298 Epoch[37] Batch [1040]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.106238,	
2017-07-25 22:59:59,240 Epoch[37] Batch [1050]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.106265,	
2017-07-25 23:00:03,143 Epoch[37] Batch [1060]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.106364,	
2017-07-25 23:00:07,178 Epoch[37] Batch [1070]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.106218,	
2017-07-25 23:00:11,154 Epoch[37] Batch [1080]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.106050,	
2017-07-25 23:00:15,052 Epoch[37] Batch [1090]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.105929,	
2017-07-25 23:00:18,981 Epoch[37] Batch [1100]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105928,	
2017-07-25 23:00:22,981 Epoch[37] Batch [1110]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105899,	
2017-07-25 23:00:26,893 Epoch[37] Batch [1120]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.105900,	
2017-07-25 23:00:30,878 Epoch[37] Batch [1130]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.105970,	
2017-07-25 23:00:34,893 Epoch[37] Batch [1140]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105891,	
2017-07-25 23:00:38,871 Epoch[37] Batch [1150]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.105892,	
2017-07-25 23:00:42,824 Epoch[37] Batch [1160]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.105789,	
2017-07-25 23:00:46,699 Epoch[37] Batch [1170]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.105748,	
2017-07-25 23:00:50,612 Epoch[37] Batch [1180]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.105845,	
2017-07-25 23:00:54,642 Epoch[37] Batch [1190]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105872,	
2017-07-25 23:00:58,481 Epoch[37] Batch [1200]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.105820,	
2017-07-25 23:01:02,629 Epoch[37] Batch [1210]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.105797,	
2017-07-25 23:01:06,576 Epoch[37] Batch [1220]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105769,	
2017-07-25 23:01:10,500 Epoch[37] Batch [1230]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.105852,	
2017-07-25 23:01:14,362 Epoch[37] Batch [1240]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.105762,	
2017-07-25 23:01:18,295 Epoch[37] Batch [1250]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.105786,	
2017-07-25 23:01:22,267 Epoch[37] Batch [1260]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.105642,	
2017-07-25 23:01:26,295 Epoch[37] Batch [1270]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105590,	
2017-07-25 23:01:30,359 Epoch[37] Batch [1280]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.105564,	
2017-07-25 23:01:34,319 Epoch[37] Batch [1290]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.105609,	
2017-07-25 23:01:38,317 Epoch[37] Batch [1300]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.105640,	
2017-07-25 23:01:42,356 Epoch[37] Batch [1310]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105623,	
2017-07-25 23:01:46,308 Epoch[37] Batch [1320]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.105569,	
2017-07-25 23:01:50,352 Epoch[37] Batch [1330]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.105568,	
2017-07-25 23:01:54,455 Epoch[37] Batch [1340]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.105525,	
2017-07-25 23:01:58,404 Epoch[37] Batch [1350]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105558,	
2017-07-25 23:02:02,386 Epoch[37] Batch [1360]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.105579,	
2017-07-25 23:02:06,279 Epoch[37] Batch [1370]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.105537,	
2017-07-25 23:02:10,347 Epoch[37] Batch [1380]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.105498,	
2017-07-25 23:02:14,582 Epoch[37] Batch [1390]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.105531,	
2017-07-25 23:02:18,574 Epoch[37] Batch [1400]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.105518,	
2017-07-25 23:02:22,521 Epoch[37] Batch [1410]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105499,	
2017-07-25 23:02:26,522 Epoch[37] Batch [1420]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105480,	
2017-07-25 23:02:30,569 Epoch[37] Batch [1430]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.105575,	
2017-07-25 23:02:34,563 Epoch[37] Batch [1440]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.105576,	
2017-07-25 23:02:38,496 Epoch[37] Batch [1450]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.105591,	
2017-07-25 23:02:42,419 Epoch[37] Batch [1460]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.105595,	
2017-07-25 23:02:46,372 Epoch[37] Batch [1470]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.105605,	
2017-07-25 23:02:50,236 Epoch[37] Batch [1480]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.105574,	
2017-07-25 23:02:52,526 Epoch[37] Train-FCNLogLoss=0.105553
2017-07-25 23:02:52,526 Epoch[37] Time cost=592.386
2017-07-25 23:02:53,293 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.params"
2017-07-25 23:02:56,619 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0038.states"
2017-07-25 23:03:01,419 Epoch[38] Batch [10]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.108641,	
2017-07-25 23:03:05,332 Epoch[38] Batch [20]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.104924,	
2017-07-25 23:03:09,318 Epoch[38] Batch [30]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.102855,	
2017-07-25 23:03:13,272 Epoch[38] Batch [40]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.103596,	
2017-07-25 23:03:17,389 Epoch[38] Batch [50]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110626,	
2017-07-25 23:03:21,381 Epoch[38] Batch [60]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110906,	
2017-07-25 23:03:25,281 Epoch[38] Batch [70]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.110618,	
2017-07-25 23:03:29,248 Epoch[38] Batch [80]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.109933,	
2017-07-25 23:03:33,287 Epoch[38] Batch [90]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.109084,	
2017-07-25 23:03:37,242 Epoch[38] Batch [100]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107965,	
2017-07-25 23:03:41,114 Epoch[38] Batch [110]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.107408,	
2017-07-25 23:03:45,040 Epoch[38] Batch [120]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.107360,	
2017-07-25 23:03:49,107 Epoch[38] Batch [130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.107712,	
2017-07-25 23:03:53,064 Epoch[38] Batch [140]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.106885,	
2017-07-25 23:03:57,010 Epoch[38] Batch [150]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.106125,	
2017-07-25 23:04:00,932 Epoch[38] Batch [160]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.105613,	
2017-07-25 23:04:04,921 Epoch[38] Batch [170]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105182,	
2017-07-25 23:04:08,796 Epoch[38] Batch [180]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.104544,	
2017-07-25 23:04:12,709 Epoch[38] Batch [190]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.104058,	
2017-07-25 23:04:16,676 Epoch[38] Batch [200]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.104206,	
2017-07-25 23:04:20,668 Epoch[38] Batch [210]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.104037,	
2017-07-25 23:04:24,779 Epoch[38] Batch [220]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105265,	
2017-07-25 23:04:28,766 Epoch[38] Batch [230]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105203,	
2017-07-25 23:04:32,813 Epoch[38] Batch [240]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.105353,	
2017-07-25 23:04:36,926 Epoch[38] Batch [250]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.105361,	
2017-07-25 23:04:41,154 Epoch[38] Batch [260]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.104783,	
2017-07-25 23:04:45,332 Epoch[38] Batch [270]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.104973,	
2017-07-25 23:04:49,308 Epoch[38] Batch [280]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.104781,	
2017-07-25 23:04:53,541 Epoch[38] Batch [290]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.105296,	
2017-07-25 23:04:57,724 Epoch[38] Batch [300]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.106185,	
2017-07-25 23:05:01,781 Epoch[38] Batch [310]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.106131,	
2017-07-25 23:05:05,778 Epoch[38] Batch [320]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.106193,	
2017-07-25 23:05:09,683 Epoch[38] Batch [330]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.106338,	
2017-07-25 23:05:13,845 Epoch[38] Batch [340]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.106409,	
2017-07-25 23:05:17,927 Epoch[38] Batch [350]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.106384,	
2017-07-25 23:05:22,133 Epoch[38] Batch [360]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.106223,	
2017-07-25 23:05:26,261 Epoch[38] Batch [370]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.106283,	
2017-07-25 23:05:30,549 Epoch[38] Batch [380]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.106874,	
2017-07-25 23:05:34,832 Epoch[38] Batch [390]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.106838,	
2017-07-25 23:05:38,913 Epoch[38] Batch [400]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.106940,	
2017-07-25 23:05:43,040 Epoch[38] Batch [410]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.106840,	
2017-07-25 23:05:47,127 Epoch[38] Batch [420]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.106762,	
2017-07-25 23:05:51,107 Epoch[38] Batch [430]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.106721,	
2017-07-25 23:05:55,171 Epoch[38] Batch [440]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.106916,	
2017-07-25 23:05:59,232 Epoch[38] Batch [450]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.106936,	
2017-07-25 23:06:03,496 Epoch[38] Batch [460]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.107336,	
2017-07-25 23:06:07,594 Epoch[38] Batch [470]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.107570,	
2017-07-25 23:06:11,572 Epoch[38] Batch [480]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.107782,	
2017-07-25 23:06:15,700 Epoch[38] Batch [490]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.107926,	
2017-07-25 23:06:19,672 Epoch[38] Batch [500]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.107674,	
2017-07-25 23:06:23,691 Epoch[38] Batch [510]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.107541,	
2017-07-25 23:06:27,831 Epoch[38] Batch [520]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.107235,	
2017-07-25 23:06:31,772 Epoch[38] Batch [530]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.107116,	
2017-07-25 23:06:35,791 Epoch[38] Batch [540]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.107205,	
2017-07-25 23:06:39,766 Epoch[38] Batch [550]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.107034,	
2017-07-25 23:06:43,871 Epoch[38] Batch [560]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.106768,	
2017-07-25 23:06:48,067 Epoch[38] Batch [570]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.106961,	
2017-07-25 23:06:52,061 Epoch[38] Batch [580]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.106872,	
2017-07-25 23:06:56,189 Epoch[38] Batch [590]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.106992,	
2017-07-25 23:07:00,229 Epoch[38] Batch [600]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.106933,	
2017-07-25 23:07:04,493 Epoch[38] Batch [610]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.107338,	
2017-07-25 23:07:08,665 Epoch[38] Batch [620]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.107595,	
2017-07-25 23:07:12,679 Epoch[38] Batch [630]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.108207,	
2017-07-25 23:07:17,051 Epoch[38] Batch [640]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.108364,	
2017-07-25 23:07:21,118 Epoch[38] Batch [650]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.108714,	
2017-07-25 23:07:25,685 Epoch[38] Batch [660]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.108877,	
2017-07-25 23:07:29,878 Epoch[38] Batch [670]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.108786,	
2017-07-25 23:07:33,871 Epoch[38] Batch [680]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.108640,	
2017-07-25 23:07:37,987 Epoch[38] Batch [690]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.108716,	
2017-07-25 23:07:42,010 Epoch[38] Batch [700]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.108812,	
2017-07-25 23:07:45,978 Epoch[38] Batch [710]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.109052,	
2017-07-25 23:07:49,896 Epoch[38] Batch [720]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.108988,	
2017-07-25 23:07:53,839 Epoch[38] Batch [730]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.109035,	
2017-07-25 23:07:57,845 Epoch[38] Batch [740]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.108956,	
2017-07-25 23:08:01,840 Epoch[38] Batch [750]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.108816,	
2017-07-25 23:08:05,685 Epoch[38] Batch [760]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.109000,	
2017-07-25 23:08:09,651 Epoch[38] Batch [770]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.108938,	
2017-07-25 23:08:13,481 Epoch[38] Batch [780]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.109036,	
2017-07-25 23:08:17,516 Epoch[38] Batch [790]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.109216,	
2017-07-25 23:08:21,674 Epoch[38] Batch [800]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.109126,	
2017-07-25 23:08:25,912 Epoch[38] Batch [810]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109107,	
2017-07-25 23:08:29,914 Epoch[38] Batch [820]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109047,	
2017-07-25 23:08:34,014 Epoch[38] Batch [830]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.109064,	
2017-07-25 23:08:38,275 Epoch[38] Batch [840]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.109182,	
2017-07-25 23:08:42,415 Epoch[38] Batch [850]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.109184,	
2017-07-25 23:08:46,337 Epoch[38] Batch [860]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.109247,	
2017-07-25 23:08:50,612 Epoch[38] Batch [870]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.109238,	
2017-07-25 23:08:54,480 Epoch[38] Batch [880]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.109171,	
2017-07-25 23:08:58,653 Epoch[38] Batch [890]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.109180,	
2017-07-25 23:09:02,888 Epoch[38] Batch [900]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109160,	
2017-07-25 23:09:07,128 Epoch[38] Batch [910]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109147,	
2017-07-25 23:09:11,177 Epoch[38] Batch [920]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.109160,	
2017-07-25 23:09:15,205 Epoch[38] Batch [930]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.109018,	
2017-07-25 23:09:19,241 Epoch[38] Batch [940]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.108988,	
2017-07-25 23:09:23,250 Epoch[38] Batch [950]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109107,	
2017-07-25 23:09:27,200 Epoch[38] Batch [960]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.109064,	
2017-07-25 23:09:31,195 Epoch[38] Batch [970]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.109087,	
2017-07-25 23:09:35,091 Epoch[38] Batch [980]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.109077,	
2017-07-25 23:09:39,036 Epoch[38] Batch [990]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.109027,	
2017-07-25 23:09:43,114 Epoch[38] Batch [1000]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109016,	
2017-07-25 23:09:47,066 Epoch[38] Batch [1010]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.109069,	
2017-07-25 23:09:51,312 Epoch[38] Batch [1020]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.108943,	
2017-07-25 23:09:55,348 Epoch[38] Batch [1030]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.108934,	
2017-07-25 23:09:59,287 Epoch[38] Batch [1040]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.108825,	
2017-07-25 23:10:03,386 Epoch[38] Batch [1050]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.108709,	
2017-07-25 23:10:07,576 Epoch[38] Batch [1060]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108692,	
2017-07-25 23:10:11,983 Epoch[38] Batch [1070]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.108593,	
2017-07-25 23:10:16,175 Epoch[38] Batch [1080]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.108541,	
2017-07-25 23:10:20,459 Epoch[38] Batch [1090]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.108435,	
2017-07-25 23:10:25,125 Epoch[38] Batch [1100]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.108461,	
2017-07-25 23:10:29,321 Epoch[38] Batch [1110]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.108494,	
2017-07-25 23:10:33,363 Epoch[38] Batch [1120]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.108509,	
2017-07-25 23:10:37,400 Epoch[38] Batch [1130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.108601,	
2017-07-25 23:10:41,410 Epoch[38] Batch [1140]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.108728,	
2017-07-25 23:10:45,348 Epoch[38] Batch [1150]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.109009,	
2017-07-25 23:10:49,587 Epoch[38] Batch [1160]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.109074,	
2017-07-25 23:10:53,758 Epoch[38] Batch [1170]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.109257,	
2017-07-25 23:10:57,767 Epoch[38] Batch [1180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.109395,	
2017-07-25 23:11:01,829 Epoch[38] Batch [1190]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.109407,	
2017-07-25 23:11:05,941 Epoch[38] Batch [1200]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.109308,	
2017-07-25 23:11:10,035 Epoch[38] Batch [1210]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.109290,	
2017-07-25 23:11:14,250 Epoch[38] Batch [1220]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.109159,	
2017-07-25 23:11:18,168 Epoch[38] Batch [1230]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.108996,	
2017-07-25 23:11:22,055 Epoch[38] Batch [1240]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.108950,	
2017-07-25 23:11:26,413 Epoch[38] Batch [1250]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.108934,	
2017-07-25 23:11:30,567 Epoch[38] Batch [1260]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.108956,	
2017-07-25 23:11:34,679 Epoch[38] Batch [1270]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.108941,	
2017-07-25 23:11:38,754 Epoch[38] Batch [1280]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.108850,	
2017-07-25 23:11:42,707 Epoch[38] Batch [1290]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.108788,	
2017-07-25 23:11:46,523 Epoch[38] Batch [1300]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.108768,	
2017-07-25 23:11:50,459 Epoch[38] Batch [1310]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.108722,	
2017-07-25 23:11:54,492 Epoch[38] Batch [1320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.108670,	
2017-07-25 23:11:58,564 Epoch[38] Batch [1330]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.108595,	
2017-07-25 23:12:02,630 Epoch[38] Batch [1340]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.108685,	
2017-07-25 23:12:06,745 Epoch[38] Batch [1350]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.108631,	
2017-07-25 23:12:11,042 Epoch[38] Batch [1360]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.108634,	
2017-07-25 23:12:15,130 Epoch[38] Batch [1370]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.108620,	
2017-07-25 23:12:19,226 Epoch[38] Batch [1380]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.108564,	
2017-07-25 23:12:23,239 Epoch[38] Batch [1390]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.108605,	
2017-07-25 23:12:27,333 Epoch[38] Batch [1400]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108483,	
2017-07-25 23:12:31,453 Epoch[38] Batch [1410]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.108492,	
2017-07-25 23:12:35,505 Epoch[38] Batch [1420]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.108532,	
2017-07-25 23:12:39,600 Epoch[38] Batch [1430]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.108478,	
2017-07-25 23:12:43,769 Epoch[38] Batch [1440]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.108445,	
2017-07-25 23:12:48,108 Epoch[38] Batch [1450]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.108377,	
2017-07-25 23:12:52,032 Epoch[38] Batch [1460]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.108304,	
2017-07-25 23:12:56,140 Epoch[38] Batch [1470]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.108262,	
2017-07-25 23:13:00,260 Epoch[38] Batch [1480]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.108204,	
2017-07-25 23:13:02,600 Epoch[38] Train-FCNLogLoss=0.108228
2017-07-25 23:13:02,600 Epoch[38] Time cost=605.981
2017-07-25 23:13:03,582 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.params"
2017-07-25 23:13:07,893 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0039.states"
2017-07-25 23:13:13,103 Epoch[39] Batch [10]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.093270,	
2017-07-25 23:13:17,418 Epoch[39] Batch [20]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.100556,	
2017-07-25 23:13:21,622 Epoch[39] Batch [30]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.100344,	
2017-07-25 23:13:25,806 Epoch[39] Batch [40]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.100448,	
2017-07-25 23:13:29,831 Epoch[39] Batch [50]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.101379,	
2017-07-25 23:13:33,900 Epoch[39] Batch [60]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.102261,	
2017-07-25 23:13:37,794 Epoch[39] Batch [70]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.102652,	
2017-07-25 23:13:41,697 Epoch[39] Batch [80]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.103145,	
2017-07-25 23:13:45,695 Epoch[39] Batch [90]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.102510,	
2017-07-25 23:13:49,588 Epoch[39] Batch [100]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.102712,	
2017-07-25 23:13:53,602 Epoch[39] Batch [110]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.102066,	
2017-07-25 23:13:57,571 Epoch[39] Batch [120]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.101746,	
2017-07-25 23:14:01,585 Epoch[39] Batch [130]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.101920,	
2017-07-25 23:14:05,593 Epoch[39] Batch [140]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.101283,	
2017-07-25 23:14:09,573 Epoch[39] Batch [150]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.101984,	
2017-07-25 23:14:13,590 Epoch[39] Batch [160]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101110,	
2017-07-25 23:14:17,610 Epoch[39] Batch [170]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.101346,	
2017-07-25 23:14:21,686 Epoch[39] Batch [180]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101754,	
2017-07-25 23:14:25,548 Epoch[39] Batch [190]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.101588,	
2017-07-25 23:14:29,494 Epoch[39] Batch [200]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.101295,	
2017-07-25 23:14:33,442 Epoch[39] Batch [210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.101167,	
2017-07-25 23:14:37,420 Epoch[39] Batch [220]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.101249,	
2017-07-25 23:14:41,293 Epoch[39] Batch [230]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.101892,	
2017-07-25 23:14:45,279 Epoch[39] Batch [240]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.102407,	
2017-07-25 23:14:49,196 Epoch[39] Batch [250]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.102662,	
2017-07-25 23:14:53,202 Epoch[39] Batch [260]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.102273,	
2017-07-25 23:14:57,108 Epoch[39] Batch [270]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.102559,	
2017-07-25 23:15:01,106 Epoch[39] Batch [280]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.102763,	
2017-07-25 23:15:05,170 Epoch[39] Batch [290]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.102067,	
2017-07-25 23:15:08,994 Epoch[39] Batch [300]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.102079,	
2017-07-25 23:15:12,915 Epoch[39] Batch [310]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.101795,	
2017-07-25 23:15:16,945 Epoch[39] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.102091,	
2017-07-25 23:15:20,879 Epoch[39] Batch [330]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.102070,	
2017-07-25 23:15:24,829 Epoch[39] Batch [340]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.102650,	
2017-07-25 23:15:28,795 Epoch[39] Batch [350]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.103108,	
2017-07-25 23:15:32,709 Epoch[39] Batch [360]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.103276,	
2017-07-25 23:15:36,607 Epoch[39] Batch [370]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.103347,	
2017-07-25 23:15:40,468 Epoch[39] Batch [380]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.103727,	
2017-07-25 23:15:44,461 Epoch[39] Batch [390]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.103625,	
2017-07-25 23:15:48,542 Epoch[39] Batch [400]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.103668,	
2017-07-25 23:15:52,604 Epoch[39] Batch [410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.103962,	
2017-07-25 23:15:56,536 Epoch[39] Batch [420]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.103767,	
2017-07-25 23:16:00,516 Epoch[39] Batch [430]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.103889,	
2017-07-25 23:16:04,477 Epoch[39] Batch [440]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.103855,	
2017-07-25 23:16:08,578 Epoch[39] Batch [450]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.103904,	
2017-07-25 23:16:12,563 Epoch[39] Batch [460]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.103735,	
2017-07-25 23:16:16,582 Epoch[39] Batch [470]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.103818,	
2017-07-25 23:16:20,556 Epoch[39] Batch [480]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.103790,	
2017-07-25 23:16:24,742 Epoch[39] Batch [490]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.104397,	
2017-07-25 23:16:28,640 Epoch[39] Batch [500]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.104572,	
2017-07-25 23:16:32,612 Epoch[39] Batch [510]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.104477,	
2017-07-25 23:16:36,549 Epoch[39] Batch [520]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.104796,	
2017-07-25 23:16:40,446 Epoch[39] Batch [530]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.104949,	
2017-07-25 23:16:44,394 Epoch[39] Batch [540]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105070,	
2017-07-25 23:16:48,329 Epoch[39] Batch [550]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.105405,	
2017-07-25 23:16:52,199 Epoch[39] Batch [560]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.105578,	
2017-07-25 23:16:56,079 Epoch[39] Batch [570]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.105502,	
2017-07-25 23:17:00,088 Epoch[39] Batch [580]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105462,	
2017-07-25 23:17:04,053 Epoch[39] Batch [590]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.105637,	
2017-07-25 23:17:08,017 Epoch[39] Batch [600]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.105746,	
2017-07-25 23:17:12,171 Epoch[39] Batch [610]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.105850,	
2017-07-25 23:17:16,127 Epoch[39] Batch [620]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.105737,	
2017-07-25 23:17:20,138 Epoch[39] Batch [630]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.105661,	
2017-07-25 23:17:24,199 Epoch[39] Batch [640]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.105600,	
2017-07-25 23:17:28,207 Epoch[39] Batch [650]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105560,	
2017-07-25 23:17:32,225 Epoch[39] Batch [660]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105429,	
2017-07-25 23:17:36,103 Epoch[39] Batch [670]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.105423,	
2017-07-25 23:17:39,975 Epoch[39] Batch [680]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.105408,	
2017-07-25 23:17:43,906 Epoch[39] Batch [690]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105078,	
2017-07-25 23:17:47,836 Epoch[39] Batch [700]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105148,	
2017-07-25 23:17:51,628 Epoch[39] Batch [710]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.105275,	
2017-07-25 23:17:55,527 Epoch[39] Batch [720]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.105108,	
2017-07-25 23:17:59,647 Epoch[39] Batch [730]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105039,	
2017-07-25 23:18:03,768 Epoch[39] Batch [740]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.104948,	
2017-07-25 23:18:07,610 Epoch[39] Batch [750]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.105036,	
2017-07-25 23:18:11,544 Epoch[39] Batch [760]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.104971,	
2017-07-25 23:18:15,440 Epoch[39] Batch [770]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.104836,	
2017-07-25 23:18:19,358 Epoch[39] Batch [780]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.104809,	
2017-07-25 23:18:23,293 Epoch[39] Batch [790]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.104772,	
2017-07-25 23:18:27,282 Epoch[39] Batch [800]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104683,	
2017-07-25 23:18:31,306 Epoch[39] Batch [810]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.104650,	
2017-07-25 23:18:35,218 Epoch[39] Batch [820]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.104710,	
2017-07-25 23:18:39,307 Epoch[39] Batch [830]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.104773,	
2017-07-25 23:18:43,178 Epoch[39] Batch [840]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.104793,	
2017-07-25 23:18:47,063 Epoch[39] Batch [850]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.104633,	
2017-07-25 23:18:51,117 Epoch[39] Batch [860]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.104538,	
2017-07-25 23:18:55,220 Epoch[39] Batch [870]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104625,	
2017-07-25 23:18:59,235 Epoch[39] Batch [880]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104713,	
2017-07-25 23:19:03,249 Epoch[39] Batch [890]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.104827,	
2017-07-25 23:19:07,252 Epoch[39] Batch [900]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.104764,	
2017-07-25 23:19:11,233 Epoch[39] Batch [910]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.104784,	
2017-07-25 23:19:15,239 Epoch[39] Batch [920]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.104697,	
2017-07-25 23:19:19,309 Epoch[39] Batch [930]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104711,	
2017-07-25 23:19:23,431 Epoch[39] Batch [940]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.104679,	
2017-07-25 23:19:27,447 Epoch[39] Batch [950]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104640,	
2017-07-25 23:19:31,601 Epoch[39] Batch [960]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104593,	
2017-07-25 23:19:35,712 Epoch[39] Batch [970]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.104487,	
2017-07-25 23:19:39,702 Epoch[39] Batch [980]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.104482,	
2017-07-25 23:19:43,738 Epoch[39] Batch [990]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104493,	
2017-07-25 23:19:47,780 Epoch[39] Batch [1000]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104758,	
2017-07-25 23:19:51,797 Epoch[39] Batch [1010]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.104788,	
2017-07-25 23:19:55,834 Epoch[39] Batch [1020]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.104946,	
2017-07-25 23:19:59,835 Epoch[39] Batch [1030]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105047,	
2017-07-25 23:20:03,810 Epoch[39] Batch [1040]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.104934,	
2017-07-25 23:20:07,852 Epoch[39] Batch [1050]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.104978,	
2017-07-25 23:20:11,782 Epoch[39] Batch [1060]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.105099,	
2017-07-25 23:20:15,906 Epoch[39] Batch [1070]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.105173,	
2017-07-25 23:20:20,069 Epoch[39] Batch [1080]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.105151,	
2017-07-25 23:20:24,022 Epoch[39] Batch [1090]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.105140,	
2017-07-25 23:20:28,043 Epoch[39] Batch [1100]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.105102,	
2017-07-25 23:20:32,033 Epoch[39] Batch [1110]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105100,	
2017-07-25 23:20:36,040 Epoch[39] Batch [1120]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105124,	
2017-07-25 23:20:40,033 Epoch[39] Batch [1130]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.105116,	
2017-07-25 23:20:43,931 Epoch[39] Batch [1140]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.105144,	
2017-07-25 23:20:47,904 Epoch[39] Batch [1150]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.105201,	
2017-07-25 23:20:51,934 Epoch[39] Batch [1160]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.105121,	
2017-07-25 23:20:55,817 Epoch[39] Batch [1170]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.105079,	
2017-07-25 23:21:00,004 Epoch[39] Batch [1180]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.105058,	
2017-07-25 23:21:04,087 Epoch[39] Batch [1190]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.104933,	
2017-07-25 23:21:08,172 Epoch[39] Batch [1200]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.104957,	
2017-07-25 23:21:12,354 Epoch[39] Batch [1210]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.104997,	
2017-07-25 23:21:16,351 Epoch[39] Batch [1220]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.105028,	
2017-07-25 23:21:20,244 Epoch[39] Batch [1230]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.105105,	
2017-07-25 23:21:24,463 Epoch[39] Batch [1240]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.105026,	
2017-07-25 23:21:28,467 Epoch[39] Batch [1250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.105075,	
2017-07-25 23:21:32,327 Epoch[39] Batch [1260]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.105078,	
2017-07-25 23:21:36,563 Epoch[39] Batch [1270]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.105009,	
2017-07-25 23:21:40,426 Epoch[39] Batch [1280]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.104962,	
2017-07-25 23:21:44,670 Epoch[39] Batch [1290]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.104889,	
2017-07-25 23:21:48,736 Epoch[39] Batch [1300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.104812,	
2017-07-25 23:21:52,929 Epoch[39] Batch [1310]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.104807,	
2017-07-25 23:21:56,874 Epoch[39] Batch [1320]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.104645,	
2017-07-25 23:22:00,958 Epoch[39] Batch [1330]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.104598,	
2017-07-25 23:22:04,755 Epoch[39] Batch [1340]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.104582,	
2017-07-25 23:22:09,075 Epoch[39] Batch [1350]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.104518,	
2017-07-25 23:22:13,541 Epoch[39] Batch [1360]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.104444,	
2017-07-25 23:22:17,860 Epoch[39] Batch [1370]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.104494,	
2017-07-25 23:22:21,711 Epoch[39] Batch [1380]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.104539,	
2017-07-25 23:22:25,685 Epoch[39] Batch [1390]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.104537,	
2017-07-25 23:22:29,537 Epoch[39] Batch [1400]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.104595,	
2017-07-25 23:22:33,729 Epoch[39] Batch [1410]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.104608,	
2017-07-25 23:22:37,641 Epoch[39] Batch [1420]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.104620,	
2017-07-25 23:22:41,985 Epoch[39] Batch [1430]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.104573,	
2017-07-25 23:22:46,341 Epoch[39] Batch [1440]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104624,	
2017-07-25 23:22:50,497 Epoch[39] Batch [1450]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104606,	
2017-07-25 23:22:54,691 Epoch[39] Batch [1460]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.104625,	
2017-07-25 23:22:58,751 Epoch[39] Batch [1470]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104647,	
2017-07-25 23:23:02,734 Epoch[39] Batch [1480]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.104702,	
2017-07-25 23:23:05,078 Epoch[39] Train-FCNLogLoss=0.104707
2017-07-25 23:23:05,078 Epoch[39] Time cost=597.185
2017-07-25 23:23:06,111 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.params"
2017-07-25 23:23:10,535 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0040.states"
2017-07-25 23:23:15,228 Epoch[40] Batch [10]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.099865,	
2017-07-25 23:23:19,165 Epoch[40] Batch [20]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.101484,	
2017-07-25 23:23:23,204 Epoch[40] Batch [30]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.099449,	
2017-07-25 23:23:27,563 Epoch[40] Batch [40]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.098764,	
2017-07-25 23:23:31,577 Epoch[40] Batch [50]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.100215,	
2017-07-25 23:23:35,723 Epoch[40] Batch [60]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.099761,	
2017-07-25 23:23:39,818 Epoch[40] Batch [70]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101116,	
2017-07-25 23:23:43,967 Epoch[40] Batch [80]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.100784,	
2017-07-25 23:23:48,017 Epoch[40] Batch [90]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.101533,	
2017-07-25 23:23:51,862 Epoch[40] Batch [100]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.101243,	
2017-07-25 23:23:55,733 Epoch[40] Batch [110]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.102342,	
2017-07-25 23:23:59,641 Epoch[40] Batch [120]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.101631,	
2017-07-25 23:24:03,842 Epoch[40] Batch [130]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.100849,	
2017-07-25 23:24:07,676 Epoch[40] Batch [140]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.100626,	
2017-07-25 23:24:12,514 Epoch[40] Batch [150]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.101588,	
2017-07-25 23:24:16,674 Epoch[40] Batch [160]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.102158,	
2017-07-25 23:24:20,998 Epoch[40] Batch [170]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.102722,	
2017-07-25 23:24:25,076 Epoch[40] Batch [180]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.104670,	
2017-07-25 23:24:29,231 Epoch[40] Batch [190]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104331,	
2017-07-25 23:24:33,312 Epoch[40] Batch [200]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.104526,	
2017-07-25 23:24:37,259 Epoch[40] Batch [210]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.104768,	
2017-07-25 23:24:41,366 Epoch[40] Batch [220]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.105217,	
2017-07-25 23:24:45,281 Epoch[40] Batch [230]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.105082,	
2017-07-25 23:24:49,283 Epoch[40] Batch [240]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.105592,	
2017-07-25 23:24:53,177 Epoch[40] Batch [250]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.105326,	
2017-07-25 23:24:57,044 Epoch[40] Batch [260]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.105507,	
2017-07-25 23:25:00,886 Epoch[40] Batch [270]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.105335,	
2017-07-25 23:25:04,801 Epoch[40] Batch [280]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.105441,	
2017-07-25 23:25:08,749 Epoch[40] Batch [290]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105892,	
2017-07-25 23:25:12,897 Epoch[40] Batch [300]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.105835,	
2017-07-25 23:25:16,842 Epoch[40] Batch [310]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.105738,	
2017-07-25 23:25:21,022 Epoch[40] Batch [320]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.105435,	
2017-07-25 23:25:25,030 Epoch[40] Batch [330]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.105292,	
2017-07-25 23:25:29,021 Epoch[40] Batch [340]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.105300,	
2017-07-25 23:25:33,156 Epoch[40] Batch [350]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.104780,	
2017-07-25 23:25:37,106 Epoch[40] Batch [360]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.105003,	
2017-07-25 23:25:41,046 Epoch[40] Batch [370]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.105137,	
2017-07-25 23:25:45,262 Epoch[40] Batch [380]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.105129,	
2017-07-25 23:25:49,195 Epoch[40] Batch [390]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.105111,	
2017-07-25 23:25:53,041 Epoch[40] Batch [400]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.104701,	
2017-07-25 23:25:57,271 Epoch[40] Batch [410]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.104440,	
2017-07-25 23:26:01,177 Epoch[40] Batch [420]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.104209,	
2017-07-25 23:26:05,237 Epoch[40] Batch [430]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.104156,	
2017-07-25 23:26:09,196 Epoch[40] Batch [440]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.104052,	
2017-07-25 23:26:13,201 Epoch[40] Batch [450]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.104235,	
2017-07-25 23:26:17,135 Epoch[40] Batch [460]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.103996,	
2017-07-25 23:26:21,293 Epoch[40] Batch [470]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104053,	
2017-07-25 23:26:25,176 Epoch[40] Batch [480]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.104113,	
2017-07-25 23:26:29,403 Epoch[40] Batch [490]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.104360,	
2017-07-25 23:26:33,387 Epoch[40] Batch [500]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.104534,	
2017-07-25 23:26:37,540 Epoch[40] Batch [510]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104562,	
2017-07-25 23:26:41,005 Update[60000]: Change learning rate to 5.00000e-05
2017-07-25 23:26:41,641 Epoch[40] Batch [520]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.104676,	
2017-07-25 23:26:45,959 Epoch[40] Batch [530]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.104874,	
2017-07-25 23:26:49,863 Epoch[40] Batch [540]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.105084,	
2017-07-25 23:26:53,734 Epoch[40] Batch [550]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.105157,	
2017-07-25 23:26:57,641 Epoch[40] Batch [560]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.105241,	
2017-07-25 23:27:01,998 Epoch[40] Batch [570]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.104984,	
2017-07-25 23:27:06,047 Epoch[40] Batch [580]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104742,	
2017-07-25 23:27:10,388 Epoch[40] Batch [590]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.104588,	
2017-07-25 23:27:14,349 Epoch[40] Batch [600]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.104632,	
2017-07-25 23:27:18,951 Epoch[40] Batch [610]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.104837,	
2017-07-25 23:27:23,233 Epoch[40] Batch [620]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.104695,	
2017-07-25 23:27:27,533 Epoch[40] Batch [630]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.104757,	
2017-07-25 23:27:31,749 Epoch[40] Batch [640]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.104738,	
2017-07-25 23:27:35,906 Epoch[40] Batch [650]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104503,	
2017-07-25 23:27:40,036 Epoch[40] Batch [660]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.104515,	
2017-07-25 23:27:44,106 Epoch[40] Batch [670]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.104456,	
2017-07-25 23:27:48,157 Epoch[40] Batch [680]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.104376,	
2017-07-25 23:27:52,183 Epoch[40] Batch [690]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.104362,	
2017-07-25 23:27:56,380 Epoch[40] Batch [700]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.104129,	
2017-07-25 23:28:00,238 Epoch[40] Batch [710]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.103979,	
2017-07-25 23:28:04,172 Epoch[40] Batch [720]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.104025,	
2017-07-25 23:28:08,201 Epoch[40] Batch [730]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.103947,	
2017-07-25 23:28:12,110 Epoch[40] Batch [740]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.103931,	
2017-07-25 23:28:16,122 Epoch[40] Batch [750]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.103824,	
2017-07-25 23:28:20,107 Epoch[40] Batch [760]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.103857,	
2017-07-25 23:28:24,063 Epoch[40] Batch [770]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.103815,	
2017-07-25 23:28:28,055 Epoch[40] Batch [780]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.103720,	
2017-07-25 23:28:32,096 Epoch[40] Batch [790]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.103512,	
2017-07-25 23:28:36,077 Epoch[40] Batch [800]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.103311,	
2017-07-25 23:28:40,188 Epoch[40] Batch [810]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.103330,	
2017-07-25 23:28:44,166 Epoch[40] Batch [820]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.103489,	
2017-07-25 23:28:48,069 Epoch[40] Batch [830]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.103573,	
2017-07-25 23:28:52,128 Epoch[40] Batch [840]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.103514,	
2017-07-25 23:28:56,139 Epoch[40] Batch [850]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.103350,	
2017-07-25 23:29:00,118 Epoch[40] Batch [860]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.103415,	
2017-07-25 23:29:04,043 Epoch[40] Batch [870]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.103369,	
2017-07-25 23:29:08,056 Epoch[40] Batch [880]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.103224,	
2017-07-25 23:29:12,151 Epoch[40] Batch [890]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.103290,	
2017-07-25 23:29:15,995 Epoch[40] Batch [900]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.103217,	
2017-07-25 23:29:19,885 Epoch[40] Batch [910]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.103166,	
2017-07-25 23:29:23,943 Epoch[40] Batch [920]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.102939,	
2017-07-25 23:29:28,061 Epoch[40] Batch [930]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.102828,	
2017-07-25 23:29:32,087 Epoch[40] Batch [940]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.102727,	
2017-07-25 23:29:36,134 Epoch[40] Batch [950]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.102840,	
2017-07-25 23:29:40,283 Epoch[40] Batch [960]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.102827,	
2017-07-25 23:29:44,249 Epoch[40] Batch [970]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.102748,	
2017-07-25 23:29:48,178 Epoch[40] Batch [980]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.102698,	
2017-07-25 23:29:52,152 Epoch[40] Batch [990]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.102710,	
2017-07-25 23:29:56,144 Epoch[40] Batch [1000]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.102638,	
2017-07-25 23:30:00,488 Epoch[40] Batch [1010]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.102719,	
2017-07-25 23:30:04,855 Epoch[40] Batch [1020]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.102643,	
2017-07-25 23:30:08,824 Epoch[40] Batch [1030]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.102529,	
2017-07-25 23:30:12,883 Epoch[40] Batch [1040]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.102448,	
2017-07-25 23:30:16,804 Epoch[40] Batch [1050]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.102383,	
2017-07-25 23:30:20,877 Epoch[40] Batch [1060]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.102330,	
2017-07-25 23:30:24,886 Epoch[40] Batch [1070]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.102282,	
2017-07-25 23:30:29,294 Epoch[40] Batch [1080]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.102312,	
2017-07-25 23:30:33,432 Epoch[40] Batch [1090]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.102292,	
2017-07-25 23:30:37,478 Epoch[40] Batch [1100]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.102173,	
2017-07-25 23:30:41,562 Epoch[40] Batch [1110]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.102206,	
2017-07-25 23:30:45,554 Epoch[40] Batch [1120]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.102112,	
2017-07-25 23:30:49,461 Epoch[40] Batch [1130]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.102020,	
2017-07-25 23:30:53,490 Epoch[40] Batch [1140]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.101932,	
2017-07-25 23:30:57,415 Epoch[40] Batch [1150]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.101898,	
2017-07-25 23:31:01,415 Epoch[40] Batch [1160]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.102062,	
2017-07-25 23:31:05,430 Epoch[40] Batch [1170]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101986,	
2017-07-25 23:31:09,342 Epoch[40] Batch [1180]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.101985,	
2017-07-25 23:31:13,248 Epoch[40] Batch [1190]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.101974,	
2017-07-25 23:31:17,311 Epoch[40] Batch [1200]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101973,	
2017-07-25 23:31:21,737 Epoch[40] Batch [1210]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.101962,	
2017-07-25 23:31:25,999 Epoch[40] Batch [1220]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.101981,	
2017-07-25 23:31:30,137 Epoch[40] Batch [1230]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.102011,	
2017-07-25 23:31:34,210 Epoch[40] Batch [1240]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.101971,	
2017-07-25 23:31:38,091 Epoch[40] Batch [1250]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.101883,	
2017-07-25 23:31:42,056 Epoch[40] Batch [1260]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.101838,	
2017-07-25 23:31:45,932 Epoch[40] Batch [1270]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.101845,	
2017-07-25 23:31:49,941 Epoch[40] Batch [1280]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.101839,	
2017-07-25 23:31:53,924 Epoch[40] Batch [1290]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.101874,	
2017-07-25 23:31:57,988 Epoch[40] Batch [1300]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.101877,	
2017-07-25 23:32:01,940 Epoch[40] Batch [1310]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.101878,	
2017-07-25 23:32:05,895 Epoch[40] Batch [1320]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.101835,	
2017-07-25 23:32:09,960 Epoch[40] Batch [1330]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.101826,	
2017-07-25 23:32:13,903 Epoch[40] Batch [1340]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.101856,	
2017-07-25 23:32:17,921 Epoch[40] Batch [1350]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.101802,	
2017-07-25 23:32:21,882 Epoch[40] Batch [1360]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.101786,	
2017-07-25 23:32:25,875 Epoch[40] Batch [1370]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.101785,	
2017-07-25 23:32:29,937 Epoch[40] Batch [1380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.101858,	
2017-07-25 23:32:33,801 Epoch[40] Batch [1390]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.101871,	
2017-07-25 23:32:37,867 Epoch[40] Batch [1400]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.101804,	
2017-07-25 23:32:41,894 Epoch[40] Batch [1410]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.101744,	
2017-07-25 23:32:45,876 Epoch[40] Batch [1420]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.101759,	
2017-07-25 23:32:49,725 Epoch[40] Batch [1430]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.101680,	
2017-07-25 23:32:53,821 Epoch[40] Batch [1440]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.101628,	
2017-07-25 23:32:57,807 Epoch[40] Batch [1450]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.101529,	
2017-07-25 23:33:01,751 Epoch[40] Batch [1460]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.101472,	
2017-07-25 23:33:05,848 Epoch[40] Batch [1470]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.101392,	
2017-07-25 23:33:09,774 Epoch[40] Batch [1480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.101373,	
2017-07-25 23:33:12,219 Epoch[40] Train-FCNLogLoss=0.101383
2017-07-25 23:33:12,219 Epoch[40] Time cost=601.683
2017-07-25 23:33:13,185 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.params"
2017-07-25 23:33:17,476 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0041.states"
2017-07-25 23:33:22,146 Epoch[41] Batch [10]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094332,	
2017-07-25 23:33:26,086 Epoch[41] Batch [20]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.091035,	
2017-07-25 23:33:30,059 Epoch[41] Batch [30]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.096290,	
2017-07-25 23:33:34,226 Epoch[41] Batch [40]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094757,	
2017-07-25 23:33:38,306 Epoch[41] Batch [50]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094315,	
2017-07-25 23:33:42,488 Epoch[41] Batch [60]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095313,	
2017-07-25 23:33:46,526 Epoch[41] Batch [70]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.095468,	
2017-07-25 23:33:50,419 Epoch[41] Batch [80]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095982,	
2017-07-25 23:33:54,345 Epoch[41] Batch [90]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.094808,	
2017-07-25 23:33:58,373 Epoch[41] Batch [100]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095990,	
2017-07-25 23:34:02,416 Epoch[41] Batch [110]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.096488,	
2017-07-25 23:34:06,503 Epoch[41] Batch [120]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.096737,	
2017-07-25 23:34:10,538 Epoch[41] Batch [130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096437,	
2017-07-25 23:34:14,561 Epoch[41] Batch [140]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096707,	
2017-07-25 23:34:18,669 Epoch[41] Batch [150]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.096335,	
2017-07-25 23:34:22,765 Epoch[41] Batch [160]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.096094,	
2017-07-25 23:34:26,875 Epoch[41] Batch [170]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095990,	
2017-07-25 23:34:30,955 Epoch[41] Batch [180]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096196,	
2017-07-25 23:34:34,981 Epoch[41] Batch [190]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096758,	
2017-07-25 23:34:39,111 Epoch[41] Batch [200]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097675,	
2017-07-25 23:34:43,108 Epoch[41] Batch [210]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.097548,	
2017-07-25 23:34:47,168 Epoch[41] Batch [220]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097321,	
2017-07-25 23:34:51,126 Epoch[41] Batch [230]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.097087,	
2017-07-25 23:34:55,075 Epoch[41] Batch [240]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.097127,	
2017-07-25 23:34:59,119 Epoch[41] Batch [250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.097134,	
2017-07-25 23:35:03,047 Epoch[41] Batch [260]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.096983,	
2017-07-25 23:35:07,168 Epoch[41] Batch [270]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.096804,	
2017-07-25 23:35:11,138 Epoch[41] Batch [280]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.097087,	
2017-07-25 23:35:15,097 Epoch[41] Batch [290]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.096773,	
2017-07-25 23:35:19,080 Epoch[41] Batch [300]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096843,	
2017-07-25 23:35:23,199 Epoch[41] Batch [310]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.096753,	
2017-07-25 23:35:27,140 Epoch[41] Batch [320]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.096870,	
2017-07-25 23:35:31,177 Epoch[41] Batch [330]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096772,	
2017-07-25 23:35:35,115 Epoch[41] Batch [340]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.097020,	
2017-07-25 23:35:39,156 Epoch[41] Batch [350]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.097296,	
2017-07-25 23:35:43,080 Epoch[41] Batch [360]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.097108,	
2017-07-25 23:35:46,956 Epoch[41] Batch [370]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.096898,	
2017-07-25 23:35:51,016 Epoch[41] Batch [380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.096983,	
2017-07-25 23:35:55,249 Epoch[41] Batch [390]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.097071,	
2017-07-25 23:35:59,530 Epoch[41] Batch [400]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.097019,	
2017-07-25 23:36:03,542 Epoch[41] Batch [410]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.096898,	
2017-07-25 23:36:07,666 Epoch[41] Batch [420]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.096750,	
2017-07-25 23:36:11,735 Epoch[41] Batch [430]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.096754,	
2017-07-25 23:36:15,683 Epoch[41] Batch [440]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.096765,	
2017-07-25 23:36:19,579 Epoch[41] Batch [450]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.096943,	
2017-07-25 23:36:23,614 Epoch[41] Batch [460]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097057,	
2017-07-25 23:36:27,631 Epoch[41] Batch [470]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.097256,	
2017-07-25 23:36:31,730 Epoch[41] Batch [480]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097417,	
2017-07-25 23:36:35,735 Epoch[41] Batch [490]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.097259,	
2017-07-25 23:36:39,829 Epoch[41] Batch [500]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097267,	
2017-07-25 23:36:43,829 Epoch[41] Batch [510]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.097581,	
2017-07-25 23:36:47,944 Epoch[41] Batch [520]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097723,	
2017-07-25 23:36:51,863 Epoch[41] Batch [530]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.097895,	
2017-07-25 23:36:55,919 Epoch[41] Batch [540]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.097948,	
2017-07-25 23:36:59,896 Epoch[41] Batch [550]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.097824,	
2017-07-25 23:37:03,817 Epoch[41] Batch [560]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.097841,	
2017-07-25 23:37:07,875 Epoch[41] Batch [570]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.097665,	
2017-07-25 23:37:11,830 Epoch[41] Batch [580]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.097681,	
2017-07-25 23:37:15,896 Epoch[41] Batch [590]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.097604,	
2017-07-25 23:37:19,863 Epoch[41] Batch [600]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.097631,	
2017-07-25 23:37:23,765 Epoch[41] Batch [610]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.097520,	
2017-07-25 23:37:27,749 Epoch[41] Batch [620]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.097450,	
2017-07-25 23:37:31,789 Epoch[41] Batch [630]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.097532,	
2017-07-25 23:37:35,729 Epoch[41] Batch [640]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.097412,	
2017-07-25 23:37:39,772 Epoch[41] Batch [650]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.097360,	
2017-07-25 23:37:43,791 Epoch[41] Batch [660]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097531,	
2017-07-25 23:37:47,792 Epoch[41] Batch [670]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.097427,	
2017-07-25 23:37:51,725 Epoch[41] Batch [680]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.097361,	
2017-07-25 23:37:55,826 Epoch[41] Batch [690]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.097537,	
2017-07-25 23:37:59,732 Epoch[41] Batch [700]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.097507,	
2017-07-25 23:38:03,803 Epoch[41] Batch [710]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.097456,	
2017-07-25 23:38:07,932 Epoch[41] Batch [720]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097499,	
2017-07-25 23:38:11,972 Epoch[41] Batch [730]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.097545,	
2017-07-25 23:38:15,827 Epoch[41] Batch [740]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.097660,	
2017-07-25 23:38:19,999 Epoch[41] Batch [750]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097918,	
2017-07-25 23:38:24,205 Epoch[41] Batch [760]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.097959,	
2017-07-25 23:38:28,294 Epoch[41] Batch [770]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.097839,	
2017-07-25 23:38:32,250 Epoch[41] Batch [780]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.097825,	
2017-07-25 23:38:36,055 Epoch[41] Batch [790]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.097842,	
2017-07-25 23:38:39,904 Epoch[41] Batch [800]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.097751,	
2017-07-25 23:38:43,952 Epoch[41] Batch [810]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097750,	
2017-07-25 23:38:48,050 Epoch[41] Batch [820]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.097645,	
2017-07-25 23:38:52,016 Epoch[41] Batch [830]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.097716,	
2017-07-25 23:38:56,080 Epoch[41] Batch [840]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.097658,	
2017-07-25 23:39:00,053 Epoch[41] Batch [850]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.097892,	
2017-07-25 23:39:04,048 Epoch[41] Batch [860]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.097873,	
2017-07-25 23:39:08,017 Epoch[41] Batch [870]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.097890,	
2017-07-25 23:39:11,972 Epoch[41] Batch [880]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.097925,	
2017-07-25 23:39:15,785 Epoch[41] Batch [890]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.097956,	
2017-07-25 23:39:19,798 Epoch[41] Batch [900]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.097927,	
2017-07-25 23:39:23,863 Epoch[41] Batch [910]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.098010,	
2017-07-25 23:39:27,893 Epoch[41] Batch [920]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.097998,	
2017-07-25 23:39:32,087 Epoch[41] Batch [930]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.098166,	
2017-07-25 23:39:36,273 Epoch[41] Batch [940]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.098183,	
2017-07-25 23:39:40,614 Epoch[41] Batch [950]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.098208,	
2017-07-25 23:39:44,607 Epoch[41] Batch [960]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.098184,	
2017-07-25 23:39:48,870 Epoch[41] Batch [970]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.098261,	
2017-07-25 23:39:52,777 Epoch[41] Batch [980]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.098146,	
2017-07-25 23:39:56,745 Epoch[41] Batch [990]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.098182,	
2017-07-25 23:40:01,061 Epoch[41] Batch [1000]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.098035,	
2017-07-25 23:40:05,237 Epoch[41] Batch [1010]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.097894,	
2017-07-25 23:40:09,254 Epoch[41] Batch [1020]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.097866,	
2017-07-25 23:40:13,408 Epoch[41] Batch [1030]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.097839,	
2017-07-25 23:40:17,610 Epoch[41] Batch [1040]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.097738,	
2017-07-25 23:40:21,751 Epoch[41] Batch [1050]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097662,	
2017-07-25 23:40:25,731 Epoch[41] Batch [1060]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.097628,	
2017-07-25 23:40:29,888 Epoch[41] Batch [1070]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.097575,	
2017-07-25 23:40:34,050 Epoch[41] Batch [1080]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.097546,	
2017-07-25 23:40:38,102 Epoch[41] Batch [1090]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.097466,	
2017-07-25 23:40:42,113 Epoch[41] Batch [1100]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.097330,	
2017-07-25 23:40:46,315 Epoch[41] Batch [1110]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.097219,	
2017-07-25 23:40:50,195 Epoch[41] Batch [1120]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.097232,	
2017-07-25 23:40:54,464 Epoch[41] Batch [1130]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.097248,	
2017-07-25 23:40:58,539 Epoch[41] Batch [1140]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.097261,	
2017-07-25 23:41:02,570 Epoch[41] Batch [1150]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.097246,	
2017-07-25 23:41:06,648 Epoch[41] Batch [1160]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.097338,	
2017-07-25 23:41:10,814 Epoch[41] Batch [1170]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.097308,	
2017-07-25 23:41:14,884 Epoch[41] Batch [1180]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.097359,	
2017-07-25 23:41:18,980 Epoch[41] Batch [1190]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.097369,	
2017-07-25 23:41:22,989 Epoch[41] Batch [1200]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.097351,	
2017-07-25 23:41:26,927 Epoch[41] Batch [1210]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.097377,	
2017-07-25 23:41:30,948 Epoch[41] Batch [1220]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097386,	
2017-07-25 23:41:34,827 Epoch[41] Batch [1230]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.097435,	
2017-07-25 23:41:38,863 Epoch[41] Batch [1240]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.097408,	
2017-07-25 23:41:42,947 Epoch[41] Batch [1250]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.097329,	
2017-07-25 23:41:46,834 Epoch[41] Batch [1260]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.097433,	
2017-07-25 23:41:50,711 Epoch[41] Batch [1270]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.097500,	
2017-07-25 23:41:54,941 Epoch[41] Batch [1280]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.097418,	
2017-07-25 23:41:58,832 Epoch[41] Batch [1290]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.097377,	
2017-07-25 23:42:02,860 Epoch[41] Batch [1300]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.097328,	
2017-07-25 23:42:06,842 Epoch[41] Batch [1310]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.097331,	
2017-07-25 23:42:10,737 Epoch[41] Batch [1320]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.097392,	
2017-07-25 23:42:14,733 Epoch[41] Batch [1330]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.097658,	
2017-07-25 23:42:18,748 Epoch[41] Batch [1340]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.097653,	
2017-07-25 23:42:22,801 Epoch[41] Batch [1350]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.097652,	
2017-07-25 23:42:26,794 Epoch[41] Batch [1360]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.097621,	
2017-07-25 23:42:30,932 Epoch[41] Batch [1370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097664,	
2017-07-25 23:42:34,994 Epoch[41] Batch [1380]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.097662,	
2017-07-25 23:42:38,983 Epoch[41] Batch [1390]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.097604,	
2017-07-25 23:42:43,059 Epoch[41] Batch [1400]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.097584,	
2017-07-25 23:42:47,037 Epoch[41] Batch [1410]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.097575,	
2017-07-25 23:42:51,010 Epoch[41] Batch [1420]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.097486,	
2017-07-25 23:42:54,994 Epoch[41] Batch [1430]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.097393,	
2017-07-25 23:42:59,145 Epoch[41] Batch [1440]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.097413,	
2017-07-25 23:43:03,272 Epoch[41] Batch [1450]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097441,	
2017-07-25 23:43:07,239 Epoch[41] Batch [1460]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.097522,	
2017-07-25 23:43:11,357 Epoch[41] Batch [1470]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.097509,	
2017-07-25 23:43:15,578 Epoch[41] Batch [1480]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.097492,	
2017-07-25 23:43:17,915 Epoch[41] Train-FCNLogLoss=0.097474
2017-07-25 23:43:17,916 Epoch[41] Time cost=600.439
2017-07-25 23:43:18,825 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.params"
2017-07-25 23:43:22,427 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0042.states"
2017-07-25 23:43:27,353 Epoch[42] Batch [10]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.105462,	
2017-07-25 23:43:31,480 Epoch[42] Batch [20]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.107064,	
2017-07-25 23:43:35,458 Epoch[42] Batch [30]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.102230,	
2017-07-25 23:43:39,387 Epoch[42] Batch [40]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.099988,	
2017-07-25 23:43:43,407 Epoch[42] Batch [50]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.098672,	
2017-07-25 23:43:47,433 Epoch[42] Batch [60]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.100306,	
2017-07-25 23:43:51,335 Epoch[42] Batch [70]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.098042,	
2017-07-25 23:43:55,475 Epoch[42] Batch [80]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.097631,	
2017-07-25 23:43:59,634 Epoch[42] Batch [90]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.097931,	
2017-07-25 23:44:03,689 Epoch[42] Batch [100]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.097465,	
2017-07-25 23:44:07,732 Epoch[42] Batch [110]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.097784,	
2017-07-25 23:44:11,858 Epoch[42] Batch [120]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.097754,	
2017-07-25 23:44:15,942 Epoch[42] Batch [130]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.098112,	
2017-07-25 23:44:20,035 Epoch[42] Batch [140]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.098058,	
2017-07-25 23:44:24,277 Epoch[42] Batch [150]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.097707,	
2017-07-25 23:44:28,357 Epoch[42] Batch [160]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.098357,	
2017-07-25 23:44:32,412 Epoch[42] Batch [170]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098296,	
2017-07-25 23:44:36,792 Epoch[42] Batch [180]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.098474,	
2017-07-25 23:44:40,908 Epoch[42] Batch [190]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097995,	
2017-07-25 23:44:45,181 Epoch[42] Batch [200]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097976,	
2017-07-25 23:44:49,296 Epoch[42] Batch [210]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.097821,	
2017-07-25 23:44:53,375 Epoch[42] Batch [220]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.097755,	
2017-07-25 23:44:57,410 Epoch[42] Batch [230]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.098315,	
2017-07-25 23:45:01,534 Epoch[42] Batch [240]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.098306,	
2017-07-25 23:45:05,726 Epoch[42] Batch [250]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.098458,	
2017-07-25 23:45:09,623 Epoch[42] Batch [260]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.098411,	
2017-07-25 23:45:13,897 Epoch[42] Batch [270]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.098254,	
2017-07-25 23:45:18,040 Epoch[42] Batch [280]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.098312,	
2017-07-25 23:45:21,884 Epoch[42] Batch [290]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.098038,	
2017-07-25 23:45:25,709 Epoch[42] Batch [300]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.097839,	
2017-07-25 23:45:29,585 Epoch[42] Batch [310]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.097593,	
2017-07-25 23:45:33,431 Epoch[42] Batch [320]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.097670,	
2017-07-25 23:45:37,308 Epoch[42] Batch [330]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.097924,	
2017-07-25 23:45:41,288 Epoch[42] Batch [340]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.097752,	
2017-07-25 23:45:45,315 Epoch[42] Batch [350]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.097849,	
2017-07-25 23:45:49,337 Epoch[42] Batch [360]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097798,	
2017-07-25 23:45:53,261 Epoch[42] Batch [370]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.097744,	
2017-07-25 23:45:57,282 Epoch[42] Batch [380]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097636,	
2017-07-25 23:46:01,317 Epoch[42] Batch [390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.098105,	
2017-07-25 23:46:05,341 Epoch[42] Batch [400]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.098276,	
2017-07-25 23:46:09,389 Epoch[42] Batch [410]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.098063,	
2017-07-25 23:46:13,366 Epoch[42] Batch [420]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.098076,	
2017-07-25 23:46:17,339 Epoch[42] Batch [430]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.098092,	
2017-07-25 23:46:21,395 Epoch[42] Batch [440]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.098033,	
2017-07-25 23:46:25,525 Epoch[42] Batch [450]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.098034,	
2017-07-25 23:46:29,360 Epoch[42] Batch [460]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.097946,	
2017-07-25 23:46:33,471 Epoch[42] Batch [470]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.098058,	
2017-07-25 23:46:37,573 Epoch[42] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.097903,	
2017-07-25 23:46:41,574 Epoch[42] Batch [490]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.097805,	
2017-07-25 23:46:45,468 Epoch[42] Batch [500]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.097809,	
2017-07-25 23:46:49,654 Epoch[42] Batch [510]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.097790,	
2017-07-25 23:46:53,798 Epoch[42] Batch [520]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.097594,	
2017-07-25 23:46:57,974 Epoch[42] Batch [530]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.097596,	
2017-07-25 23:47:01,999 Epoch[42] Batch [540]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.097469,	
2017-07-25 23:47:06,067 Epoch[42] Batch [550]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.097340,	
2017-07-25 23:47:10,044 Epoch[42] Batch [560]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.097406,	
2017-07-25 23:47:14,176 Epoch[42] Batch [570]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.097411,	
2017-07-25 23:47:18,260 Epoch[42] Batch [580]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.097313,	
2017-07-25 23:47:22,267 Epoch[42] Batch [590]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.097295,	
2017-07-25 23:47:26,268 Epoch[42] Batch [600]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.097325,	
2017-07-25 23:47:30,317 Epoch[42] Batch [610]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097388,	
2017-07-25 23:47:34,339 Epoch[42] Batch [620]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.097346,	
2017-07-25 23:47:38,396 Epoch[42] Batch [630]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.097230,	
2017-07-25 23:47:42,342 Epoch[42] Batch [640]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.097002,	
2017-07-25 23:47:46,281 Epoch[42] Batch [650]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.097164,	
2017-07-25 23:47:50,304 Epoch[42] Batch [660]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.097287,	
2017-07-25 23:47:54,266 Epoch[42] Batch [670]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.097183,	
2017-07-25 23:47:58,211 Epoch[42] Batch [680]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.097067,	
2017-07-25 23:48:02,257 Epoch[42] Batch [690]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.097003,	
2017-07-25 23:48:06,295 Epoch[42] Batch [700]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096997,	
2017-07-25 23:48:10,279 Epoch[42] Batch [710]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096874,	
2017-07-25 23:48:14,427 Epoch[42] Batch [720]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.096816,	
2017-07-25 23:48:18,423 Epoch[42] Batch [730]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096737,	
2017-07-25 23:48:22,636 Epoch[42] Batch [740]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.096680,	
2017-07-25 23:48:26,597 Epoch[42] Batch [750]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096726,	
2017-07-25 23:48:30,460 Epoch[42] Batch [760]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.096668,	
2017-07-25 23:48:34,532 Epoch[42] Batch [770]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.096590,	
2017-07-25 23:48:38,524 Epoch[42] Batch [780]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.096631,	
2017-07-25 23:48:42,443 Epoch[42] Batch [790]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.096628,	
2017-07-25 23:48:46,395 Epoch[42] Batch [800]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.096557,	
2017-07-25 23:48:50,454 Epoch[42] Batch [810]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096507,	
2017-07-25 23:48:54,461 Epoch[42] Batch [820]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096425,	
2017-07-25 23:48:58,392 Epoch[42] Batch [830]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096410,	
2017-07-25 23:49:02,345 Epoch[42] Batch [840]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.096413,	
2017-07-25 23:49:06,173 Epoch[42] Batch [850]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.096373,	
2017-07-25 23:49:10,169 Epoch[42] Batch [860]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096602,	
2017-07-25 23:49:14,245 Epoch[42] Batch [870]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096612,	
2017-07-25 23:49:18,205 Epoch[42] Batch [880]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096507,	
2017-07-25 23:49:22,264 Epoch[42] Batch [890]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.096476,	
2017-07-25 23:49:26,202 Epoch[42] Batch [900]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.096449,	
2017-07-25 23:49:30,062 Epoch[42] Batch [910]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.096450,	
2017-07-25 23:49:33,946 Epoch[42] Batch [920]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.096512,	
2017-07-25 23:49:37,874 Epoch[42] Batch [930]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.096576,	
2017-07-25 23:49:41,686 Epoch[42] Batch [940]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.096512,	
2017-07-25 23:49:45,762 Epoch[42] Batch [950]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096569,	
2017-07-25 23:49:49,930 Epoch[42] Batch [960]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096656,	
2017-07-25 23:49:53,782 Epoch[42] Batch [970]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.096617,	
2017-07-25 23:49:57,759 Epoch[42] Batch [980]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.096573,	
2017-07-25 23:50:01,763 Epoch[42] Batch [990]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096579,	
2017-07-25 23:50:05,718 Epoch[42] Batch [1000]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.096535,	
2017-07-25 23:50:09,820 Epoch[42] Batch [1010]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096457,	
2017-07-25 23:50:13,894 Epoch[42] Batch [1020]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.096563,	
2017-07-25 23:50:17,962 Epoch[42] Batch [1030]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.096438,	
2017-07-25 23:50:21,956 Epoch[42] Batch [1040]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.096475,	
2017-07-25 23:50:25,995 Epoch[42] Batch [1050]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.096480,	
2017-07-25 23:50:30,128 Epoch[42] Batch [1060]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.096597,	
2017-07-25 23:50:34,131 Epoch[42] Batch [1070]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096651,	
2017-07-25 23:50:38,110 Epoch[42] Batch [1080]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.096650,	
2017-07-25 23:50:41,971 Epoch[42] Batch [1090]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.096723,	
2017-07-25 23:50:45,999 Epoch[42] Batch [1100]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.096744,	
2017-07-25 23:50:49,951 Epoch[42] Batch [1110]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.096655,	
2017-07-25 23:50:53,777 Epoch[42] Batch [1120]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.096709,	
2017-07-25 23:50:57,660 Epoch[42] Batch [1130]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.096789,	
2017-07-25 23:51:01,600 Epoch[42] Batch [1140]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.096840,	
2017-07-25 23:51:05,569 Epoch[42] Batch [1150]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.096915,	
2017-07-25 23:51:09,613 Epoch[42] Batch [1160]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.096863,	
2017-07-25 23:51:13,734 Epoch[42] Batch [1170]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.096921,	
2017-07-25 23:51:17,858 Epoch[42] Batch [1180]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.096872,	
2017-07-25 23:51:22,137 Epoch[42] Batch [1190]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.096922,	
2017-07-25 23:51:26,455 Epoch[42] Batch [1200]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096915,	
2017-07-25 23:51:30,705 Epoch[42] Batch [1210]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.096955,	
2017-07-25 23:51:34,602 Epoch[42] Batch [1220]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.096851,	
2017-07-25 23:51:38,639 Epoch[42] Batch [1230]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096795,	
2017-07-25 23:51:42,673 Epoch[42] Batch [1240]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.096850,	
2017-07-25 23:51:46,613 Epoch[42] Batch [1250]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.096810,	
2017-07-25 23:51:50,711 Epoch[42] Batch [1260]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.096843,	
2017-07-25 23:51:54,758 Epoch[42] Batch [1270]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.096878,	
2017-07-25 23:51:58,908 Epoch[42] Batch [1280]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096823,	
2017-07-25 23:52:02,912 Epoch[42] Batch [1290]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096850,	
2017-07-25 23:52:06,803 Epoch[42] Batch [1300]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.096869,	
2017-07-25 23:52:10,875 Epoch[42] Batch [1310]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.096803,	
2017-07-25 23:52:14,810 Epoch[42] Batch [1320]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096789,	
2017-07-25 23:52:18,826 Epoch[42] Batch [1330]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.096782,	
2017-07-25 23:52:22,773 Epoch[42] Batch [1340]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.096765,	
2017-07-25 23:52:26,737 Epoch[42] Batch [1350]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096744,	
2017-07-25 23:52:30,861 Epoch[42] Batch [1360]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.096701,	
2017-07-25 23:52:34,893 Epoch[42] Batch [1370]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.096731,	
2017-07-25 23:52:38,881 Epoch[42] Batch [1380]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.096860,	
2017-07-25 23:52:42,919 Epoch[42] Batch [1390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096806,	
2017-07-25 23:52:46,815 Epoch[42] Batch [1400]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.096867,	
2017-07-25 23:52:50,755 Epoch[42] Batch [1410]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.096831,	
2017-07-25 23:52:54,795 Epoch[42] Batch [1420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.096954,	
2017-07-25 23:52:58,726 Epoch[42] Batch [1430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096896,	
2017-07-25 23:53:02,540 Epoch[42] Batch [1440]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.096840,	
2017-07-25 23:53:06,550 Epoch[42] Batch [1450]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.096808,	
2017-07-25 23:53:10,662 Epoch[42] Batch [1460]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096831,	
2017-07-25 23:53:14,822 Epoch[42] Batch [1470]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.096808,	
2017-07-25 23:53:18,932 Epoch[42] Batch [1480]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096821,	
2017-07-25 23:53:21,345 Epoch[42] Train-FCNLogLoss=0.096788
2017-07-25 23:53:21,345 Epoch[42] Time cost=598.917
2017-07-25 23:53:22,155 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.params"
2017-07-25 23:53:25,533 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0043.states"
2017-07-25 23:53:30,397 Epoch[43] Batch [10]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.093233,	
2017-07-25 23:53:34,572 Epoch[43] Batch [20]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.094283,	
2017-07-25 23:53:38,814 Epoch[43] Batch [30]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094459,	
2017-07-25 23:53:42,751 Epoch[43] Batch [40]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094718,	
2017-07-25 23:53:46,783 Epoch[43] Batch [50]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.096080,	
2017-07-25 23:53:50,919 Epoch[43] Batch [60]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.097194,	
2017-07-25 23:53:54,988 Epoch[43] Batch [70]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095719,	
2017-07-25 23:53:58,997 Epoch[43] Batch [80]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.093475,	
2017-07-25 23:54:02,961 Epoch[43] Batch [90]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094794,	
2017-07-25 23:54:06,824 Epoch[43] Batch [100]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.093939,	
2017-07-25 23:54:10,851 Epoch[43] Batch [110]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095065,	
2017-07-25 23:54:14,747 Epoch[43] Batch [120]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095478,	
2017-07-25 23:54:18,845 Epoch[43] Batch [130]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095425,	
2017-07-25 23:54:22,811 Epoch[43] Batch [140]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095021,	
2017-07-25 23:54:26,845 Epoch[43] Batch [150]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094921,	
2017-07-25 23:54:30,848 Epoch[43] Batch [160]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094752,	
2017-07-25 23:54:34,700 Epoch[43] Batch [170]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.094565,	
2017-07-25 23:54:38,682 Epoch[43] Batch [180]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094658,	
2017-07-25 23:54:42,740 Epoch[43] Batch [190]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094033,	
2017-07-25 23:54:46,681 Epoch[43] Batch [200]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.093988,	
2017-07-25 23:54:50,692 Epoch[43] Batch [210]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.093797,	
2017-07-25 23:54:54,627 Epoch[43] Batch [220]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093444,	
2017-07-25 23:54:58,550 Epoch[43] Batch [230]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.093074,	
2017-07-25 23:55:02,513 Epoch[43] Batch [240]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.093470,	
2017-07-25 23:55:06,442 Epoch[43] Batch [250]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093701,	
2017-07-25 23:55:10,461 Epoch[43] Batch [260]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.093641,	
2017-07-25 23:55:14,405 Epoch[43] Batch [270]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.093494,	
2017-07-25 23:55:18,433 Epoch[43] Batch [280]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.093483,	
2017-07-25 23:55:22,584 Epoch[43] Batch [290]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.093450,	
2017-07-25 23:55:26,572 Epoch[43] Batch [300]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.093615,	
2017-07-25 23:55:30,844 Epoch[43] Batch [310]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.093732,	
2017-07-25 23:55:34,869 Epoch[43] Batch [320]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.093558,	
2017-07-25 23:55:38,889 Epoch[43] Batch [330]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.093576,	
2017-07-25 23:55:42,996 Epoch[43] Batch [340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.093619,	
2017-07-25 23:55:46,970 Epoch[43] Batch [350]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093686,	
2017-07-25 23:55:50,874 Epoch[43] Batch [360]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.093874,	
2017-07-25 23:55:55,101 Epoch[43] Batch [370]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094029,	
2017-07-25 23:55:59,183 Epoch[43] Batch [380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093839,	
2017-07-25 23:56:03,221 Epoch[43] Batch [390]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.093806,	
2017-07-25 23:56:07,284 Epoch[43] Batch [400]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.093574,	
2017-07-25 23:56:11,345 Epoch[43] Batch [410]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.093623,	
2017-07-25 23:56:15,240 Epoch[43] Batch [420]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093670,	
2017-07-25 23:56:19,132 Epoch[43] Batch [430]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.093850,	
2017-07-25 23:56:23,161 Epoch[43] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.093771,	
2017-07-25 23:56:27,298 Epoch[43] Batch [450]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.093616,	
2017-07-25 23:56:31,344 Epoch[43] Batch [460]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.093657,	
2017-07-25 23:56:35,389 Epoch[43] Batch [470]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.093831,	
2017-07-25 23:56:39,358 Epoch[43] Batch [480]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.093931,	
2017-07-25 23:56:43,371 Epoch[43] Batch [490]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.093885,	
2017-07-25 23:56:47,360 Epoch[43] Batch [500]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094263,	
2017-07-25 23:56:51,479 Epoch[43] Batch [510]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094135,	
2017-07-25 23:56:55,454 Epoch[43] Batch [520]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094339,	
2017-07-25 23:56:59,441 Epoch[43] Batch [530]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094324,	
2017-07-25 23:57:03,399 Epoch[43] Batch [540]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094336,	
2017-07-25 23:57:07,265 Epoch[43] Batch [550]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.094430,	
2017-07-25 23:57:11,273 Epoch[43] Batch [560]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094394,	
2017-07-25 23:57:15,316 Epoch[43] Batch [570]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094523,	
2017-07-25 23:57:19,277 Epoch[43] Batch [580]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094358,	
2017-07-25 23:57:23,213 Epoch[43] Batch [590]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094416,	
2017-07-25 23:57:27,130 Epoch[43] Batch [600]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094414,	
2017-07-25 23:57:31,053 Epoch[43] Batch [610]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094416,	
2017-07-25 23:57:35,047 Epoch[43] Batch [620]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094377,	
2017-07-25 23:57:39,010 Epoch[43] Batch [630]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094379,	
2017-07-25 23:57:43,044 Epoch[43] Batch [640]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094450,	
2017-07-25 23:57:47,124 Epoch[43] Batch [650]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094519,	
2017-07-25 23:57:51,349 Epoch[43] Batch [660]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094532,	
2017-07-25 23:57:55,288 Epoch[43] Batch [670]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094853,	
2017-07-25 23:57:59,231 Epoch[43] Batch [680]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094864,	
2017-07-25 23:58:03,263 Epoch[43] Batch [690]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.095030,	
2017-07-25 23:58:07,173 Epoch[43] Batch [700]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095177,	
2017-07-25 23:58:11,131 Epoch[43] Batch [710]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095259,	
2017-07-25 23:58:15,198 Epoch[43] Batch [720]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095161,	
2017-07-25 23:58:19,157 Epoch[43] Batch [730]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095176,	
2017-07-25 23:58:23,171 Epoch[43] Batch [740]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.095152,	
2017-07-25 23:58:27,183 Epoch[43] Batch [750]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.095120,	
2017-07-25 23:58:31,171 Epoch[43] Batch [760]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095140,	
2017-07-25 23:58:35,156 Epoch[43] Batch [770]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.095141,	
2017-07-25 23:58:39,155 Epoch[43] Batch [780]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094987,	
2017-07-25 23:58:43,324 Epoch[43] Batch [790]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094924,	
2017-07-25 23:58:47,161 Epoch[43] Batch [800]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.094874,	
2017-07-25 23:58:51,435 Epoch[43] Batch [810]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.094934,	
2017-07-25 23:58:55,642 Epoch[43] Batch [820]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.094954,	
2017-07-25 23:59:00,086 Epoch[43] Batch [830]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.095097,	
2017-07-25 23:59:04,083 Epoch[43] Batch [840]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094953,	
2017-07-25 23:59:08,309 Epoch[43] Batch [850]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.095016,	
2017-07-25 23:59:12,662 Epoch[43] Batch [860]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.095054,	
2017-07-25 23:59:16,687 Epoch[43] Batch [870]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095028,	
2017-07-25 23:59:20,854 Epoch[43] Batch [880]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095117,	
2017-07-25 23:59:24,901 Epoch[43] Batch [890]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095138,	
2017-07-25 23:59:28,966 Epoch[43] Batch [900]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.095087,	
2017-07-25 23:59:32,933 Epoch[43] Batch [910]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094910,	
2017-07-25 23:59:36,883 Epoch[43] Batch [920]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094935,	
2017-07-25 23:59:40,956 Epoch[43] Batch [930]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094960,	
2017-07-25 23:59:45,045 Epoch[43] Batch [940]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095069,	
2017-07-25 23:59:49,108 Epoch[43] Batch [950]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095219,	
2017-07-25 23:59:52,993 Epoch[43] Batch [960]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.095176,	
2017-07-25 23:59:57,154 Epoch[43] Batch [970]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.095287,	
2017-07-26 00:00:01,021 Epoch[43] Batch [980]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.095175,	
2017-07-26 00:00:05,118 Epoch[43] Batch [990]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095170,	
2017-07-26 00:00:09,134 Epoch[43] Batch [1000]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.095148,	
2017-07-26 00:00:13,123 Epoch[43] Batch [1010]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095127,	
2017-07-26 00:00:17,017 Epoch[43] Batch [1020]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095144,	
2017-07-26 00:00:21,138 Epoch[43] Batch [1030]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095101,	
2017-07-26 00:00:25,160 Epoch[43] Batch [1040]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095135,	
2017-07-26 00:00:29,143 Epoch[43] Batch [1050]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.095267,	
2017-07-26 00:00:33,038 Epoch[43] Batch [1060]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095345,	
2017-07-26 00:00:37,022 Epoch[43] Batch [1070]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.095305,	
2017-07-26 00:00:41,125 Epoch[43] Batch [1080]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095412,	
2017-07-26 00:00:45,083 Epoch[43] Batch [1090]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095509,	
2017-07-26 00:00:48,999 Epoch[43] Batch [1100]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.095571,	
2017-07-26 00:00:52,884 Epoch[43] Batch [1110]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.095583,	
2017-07-26 00:00:56,799 Epoch[43] Batch [1120]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.095615,	
2017-07-26 00:01:00,944 Epoch[43] Batch [1130]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095733,	
2017-07-26 00:01:04,963 Epoch[43] Batch [1140]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.095722,	
2017-07-26 00:01:08,864 Epoch[43] Batch [1150]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.095731,	
2017-07-26 00:01:12,994 Epoch[43] Batch [1160]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095658,	
2017-07-26 00:01:17,047 Epoch[43] Batch [1170]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.095724,	
2017-07-26 00:01:20,908 Epoch[43] Batch [1180]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.095716,	
2017-07-26 00:01:24,903 Epoch[43] Batch [1190]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095795,	
2017-07-26 00:01:28,894 Epoch[43] Batch [1200]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095823,	
2017-07-26 00:01:33,021 Epoch[43] Batch [1210]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095865,	
2017-07-26 00:01:36,869 Epoch[43] Batch [1220]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.095775,	
2017-07-26 00:01:40,848 Epoch[43] Batch [1230]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095818,	
2017-07-26 00:01:44,736 Epoch[43] Batch [1240]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.095825,	
2017-07-26 00:01:48,668 Epoch[43] Batch [1250]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.095739,	
2017-07-26 00:01:52,629 Epoch[43] Batch [1260]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.095794,	
2017-07-26 00:01:56,587 Epoch[43] Batch [1270]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095831,	
2017-07-26 00:02:00,737 Epoch[43] Batch [1280]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.095970,	
2017-07-26 00:02:04,839 Epoch[43] Batch [1290]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095988,	
2017-07-26 00:02:08,766 Epoch[43] Batch [1300]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095998,	
2017-07-26 00:02:12,586 Epoch[43] Batch [1310]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.096031,	
2017-07-26 00:02:16,531 Epoch[43] Batch [1320]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096076,	
2017-07-26 00:02:20,540 Epoch[43] Batch [1330]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.096067,	
2017-07-26 00:02:24,543 Epoch[43] Batch [1340]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096057,	
2017-07-26 00:02:28,486 Epoch[43] Batch [1350]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.096024,	
2017-07-26 00:02:32,300 Epoch[43] Batch [1360]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.096035,	
2017-07-26 00:02:36,144 Epoch[43] Batch [1370]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.096015,	
2017-07-26 00:02:40,043 Epoch[43] Batch [1380]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095968,	
2017-07-26 00:02:44,076 Epoch[43] Batch [1390]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.095895,	
2017-07-26 00:02:47,975 Epoch[43] Batch [1400]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095920,	
2017-07-26 00:02:51,964 Epoch[43] Batch [1410]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095948,	
2017-07-26 00:02:55,879 Epoch[43] Batch [1420]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.096015,	
2017-07-26 00:03:00,010 Epoch[43] Batch [1430]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.096012,	
2017-07-26 00:03:04,011 Epoch[43] Batch [1440]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.096018,	
2017-07-26 00:03:08,107 Epoch[43] Batch [1450]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095939,	
2017-07-26 00:03:12,107 Epoch[43] Batch [1460]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095925,	
2017-07-26 00:03:16,088 Epoch[43] Batch [1470]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095870,	
2017-07-26 00:03:19,970 Epoch[43] Batch [1480]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.095963,	
2017-07-26 00:03:22,347 Epoch[43] Train-FCNLogLoss=0.095944
2017-07-26 00:03:22,348 Epoch[43] Time cost=596.814
2017-07-26 00:03:23,094 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.params"
2017-07-26 00:03:26,223 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0044.states"
2017-07-26 00:03:31,085 Epoch[44] Batch [10]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.096675,	
2017-07-26 00:03:35,138 Epoch[44] Batch [20]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.098162,	
2017-07-26 00:03:39,185 Epoch[44] Batch [30]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.097258,	
2017-07-26 00:03:43,172 Epoch[44] Batch [40]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.097784,	
2017-07-26 00:03:47,325 Epoch[44] Batch [50]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.097849,	
2017-07-26 00:03:51,213 Epoch[44] Batch [60]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.098618,	
2017-07-26 00:03:55,284 Epoch[44] Batch [70]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.098850,	
2017-07-26 00:03:59,442 Epoch[44] Batch [80]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.098496,	
2017-07-26 00:04:03,302 Epoch[44] Batch [90]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.098137,	
2017-07-26 00:04:07,316 Epoch[44] Batch [100]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.097618,	
2017-07-26 00:04:11,192 Epoch[44] Batch [110]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.097844,	
2017-07-26 00:04:15,183 Epoch[44] Batch [120]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.098633,	
2017-07-26 00:04:19,179 Epoch[44] Batch [130]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.098031,	
2017-07-26 00:04:23,107 Epoch[44] Batch [140]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.098076,	
2017-07-26 00:04:27,015 Epoch[44] Batch [150]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.098106,	
2017-07-26 00:04:30,995 Epoch[44] Batch [160]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.097450,	
2017-07-26 00:04:34,930 Epoch[44] Batch [170]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.097402,	
2017-07-26 00:04:38,938 Epoch[44] Batch [180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.097388,	
2017-07-26 00:04:42,879 Epoch[44] Batch [190]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.097314,	
2017-07-26 00:04:46,848 Epoch[44] Batch [200]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.097155,	
2017-07-26 00:04:50,792 Epoch[44] Batch [210]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096793,	
2017-07-26 00:04:54,646 Epoch[44] Batch [220]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.096138,	
2017-07-26 00:04:58,582 Epoch[44] Batch [230]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.095690,	
2017-07-26 00:05:02,620 Epoch[44] Batch [240]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095860,	
2017-07-26 00:05:06,630 Epoch[44] Batch [250]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095935,	
2017-07-26 00:05:10,570 Epoch[44] Batch [260]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.095931,	
2017-07-26 00:05:14,449 Epoch[44] Batch [270]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.095982,	
2017-07-26 00:05:18,586 Epoch[44] Batch [280]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.095981,	
2017-07-26 00:05:22,486 Epoch[44] Batch [290]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.096148,	
2017-07-26 00:05:26,411 Epoch[44] Batch [300]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.096039,	
2017-07-26 00:05:30,408 Epoch[44] Batch [310]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096081,	
2017-07-26 00:05:34,419 Epoch[44] Batch [320]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.096073,	
2017-07-26 00:05:38,481 Epoch[44] Batch [330]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095848,	
2017-07-26 00:05:42,615 Epoch[44] Batch [340]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095840,	
2017-07-26 00:05:46,691 Epoch[44] Batch [350]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095536,	
2017-07-26 00:05:50,643 Epoch[44] Batch [360]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.095105,	
2017-07-26 00:05:54,672 Epoch[44] Batch [370]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095244,	
2017-07-26 00:05:58,781 Epoch[44] Batch [380]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.095214,	
2017-07-26 00:06:02,809 Epoch[44] Batch [390]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095299,	
2017-07-26 00:06:06,649 Epoch[44] Batch [400]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.095390,	
2017-07-26 00:06:10,642 Epoch[44] Batch [410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095479,	
2017-07-26 00:06:14,655 Epoch[44] Batch [420]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.095474,	
2017-07-26 00:06:18,622 Epoch[44] Batch [430]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095666,	
2017-07-26 00:06:22,626 Epoch[44] Batch [440]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.095999,	
2017-07-26 00:06:26,524 Epoch[44] Batch [450]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095786,	
2017-07-26 00:06:30,646 Epoch[44] Batch [460]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095566,	
2017-07-26 00:06:34,539 Epoch[44] Batch [470]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095525,	
2017-07-26 00:06:38,400 Epoch[44] Batch [480]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.095642,	
2017-07-26 00:06:42,369 Epoch[44] Batch [490]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.095633,	
2017-07-26 00:06:46,252 Epoch[44] Batch [500]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.095442,	
2017-07-26 00:06:50,200 Epoch[44] Batch [510]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.095697,	
2017-07-26 00:06:54,274 Epoch[44] Batch [520]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.095952,	
2017-07-26 00:06:58,202 Epoch[44] Batch [530]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096108,	
2017-07-26 00:07:02,163 Epoch[44] Batch [540]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096131,	
2017-07-26 00:07:06,086 Epoch[44] Batch [550]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.096091,	
2017-07-26 00:07:10,000 Epoch[44] Batch [560]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.096081,	
2017-07-26 00:07:14,019 Epoch[44] Batch [570]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.096078,	
2017-07-26 00:07:18,129 Epoch[44] Batch [580]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.096260,	
2017-07-26 00:07:22,066 Epoch[44] Batch [590]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.096462,	
2017-07-26 00:07:26,041 Epoch[44] Batch [600]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.096557,	
2017-07-26 00:07:30,006 Epoch[44] Batch [610]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096296,	
2017-07-26 00:07:33,882 Epoch[44] Batch [620]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.096417,	
2017-07-26 00:07:37,899 Epoch[44] Batch [630]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.096431,	
2017-07-26 00:07:41,844 Epoch[44] Batch [640]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096362,	
2017-07-26 00:07:45,756 Epoch[44] Batch [650]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.096417,	
2017-07-26 00:07:49,614 Epoch[44] Batch [660]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.096506,	
2017-07-26 00:07:53,711 Epoch[44] Batch [670]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.096506,	
2017-07-26 00:07:57,838 Epoch[44] Batch [680]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096445,	
2017-07-26 00:08:01,939 Epoch[44] Batch [690]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096466,	
2017-07-26 00:08:05,776 Epoch[44] Batch [700]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.096298,	
2017-07-26 00:08:09,698 Epoch[44] Batch [710]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.096503,	
2017-07-26 00:08:13,495 Epoch[44] Batch [720]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.096577,	
2017-07-26 00:08:17,491 Epoch[44] Batch [730]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096473,	
2017-07-26 00:08:21,425 Epoch[44] Batch [740]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096396,	
2017-07-26 00:08:25,452 Epoch[44] Batch [750]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.096447,	
2017-07-26 00:08:29,399 Epoch[44] Batch [760]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096288,	
2017-07-26 00:08:33,489 Epoch[44] Batch [770]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.096227,	
2017-07-26 00:08:37,314 Epoch[44] Batch [780]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.096209,	
2017-07-26 00:08:41,273 Epoch[44] Batch [790]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096087,	
2017-07-26 00:08:45,154 Epoch[44] Batch [800]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.095896,	
2017-07-26 00:08:49,096 Epoch[44] Batch [810]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.095851,	
2017-07-26 00:08:52,993 Epoch[44] Batch [820]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095841,	
2017-07-26 00:08:57,058 Epoch[44] Batch [830]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.095825,	
2017-07-26 00:09:01,054 Epoch[44] Batch [840]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095779,	
2017-07-26 00:09:05,079 Epoch[44] Batch [850]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095861,	
2017-07-26 00:09:09,008 Epoch[44] Batch [860]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.095781,	
2017-07-26 00:09:12,992 Epoch[44] Batch [870]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.095753,	
2017-07-26 00:09:16,994 Epoch[44] Batch [880]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095964,	
2017-07-26 00:09:21,117 Epoch[44] Batch [890]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095906,	
2017-07-26 00:09:25,088 Epoch[44] Batch [900]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.095954,	
2017-07-26 00:09:29,022 Epoch[44] Batch [910]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096085,	
2017-07-26 00:09:32,985 Epoch[44] Batch [920]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096114,	
2017-07-26 00:09:36,936 Epoch[44] Batch [930]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.096195,	
2017-07-26 00:09:40,863 Epoch[44] Batch [940]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.096260,	
2017-07-26 00:09:44,820 Epoch[44] Batch [950]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.096480,	
2017-07-26 00:09:48,780 Epoch[44] Batch [960]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096430,	
2017-07-26 00:09:52,692 Epoch[44] Batch [970]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.096486,	
2017-07-26 00:09:56,634 Epoch[44] Batch [980]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.096407,	
2017-07-26 00:10:00,646 Epoch[44] Batch [990]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.096372,	
2017-07-26 00:10:04,561 Epoch[44] Batch [1000]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.096485,	
2017-07-26 00:10:08,523 Epoch[44] Batch [1010]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096511,	
2017-07-26 00:10:12,600 Epoch[44] Batch [1020]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.096499,	
2017-07-26 00:10:16,583 Epoch[44] Batch [1030]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096492,	
2017-07-26 00:10:20,504 Epoch[44] Batch [1040]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.096484,	
2017-07-26 00:10:24,467 Epoch[44] Batch [1050]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096442,	
2017-07-26 00:10:28,570 Epoch[44] Batch [1060]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096466,	
2017-07-26 00:10:32,658 Epoch[44] Batch [1070]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.096411,	
2017-07-26 00:10:36,636 Epoch[44] Batch [1080]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.096302,	
2017-07-26 00:10:40,753 Epoch[44] Batch [1090]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.096330,	
2017-07-26 00:10:44,934 Epoch[44] Batch [1100]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.096305,	
2017-07-26 00:10:49,014 Epoch[44] Batch [1110]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.096309,	
2017-07-26 00:10:53,037 Epoch[44] Batch [1120]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096405,	
2017-07-26 00:10:57,255 Epoch[44] Batch [1130]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.096359,	
2017-07-26 00:11:01,121 Epoch[44] Batch [1140]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.096324,	
2017-07-26 00:11:05,105 Epoch[44] Batch [1150]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096243,	
2017-07-26 00:11:09,163 Epoch[44] Batch [1160]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.096282,	
2017-07-26 00:11:12,995 Epoch[44] Batch [1170]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.096253,	
2017-07-26 00:11:17,080 Epoch[44] Batch [1180]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.096232,	
2017-07-26 00:11:21,064 Epoch[44] Batch [1190]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096285,	
2017-07-26 00:11:25,047 Epoch[44] Batch [1200]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096443,	
2017-07-26 00:11:29,042 Epoch[44] Batch [1210]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096392,	
2017-07-26 00:11:33,208 Epoch[44] Batch [1220]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096444,	
2017-07-26 00:11:37,231 Epoch[44] Batch [1230]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096373,	
2017-07-26 00:11:41,260 Epoch[44] Batch [1240]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.096302,	
2017-07-26 00:11:45,322 Epoch[44] Batch [1250]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.096272,	
2017-07-26 00:11:49,280 Epoch[44] Batch [1260]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.096260,	
2017-07-26 00:11:53,371 Epoch[44] Batch [1270]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.096233,	
2017-07-26 00:11:57,396 Epoch[44] Batch [1280]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096344,	
2017-07-26 00:12:01,499 Epoch[44] Batch [1290]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096341,	
2017-07-26 00:12:05,490 Epoch[44] Batch [1300]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.096278,	
2017-07-26 00:12:09,378 Epoch[44] Batch [1310]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.096232,	
2017-07-26 00:12:13,341 Epoch[44] Batch [1320]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096233,	
2017-07-26 00:12:17,282 Epoch[44] Batch [1330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.096245,	
2017-07-26 00:12:21,157 Epoch[44] Batch [1340]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.096232,	
2017-07-26 00:12:25,050 Epoch[44] Batch [1350]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.096260,	
2017-07-26 00:12:28,995 Epoch[44] Batch [1360]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096206,	
2017-07-26 00:12:32,963 Epoch[44] Batch [1370]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.096395,	
2017-07-26 00:12:36,953 Epoch[44] Batch [1380]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.096369,	
2017-07-26 00:12:41,048 Epoch[44] Batch [1390]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.096389,	
2017-07-26 00:12:45,050 Epoch[44] Batch [1400]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.096331,	
2017-07-26 00:12:48,984 Epoch[44] Batch [1410]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096369,	
2017-07-26 00:12:53,008 Epoch[44] Batch [1420]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096339,	
2017-07-26 00:12:56,975 Epoch[44] Batch [1430]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.096328,	
2017-07-26 00:13:00,909 Epoch[44] Batch [1440]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.096363,	
2017-07-26 00:13:04,785 Epoch[44] Batch [1450]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.096368,	
2017-07-26 00:13:08,811 Epoch[44] Batch [1460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.096413,	
2017-07-26 00:13:12,836 Epoch[44] Batch [1470]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096375,	
2017-07-26 00:13:16,783 Epoch[44] Batch [1480]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096355,	
2017-07-26 00:13:19,181 Epoch[44] Train-FCNLogLoss=0.096351
2017-07-26 00:13:19,181 Epoch[44] Time cost=592.958
2017-07-26 00:13:19,892 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0045.params"
2017-07-26 00:13:23,059 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0045.states"
2017-07-26 00:13:27,759 Epoch[45] Batch [10]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.089228,	
2017-07-26 00:13:31,657 Epoch[45] Batch [20]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.084451,	
2017-07-26 00:13:35,727 Epoch[45] Batch [30]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.086940,	
2017-07-26 00:13:39,894 Epoch[45] Batch [40]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.089304,	
2017-07-26 00:13:43,872 Epoch[45] Batch [50]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.090696,	
2017-07-26 00:13:47,811 Epoch[45] Batch [60]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.090939,	
2017-07-26 00:13:51,906 Epoch[45] Batch [70]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.091553,	
2017-07-26 00:13:56,003 Epoch[45] Batch [80]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.090524,	
2017-07-26 00:13:59,965 Epoch[45] Batch [90]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.091028,	
2017-07-26 00:14:03,906 Epoch[45] Batch [100]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.091287,	
2017-07-26 00:14:07,944 Epoch[45] Batch [110]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.091249,	
2017-07-26 00:14:11,996 Epoch[45] Batch [120]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.092229,	
2017-07-26 00:14:15,992 Epoch[45] Batch [130]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.093174,	
2017-07-26 00:14:19,956 Epoch[45] Batch [140]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.093461,	
2017-07-26 00:14:23,776 Epoch[45] Batch [150]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.093695,	
2017-07-26 00:14:27,859 Epoch[45] Batch [160]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094113,	
2017-07-26 00:14:31,753 Epoch[45] Batch [170]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094240,	
2017-07-26 00:14:35,765 Epoch[45] Batch [180]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094529,	
2017-07-26 00:14:39,716 Epoch[45] Batch [190]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094383,	
2017-07-26 00:14:43,770 Epoch[45] Batch [200]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094258,	
2017-07-26 00:14:47,706 Epoch[45] Batch [210]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094032,	
2017-07-26 00:14:51,649 Epoch[45] Batch [220]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094056,	
2017-07-26 00:14:55,693 Epoch[45] Batch [230]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094384,	
2017-07-26 00:14:59,585 Epoch[45] Batch [240]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.094701,	
2017-07-26 00:15:03,483 Epoch[45] Batch [250]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.094388,	
2017-07-26 00:15:07,474 Epoch[45] Batch [260]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094218,	
2017-07-26 00:15:11,393 Epoch[45] Batch [270]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094263,	
2017-07-26 00:15:15,425 Epoch[45] Batch [280]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094564,	
2017-07-26 00:15:19,482 Epoch[45] Batch [290]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094564,	
2017-07-26 00:15:23,540 Epoch[45] Batch [300]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094350,	
2017-07-26 00:15:27,463 Epoch[45] Batch [310]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094317,	
2017-07-26 00:15:31,510 Epoch[45] Batch [320]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094268,	
2017-07-26 00:15:35,431 Epoch[45] Batch [330]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094124,	
2017-07-26 00:15:39,537 Epoch[45] Batch [340]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094099,	
2017-07-26 00:15:43,547 Epoch[45] Batch [350]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094086,	
2017-07-26 00:15:47,534 Epoch[45] Batch [360]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094059,	
2017-07-26 00:15:51,424 Epoch[45] Batch [370]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.094232,	
2017-07-26 00:15:55,368 Epoch[45] Batch [380]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094027,	
2017-07-26 00:15:59,272 Epoch[45] Batch [390]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094191,	
2017-07-26 00:16:03,316 Epoch[45] Batch [400]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094256,	
2017-07-26 00:16:07,279 Epoch[45] Batch [410]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094470,	
2017-07-26 00:16:11,226 Epoch[45] Batch [420]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094586,	
2017-07-26 00:16:15,145 Epoch[45] Batch [430]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094553,	
2017-07-26 00:16:19,217 Epoch[45] Batch [440]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094539,	
2017-07-26 00:16:23,044 Epoch[45] Batch [450]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.094774,	
2017-07-26 00:16:27,171 Epoch[45] Batch [460]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095169,	
2017-07-26 00:16:31,185 Epoch[45] Batch [470]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.095073,	
2017-07-26 00:16:35,168 Epoch[45] Batch [480]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.095168,	
2017-07-26 00:16:39,146 Epoch[45] Batch [490]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095021,	
2017-07-26 00:16:43,165 Epoch[45] Batch [500]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094995,	
2017-07-26 00:16:47,205 Epoch[45] Batch [510]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094972,	
2017-07-26 00:16:51,219 Epoch[45] Batch [520]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094822,	
2017-07-26 00:16:55,115 Epoch[45] Batch [530]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094922,	
2017-07-26 00:16:59,039 Epoch[45] Batch [540]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.095008,	
2017-07-26 00:17:02,995 Epoch[45] Batch [550]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094954,	
2017-07-26 00:17:06,966 Epoch[45] Batch [560]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094949,	
2017-07-26 00:17:10,950 Epoch[45] Batch [570]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094980,	
2017-07-26 00:17:14,956 Epoch[45] Batch [580]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094878,	
2017-07-26 00:17:19,051 Epoch[45] Batch [590]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094897,	
2017-07-26 00:17:23,111 Epoch[45] Batch [600]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094734,	
2017-07-26 00:17:27,038 Epoch[45] Batch [610]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.094837,	
2017-07-26 00:17:31,088 Epoch[45] Batch [620]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094872,	
2017-07-26 00:17:35,111 Epoch[45] Batch [630]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094939,	
2017-07-26 00:17:39,057 Epoch[45] Batch [640]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.095049,	
2017-07-26 00:17:43,078 Epoch[45] Batch [650]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094982,	
2017-07-26 00:17:47,098 Epoch[45] Batch [660]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095227,	
2017-07-26 00:17:50,992 Epoch[45] Batch [670]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095206,	
2017-07-26 00:17:54,956 Epoch[45] Batch [680]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095088,	
2017-07-26 00:17:58,953 Epoch[45] Batch [690]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095256,	
2017-07-26 00:18:02,785 Epoch[45] Batch [700]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.095175,	
2017-07-26 00:18:06,757 Epoch[45] Batch [710]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.095186,	
2017-07-26 00:18:10,647 Epoch[45] Batch [720]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.095216,	
2017-07-26 00:18:14,650 Epoch[45] Batch [730]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095235,	
2017-07-26 00:18:18,639 Epoch[45] Batch [740]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095191,	
2017-07-26 00:18:22,650 Epoch[45] Batch [750]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.095195,	
2017-07-26 00:18:26,793 Epoch[45] Batch [760]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095093,	
2017-07-26 00:18:30,732 Epoch[45] Batch [770]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.095037,	
2017-07-26 00:18:34,681 Epoch[45] Batch [780]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.095046,	
2017-07-26 00:18:38,595 Epoch[45] Batch [790]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.094999,	
2017-07-26 00:18:42,548 Epoch[45] Batch [800]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094850,	
2017-07-26 00:18:46,454 Epoch[45] Batch [810]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094829,	
2017-07-26 00:18:50,494 Epoch[45] Batch [820]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094750,	
2017-07-26 00:18:54,753 Epoch[45] Batch [830]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094761,	
2017-07-26 00:18:58,829 Epoch[45] Batch [840]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094746,	
2017-07-26 00:19:02,838 Epoch[45] Batch [850]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094756,	
2017-07-26 00:19:06,719 Epoch[45] Batch [860]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094672,	
2017-07-26 00:19:10,721 Epoch[45] Batch [870]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.094624,	
2017-07-26 00:19:14,694 Epoch[45] Batch [880]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094614,	
2017-07-26 00:19:18,707 Epoch[45] Batch [890]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094578,	
2017-07-26 00:19:22,740 Epoch[45] Batch [900]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094512,	
2017-07-26 00:19:26,643 Epoch[45] Batch [910]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094616,	
2017-07-26 00:19:30,514 Epoch[45] Batch [920]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.094668,	
2017-07-26 00:19:34,537 Epoch[45] Batch [930]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094822,	
2017-07-26 00:19:38,591 Epoch[45] Batch [940]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094797,	
2017-07-26 00:19:42,581 Epoch[45] Batch [950]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094708,	
2017-07-26 00:19:46,413 Epoch[45] Batch [960]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.094696,	
2017-07-26 00:19:50,512 Epoch[45] Batch [970]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094692,	
2017-07-26 00:19:54,388 Epoch[45] Batch [980]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.094649,	
2017-07-26 00:19:58,356 Epoch[45] Batch [990]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094925,	
2017-07-26 00:20:02,302 Epoch[45] Batch [1000]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094842,	
2017-07-26 00:20:06,243 Epoch[45] Batch [1010]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094871,	
2017-07-26 00:20:10,283 Epoch[45] Batch [1020]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094953,	
2017-07-26 00:20:14,324 Epoch[45] Batch [1030]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094861,	
2017-07-26 00:20:18,404 Epoch[45] Batch [1040]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094809,	
2017-07-26 00:20:22,401 Epoch[45] Batch [1050]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094765,	
2017-07-26 00:20:26,421 Epoch[45] Batch [1060]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094782,	
2017-07-26 00:20:30,430 Epoch[45] Batch [1070]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094735,	
2017-07-26 00:20:34,512 Epoch[45] Batch [1080]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094748,	
2017-07-26 00:20:38,442 Epoch[45] Batch [1090]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094879,	
2017-07-26 00:20:42,387 Epoch[45] Batch [1100]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094926,	
2017-07-26 00:20:46,375 Epoch[45] Batch [1110]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095052,	
2017-07-26 00:20:50,264 Epoch[45] Batch [1120]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.095080,	
2017-07-26 00:20:54,293 Epoch[45] Batch [1130]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095154,	
2017-07-26 00:20:58,302 Epoch[45] Batch [1140]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095160,	
2017-07-26 00:21:02,256 Epoch[45] Batch [1150]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.095217,	
2017-07-26 00:21:06,176 Epoch[45] Batch [1160]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.095188,	
2017-07-26 00:21:10,027 Epoch[45] Batch [1170]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.095176,	
2017-07-26 00:21:13,899 Epoch[45] Batch [1180]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.095220,	
2017-07-26 00:21:18,022 Epoch[45] Batch [1190]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095230,	
2017-07-26 00:21:22,077 Epoch[45] Batch [1200]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.095166,	
2017-07-26 00:21:26,146 Epoch[45] Batch [1210]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095271,	
2017-07-26 00:21:30,108 Epoch[45] Batch [1220]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.095298,	
2017-07-26 00:21:34,073 Epoch[45] Batch [1230]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095242,	
2017-07-26 00:21:38,107 Epoch[45] Batch [1240]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.095355,	
2017-07-26 00:21:42,008 Epoch[45] Batch [1250]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.095327,	
2017-07-26 00:21:46,010 Epoch[45] Batch [1260]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.095307,	
2017-07-26 00:21:49,916 Epoch[45] Batch [1270]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.095137,	
2017-07-26 00:21:53,911 Epoch[45] Batch [1280]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095144,	
2017-07-26 00:21:57,767 Epoch[45] Batch [1290]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.095130,	
2017-07-26 00:22:01,781 Epoch[45] Batch [1300]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.095198,	
2017-07-26 00:22:05,844 Epoch[45] Batch [1310]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095238,	
2017-07-26 00:22:09,699 Epoch[45] Batch [1320]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.095151,	
2017-07-26 00:22:13,840 Epoch[45] Batch [1330]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095164,	
2017-07-26 00:22:17,866 Epoch[45] Batch [1340]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095083,	
2017-07-26 00:22:21,746 Epoch[45] Batch [1350]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.095037,	
2017-07-26 00:22:25,640 Epoch[45] Batch [1360]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.095021,	
2017-07-26 00:22:29,596 Epoch[45] Batch [1370]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094997,	
2017-07-26 00:22:33,671 Epoch[45] Batch [1380]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095026,	
2017-07-26 00:22:37,533 Epoch[45] Batch [1390]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.095065,	
2017-07-26 00:22:41,569 Epoch[45] Batch [1400]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094996,	
2017-07-26 00:22:45,600 Epoch[45] Batch [1410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094993,	
2017-07-26 00:22:49,639 Epoch[45] Batch [1420]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.095009,	
2017-07-26 00:22:53,581 Epoch[45] Batch [1430]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094947,	
2017-07-26 00:22:57,667 Epoch[45] Batch [1440]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.094876,	
2017-07-26 00:23:01,716 Epoch[45] Batch [1450]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094843,	
2017-07-26 00:23:05,745 Epoch[45] Batch [1460]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094814,	
2017-07-26 00:23:09,740 Epoch[45] Batch [1470]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094890,	
2017-07-26 00:23:13,737 Epoch[45] Batch [1480]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094865,	
2017-07-26 00:23:16,062 Epoch[45] Train-FCNLogLoss=0.094833
2017-07-26 00:23:16,062 Epoch[45] Time cost=593.002
2017-07-26 00:23:16,811 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0046.params"
2017-07-26 00:23:20,112 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0046.states"
2017-07-26 00:23:24,719 Epoch[46] Batch [10]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.099277,	
2017-07-26 00:23:28,762 Epoch[46] Batch [20]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.092194,	
2017-07-26 00:23:32,807 Epoch[46] Batch [30]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095971,	
2017-07-26 00:23:36,841 Epoch[46] Batch [40]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.092905,	
2017-07-26 00:23:40,811 Epoch[46] Batch [50]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094437,	
2017-07-26 00:23:44,805 Epoch[46] Batch [60]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.093790,	
2017-07-26 00:23:48,691 Epoch[46] Batch [70]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093521,	
2017-07-26 00:23:52,652 Epoch[46] Batch [80]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094408,	
2017-07-26 00:23:56,619 Epoch[46] Batch [90]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.094428,	
2017-07-26 00:24:00,584 Epoch[46] Batch [100]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.093608,	
2017-07-26 00:24:04,610 Epoch[46] Batch [110]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.092864,	
2017-07-26 00:24:08,699 Epoch[46] Batch [120]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.092904,	
2017-07-26 00:24:12,629 Epoch[46] Batch [130]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.093685,	
2017-07-26 00:24:16,486 Epoch[46] Batch [140]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.094572,	
2017-07-26 00:24:20,594 Epoch[46] Batch [150]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094144,	
2017-07-26 00:24:24,464 Epoch[46] Batch [160]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.095002,	
2017-07-26 00:24:28,441 Epoch[46] Batch [170]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094582,	
2017-07-26 00:24:32,442 Epoch[46] Batch [180]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095021,	
2017-07-26 00:24:36,531 Epoch[46] Batch [190]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095646,	
2017-07-26 00:24:40,437 Epoch[46] Batch [200]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.095783,	
2017-07-26 00:24:44,483 Epoch[46] Batch [210]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095655,	
2017-07-26 00:24:48,366 Epoch[46] Batch [220]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.096078,	
2017-07-26 00:24:52,286 Epoch[46] Batch [230]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.095998,	
2017-07-26 00:24:56,360 Epoch[46] Batch [240]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.095978,	
2017-07-26 00:25:00,420 Epoch[46] Batch [250]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095828,	
2017-07-26 00:25:04,410 Epoch[46] Batch [260]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095899,	
2017-07-26 00:25:08,561 Epoch[46] Batch [270]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096079,	
2017-07-26 00:25:12,580 Epoch[46] Batch [280]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095866,	
2017-07-26 00:25:16,604 Epoch[46] Batch [290]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.096091,	
2017-07-26 00:25:20,513 Epoch[46] Batch [300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095947,	
2017-07-26 00:25:24,590 Epoch[46] Batch [310]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095566,	
2017-07-26 00:25:28,591 Epoch[46] Batch [320]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095425,	
2017-07-26 00:25:32,579 Epoch[46] Batch [330]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095383,	
2017-07-26 00:25:36,555 Epoch[46] Batch [340]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095405,	
2017-07-26 00:25:40,727 Epoch[46] Batch [350]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.095642,	
2017-07-26 00:25:44,782 Epoch[46] Batch [360]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.095438,	
2017-07-26 00:25:48,823 Epoch[46] Batch [370]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.095312,	
2017-07-26 00:25:52,825 Epoch[46] Batch [380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095205,	
2017-07-26 00:25:56,823 Epoch[46] Batch [390]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095132,	
2017-07-26 00:26:00,789 Epoch[46] Batch [400]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094992,	
2017-07-26 00:26:04,747 Epoch[46] Batch [410]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095016,	
2017-07-26 00:26:09,019 Epoch[46] Batch [420]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.095217,	
2017-07-26 00:26:13,039 Epoch[46] Batch [430]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095111,	
2017-07-26 00:26:17,229 Epoch[46] Batch [440]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095398,	
2017-07-26 00:26:21,335 Epoch[46] Batch [450]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.095476,	
2017-07-26 00:26:25,272 Epoch[46] Batch [460]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.095364,	
2017-07-26 00:26:29,274 Epoch[46] Batch [470]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095320,	
2017-07-26 00:26:33,238 Epoch[46] Batch [480]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095307,	
2017-07-26 00:26:37,158 Epoch[46] Batch [490]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.095188,	
2017-07-26 00:26:41,288 Epoch[46] Batch [500]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095043,	
2017-07-26 00:26:45,282 Epoch[46] Batch [510]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094962,	
2017-07-26 00:26:49,303 Epoch[46] Batch [520]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095057,	
2017-07-26 00:26:53,307 Epoch[46] Batch [530]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094909,	
2017-07-26 00:26:57,267 Epoch[46] Batch [540]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094746,	
2017-07-26 00:27:01,405 Epoch[46] Batch [550]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094678,	
2017-07-26 00:27:05,506 Epoch[46] Batch [560]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094737,	
2017-07-26 00:27:09,367 Epoch[46] Batch [570]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094658,	
2017-07-26 00:27:13,276 Epoch[46] Batch [580]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094634,	
2017-07-26 00:27:17,484 Epoch[46] Batch [590]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.094798,	
2017-07-26 00:27:21,486 Epoch[46] Batch [600]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095020,	
2017-07-26 00:27:25,466 Epoch[46] Batch [610]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094845,	
2017-07-26 00:27:29,340 Epoch[46] Batch [620]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.094857,	
2017-07-26 00:27:33,448 Epoch[46] Batch [630]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094686,	
2017-07-26 00:27:37,457 Epoch[46] Batch [640]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094519,	
2017-07-26 00:27:41,556 Epoch[46] Batch [650]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094500,	
2017-07-26 00:27:45,535 Epoch[46] Batch [660]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094456,	
2017-07-26 00:27:49,768 Epoch[46] Batch [670]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.094373,	
2017-07-26 00:27:53,885 Epoch[46] Batch [680]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.094294,	
2017-07-26 00:27:57,889 Epoch[46] Batch [690]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094320,	
2017-07-26 00:28:01,866 Epoch[46] Batch [700]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094401,	
2017-07-26 00:28:05,673 Epoch[46] Batch [710]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.094406,	
2017-07-26 00:28:09,696 Epoch[46] Batch [720]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094419,	
2017-07-26 00:28:13,874 Epoch[46] Batch [730]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.094353,	
2017-07-26 00:28:17,999 Epoch[46] Batch [740]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094628,	
2017-07-26 00:28:22,093 Epoch[46] Batch [750]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094656,	
2017-07-26 00:28:26,090 Epoch[46] Batch [760]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094694,	
2017-07-26 00:28:30,269 Epoch[46] Batch [770]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.094483,	
2017-07-26 00:28:34,356 Epoch[46] Batch [780]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.094354,	
2017-07-26 00:28:38,452 Epoch[46] Batch [790]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094553,	
2017-07-26 00:28:42,446 Epoch[46] Batch [800]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094526,	
2017-07-26 00:28:46,462 Epoch[46] Batch [810]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094623,	
2017-07-26 00:28:50,529 Epoch[46] Batch [820]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094651,	
2017-07-26 00:28:54,554 Epoch[46] Batch [830]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094720,	
2017-07-26 00:28:58,574 Epoch[46] Batch [840]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094694,	
2017-07-26 00:29:02,753 Epoch[46] Batch [850]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.094754,	
2017-07-26 00:29:06,851 Epoch[46] Batch [860]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094723,	
2017-07-26 00:29:10,783 Epoch[46] Batch [870]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094708,	
2017-07-26 00:29:14,665 Epoch[46] Batch [880]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094622,	
2017-07-26 00:29:18,593 Epoch[46] Batch [890]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.094712,	
2017-07-26 00:29:22,559 Epoch[46] Batch [900]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094657,	
2017-07-26 00:29:26,594 Epoch[46] Batch [910]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094736,	
2017-07-26 00:29:30,681 Epoch[46] Batch [920]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.094667,	
2017-07-26 00:29:34,866 Epoch[46] Batch [930]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.094733,	
2017-07-26 00:29:38,850 Epoch[46] Batch [940]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094710,	
2017-07-26 00:29:42,796 Epoch[46] Batch [950]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094652,	
2017-07-26 00:29:46,879 Epoch[46] Batch [960]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094605,	
2017-07-26 00:29:50,906 Epoch[46] Batch [970]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094665,	
2017-07-26 00:29:54,889 Epoch[46] Batch [980]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094707,	
2017-07-26 00:29:58,864 Epoch[46] Batch [990]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094704,	
2017-07-26 00:30:02,917 Epoch[46] Batch [1000]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094658,	
2017-07-26 00:30:06,920 Epoch[46] Batch [1010]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094496,	
2017-07-26 00:30:10,955 Epoch[46] Batch [1020]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094441,	
2017-07-26 00:30:14,898 Epoch[46] Batch [1030]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094480,	
2017-07-26 00:30:18,866 Epoch[46] Batch [1040]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094401,	
2017-07-26 00:30:22,994 Epoch[46] Batch [1050]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094433,	
2017-07-26 00:30:26,938 Epoch[46] Batch [1060]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094430,	
2017-07-26 00:30:30,889 Epoch[46] Batch [1070]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094342,	
2017-07-26 00:30:34,798 Epoch[46] Batch [1080]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094420,	
2017-07-26 00:30:38,711 Epoch[46] Batch [1090]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094438,	
2017-07-26 00:30:42,567 Epoch[46] Batch [1100]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.094495,	
2017-07-26 00:30:46,504 Epoch[46] Batch [1110]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094495,	
2017-07-26 00:30:50,384 Epoch[46] Batch [1120]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094460,	
2017-07-26 00:30:54,288 Epoch[46] Batch [1130]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094454,	
2017-07-26 00:30:58,251 Epoch[46] Batch [1140]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094549,	
2017-07-26 00:31:02,112 Epoch[46] Batch [1150]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094620,	
2017-07-26 00:31:06,135 Epoch[46] Batch [1160]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094661,	
2017-07-26 00:31:10,102 Epoch[46] Batch [1170]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094642,	
2017-07-26 00:31:14,011 Epoch[46] Batch [1180]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094592,	
2017-07-26 00:31:17,950 Epoch[46] Batch [1190]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094603,	
2017-07-26 00:31:21,980 Epoch[46] Batch [1200]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094622,	
2017-07-26 00:31:25,928 Epoch[46] Batch [1210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094610,	
2017-07-26 00:31:29,839 Epoch[46] Batch [1220]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094619,	
2017-07-26 00:31:33,891 Epoch[46] Batch [1230]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094584,	
2017-07-26 00:31:37,958 Epoch[46] Batch [1240]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094582,	
2017-07-26 00:31:42,107 Epoch[46] Batch [1250]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094576,	
2017-07-26 00:31:46,194 Epoch[46] Batch [1260]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.094570,	
2017-07-26 00:31:50,269 Epoch[46] Batch [1270]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094620,	
2017-07-26 00:31:54,208 Epoch[46] Batch [1280]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094683,	
2017-07-26 00:31:58,138 Epoch[46] Batch [1290]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094707,	
2017-07-26 00:32:02,140 Epoch[46] Batch [1300]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094716,	
2017-07-26 00:32:06,068 Epoch[46] Batch [1310]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094704,	
2017-07-26 00:32:10,041 Epoch[46] Batch [1320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094664,	
2017-07-26 00:32:14,159 Epoch[46] Batch [1330]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094671,	
2017-07-26 00:32:18,025 Epoch[46] Batch [1340]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.094637,	
2017-07-26 00:32:21,975 Epoch[46] Batch [1350]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094606,	
2017-07-26 00:32:26,052 Epoch[46] Batch [1360]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094566,	
2017-07-26 00:32:30,190 Epoch[46] Batch [1370]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094631,	
2017-07-26 00:32:34,229 Epoch[46] Batch [1380]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094692,	
2017-07-26 00:32:38,320 Epoch[46] Batch [1390]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094757,	
2017-07-26 00:32:42,308 Epoch[46] Batch [1400]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094797,	
2017-07-26 00:32:46,358 Epoch[46] Batch [1410]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094737,	
2017-07-26 00:32:50,407 Epoch[46] Batch [1420]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094782,	
2017-07-26 00:32:54,483 Epoch[46] Batch [1430]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094731,	
2017-07-26 00:32:58,436 Epoch[46] Batch [1440]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094774,	
2017-07-26 00:33:02,315 Epoch[46] Batch [1450]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094829,	
2017-07-26 00:33:06,301 Epoch[46] Batch [1460]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094787,	
2017-07-26 00:33:10,220 Epoch[46] Batch [1470]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094786,	
2017-07-26 00:33:14,104 Epoch[46] Batch [1480]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094763,	
2017-07-26 00:33:16,371 Epoch[46] Train-FCNLogLoss=0.094759
2017-07-26 00:33:16,372 Epoch[46] Time cost=596.259
2017-07-26 00:33:17,141 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0047.params"
2017-07-26 00:33:20,435 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0047.states"
2017-07-26 00:33:25,313 Epoch[47] Batch [10]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.090444,	
2017-07-26 00:33:29,532 Epoch[47] Batch [20]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.092991,	
2017-07-26 00:33:33,486 Epoch[47] Batch [30]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.095615,	
2017-07-26 00:33:37,468 Epoch[47] Batch [40]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.097572,	
2017-07-26 00:33:41,332 Epoch[47] Batch [50]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.096899,	
2017-07-26 00:33:45,397 Epoch[47] Batch [60]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.096265,	
2017-07-26 00:33:49,479 Epoch[47] Batch [70]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.097879,	
2017-07-26 00:33:53,481 Epoch[47] Batch [80]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.097845,	
2017-07-26 00:33:57,356 Epoch[47] Batch [90]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.097927,	
2017-07-26 00:34:01,301 Epoch[47] Batch [100]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096925,	
2017-07-26 00:34:05,297 Epoch[47] Batch [110]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096625,	
2017-07-26 00:34:09,156 Epoch[47] Batch [120]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.096737,	
2017-07-26 00:34:13,140 Epoch[47] Batch [130]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.096415,	
2017-07-26 00:34:17,256 Epoch[47] Batch [140]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.096372,	
2017-07-26 00:34:21,204 Epoch[47] Batch [150]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.096721,	
2017-07-26 00:34:25,316 Epoch[47] Batch [160]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096814,	
2017-07-26 00:34:29,378 Epoch[47] Batch [170]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.096412,	
2017-07-26 00:34:33,387 Epoch[47] Batch [180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.096513,	
2017-07-26 00:34:37,253 Epoch[47] Batch [190]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.096832,	
2017-07-26 00:34:41,136 Epoch[47] Batch [200]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.096286,	
2017-07-26 00:34:45,027 Epoch[47] Batch [210]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.096026,	
2017-07-26 00:34:48,813 Epoch[47] Batch [220]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.095902,	
2017-07-26 00:34:52,644 Epoch[47] Batch [230]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.096062,	
2017-07-26 00:34:56,560 Epoch[47] Batch [240]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.096022,	
2017-07-26 00:35:00,539 Epoch[47] Batch [250]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095759,	
2017-07-26 00:35:04,464 Epoch[47] Batch [260]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095921,	
2017-07-26 00:35:08,440 Epoch[47] Batch [270]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095755,	
2017-07-26 00:35:12,404 Epoch[47] Batch [280]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095704,	
2017-07-26 00:35:16,384 Epoch[47] Batch [290]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095528,	
2017-07-26 00:35:20,335 Epoch[47] Batch [300]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.095404,	
2017-07-26 00:35:24,352 Epoch[47] Batch [310]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.095051,	
2017-07-26 00:35:28,245 Epoch[47] Batch [320]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094814,	
2017-07-26 00:35:32,091 Epoch[47] Batch [330]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.094803,	
2017-07-26 00:35:36,115 Epoch[47] Batch [340]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094651,	
2017-07-26 00:35:40,211 Epoch[47] Batch [350]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094608,	
2017-07-26 00:35:44,158 Epoch[47] Batch [360]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094718,	
2017-07-26 00:35:48,114 Epoch[47] Batch [370]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094594,	
2017-07-26 00:35:52,115 Epoch[47] Batch [380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.094453,	
2017-07-26 00:35:56,006 Epoch[47] Batch [390]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.094490,	
2017-07-26 00:35:59,919 Epoch[47] Batch [400]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.094669,	
2017-07-26 00:36:03,896 Epoch[47] Batch [410]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094521,	
2017-07-26 00:36:08,053 Epoch[47] Batch [420]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094428,	
2017-07-26 00:36:12,128 Epoch[47] Batch [430]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094594,	
2017-07-26 00:36:16,186 Epoch[47] Batch [440]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094770,	
2017-07-26 00:36:20,492 Epoch[47] Batch [450]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094857,	
2017-07-26 00:36:24,479 Epoch[47] Batch [460]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094956,	
2017-07-26 00:36:28,422 Epoch[47] Batch [470]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094718,	
2017-07-26 00:36:32,319 Epoch[47] Batch [480]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095061,	
2017-07-26 00:36:36,247 Epoch[47] Batch [490]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.095047,	
2017-07-26 00:36:40,372 Epoch[47] Batch [500]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094993,	
2017-07-26 00:36:44,466 Epoch[47] Batch [510]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095036,	
2017-07-26 00:36:48,732 Epoch[47] Batch [520]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095084,	
2017-07-26 00:36:52,928 Epoch[47] Batch [530]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095061,	
2017-07-26 00:36:56,971 Epoch[47] Batch [540]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094925,	
2017-07-26 00:37:01,201 Epoch[47] Batch [550]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094734,	
2017-07-26 00:37:05,229 Epoch[47] Batch [560]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094715,	
2017-07-26 00:37:09,400 Epoch[47] Batch [570]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.094698,	
2017-07-26 00:37:13,454 Epoch[47] Batch [580]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094600,	
2017-07-26 00:37:17,609 Epoch[47] Batch [590]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094467,	
2017-07-26 00:37:21,501 Epoch[47] Batch [600]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.094625,	
2017-07-26 00:37:25,639 Epoch[47] Batch [610]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094749,	
2017-07-26 00:37:29,694 Epoch[47] Batch [620]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094949,	
2017-07-26 00:37:33,854 Epoch[47] Batch [630]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.095054,	
2017-07-26 00:37:37,848 Epoch[47] Batch [640]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095141,	
2017-07-26 00:37:41,988 Epoch[47] Batch [650]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095395,	
2017-07-26 00:37:46,076 Epoch[47] Batch [660]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095524,	
2017-07-26 00:37:50,056 Epoch[47] Batch [670]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095565,	
2017-07-26 00:37:54,174 Epoch[47] Batch [680]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095560,	
2017-07-26 00:37:58,293 Epoch[47] Batch [690]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095546,	
2017-07-26 00:38:02,338 Epoch[47] Batch [700]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095385,	
2017-07-26 00:38:06,544 Epoch[47] Batch [710]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.095510,	
2017-07-26 00:38:10,546 Epoch[47] Batch [720]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095585,	
2017-07-26 00:38:14,457 Epoch[47] Batch [730]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095628,	
2017-07-26 00:38:18,767 Epoch[47] Batch [740]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.095581,	
2017-07-26 00:38:22,744 Epoch[47] Batch [750]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095428,	
2017-07-26 00:38:26,831 Epoch[47] Batch [760]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095398,	
2017-07-26 00:38:30,686 Epoch[47] Batch [770]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.095375,	
2017-07-26 00:38:34,853 Epoch[47] Batch [780]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095456,	
2017-07-26 00:38:38,842 Epoch[47] Batch [790]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095472,	
2017-07-26 00:38:42,973 Epoch[47] Batch [800]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095602,	
2017-07-26 00:38:47,108 Epoch[47] Batch [810]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095646,	
2017-07-26 00:38:51,263 Epoch[47] Batch [820]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095583,	
2017-07-26 00:38:55,510 Epoch[47] Batch [830]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.095659,	
2017-07-26 00:38:59,622 Epoch[47] Batch [840]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095584,	
2017-07-26 00:39:03,588 Epoch[47] Batch [850]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095561,	
2017-07-26 00:39:07,717 Epoch[47] Batch [860]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095478,	
2017-07-26 00:39:11,709 Epoch[47] Batch [870]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095454,	
2017-07-26 00:39:15,599 Epoch[47] Batch [880]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.095363,	
2017-07-26 00:39:19,723 Epoch[47] Batch [890]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095332,	
2017-07-26 00:39:23,900 Epoch[47] Batch [900]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.095387,	
2017-07-26 00:39:28,206 Epoch[47] Batch [910]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.095505,	
2017-07-26 00:39:32,118 Epoch[47] Batch [920]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.095390,	
2017-07-26 00:39:36,197 Epoch[47] Batch [930]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095427,	
2017-07-26 00:39:40,283 Epoch[47] Batch [940]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095362,	
2017-07-26 00:39:44,319 Epoch[47] Batch [950]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.095322,	
2017-07-26 00:39:48,446 Epoch[47] Batch [960]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095423,	
2017-07-26 00:39:52,453 Epoch[47] Batch [970]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095635,	
2017-07-26 00:39:56,472 Epoch[47] Batch [980]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095663,	
2017-07-26 00:40:00,808 Epoch[47] Batch [990]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.095739,	
2017-07-26 00:40:04,927 Epoch[47] Batch [1000]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095751,	
2017-07-26 00:40:09,029 Epoch[47] Batch [1010]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095700,	
2017-07-26 00:40:13,168 Epoch[47] Batch [1020]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.095635,	
2017-07-26 00:40:17,441 Epoch[47] Batch [1030]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.095689,	
2017-07-26 00:40:21,361 Epoch[47] Batch [1040]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.095826,	
2017-07-26 00:40:25,552 Epoch[47] Batch [1050]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.095775,	
2017-07-26 00:40:29,663 Epoch[47] Batch [1060]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096013,	
2017-07-26 00:40:33,928 Epoch[47] Batch [1070]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.096028,	
2017-07-26 00:40:38,029 Epoch[47] Batch [1080]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095960,	
2017-07-26 00:40:42,166 Epoch[47] Batch [1090]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.095945,	
2017-07-26 00:40:46,656 Epoch[47] Batch [1100]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.095935,	
2017-07-26 00:40:50,619 Epoch[47] Batch [1110]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.096024,	
2017-07-26 00:40:54,565 Epoch[47] Batch [1120]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096057,	
2017-07-26 00:40:58,676 Epoch[47] Batch [1130]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.096096,	
2017-07-26 00:41:02,843 Epoch[47] Batch [1140]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096035,	
2017-07-26 00:41:06,846 Epoch[47] Batch [1150]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096016,	
2017-07-26 00:41:10,806 Epoch[47] Batch [1160]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096072,	
2017-07-26 00:41:14,798 Epoch[47] Batch [1170]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.096086,	
2017-07-26 00:41:18,849 Epoch[47] Batch [1180]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.096051,	
2017-07-26 00:41:23,104 Epoch[47] Batch [1190]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.096018,	
2017-07-26 00:41:27,024 Epoch[47] Batch [1200]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.095952,	
2017-07-26 00:41:31,605 Epoch[47] Batch [1210]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.096018,	
2017-07-26 00:41:35,709 Epoch[47] Batch [1220]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096031,	
2017-07-26 00:41:39,784 Epoch[47] Batch [1230]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.096017,	
2017-07-26 00:41:43,908 Epoch[47] Batch [1240]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095956,	
2017-07-26 00:41:48,412 Epoch[47] Batch [1250]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095939,	
2017-07-26 00:41:52,511 Epoch[47] Batch [1260]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095836,	
2017-07-26 00:41:56,513 Epoch[47] Batch [1270]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.095953,	
2017-07-26 00:42:00,614 Epoch[47] Batch [1280]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095952,	
2017-07-26 00:42:04,914 Epoch[47] Batch [1290]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.095908,	
2017-07-26 00:42:09,149 Epoch[47] Batch [1300]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.096008,	
2017-07-26 00:42:13,266 Epoch[47] Batch [1310]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095948,	
2017-07-26 00:42:17,405 Epoch[47] Batch [1320]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.095913,	
2017-07-26 00:42:21,276 Epoch[47] Batch [1330]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.095861,	
2017-07-26 00:42:25,218 Epoch[47] Batch [1340]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.095778,	
2017-07-26 00:42:29,439 Epoch[47] Batch [1350]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.095765,	
2017-07-26 00:42:33,546 Epoch[47] Batch [1360]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.095831,	
2017-07-26 00:42:37,613 Epoch[47] Batch [1370]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.095762,	
2017-07-26 00:42:41,776 Epoch[47] Batch [1380]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.095722,	
2017-07-26 00:42:45,881 Epoch[47] Batch [1390]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.095816,	
2017-07-26 00:42:49,825 Epoch[47] Batch [1400]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.095829,	
2017-07-26 00:42:53,855 Epoch[47] Batch [1410]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095784,	
2017-07-26 00:42:57,829 Epoch[47] Batch [1420]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.095816,	
2017-07-26 00:43:01,801 Epoch[47] Batch [1430]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.095832,	
2017-07-26 00:43:06,001 Epoch[47] Batch [1440]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095811,	
2017-07-26 00:43:09,864 Epoch[47] Batch [1450]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.095785,	
2017-07-26 00:43:13,719 Epoch[47] Batch [1460]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.095817,	
2017-07-26 00:43:17,808 Epoch[47] Batch [1470]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095785,	
2017-07-26 00:43:21,862 Epoch[47] Batch [1480]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.095731,	
2017-07-26 00:43:24,466 Epoch[47] Train-FCNLogLoss=0.095692
2017-07-26 00:43:24,467 Epoch[47] Time cost=604.031
2017-07-26 00:43:25,437 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0048.params"
2017-07-26 00:43:29,123 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0048.states"
2017-07-26 00:43:34,000 Epoch[48] Batch [10]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.093674,	
2017-07-26 00:43:38,196 Epoch[48] Batch [20]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.091991,	
2017-07-26 00:43:42,592 Epoch[48] Batch [30]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.094336,	
2017-07-26 00:43:46,767 Epoch[48] Batch [40]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.093652,	
2017-07-26 00:43:50,989 Epoch[48] Batch [50]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.093450,	
2017-07-26 00:43:55,185 Epoch[48] Batch [60]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.093394,	
2017-07-26 00:43:59,307 Epoch[48] Batch [70]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094816,	
2017-07-26 00:44:03,516 Epoch[48] Batch [80]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.095337,	
2017-07-26 00:44:07,546 Epoch[48] Batch [90]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094816,	
2017-07-26 00:44:11,593 Epoch[48] Batch [100]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094023,	
2017-07-26 00:44:15,640 Epoch[48] Batch [110]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094258,	
2017-07-26 00:44:19,767 Epoch[48] Batch [120]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.093914,	
2017-07-26 00:44:23,795 Epoch[48] Batch [130]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094385,	
2017-07-26 00:44:27,896 Epoch[48] Batch [140]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.093949,	
2017-07-26 00:44:31,997 Epoch[48] Batch [150]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094379,	
2017-07-26 00:44:36,016 Epoch[48] Batch [160]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094288,	
2017-07-26 00:44:39,876 Epoch[48] Batch [170]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.094763,	
2017-07-26 00:44:44,435 Epoch[48] Batch [180]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.095077,	
2017-07-26 00:44:48,463 Epoch[48] Batch [190]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095559,	
2017-07-26 00:44:52,585 Epoch[48] Batch [200]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.095448,	
2017-07-26 00:44:56,536 Epoch[48] Batch [210]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.095807,	
2017-07-26 00:45:00,770 Epoch[48] Batch [220]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.096065,	
2017-07-26 00:45:04,873 Epoch[48] Batch [230]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.096030,	
2017-07-26 00:45:09,333 Epoch[48] Batch [240]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.095583,	
2017-07-26 00:45:13,816 Epoch[48] Batch [250]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.095219,	
2017-07-26 00:45:17,747 Epoch[48] Batch [260]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.095304,	
2017-07-26 00:45:21,791 Epoch[48] Batch [270]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095204,	
2017-07-26 00:45:25,844 Epoch[48] Batch [280]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.095100,	
2017-07-26 00:45:29,731 Epoch[48] Batch [290]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.095172,	
2017-07-26 00:45:33,762 Epoch[48] Batch [300]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.095059,	
2017-07-26 00:45:37,865 Epoch[48] Batch [310]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094703,	
2017-07-26 00:45:41,800 Epoch[48] Batch [320]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094729,	
2017-07-26 00:45:45,678 Epoch[48] Batch [330]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.095108,	
2017-07-26 00:45:49,663 Epoch[48] Batch [340]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094998,	
2017-07-26 00:45:53,931 Epoch[48] Batch [350]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095046,	
2017-07-26 00:45:58,058 Epoch[48] Batch [360]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095047,	
2017-07-26 00:46:02,168 Epoch[48] Batch [370]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.094901,	
2017-07-26 00:46:06,067 Epoch[48] Batch [380]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.094900,	
2017-07-26 00:46:10,081 Epoch[48] Batch [390]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094877,	
2017-07-26 00:46:14,336 Epoch[48] Batch [400]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.095001,	
2017-07-26 00:46:18,328 Epoch[48] Batch [410]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095055,	
2017-07-26 00:46:22,332 Epoch[48] Batch [420]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094929,	
2017-07-26 00:46:26,280 Epoch[48] Batch [430]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094871,	
2017-07-26 00:46:30,378 Epoch[48] Batch [440]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094750,	
2017-07-26 00:46:34,431 Epoch[48] Batch [450]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094742,	
2017-07-26 00:46:38,431 Epoch[48] Batch [460]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.094560,	
2017-07-26 00:46:43,040 Epoch[48] Batch [470]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.094736,	
2017-07-26 00:46:47,150 Epoch[48] Batch [480]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.094755,	
2017-07-26 00:46:51,223 Epoch[48] Batch [490]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094762,	
2017-07-26 00:46:55,393 Epoch[48] Batch [500]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.094700,	
2017-07-26 00:46:59,512 Epoch[48] Batch [510]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094900,	
2017-07-26 00:47:03,484 Epoch[48] Batch [520]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094861,	
2017-07-26 00:47:07,459 Epoch[48] Batch [530]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094945,	
2017-07-26 00:47:11,540 Epoch[48] Batch [540]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094986,	
2017-07-26 00:47:15,580 Epoch[48] Batch [550]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094896,	
2017-07-26 00:47:19,559 Epoch[48] Batch [560]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094915,	
2017-07-26 00:47:23,627 Epoch[48] Batch [570]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094670,	
2017-07-26 00:47:27,774 Epoch[48] Batch [580]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.094565,	
2017-07-26 00:47:31,585 Epoch[48] Batch [590]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.094637,	
2017-07-26 00:47:35,721 Epoch[48] Batch [600]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094727,	
2017-07-26 00:47:39,765 Epoch[48] Batch [610]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094620,	
2017-07-26 00:47:43,798 Epoch[48] Batch [620]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094593,	
2017-07-26 00:47:47,871 Epoch[48] Batch [630]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094636,	
2017-07-26 00:47:52,128 Epoch[48] Batch [640]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.094593,	
2017-07-26 00:47:56,079 Epoch[48] Batch [650]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094508,	
2017-07-26 00:47:59,989 Epoch[48] Batch [660]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.094555,	
2017-07-26 00:48:03,918 Epoch[48] Batch [670]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094433,	
2017-07-26 00:48:07,883 Epoch[48] Batch [680]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094361,	
2017-07-26 00:48:11,914 Epoch[48] Batch [690]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094271,	
2017-07-26 00:48:15,849 Epoch[48] Batch [700]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094088,	
2017-07-26 00:48:19,794 Epoch[48] Batch [710]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094130,	
2017-07-26 00:48:23,655 Epoch[48] Batch [720]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094118,	
2017-07-26 00:48:27,557 Epoch[48] Batch [730]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094238,	
2017-07-26 00:48:31,479 Epoch[48] Batch [740]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094346,	
2017-07-26 00:48:35,335 Epoch[48] Batch [750]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.094432,	
2017-07-26 00:48:39,399 Epoch[48] Batch [760]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094347,	
2017-07-26 00:48:43,409 Epoch[48] Batch [770]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094584,	
2017-07-26 00:48:47,259 Epoch[48] Batch [780]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.094448,	
2017-07-26 00:48:51,389 Epoch[48] Batch [790]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094684,	
2017-07-26 00:48:55,228 Epoch[48] Batch [800]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.094747,	
2017-07-26 00:48:59,142 Epoch[48] Batch [810]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.094821,	
2017-07-26 00:49:03,194 Epoch[48] Batch [820]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094856,	
2017-07-26 00:49:07,057 Epoch[48] Batch [830]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094804,	
2017-07-26 00:49:11,083 Epoch[48] Batch [840]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094725,	
2017-07-26 00:49:15,149 Epoch[48] Batch [850]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094576,	
2017-07-26 00:49:19,071 Epoch[48] Batch [860]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094585,	
2017-07-26 00:49:23,139 Epoch[48] Batch [870]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094580,	
2017-07-26 00:49:27,107 Epoch[48] Batch [880]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094629,	
2017-07-26 00:49:31,188 Epoch[48] Batch [890]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094859,	
2017-07-26 00:49:35,049 Epoch[48] Batch [900]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094779,	
2017-07-26 00:49:38,953 Epoch[48] Batch [910]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094732,	
2017-07-26 00:49:42,983 Epoch[48] Batch [920]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094730,	
2017-07-26 00:49:46,997 Epoch[48] Batch [930]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094812,	
2017-07-26 00:49:51,020 Epoch[48] Batch [940]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094990,	
2017-07-26 00:49:54,978 Epoch[48] Batch [950]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094929,	
2017-07-26 00:49:59,273 Epoch[48] Batch [960]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.095036,	
2017-07-26 00:50:03,272 Epoch[48] Batch [970]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095003,	
2017-07-26 00:50:07,767 Epoch[48] Batch [980]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.095016,	
2017-07-26 00:50:11,913 Epoch[48] Batch [990]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095025,	
2017-07-26 00:50:15,908 Epoch[48] Batch [1000]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095023,	
2017-07-26 00:50:19,985 Epoch[48] Batch [1010]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095141,	
2017-07-26 00:50:24,066 Epoch[48] Batch [1020]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.095140,	
2017-07-26 00:50:28,208 Epoch[48] Batch [1030]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095152,	
2017-07-26 00:50:32,278 Epoch[48] Batch [1040]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095171,	
2017-07-26 00:50:36,176 Epoch[48] Batch [1050]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095131,	
2017-07-26 00:50:40,134 Epoch[48] Batch [1060]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095207,	
2017-07-26 00:50:44,142 Epoch[48] Batch [1070]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095166,	
2017-07-26 00:50:48,249 Epoch[48] Batch [1080]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.095164,	
2017-07-26 00:50:52,279 Epoch[48] Batch [1090]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095153,	
2017-07-26 00:50:56,234 Epoch[48] Batch [1100]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095188,	
2017-07-26 00:51:00,191 Epoch[48] Batch [1110]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095175,	
2017-07-26 00:51:04,374 Epoch[48] Batch [1120]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095207,	
2017-07-26 00:51:08,367 Epoch[48] Batch [1130]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095181,	
2017-07-26 00:51:12,415 Epoch[48] Batch [1140]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.095228,	
2017-07-26 00:51:16,469 Epoch[48] Batch [1150]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.095283,	
2017-07-26 00:51:20,360 Epoch[48] Batch [1160]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.095282,	
2017-07-26 00:51:24,274 Epoch[48] Batch [1170]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.095298,	
2017-07-26 00:51:28,215 Epoch[48] Batch [1180]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.095328,	
2017-07-26 00:51:32,170 Epoch[48] Batch [1190]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.095316,	
2017-07-26 00:51:36,161 Epoch[48] Batch [1200]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095305,	
2017-07-26 00:51:40,153 Epoch[48] Batch [1210]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095313,	
2017-07-26 00:51:44,224 Epoch[48] Batch [1220]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095297,	
2017-07-26 00:51:48,222 Epoch[48] Batch [1230]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095326,	
2017-07-26 00:51:52,278 Epoch[48] Batch [1240]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.095458,	
2017-07-26 00:51:56,203 Epoch[48] Batch [1250]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095486,	
2017-07-26 00:52:00,095 Epoch[48] Batch [1260]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.095446,	
2017-07-26 00:52:04,124 Epoch[48] Batch [1270]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095348,	
2017-07-26 00:52:08,193 Epoch[48] Batch [1280]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095320,	
2017-07-26 00:52:12,454 Epoch[48] Batch [1290]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.095324,	
2017-07-26 00:52:16,585 Epoch[48] Batch [1300]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.095258,	
2017-07-26 00:52:20,582 Epoch[48] Batch [1310]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095206,	
2017-07-26 00:52:24,556 Epoch[48] Batch [1320]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.095195,	
2017-07-26 00:52:28,498 Epoch[48] Batch [1330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.095152,	
2017-07-26 00:52:32,353 Epoch[48] Batch [1340]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.095110,	
2017-07-26 00:52:36,302 Epoch[48] Batch [1350]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.095137,	
2017-07-26 00:52:40,178 Epoch[48] Batch [1360]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.095080,	
2017-07-26 00:52:44,147 Epoch[48] Batch [1370]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.095147,	
2017-07-26 00:52:48,091 Epoch[48] Batch [1380]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.095095,	
2017-07-26 00:52:52,125 Epoch[48] Batch [1390]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.095118,	
2017-07-26 00:52:56,032 Epoch[48] Batch [1400]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.095149,	
2017-07-26 00:52:59,964 Epoch[48] Batch [1410]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.095110,	
2017-07-26 00:53:03,865 Epoch[48] Batch [1420]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095074,	
2017-07-26 00:53:07,724 Epoch[48] Batch [1430]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.095034,	
2017-07-26 00:53:11,638 Epoch[48] Batch [1440]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.095035,	
2017-07-26 00:53:15,637 Epoch[48] Batch [1450]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095149,	
2017-07-26 00:53:19,790 Epoch[48] Batch [1460]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095118,	
2017-07-26 00:53:23,746 Epoch[48] Batch [1470]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095062,	
2017-07-26 00:53:27,745 Epoch[48] Batch [1480]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095033,	
2017-07-26 00:53:30,146 Epoch[48] Train-FCNLogLoss=0.095018
2017-07-26 00:53:30,146 Epoch[48] Time cost=601.023
2017-07-26 00:53:30,855 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0049.params"
2017-07-26 00:53:33,985 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0049.states"
2017-07-26 00:53:38,733 Epoch[49] Batch [10]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.088542,	
2017-07-26 00:53:42,640 Epoch[49] Batch [20]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.091084,	
2017-07-26 00:53:46,650 Epoch[49] Batch [30]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.088547,	
2017-07-26 00:53:50,661 Epoch[49] Batch [40]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.089026,	
2017-07-26 00:53:54,563 Epoch[49] Batch [50]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.091461,	
2017-07-26 00:53:58,621 Epoch[49] Batch [60]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.090545,	
2017-07-26 00:54:02,678 Epoch[49] Batch [70]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.089884,	
2017-07-26 00:54:06,821 Epoch[49] Batch [80]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.091479,	
2017-07-26 00:54:10,778 Epoch[49] Batch [90]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.092124,	
2017-07-26 00:54:14,756 Epoch[49] Batch [100]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.092854,	
2017-07-26 00:54:18,650 Epoch[49] Batch [110]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.093141,	
2017-07-26 00:54:22,513 Epoch[49] Batch [120]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.093262,	
2017-07-26 00:54:26,399 Epoch[49] Batch [130]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093839,	
2017-07-26 00:54:30,496 Epoch[49] Batch [140]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.093750,	
2017-07-26 00:54:34,315 Epoch[49] Batch [150]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.094000,	
2017-07-26 00:54:38,272 Epoch[49] Batch [160]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094816,	
2017-07-26 00:54:42,298 Epoch[49] Batch [170]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094429,	
2017-07-26 00:54:46,343 Epoch[49] Batch [180]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094471,	
2017-07-26 00:54:50,229 Epoch[49] Batch [190]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.094959,	
2017-07-26 00:54:54,370 Epoch[49] Batch [200]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095026,	
2017-07-26 00:54:58,566 Epoch[49] Batch [210]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.095355,	
2017-07-26 00:55:02,495 Epoch[49] Batch [220]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.095365,	
2017-07-26 00:55:06,638 Epoch[49] Batch [230]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095169,	
2017-07-26 00:55:10,833 Epoch[49] Batch [240]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094765,	
2017-07-26 00:55:14,838 Epoch[49] Batch [250]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094771,	
2017-07-26 00:55:18,850 Epoch[49] Batch [260]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094631,	
2017-07-26 00:55:22,755 Epoch[49] Batch [270]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094270,	
2017-07-26 00:55:26,846 Epoch[49] Batch [280]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.093961,	
2017-07-26 00:55:30,948 Epoch[49] Batch [290]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094317,	
2017-07-26 00:55:35,055 Epoch[49] Batch [300]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094237,	
2017-07-26 00:55:38,936 Epoch[49] Batch [310]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094100,	
2017-07-26 00:55:42,894 Epoch[49] Batch [320]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094053,	
2017-07-26 00:55:46,835 Epoch[49] Batch [330]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094106,	
2017-07-26 00:55:50,929 Epoch[49] Batch [340]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094131,	
2017-07-26 00:55:54,874 Epoch[49] Batch [350]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.093946,	
2017-07-26 00:55:58,732 Epoch[49] Batch [360]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093612,	
2017-07-26 00:56:02,863 Epoch[49] Batch [370]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.093747,	
2017-07-26 00:56:07,188 Epoch[49] Batch [380]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.093598,	
2017-07-26 00:56:11,117 Epoch[49] Batch [390]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.093507,	
2017-07-26 00:56:15,088 Epoch[49] Batch [400]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093583,	
2017-07-26 00:56:19,309 Epoch[49] Batch [410]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.093492,	
2017-07-26 00:56:23,531 Epoch[49] Batch [420]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.093466,	
2017-07-26 00:56:27,702 Epoch[49] Batch [430]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.093680,	
2017-07-26 00:56:31,756 Epoch[49] Batch [440]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.093945,	
2017-07-26 00:56:36,063 Epoch[49] Batch [450]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094206,	
2017-07-26 00:56:40,087 Epoch[49] Batch [460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094349,	
2017-07-26 00:56:44,052 Epoch[49] Batch [470]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094342,	
2017-07-26 00:56:48,098 Epoch[49] Batch [480]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094475,	
2017-07-26 00:56:51,959 Epoch[49] Batch [490]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094512,	
2017-07-26 00:56:55,966 Epoch[49] Batch [500]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094282,	
2017-07-26 00:56:59,938 Epoch[49] Batch [510]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094332,	
2017-07-26 00:57:04,003 Epoch[49] Batch [520]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094304,	
2017-07-26 00:57:08,022 Epoch[49] Batch [530]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094223,	
2017-07-26 00:57:12,494 Epoch[49] Batch [540]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.094055,	
2017-07-26 00:57:16,824 Epoch[49] Batch [550]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.094255,	
2017-07-26 00:57:20,988 Epoch[49] Batch [560]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.094266,	
2017-07-26 00:57:25,006 Epoch[49] Batch [570]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094273,	
2017-07-26 00:57:28,979 Epoch[49] Batch [580]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094414,	
2017-07-26 00:57:33,176 Epoch[49] Batch [590]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094413,	
2017-07-26 00:57:37,570 Epoch[49] Batch [600]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.094430,	
2017-07-26 00:57:41,590 Epoch[49] Batch [610]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094383,	
2017-07-26 00:57:45,782 Epoch[49] Batch [620]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.094343,	
2017-07-26 00:57:49,842 Epoch[49] Batch [630]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094388,	
2017-07-26 00:57:53,962 Epoch[49] Batch [640]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094357,	
2017-07-26 00:57:57,921 Epoch[49] Batch [650]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094361,	
2017-07-26 00:58:01,941 Epoch[49] Batch [660]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094367,	
2017-07-26 00:58:06,141 Epoch[49] Batch [670]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094282,	
2017-07-26 00:58:10,072 Epoch[49] Batch [680]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094270,	
2017-07-26 00:58:14,198 Epoch[49] Batch [690]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094437,	
2017-07-26 00:58:18,227 Epoch[49] Batch [700]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094364,	
2017-07-26 00:58:22,338 Epoch[49] Batch [710]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.094296,	
2017-07-26 00:58:26,592 Epoch[49] Batch [720]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.094271,	
2017-07-26 00:58:30,877 Epoch[49] Batch [730]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.094271,	
2017-07-26 00:58:34,985 Epoch[49] Batch [740]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094240,	
2017-07-26 00:58:39,186 Epoch[49] Batch [750]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.094425,	
2017-07-26 00:58:43,109 Epoch[49] Batch [760]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094607,	
2017-07-26 00:58:47,080 Epoch[49] Batch [770]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094630,	
2017-07-26 00:58:51,024 Epoch[49] Batch [780]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094605,	
2017-07-26 00:58:54,977 Epoch[49] Batch [790]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094494,	
2017-07-26 00:58:59,723 Epoch[49] Batch [800]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.094407,	
2017-07-26 00:59:03,793 Epoch[49] Batch [810]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094353,	
2017-07-26 00:59:08,021 Epoch[49] Batch [820]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094384,	
2017-07-26 00:59:12,359 Epoch[49] Batch [830]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.094432,	
2017-07-26 00:59:16,416 Epoch[49] Batch [840]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094411,	
2017-07-26 00:59:20,294 Epoch[49] Batch [850]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.094411,	
2017-07-26 00:59:24,460 Epoch[49] Batch [860]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094318,	
2017-07-26 00:59:28,445 Epoch[49] Batch [870]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094245,	
2017-07-26 00:59:32,427 Epoch[49] Batch [880]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094228,	
2017-07-26 00:59:36,893 Epoch[49] Batch [890]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.094180,	
2017-07-26 00:59:41,154 Epoch[49] Batch [900]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.094085,	
2017-07-26 00:59:45,685 Epoch[49] Batch [910]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.094179,	
2017-07-26 00:59:49,716 Epoch[49] Batch [920]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094295,	
2017-07-26 00:59:53,776 Epoch[49] Batch [930]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094296,	
2017-07-26 00:59:58,084 Epoch[49] Batch [940]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.094349,	
2017-07-26 01:00:02,044 Epoch[49] Batch [950]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094368,	
2017-07-26 01:00:06,130 Epoch[49] Batch [960]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.094362,	
2017-07-26 01:00:10,272 Epoch[49] Batch [970]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094569,	
2017-07-26 01:00:14,234 Epoch[49] Batch [980]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094646,	
2017-07-26 01:00:18,074 Epoch[49] Batch [990]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.094624,	
2017-07-26 01:00:22,283 Epoch[49] Batch [1000]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094641,	
2017-07-26 01:00:26,431 Epoch[49] Batch [1010]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.094621,	
2017-07-26 01:00:30,512 Epoch[49] Batch [1020]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094548,	
2017-07-26 01:00:34,577 Epoch[49] Batch [1030]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094535,	
2017-07-26 01:00:38,513 Epoch[49] Batch [1040]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094585,	
2017-07-26 01:00:42,525 Epoch[49] Batch [1050]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094605,	
2017-07-26 01:00:46,621 Epoch[49] Batch [1060]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094580,	
2017-07-26 01:00:50,897 Epoch[49] Batch [1070]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094657,	
2017-07-26 01:00:54,901 Epoch[49] Batch [1080]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094657,	
2017-07-26 01:00:58,998 Epoch[49] Batch [1090]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.094568,	
2017-07-26 01:01:03,071 Epoch[49] Batch [1100]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094658,	
2017-07-26 01:01:07,155 Epoch[49] Batch [1110]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094641,	
2017-07-26 01:01:11,435 Epoch[49] Batch [1120]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094626,	
2017-07-26 01:01:15,304 Epoch[49] Batch [1130]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.094826,	
2017-07-26 01:01:19,271 Epoch[49] Batch [1140]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094842,	
2017-07-26 01:01:23,405 Epoch[49] Batch [1150]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094818,	
2017-07-26 01:01:27,463 Epoch[49] Batch [1160]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094790,	
2017-07-26 01:01:31,480 Epoch[49] Batch [1170]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094824,	
2017-07-26 01:01:35,478 Epoch[49] Batch [1180]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094839,	
2017-07-26 01:01:39,515 Epoch[49] Batch [1190]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.094867,	
2017-07-26 01:01:43,871 Epoch[49] Batch [1200]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.094798,	
2017-07-26 01:01:47,815 Epoch[49] Batch [1210]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094812,	
2017-07-26 01:01:51,765 Epoch[49] Batch [1220]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094800,	
2017-07-26 01:01:55,822 Epoch[49] Batch [1230]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094794,	
2017-07-26 01:02:00,024 Epoch[49] Batch [1240]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.094838,	
2017-07-26 01:02:04,157 Epoch[49] Batch [1250]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094913,	
2017-07-26 01:02:08,051 Epoch[49] Batch [1260]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094919,	
2017-07-26 01:02:12,194 Epoch[49] Batch [1270]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094954,	
2017-07-26 01:02:16,410 Epoch[49] Batch [1280]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094854,	
2017-07-26 01:02:20,371 Epoch[49] Batch [1290]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094929,	
2017-07-26 01:02:24,472 Epoch[49] Batch [1300]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.094989,	
2017-07-26 01:02:28,409 Epoch[49] Batch [1310]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094897,	
2017-07-26 01:02:32,442 Epoch[49] Batch [1320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094911,	
2017-07-26 01:02:36,305 Epoch[49] Batch [1330]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.094963,	
2017-07-26 01:02:40,124 Epoch[49] Batch [1340]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.094963,	
2017-07-26 01:02:44,266 Epoch[49] Batch [1350]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.094936,	
2017-07-26 01:02:48,420 Epoch[49] Batch [1360]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095076,	
2017-07-26 01:02:52,571 Epoch[49] Batch [1370]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.095103,	
2017-07-26 01:02:56,600 Epoch[49] Batch [1380]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095055,	
2017-07-26 01:03:01,119 Epoch[49] Batch [1390]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.095059,	
2017-07-26 01:03:05,218 Epoch[49] Batch [1400]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.095059,	
2017-07-26 01:03:09,151 Epoch[49] Batch [1410]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.095039,	
2017-07-26 01:03:13,176 Epoch[49] Batch [1420]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094999,	
2017-07-26 01:03:17,248 Epoch[49] Batch [1430]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095008,	
2017-07-26 01:03:21,519 Epoch[49] Batch [1440]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.095046,	
2017-07-26 01:03:25,567 Epoch[49] Batch [1450]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094959,	
2017-07-26 01:03:29,401 Epoch[49] Batch [1460]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.095026,	
2017-07-26 01:03:33,543 Epoch[49] Batch [1470]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.095024,	
2017-07-26 01:03:37,553 Epoch[49] Batch [1480]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095035,	
2017-07-26 01:03:39,890 Epoch[49] Train-FCNLogLoss=0.094993
2017-07-26 01:03:39,890 Epoch[49] Time cost=605.904
2017-07-26 01:03:40,670 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0050.params"
2017-07-26 01:03:44,094 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0050.states"
2017-07-26 01:03:48,797 Epoch[50] Batch [10]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.095914,	
2017-07-26 01:03:52,651 Epoch[50] Batch [20]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.096518,	
2017-07-26 01:03:56,790 Epoch[50] Batch [30]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.096697,	
2017-07-26 01:04:00,872 Epoch[50] Batch [40]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094729,	
2017-07-26 01:04:05,034 Epoch[50] Batch [50]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093917,	
2017-07-26 01:04:09,122 Epoch[50] Batch [60]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.093322,	
2017-07-26 01:04:13,131 Epoch[50] Batch [70]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.092745,	
2017-07-26 01:04:17,664 Epoch[50] Batch [80]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.091749,	
2017-07-26 01:04:21,567 Epoch[50] Batch [90]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.091201,	
2017-07-26 01:04:25,803 Epoch[50] Batch [100]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.091407,	
2017-07-26 01:04:30,248 Epoch[50] Batch [110]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.091094,	
2017-07-26 01:04:34,262 Epoch[50] Batch [120]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.092779,	
2017-07-26 01:04:39,194 Epoch[50] Batch [130]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.092756,	
2017-07-26 01:04:43,195 Epoch[50] Batch [140]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.092754,	
2017-07-26 01:04:47,156 Epoch[50] Batch [150]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.092969,	
2017-07-26 01:04:51,501 Epoch[50] Batch [160]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.093223,	
2017-07-26 01:04:55,359 Epoch[50] Batch [170]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.093353,	
2017-07-26 01:04:59,453 Epoch[50] Batch [180]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094097,	
2017-07-26 01:05:03,482 Epoch[50] Batch [190]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.093681,	
2017-07-26 01:05:07,626 Epoch[50] Batch [200]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.094030,	
2017-07-26 01:05:11,855 Epoch[50] Batch [210]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.094341,	
2017-07-26 01:05:15,888 Epoch[50] Batch [220]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094248,	
2017-07-26 01:05:19,938 Epoch[50] Batch [230]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094627,	
2017-07-26 01:05:23,957 Epoch[50] Batch [240]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.095112,	
2017-07-26 01:05:28,137 Epoch[50] Batch [250]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.094762,	
2017-07-26 01:05:32,238 Epoch[50] Batch [260]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094983,	
2017-07-26 01:05:36,300 Epoch[50] Batch [270]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094982,	
2017-07-26 01:05:40,485 Epoch[50] Batch [280]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095196,	
2017-07-26 01:05:44,522 Epoch[50] Batch [290]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.095371,	
2017-07-26 01:05:48,434 Epoch[50] Batch [300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095327,	
2017-07-26 01:05:52,415 Epoch[50] Batch [310]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095703,	
2017-07-26 01:05:56,570 Epoch[50] Batch [320]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.095559,	
2017-07-26 01:06:00,630 Epoch[50] Batch [330]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095470,	
2017-07-26 01:06:04,619 Epoch[50] Batch [340]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095573,	
2017-07-26 01:06:08,899 Epoch[50] Batch [350]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095834,	
2017-07-26 01:06:12,974 Epoch[50] Batch [360]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.095766,	
2017-07-26 01:06:16,952 Epoch[50] Batch [370]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095720,	
2017-07-26 01:06:20,984 Epoch[50] Batch [380]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.095896,	
2017-07-26 01:06:25,212 Epoch[50] Batch [390]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.095753,	
2017-07-26 01:06:29,293 Epoch[50] Batch [400]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.095989,	
2017-07-26 01:06:33,378 Epoch[50] Batch [410]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.096045,	
2017-07-26 01:06:37,472 Epoch[50] Batch [420]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.096030,	
2017-07-26 01:06:41,548 Epoch[50] Batch [430]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.095970,	
2017-07-26 01:06:45,515 Epoch[50] Batch [440]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.096137,	
2017-07-26 01:06:49,549 Epoch[50] Batch [450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.096001,	
2017-07-26 01:06:53,873 Epoch[50] Batch [460]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095959,	
2017-07-26 01:06:58,035 Epoch[50] Batch [470]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.096155,	
2017-07-26 01:07:01,914 Epoch[50] Batch [480]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.096058,	
2017-07-26 01:07:06,224 Epoch[50] Batch [490]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.096022,	
2017-07-26 01:07:10,391 Epoch[50] Batch [500]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.096777,	
2017-07-26 01:07:14,443 Epoch[50] Batch [510]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.096749,	
2017-07-26 01:07:18,444 Epoch[50] Batch [520]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.096562,	
2017-07-26 01:07:22,477 Epoch[50] Batch [530]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.096669,	
2017-07-26 01:07:26,421 Epoch[50] Batch [540]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096662,	
2017-07-26 01:07:30,602 Epoch[50] Batch [550]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.096584,	
2017-07-26 01:07:34,649 Epoch[50] Batch [560]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.096405,	
2017-07-26 01:07:38,882 Epoch[50] Batch [570]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.096469,	
2017-07-26 01:07:43,207 Epoch[50] Batch [580]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.096438,	
2017-07-26 01:07:47,274 Epoch[50] Batch [590]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.096353,	
2017-07-26 01:07:51,512 Epoch[50] Batch [600]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.096450,	
2017-07-26 01:07:55,731 Epoch[50] Batch [610]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.096251,	
2017-07-26 01:07:59,927 Epoch[50] Batch [620]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.096185,	
2017-07-26 01:08:04,478 Epoch[50] Batch [630]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.096227,	
2017-07-26 01:08:08,612 Epoch[50] Batch [640]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.096125,	
2017-07-26 01:08:12,706 Epoch[50] Batch [650]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095985,	
2017-07-26 01:08:16,857 Epoch[50] Batch [660]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.096160,	
2017-07-26 01:08:21,020 Epoch[50] Batch [670]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.096050,	
2017-07-26 01:08:24,965 Epoch[50] Batch [680]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.096006,	
2017-07-26 01:08:29,092 Epoch[50] Batch [690]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.096011,	
2017-07-26 01:08:32,997 Epoch[50] Batch [700]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.096092,	
2017-07-26 01:08:36,927 Epoch[50] Batch [710]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.096006,	
2017-07-26 01:08:41,380 Epoch[50] Batch [720]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.095964,	
2017-07-26 01:08:45,469 Epoch[50] Batch [730]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095802,	
2017-07-26 01:08:49,685 Epoch[50] Batch [740]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.095786,	
2017-07-26 01:08:53,723 Epoch[50] Batch [750]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.095794,	
2017-07-26 01:08:57,679 Epoch[50] Batch [760]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095673,	
2017-07-26 01:09:01,764 Epoch[50] Batch [770]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095628,	
2017-07-26 01:09:05,688 Epoch[50] Batch [780]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095702,	
2017-07-26 01:09:09,587 Epoch[50] Batch [790]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095889,	
2017-07-26 01:09:13,681 Epoch[50] Batch [800]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095759,	
2017-07-26 01:09:17,798 Epoch[50] Batch [810]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095667,	
2017-07-26 01:09:21,982 Epoch[50] Batch [820]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.095647,	
2017-07-26 01:09:26,219 Epoch[50] Batch [830]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.095693,	
2017-07-26 01:09:30,242 Epoch[50] Batch [840]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095802,	
2017-07-26 01:09:34,442 Epoch[50] Batch [850]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.095940,	
2017-07-26 01:09:38,444 Epoch[50] Batch [860]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095881,	
2017-07-26 01:09:42,490 Epoch[50] Batch [870]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095867,	
2017-07-26 01:09:46,386 Epoch[50] Batch [880]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.095942,	
2017-07-26 01:09:50,335 Epoch[50] Batch [890]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.096043,	
2017-07-26 01:09:54,255 Epoch[50] Batch [900]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.096006,	
2017-07-26 01:09:58,351 Epoch[50] Batch [910]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095884,	
2017-07-26 01:10:02,347 Epoch[50] Batch [920]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095775,	
2017-07-26 01:10:06,247 Epoch[50] Batch [930]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095683,	
2017-07-26 01:10:10,160 Epoch[50] Batch [940]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.095649,	
2017-07-26 01:10:14,135 Epoch[50] Batch [950]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095665,	
2017-07-26 01:10:18,046 Epoch[50] Batch [960]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095608,	
2017-07-26 01:10:22,035 Epoch[50] Batch [970]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.095608,	
2017-07-26 01:10:26,105 Epoch[50] Batch [980]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095577,	
2017-07-26 01:10:30,010 Epoch[50] Batch [990]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.095576,	
2017-07-26 01:10:33,930 Epoch[50] Batch [1000]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.095657,	
2017-07-26 01:10:38,042 Epoch[50] Batch [1010]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.095742,	
2017-07-26 01:10:42,042 Epoch[50] Batch [1020]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095669,	
2017-07-26 01:10:45,984 Epoch[50] Batch [1030]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.095739,	
2017-07-26 01:10:50,034 Epoch[50] Batch [1040]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.095800,	
2017-07-26 01:10:54,257 Epoch[50] Batch [1050]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.095721,	
2017-07-26 01:10:58,200 Epoch[50] Batch [1060]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.095744,	
2017-07-26 01:11:02,137 Epoch[50] Batch [1070]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.095732,	
2017-07-26 01:11:06,041 Epoch[50] Batch [1080]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.095624,	
2017-07-26 01:11:10,109 Epoch[50] Batch [1090]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.095645,	
2017-07-26 01:11:14,238 Epoch[50] Batch [1100]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095709,	
2017-07-26 01:11:18,231 Epoch[50] Batch [1110]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095763,	
2017-07-26 01:11:22,135 Epoch[50] Batch [1120]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.095746,	
2017-07-26 01:11:26,092 Epoch[50] Batch [1130]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.095638,	
2017-07-26 01:11:30,089 Epoch[50] Batch [1140]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095653,	
2017-07-26 01:11:34,139 Epoch[50] Batch [1150]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.095592,	
2017-07-26 01:11:38,227 Epoch[50] Batch [1160]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.095585,	
2017-07-26 01:11:42,224 Epoch[50] Batch [1170]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095575,	
2017-07-26 01:11:46,063 Epoch[50] Batch [1180]	Speed: 10.42 samples/sec	Train-FCNLogLoss=0.095488,	
2017-07-26 01:11:49,975 Epoch[50] Batch [1190]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.095502,	
2017-07-26 01:11:53,910 Epoch[50] Batch [1200]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.095513,	
2017-07-26 01:11:57,825 Epoch[50] Batch [1210]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.095526,	
2017-07-26 01:12:01,803 Epoch[50] Batch [1220]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095529,	
2017-07-26 01:12:05,813 Epoch[50] Batch [1230]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.095553,	
2017-07-26 01:12:09,670 Epoch[50] Batch [1240]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.095499,	
2017-07-26 01:12:13,649 Epoch[50] Batch [1250]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095446,	
2017-07-26 01:12:17,596 Epoch[50] Batch [1260]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.095538,	
2017-07-26 01:12:21,724 Epoch[50] Batch [1270]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095540,	
2017-07-26 01:12:25,651 Epoch[50] Batch [1280]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095567,	
2017-07-26 01:12:29,510 Epoch[50] Batch [1290]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.095505,	
2017-07-26 01:12:33,806 Epoch[50] Batch [1300]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.095548,	
2017-07-26 01:12:37,835 Epoch[50] Batch [1310]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095516,	
2017-07-26 01:12:41,702 Epoch[50] Batch [1320]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.095527,	
2017-07-26 01:12:45,797 Epoch[50] Batch [1330]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095447,	
2017-07-26 01:12:49,837 Epoch[50] Batch [1340]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.095351,	
2017-07-26 01:12:53,761 Epoch[50] Batch [1350]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095322,	
2017-07-26 01:12:57,592 Epoch[50] Batch [1360]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.095412,	
2017-07-26 01:13:01,718 Epoch[50] Batch [1370]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.095413,	
2017-07-26 01:13:05,802 Epoch[50] Batch [1380]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.095367,	
2017-07-26 01:13:09,949 Epoch[50] Batch [1390]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.095282,	
2017-07-26 01:13:13,928 Epoch[50] Batch [1400]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095244,	
2017-07-26 01:13:18,302 Epoch[50] Batch [1410]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095190,	
2017-07-26 01:13:22,330 Epoch[50] Batch [1420]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095152,	
2017-07-26 01:13:26,324 Epoch[50] Batch [1430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095137,	
2017-07-26 01:13:30,264 Epoch[50] Batch [1440]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.095088,	
2017-07-26 01:13:34,297 Epoch[50] Batch [1450]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.095067,	
2017-07-26 01:13:38,610 Epoch[50] Batch [1460]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.095020,	
2017-07-26 01:13:42,644 Epoch[50] Batch [1470]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.095000,	
2017-07-26 01:13:46,712 Epoch[50] Batch [1480]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094973,	
2017-07-26 01:13:49,065 Epoch[50] Train-FCNLogLoss=0.094973
2017-07-26 01:13:49,066 Epoch[50] Time cost=604.971
2017-07-26 01:13:49,904 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0051.params"
2017-07-26 01:13:53,249 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0051.states"
2017-07-26 01:13:57,894 Epoch[51] Batch [10]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093326,	
2017-07-26 01:14:01,965 Epoch[51] Batch [20]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.092117,	
2017-07-26 01:14:05,946 Epoch[51] Batch [30]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.093693,	
2017-07-26 01:14:09,936 Epoch[51] Batch [40]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.093161,	
2017-07-26 01:14:13,856 Epoch[51] Batch [50]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094098,	
2017-07-26 01:14:17,923 Epoch[51] Batch [60]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094134,	
2017-07-26 01:14:21,944 Epoch[51] Batch [70]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.093305,	
2017-07-26 01:14:26,256 Epoch[51] Batch [80]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.093638,	
2017-07-26 01:14:30,321 Epoch[51] Batch [90]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.093501,	
2017-07-26 01:14:34,292 Epoch[51] Batch [100]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.094131,	
2017-07-26 01:14:38,405 Epoch[51] Batch [110]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.094080,	
2017-07-26 01:14:42,375 Epoch[51] Batch [120]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094511,	
2017-07-26 01:14:46,877 Epoch[51] Batch [130]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095024,	
2017-07-26 01:14:50,869 Epoch[51] Batch [140]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.095620,	
2017-07-26 01:14:55,017 Epoch[51] Batch [150]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.095200,	
2017-07-26 01:14:59,039 Epoch[51] Batch [160]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094778,	
2017-07-26 01:15:03,092 Epoch[51] Batch [170]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094553,	
2017-07-26 01:15:06,946 Epoch[51] Batch [180]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.095008,	
2017-07-26 01:15:11,162 Epoch[51] Batch [190]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094550,	
2017-07-26 01:15:15,183 Epoch[51] Batch [200]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094420,	
2017-07-26 01:15:19,181 Epoch[51] Batch [210]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094040,	
2017-07-26 01:15:23,112 Epoch[51] Batch [220]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.093545,	
2017-07-26 01:15:27,253 Epoch[51] Batch [230]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.093487,	
2017-07-26 01:15:31,472 Epoch[51] Batch [240]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.093307,	
2017-07-26 01:15:35,675 Epoch[51] Batch [250]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.093243,	
2017-07-26 01:15:39,758 Epoch[51] Batch [260]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.093757,	
2017-07-26 01:15:43,860 Epoch[51] Batch [270]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.093466,	
2017-07-26 01:15:47,923 Epoch[51] Batch [280]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.093409,	
2017-07-26 01:15:51,963 Epoch[51] Batch [290]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.093180,	
2017-07-26 01:15:56,072 Epoch[51] Batch [300]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.092890,	
2017-07-26 01:15:59,974 Epoch[51] Batch [310]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.092919,	
2017-07-26 01:16:04,061 Epoch[51] Batch [320]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.092924,	
2017-07-26 01:16:08,032 Epoch[51] Batch [330]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.092962,	
2017-07-26 01:16:12,206 Epoch[51] Batch [340]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.092552,	
2017-07-26 01:16:16,281 Epoch[51] Batch [350]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.092623,	
2017-07-26 01:16:20,279 Epoch[51] Batch [360]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.092510,	
2017-07-26 01:16:24,257 Epoch[51] Batch [370]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.092896,	
2017-07-26 01:16:28,421 Epoch[51] Batch [380]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093086,	
2017-07-26 01:16:32,539 Epoch[51] Batch [390]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.092938,	
2017-07-26 01:16:36,483 Epoch[51] Batch [400]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.092910,	
2017-07-26 01:16:40,370 Epoch[51] Batch [410]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.092860,	
2017-07-26 01:16:44,231 Epoch[51] Batch [420]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.092921,	
2017-07-26 01:16:48,377 Epoch[51] Batch [430]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.092927,	
2017-07-26 01:16:52,462 Epoch[51] Batch [440]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.092936,	
2017-07-26 01:16:56,500 Epoch[51] Batch [450]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.093106,	
2017-07-26 01:17:00,542 Epoch[51] Batch [460]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.093111,	
2017-07-26 01:17:04,485 Epoch[51] Batch [470]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.092900,	
2017-07-26 01:17:08,508 Epoch[51] Batch [480]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.093104,	
2017-07-26 01:17:12,463 Epoch[51] Batch [490]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.093117,	
2017-07-26 01:17:16,505 Epoch[51] Batch [500]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.093138,	
2017-07-26 01:17:20,665 Epoch[51] Batch [510]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.093023,	
2017-07-26 01:17:24,659 Epoch[51] Batch [520]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.093136,	
2017-07-26 01:17:28,731 Epoch[51] Batch [530]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.092992,	
2017-07-26 01:17:32,661 Epoch[51] Batch [540]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.092923,	
2017-07-26 01:17:36,544 Epoch[51] Batch [550]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.093013,	
2017-07-26 01:17:40,442 Epoch[51] Batch [560]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.093282,	
2017-07-26 01:17:44,414 Epoch[51] Batch [570]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.093335,	
2017-07-26 01:17:48,289 Epoch[51] Batch [580]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.093498,	
2017-07-26 01:17:52,266 Epoch[51] Batch [590]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.093501,	
2017-07-26 01:17:56,250 Epoch[51] Batch [600]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.093625,	
2017-07-26 01:18:00,234 Epoch[51] Batch [610]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.093684,	
2017-07-26 01:18:04,338 Epoch[51] Batch [620]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.093598,	
2017-07-26 01:18:08,252 Epoch[51] Batch [630]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.093624,	
2017-07-26 01:18:12,079 Epoch[51] Batch [640]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.093744,	
2017-07-26 01:18:16,017 Epoch[51] Batch [650]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.093871,	
2017-07-26 01:18:19,872 Epoch[51] Batch [660]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.094058,	
2017-07-26 01:18:23,895 Epoch[51] Batch [670]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094180,	
2017-07-26 01:18:27,858 Epoch[51] Batch [680]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094172,	
2017-07-26 01:18:31,954 Epoch[51] Batch [690]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094129,	
2017-07-26 01:18:35,917 Epoch[51] Batch [700]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094167,	
2017-07-26 01:18:39,926 Epoch[51] Batch [710]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094476,	
2017-07-26 01:18:43,995 Epoch[51] Batch [720]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094555,	
2017-07-26 01:18:47,893 Epoch[51] Batch [730]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.094644,	
2017-07-26 01:18:51,984 Epoch[51] Batch [740]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094610,	
2017-07-26 01:18:55,968 Epoch[51] Batch [750]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094747,	
2017-07-26 01:18:59,874 Epoch[51] Batch [760]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094742,	
2017-07-26 01:19:03,996 Epoch[51] Batch [770]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.094720,	
2017-07-26 01:19:07,960 Epoch[51] Batch [780]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094709,	
2017-07-26 01:19:12,105 Epoch[51] Batch [790]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.094697,	
2017-07-26 01:19:16,086 Epoch[51] Batch [800]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094815,	
2017-07-26 01:19:19,985 Epoch[51] Batch [810]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095042,	
2017-07-26 01:19:24,116 Epoch[51] Batch [820]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.094894,	
2017-07-26 01:19:28,281 Epoch[51] Batch [830]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095141,	
2017-07-26 01:19:32,247 Epoch[51] Batch [840]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095183,	
2017-07-26 01:19:36,291 Epoch[51] Batch [850]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.095186,	
2017-07-26 01:19:40,322 Epoch[51] Batch [860]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095210,	
2017-07-26 01:19:44,435 Epoch[51] Batch [870]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.095214,	
2017-07-26 01:19:48,442 Epoch[51] Batch [880]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095195,	
2017-07-26 01:19:52,444 Epoch[51] Batch [890]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.095143,	
2017-07-26 01:19:56,367 Epoch[51] Batch [900]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.095054,	
2017-07-26 01:20:00,290 Epoch[51] Batch [910]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.095104,	
2017-07-26 01:20:04,182 Epoch[51] Batch [920]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.095140,	
2017-07-26 01:20:08,107 Epoch[51] Batch [930]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.095096,	
2017-07-26 01:20:12,093 Epoch[51] Batch [940]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095059,	
2017-07-26 01:20:16,098 Epoch[51] Batch [950]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.095035,	
2017-07-26 01:20:19,966 Epoch[51] Batch [960]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.095155,	
2017-07-26 01:20:24,014 Epoch[51] Batch [970]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.095051,	
2017-07-26 01:20:28,101 Epoch[51] Batch [980]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.095112,	
2017-07-26 01:20:31,999 Epoch[51] Batch [990]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095134,	
2017-07-26 01:20:35,836 Epoch[51] Batch [1000]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.095029,	
2017-07-26 01:20:39,914 Epoch[51] Batch [1010]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094997,	
2017-07-26 01:20:43,996 Epoch[51] Batch [1020]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.094822,	
2017-07-26 01:20:47,851 Epoch[51] Batch [1030]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.094922,	
2017-07-26 01:20:51,714 Epoch[51] Batch [1040]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.094885,	
2017-07-26 01:20:55,735 Epoch[51] Batch [1050]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094853,	
2017-07-26 01:20:59,806 Epoch[51] Batch [1060]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094820,	
2017-07-26 01:21:03,839 Epoch[51] Batch [1070]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094792,	
2017-07-26 01:21:07,867 Epoch[51] Batch [1080]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094811,	
2017-07-26 01:21:11,891 Epoch[51] Batch [1090]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094881,	
2017-07-26 01:21:15,940 Epoch[51] Batch [1100]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094883,	
2017-07-26 01:21:19,880 Epoch[51] Batch [1110]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094988,	
2017-07-26 01:21:23,857 Epoch[51] Batch [1120]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094931,	
2017-07-26 01:21:28,043 Epoch[51] Batch [1130]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.094922,	
2017-07-26 01:21:32,028 Epoch[51] Batch [1140]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094804,	
2017-07-26 01:21:35,966 Epoch[51] Batch [1150]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094772,	
2017-07-26 01:21:39,879 Epoch[51] Batch [1160]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.094739,	
2017-07-26 01:21:43,670 Epoch[51] Batch [1170]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.094827,	
2017-07-26 01:21:47,633 Epoch[51] Batch [1180]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094880,	
2017-07-26 01:21:51,682 Epoch[51] Batch [1190]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094814,	
2017-07-26 01:21:55,672 Epoch[51] Batch [1200]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094757,	
2017-07-26 01:21:59,558 Epoch[51] Batch [1210]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094734,	
2017-07-26 01:22:03,488 Epoch[51] Batch [1220]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.094761,	
2017-07-26 01:22:07,500 Epoch[51] Batch [1230]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094775,	
2017-07-26 01:22:11,362 Epoch[51] Batch [1240]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.094735,	
2017-07-26 01:22:15,363 Epoch[51] Batch [1250]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.094758,	
2017-07-26 01:22:19,148 Epoch[51] Batch [1260]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.094661,	
2017-07-26 01:22:23,193 Epoch[51] Batch [1270]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094671,	
2017-07-26 01:22:27,148 Epoch[51] Batch [1280]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094777,	
2017-07-26 01:22:31,275 Epoch[51] Batch [1290]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094774,	
2017-07-26 01:22:35,467 Epoch[51] Batch [1300]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094711,	
2017-07-26 01:22:39,521 Epoch[51] Batch [1310]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094745,	
2017-07-26 01:22:43,703 Epoch[51] Batch [1320]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.094722,	
2017-07-26 01:22:47,793 Epoch[51] Batch [1330]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094706,	
2017-07-26 01:22:51,782 Epoch[51] Batch [1340]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094781,	
2017-07-26 01:22:55,608 Epoch[51] Batch [1350]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.094793,	
2017-07-26 01:22:59,773 Epoch[51] Batch [1360]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.094798,	
2017-07-26 01:23:03,834 Epoch[51] Batch [1370]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094792,	
2017-07-26 01:23:07,666 Epoch[51] Batch [1380]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.094809,	
2017-07-26 01:23:11,550 Epoch[51] Batch [1390]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094772,	
2017-07-26 01:23:15,598 Epoch[51] Batch [1400]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094792,	
2017-07-26 01:23:19,515 Epoch[51] Batch [1410]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.094724,	
2017-07-26 01:23:23,506 Epoch[51] Batch [1420]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094727,	
2017-07-26 01:23:27,553 Epoch[51] Batch [1430]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094704,	
2017-07-26 01:23:31,563 Epoch[51] Batch [1440]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094833,	
2017-07-26 01:23:35,725 Epoch[51] Batch [1450]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.094781,	
2017-07-26 01:23:39,662 Epoch[51] Batch [1460]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094761,	
2017-07-26 01:23:43,782 Epoch[51] Batch [1470]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094716,	
2017-07-26 01:23:47,836 Epoch[51] Batch [1480]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094758,	
2017-07-26 01:23:50,341 Epoch[51] Train-FCNLogLoss=0.094766
2017-07-26 01:23:50,341 Epoch[51] Time cost=597.091
2017-07-26 01:23:51,071 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0052.params"
2017-07-26 01:23:54,217 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0052.states"
2017-07-26 01:23:58,901 Epoch[52] Batch [10]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.103231,	
2017-07-26 01:24:02,783 Epoch[52] Batch [20]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.100014,	
2017-07-26 01:24:06,788 Epoch[52] Batch [30]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.096416,	
2017-07-26 01:24:10,842 Epoch[52] Batch [40]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094676,	
2017-07-26 01:24:14,870 Epoch[52] Batch [50]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.095511,	
2017-07-26 01:24:18,960 Epoch[52] Batch [60]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094599,	
2017-07-26 01:24:22,953 Epoch[52] Batch [70]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094406,	
2017-07-26 01:24:26,920 Epoch[52] Batch [80]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095179,	
2017-07-26 01:24:30,867 Epoch[52] Batch [90]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.095772,	
2017-07-26 01:24:34,777 Epoch[52] Batch [100]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.096205,	
2017-07-26 01:24:38,700 Epoch[52] Batch [110]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.097739,	
2017-07-26 01:24:42,629 Epoch[52] Batch [120]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.097910,	
2017-07-26 01:24:46,621 Epoch[52] Batch [130]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.097204,	
2017-07-26 01:24:50,581 Epoch[52] Batch [140]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.096991,	
2017-07-26 01:24:54,578 Epoch[52] Batch [150]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.096311,	
2017-07-26 01:24:58,485 Epoch[52] Batch [160]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.095836,	
2017-07-26 01:25:02,331 Epoch[52] Batch [170]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.095833,	
2017-07-26 01:25:06,338 Epoch[52] Batch [180]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095233,	
2017-07-26 01:25:10,305 Epoch[52] Batch [190]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.095545,	
2017-07-26 01:25:14,136 Epoch[52] Batch [200]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.095811,	
2017-07-26 01:25:18,100 Epoch[52] Batch [210]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.095908,	
2017-07-26 01:25:22,160 Epoch[52] Batch [220]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095527,	
2017-07-26 01:25:26,186 Epoch[52] Batch [230]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.095401,	
2017-07-26 01:25:30,181 Epoch[52] Batch [240]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095564,	
2017-07-26 01:25:34,177 Epoch[52] Batch [250]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.095561,	
2017-07-26 01:25:38,186 Epoch[52] Batch [260]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095344,	
2017-07-26 01:25:42,085 Epoch[52] Batch [270]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.095106,	
2017-07-26 01:25:46,014 Epoch[52] Batch [280]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.095264,	
2017-07-26 01:25:49,989 Epoch[52] Batch [290]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.095345,	
2017-07-26 01:25:54,084 Epoch[52] Batch [300]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.095363,	
2017-07-26 01:25:58,225 Epoch[52] Batch [310]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.095253,	
2017-07-26 01:26:02,204 Epoch[52] Batch [320]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.095081,	
2017-07-26 01:26:06,265 Epoch[52] Batch [330]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.095017,	
2017-07-26 01:26:10,162 Epoch[52] Batch [340]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.094729,	
2017-07-26 01:26:14,256 Epoch[52] Batch [350]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094634,	
2017-07-26 01:26:18,347 Epoch[52] Batch [360]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094354,	
2017-07-26 01:26:22,393 Epoch[52] Batch [370]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094318,	
2017-07-26 01:26:26,462 Epoch[52] Batch [380]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094288,	
2017-07-26 01:26:30,644 Epoch[52] Batch [390]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.094418,	
2017-07-26 01:26:34,715 Epoch[52] Batch [400]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094422,	
2017-07-26 01:26:38,747 Epoch[52] Batch [410]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094609,	
2017-07-26 01:26:42,946 Epoch[52] Batch [420]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094828,	
2017-07-26 01:26:46,910 Epoch[52] Batch [430]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094734,	
2017-07-26 01:26:51,005 Epoch[52] Batch [440]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.094664,	
2017-07-26 01:26:55,290 Epoch[52] Batch [450]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.094485,	
2017-07-26 01:26:59,244 Epoch[52] Batch [460]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.094556,	
2017-07-26 01:27:03,476 Epoch[52] Batch [470]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.094518,	
2017-07-26 01:27:07,580 Epoch[52] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094609,	
2017-07-26 01:27:11,447 Epoch[52] Batch [490]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.094811,	
2017-07-26 01:27:15,450 Epoch[52] Batch [500]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094680,	
2017-07-26 01:27:19,728 Epoch[52] Batch [510]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094936,	
2017-07-26 01:27:23,740 Epoch[52] Batch [520]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094913,	
2017-07-26 01:27:27,586 Epoch[52] Batch [530]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.094933,	
2017-07-26 01:27:31,591 Epoch[52] Batch [540]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094945,	
2017-07-26 01:27:35,473 Epoch[52] Batch [550]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094916,	
2017-07-26 01:27:39,378 Epoch[52] Batch [560]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094848,	
2017-07-26 01:27:43,367 Epoch[52] Batch [570]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094848,	
2017-07-26 01:27:47,495 Epoch[52] Batch [580]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094972,	
2017-07-26 01:27:51,505 Epoch[52] Batch [590]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.095013,	
2017-07-26 01:27:55,448 Epoch[52] Batch [600]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.094913,	
2017-07-26 01:27:59,632 Epoch[52] Batch [610]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.094846,	
2017-07-26 01:28:03,706 Epoch[52] Batch [620]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.094798,	
2017-07-26 01:28:07,632 Epoch[52] Batch [630]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.094718,	
2017-07-26 01:28:11,592 Epoch[52] Batch [640]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094835,	
2017-07-26 01:28:15,547 Epoch[52] Batch [650]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094752,	
2017-07-26 01:28:19,522 Epoch[52] Batch [660]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094747,	
2017-07-26 01:28:23,402 Epoch[52] Batch [670]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.094742,	
2017-07-26 01:28:27,458 Epoch[52] Batch [680]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094681,	
2017-07-26 01:28:31,476 Epoch[52] Batch [690]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094537,	
2017-07-26 01:28:35,606 Epoch[52] Batch [700]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.094656,	
2017-07-26 01:28:39,672 Epoch[52] Batch [710]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094602,	
2017-07-26 01:28:43,704 Epoch[52] Batch [720]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.094405,	
2017-07-26 01:28:47,670 Epoch[52] Batch [730]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094403,	
2017-07-26 01:28:51,661 Epoch[52] Batch [740]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094338,	
2017-07-26 01:28:55,568 Epoch[52] Batch [750]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094282,	
2017-07-26 01:28:59,616 Epoch[52] Batch [760]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.094206,	
2017-07-26 01:29:03,638 Epoch[52] Batch [770]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094239,	
2017-07-26 01:29:07,651 Epoch[52] Batch [780]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094258,	
2017-07-26 01:29:11,618 Epoch[52] Batch [790]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094316,	
2017-07-26 01:29:15,555 Epoch[52] Batch [800]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094298,	
2017-07-26 01:29:19,568 Epoch[52] Batch [810]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094267,	
2017-07-26 01:29:23,502 Epoch[52] Batch [820]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.094285,	
2017-07-26 01:29:27,525 Epoch[52] Batch [830]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094324,	
2017-07-26 01:29:31,510 Epoch[52] Batch [840]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094670,	
2017-07-26 01:29:35,817 Epoch[52] Batch [850]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.094648,	
2017-07-26 01:29:39,870 Epoch[52] Batch [860]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094545,	
2017-07-26 01:29:43,849 Epoch[52] Batch [870]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094443,	
2017-07-26 01:29:47,928 Epoch[52] Batch [880]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.094468,	
2017-07-26 01:29:51,970 Epoch[52] Batch [890]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094446,	
2017-07-26 01:29:55,958 Epoch[52] Batch [900]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.094460,	
2017-07-26 01:30:00,108 Epoch[52] Batch [910]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094534,	
2017-07-26 01:30:03,969 Epoch[52] Batch [920]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.094492,	
2017-07-26 01:30:07,966 Epoch[52] Batch [930]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094512,	
2017-07-26 01:30:11,936 Epoch[52] Batch [940]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094427,	
2017-07-26 01:30:15,963 Epoch[52] Batch [950]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094361,	
2017-07-26 01:30:19,870 Epoch[52] Batch [960]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.094379,	
2017-07-26 01:30:23,934 Epoch[52] Batch [970]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.094326,	
2017-07-26 01:30:27,909 Epoch[52] Batch [980]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094439,	
2017-07-26 01:30:32,065 Epoch[52] Batch [990]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.094385,	
2017-07-26 01:30:36,075 Epoch[52] Batch [1000]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094438,	
2017-07-26 01:30:40,114 Epoch[52] Batch [1010]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094315,	
2017-07-26 01:30:44,350 Epoch[52] Batch [1020]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.094203,	
2017-07-26 01:30:48,353 Epoch[52] Batch [1030]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.094144,	
2017-07-26 01:30:52,338 Epoch[52] Batch [1040]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094211,	
2017-07-26 01:30:56,339 Epoch[52] Batch [1050]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.094152,	
2017-07-26 01:31:00,448 Epoch[52] Batch [1060]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.094125,	
2017-07-26 01:31:04,647 Epoch[52] Batch [1070]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.094157,	
2017-07-26 01:31:08,796 Epoch[52] Batch [1080]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094224,	
2017-07-26 01:31:13,011 Epoch[52] Batch [1090]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094218,	
2017-07-26 01:31:17,073 Epoch[52] Batch [1100]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094185,	
2017-07-26 01:31:21,100 Epoch[52] Batch [1110]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.094247,	
2017-07-26 01:31:24,969 Epoch[52] Batch [1120]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.094171,	
2017-07-26 01:31:29,117 Epoch[52] Batch [1130]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.094268,	
2017-07-26 01:31:33,078 Epoch[52] Batch [1140]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.094215,	
2017-07-26 01:31:37,057 Epoch[52] Batch [1150]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.094186,	
2017-07-26 01:31:41,022 Epoch[52] Batch [1160]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094211,	
2017-07-26 01:31:44,999 Epoch[52] Batch [1170]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094213,	
2017-07-26 01:31:48,984 Epoch[52] Batch [1180]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.094263,	
2017-07-26 01:31:52,929 Epoch[52] Batch [1190]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094196,	
2017-07-26 01:31:56,823 Epoch[52] Batch [1200]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.094205,	
2017-07-26 01:32:00,761 Epoch[52] Batch [1210]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.094291,	
2017-07-26 01:32:04,683 Epoch[52] Batch [1220]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.094185,	
2017-07-26 01:32:08,649 Epoch[52] Batch [1230]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.094200,	
2017-07-26 01:32:12,617 Epoch[52] Batch [1240]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094218,	
2017-07-26 01:32:16,630 Epoch[52] Batch [1250]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.094183,	
2017-07-26 01:32:20,607 Epoch[52] Batch [1260]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094220,	
2017-07-26 01:32:24,677 Epoch[52] Batch [1270]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.094258,	
2017-07-26 01:32:28,720 Epoch[52] Batch [1280]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.094270,	
2017-07-26 01:32:32,775 Epoch[52] Batch [1290]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.094223,	
2017-07-26 01:32:36,834 Epoch[52] Batch [1300]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.094253,	
2017-07-26 01:32:40,789 Epoch[52] Batch [1310]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.094210,	
2017-07-26 01:32:45,177 Epoch[52] Batch [1320]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.094160,	
2017-07-26 01:32:49,121 Epoch[52] Batch [1330]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.094197,	
2017-07-26 01:32:53,142 Epoch[52] Batch [1340]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.094180,	
2017-07-26 01:32:57,046 Epoch[52] Batch [1350]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.094142,	
2017-07-26 01:33:01,054 Epoch[52] Batch [1360]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.094104,	
2017-07-26 01:33:05,045 Epoch[52] Batch [1370]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.094204,	
2017-07-26 01:33:09,136 Epoch[52] Batch [1380]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094198,	
2017-07-26 01:33:13,162 Epoch[52] Batch [1390]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.094205,	
2017-07-26 01:33:17,177 Epoch[52] Batch [1400]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094278,	
2017-07-26 01:33:21,194 Epoch[52] Batch [1410]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094308,	
2017-07-26 01:33:25,312 Epoch[52] Batch [1420]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.094328,	
2017-07-26 01:33:29,260 Epoch[52] Batch [1430]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.094232,	
2017-07-26 01:33:33,235 Epoch[52] Batch [1440]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.094249,	
2017-07-26 01:33:37,251 Epoch[52] Batch [1450]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.094231,	
2017-07-26 01:33:41,220 Epoch[52] Batch [1460]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.094209,	
2017-07-26 01:33:45,104 Epoch[52] Batch [1470]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.094221,	
2017-07-26 01:33:49,102 Epoch[52] Batch [1480]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.094176,	
2017-07-26 01:33:51,532 Epoch[52] Train-FCNLogLoss=0.094160
2017-07-26 01:33:51,532 Epoch[52] Time cost=597.314
2017-07-26 01:33:52,272 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0053.params"
2017-07-26 01:33:55,661 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_acn/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_acn-0053.states"
2017-07-26 01:33:55,671 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet-aconv',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_acn',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_acn'}

2017-07-26 01:34:02,305 testing 4/500 data 0.6350s net 0.2857s post 0.0061s
2017-07-26 01:34:03,053 testing 8/500 data 0.5601s net 0.2697s post 0.0077s
2017-07-26 01:34:04,454 testing 12/500 data 0.7511s net 0.2665s post 0.0074s
2017-07-26 01:34:05,732 testing 16/500 data 0.8174s net 0.2633s post 0.0078s
2017-07-26 01:34:06,989 testing 20/500 data 0.8528s net 0.2613s post 0.0080s
2017-07-26 01:34:08,297 testing 24/500 data 0.8853s net 0.2600s post 0.0078s
2017-07-26 01:34:09,516 testing 28/500 data 0.8954s net 0.2592s post 0.0079s
2017-07-26 01:34:10,757 testing 32/500 data 0.9058s net 0.2586s post 0.0078s
2017-07-26 01:34:12,014 testing 36/500 data 0.9157s net 0.2582s post 0.0078s
2017-07-26 01:34:13,160 testing 40/500 data 0.9123s net 0.2579s post 0.0079s
2017-07-26 01:34:14,431 testing 44/500 data 0.9214s net 0.2573s post 0.0078s
2017-07-26 01:34:15,704 testing 48/500 data 0.9290s net 0.2569s post 0.0078s
2017-07-26 01:34:16,957 testing 52/500 data 0.9339s net 0.2567s post 0.0077s
2017-07-26 01:34:18,220 testing 56/500 data 0.9387s net 0.2565s post 0.0078s
2017-07-26 01:34:19,458 testing 60/500 data 0.9413s net 0.2563s post 0.0077s
2017-07-26 01:34:20,719 testing 64/500 data 0.9447s net 0.2560s post 0.0080s
2017-07-26 01:34:21,933 testing 68/500 data 0.9451s net 0.2558s post 0.0082s
2017-07-26 01:34:23,225 testing 72/500 data 0.9498s net 0.2557s post 0.0081s
2017-07-26 01:34:24,471 testing 76/500 data 0.9518s net 0.2555s post 0.0081s
2017-07-26 01:34:25,749 testing 80/500 data 0.9551s net 0.2553s post 0.0081s
2017-07-26 01:34:26,982 testing 84/500 data 0.9557s net 0.2553s post 0.0083s
2017-07-26 01:34:28,190 testing 88/500 data 0.9552s net 0.2552s post 0.0082s
2017-07-26 01:34:29,440 testing 92/500 data 0.9568s net 0.2551s post 0.0082s
2017-07-26 01:34:30,705 testing 96/500 data 0.9588s net 0.2550s post 0.0081s
2017-07-26 01:34:31,980 testing 100/500 data 0.9611s net 0.2549s post 0.0080s
2017-07-26 01:34:33,208 testing 104/500 data 0.9613s net 0.2549s post 0.0080s
2017-07-26 01:34:34,466 testing 108/500 data 0.9628s net 0.2548s post 0.0079s
2017-07-26 01:34:35,691 testing 112/500 data 0.9629s net 0.2547s post 0.0079s
2017-07-26 01:34:36,931 testing 116/500 data 0.9635s net 0.2546s post 0.0078s
2017-07-26 01:34:38,176 testing 120/500 data 0.9642s net 0.2545s post 0.0079s
2017-07-26 01:34:39,409 testing 124/500 data 0.9644s net 0.2545s post 0.0079s
2017-07-26 01:34:40,665 testing 128/500 data 0.9654s net 0.2544s post 0.0079s
2017-07-26 01:34:41,890 testing 132/500 data 0.9653s net 0.2544s post 0.0079s
2017-07-26 01:34:43,088 testing 136/500 data 0.9644s net 0.2544s post 0.0080s
2017-07-26 01:34:44,310 testing 140/500 data 0.9643s net 0.2543s post 0.0080s
2017-07-26 01:34:45,586 testing 144/500 data 0.9656s net 0.2543s post 0.0080s
2017-07-26 01:34:46,463 testing 148/500 data 0.9563s net 0.2542s post 0.0080s
2017-07-26 01:34:47,733 testing 152/500 data 0.9577s net 0.2542s post 0.0079s
2017-07-26 01:34:48,985 testing 156/500 data 0.9586s net 0.2542s post 0.0080s
2017-07-26 01:34:50,312 testing 160/500 data 0.9614s net 0.2541s post 0.0079s
2017-07-26 01:34:51,528 testing 164/500 data 0.9612s net 0.2540s post 0.0080s
2017-07-26 01:34:52,801 testing 168/500 data 0.9625s net 0.2540s post 0.0079s
2017-07-26 01:34:54,090 testing 172/500 data 0.9640s net 0.2539s post 0.0079s
2017-07-26 01:34:55,326 testing 176/500 data 0.9641s net 0.2540s post 0.0080s
2017-07-26 01:34:56,543 testing 180/500 data 0.9640s net 0.2539s post 0.0080s
2017-07-26 01:34:57,783 testing 184/500 data 0.9644s net 0.2539s post 0.0079s
2017-07-26 01:34:59,045 testing 188/500 data 0.9653s net 0.2538s post 0.0079s
2017-07-26 01:35:00,349 testing 192/500 data 0.9669s net 0.2537s post 0.0079s
2017-07-26 01:35:01,554 testing 196/500 data 0.9666s net 0.2536s post 0.0079s
2017-07-26 01:35:02,827 testing 200/500 data 0.9674s net 0.2536s post 0.0079s
2017-07-26 01:35:04,036 testing 204/500 data 0.9671s net 0.2536s post 0.0079s
2017-07-26 01:35:05,279 testing 208/500 data 0.9674s net 0.2535s post 0.0079s
2017-07-26 01:35:06,503 testing 212/500 data 0.9673s net 0.2535s post 0.0080s
2017-07-26 01:35:07,717 testing 216/500 data 0.9671s net 0.2534s post 0.0080s
2017-07-26 01:35:08,969 testing 220/500 data 0.9675s net 0.2535s post 0.0080s
2017-07-26 01:35:10,245 testing 224/500 data 0.9685s net 0.2534s post 0.0079s
2017-07-26 01:35:11,488 testing 228/500 data 0.9687s net 0.2534s post 0.0079s
2017-07-26 01:35:12,711 testing 232/500 data 0.9686s net 0.2533s post 0.0079s
2017-07-26 01:35:13,940 testing 236/500 data 0.9686s net 0.2533s post 0.0080s
2017-07-26 01:35:15,152 testing 240/500 data 0.9683s net 0.2533s post 0.0080s
2017-07-26 01:35:16,402 testing 244/500 data 0.9687s net 0.2532s post 0.0080s
2017-07-26 01:35:17,608 testing 248/500 data 0.9683s net 0.2532s post 0.0080s
2017-07-26 01:35:18,805 testing 252/500 data 0.9679s net 0.2531s post 0.0079s
2017-07-26 01:35:20,059 testing 256/500 data 0.9684s net 0.2531s post 0.0079s
2017-07-26 01:35:21,301 testing 260/500 data 0.9686s net 0.2530s post 0.0079s
2017-07-26 01:35:22,493 testing 264/500 data 0.9681s net 0.2530s post 0.0079s
2017-07-26 01:35:23,727 testing 268/500 data 0.9682s net 0.2530s post 0.0079s
2017-07-26 01:35:24,951 testing 272/500 data 0.9682s net 0.2529s post 0.0079s
2017-07-26 01:35:26,167 testing 276/500 data 0.9680s net 0.2529s post 0.0079s
2017-07-26 01:35:27,344 testing 280/500 data 0.9674s net 0.2528s post 0.0079s
2017-07-26 01:35:28,555 testing 284/500 data 0.9672s net 0.2528s post 0.0079s
2017-07-26 01:35:29,751 testing 288/500 data 0.9667s net 0.2528s post 0.0079s
2017-07-26 01:35:30,915 testing 292/500 data 0.9659s net 0.2528s post 0.0078s
2017-07-26 01:35:32,110 testing 296/500 data 0.9655s net 0.2528s post 0.0078s
2017-07-26 01:35:33,305 testing 300/500 data 0.9651s net 0.2527s post 0.0078s
2017-07-26 01:35:34,557 testing 304/500 data 0.9655s net 0.2527s post 0.0079s
2017-07-26 01:35:35,748 testing 308/500 data 0.9651s net 0.2527s post 0.0079s
2017-07-26 01:35:36,923 testing 312/500 data 0.9644s net 0.2527s post 0.0078s
2017-07-26 01:35:38,125 testing 316/500 data 0.9642s net 0.2526s post 0.0078s
2017-07-26 01:35:39,305 testing 320/500 data 0.9636s net 0.2526s post 0.0079s
2017-07-26 01:35:40,492 testing 324/500 data 0.9631s net 0.2526s post 0.0079s
2017-07-26 01:35:41,743 testing 328/500 data 0.9635s net 0.2525s post 0.0079s
2017-07-26 01:35:42,806 testing 332/500 data 0.9617s net 0.2525s post 0.0079s
2017-07-26 01:35:44,023 testing 336/500 data 0.9616s net 0.2525s post 0.0078s
2017-07-26 01:35:45,234 testing 340/500 data 0.9616s net 0.2524s post 0.0078s
2017-07-26 01:35:46,469 testing 344/500 data 0.9618s net 0.2524s post 0.0078s
2017-07-26 01:35:47,675 testing 348/500 data 0.9615s net 0.2525s post 0.0078s
2017-07-26 01:35:48,899 testing 352/500 data 0.9616s net 0.2524s post 0.0078s
2017-07-26 01:35:50,182 testing 356/500 data 0.9623s net 0.2524s post 0.0078s
2017-07-26 01:35:51,378 testing 360/500 data 0.9620s net 0.2524s post 0.0078s
2017-07-26 01:35:52,600 testing 364/500 data 0.9620s net 0.2524s post 0.0078s
2017-07-26 01:35:53,878 testing 368/500 data 0.9626s net 0.2524s post 0.0079s
2017-07-26 01:35:55,079 testing 372/500 data 0.9624s net 0.2523s post 0.0079s
2017-07-26 01:35:56,300 testing 376/500 data 0.9624s net 0.2523s post 0.0079s
2017-07-26 01:35:57,474 testing 380/500 data 0.9619s net 0.2523s post 0.0079s
2017-07-26 01:35:58,822 testing 384/500 data 0.9631s net 0.2523s post 0.0079s
2017-07-26 01:35:59,994 testing 388/500 data 0.9626s net 0.2523s post 0.0079s
2017-07-26 01:36:01,263 testing 392/500 data 0.9631s net 0.2522s post 0.0079s
2017-07-26 01:36:02,455 testing 396/500 data 0.9629s net 0.2522s post 0.0079s
2017-07-26 01:36:03,661 testing 400/500 data 0.9627s net 0.2522s post 0.0079s
2017-07-26 01:36:04,822 testing 404/500 data 0.9622s net 0.2521s post 0.0079s
2017-07-26 01:36:05,924 testing 408/500 data 0.9610s net 0.2522s post 0.0079s
2017-07-26 01:36:07,139 testing 412/500 data 0.9609s net 0.2522s post 0.0079s
2017-07-26 01:36:08,313 testing 416/500 data 0.9604s net 0.2522s post 0.0080s
2017-07-26 01:36:09,624 testing 420/500 data 0.9613s net 0.2522s post 0.0079s
2017-07-26 01:36:10,855 testing 424/500 data 0.9614s net 0.2521s post 0.0079s
2017-07-26 01:36:12,045 testing 428/500 data 0.9612s net 0.2521s post 0.0079s
2017-07-26 01:36:13,360 testing 432/500 data 0.9621s net 0.2521s post 0.0079s
2017-07-26 01:36:14,548 testing 436/500 data 0.9618s net 0.2521s post 0.0079s
2017-07-26 01:36:15,871 testing 440/500 data 0.9627s net 0.2521s post 0.0079s
2017-07-26 01:36:17,056 testing 444/500 data 0.9624s net 0.2521s post 0.0079s
2017-07-26 01:36:18,430 testing 448/500 data 0.9638s net 0.2521s post 0.0078s
2017-07-26 01:36:19,620 testing 452/500 data 0.9635s net 0.2521s post 0.0078s
2017-07-26 01:36:21,025 testing 456/500 data 0.9651s net 0.2520s post 0.0078s
2017-07-26 01:36:22,261 testing 460/500 data 0.9652s net 0.2520s post 0.0078s
2017-07-26 01:36:23,658 testing 464/500 data 0.9667s net 0.2520s post 0.0078s
2017-07-26 01:36:24,867 testing 468/500 data 0.9666s net 0.2520s post 0.0078s
2017-07-26 01:36:26,241 testing 472/500 data 0.9679s net 0.2520s post 0.0078s
2017-07-26 01:36:27,459 testing 476/500 data 0.9678s net 0.2520s post 0.0078s
2017-07-26 01:36:28,615 testing 480/500 data 0.9672s net 0.2520s post 0.0078s
2017-07-26 01:36:29,972 testing 484/500 data 0.9683s net 0.2520s post 0.0078s
2017-07-26 01:36:31,159 testing 488/500 data 0.9679s net 0.2520s post 0.0079s
2017-07-26 01:36:32,446 testing 492/500 data 0.9683s net 0.2520s post 0.0079s
2017-07-26 01:36:33,743 testing 496/500 data 0.9689s net 0.2520s post 0.0079s
2017-07-26 01:36:35,004 testing 500/500 data 0.9691s net 0.2520s post 0.0079s
2017-07-26 01:38:32,029 evaluate segmentation: 

2017-07-26 01:38:32,030 IU_array:

2017-07-26 01:38:32,030 0.97655
2017-07-26 01:38:32,030 0.81687
2017-07-26 01:38:32,030 0.90452
2017-07-26 01:38:32,030 0.42344
2017-07-26 01:38:32,030 0.49839
2017-07-26 01:38:32,030 0.52785
2017-07-26 01:38:32,030 0.63148
2017-07-26 01:38:32,031 0.72069
2017-07-26 01:38:32,031 0.91155
2017-07-26 01:38:32,031 0.58505
2017-07-26 01:38:32,031 0.93452
2017-07-26 01:38:32,031 0.76909
2017-07-26 01:38:32,031 0.53141
2017-07-26 01:38:32,031 0.92909
2017-07-26 01:38:32,031 0.47774
2017-07-26 01:38:32,031 0.68984
2017-07-26 01:38:32,031 0.45527
2017-07-26 01:38:32,031 0.50652
2017-07-26 01:38:32,031 0.73244
2017-07-26 01:38:32,031 meanIU:0.68538

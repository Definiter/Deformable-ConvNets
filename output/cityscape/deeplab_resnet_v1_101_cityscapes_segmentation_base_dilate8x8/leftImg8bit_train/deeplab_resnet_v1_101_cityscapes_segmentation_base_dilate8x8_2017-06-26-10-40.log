2017-06-26 10:40:53,027 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate8x8'}

2017-06-26 10:42:27,343 Epoch[0] Batch [10]	Speed: 3.77 samples/sec	Train-FCNLogLoss=2.888905,	
2017-06-26 10:42:43,374 Epoch[0] Batch [20]	Speed: 2.50 samples/sec	Train-FCNLogLoss=2.753994,	
2017-06-26 10:43:00,891 Epoch[0] Batch [30]	Speed: 2.28 samples/sec	Train-FCNLogLoss=2.508744,	
2017-06-26 10:43:21,681 Epoch[0] Batch [40]	Speed: 1.92 samples/sec	Train-FCNLogLoss=2.249007,	
2017-06-26 10:43:30,283 Epoch[0] Batch [50]	Speed: 4.65 samples/sec	Train-FCNLogLoss=2.045212,	
2017-06-26 10:43:39,608 Epoch[0] Batch [60]	Speed: 4.29 samples/sec	Train-FCNLogLoss=1.856915,	
2017-06-26 10:43:48,735 Epoch[0] Batch [70]	Speed: 4.38 samples/sec	Train-FCNLogLoss=1.738410,	
2017-06-26 10:43:57,729 Epoch[0] Batch [80]	Speed: 4.45 samples/sec	Train-FCNLogLoss=1.628275,	
2017-06-26 10:44:06,172 Epoch[0] Batch [90]	Speed: 4.74 samples/sec	Train-FCNLogLoss=1.524276,	
2017-06-26 10:44:15,418 Epoch[0] Batch [100]	Speed: 4.33 samples/sec	Train-FCNLogLoss=1.446355,	
2017-06-26 10:44:23,836 Epoch[0] Batch [110]	Speed: 4.75 samples/sec	Train-FCNLogLoss=1.379078,	
2017-06-26 10:44:31,201 Epoch[0] Batch [120]	Speed: 5.43 samples/sec	Train-FCNLogLoss=1.312499,	
2017-06-26 10:44:39,121 Epoch[0] Batch [130]	Speed: 5.05 samples/sec	Train-FCNLogLoss=1.265103,	
2017-06-26 10:44:46,738 Epoch[0] Batch [140]	Speed: 5.25 samples/sec	Train-FCNLogLoss=1.229169,	
2017-06-26 10:44:54,138 Epoch[0] Batch [150]	Speed: 5.41 samples/sec	Train-FCNLogLoss=1.189990,	
2017-06-26 10:45:01,897 Epoch[0] Batch [160]	Speed: 5.16 samples/sec	Train-FCNLogLoss=1.153999,	
2017-06-26 10:45:10,145 Epoch[0] Batch [170]	Speed: 4.85 samples/sec	Train-FCNLogLoss=1.118144,	
2017-06-26 10:45:18,102 Epoch[0] Batch [180]	Speed: 5.03 samples/sec	Train-FCNLogLoss=1.080912,	
2017-06-26 10:45:27,285 Epoch[0] Batch [190]	Speed: 4.36 samples/sec	Train-FCNLogLoss=1.056828,	
2017-06-26 10:45:35,620 Epoch[0] Batch [200]	Speed: 4.80 samples/sec	Train-FCNLogLoss=1.030908,	
2017-06-26 10:45:45,847 Epoch[0] Batch [210]	Speed: 3.91 samples/sec	Train-FCNLogLoss=1.007576,	
2017-06-26 10:45:55,736 Epoch[0] Batch [220]	Speed: 4.05 samples/sec	Train-FCNLogLoss=0.982809,	
2017-06-26 10:46:05,822 Epoch[0] Batch [230]	Speed: 3.97 samples/sec	Train-FCNLogLoss=0.965065,	
2017-06-26 10:46:15,812 Epoch[0] Batch [240]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.946780,	
2017-06-26 10:46:24,917 Epoch[0] Batch [250]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.931196,	
2017-06-26 10:46:34,152 Epoch[0] Batch [260]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.915893,	
2017-06-26 10:46:42,056 Epoch[0] Batch [270]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.900643,	
2017-06-26 10:46:51,026 Epoch[0] Batch [280]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.885632,	
2017-06-26 10:47:05,597 Epoch[0] Batch [290]	Speed: 2.75 samples/sec	Train-FCNLogLoss=0.869894,	
2017-06-26 10:47:14,216 Epoch[0] Batch [300]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.855117,	
2017-06-26 10:47:23,457 Epoch[0] Batch [310]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.842088,	
2017-06-26 10:47:32,065 Epoch[0] Batch [320]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.830355,	
2017-06-26 10:47:41,002 Epoch[0] Batch [330]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.818018,	
2017-06-26 10:47:49,622 Epoch[0] Batch [340]	Speed: 4.64 samples/sec	Train-FCNLogLoss=0.807011,	
2017-06-26 10:47:58,205 Epoch[0] Batch [350]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.797281,	
2017-06-26 10:48:07,155 Epoch[0] Batch [360]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.785657,	
2017-06-26 10:48:15,067 Epoch[0] Batch [370]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.774604,	
2017-06-26 10:48:23,817 Epoch[0] Batch [380]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.766427,	
2017-06-26 10:48:32,353 Epoch[0] Batch [390]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.760817,	
2017-06-26 10:48:41,048 Epoch[0] Batch [400]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.754411,	
2017-06-26 10:48:49,637 Epoch[0] Batch [410]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.747058,	
2017-06-26 10:48:58,131 Epoch[0] Batch [420]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.738891,	
2017-06-26 10:49:07,363 Epoch[0] Batch [430]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.732319,	
2017-06-26 10:49:16,628 Epoch[0] Batch [440]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.725690,	
2017-06-26 10:49:25,951 Epoch[0] Batch [450]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.718678,	
2017-06-26 10:49:34,970 Epoch[0] Batch [460]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.710713,	
2017-06-26 10:49:43,738 Epoch[0] Batch [470]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.705314,	
2017-06-26 10:49:52,825 Epoch[0] Batch [480]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.698596,	
2017-06-26 10:50:01,503 Epoch[0] Batch [490]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.692271,	
2017-06-26 10:50:10,333 Epoch[0] Batch [500]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.685973,	
2017-06-26 10:50:19,343 Epoch[0] Batch [510]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.679938,	
2017-06-26 10:50:27,786 Epoch[0] Batch [520]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.672901,	
2017-06-26 10:50:37,120 Epoch[0] Batch [530]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.666791,	
2017-06-26 10:50:46,151 Epoch[0] Batch [540]	Speed: 4.43 samples/sec	Train-FCNLogLoss=0.660254,	
2017-06-26 10:50:55,477 Epoch[0] Batch [550]	Speed: 4.29 samples/sec	Train-FCNLogLoss=0.654929,	
2017-06-26 10:51:04,537 Epoch[0] Batch [560]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.649328,	
2017-06-26 10:51:13,792 Epoch[0] Batch [570]	Speed: 4.32 samples/sec	Train-FCNLogLoss=0.643981,	
2017-06-26 10:51:22,890 Epoch[0] Batch [580]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.639288,	
2017-06-26 10:51:32,069 Epoch[0] Batch [590]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.634540,	
2017-06-26 10:51:40,941 Epoch[0] Batch [600]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.631290,	
2017-06-26 10:51:50,461 Epoch[0] Batch [610]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.626638,	
2017-06-26 10:51:59,618 Epoch[0] Batch [620]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.621742,	
2017-06-26 10:52:09,194 Epoch[0] Batch [630]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.617145,	
2017-06-26 10:52:18,643 Epoch[0] Batch [640]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.613419,	
2017-06-26 10:52:27,615 Epoch[0] Batch [650]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.609149,	
2017-06-26 10:52:37,159 Epoch[0] Batch [660]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.604370,	
2017-06-26 10:52:46,283 Epoch[0] Batch [670]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.600807,	
2017-06-26 10:52:55,928 Epoch[0] Batch [680]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.597147,	
2017-06-26 10:53:05,388 Epoch[0] Batch [690]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.592806,	
2017-06-26 10:53:14,251 Epoch[0] Batch [700]	Speed: 4.51 samples/sec	Train-FCNLogLoss=0.589160,	
2017-06-26 10:53:23,260 Epoch[0] Batch [710]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.585590,	
2017-06-26 10:53:31,548 Epoch[0] Batch [720]	Speed: 4.83 samples/sec	Train-FCNLogLoss=0.582081,	
2017-06-26 10:53:40,903 Epoch[0] Batch [730]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.579848,	
2017-06-26 10:53:50,577 Epoch[0] Batch [740]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.576964,	
2017-06-26 10:54:00,040 Epoch[0] Batch [750]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.574518,	
2017-06-26 10:54:09,200 Epoch[0] Batch [760]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.571093,	
2017-06-26 10:54:18,281 Epoch[0] Batch [770]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.568510,	
2017-06-26 10:54:27,031 Epoch[0] Batch [780]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.565613,	
2017-06-26 10:54:36,716 Epoch[0] Batch [790]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.562877,	
2017-06-26 10:54:46,114 Epoch[0] Batch [800]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.560270,	
2017-06-26 10:54:55,311 Epoch[0] Batch [810]	Speed: 4.35 samples/sec	Train-FCNLogLoss=0.558009,	
2017-06-26 10:55:04,497 Epoch[0] Batch [820]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.555328,	
2017-06-26 10:55:13,474 Epoch[0] Batch [830]	Speed: 4.46 samples/sec	Train-FCNLogLoss=0.552698,	
2017-06-26 10:55:22,783 Epoch[0] Batch [840]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.549958,	
2017-06-26 10:55:32,237 Epoch[0] Batch [850]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.546768,	
2017-06-26 10:55:41,591 Epoch[0] Batch [860]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.544529,	
2017-06-26 10:55:50,894 Epoch[0] Batch [870]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.542311,	
2017-06-26 10:55:59,844 Epoch[0] Batch [880]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.539552,	
2017-06-26 10:56:09,196 Epoch[0] Batch [890]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.536864,	
2017-06-26 10:56:18,295 Epoch[0] Batch [900]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.534055,	
2017-06-26 10:56:27,187 Epoch[0] Batch [910]	Speed: 4.50 samples/sec	Train-FCNLogLoss=0.531661,	
2017-06-26 10:56:36,527 Epoch[0] Batch [920]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.529586,	
2017-06-26 10:56:45,878 Epoch[0] Batch [930]	Speed: 4.28 samples/sec	Train-FCNLogLoss=0.527281,	
2017-06-26 10:56:55,517 Epoch[0] Batch [940]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.524934,	
2017-06-26 10:57:05,207 Epoch[0] Batch [950]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.522855,	
2017-06-26 10:57:14,790 Epoch[0] Batch [960]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.520920,	
2017-06-26 10:57:24,482 Epoch[0] Batch [970]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.518611,	
2017-06-26 10:57:34,396 Epoch[0] Batch [980]	Speed: 4.03 samples/sec	Train-FCNLogLoss=0.516510,	
2017-06-26 10:57:44,361 Epoch[0] Batch [990]	Speed: 4.01 samples/sec	Train-FCNLogLoss=0.514622,	
2017-06-26 10:57:54,034 Epoch[0] Batch [1000]	Speed: 4.14 samples/sec	Train-FCNLogLoss=0.513114,	
2017-06-26 10:58:03,470 Epoch[0] Batch [1010]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.511566,	
2017-06-26 10:58:12,397 Epoch[0] Batch [1020]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.511310,	
2017-06-26 10:58:21,558 Epoch[0] Batch [1030]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.510778,	
2017-06-26 10:58:30,733 Epoch[0] Batch [1040]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.509731,	
2017-06-26 10:58:39,805 Epoch[0] Batch [1050]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.508516,	
2017-06-26 10:58:49,088 Epoch[0] Batch [1060]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.507385,	
2017-06-26 10:58:58,159 Epoch[0] Batch [1070]	Speed: 4.41 samples/sec	Train-FCNLogLoss=0.505851,	
2017-06-26 10:59:07,627 Epoch[0] Batch [1080]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.504050,	
2017-06-26 10:59:16,675 Epoch[0] Batch [1090]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.503010,	
2017-06-26 10:59:25,847 Epoch[0] Batch [1100]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.502242,	
2017-06-26 10:59:35,673 Epoch[0] Batch [1110]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.502124,	
2017-06-26 10:59:45,399 Epoch[0] Batch [1120]	Speed: 4.11 samples/sec	Train-FCNLogLoss=0.501459,	
2017-06-26 10:59:55,349 Epoch[0] Batch [1130]	Speed: 4.02 samples/sec	Train-FCNLogLoss=0.500410,	
2017-06-26 11:00:04,880 Epoch[0] Batch [1140]	Speed: 4.20 samples/sec	Train-FCNLogLoss=0.499540,	
2017-06-26 11:00:14,117 Epoch[0] Batch [1150]	Speed: 4.33 samples/sec	Train-FCNLogLoss=0.499349,	
2017-06-26 11:00:23,555 Epoch[0] Batch [1160]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.497972,	
2017-06-26 11:00:32,714 Epoch[0] Batch [1170]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.497262,	
2017-06-26 11:00:42,328 Epoch[0] Batch [1180]	Speed: 4.16 samples/sec	Train-FCNLogLoss=0.495818,	
2017-06-26 11:00:51,781 Epoch[0] Batch [1190]	Speed: 4.23 samples/sec	Train-FCNLogLoss=0.496321,	
2017-06-26 11:01:01,183 Epoch[0] Batch [1200]	Speed: 4.25 samples/sec	Train-FCNLogLoss=0.495892,	
2017-06-26 11:01:10,362 Epoch[0] Batch [1210]	Speed: 4.36 samples/sec	Train-FCNLogLoss=0.494770,	
2017-06-26 11:01:19,291 Epoch[0] Batch [1220]	Speed: 4.48 samples/sec	Train-FCNLogLoss=0.494139,	
2017-06-26 11:01:28,867 Epoch[0] Batch [1230]	Speed: 4.18 samples/sec	Train-FCNLogLoss=0.493769,	
2017-06-26 11:01:38,021 Epoch[0] Batch [1240]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.492337,	
2017-06-26 11:01:47,166 Epoch[0] Batch [1250]	Speed: 4.37 samples/sec	Train-FCNLogLoss=0.490901,	
2017-06-26 11:01:56,167 Epoch[0] Batch [1260]	Speed: 4.44 samples/sec	Train-FCNLogLoss=0.489696,	
2017-06-26 11:02:05,212 Epoch[0] Batch [1270]	Speed: 4.42 samples/sec	Train-FCNLogLoss=0.489048,	
2017-06-26 11:02:14,064 Epoch[0] Batch [1280]	Speed: 4.52 samples/sec	Train-FCNLogLoss=0.488115,	
2017-06-26 11:02:23,606 Epoch[0] Batch [1290]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.486971,	
2017-06-26 11:02:33,950 Epoch[0] Batch [1300]	Speed: 3.87 samples/sec	Train-FCNLogLoss=0.485663,	
2017-06-26 11:02:43,774 Epoch[0] Batch [1310]	Speed: 4.07 samples/sec	Train-FCNLogLoss=0.484216,	
2017-06-26 11:02:53,972 Epoch[0] Batch [1320]	Speed: 3.92 samples/sec	Train-FCNLogLoss=0.482846,	
2017-06-26 11:03:03,602 Epoch[0] Batch [1330]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.481698,	
2017-06-26 11:03:13,185 Epoch[0] Batch [1340]	Speed: 4.17 samples/sec	Train-FCNLogLoss=0.480651,	
2017-06-26 11:03:22,743 Epoch[0] Batch [1350]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.479716,	
2017-06-26 11:03:32,422 Epoch[0] Batch [1360]	Speed: 4.13 samples/sec	Train-FCNLogLoss=0.478724,	
2017-06-26 11:03:41,865 Epoch[0] Batch [1370]	Speed: 4.24 samples/sec	Train-FCNLogLoss=0.477491,	
2017-06-26 11:03:51,408 Epoch[0] Batch [1380]	Speed: 4.19 samples/sec	Train-FCNLogLoss=0.476141,	
2017-06-26 11:04:01,108 Epoch[0] Batch [1390]	Speed: 4.12 samples/sec	Train-FCNLogLoss=0.475024,	
2017-06-26 11:04:11,118 Epoch[0] Batch [1400]	Speed: 4.00 samples/sec	Train-FCNLogLoss=0.473462,	
2017-06-26 11:04:20,211 Epoch[0] Batch [1410]	Speed: 4.40 samples/sec	Train-FCNLogLoss=0.471992,	
2017-06-26 11:04:29,593 Epoch[0] Batch [1420]	Speed: 4.26 samples/sec	Train-FCNLogLoss=0.470637,	
2017-06-26 11:04:38,731 Epoch[0] Batch [1430]	Speed: 4.38 samples/sec	Train-FCNLogLoss=0.469292,	
2017-06-26 11:04:48,750 Epoch[0] Batch [1440]	Speed: 3.99 samples/sec	Train-FCNLogLoss=0.467839,	
2017-06-26 11:04:58,552 Epoch[0] Batch [1450]	Speed: 4.08 samples/sec	Train-FCNLogLoss=0.466401,	
2017-06-26 11:05:08,179 Epoch[0] Batch [1460]	Speed: 4.15 samples/sec	Train-FCNLogLoss=0.465091,	
2017-06-26 11:05:17,473 Epoch[0] Batch [1470]	Speed: 4.30 samples/sec	Train-FCNLogLoss=0.463699,	
2017-06-26 11:05:26,761 Epoch[0] Batch [1480]	Speed: 4.31 samples/sec	Train-FCNLogLoss=0.462352,	
2017-06-26 11:05:33,537 Epoch[0] Train-FCNLogLoss=0.461556
2017-06-26 11:05:33,537 Epoch[0] Time cost=1409.436
2017-06-26 11:05:35,321 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0001.params"
2017-06-26 11:05:42,008 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0001.states"
2017-06-26 11:05:51,670 Epoch[1] Batch [10]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.304873,	
2017-06-26 11:06:00,445 Epoch[1] Batch [20]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.289623,	
2017-06-26 11:06:08,963 Epoch[1] Batch [30]	Speed: 4.70 samples/sec	Train-FCNLogLoss=0.290100,	
2017-06-26 11:06:17,135 Epoch[1] Batch [40]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.297300,	
2017-06-26 11:06:25,455 Epoch[1] Batch [50]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.287899,	
2017-06-26 11:06:33,792 Epoch[1] Batch [60]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.291122,	
2017-06-26 11:06:42,484 Epoch[1] Batch [70]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.294044,	
2017-06-26 11:06:51,588 Epoch[1] Batch [80]	Speed: 4.39 samples/sec	Train-FCNLogLoss=0.295809,	
2017-06-26 11:07:00,359 Epoch[1] Batch [90]	Speed: 4.56 samples/sec	Train-FCNLogLoss=0.291672,	
2017-06-26 11:07:08,748 Epoch[1] Batch [100]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.298042,	
2017-06-26 11:07:17,067 Epoch[1] Batch [110]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.300633,	
2017-06-26 11:07:25,492 Epoch[1] Batch [120]	Speed: 4.75 samples/sec	Train-FCNLogLoss=0.294783,	
2017-06-26 11:07:33,993 Epoch[1] Batch [130]	Speed: 4.71 samples/sec	Train-FCNLogLoss=0.294017,	
2017-06-26 11:07:42,284 Epoch[1] Batch [140]	Speed: 4.82 samples/sec	Train-FCNLogLoss=0.292034,	
2017-06-26 11:07:50,227 Epoch[1] Batch [150]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.287760,	
2017-06-26 11:07:57,972 Epoch[1] Batch [160]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.284976,	
2017-06-26 11:08:05,926 Epoch[1] Batch [170]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.283718,	
2017-06-26 11:08:13,837 Epoch[1] Batch [180]	Speed: 5.06 samples/sec	Train-FCNLogLoss=0.282907,	
2017-06-26 11:08:21,719 Epoch[1] Batch [190]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.280960,	
2017-06-26 11:08:29,594 Epoch[1] Batch [200]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.280531,	
2017-06-26 11:08:37,491 Epoch[1] Batch [210]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.280302,	
2017-06-26 11:08:45,606 Epoch[1] Batch [220]	Speed: 4.93 samples/sec	Train-FCNLogLoss=0.279773,	
2017-06-26 11:08:53,594 Epoch[1] Batch [230]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.280217,	
2017-06-26 11:09:01,974 Epoch[1] Batch [240]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.278236,	
2017-06-26 11:09:09,822 Epoch[1] Batch [250]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.277471,	
2017-06-26 11:09:17,870 Epoch[1] Batch [260]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.276085,	
2017-06-26 11:09:26,049 Epoch[1] Batch [270]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.275694,	
2017-06-26 11:09:33,695 Epoch[1] Batch [280]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.273594,	
2017-06-26 11:09:41,232 Epoch[1] Batch [290]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.272814,	
2017-06-26 11:09:48,898 Epoch[1] Batch [300]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.270852,	
2017-06-26 11:09:56,499 Epoch[1] Batch [310]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.269372,	
2017-06-26 11:10:04,092 Epoch[1] Batch [320]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.269448,	
2017-06-26 11:10:11,796 Epoch[1] Batch [330]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.269763,	
2017-06-26 11:10:19,479 Epoch[1] Batch [340]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.269337,	
2017-06-26 11:10:27,124 Epoch[1] Batch [350]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.268303,	
2017-06-26 11:10:34,778 Epoch[1] Batch [360]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.268585,	
2017-06-26 11:10:42,160 Epoch[1] Batch [370]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.269362,	
2017-06-26 11:10:50,263 Epoch[1] Batch [380]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.269570,	
2017-06-26 11:10:58,509 Epoch[1] Batch [390]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.269777,	
2017-06-26 11:11:06,653 Epoch[1] Batch [400]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.268912,	
2017-06-26 11:11:14,156 Epoch[1] Batch [410]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.268695,	
2017-06-26 11:11:21,894 Epoch[1] Batch [420]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.268623,	
2017-06-26 11:11:29,747 Epoch[1] Batch [430]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.268663,	
2017-06-26 11:11:37,917 Epoch[1] Batch [440]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.268191,	
2017-06-26 11:11:45,641 Epoch[1] Batch [450]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.270661,	
2017-06-26 11:11:53,256 Epoch[1] Batch [460]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.272488,	
2017-06-26 11:12:00,946 Epoch[1] Batch [470]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.273828,	
2017-06-26 11:12:08,479 Epoch[1] Batch [480]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.274381,	
2017-06-26 11:12:16,195 Epoch[1] Batch [490]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.274230,	
2017-06-26 11:12:23,155 Epoch[1] Batch [500]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.275254,	
2017-06-26 11:12:29,538 Epoch[1] Batch [510]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.275963,	
2017-06-26 11:12:36,696 Epoch[1] Batch [520]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.275274,	
2017-06-26 11:12:43,212 Epoch[1] Batch [530]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.274561,	
2017-06-26 11:12:49,420 Epoch[1] Batch [540]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.273441,	
2017-06-26 11:12:55,653 Epoch[1] Batch [550]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.273155,	
2017-06-26 11:13:02,329 Epoch[1] Batch [560]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.272712,	
2017-06-26 11:13:08,815 Epoch[1] Batch [570]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.272068,	
2017-06-26 11:13:15,457 Epoch[1] Batch [580]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.271744,	
2017-06-26 11:13:22,421 Epoch[1] Batch [590]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.270625,	
2017-06-26 11:13:29,181 Epoch[1] Batch [600]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.271886,	
2017-06-26 11:13:36,008 Epoch[1] Batch [610]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.272838,	
2017-06-26 11:13:42,866 Epoch[1] Batch [620]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.274542,	
2017-06-26 11:13:49,410 Epoch[1] Batch [630]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.276101,	
2017-06-26 11:13:56,567 Epoch[1] Batch [640]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.276399,	
2017-06-26 11:14:03,525 Epoch[1] Batch [650]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.275683,	
2017-06-26 11:14:10,180 Epoch[1] Batch [660]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.275820,	
2017-06-26 11:14:16,933 Epoch[1] Batch [670]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.275173,	
2017-06-26 11:14:23,104 Epoch[1] Batch [680]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.274644,	
2017-06-26 11:14:29,959 Epoch[1] Batch [690]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.274317,	
2017-06-26 11:14:36,407 Epoch[1] Batch [700]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.273863,	
2017-06-26 11:14:42,763 Epoch[1] Batch [710]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.274144,	
2017-06-26 11:14:49,325 Epoch[1] Batch [720]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.274277,	
2017-06-26 11:14:55,756 Epoch[1] Batch [730]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.273621,	
2017-06-26 11:15:01,919 Epoch[1] Batch [740]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.273348,	
2017-06-26 11:15:08,870 Epoch[1] Batch [750]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.273130,	
2017-06-26 11:15:15,302 Epoch[1] Batch [760]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.273000,	
2017-06-26 11:15:22,301 Epoch[1] Batch [770]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.273356,	
2017-06-26 11:15:29,140 Epoch[1] Batch [780]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.272638,	
2017-06-26 11:15:35,959 Epoch[1] Batch [790]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.272403,	
2017-06-26 11:15:43,187 Epoch[1] Batch [800]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.272038,	
2017-06-26 11:15:50,059 Epoch[1] Batch [810]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.271320,	
2017-06-26 11:15:56,989 Epoch[1] Batch [820]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.270663,	
2017-06-26 11:16:03,711 Epoch[1] Batch [830]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.270645,	
2017-06-26 11:16:10,647 Epoch[1] Batch [840]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.270335,	
2017-06-26 11:16:17,172 Epoch[1] Batch [850]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.270107,	
2017-06-26 11:16:24,134 Epoch[1] Batch [860]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.269418,	
2017-06-26 11:16:30,882 Epoch[1] Batch [870]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.269654,	
2017-06-26 11:16:37,635 Epoch[1] Batch [880]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.269280,	
2017-06-26 11:16:44,571 Epoch[1] Batch [890]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.268966,	
2017-06-26 11:16:51,679 Epoch[1] Batch [900]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.268891,	
2017-06-26 11:16:58,503 Epoch[1] Batch [910]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.268196,	
2017-06-26 11:17:05,067 Epoch[1] Batch [920]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.267675,	
2017-06-26 11:17:11,866 Epoch[1] Batch [930]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.267237,	
2017-06-26 11:17:18,955 Epoch[1] Batch [940]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.266640,	
2017-06-26 11:17:26,380 Epoch[1] Batch [950]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.266597,	
2017-06-26 11:17:33,250 Epoch[1] Batch [960]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.266473,	
2017-06-26 11:17:40,210 Epoch[1] Batch [970]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.266106,	
2017-06-26 11:17:47,239 Epoch[1] Batch [980]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.266047,	
2017-06-26 11:17:53,848 Epoch[1] Batch [990]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.265503,	
2017-06-26 11:18:00,426 Epoch[1] Batch [1000]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.265503,	
2017-06-26 11:18:07,066 Epoch[1] Batch [1010]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.264762,	
2017-06-26 11:18:14,271 Epoch[1] Batch [1020]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.264539,	
2017-06-26 11:18:21,437 Epoch[1] Batch [1030]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.264248,	
2017-06-26 11:18:28,491 Epoch[1] Batch [1040]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.263802,	
2017-06-26 11:18:35,593 Epoch[1] Batch [1050]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.263391,	
2017-06-26 11:18:42,235 Epoch[1] Batch [1060]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.262857,	
2017-06-26 11:18:50,080 Epoch[1] Batch [1070]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.262315,	
2017-06-26 11:18:58,153 Epoch[1] Batch [1080]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.262027,	
2017-06-26 11:19:06,404 Epoch[1] Batch [1090]	Speed: 4.85 samples/sec	Train-FCNLogLoss=0.261907,	
2017-06-26 11:19:14,413 Epoch[1] Batch [1100]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.261611,	
2017-06-26 11:19:22,047 Epoch[1] Batch [1110]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.261102,	
2017-06-26 11:19:29,246 Epoch[1] Batch [1120]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.261130,	
2017-06-26 11:19:36,325 Epoch[1] Batch [1130]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.261251,	
2017-06-26 11:19:43,185 Epoch[1] Batch [1140]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.261214,	
2017-06-26 11:19:50,340 Epoch[1] Batch [1150]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.260952,	
2017-06-26 11:19:57,499 Epoch[1] Batch [1160]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.261015,	
2017-06-26 11:20:04,648 Epoch[1] Batch [1170]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.261021,	
2017-06-26 11:20:11,696 Epoch[1] Batch [1180]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.260946,	
2017-06-26 11:20:18,706 Epoch[1] Batch [1190]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.260427,	
2017-06-26 11:20:25,625 Epoch[1] Batch [1200]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.259763,	
2017-06-26 11:20:32,584 Epoch[1] Batch [1210]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.259228,	
2017-06-26 11:20:39,428 Epoch[1] Batch [1220]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.259121,	
2017-06-26 11:20:46,302 Epoch[1] Batch [1230]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.259164,	
2017-06-26 11:20:53,366 Epoch[1] Batch [1240]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.258965,	
2017-06-26 11:21:00,921 Epoch[1] Batch [1250]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.258905,	
2017-06-26 11:21:08,162 Epoch[1] Batch [1260]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.258688,	
2017-06-26 11:21:15,532 Epoch[1] Batch [1270]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.258499,	
2017-06-26 11:21:23,484 Epoch[1] Batch [1280]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.258368,	
2017-06-26 11:21:30,836 Epoch[1] Batch [1290]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.258574,	
2017-06-26 11:21:38,391 Epoch[1] Batch [1300]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.258738,	
2017-06-26 11:21:45,858 Epoch[1] Batch [1310]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.258094,	
2017-06-26 11:21:53,242 Epoch[1] Batch [1320]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.258013,	
2017-06-26 11:22:00,641 Epoch[1] Batch [1330]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.258034,	
2017-06-26 11:22:08,277 Epoch[1] Batch [1340]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.257681,	
2017-06-26 11:22:15,654 Epoch[1] Batch [1350]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.257458,	
2017-06-26 11:22:22,961 Epoch[1] Batch [1360]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.257362,	
2017-06-26 11:22:30,854 Epoch[1] Batch [1370]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.257004,	
2017-06-26 11:22:38,285 Epoch[1] Batch [1380]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.256719,	
2017-06-26 11:22:45,967 Epoch[1] Batch [1390]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.256248,	
2017-06-26 11:22:53,390 Epoch[1] Batch [1400]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.255637,	
2017-06-26 11:23:00,718 Epoch[1] Batch [1410]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.255127,	
2017-06-26 11:23:08,147 Epoch[1] Batch [1420]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.254829,	
2017-06-26 11:23:15,850 Epoch[1] Batch [1430]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.254472,	
2017-06-26 11:23:23,143 Epoch[1] Batch [1440]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.254057,	
2017-06-26 11:23:30,551 Epoch[1] Batch [1450]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.254034,	
2017-06-26 11:23:37,697 Epoch[1] Batch [1460]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.253792,	
2017-06-26 11:23:45,124 Epoch[1] Batch [1470]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.253465,	
2017-06-26 11:23:52,770 Epoch[1] Batch [1480]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.253146,	
2017-06-26 11:23:57,084 Epoch[1] Train-FCNLogLoss=0.252973
2017-06-26 11:23:57,084 Epoch[1] Time cost=1095.075
2017-06-26 11:23:58,251 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0002.params"
2017-06-26 11:24:02,017 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0002.states"
2017-06-26 11:24:10,449 Epoch[2] Batch [10]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.226390,	
2017-06-26 11:24:17,821 Epoch[2] Batch [20]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.226703,	
2017-06-26 11:24:25,223 Epoch[2] Batch [30]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.228917,	
2017-06-26 11:24:32,321 Epoch[2] Batch [40]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.223420,	
2017-06-26 11:24:39,923 Epoch[2] Batch [50]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.224127,	
2017-06-26 11:24:47,649 Epoch[2] Batch [60]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.223834,	
2017-06-26 11:24:55,109 Epoch[2] Batch [70]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.221642,	
2017-06-26 11:25:02,658 Epoch[2] Batch [80]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.228139,	
2017-06-26 11:25:09,720 Epoch[2] Batch [90]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.228040,	
2017-06-26 11:25:17,391 Epoch[2] Batch [100]	Speed: 5.21 samples/sec	Train-FCNLogLoss=0.230332,	
2017-06-26 11:25:25,261 Epoch[2] Batch [110]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.227144,	
2017-06-26 11:25:32,484 Epoch[2] Batch [120]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.228073,	
2017-06-26 11:25:40,126 Epoch[2] Batch [130]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.230152,	
2017-06-26 11:25:47,790 Epoch[2] Batch [140]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.229062,	
2017-06-26 11:25:55,852 Epoch[2] Batch [150]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.228247,	
2017-06-26 11:26:03,040 Epoch[2] Batch [160]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.227339,	
2017-06-26 11:26:10,503 Epoch[2] Batch [170]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.226571,	
2017-06-26 11:26:18,240 Epoch[2] Batch [180]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.225320,	
2017-06-26 11:26:25,587 Epoch[2] Batch [190]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.225256,	
2017-06-26 11:26:33,057 Epoch[2] Batch [200]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.224458,	
2017-06-26 11:26:40,848 Epoch[2] Batch [210]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.224325,	
2017-06-26 11:26:47,883 Epoch[2] Batch [220]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.222758,	
2017-06-26 11:26:54,828 Epoch[2] Batch [230]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.222006,	
2017-06-26 11:27:01,992 Epoch[2] Batch [240]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.221928,	
2017-06-26 11:27:08,895 Epoch[2] Batch [250]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.220747,	
2017-06-26 11:27:16,178 Epoch[2] Batch [260]	Speed: 5.49 samples/sec	Train-FCNLogLoss=0.219922,	
2017-06-26 11:27:23,472 Epoch[2] Batch [270]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.221303,	
2017-06-26 11:27:30,605 Epoch[2] Batch [280]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.221287,	
2017-06-26 11:27:37,933 Epoch[2] Batch [290]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.222066,	
2017-06-26 11:27:45,201 Epoch[2] Batch [300]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.221473,	
2017-06-26 11:27:52,298 Epoch[2] Batch [310]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.220514,	
2017-06-26 11:27:59,830 Epoch[2] Batch [320]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.219785,	
2017-06-26 11:28:07,666 Epoch[2] Batch [330]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.219682,	
2017-06-26 11:28:15,587 Epoch[2] Batch [340]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.219020,	
2017-06-26 11:28:23,401 Epoch[2] Batch [350]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.219933,	
2017-06-26 11:28:30,644 Epoch[2] Batch [360]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.220106,	
2017-06-26 11:28:38,335 Epoch[2] Batch [370]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.219772,	
2017-06-26 11:28:45,270 Epoch[2] Batch [380]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.218855,	
2017-06-26 11:28:52,491 Epoch[2] Batch [390]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.219314,	
2017-06-26 11:29:00,074 Epoch[2] Batch [400]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.219195,	
2017-06-26 11:29:07,368 Epoch[2] Batch [410]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.218346,	
2017-06-26 11:29:14,413 Epoch[2] Batch [420]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.217756,	
2017-06-26 11:29:21,477 Epoch[2] Batch [430]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.217402,	
2017-06-26 11:29:29,013 Epoch[2] Batch [440]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.216675,	
2017-06-26 11:29:36,590 Epoch[2] Batch [450]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.216040,	
2017-06-26 11:29:43,779 Epoch[2] Batch [460]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.215827,	
2017-06-26 11:29:50,990 Epoch[2] Batch [470]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.215676,	
2017-06-26 11:29:58,256 Epoch[2] Batch [480]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.215390,	
2017-06-26 11:30:05,698 Epoch[2] Batch [490]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.214956,	
2017-06-26 11:30:13,405 Epoch[2] Batch [500]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.214639,	
2017-06-26 11:30:21,152 Epoch[2] Batch [510]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.214235,	
2017-06-26 11:30:28,757 Epoch[2] Batch [520]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.213580,	
2017-06-26 11:30:36,631 Epoch[2] Batch [530]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.212911,	
2017-06-26 11:30:44,319 Epoch[2] Batch [540]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.213040,	
2017-06-26 11:30:51,797 Epoch[2] Batch [550]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.212864,	
2017-06-26 11:30:59,439 Epoch[2] Batch [560]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.213709,	
2017-06-26 11:31:07,034 Epoch[2] Batch [570]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.213107,	
2017-06-26 11:31:14,733 Epoch[2] Batch [580]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.212663,	
2017-06-26 11:31:22,361 Epoch[2] Batch [590]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.212483,	
2017-06-26 11:31:29,826 Epoch[2] Batch [600]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.212214,	
2017-06-26 11:31:37,588 Epoch[2] Batch [610]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.212009,	
2017-06-26 11:31:44,955 Epoch[2] Batch [620]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.212412,	
2017-06-26 11:31:52,311 Epoch[2] Batch [630]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.212193,	
2017-06-26 11:31:59,772 Epoch[2] Batch [640]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.213233,	
2017-06-26 11:32:07,307 Epoch[2] Batch [650]	Speed: 5.31 samples/sec	Train-FCNLogLoss=0.212991,	
2017-06-26 11:32:14,755 Epoch[2] Batch [660]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.213066,	
2017-06-26 11:32:22,131 Epoch[2] Batch [670]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.213092,	
2017-06-26 11:32:29,737 Epoch[2] Batch [680]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.212833,	
2017-06-26 11:32:37,097 Epoch[2] Batch [690]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.212597,	
2017-06-26 11:32:44,645 Epoch[2] Batch [700]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.212356,	
2017-06-26 11:32:52,218 Epoch[2] Batch [710]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.212969,	
2017-06-26 11:32:59,800 Epoch[2] Batch [720]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.213350,	
2017-06-26 11:33:07,277 Epoch[2] Batch [730]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.213316,	
2017-06-26 11:33:14,791 Epoch[2] Batch [740]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.213335,	
2017-06-26 11:33:22,358 Epoch[2] Batch [750]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.212892,	
2017-06-26 11:33:29,960 Epoch[2] Batch [760]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.212967,	
2017-06-26 11:33:37,811 Epoch[2] Batch [770]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.212819,	
2017-06-26 11:33:45,511 Epoch[2] Batch [780]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.212677,	
2017-06-26 11:33:53,408 Epoch[2] Batch [790]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.212328,	
2017-06-26 11:34:01,286 Epoch[2] Batch [800]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.212191,	
2017-06-26 11:34:09,045 Epoch[2] Batch [810]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.211978,	
2017-06-26 11:34:16,640 Epoch[2] Batch [820]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.211566,	
2017-06-26 11:34:24,460 Epoch[2] Batch [830]	Speed: 5.12 samples/sec	Train-FCNLogLoss=0.211040,	
2017-06-26 11:34:32,313 Epoch[2] Batch [840]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.210865,	
2017-06-26 11:34:40,094 Epoch[2] Batch [850]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.210563,	
2017-06-26 11:34:47,924 Epoch[2] Batch [860]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.210133,	
2017-06-26 11:34:55,842 Epoch[2] Batch [870]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.210310,	
2017-06-26 11:35:03,585 Epoch[2] Batch [880]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.209939,	
2017-06-26 11:35:11,528 Epoch[2] Batch [890]	Speed: 5.04 samples/sec	Train-FCNLogLoss=0.209543,	
2017-06-26 11:35:19,450 Epoch[2] Batch [900]	Speed: 5.05 samples/sec	Train-FCNLogLoss=0.209656,	
2017-06-26 11:35:27,235 Epoch[2] Batch [910]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.209510,	
2017-06-26 11:35:35,382 Epoch[2] Batch [920]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.209616,	
2017-06-26 11:35:43,272 Epoch[2] Batch [930]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.209333,	
2017-06-26 11:35:51,304 Epoch[2] Batch [940]	Speed: 4.98 samples/sec	Train-FCNLogLoss=0.209454,	
2017-06-26 11:35:59,382 Epoch[2] Batch [950]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.209419,	
2017-06-26 11:36:07,139 Epoch[2] Batch [960]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.209539,	
2017-06-26 11:36:14,760 Epoch[2] Batch [970]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.209217,	
2017-06-26 11:36:22,236 Epoch[2] Batch [980]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.209066,	
2017-06-26 11:36:29,891 Epoch[2] Batch [990]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.208861,	
2017-06-26 11:36:37,436 Epoch[2] Batch [1000]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.208489,	
2017-06-26 11:36:44,938 Epoch[2] Batch [1010]	Speed: 5.33 samples/sec	Train-FCNLogLoss=0.208712,	
2017-06-26 11:36:52,328 Epoch[2] Batch [1020]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.208371,	
2017-06-26 11:36:59,884 Epoch[2] Batch [1030]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.208373,	
2017-06-26 11:37:07,648 Epoch[2] Batch [1040]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.208350,	
2017-06-26 11:37:15,437 Epoch[2] Batch [1050]	Speed: 5.14 samples/sec	Train-FCNLogLoss=0.208151,	
2017-06-26 11:37:23,019 Epoch[2] Batch [1060]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.208157,	
2017-06-26 11:37:30,593 Epoch[2] Batch [1070]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.208326,	
2017-06-26 11:37:38,445 Epoch[2] Batch [1080]	Speed: 5.09 samples/sec	Train-FCNLogLoss=0.208657,	
2017-06-26 11:37:46,059 Epoch[2] Batch [1090]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.209134,	
2017-06-26 11:37:53,762 Epoch[2] Batch [1100]	Speed: 5.19 samples/sec	Train-FCNLogLoss=0.209098,	
2017-06-26 11:38:01,208 Epoch[2] Batch [1110]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.209025,	
2017-06-26 11:38:08,795 Epoch[2] Batch [1120]	Speed: 5.27 samples/sec	Train-FCNLogLoss=0.209001,	
2017-06-26 11:38:16,428 Epoch[2] Batch [1130]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.208703,	
2017-06-26 11:38:24,071 Epoch[2] Batch [1140]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.208766,	
2017-06-26 11:38:31,703 Epoch[2] Batch [1150]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.208780,	
2017-06-26 11:38:39,368 Epoch[2] Batch [1160]	Speed: 5.22 samples/sec	Train-FCNLogLoss=0.208462,	
2017-06-26 11:38:47,209 Epoch[2] Batch [1170]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.208267,	
2017-06-26 11:38:54,967 Epoch[2] Batch [1180]	Speed: 5.16 samples/sec	Train-FCNLogLoss=0.208020,	
2017-06-26 11:39:02,666 Epoch[2] Batch [1190]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.208815,	
2017-06-26 11:39:10,560 Epoch[2] Batch [1200]	Speed: 5.07 samples/sec	Train-FCNLogLoss=0.209332,	
2017-06-26 11:39:18,552 Epoch[2] Batch [1210]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.209328,	
2017-06-26 11:39:26,550 Epoch[2] Batch [1220]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.209541,	
2017-06-26 11:39:34,432 Epoch[2] Batch [1230]	Speed: 5.08 samples/sec	Train-FCNLogLoss=0.209582,	
2017-06-26 11:39:42,076 Epoch[2] Batch [1240]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.209565,	
2017-06-26 11:39:49,718 Epoch[2] Batch [1250]	Speed: 5.23 samples/sec	Train-FCNLogLoss=0.209400,	
2017-06-26 11:39:57,323 Epoch[2] Batch [1260]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.209685,	
2017-06-26 11:40:05,097 Epoch[2] Batch [1270]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.209642,	
2017-06-26 11:40:12,705 Epoch[2] Batch [1280]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.209839,	
2017-06-26 11:40:20,468 Epoch[2] Batch [1290]	Speed: 5.15 samples/sec	Train-FCNLogLoss=0.209957,	
2017-06-26 11:40:28,106 Epoch[2] Batch [1300]	Speed: 5.24 samples/sec	Train-FCNLogLoss=0.209851,	
2017-06-26 11:40:34,976 Epoch[2] Batch [1310]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.209836,	
2017-06-26 11:40:41,341 Epoch[2] Batch [1320]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.210134,	
2017-06-26 11:40:48,068 Epoch[2] Batch [1330]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.210039,	
2017-06-26 11:40:54,361 Epoch[2] Batch [1340]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.209906,	
2017-06-26 11:41:00,966 Epoch[2] Batch [1350]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.209536,	
2017-06-26 11:41:07,409 Epoch[2] Batch [1360]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.209340,	
2017-06-26 11:41:13,874 Epoch[2] Batch [1370]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.209174,	
2017-06-26 11:41:20,166 Epoch[2] Batch [1380]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.208895,	
2017-06-26 11:41:26,347 Epoch[2] Batch [1390]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.208482,	
2017-06-26 11:41:33,231 Epoch[2] Batch [1400]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.208252,	
2017-06-26 11:41:39,634 Epoch[2] Batch [1410]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.208108,	
2017-06-26 11:41:46,343 Epoch[2] Batch [1420]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.207870,	
2017-06-26 11:41:53,114 Epoch[2] Batch [1430]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.207788,	
2017-06-26 11:41:59,844 Epoch[2] Batch [1440]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.207733,	
2017-06-26 11:42:06,581 Epoch[2] Batch [1450]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.207753,	
2017-06-26 11:42:13,471 Epoch[2] Batch [1460]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.207494,	
2017-06-26 11:42:20,395 Epoch[2] Batch [1470]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.207190,	
2017-06-26 11:42:27,271 Epoch[2] Batch [1480]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.207126,	
2017-06-26 11:42:31,492 Epoch[2] Train-FCNLogLoss=0.207091
2017-06-26 11:42:31,493 Epoch[2] Time cost=1109.475
2017-06-26 11:42:32,892 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0003.params"
2017-06-26 11:42:36,661 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0003.states"
2017-06-26 11:42:44,352 Epoch[3] Batch [10]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.201408,	
2017-06-26 11:42:51,103 Epoch[3] Batch [20]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.188150,	
2017-06-26 11:42:57,913 Epoch[3] Batch [30]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.192005,	
2017-06-26 11:43:04,543 Epoch[3] Batch [40]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.189634,	
2017-06-26 11:43:11,474 Epoch[3] Batch [50]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.184447,	
2017-06-26 11:43:18,347 Epoch[3] Batch [60]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.183813,	
2017-06-26 11:43:24,895 Epoch[3] Batch [70]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.188058,	
2017-06-26 11:43:31,739 Epoch[3] Batch [80]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.187841,	
2017-06-26 11:43:38,373 Epoch[3] Batch [90]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.184889,	
2017-06-26 11:43:45,017 Epoch[3] Batch [100]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.185164,	
2017-06-26 11:43:52,121 Epoch[3] Batch [110]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.185872,	
2017-06-26 11:43:58,872 Epoch[3] Batch [120]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.186084,	
2017-06-26 11:44:05,068 Epoch[3] Batch [130]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.192962,	
2017-06-26 11:44:11,580 Epoch[3] Batch [140]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.192979,	
2017-06-26 11:44:18,485 Epoch[3] Batch [150]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.190936,	
2017-06-26 11:44:25,288 Epoch[3] Batch [160]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.190686,	
2017-06-26 11:44:31,802 Epoch[3] Batch [170]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.189875,	
2017-06-26 11:44:38,636 Epoch[3] Batch [180]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.190143,	
2017-06-26 11:44:45,295 Epoch[3] Batch [190]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.188611,	
2017-06-26 11:44:52,113 Epoch[3] Batch [200]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.190307,	
2017-06-26 11:44:58,854 Epoch[3] Batch [210]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.190003,	
2017-06-26 11:45:05,721 Epoch[3] Batch [220]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.188771,	
2017-06-26 11:45:12,415 Epoch[3] Batch [230]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.188724,	
2017-06-26 11:45:19,428 Epoch[3] Batch [240]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.188859,	
2017-06-26 11:45:26,541 Epoch[3] Batch [250]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.189476,	
2017-06-26 11:45:33,422 Epoch[3] Batch [260]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.189356,	
2017-06-26 11:45:40,177 Epoch[3] Batch [270]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.190228,	
2017-06-26 11:45:47,015 Epoch[3] Batch [280]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.192298,	
2017-06-26 11:45:53,933 Epoch[3] Batch [290]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.192511,	
2017-06-26 11:46:00,729 Epoch[3] Batch [300]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.193235,	
2017-06-26 11:46:08,007 Epoch[3] Batch [310]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.193960,	
2017-06-26 11:46:15,099 Epoch[3] Batch [320]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.193733,	
2017-06-26 11:46:22,139 Epoch[3] Batch [330]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.193646,	
2017-06-26 11:46:29,366 Epoch[3] Batch [340]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.193030,	
2017-06-26 11:46:36,179 Epoch[3] Batch [350]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.192677,	
2017-06-26 11:46:42,539 Epoch[3] Batch [360]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.191775,	
2017-06-26 11:46:49,352 Epoch[3] Batch [370]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.191569,	
2017-06-26 11:46:56,667 Epoch[3] Batch [380]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.191795,	
2017-06-26 11:47:03,531 Epoch[3] Batch [390]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.190978,	
2017-06-26 11:47:10,668 Epoch[3] Batch [400]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.191158,	
2017-06-26 11:47:17,656 Epoch[3] Batch [410]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.190865,	
2017-06-26 11:47:24,484 Epoch[3] Batch [420]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.189755,	
2017-06-26 11:47:31,633 Epoch[3] Batch [430]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.189976,	
2017-06-26 11:47:38,401 Epoch[3] Batch [440]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.189747,	
2017-06-26 11:47:45,305 Epoch[3] Batch [450]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.189558,	
2017-06-26 11:47:50,813 Epoch[3] Batch [460]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.189969,	
2017-06-26 11:47:56,987 Epoch[3] Batch [470]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.190008,	
2017-06-26 11:48:03,378 Epoch[3] Batch [480]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.190466,	
2017-06-26 11:48:09,512 Epoch[3] Batch [490]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.190745,	
2017-06-26 11:48:15,987 Epoch[3] Batch [500]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.190888,	
2017-06-26 11:48:22,602 Epoch[3] Batch [510]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.191636,	
2017-06-26 11:48:29,503 Epoch[3] Batch [520]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.191888,	
2017-06-26 11:48:36,852 Epoch[3] Batch [530]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.192381,	
2017-06-26 11:48:43,058 Epoch[3] Batch [540]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.192607,	
2017-06-26 11:48:49,147 Epoch[3] Batch [550]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.192208,	
2017-06-26 11:48:55,267 Epoch[3] Batch [560]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.191807,	
2017-06-26 11:49:01,318 Epoch[3] Batch [570]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.191630,	
2017-06-26 11:49:07,413 Epoch[3] Batch [580]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.191198,	
2017-06-26 11:49:13,431 Epoch[3] Batch [590]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.191191,	
2017-06-26 11:49:19,536 Epoch[3] Batch [600]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.191720,	
2017-06-26 11:49:25,684 Epoch[3] Batch [610]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.191155,	
2017-06-26 11:49:31,743 Epoch[3] Batch [620]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.190848,	
2017-06-26 11:49:37,840 Epoch[3] Batch [630]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.190509,	
2017-06-26 11:49:43,941 Epoch[3] Batch [640]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.190207,	
2017-06-26 11:49:50,128 Epoch[3] Batch [650]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.190251,	
2017-06-26 11:49:56,220 Epoch[3] Batch [660]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.190265,	
2017-06-26 11:50:02,350 Epoch[3] Batch [670]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.190202,	
2017-06-26 11:50:08,458 Epoch[3] Batch [680]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.189848,	
2017-06-26 11:50:14,533 Epoch[3] Batch [690]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.189262,	
2017-06-26 11:50:20,653 Epoch[3] Batch [700]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.189168,	
2017-06-26 11:50:26,772 Epoch[3] Batch [710]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.189010,	
2017-06-26 11:50:32,916 Epoch[3] Batch [720]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.188470,	
2017-06-26 11:50:39,006 Epoch[3] Batch [730]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.188340,	
2017-06-26 11:50:45,104 Epoch[3] Batch [740]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.188217,	
2017-06-26 11:50:51,274 Epoch[3] Batch [750]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.188204,	
2017-06-26 11:50:57,370 Epoch[3] Batch [760]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.188331,	
2017-06-26 11:51:03,465 Epoch[3] Batch [770]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.187912,	
2017-06-26 11:51:10,111 Epoch[3] Batch [780]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.187958,	
2017-06-26 11:51:16,279 Epoch[3] Batch [790]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.187476,	
2017-06-26 11:51:22,454 Epoch[3] Batch [800]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.188400,	
2017-06-26 11:51:28,616 Epoch[3] Batch [810]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.188604,	
2017-06-26 11:51:34,692 Epoch[3] Batch [820]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.188726,	
2017-06-26 11:51:40,860 Epoch[3] Batch [830]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.188869,	
2017-06-26 11:51:46,957 Epoch[3] Batch [840]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.189144,	
2017-06-26 11:51:53,103 Epoch[3] Batch [850]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.189184,	
2017-06-26 11:51:59,186 Epoch[3] Batch [860]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.189097,	
2017-06-26 11:52:05,269 Epoch[3] Batch [870]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.188682,	
2017-06-26 11:52:11,390 Epoch[3] Batch [880]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.188864,	
2017-06-26 11:52:17,517 Epoch[3] Batch [890]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.188771,	
2017-06-26 11:52:23,568 Epoch[3] Batch [900]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.188729,	
2017-06-26 11:52:29,699 Epoch[3] Batch [910]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.188601,	
2017-06-26 11:52:35,809 Epoch[3] Batch [920]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.188575,	
2017-06-26 11:52:41,969 Epoch[3] Batch [930]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.188663,	
2017-06-26 11:52:48,097 Epoch[3] Batch [940]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.188446,	
2017-06-26 11:52:54,211 Epoch[3] Batch [950]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.188607,	
2017-06-26 11:53:00,302 Epoch[3] Batch [960]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.188358,	
2017-06-26 11:53:06,372 Epoch[3] Batch [970]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.188052,	
2017-06-26 11:53:12,445 Epoch[3] Batch [980]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.187768,	
2017-06-26 11:53:18,517 Epoch[3] Batch [990]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.187400,	
2017-06-26 11:53:24,650 Epoch[3] Batch [1000]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.187213,	
2017-06-26 11:53:30,734 Epoch[3] Batch [1010]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.187026,	
2017-06-26 11:53:36,889 Epoch[3] Batch [1020]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.187013,	
2017-06-26 11:53:43,023 Epoch[3] Batch [1030]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.186848,	
2017-06-26 11:53:49,163 Epoch[3] Batch [1040]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.186615,	
2017-06-26 11:53:55,235 Epoch[3] Batch [1050]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.186610,	
2017-06-26 11:54:01,307 Epoch[3] Batch [1060]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.186588,	
2017-06-26 11:54:07,478 Epoch[3] Batch [1070]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.186563,	
2017-06-26 11:54:13,523 Epoch[3] Batch [1080]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.186553,	
2017-06-26 11:54:19,652 Epoch[3] Batch [1090]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.186470,	
2017-06-26 11:54:25,776 Epoch[3] Batch [1100]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.186365,	
2017-06-26 11:54:31,893 Epoch[3] Batch [1110]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.186294,	
2017-06-26 11:54:37,991 Epoch[3] Batch [1120]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.185968,	
2017-06-26 11:54:44,118 Epoch[3] Batch [1130]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.185759,	
2017-06-26 11:54:50,228 Epoch[3] Batch [1140]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.185500,	
2017-06-26 11:54:56,348 Epoch[3] Batch [1150]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.185415,	
2017-06-26 11:55:02,329 Epoch[3] Batch [1160]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.185266,	
2017-06-26 11:55:08,940 Epoch[3] Batch [1170]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.185137,	
2017-06-26 11:55:15,336 Epoch[3] Batch [1180]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.185225,	
2017-06-26 11:55:21,368 Epoch[3] Batch [1190]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.185148,	
2017-06-26 11:55:27,461 Epoch[3] Batch [1200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.185050,	
2017-06-26 11:55:33,560 Epoch[3] Batch [1210]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.184882,	
2017-06-26 11:55:39,653 Epoch[3] Batch [1220]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.185108,	
2017-06-26 11:55:45,779 Epoch[3] Batch [1230]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.185110,	
2017-06-26 11:55:51,846 Epoch[3] Batch [1240]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.185087,	
2017-06-26 11:55:57,983 Epoch[3] Batch [1250]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.185162,	
2017-06-26 11:56:04,086 Epoch[3] Batch [1260]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.185322,	
2017-06-26 11:56:10,229 Epoch[3] Batch [1270]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.185333,	
2017-06-26 11:56:16,313 Epoch[3] Batch [1280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.185363,	
2017-06-26 11:56:22,378 Epoch[3] Batch [1290]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.185476,	
2017-06-26 11:56:28,505 Epoch[3] Batch [1300]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.185544,	
2017-06-26 11:56:34,614 Epoch[3] Batch [1310]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.185650,	
2017-06-26 11:56:40,750 Epoch[3] Batch [1320]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.185554,	
2017-06-26 11:56:46,863 Epoch[3] Batch [1330]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.185482,	
2017-06-26 11:56:53,012 Epoch[3] Batch [1340]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.185481,	
2017-06-26 11:56:59,100 Epoch[3] Batch [1350]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.185553,	
2017-06-26 11:57:05,242 Epoch[3] Batch [1360]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.185379,	
2017-06-26 11:57:11,351 Epoch[3] Batch [1370]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.185230,	
2017-06-26 11:57:17,453 Epoch[3] Batch [1380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.185330,	
2017-06-26 11:57:23,571 Epoch[3] Batch [1390]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.185239,	
2017-06-26 11:57:29,739 Epoch[3] Batch [1400]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.185070,	
2017-06-26 11:57:35,761 Epoch[3] Batch [1410]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.185024,	
2017-06-26 11:57:41,811 Epoch[3] Batch [1420]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.184856,	
2017-06-26 11:57:47,935 Epoch[3] Batch [1430]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.184926,	
2017-06-26 11:57:54,017 Epoch[3] Batch [1440]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.185009,	
2017-06-26 11:58:00,258 Epoch[3] Batch [1450]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.185013,	
2017-06-26 11:58:06,220 Epoch[3] Batch [1460]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.184860,	
2017-06-26 11:58:12,288 Epoch[3] Batch [1470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.184816,	
2017-06-26 11:58:18,436 Epoch[3] Batch [1480]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.184866,	
2017-06-26 11:58:22,132 Epoch[3] Train-FCNLogLoss=0.184942
2017-06-26 11:58:22,132 Epoch[3] Time cost=945.471
2017-06-26 11:58:23,178 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0004.params"
2017-06-26 11:58:25,256 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0004.states"
2017-06-26 11:58:32,112 Epoch[4] Batch [10]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.216898,	
2017-06-26 11:58:38,122 Epoch[4] Batch [20]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.203414,	
2017-06-26 11:58:44,200 Epoch[4] Batch [30]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.200799,	
2017-06-26 11:58:50,407 Epoch[4] Batch [40]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.194927,	
2017-06-26 11:58:56,517 Epoch[4] Batch [50]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.194030,	
2017-06-26 11:59:02,718 Epoch[4] Batch [60]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.191357,	
2017-06-26 11:59:09,390 Epoch[4] Batch [70]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.191735,	
2017-06-26 11:59:15,465 Epoch[4] Batch [80]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.191595,	
2017-06-26 11:59:21,481 Epoch[4] Batch [90]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.187339,	
2017-06-26 11:59:27,172 Epoch[4] Batch [100]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.188103,	
2017-06-26 11:59:31,941 Epoch[4] Batch [110]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.186700,	
2017-06-26 11:59:37,920 Epoch[4] Batch [120]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.185950,	
2017-06-26 11:59:43,947 Epoch[4] Batch [130]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.183377,	
2017-06-26 11:59:50,050 Epoch[4] Batch [140]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.183890,	
2017-06-26 11:59:56,132 Epoch[4] Batch [150]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.184086,	
2017-06-26 12:00:02,251 Epoch[4] Batch [160]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.183391,	
2017-06-26 12:00:08,307 Epoch[4] Batch [170]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.183298,	
2017-06-26 12:00:14,375 Epoch[4] Batch [180]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.182052,	
2017-06-26 12:00:20,461 Epoch[4] Batch [190]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.181049,	
2017-06-26 12:00:26,568 Epoch[4] Batch [200]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.179832,	
2017-06-26 12:00:32,637 Epoch[4] Batch [210]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.179180,	
2017-06-26 12:00:38,751 Epoch[4] Batch [220]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.179758,	
2017-06-26 12:00:44,865 Epoch[4] Batch [230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.178886,	
2017-06-26 12:00:50,998 Epoch[4] Batch [240]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.178835,	
2017-06-26 12:00:57,109 Epoch[4] Batch [250]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.179153,	
2017-06-26 12:01:03,230 Epoch[4] Batch [260]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.178055,	
2017-06-26 12:01:09,353 Epoch[4] Batch [270]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.178838,	
2017-06-26 12:01:15,430 Epoch[4] Batch [280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.178717,	
2017-06-26 12:01:21,573 Epoch[4] Batch [290]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.178819,	
2017-06-26 12:01:27,637 Epoch[4] Batch [300]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.178346,	
2017-06-26 12:01:33,814 Epoch[4] Batch [310]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.178538,	
2017-06-26 12:01:39,912 Epoch[4] Batch [320]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.178025,	
2017-06-26 12:01:46,043 Epoch[4] Batch [330]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.177307,	
2017-06-26 12:01:52,197 Epoch[4] Batch [340]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.178126,	
2017-06-26 12:01:58,299 Epoch[4] Batch [350]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.178389,	
2017-06-26 12:02:04,381 Epoch[4] Batch [360]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.178836,	
2017-06-26 12:02:10,499 Epoch[4] Batch [370]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.178877,	
2017-06-26 12:02:16,615 Epoch[4] Batch [380]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.179773,	
2017-06-26 12:02:22,784 Epoch[4] Batch [390]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.180027,	
2017-06-26 12:02:28,835 Epoch[4] Batch [400]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.179952,	
2017-06-26 12:02:34,945 Epoch[4] Batch [410]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.179977,	
2017-06-26 12:02:41,023 Epoch[4] Batch [420]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.179606,	
2017-06-26 12:02:47,145 Epoch[4] Batch [430]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.179030,	
2017-06-26 12:02:53,212 Epoch[4] Batch [440]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.178819,	
2017-06-26 12:02:59,907 Epoch[4] Batch [450]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.178641,	
2017-06-26 12:03:06,120 Epoch[4] Batch [460]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.178434,	
2017-06-26 12:03:12,169 Epoch[4] Batch [470]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.177946,	
2017-06-26 12:03:18,251 Epoch[4] Batch [480]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.178380,	
2017-06-26 12:03:24,331 Epoch[4] Batch [490]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.178538,	
2017-06-26 12:03:30,422 Epoch[4] Batch [500]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.177922,	
2017-06-26 12:03:36,525 Epoch[4] Batch [510]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.178237,	
2017-06-26 12:03:42,638 Epoch[4] Batch [520]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.177905,	
2017-06-26 12:03:48,812 Epoch[4] Batch [530]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.177571,	
2017-06-26 12:03:54,900 Epoch[4] Batch [540]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.178193,	
2017-06-26 12:04:01,067 Epoch[4] Batch [550]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.177743,	
2017-06-26 12:04:07,232 Epoch[4] Batch [560]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.177378,	
2017-06-26 12:04:13,333 Epoch[4] Batch [570]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.177549,	
2017-06-26 12:04:19,503 Epoch[4] Batch [580]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.177467,	
2017-06-26 12:04:25,609 Epoch[4] Batch [590]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.177428,	
2017-06-26 12:04:31,747 Epoch[4] Batch [600]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.178344,	
2017-06-26 12:04:37,910 Epoch[4] Batch [610]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.179215,	
2017-06-26 12:04:44,036 Epoch[4] Batch [620]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.179673,	
2017-06-26 12:04:50,169 Epoch[4] Batch [630]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.179893,	
2017-06-26 12:04:56,286 Epoch[4] Batch [640]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.179613,	
2017-06-26 12:05:02,371 Epoch[4] Batch [650]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.179509,	
2017-06-26 12:05:08,493 Epoch[4] Batch [660]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.179178,	
2017-06-26 12:05:14,617 Epoch[4] Batch [670]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.179143,	
2017-06-26 12:05:20,733 Epoch[4] Batch [680]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.179143,	
2017-06-26 12:05:26,868 Epoch[4] Batch [690]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.178861,	
2017-06-26 12:05:32,934 Epoch[4] Batch [700]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.178829,	
2017-06-26 12:05:39,079 Epoch[4] Batch [710]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.178450,	
2017-06-26 12:05:45,156 Epoch[4] Batch [720]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.178430,	
2017-06-26 12:05:51,260 Epoch[4] Batch [730]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.178402,	
2017-06-26 12:05:57,355 Epoch[4] Batch [740]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.178097,	
2017-06-26 12:06:03,445 Epoch[4] Batch [750]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.178291,	
2017-06-26 12:06:09,581 Epoch[4] Batch [760]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.178097,	
2017-06-26 12:06:15,693 Epoch[4] Batch [770]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.177823,	
2017-06-26 12:06:21,805 Epoch[4] Batch [780]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.177621,	
2017-06-26 12:06:27,889 Epoch[4] Batch [790]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.177366,	
2017-06-26 12:06:33,978 Epoch[4] Batch [800]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.177055,	
2017-06-26 12:06:40,050 Epoch[4] Batch [810]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.176915,	
2017-06-26 12:06:46,123 Epoch[4] Batch [820]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.176726,	
2017-06-26 12:06:52,187 Epoch[4] Batch [830]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.176516,	
2017-06-26 12:06:58,502 Epoch[4] Batch [840]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.176106,	
2017-06-26 12:07:05,192 Epoch[4] Batch [850]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.176053,	
2017-06-26 12:07:11,103 Epoch[4] Batch [860]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.176368,	
2017-06-26 12:07:17,209 Epoch[4] Batch [870]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.176696,	
2017-06-26 12:07:23,347 Epoch[4] Batch [880]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.176797,	
2017-06-26 12:07:29,460 Epoch[4] Batch [890]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.176853,	
2017-06-26 12:07:35,568 Epoch[4] Batch [900]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.176565,	
2017-06-26 12:07:41,698 Epoch[4] Batch [910]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.176463,	
2017-06-26 12:07:47,823 Epoch[4] Batch [920]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.176359,	
2017-06-26 12:07:53,907 Epoch[4] Batch [930]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.176264,	
2017-06-26 12:08:00,015 Epoch[4] Batch [940]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.176065,	
2017-06-26 12:08:06,099 Epoch[4] Batch [950]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.176037,	
2017-06-26 12:08:12,240 Epoch[4] Batch [960]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.175995,	
2017-06-26 12:08:18,319 Epoch[4] Batch [970]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.175894,	
2017-06-26 12:08:24,476 Epoch[4] Batch [980]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.175779,	
2017-06-26 12:08:30,555 Epoch[4] Batch [990]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.175810,	
2017-06-26 12:08:36,625 Epoch[4] Batch [1000]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.175738,	
2017-06-26 12:08:42,756 Epoch[4] Batch [1010]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.175672,	
2017-06-26 12:08:48,864 Epoch[4] Batch [1020]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.175574,	
2017-06-26 12:08:54,982 Epoch[4] Batch [1030]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.175199,	
2017-06-26 12:09:01,101 Epoch[4] Batch [1040]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.175115,	
2017-06-26 12:09:07,191 Epoch[4] Batch [1050]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.174999,	
2017-06-26 12:09:13,266 Epoch[4] Batch [1060]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.174902,	
2017-06-26 12:09:19,382 Epoch[4] Batch [1070]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.175050,	
2017-06-26 12:09:25,522 Epoch[4] Batch [1080]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.174920,	
2017-06-26 12:09:31,613 Epoch[4] Batch [1090]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.174873,	
2017-06-26 12:09:37,785 Epoch[4] Batch [1100]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.174692,	
2017-06-26 12:09:43,904 Epoch[4] Batch [1110]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.174603,	
2017-06-26 12:09:49,983 Epoch[4] Batch [1120]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.174819,	
2017-06-26 12:09:56,038 Epoch[4] Batch [1130]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.174773,	
2017-06-26 12:10:02,224 Epoch[4] Batch [1140]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.174747,	
2017-06-26 12:10:08,288 Epoch[4] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.174749,	
2017-06-26 12:10:14,416 Epoch[4] Batch [1160]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.174574,	
2017-06-26 12:10:20,444 Epoch[4] Batch [1170]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.174433,	
2017-06-26 12:10:26,639 Epoch[4] Batch [1180]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.174577,	
2017-06-26 12:10:32,655 Epoch[4] Batch [1190]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.174633,	
2017-06-26 12:10:38,777 Epoch[4] Batch [1200]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.174374,	
2017-06-26 12:10:44,845 Epoch[4] Batch [1210]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.174357,	
2017-06-26 12:10:50,970 Epoch[4] Batch [1220]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.174272,	
2017-06-26 12:10:56,986 Epoch[4] Batch [1230]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.174266,	
2017-06-26 12:11:03,676 Epoch[4] Batch [1240]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.174193,	
2017-06-26 12:11:10,033 Epoch[4] Batch [1250]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.174201,	
2017-06-26 12:11:16,102 Epoch[4] Batch [1260]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.174810,	
2017-06-26 12:11:22,214 Epoch[4] Batch [1270]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.174884,	
2017-06-26 12:11:28,296 Epoch[4] Batch [1280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.174836,	
2017-06-26 12:11:34,462 Epoch[4] Batch [1290]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.174967,	
2017-06-26 12:11:40,556 Epoch[4] Batch [1300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.175041,	
2017-06-26 12:11:46,641 Epoch[4] Batch [1310]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.175061,	
2017-06-26 12:11:52,808 Epoch[4] Batch [1320]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.175006,	
2017-06-26 12:11:58,889 Epoch[4] Batch [1330]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.174955,	
2017-06-26 12:12:04,988 Epoch[4] Batch [1340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.174871,	
2017-06-26 12:12:11,119 Epoch[4] Batch [1350]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.174756,	
2017-06-26 12:12:17,233 Epoch[4] Batch [1360]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.174671,	
2017-06-26 12:12:23,485 Epoch[4] Batch [1370]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.174518,	
2017-06-26 12:12:29,465 Epoch[4] Batch [1380]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.174325,	
2017-06-26 12:12:35,590 Epoch[4] Batch [1390]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.174299,	
2017-06-26 12:12:41,734 Epoch[4] Batch [1400]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.174389,	
2017-06-26 12:12:47,811 Epoch[4] Batch [1410]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.174276,	
2017-06-26 12:12:53,883 Epoch[4] Batch [1420]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.174119,	
2017-06-26 12:12:59,989 Epoch[4] Batch [1430]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.174241,	
2017-06-26 12:13:06,155 Epoch[4] Batch [1440]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.174113,	
2017-06-26 12:13:12,217 Epoch[4] Batch [1450]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.174156,	
2017-06-26 12:13:18,331 Epoch[4] Batch [1460]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.174147,	
2017-06-26 12:13:24,439 Epoch[4] Batch [1470]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.174154,	
2017-06-26 12:13:30,536 Epoch[4] Batch [1480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.174132,	
2017-06-26 12:13:34,213 Epoch[4] Train-FCNLogLoss=0.174105
2017-06-26 12:13:34,213 Epoch[4] Time cost=908.956
2017-06-26 12:13:35,425 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0005.params"
2017-06-26 12:13:37,443 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0005.states"
2017-06-26 12:13:44,283 Epoch[5] Batch [10]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.163592,	
2017-06-26 12:13:50,408 Epoch[5] Batch [20]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.152769,	
2017-06-26 12:13:56,517 Epoch[5] Batch [30]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.152355,	
2017-06-26 12:14:02,631 Epoch[5] Batch [40]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.151419,	
2017-06-26 12:14:08,699 Epoch[5] Batch [50]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.151139,	
2017-06-26 12:14:14,799 Epoch[5] Batch [60]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.158297,	
2017-06-26 12:14:20,873 Epoch[5] Batch [70]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.157734,	
2017-06-26 12:14:26,957 Epoch[5] Batch [80]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.159206,	
2017-06-26 12:14:33,080 Epoch[5] Batch [90]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.159486,	
2017-06-26 12:14:39,146 Epoch[5] Batch [100]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.161506,	
2017-06-26 12:14:44,313 Epoch[5] Batch [110]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.161575,	
2017-06-26 12:14:50,281 Epoch[5] Batch [120]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.161950,	
2017-06-26 12:14:56,865 Epoch[5] Batch [130]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.163601,	
2017-06-26 12:15:02,880 Epoch[5] Batch [140]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.164957,	
2017-06-26 12:15:08,973 Epoch[5] Batch [150]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.164454,	
2017-06-26 12:15:15,167 Epoch[5] Batch [160]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.165034,	
2017-06-26 12:15:21,263 Epoch[5] Batch [170]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.164787,	
2017-06-26 12:15:27,398 Epoch[5] Batch [180]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.165799,	
2017-06-26 12:15:33,512 Epoch[5] Batch [190]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.165501,	
2017-06-26 12:15:39,672 Epoch[5] Batch [200]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.166030,	
2017-06-26 12:15:45,741 Epoch[5] Batch [210]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.165517,	
2017-06-26 12:15:51,885 Epoch[5] Batch [220]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.164934,	
2017-06-26 12:15:58,046 Epoch[5] Batch [230]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.164471,	
2017-06-26 12:16:04,087 Epoch[5] Batch [240]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.163730,	
2017-06-26 12:16:10,184 Epoch[5] Batch [250]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.163295,	
2017-06-26 12:16:16,370 Epoch[5] Batch [260]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.162659,	
2017-06-26 12:16:22,427 Epoch[5] Batch [270]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.161816,	
2017-06-26 12:16:28,474 Epoch[5] Batch [280]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.162721,	
2017-06-26 12:16:34,617 Epoch[5] Batch [290]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.163821,	
2017-06-26 12:16:40,729 Epoch[5] Batch [300]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164128,	
2017-06-26 12:16:46,835 Epoch[5] Batch [310]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164023,	
2017-06-26 12:16:52,936 Epoch[5] Batch [320]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.164550,	
2017-06-26 12:16:59,033 Epoch[5] Batch [330]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.164818,	
2017-06-26 12:17:05,082 Epoch[5] Batch [340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.164703,	
2017-06-26 12:17:11,197 Epoch[5] Batch [350]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.164230,	
2017-06-26 12:17:17,339 Epoch[5] Batch [360]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.163890,	
2017-06-26 12:17:23,452 Epoch[5] Batch [370]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.163804,	
2017-06-26 12:17:29,553 Epoch[5] Batch [380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.163898,	
2017-06-26 12:17:35,728 Epoch[5] Batch [390]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.162975,	
2017-06-26 12:17:41,826 Epoch[5] Batch [400]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.162808,	
2017-06-26 12:17:47,938 Epoch[5] Batch [410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.162659,	
2017-06-26 12:17:54,070 Epoch[5] Batch [420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.163104,	
2017-06-26 12:18:00,240 Epoch[5] Batch [430]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.163152,	
2017-06-26 12:18:06,287 Epoch[5] Batch [440]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.163205,	
2017-06-26 12:18:12,356 Epoch[5] Batch [450]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.163218,	
2017-06-26 12:18:18,547 Epoch[5] Batch [460]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.163183,	
2017-06-26 12:18:24,643 Epoch[5] Batch [470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.162565,	
2017-06-26 12:18:30,717 Epoch[5] Batch [480]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.162285,	
2017-06-26 12:18:36,858 Epoch[5] Batch [490]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.161984,	
2017-06-26 12:18:42,964 Epoch[5] Batch [500]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.161398,	
2017-06-26 12:18:49,031 Epoch[5] Batch [510]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.161368,	
2017-06-26 12:18:55,423 Epoch[5] Batch [520]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.161567,	
2017-06-26 12:19:01,952 Epoch[5] Batch [530]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.161310,	
2017-06-26 12:19:07,918 Epoch[5] Batch [540]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.161547,	
2017-06-26 12:19:14,036 Epoch[5] Batch [550]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.162582,	
2017-06-26 12:19:20,174 Epoch[5] Batch [560]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.162811,	
2017-06-26 12:19:26,299 Epoch[5] Batch [570]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.163034,	
2017-06-26 12:19:32,388 Epoch[5] Batch [580]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.162981,	
2017-06-26 12:19:38,482 Epoch[5] Batch [590]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.163123,	
2017-06-26 12:19:44,600 Epoch[5] Batch [600]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.163189,	
2017-06-26 12:19:50,790 Epoch[5] Batch [610]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.163166,	
2017-06-26 12:19:56,777 Epoch[5] Batch [620]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.163184,	
2017-06-26 12:20:02,932 Epoch[5] Batch [630]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.163145,	
2017-06-26 12:20:08,991 Epoch[5] Batch [640]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.162945,	
2017-06-26 12:20:15,092 Epoch[5] Batch [650]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.163435,	
2017-06-26 12:20:21,232 Epoch[5] Batch [660]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.163147,	
2017-06-26 12:20:27,347 Epoch[5] Batch [670]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.162850,	
2017-06-26 12:20:33,485 Epoch[5] Batch [680]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.162758,	
2017-06-26 12:20:39,774 Epoch[5] Batch [690]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.162741,	
2017-06-26 12:20:45,915 Epoch[5] Batch [700]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.162615,	
2017-06-26 12:20:52,071 Epoch[5] Batch [710]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.162730,	
2017-06-26 12:20:58,104 Epoch[5] Batch [720]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.162733,	
2017-06-26 12:21:04,174 Epoch[5] Batch [730]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.162393,	
2017-06-26 12:21:10,372 Epoch[5] Batch [740]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.162440,	
2017-06-26 12:21:16,439 Epoch[5] Batch [750]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.162284,	
2017-06-26 12:21:22,526 Epoch[5] Batch [760]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.162381,	
2017-06-26 12:21:28,699 Epoch[5] Batch [770]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.162472,	
2017-06-26 12:21:34,746 Epoch[5] Batch [780]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.162655,	
2017-06-26 12:21:40,811 Epoch[5] Batch [790]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.162614,	
2017-06-26 12:21:47,018 Epoch[5] Batch [800]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.162632,	
2017-06-26 12:21:53,129 Epoch[5] Batch [810]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.162726,	
2017-06-26 12:21:59,178 Epoch[5] Batch [820]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.162770,	
2017-06-26 12:22:05,332 Epoch[5] Batch [830]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.163114,	
2017-06-26 12:22:11,438 Epoch[5] Batch [840]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.163068,	
2017-06-26 12:22:17,540 Epoch[5] Batch [850]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.163227,	
2017-06-26 12:22:23,597 Epoch[5] Batch [860]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.163134,	
2017-06-26 12:22:29,689 Epoch[5] Batch [870]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.163316,	
2017-06-26 12:22:35,787 Epoch[5] Batch [880]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.163378,	
2017-06-26 12:22:41,872 Epoch[5] Batch [890]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.163440,	
2017-06-26 12:22:48,064 Epoch[5] Batch [900]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.163515,	
2017-06-26 12:22:54,122 Epoch[5] Batch [910]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.163589,	
2017-06-26 12:23:00,617 Epoch[5] Batch [920]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.163327,	
2017-06-26 12:23:07,046 Epoch[5] Batch [930]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.163286,	
2017-06-26 12:23:13,113 Epoch[5] Batch [940]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.163546,	
2017-06-26 12:23:19,194 Epoch[5] Batch [950]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.163673,	
2017-06-26 12:23:25,314 Epoch[5] Batch [960]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.163799,	
2017-06-26 12:23:31,417 Epoch[5] Batch [970]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164189,	
2017-06-26 12:23:37,526 Epoch[5] Batch [980]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164293,	
2017-06-26 12:23:43,621 Epoch[5] Batch [990]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.164424,	
2017-06-26 12:23:49,694 Epoch[5] Batch [1000]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.164595,	
2017-06-26 12:23:55,777 Epoch[5] Batch [1010]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.164597,	
2017-06-26 12:24:01,883 Epoch[5] Batch [1020]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.164328,	
2017-06-26 12:24:07,942 Epoch[5] Batch [1030]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.164655,	
2017-06-26 12:24:14,112 Epoch[5] Batch [1040]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.164695,	
2017-06-26 12:24:20,315 Epoch[5] Batch [1050]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.164821,	
2017-06-26 12:24:26,426 Epoch[5] Batch [1060]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165194,	
2017-06-26 12:24:32,540 Epoch[5] Batch [1070]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.165757,	
2017-06-26 12:24:38,665 Epoch[5] Batch [1080]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165632,	
2017-06-26 12:24:44,788 Epoch[5] Batch [1090]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165755,	
2017-06-26 12:24:50,960 Epoch[5] Batch [1100]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.165934,	
2017-06-26 12:24:57,041 Epoch[5] Batch [1110]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.165820,	
2017-06-26 12:25:03,157 Epoch[5] Batch [1120]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.165660,	
2017-06-26 12:25:09,260 Epoch[5] Batch [1130]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165786,	
2017-06-26 12:25:15,390 Epoch[5] Batch [1140]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165648,	
2017-06-26 12:25:21,490 Epoch[5] Batch [1150]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.165525,	
2017-06-26 12:25:27,573 Epoch[5] Batch [1160]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.165784,	
2017-06-26 12:25:33,667 Epoch[5] Batch [1170]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.165634,	
2017-06-26 12:25:39,702 Epoch[5] Batch [1180]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.165548,	
2017-06-26 12:25:45,803 Epoch[5] Batch [1190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.165594,	
2017-06-26 12:25:51,886 Epoch[5] Batch [1200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.165538,	
2017-06-26 12:25:57,981 Epoch[5] Batch [1210]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.165824,	
2017-06-26 12:26:04,014 Epoch[5] Batch [1220]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.165754,	
2017-06-26 12:26:10,118 Epoch[5] Batch [1230]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165783,	
2017-06-26 12:26:16,178 Epoch[5] Batch [1240]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.165829,	
2017-06-26 12:26:22,278 Epoch[5] Batch [1250]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.165727,	
2017-06-26 12:26:28,327 Epoch[5] Batch [1260]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.165522,	
2017-06-26 12:26:34,491 Epoch[5] Batch [1270]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.165608,	
2017-06-26 12:26:40,601 Epoch[5] Batch [1280]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165614,	
2017-06-26 12:26:46,695 Epoch[5] Batch [1290]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.165675,	
2017-06-26 12:26:52,862 Epoch[5] Batch [1300]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.165641,	
2017-06-26 12:26:58,917 Epoch[5] Batch [1310]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.165760,	
2017-06-26 12:27:05,607 Epoch[5] Batch [1320]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.165828,	
2017-06-26 12:27:11,880 Epoch[5] Batch [1330]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.165962,	
2017-06-26 12:27:17,921 Epoch[5] Batch [1340]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.165843,	
2017-06-26 12:27:24,047 Epoch[5] Batch [1350]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.165876,	
2017-06-26 12:27:29,968 Epoch[5] Batch [1360]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.165863,	
2017-06-26 12:27:35,883 Epoch[5] Batch [1370]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.166014,	
2017-06-26 12:27:41,907 Epoch[5] Batch [1380]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.165973,	
2017-06-26 12:27:48,012 Epoch[5] Batch [1390]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.166037,	
2017-06-26 12:27:54,137 Epoch[5] Batch [1400]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.166161,	
2017-06-26 12:28:00,236 Epoch[5] Batch [1410]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.166088,	
2017-06-26 12:28:06,408 Epoch[5] Batch [1420]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.165919,	
2017-06-26 12:28:12,495 Epoch[5] Batch [1430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.165740,	
2017-06-26 12:28:18,598 Epoch[5] Batch [1440]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.165794,	
2017-06-26 12:28:24,384 Epoch[5] Batch [1450]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.165623,	
2017-06-26 12:28:30,107 Epoch[5] Batch [1460]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.165542,	
2017-06-26 12:28:36,023 Epoch[5] Batch [1470]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.165353,	
2017-06-26 12:28:42,182 Epoch[5] Batch [1480]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.165380,	
2017-06-26 12:28:45,744 Epoch[5] Train-FCNLogLoss=0.165342
2017-06-26 12:28:45,744 Epoch[5] Time cost=908.300
2017-06-26 12:28:47,195 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0006.params"
2017-06-26 12:28:49,009 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0006.states"
2017-06-26 12:28:55,910 Epoch[6] Batch [10]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.144673,	
2017-06-26 12:29:02,000 Epoch[6] Batch [20]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.145544,	
2017-06-26 12:29:08,110 Epoch[6] Batch [30]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.144719,	
2017-06-26 12:29:14,167 Epoch[6] Batch [40]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.144062,	
2017-06-26 12:29:20,260 Epoch[6] Batch [50]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.145936,	
2017-06-26 12:29:26,399 Epoch[6] Batch [60]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.150175,	
2017-06-26 12:29:32,534 Epoch[6] Batch [70]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.155994,	
2017-06-26 12:29:38,645 Epoch[6] Batch [80]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.158815,	
2017-06-26 12:29:44,805 Epoch[6] Batch [90]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.158806,	
2017-06-26 12:29:50,664 Epoch[6] Batch [100]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.157495,	
2017-06-26 12:29:56,770 Epoch[6] Batch [110]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.156333,	
2017-06-26 12:30:01,757 Epoch[6] Batch [120]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.154307,	
2017-06-26 12:30:07,490 Epoch[6] Batch [130]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.154541,	
2017-06-26 12:30:13,562 Epoch[6] Batch [140]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.155126,	
2017-06-26 12:30:19,683 Epoch[6] Batch [150]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.154750,	
2017-06-26 12:30:25,770 Epoch[6] Batch [160]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.155718,	
2017-06-26 12:30:31,708 Epoch[6] Batch [170]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.155556,	
2017-06-26 12:30:37,756 Epoch[6] Batch [180]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.156288,	
2017-06-26 12:30:43,843 Epoch[6] Batch [190]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.157081,	
2017-06-26 12:30:50,483 Epoch[6] Batch [200]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.158721,	
2017-06-26 12:30:56,755 Epoch[6] Batch [210]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.158804,	
2017-06-26 12:31:02,766 Epoch[6] Batch [220]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.158317,	
2017-06-26 12:31:08,884 Epoch[6] Batch [230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.159104,	
2017-06-26 12:31:15,002 Epoch[6] Batch [240]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.158269,	
2017-06-26 12:31:21,085 Epoch[6] Batch [250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.157387,	
2017-06-26 12:31:27,137 Epoch[6] Batch [260]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.156817,	
2017-06-26 12:31:33,316 Epoch[6] Batch [270]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.157146,	
2017-06-26 12:31:39,498 Epoch[6] Batch [280]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.156508,	
2017-06-26 12:31:45,571 Epoch[6] Batch [290]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.156211,	
2017-06-26 12:31:51,471 Epoch[6] Batch [300]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.156246,	
2017-06-26 12:31:57,558 Epoch[6] Batch [310]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.155845,	
2017-06-26 12:32:03,672 Epoch[6] Batch [320]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.155593,	
2017-06-26 12:32:09,850 Epoch[6] Batch [330]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.155526,	
2017-06-26 12:32:15,848 Epoch[6] Batch [340]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.155625,	
2017-06-26 12:32:21,426 Epoch[6] Batch [350]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.155453,	
2017-06-26 12:32:27,329 Epoch[6] Batch [360]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.155106,	
2017-06-26 12:32:33,060 Epoch[6] Batch [370]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.154666,	
2017-06-26 12:32:39,201 Epoch[6] Batch [380]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.154804,	
2017-06-26 12:32:45,125 Epoch[6] Batch [390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.154811,	
2017-06-26 12:32:51,158 Epoch[6] Batch [400]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.155429,	
2017-06-26 12:32:57,265 Epoch[6] Batch [410]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.155296,	
2017-06-26 12:33:03,382 Epoch[6] Batch [420]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.155079,	
2017-06-26 12:33:09,466 Epoch[6] Batch [430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.154723,	
2017-06-26 12:33:15,539 Epoch[6] Batch [440]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.154390,	
2017-06-26 12:33:21,652 Epoch[6] Batch [450]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.154350,	
2017-06-26 12:33:27,759 Epoch[6] Batch [460]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.154704,	
2017-06-26 12:33:33,789 Epoch[6] Batch [470]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.154767,	
2017-06-26 12:33:39,960 Epoch[6] Batch [480]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.154961,	
2017-06-26 12:33:45,996 Epoch[6] Batch [490]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.154973,	
2017-06-26 12:33:52,061 Epoch[6] Batch [500]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.155349,	
2017-06-26 12:33:58,158 Epoch[6] Batch [510]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155649,	
2017-06-26 12:34:03,981 Epoch[6] Batch [520]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.155690,	
2017-06-26 12:34:10,117 Epoch[6] Batch [530]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.155512,	
2017-06-26 12:34:16,204 Epoch[6] Batch [540]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.156494,	
2017-06-26 12:34:22,303 Epoch[6] Batch [550]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.156648,	
2017-06-26 12:34:28,409 Epoch[6] Batch [560]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.156760,	
2017-06-26 12:34:34,496 Epoch[6] Batch [570]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.157141,	
2017-06-26 12:34:40,600 Epoch[6] Batch [580]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.157188,	
2017-06-26 12:34:46,852 Epoch[6] Batch [590]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.156972,	
2017-06-26 12:34:53,454 Epoch[6] Batch [600]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.156773,	
2017-06-26 12:34:59,534 Epoch[6] Batch [610]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.156577,	
2017-06-26 12:35:05,606 Epoch[6] Batch [620]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.156494,	
2017-06-26 12:35:11,829 Epoch[6] Batch [630]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.156461,	
2017-06-26 12:35:17,688 Epoch[6] Batch [640]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.157377,	
2017-06-26 12:35:23,739 Epoch[6] Batch [650]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.157886,	
2017-06-26 12:35:29,279 Epoch[6] Batch [660]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.158177,	
2017-06-26 12:35:35,296 Epoch[6] Batch [670]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.158587,	
2017-06-26 12:35:41,341 Epoch[6] Batch [680]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.158504,	
2017-06-26 12:35:47,476 Epoch[6] Batch [690]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.158451,	
2017-06-26 12:35:53,379 Epoch[6] Batch [700]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.158195,	
2017-06-26 12:35:59,400 Epoch[6] Batch [710]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.158371,	
2017-06-26 12:36:05,171 Epoch[6] Batch [720]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.158543,	
2017-06-26 12:36:11,207 Epoch[6] Batch [730]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.158395,	
2017-06-26 12:36:17,118 Epoch[6] Batch [740]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.158351,	
2017-06-26 12:36:23,233 Epoch[6] Batch [750]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.158700,	
2017-06-26 12:36:29,329 Epoch[6] Batch [760]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.158467,	
2017-06-26 12:36:35,436 Epoch[6] Batch [770]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.158467,	
2017-06-26 12:36:41,371 Epoch[6] Batch [780]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.158331,	
2017-06-26 12:36:47,242 Epoch[6] Batch [790]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.158306,	
2017-06-26 12:36:53,293 Epoch[6] Batch [800]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.158477,	
2017-06-26 12:36:59,163 Epoch[6] Batch [810]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.158349,	
2017-06-26 12:37:05,254 Epoch[6] Batch [820]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.158323,	
2017-06-26 12:37:11,370 Epoch[6] Batch [830]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.158154,	
2017-06-26 12:37:17,443 Epoch[6] Batch [840]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.158063,	
2017-06-26 12:37:23,548 Epoch[6] Batch [850]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.158132,	
2017-06-26 12:37:29,705 Epoch[6] Batch [860]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.157987,	
2017-06-26 12:37:35,743 Epoch[6] Batch [870]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.158041,	
2017-06-26 12:37:41,822 Epoch[6] Batch [880]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.158064,	
2017-06-26 12:37:47,920 Epoch[6] Batch [890]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.157819,	
2017-06-26 12:37:53,959 Epoch[6] Batch [900]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.157986,	
2017-06-26 12:37:59,718 Epoch[6] Batch [910]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.157937,	
2017-06-26 12:38:05,647 Epoch[6] Batch [920]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.158150,	
2017-06-26 12:38:11,560 Epoch[6] Batch [930]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.158219,	
2017-06-26 12:38:17,578 Epoch[6] Batch [940]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.158343,	
2017-06-26 12:38:23,483 Epoch[6] Batch [950]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.158300,	
2017-06-26 12:38:29,421 Epoch[6] Batch [960]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.158373,	
2017-06-26 12:38:35,219 Epoch[6] Batch [970]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.158360,	
2017-06-26 12:38:40,752 Epoch[6] Batch [980]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.158185,	
2017-06-26 12:38:47,324 Epoch[6] Batch [990]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.158386,	
2017-06-26 12:38:53,522 Epoch[6] Batch [1000]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.158368,	
2017-06-26 12:38:59,702 Epoch[6] Batch [1010]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.158495,	
2017-06-26 12:39:05,788 Epoch[6] Batch [1020]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.158447,	
2017-06-26 12:39:11,821 Epoch[6] Batch [1030]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.158456,	
2017-06-26 12:39:17,982 Epoch[6] Batch [1040]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.158370,	
2017-06-26 12:39:24,072 Epoch[6] Batch [1050]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.158171,	
2017-06-26 12:39:29,978 Epoch[6] Batch [1060]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.158177,	
2017-06-26 12:39:36,088 Epoch[6] Batch [1070]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.158074,	
2017-06-26 12:39:42,163 Epoch[6] Batch [1080]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.157970,	
2017-06-26 12:39:48,116 Epoch[6] Batch [1090]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.157920,	
2017-06-26 12:39:54,193 Epoch[6] Batch [1100]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.158068,	
2017-06-26 12:39:59,988 Epoch[6] Batch [1110]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.158275,	
2017-06-26 12:40:05,723 Epoch[6] Batch [1120]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.158329,	
2017-06-26 12:40:11,560 Epoch[6] Batch [1130]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.158288,	
2017-06-26 12:40:17,620 Epoch[6] Batch [1140]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.158362,	
2017-06-26 12:40:23,771 Epoch[6] Batch [1150]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.158751,	
2017-06-26 12:40:29,731 Epoch[6] Batch [1160]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.158762,	
2017-06-26 12:40:35,763 Epoch[6] Batch [1170]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.159520,	
2017-06-26 12:40:41,454 Epoch[6] Batch [1180]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.159778,	
2017-06-26 12:40:47,528 Epoch[6] Batch [1190]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.159824,	
2017-06-26 12:40:53,283 Epoch[6] Batch [1200]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.160052,	
2017-06-26 12:40:58,972 Epoch[6] Batch [1210]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.159993,	
2017-06-26 12:41:04,701 Epoch[6] Batch [1220]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.160117,	
2017-06-26 12:41:10,522 Epoch[6] Batch [1230]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.160454,	
2017-06-26 12:41:16,349 Epoch[6] Batch [1240]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.160446,	
2017-06-26 12:41:22,063 Epoch[6] Batch [1250]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.160536,	
2017-06-26 12:41:28,038 Epoch[6] Batch [1260]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.160851,	
2017-06-26 12:41:33,948 Epoch[6] Batch [1270]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.160908,	
2017-06-26 12:41:40,024 Epoch[6] Batch [1280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.160869,	
2017-06-26 12:41:46,157 Epoch[6] Batch [1290]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.160908,	
2017-06-26 12:41:52,265 Epoch[6] Batch [1300]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.160857,	
2017-06-26 12:41:58,352 Epoch[6] Batch [1310]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.160752,	
2017-06-26 12:42:04,578 Epoch[6] Batch [1320]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.160627,	
2017-06-26 12:42:10,642 Epoch[6] Batch [1330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.160600,	
2017-06-26 12:42:16,722 Epoch[6] Batch [1340]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.160527,	
2017-06-26 12:42:22,763 Epoch[6] Batch [1350]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.160392,	
2017-06-26 12:42:28,907 Epoch[6] Batch [1360]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.160299,	
2017-06-26 12:42:35,010 Epoch[6] Batch [1370]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.160253,	
2017-06-26 12:42:41,471 Epoch[6] Batch [1380]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.160434,	
2017-06-26 12:42:47,956 Epoch[6] Batch [1390]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.160664,	
2017-06-26 12:42:54,024 Epoch[6] Batch [1400]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.160571,	
2017-06-26 12:43:00,111 Epoch[6] Batch [1410]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.160642,	
2017-06-26 12:43:05,741 Epoch[6] Batch [1420]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.160732,	
2017-06-26 12:43:11,582 Epoch[6] Batch [1430]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.160628,	
2017-06-26 12:43:17,683 Epoch[6] Batch [1440]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.160593,	
2017-06-26 12:43:23,788 Epoch[6] Batch [1450]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.160479,	
2017-06-26 12:43:29,846 Epoch[6] Batch [1460]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.160560,	
2017-06-26 12:43:35,941 Epoch[6] Batch [1470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.160529,	
2017-06-26 12:43:41,848 Epoch[6] Batch [1480]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.160491,	
2017-06-26 12:43:45,292 Epoch[6] Train-FCNLogLoss=0.160547
2017-06-26 12:43:45,292 Epoch[6] Time cost=896.283
2017-06-26 12:43:46,179 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0007.params"
2017-06-26 12:43:47,867 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0007.states"
2017-06-26 12:43:54,480 Epoch[7] Batch [10]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.158155,	
2017-06-26 12:44:00,180 Epoch[7] Batch [20]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.155152,	
2017-06-26 12:44:05,571 Epoch[7] Batch [30]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.162810,	
2017-06-26 12:44:11,134 Epoch[7] Batch [40]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.167380,	
2017-06-26 12:44:16,711 Epoch[7] Batch [50]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.162993,	
2017-06-26 12:44:22,027 Epoch[7] Batch [60]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.162607,	
2017-06-26 12:44:27,705 Epoch[7] Batch [70]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.159078,	
2017-06-26 12:44:33,736 Epoch[7] Batch [80]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.157879,	
2017-06-26 12:44:39,818 Epoch[7] Batch [90]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.158412,	
2017-06-26 12:44:45,899 Epoch[7] Batch [100]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.159665,	
2017-06-26 12:44:51,980 Epoch[7] Batch [110]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.160013,	
2017-06-26 12:44:58,085 Epoch[7] Batch [120]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.159652,	
2017-06-26 12:45:04,176 Epoch[7] Batch [130]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.159060,	
2017-06-26 12:45:10,203 Epoch[7] Batch [140]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.159231,	
2017-06-26 12:45:16,291 Epoch[7] Batch [150]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.159375,	
2017-06-26 12:45:22,384 Epoch[7] Batch [160]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.160609,	
2017-06-26 12:45:28,468 Epoch[7] Batch [170]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.159585,	
2017-06-26 12:45:34,596 Epoch[7] Batch [180]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.159136,	
2017-06-26 12:45:40,309 Epoch[7] Batch [190]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.158674,	
2017-06-26 12:45:45,471 Epoch[7] Batch [200]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.160082,	
2017-06-26 12:45:51,491 Epoch[7] Batch [210]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.159430,	
2017-06-26 12:45:57,219 Epoch[7] Batch [220]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.159594,	
2017-06-26 12:46:03,297 Epoch[7] Batch [230]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.159392,	
2017-06-26 12:46:09,434 Epoch[7] Batch [240]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.160867,	
2017-06-26 12:46:15,366 Epoch[7] Batch [250]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.160390,	
2017-06-26 12:46:22,029 Epoch[7] Batch [260]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.160430,	
2017-06-26 12:46:28,295 Epoch[7] Batch [270]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.159859,	
2017-06-26 12:46:34,418 Epoch[7] Batch [280]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.159292,	
2017-06-26 12:46:40,467 Epoch[7] Batch [290]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.158591,	
2017-06-26 12:46:46,599 Epoch[7] Batch [300]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.157983,	
2017-06-26 12:46:52,535 Epoch[7] Batch [310]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.157070,	
2017-06-26 12:46:58,615 Epoch[7] Batch [320]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.156243,	
2017-06-26 12:47:04,821 Epoch[7] Batch [330]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.155364,	
2017-06-26 12:47:10,920 Epoch[7] Batch [340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155371,	
2017-06-26 12:47:17,020 Epoch[7] Batch [350]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155258,	
2017-06-26 12:47:23,126 Epoch[7] Batch [360]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.154642,	
2017-06-26 12:47:29,284 Epoch[7] Batch [370]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.154458,	
2017-06-26 12:47:35,309 Epoch[7] Batch [380]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.154767,	
2017-06-26 12:47:41,375 Epoch[7] Batch [390]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.154451,	
2017-06-26 12:47:47,499 Epoch[7] Batch [400]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.154464,	
2017-06-26 12:47:53,565 Epoch[7] Batch [410]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.154139,	
2017-06-26 12:47:59,670 Epoch[7] Batch [420]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.153928,	
2017-06-26 12:48:05,755 Epoch[7] Batch [430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.153517,	
2017-06-26 12:48:11,944 Epoch[7] Batch [440]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.153186,	
2017-06-26 12:48:17,972 Epoch[7] Batch [450]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.152834,	
2017-06-26 12:48:24,079 Epoch[7] Batch [460]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.152577,	
2017-06-26 12:48:30,151 Epoch[7] Batch [470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.152704,	
2017-06-26 12:48:36,231 Epoch[7] Batch [480]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.152667,	
2017-06-26 12:48:42,352 Epoch[7] Batch [490]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.152591,	
2017-06-26 12:48:48,455 Epoch[7] Batch [500]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.152788,	
2017-06-26 12:48:54,560 Epoch[7] Batch [510]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.153110,	
2017-06-26 12:49:00,666 Epoch[7] Batch [520]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.153217,	
2017-06-26 12:49:06,764 Epoch[7] Batch [530]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.152993,	
2017-06-26 12:49:12,875 Epoch[7] Batch [540]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.155928,	
2017-06-26 12:49:19,004 Epoch[7] Batch [550]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.156963,	
2017-06-26 12:49:25,161 Epoch[7] Batch [560]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.157804,	
2017-06-26 12:49:31,192 Epoch[7] Batch [570]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.157726,	
2017-06-26 12:49:37,333 Epoch[7] Batch [580]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.157959,	
2017-06-26 12:49:43,546 Epoch[7] Batch [590]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.157664,	
2017-06-26 12:49:49,600 Epoch[7] Batch [600]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.157622,	
2017-06-26 12:49:55,754 Epoch[7] Batch [610]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.157389,	
2017-06-26 12:50:01,827 Epoch[7] Batch [620]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.157188,	
2017-06-26 12:50:07,940 Epoch[7] Batch [630]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.157102,	
2017-06-26 12:50:14,065 Epoch[7] Batch [640]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.156998,	
2017-06-26 12:50:20,210 Epoch[7] Batch [650]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.156875,	
2017-06-26 12:50:26,821 Epoch[7] Batch [660]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.157126,	
2017-06-26 12:50:32,914 Epoch[7] Batch [670]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.157319,	
2017-06-26 12:50:39,043 Epoch[7] Batch [680]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.157182,	
2017-06-26 12:50:44,952 Epoch[7] Batch [690]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.157165,	
2017-06-26 12:50:51,069 Epoch[7] Batch [700]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.156930,	
2017-06-26 12:50:57,155 Epoch[7] Batch [710]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.156837,	
2017-06-26 12:51:03,039 Epoch[7] Batch [720]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.156621,	
2017-06-26 12:51:09,132 Epoch[7] Batch [730]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.156727,	
2017-06-26 12:51:14,974 Epoch[7] Batch [740]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.156584,	
2017-06-26 12:51:21,112 Epoch[7] Batch [750]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.156604,	
2017-06-26 12:51:27,199 Epoch[7] Batch [760]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.156716,	
2017-06-26 12:51:33,374 Epoch[7] Batch [770]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.156794,	
2017-06-26 12:51:39,357 Epoch[7] Batch [780]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.156865,	
2017-06-26 12:51:45,417 Epoch[7] Batch [790]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.156877,	
2017-06-26 12:51:51,634 Epoch[7] Batch [800]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.156519,	
2017-06-26 12:51:57,771 Epoch[7] Batch [810]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.156429,	
2017-06-26 12:52:03,889 Epoch[7] Batch [820]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.156376,	
2017-06-26 12:52:09,980 Epoch[7] Batch [830]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.156119,	
2017-06-26 12:52:15,988 Epoch[7] Batch [840]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.156208,	
2017-06-26 12:52:21,923 Epoch[7] Batch [850]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.156109,	
2017-06-26 12:52:28,025 Epoch[7] Batch [860]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155851,	
2017-06-26 12:52:34,110 Epoch[7] Batch [870]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.155662,	
2017-06-26 12:52:40,173 Epoch[7] Batch [880]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.155680,	
2017-06-26 12:52:46,044 Epoch[7] Batch [890]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.155630,	
2017-06-26 12:52:51,809 Epoch[7] Batch [900]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.155863,	
2017-06-26 12:52:57,483 Epoch[7] Batch [910]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.155882,	
2017-06-26 12:53:03,063 Epoch[7] Batch [920]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.155737,	
2017-06-26 12:53:08,767 Epoch[7] Batch [930]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.155788,	
2017-06-26 12:53:14,762 Epoch[7] Batch [940]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.155905,	
2017-06-26 12:53:20,416 Epoch[7] Batch [950]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.155794,	
2017-06-26 12:53:26,314 Epoch[7] Batch [960]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.155880,	
2017-06-26 12:53:32,212 Epoch[7] Batch [970]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.155995,	
2017-06-26 12:53:38,351 Epoch[7] Batch [980]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.155975,	
2017-06-26 12:53:44,368 Epoch[7] Batch [990]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.155838,	
2017-06-26 12:53:50,299 Epoch[7] Batch [1000]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.155713,	
2017-06-26 12:53:56,355 Epoch[7] Batch [1010]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.155715,	
2017-06-26 12:54:02,456 Epoch[7] Batch [1020]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155426,	
2017-06-26 12:54:08,363 Epoch[7] Batch [1030]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.155364,	
2017-06-26 12:54:14,534 Epoch[7] Batch [1040]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.155266,	
2017-06-26 12:54:20,860 Epoch[7] Batch [1050]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.155295,	
2017-06-26 12:54:27,403 Epoch[7] Batch [1060]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.155224,	
2017-06-26 12:54:33,296 Epoch[7] Batch [1070]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.155209,	
2017-06-26 12:54:39,266 Epoch[7] Batch [1080]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.155095,	
2017-06-26 12:54:45,052 Epoch[7] Batch [1090]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.155205,	
2017-06-26 12:54:50,906 Epoch[7] Batch [1100]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.155132,	
2017-06-26 12:54:56,546 Epoch[7] Batch [1110]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.155042,	
2017-06-26 12:55:02,525 Epoch[7] Batch [1120]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.154945,	
2017-06-26 12:55:08,501 Epoch[7] Batch [1130]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.154837,	
2017-06-26 12:55:14,612 Epoch[7] Batch [1140]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.154675,	
2017-06-26 12:55:20,709 Epoch[7] Batch [1150]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.154392,	
2017-06-26 12:55:26,816 Epoch[7] Batch [1160]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.154986,	
2017-06-26 12:55:32,922 Epoch[7] Batch [1170]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.154831,	
2017-06-26 12:55:39,013 Epoch[7] Batch [1180]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.154758,	
2017-06-26 12:55:45,133 Epoch[7] Batch [1190]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.155069,	
2017-06-26 12:55:51,230 Epoch[7] Batch [1200]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155072,	
2017-06-26 12:55:57,326 Epoch[7] Batch [1210]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.155220,	
2017-06-26 12:56:03,440 Epoch[7] Batch [1220]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.155113,	
2017-06-26 12:56:09,519 Epoch[7] Batch [1230]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.155041,	
2017-06-26 12:56:15,582 Epoch[7] Batch [1240]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.155034,	
2017-06-26 12:56:21,706 Epoch[7] Batch [1250]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.154963,	
2017-06-26 12:56:27,764 Epoch[7] Batch [1260]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.155015,	
2017-06-26 12:56:33,844 Epoch[7] Batch [1270]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.155178,	
2017-06-26 12:56:39,927 Epoch[7] Batch [1280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.154966,	
2017-06-26 12:56:46,062 Epoch[7] Batch [1290]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.154815,	
2017-06-26 12:56:52,166 Epoch[7] Batch [1300]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.154785,	
2017-06-26 12:56:58,242 Epoch[7] Batch [1310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.154731,	
2017-06-26 12:57:04,368 Epoch[7] Batch [1320]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.154698,	
2017-06-26 12:57:10,475 Epoch[7] Batch [1330]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.154582,	
2017-06-26 12:57:16,549 Epoch[7] Batch [1340]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.154481,	
2017-06-26 12:57:22,442 Epoch[7] Batch [1350]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.154422,	
2017-06-26 12:57:28,448 Epoch[7] Batch [1360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.154238,	
2017-06-26 12:57:34,181 Epoch[7] Batch [1370]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.154248,	
2017-06-26 12:57:40,280 Epoch[7] Batch [1380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.154291,	
2017-06-26 12:57:46,185 Epoch[7] Batch [1390]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.154170,	
2017-06-26 12:57:52,263 Epoch[7] Batch [1400]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.154136,	
2017-06-26 12:57:58,390 Epoch[7] Batch [1410]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.154228,	
2017-06-26 12:58:04,250 Epoch[7] Batch [1420]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.154301,	
2017-06-26 12:58:10,001 Epoch[7] Batch [1430]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.154242,	
2017-06-26 12:58:15,915 Epoch[7] Batch [1440]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.154297,	
2017-06-26 12:58:22,597 Epoch[7] Batch [1450]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.154253,	
2017-06-26 12:58:28,621 Epoch[7] Batch [1460]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.154142,	
2017-06-26 12:58:34,693 Epoch[7] Batch [1470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.154078,	
2017-06-26 12:58:40,794 Epoch[7] Batch [1480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.154055,	
2017-06-26 12:58:44,295 Epoch[7] Train-FCNLogLoss=0.153976
2017-06-26 12:58:44,295 Epoch[7] Time cost=896.428
2017-06-26 12:58:45,166 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0008.params"
2017-06-26 12:58:46,883 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0008.states"
2017-06-26 12:58:53,843 Epoch[8] Batch [10]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.154470,	
2017-06-26 12:59:00,076 Epoch[8] Batch [20]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.149554,	
2017-06-26 12:59:06,006 Epoch[8] Batch [30]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.148871,	
2017-06-26 12:59:11,889 Epoch[8] Batch [40]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.146565,	
2017-06-26 12:59:17,877 Epoch[8] Batch [50]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.144486,	
2017-06-26 12:59:23,995 Epoch[8] Batch [60]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.141712,	
2017-06-26 12:59:30,145 Epoch[8] Batch [70]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.141769,	
2017-06-26 12:59:36,017 Epoch[8] Batch [80]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.144887,	
2017-06-26 12:59:41,927 Epoch[8] Batch [90]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.145954,	
2017-06-26 12:59:47,631 Epoch[8] Batch [100]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.147367,	
2017-06-26 12:59:53,677 Epoch[8] Batch [110]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.146935,	
2017-06-26 12:59:59,761 Epoch[8] Batch [120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.147928,	
2017-06-26 13:00:05,842 Epoch[8] Batch [130]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.147559,	
2017-06-26 13:00:11,902 Epoch[8] Batch [140]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.147577,	
2017-06-26 13:00:18,040 Epoch[8] Batch [150]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.146905,	
2017-06-26 13:00:24,094 Epoch[8] Batch [160]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.148844,	
2017-06-26 13:00:30,207 Epoch[8] Batch [170]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.149347,	
2017-06-26 13:00:36,372 Epoch[8] Batch [180]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.149135,	
2017-06-26 13:00:42,477 Epoch[8] Batch [190]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.148881,	
2017-06-26 13:00:48,656 Epoch[8] Batch [200]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.149224,	
2017-06-26 13:00:54,440 Epoch[8] Batch [210]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.149049,	
2017-06-26 13:01:00,428 Epoch[8] Batch [220]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.149551,	
2017-06-26 13:01:06,360 Epoch[8] Batch [230]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.148903,	
2017-06-26 13:01:12,166 Epoch[8] Batch [240]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.149815,	
2017-06-26 13:01:17,204 Epoch[8] Batch [250]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.149893,	
2017-06-26 13:01:22,926 Epoch[8] Batch [260]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.149992,	
2017-06-26 13:01:28,680 Epoch[8] Batch [270]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.149816,	
2017-06-26 13:01:34,760 Epoch[8] Batch [280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.150133,	
2017-06-26 13:01:40,863 Epoch[8] Batch [290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.149851,	
2017-06-26 13:01:47,018 Epoch[8] Batch [300]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.149744,	
2017-06-26 13:01:53,082 Epoch[8] Batch [310]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.149710,	
2017-06-26 13:01:59,394 Epoch[8] Batch [320]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.149602,	
2017-06-26 13:02:05,995 Epoch[8] Batch [330]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.150750,	
2017-06-26 13:02:11,663 Epoch[8] Batch [340]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.151112,	
2017-06-26 13:02:17,565 Epoch[8] Batch [350]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.151673,	
2017-06-26 13:02:23,467 Epoch[8] Batch [360]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.151258,	
2017-06-26 13:02:29,549 Epoch[8] Batch [370]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.151100,	
2017-06-26 13:02:35,568 Epoch[8] Batch [380]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.150681,	
2017-06-26 13:02:41,497 Epoch[8] Batch [390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.150002,	
2017-06-26 13:02:47,612 Epoch[8] Batch [400]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.149692,	
2017-06-26 13:02:53,727 Epoch[8] Batch [410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.149947,	
2017-06-26 13:02:59,638 Epoch[8] Batch [420]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.149684,	
2017-06-26 13:03:05,749 Epoch[8] Batch [430]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.149612,	
2017-06-26 13:03:11,521 Epoch[8] Batch [440]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.149786,	
2017-06-26 13:03:17,442 Epoch[8] Batch [450]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.149592,	
2017-06-26 13:03:23,472 Epoch[8] Batch [460]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.149466,	
2017-06-26 13:03:29,206 Epoch[8] Batch [470]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.149845,	
2017-06-26 13:03:35,252 Epoch[8] Batch [480]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.149650,	
2017-06-26 13:03:41,169 Epoch[8] Batch [490]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.149801,	
2017-06-26 13:03:47,226 Epoch[8] Batch [500]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.150014,	
2017-06-26 13:03:53,342 Epoch[8] Batch [510]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.149446,	
2017-06-26 13:03:59,418 Epoch[8] Batch [520]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.149241,	
2017-06-26 13:04:05,533 Epoch[8] Batch [530]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.148859,	
2017-06-26 13:04:11,567 Epoch[8] Batch [540]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.148742,	
2017-06-26 13:04:17,467 Epoch[8] Batch [550]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.148782,	
2017-06-26 13:04:23,525 Epoch[8] Batch [560]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.148636,	
2017-06-26 13:04:29,601 Epoch[8] Batch [570]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.148885,	
2017-06-26 13:04:35,699 Epoch[8] Batch [580]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.148960,	
2017-06-26 13:04:41,852 Epoch[8] Batch [590]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.148898,	
2017-06-26 13:04:47,933 Epoch[8] Batch [600]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.149077,	
2017-06-26 13:04:53,977 Epoch[8] Batch [610]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.149042,	
2017-06-26 13:05:00,127 Epoch[8] Batch [620]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.149591,	
2017-06-26 13:05:06,297 Epoch[8] Batch [630]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.149442,	
2017-06-26 13:05:12,264 Epoch[8] Batch [640]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.149277,	
2017-06-26 13:05:18,368 Epoch[8] Batch [650]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.149371,	
2017-06-26 13:05:24,462 Epoch[8] Batch [660]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.149655,	
2017-06-26 13:05:30,640 Epoch[8] Batch [670]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.149778,	
2017-06-26 13:05:36,781 Epoch[8] Batch [680]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.150103,	
2017-06-26 13:05:42,914 Epoch[8] Batch [690]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.150118,	
2017-06-26 13:05:49,028 Epoch[8] Batch [700]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.150055,	
2017-06-26 13:05:55,048 Epoch[8] Batch [710]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.150117,	
2017-06-26 13:06:01,558 Epoch[8] Batch [720]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.150046,	
2017-06-26 13:06:07,944 Epoch[8] Batch [730]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.149839,	
2017-06-26 13:06:14,020 Epoch[8] Batch [740]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.149982,	
2017-06-26 13:06:20,084 Epoch[8] Batch [750]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.150251,	
2017-06-26 13:06:26,165 Epoch[8] Batch [760]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.150307,	
2017-06-26 13:06:32,083 Epoch[8] Batch [770]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.150315,	
2017-06-26 13:06:37,753 Epoch[8] Batch [780]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.150391,	
2017-06-26 13:06:43,477 Epoch[8] Batch [790]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.150254,	
2017-06-26 13:06:49,565 Epoch[8] Batch [800]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.149976,	
2017-06-26 13:06:55,722 Epoch[8] Batch [810]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.149972,	
2017-06-26 13:07:01,784 Epoch[8] Batch [820]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.149801,	
2017-06-26 13:07:07,933 Epoch[8] Batch [830]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.149865,	
2017-06-26 13:07:14,032 Epoch[8] Batch [840]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.150576,	
2017-06-26 13:07:20,105 Epoch[8] Batch [850]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.150465,	
2017-06-26 13:07:26,245 Epoch[8] Batch [860]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.150463,	
2017-06-26 13:07:32,357 Epoch[8] Batch [870]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.150368,	
2017-06-26 13:07:38,418 Epoch[8] Batch [880]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.150083,	
2017-06-26 13:07:44,460 Epoch[8] Batch [890]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.149614,	
2017-06-26 13:07:50,249 Epoch[8] Batch [900]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.149486,	
2017-06-26 13:07:56,305 Epoch[8] Batch [910]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.149301,	
2017-06-26 13:08:02,135 Epoch[8] Batch [920]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.148997,	
2017-06-26 13:08:08,249 Epoch[8] Batch [930]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.149056,	
2017-06-26 13:08:14,397 Epoch[8] Batch [940]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.148850,	
2017-06-26 13:08:20,543 Epoch[8] Batch [950]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.148706,	
2017-06-26 13:08:26,649 Epoch[8] Batch [960]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.148651,	
2017-06-26 13:08:32,723 Epoch[8] Batch [970]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.148640,	
2017-06-26 13:08:38,882 Epoch[8] Batch [980]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.148543,	
2017-06-26 13:08:44,921 Epoch[8] Batch [990]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.148637,	
2017-06-26 13:08:50,951 Epoch[8] Batch [1000]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.148408,	
2017-06-26 13:08:57,054 Epoch[8] Batch [1010]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.148357,	
2017-06-26 13:09:03,208 Epoch[8] Batch [1020]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.148266,	
2017-06-26 13:09:09,076 Epoch[8] Batch [1030]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.148269,	
2017-06-26 13:09:15,243 Epoch[8] Batch [1040]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.148181,	
2017-06-26 13:09:21,295 Epoch[8] Batch [1050]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.148120,	
2017-06-26 13:09:27,446 Epoch[8] Batch [1060]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.148054,	
2017-06-26 13:09:33,458 Epoch[8] Batch [1070]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.147895,	
2017-06-26 13:09:39,593 Epoch[8] Batch [1080]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.147817,	
2017-06-26 13:09:45,776 Epoch[8] Batch [1090]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.147767,	
2017-06-26 13:09:51,816 Epoch[8] Batch [1100]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.147735,	
2017-06-26 13:09:58,161 Epoch[8] Batch [1110]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.147744,	
2017-06-26 13:10:04,756 Epoch[8] Batch [1120]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.147662,	
2017-06-26 13:10:10,698 Epoch[8] Batch [1130]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.147740,	
2017-06-26 13:10:16,756 Epoch[8] Batch [1140]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.147777,	
2017-06-26 13:10:22,638 Epoch[8] Batch [1150]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.147775,	
2017-06-26 13:10:28,452 Epoch[8] Batch [1160]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.147737,	
2017-06-26 13:10:34,340 Epoch[8] Batch [1170]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.147679,	
2017-06-26 13:10:40,185 Epoch[8] Batch [1180]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.147642,	
2017-06-26 13:10:46,318 Epoch[8] Batch [1190]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.147847,	
2017-06-26 13:10:52,389 Epoch[8] Batch [1200]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.147752,	
2017-06-26 13:10:58,277 Epoch[8] Batch [1210]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.147729,	
2017-06-26 13:11:04,336 Epoch[8] Batch [1220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.147591,	
2017-06-26 13:11:10,456 Epoch[8] Batch [1230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.147563,	
2017-06-26 13:11:16,564 Epoch[8] Batch [1240]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.147515,	
2017-06-26 13:11:22,628 Epoch[8] Batch [1250]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.147579,	
2017-06-26 13:11:28,791 Epoch[8] Batch [1260]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.147625,	
2017-06-26 13:11:34,803 Epoch[8] Batch [1270]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.147561,	
2017-06-26 13:11:40,911 Epoch[8] Batch [1280]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.147516,	
2017-06-26 13:11:47,001 Epoch[8] Batch [1290]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.147414,	
2017-06-26 13:11:53,111 Epoch[8] Batch [1300]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.147309,	
2017-06-26 13:11:59,177 Epoch[8] Batch [1310]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.147296,	
2017-06-26 13:12:04,917 Epoch[8] Batch [1320]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.147375,	
2017-06-26 13:12:11,006 Epoch[8] Batch [1330]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.147382,	
2017-06-26 13:12:16,930 Epoch[8] Batch [1340]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.147412,	
2017-06-26 13:12:22,596 Epoch[8] Batch [1350]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.147442,	
2017-06-26 13:12:28,606 Epoch[8] Batch [1360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.147389,	
2017-06-26 13:12:34,796 Epoch[8] Batch [1370]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.147304,	
2017-06-26 13:12:40,922 Epoch[8] Batch [1380]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.147126,	
2017-06-26 13:12:47,085 Epoch[8] Batch [1390]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.147124,	
2017-06-26 13:12:53,008 Epoch[8] Batch [1400]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.147166,	
2017-06-26 13:12:59,050 Epoch[8] Batch [1410]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.147272,	
2017-06-26 13:13:04,954 Epoch[8] Batch [1420]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.147205,	
2017-06-26 13:13:10,794 Epoch[8] Batch [1430]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.147239,	
2017-06-26 13:13:16,643 Epoch[8] Batch [1440]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.147140,	
2017-06-26 13:13:22,723 Epoch[8] Batch [1450]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.147111,	
2017-06-26 13:13:28,833 Epoch[8] Batch [1460]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.147121,	
2017-06-26 13:13:34,928 Epoch[8] Batch [1470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.147009,	
2017-06-26 13:13:41,061 Epoch[8] Batch [1480]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.147096,	
2017-06-26 13:13:44,719 Epoch[8] Train-FCNLogLoss=0.147078
2017-06-26 13:13:44,719 Epoch[8] Time cost=897.835
2017-06-26 13:13:45,550 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0009.params"
2017-06-26 13:13:47,234 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0009.states"
2017-06-26 13:13:54,937 Epoch[9] Batch [10]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.129331,	
2017-06-26 13:14:01,251 Epoch[9] Batch [20]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.138023,	
2017-06-26 13:14:07,465 Epoch[9] Batch [30]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.132639,	
2017-06-26 13:14:13,501 Epoch[9] Batch [40]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.132345,	
2017-06-26 13:14:19,634 Epoch[9] Batch [50]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.137079,	
2017-06-26 13:14:25,700 Epoch[9] Batch [60]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.137634,	
2017-06-26 13:14:31,814 Epoch[9] Batch [70]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.138141,	
2017-06-26 13:14:37,790 Epoch[9] Batch [80]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.138935,	
2017-06-26 13:14:43,787 Epoch[9] Batch [90]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.139171,	
2017-06-26 13:14:49,861 Epoch[9] Batch [100]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.140943,	
2017-06-26 13:14:55,930 Epoch[9] Batch [110]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.141337,	
2017-06-26 13:15:02,062 Epoch[9] Batch [120]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.141654,	
2017-06-26 13:15:08,150 Epoch[9] Batch [130]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.143886,	
2017-06-26 13:15:14,210 Epoch[9] Batch [140]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.143087,	
2017-06-26 13:15:20,345 Epoch[9] Batch [150]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.142218,	
2017-06-26 13:15:26,440 Epoch[9] Batch [160]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.141475,	
2017-06-26 13:15:32,618 Epoch[9] Batch [170]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.141202,	
2017-06-26 13:15:38,675 Epoch[9] Batch [180]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.140437,	
2017-06-26 13:15:44,671 Epoch[9] Batch [190]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.140765,	
2017-06-26 13:15:50,701 Epoch[9] Batch [200]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.140684,	
2017-06-26 13:15:56,802 Epoch[9] Batch [210]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.140356,	
2017-06-26 13:16:02,859 Epoch[9] Batch [220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.141133,	
2017-06-26 13:16:08,972 Epoch[9] Batch [230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.143276,	
2017-06-26 13:16:15,026 Epoch[9] Batch [240]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.146358,	
2017-06-26 13:16:21,034 Epoch[9] Batch [250]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.146539,	
2017-06-26 13:16:26,936 Epoch[9] Batch [260]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.147392,	
2017-06-26 13:16:33,016 Epoch[9] Batch [270]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.147334,	
2017-06-26 13:16:39,150 Epoch[9] Batch [280]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.146820,	
2017-06-26 13:16:44,789 Epoch[9] Batch [290]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.146429,	
2017-06-26 13:16:50,285 Epoch[9] Batch [300]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.146625,	
2017-06-26 13:16:56,410 Epoch[9] Batch [310]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.146570,	
2017-06-26 13:17:02,293 Epoch[9] Batch [320]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.146070,	
2017-06-26 13:17:08,428 Epoch[9] Batch [330]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.145835,	
2017-06-26 13:17:14,484 Epoch[9] Batch [340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.145824,	
2017-06-26 13:17:20,581 Epoch[9] Batch [350]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.146194,	
2017-06-26 13:17:26,725 Epoch[9] Batch [360]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.146124,	
2017-06-26 13:17:32,676 Epoch[9] Batch [370]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.146363,	
2017-06-26 13:17:38,705 Epoch[9] Batch [380]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.146558,	
2017-06-26 13:17:45,348 Epoch[9] Batch [390]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.146654,	
2017-06-26 13:17:51,514 Epoch[9] Batch [400]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.146029,	
2017-06-26 13:17:57,402 Epoch[9] Batch [410]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.146484,	
2017-06-26 13:18:03,450 Epoch[9] Batch [420]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.146551,	
2017-06-26 13:18:09,163 Epoch[9] Batch [430]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.146500,	
2017-06-26 13:18:15,064 Epoch[9] Batch [440]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.146083,	
2017-06-26 13:18:20,907 Epoch[9] Batch [450]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.146004,	
2017-06-26 13:18:26,510 Epoch[9] Batch [460]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.145627,	
2017-06-26 13:18:32,067 Epoch[9] Batch [470]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.145433,	
2017-06-26 13:18:37,933 Epoch[9] Batch [480]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.145104,	
2017-06-26 13:18:43,809 Epoch[9] Batch [490]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.145473,	
2017-06-26 13:18:49,551 Epoch[9] Batch [500]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.145540,	
2017-06-26 13:18:55,375 Epoch[9] Batch [510]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.145461,	
2017-06-26 13:19:01,170 Epoch[9] Batch [520]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.145210,	
2017-06-26 13:19:07,175 Epoch[9] Batch [530]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.145038,	
2017-06-26 13:19:13,264 Epoch[9] Batch [540]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.145065,	
2017-06-26 13:19:19,356 Epoch[9] Batch [550]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.145120,	
2017-06-26 13:19:25,427 Epoch[9] Batch [560]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.144836,	
2017-06-26 13:19:31,570 Epoch[9] Batch [570]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.144495,	
2017-06-26 13:19:37,459 Epoch[9] Batch [580]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.144555,	
2017-06-26 13:19:43,613 Epoch[9] Batch [590]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.144542,	
2017-06-26 13:19:49,701 Epoch[9] Batch [600]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.144725,	
2017-06-26 13:19:55,804 Epoch[9] Batch [610]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.144634,	
2017-06-26 13:20:01,915 Epoch[9] Batch [620]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.144354,	
2017-06-26 13:20:08,032 Epoch[9] Batch [630]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.144304,	
2017-06-26 13:20:13,904 Epoch[9] Batch [640]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.144493,	
2017-06-26 13:20:19,527 Epoch[9] Batch [650]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.144467,	
2017-06-26 13:20:25,100 Epoch[9] Batch [660]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.144413,	
2017-06-26 13:20:30,766 Epoch[9] Batch [670]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.144364,	
2017-06-26 13:20:36,729 Epoch[9] Batch [680]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.144458,	
2017-06-26 13:20:42,673 Epoch[9] Batch [690]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.144610,	
2017-06-26 13:20:48,726 Epoch[9] Batch [700]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.144567,	
2017-06-26 13:20:54,721 Epoch[9] Batch [710]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.144425,	
2017-06-26 13:21:00,822 Epoch[9] Batch [720]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.144418,	
2017-06-26 13:21:06,785 Epoch[9] Batch [730]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.144131,	
2017-06-26 13:21:12,855 Epoch[9] Batch [740]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.144013,	
2017-06-26 13:21:18,861 Epoch[9] Batch [750]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.143967,	
2017-06-26 13:21:24,477 Epoch[9] Batch [760]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.143587,	
2017-06-26 13:21:30,025 Epoch[9] Batch [770]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.143420,	
2017-06-26 13:21:36,710 Epoch[9] Batch [780]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.143309,	
2017-06-26 13:21:42,821 Epoch[9] Batch [790]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.143105,	
2017-06-26 13:21:48,975 Epoch[9] Batch [800]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.143341,	
2017-06-26 13:21:55,089 Epoch[9] Batch [810]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.143292,	
2017-06-26 13:22:01,224 Epoch[9] Batch [820]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.143391,	
2017-06-26 13:22:07,319 Epoch[9] Batch [830]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.143411,	
2017-06-26 13:22:13,392 Epoch[9] Batch [840]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.143418,	
2017-06-26 13:22:19,545 Epoch[9] Batch [850]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.143346,	
2017-06-26 13:22:25,532 Epoch[9] Batch [860]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.143230,	
2017-06-26 13:22:31,586 Epoch[9] Batch [870]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.143711,	
2017-06-26 13:22:37,629 Epoch[9] Batch [880]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.143661,	
2017-06-26 13:22:43,728 Epoch[9] Batch [890]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.143665,	
2017-06-26 13:22:49,832 Epoch[9] Batch [900]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.143851,	
2017-06-26 13:22:55,945 Epoch[9] Batch [910]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.143764,	
2017-06-26 13:23:02,044 Epoch[9] Batch [920]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.144020,	
2017-06-26 13:23:08,147 Epoch[9] Batch [930]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.144116,	
2017-06-26 13:23:14,310 Epoch[9] Batch [940]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.144178,	
2017-06-26 13:23:20,431 Epoch[9] Batch [950]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.144136,	
2017-06-26 13:23:26,602 Epoch[9] Batch [960]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.144111,	
2017-06-26 13:23:32,649 Epoch[9] Batch [970]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.143965,	
2017-06-26 13:23:38,537 Epoch[9] Batch [980]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.143915,	
2017-06-26 13:23:44,211 Epoch[9] Batch [990]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.144210,	
2017-06-26 13:23:50,220 Epoch[9] Batch [1000]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.144381,	
2017-06-26 13:23:56,065 Epoch[9] Batch [1010]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.144571,	
2017-06-26 13:24:01,898 Epoch[9] Batch [1020]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.144541,	
2017-06-26 13:24:07,769 Epoch[9] Batch [1030]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.144406,	
2017-06-26 13:24:13,367 Epoch[9] Batch [1040]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.144288,	
2017-06-26 13:24:19,122 Epoch[9] Batch [1050]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.144274,	
2017-06-26 13:24:24,711 Epoch[9] Batch [1060]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.144330,	
2017-06-26 13:24:30,530 Epoch[9] Batch [1070]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.144117,	
2017-06-26 13:24:36,415 Epoch[9] Batch [1080]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.144153,	
2017-06-26 13:24:42,062 Epoch[9] Batch [1090]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.144054,	
2017-06-26 13:24:48,089 Epoch[9] Batch [1100]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.143890,	
2017-06-26 13:24:54,007 Epoch[9] Batch [1110]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.143876,	
2017-06-26 13:25:00,077 Epoch[9] Batch [1120]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.143857,	
2017-06-26 13:25:06,134 Epoch[9] Batch [1130]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.144013,	
2017-06-26 13:25:12,217 Epoch[9] Batch [1140]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.144011,	
2017-06-26 13:25:18,294 Epoch[9] Batch [1150]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.143896,	
2017-06-26 13:25:24,416 Epoch[9] Batch [1160]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.143994,	
2017-06-26 13:25:30,816 Epoch[9] Batch [1170]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.143787,	
2017-06-26 13:25:37,272 Epoch[9] Batch [1180]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.143879,	
2017-06-26 13:25:43,322 Epoch[9] Batch [1190]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.143706,	
2017-06-26 13:25:49,471 Epoch[9] Batch [1200]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.143625,	
2017-06-26 13:25:55,560 Epoch[9] Batch [1210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.143609,	
2017-06-26 13:26:01,650 Epoch[9] Batch [1220]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.143700,	
2017-06-26 13:26:07,702 Epoch[9] Batch [1230]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.143761,	
2017-06-26 13:26:13,891 Epoch[9] Batch [1240]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.143883,	
2017-06-26 13:26:19,922 Epoch[9] Batch [1250]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.143849,	
2017-06-26 13:26:25,847 Epoch[9] Batch [1260]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.143715,	
2017-06-26 13:26:32,037 Epoch[9] Batch [1270]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.143614,	
2017-06-26 13:26:38,100 Epoch[9] Batch [1280]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.143531,	
2017-06-26 13:26:44,209 Epoch[9] Batch [1290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.143465,	
2017-06-26 13:26:50,275 Epoch[9] Batch [1300]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.143515,	
2017-06-26 13:26:56,122 Epoch[9] Batch [1310]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.143450,	
2017-06-26 13:27:01,718 Epoch[9] Batch [1320]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.143443,	
2017-06-26 13:27:07,335 Epoch[9] Batch [1330]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.143316,	
2017-06-26 13:27:12,978 Epoch[9] Batch [1340]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.143290,	
2017-06-26 13:27:18,421 Epoch[9] Batch [1350]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.143177,	
2017-06-26 13:27:24,174 Epoch[9] Batch [1360]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.143073,	
2017-06-26 13:27:30,149 Epoch[9] Batch [1370]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.143089,	
2017-06-26 13:27:35,736 Epoch[9] Batch [1380]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.143108,	
2017-06-26 13:27:41,532 Epoch[9] Batch [1390]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.143151,	
2017-06-26 13:27:47,342 Epoch[9] Batch [1400]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.143118,	
2017-06-26 13:27:53,190 Epoch[9] Batch [1410]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.143118,	
2017-06-26 13:27:59,076 Epoch[9] Batch [1420]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.143044,	
2017-06-26 13:28:05,084 Epoch[9] Batch [1430]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.142973,	
2017-06-26 13:28:10,821 Epoch[9] Batch [1440]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.142973,	
2017-06-26 13:28:16,322 Epoch[9] Batch [1450]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.142887,	
2017-06-26 13:28:21,831 Epoch[9] Batch [1460]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.142879,	
2017-06-26 13:28:27,860 Epoch[9] Batch [1470]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.142875,	
2017-06-26 13:28:33,691 Epoch[9] Batch [1480]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.142794,	
2017-06-26 13:28:37,168 Epoch[9] Train-FCNLogLoss=0.142753
2017-06-26 13:28:37,169 Epoch[9] Time cost=889.934
2017-06-26 13:28:38,084 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0010.params"
2017-06-26 13:28:39,777 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0010.states"
2017-06-26 13:28:46,614 Epoch[10] Batch [10]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.133221,	
2017-06-26 13:28:52,692 Epoch[10] Batch [20]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135324,	
2017-06-26 13:28:58,612 Epoch[10] Batch [30]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.143603,	
2017-06-26 13:29:04,311 Epoch[10] Batch [40]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.144407,	
2017-06-26 13:29:10,131 Epoch[10] Batch [50]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.146568,	
2017-06-26 13:29:16,548 Epoch[10] Batch [60]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.143926,	
2017-06-26 13:29:23,092 Epoch[10] Batch [70]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.140545,	
2017-06-26 13:29:29,131 Epoch[10] Batch [80]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.139957,	
2017-06-26 13:29:35,238 Epoch[10] Batch [90]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.137542,	
2017-06-26 13:29:41,302 Epoch[10] Batch [100]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.139036,	
2017-06-26 13:29:47,375 Epoch[10] Batch [110]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.138939,	
2017-06-26 13:29:53,337 Epoch[10] Batch [120]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.137730,	
2017-06-26 13:29:59,394 Epoch[10] Batch [130]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.136850,	
2017-06-26 13:30:05,756 Epoch[10] Batch [140]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.136755,	
2017-06-26 13:30:11,838 Epoch[10] Batch [150]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135958,	
2017-06-26 13:30:17,987 Epoch[10] Batch [160]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.136362,	
2017-06-26 13:30:24,111 Epoch[10] Batch [170]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.135380,	
2017-06-26 13:30:30,173 Epoch[10] Batch [180]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.135423,	
2017-06-26 13:30:36,111 Epoch[10] Batch [190]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.134546,	
2017-06-26 13:30:42,236 Epoch[10] Batch [200]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.134599,	
2017-06-26 13:30:48,297 Epoch[10] Batch [210]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.135582,	
2017-06-26 13:30:54,377 Epoch[10] Batch [220]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135237,	
2017-06-26 13:31:00,528 Epoch[10] Batch [230]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.134664,	
2017-06-26 13:31:06,653 Epoch[10] Batch [240]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.134614,	
2017-06-26 13:31:12,747 Epoch[10] Batch [250]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.133642,	
2017-06-26 13:31:18,871 Epoch[10] Batch [260]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.133958,	
2017-06-26 13:31:24,743 Epoch[10] Batch [270]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.133467,	
2017-06-26 13:31:30,913 Epoch[10] Batch [280]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.134007,	
2017-06-26 13:31:36,794 Epoch[10] Batch [290]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.134240,	
2017-06-26 13:31:42,851 Epoch[10] Batch [300]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.134096,	
2017-06-26 13:31:49,069 Epoch[10] Batch [310]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.134337,	
2017-06-26 13:31:55,134 Epoch[10] Batch [320]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.134045,	
2017-06-26 13:32:01,297 Epoch[10] Batch [330]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.134402,	
2017-06-26 13:32:07,394 Epoch[10] Batch [340]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.134297,	
2017-06-26 13:32:13,467 Epoch[10] Batch [350]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.133872,	
2017-06-26 13:32:19,231 Epoch[10] Batch [360]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.134294,	
2017-06-26 13:32:25,046 Epoch[10] Batch [370]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.134474,	
2017-06-26 13:32:31,056 Epoch[10] Batch [380]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.134581,	
2017-06-26 13:32:36,108 Epoch[10] Batch [390]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.135144,	
2017-06-26 13:32:42,150 Epoch[10] Batch [400]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.135392,	
2017-06-26 13:32:47,969 Epoch[10] Batch [410]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.135561,	
2017-06-26 13:32:53,969 Epoch[10] Batch [420]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.135578,	
2017-06-26 13:32:59,898 Epoch[10] Batch [430]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.135518,	
2017-06-26 13:33:05,980 Epoch[10] Batch [440]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135418,	
2017-06-26 13:33:12,558 Epoch[10] Batch [450]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.135886,	
2017-06-26 13:33:18,529 Epoch[10] Batch [460]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.135834,	
2017-06-26 13:33:24,605 Epoch[10] Batch [470]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.136208,	
2017-06-26 13:33:30,701 Epoch[10] Batch [480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.136229,	
2017-06-26 13:33:36,854 Epoch[10] Batch [490]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.136213,	
2017-06-26 13:33:42,912 Epoch[10] Batch [500]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.136410,	
2017-06-26 13:33:48,975 Epoch[10] Batch [510]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.136234,	
2017-06-26 13:33:55,110 Epoch[10] Batch [520]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.136217,	
2017-06-26 13:34:01,291 Epoch[10] Batch [530]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.136213,	
2017-06-26 13:34:07,298 Epoch[10] Batch [540]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.136249,	
2017-06-26 13:34:13,352 Epoch[10] Batch [550]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.136041,	
2017-06-26 13:34:19,472 Epoch[10] Batch [560]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.135909,	
2017-06-26 13:34:25,576 Epoch[10] Batch [570]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135790,	
2017-06-26 13:34:31,685 Epoch[10] Batch [580]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135723,	
2017-06-26 13:34:37,807 Epoch[10] Batch [590]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.135670,	
2017-06-26 13:34:43,941 Epoch[10] Batch [600]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.135726,	
2017-06-26 13:34:50,093 Epoch[10] Batch [610]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.135596,	
2017-06-26 13:34:56,211 Epoch[10] Batch [620]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.135540,	
2017-06-26 13:35:02,292 Epoch[10] Batch [630]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135523,	
2017-06-26 13:35:08,376 Epoch[10] Batch [640]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.135512,	
2017-06-26 13:35:14,486 Epoch[10] Batch [650]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135577,	
2017-06-26 13:35:20,586 Epoch[10] Batch [660]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.135398,	
2017-06-26 13:35:26,733 Epoch[10] Batch [670]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.135242,	
2017-06-26 13:35:32,788 Epoch[10] Batch [680]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.135398,	
2017-06-26 13:35:38,902 Epoch[10] Batch [690]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.135541,	
2017-06-26 13:35:45,057 Epoch[10] Batch [700]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.135443,	
2017-06-26 13:35:51,094 Epoch[10] Batch [710]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.135359,	
2017-06-26 13:35:57,266 Epoch[10] Batch [720]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.135453,	
2017-06-26 13:36:03,351 Epoch[10] Batch [730]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.135424,	
2017-06-26 13:36:09,475 Epoch[10] Batch [740]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.135052,	
2017-06-26 13:36:15,573 Epoch[10] Batch [750]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.134861,	
2017-06-26 13:36:21,733 Epoch[10] Batch [760]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.134784,	
2017-06-26 13:36:27,842 Epoch[10] Batch [770]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135111,	
2017-06-26 13:36:33,918 Epoch[10] Batch [780]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135061,	
2017-06-26 13:36:40,053 Epoch[10] Batch [790]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.134969,	
2017-06-26 13:36:46,127 Epoch[10] Batch [800]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.134743,	
2017-06-26 13:36:52,183 Epoch[10] Batch [810]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.134959,	
2017-06-26 13:36:58,267 Epoch[10] Batch [820]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.134932,	
2017-06-26 13:37:04,296 Epoch[10] Batch [830]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.134903,	
2017-06-26 13:37:10,928 Epoch[10] Batch [840]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.135042,	
2017-06-26 13:37:17,299 Epoch[10] Batch [850]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.135061,	
2017-06-26 13:37:23,218 Epoch[10] Batch [860]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.135093,	
2017-06-26 13:37:29,204 Epoch[10] Batch [870]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.135255,	
2017-06-26 13:37:34,905 Epoch[10] Batch [880]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.135231,	
2017-06-26 13:37:40,985 Epoch[10] Batch [890]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135199,	
2017-06-26 13:37:47,096 Epoch[10] Batch [900]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135364,	
2017-06-26 13:37:53,220 Epoch[10] Batch [910]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.135392,	
2017-06-26 13:37:59,278 Epoch[10] Batch [920]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.135376,	
2017-06-26 13:38:05,037 Epoch[10] Batch [930]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.135307,	
2017-06-26 13:38:10,716 Epoch[10] Batch [940]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.135491,	
2017-06-26 13:38:16,576 Epoch[10] Batch [950]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.135310,	
2017-06-26 13:38:22,438 Epoch[10] Batch [960]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.135338,	
2017-06-26 13:38:28,326 Epoch[10] Batch [970]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.135439,	
2017-06-26 13:38:34,431 Epoch[10] Batch [980]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.135443,	
2017-06-26 13:38:40,556 Epoch[10] Batch [990]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.135385,	
2017-06-26 13:38:46,682 Epoch[10] Batch [1000]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.135261,	
2017-06-26 13:38:52,832 Epoch[10] Batch [1010]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.135245,	
2017-06-26 13:38:58,884 Epoch[10] Batch [1020]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.135528,	
2017-06-26 13:39:04,958 Epoch[10] Batch [1030]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.135650,	
2017-06-26 13:39:10,960 Epoch[10] Batch [1040]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.135630,	
2017-06-26 13:39:17,023 Epoch[10] Batch [1050]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.135552,	
2017-06-26 13:39:23,055 Epoch[10] Batch [1060]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.135328,	
2017-06-26 13:39:28,997 Epoch[10] Batch [1070]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.135240,	
2017-06-26 13:39:35,109 Epoch[10] Batch [1080]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.135387,	
2017-06-26 13:39:41,186 Epoch[10] Batch [1090]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135538,	
2017-06-26 13:39:47,276 Epoch[10] Batch [1100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.135555,	
2017-06-26 13:39:53,379 Epoch[10] Batch [1110]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.135444,	
2017-06-26 13:39:59,457 Epoch[10] Batch [1120]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135380,	
2017-06-26 13:40:05,631 Epoch[10] Batch [1130]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.135283,	
2017-06-26 13:40:11,698 Epoch[10] Batch [1140]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.135320,	
2017-06-26 13:40:17,762 Epoch[10] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.135375,	
2017-06-26 13:40:23,668 Epoch[10] Batch [1160]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.135328,	
2017-06-26 13:40:29,636 Epoch[10] Batch [1170]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.135309,	
2017-06-26 13:40:35,546 Epoch[10] Batch [1180]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.135263,	
2017-06-26 13:40:41,455 Epoch[10] Batch [1190]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.135250,	
2017-06-26 13:40:47,213 Epoch[10] Batch [1200]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.135334,	
2017-06-26 13:40:53,181 Epoch[10] Batch [1210]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.135390,	
2017-06-26 13:40:59,258 Epoch[10] Batch [1220]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.135353,	
2017-06-26 13:41:05,454 Epoch[10] Batch [1230]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.135358,	
2017-06-26 13:41:12,126 Epoch[10] Batch [1240]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.135484,	
2017-06-26 13:41:17,728 Epoch[10] Batch [1250]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.135297,	
2017-06-26 13:41:23,185 Epoch[10] Batch [1260]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.135329,	
2017-06-26 13:41:28,536 Epoch[10] Batch [1270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.135352,	
2017-06-26 13:41:33,932 Epoch[10] Batch [1280]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.135485,	
2017-06-26 13:41:39,262 Epoch[10] Batch [1290]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135621,	
2017-06-26 13:41:44,628 Epoch[10] Batch [1300]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.135787,	
2017-06-26 13:41:49,951 Epoch[10] Batch [1310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135829,	
2017-06-26 13:41:55,299 Epoch[10] Batch [1320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.135745,	
2017-06-26 13:42:00,629 Epoch[10] Batch [1330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135701,	
2017-06-26 13:42:05,984 Epoch[10] Batch [1340]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.135771,	
2017-06-26 13:42:11,377 Epoch[10] Batch [1350]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.135845,	
2017-06-26 13:42:16,691 Epoch[10] Batch [1360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.135932,	
2017-06-26 13:42:21,992 Epoch[10] Batch [1370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.136034,	
2017-06-26 13:42:27,359 Epoch[10] Batch [1380]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.136044,	
2017-06-26 13:42:32,697 Epoch[10] Batch [1390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.136001,	
2017-06-26 13:42:38,012 Epoch[10] Batch [1400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.136120,	
2017-06-26 13:42:43,342 Epoch[10] Batch [1410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.136243,	
2017-06-26 13:42:48,709 Epoch[10] Batch [1420]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.136206,	
2017-06-26 13:42:54,020 Epoch[10] Batch [1430]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.136352,	
2017-06-26 13:42:59,335 Epoch[10] Batch [1440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.136526,	
2017-06-26 13:43:04,674 Epoch[10] Batch [1450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.136511,	
2017-06-26 13:43:10,020 Epoch[10] Batch [1460]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.136730,	
2017-06-26 13:43:15,341 Epoch[10] Batch [1470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.136808,	
2017-06-26 13:43:20,673 Epoch[10] Batch [1480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136729,	
2017-06-26 13:43:23,866 Epoch[10] Train-FCNLogLoss=0.136683
2017-06-26 13:43:23,866 Epoch[10] Time cost=884.088
2017-06-26 13:43:24,771 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0011.params"
2017-06-26 13:43:26,411 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0011.states"
2017-06-26 13:43:32,160 Epoch[11] Batch [10]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.142884,	
2017-06-26 13:43:37,440 Epoch[11] Batch [20]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.140446,	
2017-06-26 13:43:42,810 Epoch[11] Batch [30]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.134081,	
2017-06-26 13:43:48,150 Epoch[11] Batch [40]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134438,	
2017-06-26 13:43:53,455 Epoch[11] Batch [50]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.135721,	
2017-06-26 13:43:58,839 Epoch[11] Batch [60]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.133499,	
2017-06-26 13:44:04,227 Epoch[11] Batch [70]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.134830,	
2017-06-26 13:44:09,555 Epoch[11] Batch [80]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134318,	
2017-06-26 13:44:14,875 Epoch[11] Batch [90]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133430,	
2017-06-26 13:44:20,217 Epoch[11] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.132810,	
2017-06-26 13:44:25,572 Epoch[11] Batch [110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.132824,	
2017-06-26 13:44:30,888 Epoch[11] Batch [120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.134714,	
2017-06-26 13:44:36,178 Epoch[11] Batch [130]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.134257,	
2017-06-26 13:44:41,535 Epoch[11] Batch [140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134768,	
2017-06-26 13:44:46,898 Epoch[11] Batch [150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.134152,	
2017-06-26 13:44:52,227 Epoch[11] Batch [160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134081,	
2017-06-26 13:44:57,592 Epoch[11] Batch [170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.133956,	
2017-06-26 13:45:02,941 Epoch[11] Batch [180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.134683,	
2017-06-26 13:45:08,257 Epoch[11] Batch [190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134016,	
2017-06-26 13:45:13,574 Epoch[11] Batch [200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133599,	
2017-06-26 13:45:18,944 Epoch[11] Batch [210]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.133561,	
2017-06-26 13:45:24,265 Epoch[11] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133490,	
2017-06-26 13:45:29,627 Epoch[11] Batch [230]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.133783,	
2017-06-26 13:45:35,002 Epoch[11] Batch [240]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.134418,	
2017-06-26 13:45:40,295 Epoch[11] Batch [250]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.134732,	
2017-06-26 13:45:45,589 Epoch[11] Batch [260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.135074,	
2017-06-26 13:45:50,940 Epoch[11] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.135444,	
2017-06-26 13:45:56,293 Epoch[11] Batch [280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.135328,	
2017-06-26 13:46:01,686 Epoch[11] Batch [290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.135277,	
2017-06-26 13:46:07,022 Epoch[11] Batch [300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.135254,	
2017-06-26 13:46:12,319 Epoch[11] Batch [310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.135469,	
2017-06-26 13:46:17,696 Epoch[11] Batch [320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.135491,	
2017-06-26 13:46:23,058 Epoch[11] Batch [330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.135040,	
2017-06-26 13:46:28,383 Epoch[11] Batch [340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135084,	
2017-06-26 13:46:33,706 Epoch[11] Batch [350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.135294,	
2017-06-26 13:46:39,061 Epoch[11] Batch [360]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.135453,	
2017-06-26 13:46:44,348 Epoch[11] Batch [370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.134913,	
2017-06-26 13:46:49,724 Epoch[11] Batch [380]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.134897,	
2017-06-26 13:46:55,072 Epoch[11] Batch [390]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.135110,	
2017-06-26 13:47:00,405 Epoch[11] Batch [400]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.135057,	
2017-06-26 13:47:05,179 Epoch[11] Batch [410]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.134647,	
2017-06-26 13:47:09,710 Epoch[11] Batch [420]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.134554,	
2017-06-26 13:47:14,909 Epoch[11] Batch [430]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.134651,	
2017-06-26 13:47:20,311 Epoch[11] Batch [440]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.134408,	
2017-06-26 13:47:25,751 Epoch[11] Batch [450]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.133881,	
2017-06-26 13:47:30,986 Epoch[11] Batch [460]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.133868,	
2017-06-26 13:47:36,294 Epoch[11] Batch [470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.134210,	
2017-06-26 13:47:41,635 Epoch[11] Batch [480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134325,	
2017-06-26 13:47:47,021 Epoch[11] Batch [490]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.134213,	
2017-06-26 13:47:52,350 Epoch[11] Batch [500]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133853,	
2017-06-26 13:47:57,666 Epoch[11] Batch [510]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133686,	
2017-06-26 13:48:03,016 Epoch[11] Batch [520]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133571,	
2017-06-26 13:48:08,353 Epoch[11] Batch [530]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133506,	
2017-06-26 13:48:13,671 Epoch[11] Batch [540]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133255,	
2017-06-26 13:48:18,985 Epoch[11] Batch [550]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133150,	
2017-06-26 13:48:24,381 Epoch[11] Batch [560]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.133080,	
2017-06-26 13:48:29,684 Epoch[11] Batch [570]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.133078,	
2017-06-26 13:48:35,047 Epoch[11] Batch [580]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.132739,	
2017-06-26 13:48:40,363 Epoch[11] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.132922,	
2017-06-26 13:48:45,724 Epoch[11] Batch [600]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.133061,	
2017-06-26 13:48:51,053 Epoch[11] Batch [610]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133177,	
2017-06-26 13:48:56,470 Epoch[11] Batch [620]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.133226,	
2017-06-26 13:49:01,794 Epoch[11] Batch [630]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133285,	
2017-06-26 13:49:07,119 Epoch[11] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133078,	
2017-06-26 13:49:12,472 Epoch[11] Batch [650]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.133228,	
2017-06-26 13:49:17,819 Epoch[11] Batch [660]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133320,	
2017-06-26 13:49:23,155 Epoch[11] Batch [670]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133491,	
2017-06-26 13:49:28,541 Epoch[11] Batch [680]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.133436,	
2017-06-26 13:49:33,879 Epoch[11] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.133327,	
2017-06-26 13:49:39,189 Epoch[11] Batch [700]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133517,	
2017-06-26 13:49:44,517 Epoch[11] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133653,	
2017-06-26 13:49:49,857 Epoch[11] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.133516,	
2017-06-26 13:49:55,238 Epoch[11] Batch [730]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.133330,	
2017-06-26 13:50:00,547 Epoch[11] Batch [740]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133361,	
2017-06-26 13:50:05,886 Epoch[11] Batch [750]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.133394,	
2017-06-26 13:50:11,233 Epoch[11] Batch [760]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133227,	
2017-06-26 13:50:16,589 Epoch[11] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.133229,	
2017-06-26 13:50:21,875 Epoch[11] Batch [780]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.133093,	
2017-06-26 13:50:27,207 Epoch[11] Batch [790]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133069,	
2017-06-26 13:50:32,592 Epoch[11] Batch [800]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.133000,	
2017-06-26 13:50:37,879 Epoch[11] Batch [810]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.132892,	
2017-06-26 13:50:43,257 Epoch[11] Batch [820]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.132904,	
2017-06-26 13:50:48,589 Epoch[11] Batch [830]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.132905,	
2017-06-26 13:50:53,955 Epoch[11] Batch [840]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.132770,	
2017-06-26 13:50:59,291 Epoch[11] Batch [850]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.132720,	
2017-06-26 13:51:04,630 Epoch[11] Batch [860]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.132600,	
2017-06-26 13:51:09,970 Epoch[11] Batch [870]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.132609,	
2017-06-26 13:51:15,272 Epoch[11] Batch [880]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.132565,	
2017-06-26 13:51:20,619 Epoch[11] Batch [890]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.132521,	
2017-06-26 13:51:25,862 Epoch[11] Batch [900]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.132590,	
2017-06-26 13:51:31,238 Epoch[11] Batch [910]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.132447,	
2017-06-26 13:51:36,576 Epoch[11] Batch [920]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.132368,	
2017-06-26 13:51:41,943 Epoch[11] Batch [930]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.132244,	
2017-06-26 13:51:47,244 Epoch[11] Batch [940]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.132138,	
2017-06-26 13:51:52,533 Epoch[11] Batch [950]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.131987,	
2017-06-26 13:51:57,916 Epoch[11] Batch [960]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.131801,	
2017-06-26 13:52:03,242 Epoch[11] Batch [970]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131794,	
2017-06-26 13:52:08,604 Epoch[11] Batch [980]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131942,	
2017-06-26 13:52:13,919 Epoch[11] Batch [990]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.131986,	
2017-06-26 13:52:19,311 Epoch[11] Batch [1000]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.132138,	
2017-06-26 13:52:24,623 Epoch[11] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.132357,	
2017-06-26 13:52:30,006 Epoch[11] Batch [1020]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.132476,	
2017-06-26 13:52:35,315 Epoch[11] Batch [1030]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.132497,	
2017-06-26 13:52:40,689 Epoch[11] Batch [1040]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.132695,	
2017-06-26 13:52:46,049 Epoch[11] Batch [1050]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.132713,	
2017-06-26 13:52:51,344 Epoch[11] Batch [1060]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.132783,	
2017-06-26 13:52:56,727 Epoch[11] Batch [1070]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.132845,	
2017-06-26 13:53:02,010 Epoch[11] Batch [1080]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.132906,	
2017-06-26 13:53:07,387 Epoch[11] Batch [1090]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.132986,	
2017-06-26 13:53:12,725 Epoch[11] Batch [1100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.132994,	
2017-06-26 13:53:18,098 Epoch[11] Batch [1110]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.133063,	
2017-06-26 13:53:23,412 Epoch[11] Batch [1120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133105,	
2017-06-26 13:53:28,745 Epoch[11] Batch [1130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133088,	
2017-06-26 13:53:34,054 Epoch[11] Batch [1140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133033,	
2017-06-26 13:53:39,420 Epoch[11] Batch [1150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.133358,	
2017-06-26 13:53:44,786 Epoch[11] Batch [1160]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.133537,	
2017-06-26 13:53:50,086 Epoch[11] Batch [1170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.133837,	
2017-06-26 13:53:55,267 Epoch[11] Batch [1180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.134178,	
2017-06-26 13:54:00,604 Epoch[11] Batch [1190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.134208,	
2017-06-26 13:54:05,957 Epoch[11] Batch [1200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134176,	
2017-06-26 13:54:11,290 Epoch[11] Batch [1210]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.134180,	
2017-06-26 13:54:16,636 Epoch[11] Batch [1220]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.134198,	
2017-06-26 13:54:21,989 Epoch[11] Batch [1230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134187,	
2017-06-26 13:54:27,295 Epoch[11] Batch [1240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.133984,	
2017-06-26 13:54:32,644 Epoch[11] Batch [1250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133893,	
2017-06-26 13:54:38,002 Epoch[11] Batch [1260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134001,	
2017-06-26 13:54:43,307 Epoch[11] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.134082,	
2017-06-26 13:54:48,665 Epoch[11] Batch [1280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134140,	
2017-06-26 13:54:53,997 Epoch[11] Batch [1290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.134243,	
2017-06-26 13:54:59,325 Epoch[11] Batch [1300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134279,	
2017-06-26 13:55:04,666 Epoch[11] Batch [1310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134306,	
2017-06-26 13:55:09,961 Epoch[11] Batch [1320]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.134317,	
2017-06-26 13:55:15,261 Epoch[11] Batch [1330]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.134234,	
2017-06-26 13:55:20,660 Epoch[11] Batch [1340]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.134288,	
2017-06-26 13:55:25,907 Epoch[11] Batch [1350]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.134316,	
2017-06-26 13:55:31,251 Epoch[11] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.134395,	
2017-06-26 13:55:36,614 Epoch[11] Batch [1370]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.134240,	
2017-06-26 13:55:41,953 Epoch[11] Batch [1380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134249,	
2017-06-26 13:55:47,308 Epoch[11] Batch [1390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134181,	
2017-06-26 13:55:52,652 Epoch[11] Batch [1400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134107,	
2017-06-26 13:55:57,995 Epoch[11] Batch [1410]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.133974,	
2017-06-26 13:56:03,338 Epoch[11] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134007,	
2017-06-26 13:56:08,629 Epoch[11] Batch [1430]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.134047,	
2017-06-26 13:56:13,961 Epoch[11] Batch [1440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133954,	
2017-06-26 13:56:19,275 Epoch[11] Batch [1450]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133822,	
2017-06-26 13:56:24,678 Epoch[11] Batch [1460]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.133861,	
2017-06-26 13:56:29,938 Epoch[11] Batch [1470]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.133891,	
2017-06-26 13:56:35,271 Epoch[11] Batch [1480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.134016,	
2017-06-26 13:56:38,481 Epoch[11] Train-FCNLogLoss=0.134075
2017-06-26 13:56:38,481 Epoch[11] Time cost=792.070
2017-06-26 13:56:39,293 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0012.params"
2017-06-26 13:56:41,016 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0012.states"
2017-06-26 13:56:47,120 Epoch[12] Batch [10]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130646,	
2017-06-26 13:56:52,341 Epoch[12] Batch [20]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.131038,	
2017-06-26 13:56:57,656 Epoch[12] Batch [30]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.137982,	
2017-06-26 13:57:02,990 Epoch[12] Batch [40]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.135907,	
2017-06-26 13:57:08,295 Epoch[12] Batch [50]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.135447,	
2017-06-26 13:57:13,633 Epoch[12] Batch [60]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.137798,	
2017-06-26 13:57:18,951 Epoch[12] Batch [70]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.136620,	
2017-06-26 13:57:24,296 Epoch[12] Batch [80]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.136755,	
2017-06-26 13:57:29,644 Epoch[12] Batch [90]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.137180,	
2017-06-26 13:57:34,967 Epoch[12] Batch [100]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.135545,	
2017-06-26 13:57:40,338 Epoch[12] Batch [110]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.134440,	
2017-06-26 13:57:45,630 Epoch[12] Batch [120]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.133553,	
2017-06-26 13:57:50,886 Epoch[12] Batch [130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.133319,	
2017-06-26 13:57:56,321 Epoch[12] Batch [140]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.132833,	
2017-06-26 13:58:01,684 Epoch[12] Batch [150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.132866,	
2017-06-26 13:58:06,972 Epoch[12] Batch [160]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.132392,	
2017-06-26 13:58:12,294 Epoch[12] Batch [170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.132064,	
2017-06-26 13:58:17,639 Epoch[12] Batch [180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.132045,	
2017-06-26 13:58:23,039 Epoch[12] Batch [190]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.131744,	
2017-06-26 13:58:28,411 Epoch[12] Batch [200]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.132396,	
2017-06-26 13:58:33,727 Epoch[12] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.132388,	
2017-06-26 13:58:39,128 Epoch[12] Batch [220]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.131854,	
2017-06-26 13:58:44,467 Epoch[12] Batch [230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.131640,	
2017-06-26 13:58:49,831 Epoch[12] Batch [240]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131308,	
2017-06-26 13:58:55,192 Epoch[12] Batch [250]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131737,	
2017-06-26 13:59:00,526 Epoch[12] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131439,	
2017-06-26 13:59:05,847 Epoch[12] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131299,	
2017-06-26 13:59:11,185 Epoch[12] Batch [280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130863,	
2017-06-26 13:59:16,518 Epoch[12] Batch [290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130022,	
2017-06-26 13:59:21,856 Epoch[12] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130278,	
2017-06-26 13:59:27,187 Epoch[12] Batch [310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130316,	
2017-06-26 13:59:32,503 Epoch[12] Batch [320]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130039,	
2017-06-26 13:59:37,840 Epoch[12] Batch [330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130166,	
2017-06-26 13:59:43,169 Epoch[12] Batch [340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.129939,	
2017-06-26 13:59:48,507 Epoch[12] Batch [350]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129798,	
2017-06-26 13:59:53,875 Epoch[12] Batch [360]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.129569,	
2017-06-26 13:59:59,156 Epoch[12] Batch [370]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.130350,	
2017-06-26 14:00:04,534 Epoch[12] Batch [380]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.129932,	
2017-06-26 14:00:09,877 Epoch[12] Batch [390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129718,	
2017-06-26 14:00:15,218 Epoch[12] Batch [400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129577,	
2017-06-26 14:00:20,564 Epoch[12] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.129744,	
2017-06-26 14:00:25,024 Epoch[12] Batch [420]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.129748,	
2017-06-26 14:00:29,969 Epoch[12] Batch [430]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.129619,	
2017-06-26 14:00:35,280 Epoch[12] Batch [440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.129684,	
2017-06-26 14:00:40,610 Epoch[12] Batch [450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130051,	
2017-06-26 14:00:45,939 Epoch[12] Batch [460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.129671,	
2017-06-26 14:00:51,280 Epoch[12] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129954,	
2017-06-26 14:00:56,608 Epoch[12] Batch [480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.129761,	
2017-06-26 14:01:01,989 Epoch[12] Batch [490]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129350,	
2017-06-26 14:01:07,294 Epoch[12] Batch [500]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.129336,	
2017-06-26 14:01:12,660 Epoch[12] Batch [510]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.129340,	
2017-06-26 14:01:18,006 Epoch[12] Batch [520]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.129275,	
2017-06-26 14:01:23,343 Epoch[12] Batch [530]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129448,	
2017-06-26 14:01:28,641 Epoch[12] Batch [540]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.129543,	
2017-06-26 14:01:34,037 Epoch[12] Batch [550]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.129868,	
2017-06-26 14:01:39,391 Epoch[12] Batch [560]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.129997,	
2017-06-26 14:01:44,711 Epoch[12] Batch [570]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130322,	
2017-06-26 14:01:50,025 Epoch[12] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130502,	
2017-06-26 14:01:55,323 Epoch[12] Batch [590]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.130538,	
2017-06-26 14:02:00,707 Epoch[12] Batch [600]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.130273,	
2017-06-26 14:02:06,015 Epoch[12] Batch [610]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130208,	
2017-06-26 14:02:11,362 Epoch[12] Batch [620]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.129979,	
2017-06-26 14:02:16,725 Epoch[12] Batch [630]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.129887,	
2017-06-26 14:02:22,044 Epoch[12] Batch [640]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.129792,	
2017-06-26 14:02:27,394 Epoch[12] Batch [650]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.129637,	
2017-06-26 14:02:32,778 Epoch[12] Batch [660]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129410,	
2017-06-26 14:02:38,098 Epoch[12] Batch [670]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.129258,	
2017-06-26 14:02:43,360 Epoch[12] Batch [680]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.129192,	
2017-06-26 14:02:48,674 Epoch[12] Batch [690]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.129247,	
2017-06-26 14:02:54,091 Epoch[12] Batch [700]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.129522,	
2017-06-26 14:02:59,392 Epoch[12] Batch [710]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.129655,	
2017-06-26 14:03:04,774 Epoch[12] Batch [720]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129800,	
2017-06-26 14:03:10,050 Epoch[12] Batch [730]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.129609,	
2017-06-26 14:03:15,422 Epoch[12] Batch [740]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.129474,	
2017-06-26 14:03:20,825 Epoch[12] Batch [750]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.129369,	
2017-06-26 14:03:26,049 Epoch[12] Batch [760]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.129322,	
2017-06-26 14:03:31,407 Epoch[12] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.129189,	
2017-06-26 14:03:36,721 Epoch[12] Batch [780]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.129400,	
2017-06-26 14:03:42,105 Epoch[12] Batch [790]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129519,	
2017-06-26 14:03:47,430 Epoch[12] Batch [800]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.129512,	
2017-06-26 14:03:52,773 Epoch[12] Batch [810]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129392,	
2017-06-26 14:03:58,153 Epoch[12] Batch [820]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129622,	
2017-06-26 14:04:03,484 Epoch[12] Batch [830]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.129806,	
2017-06-26 14:04:08,822 Epoch[12] Batch [840]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129791,	
2017-06-26 14:04:14,204 Epoch[12] Batch [850]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129877,	
2017-06-26 14:04:19,469 Epoch[12] Batch [860]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.130137,	
2017-06-26 14:04:24,756 Epoch[12] Batch [870]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130159,	
2017-06-26 14:04:30,140 Epoch[12] Batch [880]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.130545,	
2017-06-26 14:04:35,521 Epoch[12] Batch [890]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.130710,	
2017-06-26 14:04:40,826 Epoch[12] Batch [900]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130789,	
2017-06-26 14:04:46,119 Epoch[12] Batch [910]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.130891,	
2017-06-26 14:04:51,525 Epoch[12] Batch [920]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.131121,	
2017-06-26 14:04:56,777 Epoch[12] Batch [930]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.131379,	
2017-06-26 14:05:02,124 Epoch[12] Batch [940]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.131721,	
2017-06-26 14:05:07,469 Epoch[12] Batch [950]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.131923,	
2017-06-26 14:05:12,771 Epoch[12] Batch [960]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.131983,	
2017-06-26 14:05:18,159 Epoch[12] Batch [970]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.132008,	
2017-06-26 14:05:23,403 Epoch[12] Batch [980]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.131901,	
2017-06-26 14:05:28,752 Epoch[12] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.132274,	
2017-06-26 14:05:34,109 Epoch[12] Batch [1000]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.132370,	
2017-06-26 14:05:39,504 Epoch[12] Batch [1010]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.132545,	
2017-06-26 14:05:44,794 Epoch[12] Batch [1020]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.132586,	
2017-06-26 14:05:50,189 Epoch[12] Batch [1030]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.132619,	
2017-06-26 14:05:55,524 Epoch[12] Batch [1040]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.132785,	
2017-06-26 14:06:00,826 Epoch[12] Batch [1050]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.132760,	
2017-06-26 14:06:06,185 Epoch[12] Batch [1060]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.132877,	
2017-06-26 14:06:11,542 Epoch[12] Batch [1070]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.132974,	
2017-06-26 14:06:16,836 Epoch[12] Batch [1080]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.132874,	
2017-06-26 14:06:22,160 Epoch[12] Batch [1090]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.132982,	
2017-06-26 14:06:27,456 Epoch[12] Batch [1100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.132968,	
2017-06-26 14:06:32,777 Epoch[12] Batch [1110]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133135,	
2017-06-26 14:06:38,188 Epoch[12] Batch [1120]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.133182,	
2017-06-26 14:06:43,484 Epoch[12] Batch [1130]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.133373,	
2017-06-26 14:06:48,841 Epoch[12] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.133442,	
2017-06-26 14:06:54,233 Epoch[12] Batch [1150]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.133726,	
2017-06-26 14:06:59,552 Epoch[12] Batch [1160]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133585,	
2017-06-26 14:07:04,875 Epoch[12] Batch [1170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133576,	
2017-06-26 14:07:10,237 Epoch[12] Batch [1180]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.133634,	
2017-06-26 14:07:15,578 Epoch[12] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.133628,	
2017-06-26 14:07:20,894 Epoch[12] Batch [1200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133626,	
2017-06-26 14:07:26,269 Epoch[12] Batch [1210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.133811,	
2017-06-26 14:07:31,548 Epoch[12] Batch [1220]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.133792,	
2017-06-26 14:07:36,876 Epoch[12] Batch [1230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133742,	
2017-06-26 14:07:42,201 Epoch[12] Batch [1240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133810,	
2017-06-26 14:07:47,527 Epoch[12] Batch [1250]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133808,	
2017-06-26 14:07:52,821 Epoch[12] Batch [1260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.133775,	
2017-06-26 14:07:58,149 Epoch[12] Batch [1270]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133575,	
2017-06-26 14:08:03,504 Epoch[12] Batch [1280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.133769,	
2017-06-26 14:08:08,854 Epoch[12] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133762,	
2017-06-26 14:08:14,176 Epoch[12] Batch [1300]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.133781,	
2017-06-26 14:08:19,503 Epoch[12] Batch [1310]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133806,	
2017-06-26 14:08:24,944 Epoch[12] Batch [1320]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.133790,	
2017-06-26 14:08:30,309 Epoch[12] Batch [1330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.133822,	
2017-06-26 14:08:35,657 Epoch[12] Batch [1340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133803,	
2017-06-26 14:08:41,030 Epoch[12] Batch [1350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.133668,	
2017-06-26 14:08:46,359 Epoch[12] Batch [1360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133657,	
2017-06-26 14:08:51,706 Epoch[12] Batch [1370]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133663,	
2017-06-26 14:08:57,074 Epoch[12] Batch [1380]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.133765,	
2017-06-26 14:09:02,407 Epoch[12] Batch [1390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.133846,	
2017-06-26 14:09:07,781 Epoch[12] Batch [1400]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.133982,	
2017-06-26 14:09:13,137 Epoch[12] Batch [1410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134100,	
2017-06-26 14:09:18,435 Epoch[12] Batch [1420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.134075,	
2017-06-26 14:09:23,753 Epoch[12] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.134073,	
2017-06-26 14:09:29,123 Epoch[12] Batch [1440]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.134260,	
2017-06-26 14:09:34,432 Epoch[12] Batch [1450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.134558,	
2017-06-26 14:09:39,774 Epoch[12] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134685,	
2017-06-26 14:09:45,115 Epoch[12] Batch [1470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.134784,	
2017-06-26 14:09:50,439 Epoch[12] Batch [1480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.134866,	
2017-06-26 14:09:53,617 Epoch[12] Train-FCNLogLoss=0.134818
2017-06-26 14:09:53,617 Epoch[12] Time cost=792.601
2017-06-26 14:09:54,386 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0013.params"
2017-06-26 14:09:56,022 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0013.states"
2017-06-26 14:10:02,000 Epoch[13] Batch [10]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.122003,	
2017-06-26 14:10:07,373 Epoch[13] Batch [20]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118135,	
2017-06-26 14:10:12,652 Epoch[13] Batch [30]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121593,	
2017-06-26 14:10:18,011 Epoch[13] Batch [40]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.122651,	
2017-06-26 14:10:23,398 Epoch[13] Batch [50]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129729,	
2017-06-26 14:10:28,720 Epoch[13] Batch [60]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.136054,	
2017-06-26 14:10:34,056 Epoch[13] Batch [70]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.136719,	
2017-06-26 14:10:39,402 Epoch[13] Batch [80]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.136225,	
2017-06-26 14:10:44,758 Epoch[13] Batch [90]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.136076,	
2017-06-26 14:10:50,072 Epoch[13] Batch [100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.135816,	
2017-06-26 14:10:55,416 Epoch[13] Batch [110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.135229,	
2017-06-26 14:11:00,801 Epoch[13] Batch [120]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.136022,	
2017-06-26 14:11:06,096 Epoch[13] Batch [130]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.135509,	
2017-06-26 14:11:11,448 Epoch[13] Batch [140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.134489,	
2017-06-26 14:11:16,829 Epoch[13] Batch [150]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.133403,	
2017-06-26 14:11:22,141 Epoch[13] Batch [160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.133520,	
2017-06-26 14:11:27,470 Epoch[13] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.133183,	
2017-06-26 14:11:32,820 Epoch[13] Batch [180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.133421,	
2017-06-26 14:11:38,230 Epoch[13] Batch [190]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.132489,	
2017-06-26 14:11:43,500 Epoch[13] Batch [200]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.131922,	
2017-06-26 14:11:48,873 Epoch[13] Batch [210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.131665,	
2017-06-26 14:11:54,260 Epoch[13] Batch [220]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.131246,	
2017-06-26 14:11:59,550 Epoch[13] Batch [230]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.131359,	
2017-06-26 14:12:04,880 Epoch[13] Batch [240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130567,	
2017-06-26 14:12:10,151 Epoch[13] Batch [250]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.129913,	
2017-06-26 14:12:15,508 Epoch[13] Batch [260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130008,	
2017-06-26 14:12:20,820 Epoch[13] Batch [270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.129847,	
2017-06-26 14:12:26,175 Epoch[13] Batch [280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130017,	
2017-06-26 14:12:31,485 Epoch[13] Batch [290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130271,	
2017-06-26 14:12:36,825 Epoch[13] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130144,	
2017-06-26 14:12:42,174 Epoch[13] Batch [310]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130292,	
2017-06-26 14:12:47,526 Epoch[13] Batch [320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131437,	
2017-06-26 14:12:52,896 Epoch[13] Batch [330]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.131427,	
2017-06-26 14:12:58,181 Epoch[13] Batch [340]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.131281,	
2017-06-26 14:13:03,522 Epoch[13] Batch [350]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.131616,	
2017-06-26 14:13:08,828 Epoch[13] Batch [360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.131443,	
2017-06-26 14:13:14,115 Epoch[13] Batch [370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130881,	
2017-06-26 14:13:19,457 Epoch[13] Batch [380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.131054,	
2017-06-26 14:13:24,778 Epoch[13] Batch [390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130762,	
2017-06-26 14:13:30,135 Epoch[13] Batch [400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130501,	
2017-06-26 14:13:35,442 Epoch[13] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130081,	
2017-06-26 14:13:40,474 Epoch[13] Batch [420]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.129904,	
2017-06-26 14:13:45,227 Epoch[13] Batch [430]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.129945,	
2017-06-26 14:13:50,409 Epoch[13] Batch [440]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.129752,	
2017-06-26 14:13:55,726 Epoch[13] Batch [450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.129880,	
2017-06-26 14:14:01,072 Epoch[13] Batch [460]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130156,	
2017-06-26 14:14:06,407 Epoch[13] Batch [470]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131648,	
2017-06-26 14:14:11,730 Epoch[13] Batch [480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.132133,	
2017-06-26 14:14:17,037 Epoch[13] Batch [490]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.132187,	
2017-06-26 14:14:22,357 Epoch[13] Batch [500]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.132183,	
2017-06-26 14:14:27,796 Epoch[13] Batch [510]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.132300,	
2017-06-26 14:14:33,014 Epoch[13] Batch [520]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.132026,	
2017-06-26 14:14:38,378 Epoch[13] Batch [530]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131955,	
2017-06-26 14:14:43,715 Epoch[13] Batch [540]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131866,	
2017-06-26 14:14:49,031 Epoch[13] Batch [550]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.131892,	
2017-06-26 14:14:54,419 Epoch[13] Batch [560]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.131857,	
2017-06-26 14:14:59,673 Epoch[13] Batch [570]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.132206,	
2017-06-26 14:15:04,696 Epoch[13] Batch [580]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.132135,	
2017-06-26 14:15:10,063 Epoch[13] Batch [590]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.131919,	
2017-06-26 14:15:15,171 Epoch[13] Batch [600]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.131664,	
2017-06-26 14:15:20,490 Epoch[13] Batch [610]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131757,	
2017-06-26 14:15:25,756 Epoch[13] Batch [620]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.132037,	
2017-06-26 14:15:31,080 Epoch[13] Batch [630]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131870,	
2017-06-26 14:15:36,471 Epoch[13] Batch [640]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.131641,	
2017-06-26 14:15:41,541 Epoch[13] Batch [650]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.131446,	
2017-06-26 14:15:46,805 Epoch[13] Batch [660]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.131464,	
2017-06-26 14:15:52,138 Epoch[13] Batch [670]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.131580,	
2017-06-26 14:15:57,451 Epoch[13] Batch [680]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.131317,	
2017-06-26 14:16:02,693 Epoch[13] Batch [690]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.131137,	
2017-06-26 14:16:08,101 Epoch[13] Batch [700]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.131304,	
2017-06-26 14:16:13,403 Epoch[13] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.131402,	
2017-06-26 14:16:18,758 Epoch[13] Batch [720]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131491,	
2017-06-26 14:16:24,115 Epoch[13] Batch [730]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131327,	
2017-06-26 14:16:29,438 Epoch[13] Batch [740]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131513,	
2017-06-26 14:16:34,796 Epoch[13] Batch [750]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.131572,	
2017-06-26 14:16:40,114 Epoch[13] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131539,	
2017-06-26 14:16:45,406 Epoch[13] Batch [770]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.131733,	
2017-06-26 14:16:50,653 Epoch[13] Batch [780]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.131636,	
2017-06-26 14:16:56,033 Epoch[13] Batch [790]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.131578,	
2017-06-26 14:17:01,336 Epoch[13] Batch [800]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.131792,	
2017-06-26 14:17:06,750 Epoch[13] Batch [810]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.131780,	
2017-06-26 14:17:12,060 Epoch[13] Batch [820]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.131684,	
2017-06-26 14:17:17,353 Epoch[13] Batch [830]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.131623,	
2017-06-26 14:17:22,682 Epoch[13] Batch [840]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.131725,	
2017-06-26 14:17:28,023 Epoch[13] Batch [850]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.131584,	
2017-06-26 14:17:33,385 Epoch[13] Batch [860]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131514,	
2017-06-26 14:17:38,702 Epoch[13] Batch [870]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.131337,	
2017-06-26 14:17:44,064 Epoch[13] Batch [880]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.131130,	
2017-06-26 14:17:49,404 Epoch[13] Batch [890]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130987,	
2017-06-26 14:17:54,715 Epoch[13] Batch [900]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130767,	
2017-06-26 14:18:00,044 Epoch[13] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130722,	
2017-06-26 14:18:05,100 Epoch[13] Batch [920]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.130607,	
2017-06-26 14:18:10,213 Epoch[13] Batch [930]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.130619,	
2017-06-26 14:18:15,282 Epoch[13] Batch [940]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.130739,	
2017-06-26 14:18:20,577 Epoch[13] Batch [950]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.130839,	
2017-06-26 14:18:25,445 Epoch[13] Batch [960]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.130816,	
2017-06-26 14:18:30,217 Epoch[13] Batch [970]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.130695,	
2017-06-26 14:18:35,021 Epoch[13] Batch [980]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.130611,	
2017-06-26 14:18:40,338 Epoch[13] Batch [990]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130612,	
2017-06-26 14:18:45,666 Epoch[13] Batch [1000]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130797,	
2017-06-26 14:18:50,889 Epoch[13] Batch [1010]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.130762,	
2017-06-26 14:18:56,043 Epoch[13] Batch [1020]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.130611,	
2017-06-26 14:19:01,334 Epoch[13] Batch [1030]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.130692,	
2017-06-26 14:19:06,686 Epoch[13] Batch [1040]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130765,	
2017-06-26 14:19:12,044 Epoch[13] Batch [1050]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130919,	
2017-06-26 14:19:17,462 Epoch[13] Batch [1060]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.130979,	
2017-06-26 14:19:22,734 Epoch[13] Batch [1070]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.130832,	
2017-06-26 14:19:28,089 Epoch[13] Batch [1080]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130792,	
2017-06-26 14:19:33,467 Epoch[13] Batch [1090]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.130729,	
2017-06-26 14:19:38,793 Epoch[13] Batch [1100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130605,	
2017-06-26 14:19:44,156 Epoch[13] Batch [1110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130534,	
2017-06-26 14:19:49,519 Epoch[13] Batch [1120]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130690,	
2017-06-26 14:19:54,826 Epoch[13] Batch [1130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130541,	
2017-06-26 14:20:00,160 Epoch[13] Batch [1140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.130517,	
2017-06-26 14:20:05,519 Epoch[13] Batch [1150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.130471,	
2017-06-26 14:20:10,890 Epoch[13] Batch [1160]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.130483,	
2017-06-26 14:20:16,192 Epoch[13] Batch [1170]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.130434,	
2017-06-26 14:20:21,507 Epoch[13] Batch [1180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130460,	
2017-06-26 14:20:26,823 Epoch[13] Batch [1190]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130386,	
2017-06-26 14:20:32,167 Epoch[13] Batch [1200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130316,	
2017-06-26 14:20:37,479 Epoch[13] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.130235,	
2017-06-26 14:20:42,821 Epoch[13] Batch [1220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130166,	
2017-06-26 14:20:48,178 Epoch[13] Batch [1230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.130203,	
2017-06-26 14:20:53,521 Epoch[13] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130136,	
2017-06-26 14:20:58,826 Epoch[13] Batch [1250]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130063,	
2017-06-26 14:21:03,893 Epoch[13] Batch [1260]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.130060,	
2017-06-26 14:21:09,198 Epoch[13] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.130084,	
2017-06-26 14:21:14,484 Epoch[13] Batch [1280]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130203,	
2017-06-26 14:21:19,806 Epoch[13] Batch [1290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.130249,	
2017-06-26 14:21:25,107 Epoch[13] Batch [1300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.130242,	
2017-06-26 14:21:30,446 Epoch[13] Batch [1310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130195,	
2017-06-26 14:21:35,793 Epoch[13] Batch [1320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.130216,	
2017-06-26 14:21:41,170 Epoch[13] Batch [1330]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.130296,	
2017-06-26 14:21:46,513 Epoch[13] Batch [1340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.130208,	
2017-06-26 14:21:51,908 Epoch[13] Batch [1350]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.130145,	
2017-06-26 14:21:57,120 Epoch[13] Batch [1360]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.130179,	
2017-06-26 14:22:02,510 Epoch[13] Batch [1370]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.130099,	
2017-06-26 14:22:07,840 Epoch[13] Batch [1380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.130075,	
2017-06-26 14:22:13,227 Epoch[13] Batch [1390]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.130091,	
2017-06-26 14:22:18,528 Epoch[13] Batch [1400]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.130074,	
2017-06-26 14:22:23,870 Epoch[13] Batch [1410]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129979,	
2017-06-26 14:22:29,272 Epoch[13] Batch [1420]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.129951,	
2017-06-26 14:22:34,552 Epoch[13] Batch [1430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.129966,	
2017-06-26 14:22:39,936 Epoch[13] Batch [1440]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.129905,	
2017-06-26 14:22:45,239 Epoch[13] Batch [1450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.129830,	
2017-06-26 14:22:50,577 Epoch[13] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.129749,	
2017-06-26 14:22:55,937 Epoch[13] Batch [1470]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.129784,	
2017-06-26 14:23:01,228 Epoch[13] Batch [1480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.129810,	
2017-06-26 14:23:04,412 Epoch[13] Train-FCNLogLoss=0.129830
2017-06-26 14:23:04,412 Epoch[13] Time cost=788.389
2017-06-26 14:23:05,250 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0014.params"
2017-06-26 14:23:07,040 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0014.states"
2017-06-26 14:23:13,187 Epoch[14] Batch [10]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.115939,	
2017-06-26 14:23:18,532 Epoch[14] Batch [20]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125034,	
2017-06-26 14:23:23,929 Epoch[14] Batch [30]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.128459,	
2017-06-26 14:23:29,216 Epoch[14] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.130324,	
2017-06-26 14:23:34,603 Epoch[14] Batch [50]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.127333,	
2017-06-26 14:23:39,891 Epoch[14] Batch [60]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.126870,	
2017-06-26 14:23:45,227 Epoch[14] Batch [70]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.126739,	
2017-06-26 14:23:50,569 Epoch[14] Batch [80]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125140,	
2017-06-26 14:23:55,959 Epoch[14] Batch [90]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125356,	
2017-06-26 14:24:01,300 Epoch[14] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124411,	
2017-06-26 14:24:06,607 Epoch[14] Batch [110]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124898,	
2017-06-26 14:24:11,749 Epoch[14] Batch [120]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.123576,	
2017-06-26 14:24:16,747 Epoch[14] Batch [130]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.123251,	
2017-06-26 14:24:22,087 Epoch[14] Batch [140]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.122718,	
2017-06-26 14:24:27,429 Epoch[14] Batch [150]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.122381,	
2017-06-26 14:24:32,760 Epoch[14] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.122054,	
2017-06-26 14:24:38,115 Epoch[14] Batch [170]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.122052,	
2017-06-26 14:24:43,471 Epoch[14] Batch [180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.122227,	
2017-06-26 14:24:48,810 Epoch[14] Batch [190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.122986,	
2017-06-26 14:24:54,198 Epoch[14] Batch [200]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.123924,	
2017-06-26 14:24:59,499 Epoch[14] Batch [210]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124805,	
2017-06-26 14:25:04,895 Epoch[14] Batch [220]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.124493,	
2017-06-26 14:25:10,175 Epoch[14] Batch [230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.124585,	
2017-06-26 14:25:15,525 Epoch[14] Batch [240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124258,	
2017-06-26 14:25:20,883 Epoch[14] Batch [250]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124363,	
2017-06-26 14:25:26,216 Epoch[14] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124128,	
2017-06-26 14:25:31,571 Epoch[14] Batch [270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124448,	
2017-06-26 14:25:36,904 Epoch[14] Batch [280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124314,	
2017-06-26 14:25:42,268 Epoch[14] Batch [290]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125417,	
2017-06-26 14:25:47,631 Epoch[14] Batch [300]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125815,	
2017-06-26 14:25:53,021 Epoch[14] Batch [310]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.127042,	
2017-06-26 14:25:58,301 Epoch[14] Batch [320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.127937,	
2017-06-26 14:26:03,622 Epoch[14] Batch [330]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.127880,	
2017-06-26 14:26:08,971 Epoch[14] Batch [340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.127866,	
2017-06-26 14:26:14,300 Epoch[14] Batch [350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.127791,	
2017-06-26 14:26:19,620 Epoch[14] Batch [360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.127721,	
2017-06-26 14:26:25,006 Epoch[14] Batch [370]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.127855,	
2017-06-26 14:26:30,340 Epoch[14] Batch [380]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.127978,	
2017-06-26 14:26:35,706 Epoch[14] Batch [390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.127879,	
2017-06-26 14:26:40,987 Epoch[14] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.127901,	
2017-06-26 14:26:46,311 Epoch[14] Batch [410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.127731,	
2017-06-26 14:26:51,634 Epoch[14] Batch [420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.127472,	
2017-06-26 14:26:56,937 Epoch[14] Batch [430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.127523,	
2017-06-26 14:27:02,271 Epoch[14] Batch [440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.127470,	
2017-06-26 14:27:06,127 Epoch[14] Batch [450]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.127843,	
2017-06-26 14:27:11,125 Epoch[14] Batch [460]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.128015,	
2017-06-26 14:27:16,464 Epoch[14] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.127968,	
2017-06-26 14:27:21,811 Epoch[14] Batch [480]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.127735,	
2017-06-26 14:27:27,040 Epoch[14] Batch [490]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.127702,	
2017-06-26 14:27:32,401 Epoch[14] Batch [500]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.127412,	
2017-06-26 14:27:37,761 Epoch[14] Batch [510]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.127371,	
2017-06-26 14:27:43,082 Epoch[14] Batch [520]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.127408,	
2017-06-26 14:27:48,066 Epoch[14] Batch [530]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.127576,	
2017-06-26 14:27:53,040 Epoch[14] Batch [540]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.127462,	
2017-06-26 14:27:58,421 Epoch[14] Batch [550]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.127264,	
2017-06-26 14:28:03,760 Epoch[14] Batch [560]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.126983,	
2017-06-26 14:28:09,040 Epoch[14] Batch [570]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.126709,	
2017-06-26 14:28:14,244 Epoch[14] Batch [580]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126603,	
2017-06-26 14:28:19,351 Epoch[14] Batch [590]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.126336,	
2017-06-26 14:28:24,620 Epoch[14] Batch [600]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.126461,	
2017-06-26 14:28:29,973 Epoch[14] Batch [610]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.126606,	
2017-06-26 14:28:35,310 Epoch[14] Batch [620]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.126857,	
2017-06-26 14:28:40,640 Epoch[14] Batch [630]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.126797,	
2017-06-26 14:28:45,995 Epoch[14] Batch [640]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.126775,	
2017-06-26 14:28:51,330 Epoch[14] Batch [650]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.126827,	
2017-06-26 14:28:56,632 Epoch[14] Batch [660]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.126690,	
2017-06-26 14:29:01,972 Epoch[14] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.126782,	
2017-06-26 14:29:07,321 Epoch[14] Batch [680]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.126541,	
2017-06-26 14:29:12,635 Epoch[14] Batch [690]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.126562,	
2017-06-26 14:29:17,990 Epoch[14] Batch [700]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.126411,	
2017-06-26 14:29:23,361 Epoch[14] Batch [710]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.126145,	
2017-06-26 14:29:28,660 Epoch[14] Batch [720]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125997,	
2017-06-26 14:29:33,991 Epoch[14] Batch [730]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125833,	
2017-06-26 14:29:39,369 Epoch[14] Batch [740]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125527,	
2017-06-26 14:29:44,659 Epoch[14] Batch [750]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125853,	
2017-06-26 14:29:50,028 Epoch[14] Batch [760]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125899,	
2017-06-26 14:29:55,322 Epoch[14] Batch [770]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125942,	
2017-06-26 14:30:00,720 Epoch[14] Batch [780]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.125852,	
2017-06-26 14:30:06,031 Epoch[14] Batch [790]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125878,	
2017-06-26 14:30:10,906 Epoch[14] Batch [800]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.126010,	
2017-06-26 14:30:16,106 Epoch[14] Batch [810]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.126218,	
2017-06-26 14:30:21,180 Epoch[14] Batch [820]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.126342,	
2017-06-26 14:30:25,794 Epoch[14] Batch [830]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.126328,	
2017-06-26 14:30:30,669 Epoch[14] Batch [840]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.126341,	
2017-06-26 14:30:35,560 Epoch[14] Batch [850]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.126237,	
2017-06-26 14:30:40,861 Epoch[14] Batch [860]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.126079,	
2017-06-26 14:30:46,148 Epoch[14] Batch [870]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.126138,	
2017-06-26 14:30:51,536 Epoch[14] Batch [880]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.126158,	
2017-06-26 14:30:56,848 Epoch[14] Batch [890]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.126061,	
2017-06-26 14:31:02,195 Epoch[14] Batch [900]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.126073,	
2017-06-26 14:31:07,562 Epoch[14] Batch [910]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.126037,	
2017-06-26 14:31:12,874 Epoch[14] Batch [920]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.126041,	
2017-06-26 14:31:18,241 Epoch[14] Batch [930]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125877,	
2017-06-26 14:31:23,589 Epoch[14] Batch [940]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125931,	
2017-06-26 14:31:28,969 Epoch[14] Batch [950]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125991,	
2017-06-26 14:31:34,275 Epoch[14] Batch [960]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125948,	
2017-06-26 14:31:39,598 Epoch[14] Batch [970]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125891,	
2017-06-26 14:31:44,952 Epoch[14] Batch [980]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125843,	
2017-06-26 14:31:50,306 Epoch[14] Batch [990]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125833,	
2017-06-26 14:31:55,646 Epoch[14] Batch [1000]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125773,	
2017-06-26 14:32:00,958 Epoch[14] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125754,	
2017-06-26 14:32:06,309 Epoch[14] Batch [1020]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125620,	
2017-06-26 14:32:11,620 Epoch[14] Batch [1030]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125590,	
2017-06-26 14:32:16,975 Epoch[14] Batch [1040]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125602,	
2017-06-26 14:32:22,321 Epoch[14] Batch [1050]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125525,	
2017-06-26 14:32:27,628 Epoch[14] Batch [1060]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125573,	
2017-06-26 14:32:32,991 Epoch[14] Batch [1070]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125441,	
2017-06-26 14:32:38,338 Epoch[14] Batch [1080]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125352,	
2017-06-26 14:32:43,648 Epoch[14] Batch [1090]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125258,	
2017-06-26 14:32:48,977 Epoch[14] Batch [1100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125274,	
2017-06-26 14:32:54,342 Epoch[14] Batch [1110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125169,	
2017-06-26 14:32:59,663 Epoch[14] Batch [1120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125122,	
2017-06-26 14:33:05,018 Epoch[14] Batch [1130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125140,	
2017-06-26 14:33:10,353 Epoch[14] Batch [1140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125120,	
2017-06-26 14:33:15,683 Epoch[14] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125214,	
2017-06-26 14:33:21,047 Epoch[14] Batch [1160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125149,	
2017-06-26 14:33:26,382 Epoch[14] Batch [1170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125175,	
2017-06-26 14:33:31,735 Epoch[14] Batch [1180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125203,	
2017-06-26 14:33:37,147 Epoch[14] Batch [1190]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.125220,	
2017-06-26 14:33:42,430 Epoch[14] Batch [1200]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125191,	
2017-06-26 14:33:47,721 Epoch[14] Batch [1210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125176,	
2017-06-26 14:33:53,107 Epoch[14] Batch [1220]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125209,	
2017-06-26 14:33:58,441 Epoch[14] Batch [1230]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125188,	
2017-06-26 14:34:03,787 Epoch[14] Batch [1240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125119,	
2017-06-26 14:34:09,135 Epoch[14] Batch [1250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125061,	
2017-06-26 14:34:14,442 Epoch[14] Batch [1260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125001,	
2017-06-26 14:34:19,775 Epoch[14] Batch [1270]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124833,	
2017-06-26 14:34:25,093 Epoch[14] Batch [1280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.124782,	
2017-06-26 14:34:30,437 Epoch[14] Batch [1290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124708,	
2017-06-26 14:34:35,760 Epoch[14] Batch [1300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124653,	
2017-06-26 14:34:41,103 Epoch[14] Batch [1310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124630,	
2017-06-26 14:34:46,439 Epoch[14] Batch [1320]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124653,	
2017-06-26 14:34:51,825 Epoch[14] Batch [1330]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.124655,	
2017-06-26 14:34:57,154 Epoch[14] Batch [1340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124645,	
2017-06-26 14:35:02,466 Epoch[14] Batch [1350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124580,	
2017-06-26 14:35:07,799 Epoch[14] Batch [1360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124582,	
2017-06-26 14:35:13,175 Epoch[14] Batch [1370]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.124693,	
2017-06-26 14:35:18,464 Epoch[14] Batch [1380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.124715,	
2017-06-26 14:35:23,794 Epoch[14] Batch [1390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124859,	
2017-06-26 14:35:29,141 Epoch[14] Batch [1400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124983,	
2017-06-26 14:35:34,475 Epoch[14] Batch [1410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125102,	
2017-06-26 14:35:39,827 Epoch[14] Batch [1420]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125239,	
2017-06-26 14:35:45,205 Epoch[14] Batch [1430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.125254,	
2017-06-26 14:35:50,498 Epoch[14] Batch [1440]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125265,	
2017-06-26 14:35:55,855 Epoch[14] Batch [1450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125277,	
2017-06-26 14:36:01,203 Epoch[14] Batch [1460]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125292,	
2017-06-26 14:36:06,542 Epoch[14] Batch [1470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125283,	
2017-06-26 14:36:11,912 Epoch[14] Batch [1480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125317,	
2017-06-26 14:36:15,077 Epoch[14] Train-FCNLogLoss=0.125329
2017-06-26 14:36:15,077 Epoch[14] Time cost=788.037
2017-06-26 14:36:15,908 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0015.params"
2017-06-26 14:36:17,537 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0015.states"
2017-06-26 14:36:23,566 Epoch[15] Batch [10]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.132804,	
2017-06-26 14:36:28,873 Epoch[15] Batch [20]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.127880,	
2017-06-26 14:36:34,263 Epoch[15] Batch [30]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125842,	
2017-06-26 14:36:39,579 Epoch[15] Batch [40]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.126044,	
2017-06-26 14:36:44,905 Epoch[15] Batch [50]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.126523,	
2017-06-26 14:36:50,255 Epoch[15] Batch [60]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124880,	
2017-06-26 14:36:55,601 Epoch[15] Batch [70]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.126611,	
2017-06-26 14:37:00,894 Epoch[15] Batch [80]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.127132,	
2017-06-26 14:37:06,140 Epoch[15] Batch [90]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.127692,	
2017-06-26 14:37:11,468 Epoch[15] Batch [100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.126168,	
2017-06-26 14:37:16,860 Epoch[15] Batch [110]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125748,	
2017-06-26 14:37:22,180 Epoch[15] Batch [120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125436,	
2017-06-26 14:37:27,597 Epoch[15] Batch [130]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.126068,	
2017-06-26 14:37:32,860 Epoch[15] Batch [140]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.125703,	
2017-06-26 14:37:38,228 Epoch[15] Batch [150]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.125897,	
2017-06-26 14:37:43,557 Epoch[15] Batch [160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125421,	
2017-06-26 14:37:48,873 Epoch[15] Batch [170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.124846,	
2017-06-26 14:37:54,224 Epoch[15] Batch [180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.126501,	
2017-06-26 14:37:59,518 Epoch[15] Batch [190]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.126160,	
2017-06-26 14:38:04,825 Epoch[15] Batch [200]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125833,	
2017-06-26 14:38:10,159 Epoch[15] Batch [210]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125172,	
2017-06-26 14:38:15,502 Epoch[15] Batch [220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124953,	
2017-06-26 14:38:20,174 Epoch[15] Batch [230]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.124753,	
2017-06-26 14:38:25,438 Epoch[15] Batch [240]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124480,	
2017-06-26 14:38:30,759 Epoch[15] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.124231,	
2017-06-26 14:38:36,193 Epoch[15] Batch [260]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.123626,	
2017-06-26 14:38:41,543 Epoch[15] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.123497,	
2017-06-26 14:38:46,835 Epoch[15] Batch [280]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.123261,	
2017-06-26 14:38:52,155 Epoch[15] Batch [290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.122667,	
2017-06-26 14:38:57,587 Epoch[15] Batch [300]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.122693,	
2017-06-26 14:39:02,876 Epoch[15] Batch [310]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122914,	
2017-06-26 14:39:08,274 Epoch[15] Batch [320]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.123401,	
2017-06-26 14:39:13,544 Epoch[15] Batch [330]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.123454,	
2017-06-26 14:39:18,892 Epoch[15] Batch [340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122989,	
2017-06-26 14:39:24,276 Epoch[15] Batch [350]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.122832,	
2017-06-26 14:39:29,605 Epoch[15] Batch [360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122839,	
2017-06-26 14:39:34,932 Epoch[15] Batch [370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122744,	
2017-06-26 14:39:40,215 Epoch[15] Batch [380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122588,	
2017-06-26 14:39:45,614 Epoch[15] Batch [390]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.122482,	
2017-06-26 14:39:50,927 Epoch[15] Batch [400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.122390,	
2017-06-26 14:39:56,278 Epoch[15] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122134,	
2017-06-26 14:40:01,599 Epoch[15] Batch [420]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121923,	
2017-06-26 14:40:06,978 Epoch[15] Batch [430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121854,	
2017-06-26 14:40:12,309 Epoch[15] Batch [440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121707,	
2017-06-26 14:40:17,617 Epoch[15] Batch [450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.122004,	
2017-06-26 14:40:23,018 Epoch[15] Batch [460]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.121872,	
2017-06-26 14:40:27,455 Epoch[15] Batch [470]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.121837,	
2017-06-26 14:40:31,857 Epoch[15] Batch [480]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.121950,	
2017-06-26 14:40:37,109 Epoch[15] Batch [490]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.121805,	
2017-06-26 14:40:42,461 Epoch[15] Batch [500]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121474,	
2017-06-26 14:40:47,784 Epoch[15] Batch [510]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121301,	
2017-06-26 14:40:53,131 Epoch[15] Batch [520]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121115,	
2017-06-26 14:40:58,469 Epoch[15] Batch [530]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121108,	
2017-06-26 14:41:03,769 Epoch[15] Batch [540]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121221,	
2017-06-26 14:41:09,112 Epoch[15] Batch [550]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121374,	
2017-06-26 14:41:14,428 Epoch[15] Batch [560]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121345,	
2017-06-26 14:41:19,783 Epoch[15] Batch [570]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121432,	
2017-06-26 14:41:25,159 Epoch[15] Batch [580]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121454,	
2017-06-26 14:41:30,440 Epoch[15] Batch [590]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121442,	
2017-06-26 14:41:35,788 Epoch[15] Batch [600]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121442,	
2017-06-26 14:41:41,102 Epoch[15] Batch [610]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121425,	
2017-06-26 14:41:46,468 Epoch[15] Batch [620]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.121350,	
2017-06-26 14:41:51,782 Epoch[15] Batch [630]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121303,	
2017-06-26 14:41:57,159 Epoch[15] Batch [640]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121202,	
2017-06-26 14:42:02,525 Epoch[15] Batch [650]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121062,	
2017-06-26 14:42:07,846 Epoch[15] Batch [660]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121250,	
2017-06-26 14:42:13,169 Epoch[15] Batch [670]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121280,	
2017-06-26 14:42:18,538 Epoch[15] Batch [680]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121368,	
2017-06-26 14:42:23,825 Epoch[15] Batch [690]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121289,	
2017-06-26 14:42:29,191 Epoch[15] Batch [700]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121212,	
2017-06-26 14:42:34,500 Epoch[15] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.121180,	
2017-06-26 14:42:39,825 Epoch[15] Batch [720]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121229,	
2017-06-26 14:42:45,183 Epoch[15] Batch [730]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121377,	
2017-06-26 14:42:50,587 Epoch[15] Batch [740]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.121245,	
2017-06-26 14:42:55,870 Epoch[15] Batch [750]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121183,	
2017-06-26 14:43:01,224 Epoch[15] Batch [760]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121333,	
2017-06-26 14:43:06,592 Epoch[15] Batch [770]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121467,	
2017-06-26 14:43:11,922 Epoch[15] Batch [780]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121603,	
2017-06-26 14:43:17,250 Epoch[15] Batch [790]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121535,	
2017-06-26 14:43:22,578 Epoch[15] Batch [800]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121391,	
2017-06-26 14:43:27,954 Epoch[15] Batch [810]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.121441,	
2017-06-26 14:43:33,240 Epoch[15] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.121436,	
2017-06-26 14:43:38,554 Epoch[15] Batch [830]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121567,	
2017-06-26 14:43:43,881 Epoch[15] Batch [840]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121586,	
2017-06-26 14:43:49,218 Epoch[15] Batch [850]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121940,	
2017-06-26 14:43:54,408 Epoch[15] Batch [860]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.122090,	
2017-06-26 14:43:59,680 Epoch[15] Batch [870]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.122139,	
2017-06-26 14:44:04,968 Epoch[15] Batch [880]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122217,	
2017-06-26 14:44:10,369 Epoch[15] Batch [890]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.122256,	
2017-06-26 14:44:15,655 Epoch[15] Batch [900]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122251,	
2017-06-26 14:44:20,996 Epoch[15] Batch [910]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.122142,	
2017-06-26 14:44:26,346 Epoch[15] Batch [920]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122185,	
2017-06-26 14:44:31,716 Epoch[15] Batch [930]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122360,	
2017-06-26 14:44:37,086 Epoch[15] Batch [940]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122450,	
2017-06-26 14:44:42,367 Epoch[15] Batch [950]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.122466,	
2017-06-26 14:44:47,735 Epoch[15] Batch [960]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122459,	
2017-06-26 14:44:53,087 Epoch[15] Batch [970]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.122459,	
2017-06-26 14:44:58,460 Epoch[15] Batch [980]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122435,	
2017-06-26 14:45:03,790 Epoch[15] Batch [990]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122349,	
2017-06-26 14:45:09,082 Epoch[15] Batch [1000]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.122446,	
2017-06-26 14:45:14,357 Epoch[15] Batch [1010]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122402,	
2017-06-26 14:45:19,709 Epoch[15] Batch [1020]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122434,	
2017-06-26 14:45:25,059 Epoch[15] Batch [1030]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122379,	
2017-06-26 14:45:30,390 Epoch[15] Batch [1040]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.122490,	
2017-06-26 14:45:35,759 Epoch[15] Batch [1050]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122420,	
2017-06-26 14:45:41,127 Epoch[15] Batch [1060]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122473,	
2017-06-26 14:45:46,444 Epoch[15] Batch [1070]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.122447,	
2017-06-26 14:45:51,773 Epoch[15] Batch [1080]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122502,	
2017-06-26 14:45:57,051 Epoch[15] Batch [1090]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.122399,	
2017-06-26 14:46:02,430 Epoch[15] Batch [1100]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.122473,	
2017-06-26 14:46:07,775 Epoch[15] Batch [1110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.122498,	
2017-06-26 14:46:13,135 Epoch[15] Batch [1120]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.122454,	
2017-06-26 14:46:18,493 Epoch[15] Batch [1130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.122425,	
2017-06-26 14:46:23,828 Epoch[15] Batch [1140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.122370,	
2017-06-26 14:46:29,207 Epoch[15] Batch [1150]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.122423,	
2017-06-26 14:46:34,509 Epoch[15] Batch [1160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.122293,	
2017-06-26 14:46:39,768 Epoch[15] Batch [1170]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.122518,	
2017-06-26 14:46:45,182 Epoch[15] Batch [1180]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.122521,	
2017-06-26 14:46:50,506 Epoch[15] Batch [1190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.122567,	
2017-06-26 14:46:55,873 Epoch[15] Batch [1200]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.122494,	
2017-06-26 14:47:01,131 Epoch[15] Batch [1210]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.122448,	
2017-06-26 14:47:06,533 Epoch[15] Batch [1220]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.122617,	
2017-06-26 14:47:11,888 Epoch[15] Batch [1230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.122648,	
2017-06-26 14:47:17,184 Epoch[15] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.122838,	
2017-06-26 14:47:22,555 Epoch[15] Batch [1250]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.123089,	
2017-06-26 14:47:27,862 Epoch[15] Batch [1260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.123211,	
2017-06-26 14:47:33,177 Epoch[15] Batch [1270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.123179,	
2017-06-26 14:47:38,258 Epoch[15] Batch [1280]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.123202,	
2017-06-26 14:47:43,655 Epoch[15] Batch [1290]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.123205,	
2017-06-26 14:47:48,963 Epoch[15] Batch [1300]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.123177,	
2017-06-26 14:47:54,223 Epoch[15] Batch [1310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123299,	
2017-06-26 14:47:59,611 Epoch[15] Batch [1320]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.123215,	
2017-06-26 14:48:04,898 Epoch[15] Batch [1330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.123169,	
2017-06-26 14:48:10,157 Epoch[15] Batch [1340]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.123198,	
2017-06-26 14:48:15,524 Epoch[15] Batch [1350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.123302,	
2017-06-26 14:48:20,956 Epoch[15] Batch [1360]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.123325,	
2017-06-26 14:48:26,195 Epoch[15] Batch [1370]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.123445,	
2017-06-26 14:48:31,615 Epoch[15] Batch [1380]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.123404,	
2017-06-26 14:48:36,681 Epoch[15] Batch [1390]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.123377,	
2017-06-26 14:48:41,995 Epoch[15] Batch [1400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.123415,	
2017-06-26 14:48:47,347 Epoch[15] Batch [1410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.123353,	
2017-06-26 14:48:52,749 Epoch[15] Batch [1420]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.123328,	
2017-06-26 14:48:58,032 Epoch[15] Batch [1430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.123599,	
2017-06-26 14:49:03,348 Epoch[15] Batch [1440]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.123711,	
2017-06-26 14:49:08,687 Epoch[15] Batch [1450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.123695,	
2017-06-26 14:49:13,985 Epoch[15] Batch [1460]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.123590,	
2017-06-26 14:49:19,307 Epoch[15] Batch [1470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.123543,	
2017-06-26 14:49:24,666 Epoch[15] Batch [1480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.123695,	
2017-06-26 14:49:27,833 Epoch[15] Train-FCNLogLoss=0.123712
2017-06-26 14:49:27,833 Epoch[15] Time cost=790.296
2017-06-26 14:49:28,652 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0016.params"
2017-06-26 14:49:30,353 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0016.states"
2017-06-26 14:49:36,141 Epoch[16] Batch [10]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.118629,	
2017-06-26 14:49:41,431 Epoch[16] Batch [20]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.116649,	
2017-06-26 14:49:46,753 Epoch[16] Batch [30]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.111986,	
2017-06-26 14:49:52,179 Epoch[16] Batch [40]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.116712,	
2017-06-26 14:49:57,366 Epoch[16] Batch [50]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.117016,	
2017-06-26 14:50:02,487 Epoch[16] Batch [60]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.114625,	
2017-06-26 14:50:07,559 Epoch[16] Batch [70]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.113938,	
2017-06-26 14:50:12,833 Epoch[16] Batch [80]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.114792,	
2017-06-26 14:50:18,227 Epoch[16] Batch [90]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.115185,	
2017-06-26 14:50:23,579 Epoch[16] Batch [100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.115345,	
2017-06-26 14:50:28,902 Epoch[16] Batch [110]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116375,	
2017-06-26 14:50:34,303 Epoch[16] Batch [120]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.116560,	
2017-06-26 14:50:39,576 Epoch[16] Batch [130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.116777,	
2017-06-26 14:50:44,895 Epoch[16] Batch [140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118225,	
2017-06-26 14:50:50,261 Epoch[16] Batch [150]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118470,	
2017-06-26 14:50:55,647 Epoch[16] Batch [160]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.118358,	
2017-06-26 14:51:00,975 Epoch[16] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117630,	
2017-06-26 14:51:06,330 Epoch[16] Batch [180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118209,	
2017-06-26 14:51:11,637 Epoch[16] Batch [190]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.118266,	
2017-06-26 14:51:16,951 Epoch[16] Batch [200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117839,	
2017-06-26 14:51:22,329 Epoch[16] Batch [210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.118034,	
2017-06-26 14:51:27,597 Epoch[16] Batch [220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118168,	
2017-06-26 14:51:32,873 Epoch[16] Batch [230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.118020,	
2017-06-26 14:51:38,119 Epoch[16] Batch [240]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.117707,	
2017-06-26 14:51:43,517 Epoch[16] Batch [250]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.118119,	
2017-06-26 14:51:48,846 Epoch[16] Batch [260]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117857,	
2017-06-26 14:51:54,203 Epoch[16] Batch [270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118324,	
2017-06-26 14:51:59,525 Epoch[16] Batch [280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118640,	
2017-06-26 14:52:04,815 Epoch[16] Batch [290]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118691,	
2017-06-26 14:52:10,183 Epoch[16] Batch [300]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118663,	
2017-06-26 14:52:15,468 Epoch[16] Batch [310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.118584,	
2017-06-26 14:52:20,813 Epoch[16] Batch [320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118918,	
2017-06-26 14:52:26,164 Epoch[16] Batch [330]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118930,	
2017-06-26 14:52:31,463 Epoch[16] Batch [340]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.119011,	
2017-06-26 14:52:36,819 Epoch[16] Batch [350]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118791,	
2017-06-26 14:52:42,136 Epoch[16] Batch [360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118898,	
2017-06-26 14:52:47,415 Epoch[16] Batch [370]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.118608,	
2017-06-26 14:52:52,776 Epoch[16] Batch [380]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118691,	
2017-06-26 14:52:58,143 Epoch[16] Batch [390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118643,	
2017-06-26 14:53:03,550 Epoch[16] Batch [400]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.118535,	
2017-06-26 14:53:08,545 Epoch[16] Batch [410]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.119142,	
2017-06-26 14:53:13,874 Epoch[16] Batch [420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119647,	
2017-06-26 14:53:19,209 Epoch[16] Batch [430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.121881,	
2017-06-26 14:53:24,582 Epoch[16] Batch [440]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.123288,	
2017-06-26 14:53:29,934 Epoch[16] Batch [450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.123988,	
2017-06-26 14:53:35,209 Epoch[16] Batch [460]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.124398,	
2017-06-26 14:53:40,558 Epoch[16] Batch [470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124589,	
2017-06-26 14:53:45,791 Epoch[16] Batch [480]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125125,	
2017-06-26 14:53:50,088 Epoch[16] Batch [490]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.125371,	
2017-06-26 14:53:55,085 Epoch[16] Batch [500]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.125308,	
2017-06-26 14:54:00,487 Epoch[16] Batch [510]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.125771,	
2017-06-26 14:54:05,798 Epoch[16] Batch [520]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125767,	
2017-06-26 14:54:11,186 Epoch[16] Batch [530]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125668,	
2017-06-26 14:54:15,788 Epoch[16] Batch [540]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.125586,	
2017-06-26 14:54:20,437 Epoch[16] Batch [550]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.125630,	
2017-06-26 14:54:25,478 Epoch[16] Batch [560]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.125533,	
2017-06-26 14:54:30,595 Epoch[16] Batch [570]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.125165,	
2017-06-26 14:54:35,375 Epoch[16] Batch [580]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.125206,	
2017-06-26 14:54:40,512 Epoch[16] Batch [590]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.125173,	
2017-06-26 14:54:45,737 Epoch[16] Batch [600]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.125090,	
2017-06-26 14:54:50,818 Epoch[16] Batch [610]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.125084,	
2017-06-26 14:54:56,125 Epoch[16] Batch [620]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.125066,	
2017-06-26 14:55:01,438 Epoch[16] Batch [630]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125277,	
2017-06-26 14:55:06,725 Epoch[16] Batch [640]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125391,	
2017-06-26 14:55:11,944 Epoch[16] Batch [650]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.125341,	
2017-06-26 14:55:16,817 Epoch[16] Batch [660]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.125249,	
2017-06-26 14:55:21,878 Epoch[16] Batch [670]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.125311,	
2017-06-26 14:55:27,179 Epoch[16] Batch [680]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.125129,	
2017-06-26 14:55:32,523 Epoch[16] Batch [690]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125116,	
2017-06-26 14:55:37,855 Epoch[16] Batch [700]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125271,	
2017-06-26 14:55:43,178 Epoch[16] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125205,	
2017-06-26 14:55:48,541 Epoch[16] Batch [720]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125191,	
2017-06-26 14:55:53,685 Epoch[16] Batch [730]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.125094,	
2017-06-26 14:55:59,001 Epoch[16] Batch [740]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.125154,	
2017-06-26 14:56:04,296 Epoch[16] Batch [750]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.125305,	
2017-06-26 14:56:09,637 Epoch[16] Batch [760]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.125080,	
2017-06-26 14:56:14,974 Epoch[16] Batch [770]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125121,	
2017-06-26 14:56:20,191 Epoch[16] Batch [780]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.125043,	
2017-06-26 14:56:25,361 Epoch[16] Batch [790]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.125097,	
2017-06-26 14:56:30,689 Epoch[16] Batch [800]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.125038,	
2017-06-26 14:56:35,817 Epoch[16] Batch [810]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.124910,	
2017-06-26 14:56:40,637 Epoch[16] Batch [820]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.125362,	
2017-06-26 14:56:45,973 Epoch[16] Batch [830]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125546,	
2017-06-26 14:56:51,295 Epoch[16] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125505,	
2017-06-26 14:56:56,678 Epoch[16] Batch [850]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.125547,	
2017-06-26 14:57:01,852 Epoch[16] Batch [860]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.125257,	
2017-06-26 14:57:07,198 Epoch[16] Batch [870]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.125285,	
2017-06-26 14:57:12,608 Epoch[16] Batch [880]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.125140,	
2017-06-26 14:57:17,843 Epoch[16] Batch [890]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.125120,	
2017-06-26 14:57:23,176 Epoch[16] Batch [900]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.125345,	
2017-06-26 14:57:28,565 Epoch[16] Batch [910]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.125456,	
2017-06-26 14:57:33,852 Epoch[16] Batch [920]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.125354,	
2017-06-26 14:57:39,172 Epoch[16] Batch [930]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.125293,	
2017-06-26 14:57:44,446 Epoch[16] Batch [940]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.125217,	
2017-06-26 14:57:49,805 Epoch[16] Batch [950]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.125165,	
2017-06-26 14:57:55,160 Epoch[16] Batch [960]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.125163,	
2017-06-26 14:58:00,555 Epoch[16] Batch [970]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.124963,	
2017-06-26 14:58:05,647 Epoch[16] Batch [980]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.124928,	
2017-06-26 14:58:10,981 Epoch[16] Batch [990]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124777,	
2017-06-26 14:58:16,271 Epoch[16] Batch [1000]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.124649,	
2017-06-26 14:58:21,487 Epoch[16] Batch [1010]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.124676,	
2017-06-26 14:58:26,727 Epoch[16] Batch [1020]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.124684,	
2017-06-26 14:58:32,149 Epoch[16] Batch [1030]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.124590,	
2017-06-26 14:58:37,419 Epoch[16] Batch [1040]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.124699,	
2017-06-26 14:58:42,717 Epoch[16] Batch [1050]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124638,	
2017-06-26 14:58:47,796 Epoch[16] Batch [1060]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.124750,	
2017-06-26 14:58:52,867 Epoch[16] Batch [1070]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.124726,	
2017-06-26 14:58:58,220 Epoch[16] Batch [1080]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124679,	
2017-06-26 14:59:03,526 Epoch[16] Batch [1090]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124585,	
2017-06-26 14:59:08,787 Epoch[16] Batch [1100]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.124607,	
2017-06-26 14:59:13,636 Epoch[16] Batch [1110]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.124652,	
2017-06-26 14:59:18,507 Epoch[16] Batch [1120]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.124479,	
2017-06-26 14:59:23,762 Epoch[16] Batch [1130]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.124572,	
2017-06-26 14:59:29,145 Epoch[16] Batch [1140]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.124575,	
2017-06-26 14:59:34,477 Epoch[16] Batch [1150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124535,	
2017-06-26 14:59:39,846 Epoch[16] Batch [1160]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.124571,	
2017-06-26 14:59:45,177 Epoch[16] Batch [1170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124538,	
2017-06-26 14:59:50,468 Epoch[16] Batch [1180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.124476,	
2017-06-26 14:59:55,796 Epoch[16] Batch [1190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124448,	
2017-06-26 15:00:01,143 Epoch[16] Batch [1200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124409,	
2017-06-26 15:00:06,523 Epoch[16] Batch [1210]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.124342,	
2017-06-26 15:00:11,866 Epoch[16] Batch [1220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124346,	
2017-06-26 15:00:17,174 Epoch[16] Batch [1230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124192,	
2017-06-26 15:00:22,469 Epoch[16] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124167,	
2017-06-26 15:00:27,784 Epoch[16] Batch [1250]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124165,	
2017-06-26 15:00:32,901 Epoch[16] Batch [1260]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.124246,	
2017-06-26 15:00:37,574 Epoch[16] Batch [1270]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.124286,	
2017-06-26 15:00:42,820 Epoch[16] Batch [1280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.124361,	
2017-06-26 15:00:48,169 Epoch[16] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124427,	
2017-06-26 15:00:53,509 Epoch[16] Batch [1300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124473,	
2017-06-26 15:00:58,848 Epoch[16] Batch [1310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124550,	
2017-06-26 15:01:04,205 Epoch[16] Batch [1320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124703,	
2017-06-26 15:01:09,516 Epoch[16] Batch [1330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124742,	
2017-06-26 15:01:14,863 Epoch[16] Batch [1340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124666,	
2017-06-26 15:01:20,160 Epoch[16] Batch [1350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.124618,	
2017-06-26 15:01:25,217 Epoch[16] Batch [1360]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.124562,	
2017-06-26 15:01:30,573 Epoch[16] Batch [1370]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124705,	
2017-06-26 15:01:35,896 Epoch[16] Batch [1380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124742,	
2017-06-26 15:01:41,222 Epoch[16] Batch [1390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124697,	
2017-06-26 15:01:46,568 Epoch[16] Batch [1400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.124670,	
2017-06-26 15:01:51,882 Epoch[16] Batch [1410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.124715,	
2017-06-26 15:01:57,235 Epoch[16] Batch [1420]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124841,	
2017-06-26 15:02:02,572 Epoch[16] Batch [1430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.124882,	
2017-06-26 15:02:07,910 Epoch[16] Batch [1440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124901,	
2017-06-26 15:02:12,992 Epoch[16] Batch [1450]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.124917,	
2017-06-26 15:02:18,321 Epoch[16] Batch [1460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.124877,	
2017-06-26 15:02:23,626 Epoch[16] Batch [1470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.124830,	
2017-06-26 15:02:28,969 Epoch[16] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.124783,	
2017-06-26 15:02:32,167 Epoch[16] Train-FCNLogLoss=0.124732
2017-06-26 15:02:32,167 Epoch[16] Time cost=781.814
2017-06-26 15:02:33,040 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0017.params"
2017-06-26 15:02:34,804 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0017.states"
2017-06-26 15:02:40,842 Epoch[17] Batch [10]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111659,	
2017-06-26 15:02:46,153 Epoch[17] Batch [20]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.106728,	
2017-06-26 15:02:51,524 Epoch[17] Batch [30]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.110042,	
2017-06-26 15:02:56,845 Epoch[17] Batch [40]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.115164,	
2017-06-26 15:03:02,181 Epoch[17] Batch [50]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116315,	
2017-06-26 15:03:07,519 Epoch[17] Batch [60]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.115265,	
2017-06-26 15:03:12,857 Epoch[17] Batch [70]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.115230,	
2017-06-26 15:03:17,996 Epoch[17] Batch [80]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.115972,	
2017-06-26 15:03:23,300 Epoch[17] Batch [90]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116203,	
2017-06-26 15:03:28,645 Epoch[17] Batch [100]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117569,	
2017-06-26 15:03:33,962 Epoch[17] Batch [110]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.117357,	
2017-06-26 15:03:39,307 Epoch[17] Batch [120]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.116804,	
2017-06-26 15:03:44,644 Epoch[17] Batch [130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117178,	
2017-06-26 15:03:49,982 Epoch[17] Batch [140]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.116774,	
2017-06-26 15:03:55,298 Epoch[17] Batch [150]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117586,	
2017-06-26 15:04:00,630 Epoch[17] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117982,	
2017-06-26 15:04:05,991 Epoch[17] Batch [170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118306,	
2017-06-26 15:04:11,396 Epoch[17] Batch [180]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.118357,	
2017-06-26 15:04:16,628 Epoch[17] Batch [190]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.118434,	
2017-06-26 15:04:21,988 Epoch[17] Batch [200]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118257,	
2017-06-26 15:04:27,338 Epoch[17] Batch [210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117816,	
2017-06-26 15:04:32,650 Epoch[17] Batch [220]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117976,	
2017-06-26 15:04:37,990 Epoch[17] Batch [230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117635,	
2017-06-26 15:04:43,337 Epoch[17] Batch [240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117848,	
2017-06-26 15:04:48,688 Epoch[17] Batch [250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118335,	
2017-06-26 15:04:54,024 Epoch[17] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118249,	
2017-06-26 15:04:59,353 Epoch[17] Batch [270]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.118009,	
2017-06-26 15:05:04,692 Epoch[17] Batch [280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118513,	
2017-06-26 15:05:09,960 Epoch[17] Batch [290]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118223,	
2017-06-26 15:05:15,096 Epoch[17] Batch [300]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.118092,	
2017-06-26 15:05:20,412 Epoch[17] Batch [310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.117833,	
2017-06-26 15:05:25,733 Epoch[17] Batch [320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118060,	
2017-06-26 15:05:31,095 Epoch[17] Batch [330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118125,	
2017-06-26 15:05:36,432 Epoch[17] Batch [340]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117932,	
2017-06-26 15:05:41,823 Epoch[17] Batch [350]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117752,	
2017-06-26 15:05:47,011 Epoch[17] Batch [360]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.118195,	
2017-06-26 15:05:52,086 Epoch[17] Batch [370]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.118207,	
2017-06-26 15:05:57,477 Epoch[17] Batch [380]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.118683,	
2017-06-26 15:06:02,809 Epoch[17] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118906,	
2017-06-26 15:06:08,163 Epoch[17] Batch [400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118785,	
2017-06-26 15:06:13,546 Epoch[17] Batch [410]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.118798,	
2017-06-26 15:06:18,818 Epoch[17] Batch [420]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.118922,	
2017-06-26 15:06:24,208 Epoch[17] Batch [430]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.118979,	
2017-06-26 15:06:29,552 Epoch[17] Batch [440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118728,	
2017-06-26 15:06:34,912 Epoch[17] Batch [450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118722,	
2017-06-26 15:06:40,216 Epoch[17] Batch [460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.118892,	
2017-06-26 15:06:45,552 Epoch[17] Batch [470]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119125,	
2017-06-26 15:06:50,936 Epoch[17] Batch [480]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.119110,	
2017-06-26 15:06:56,211 Epoch[17] Batch [490]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119170,	
2017-06-26 15:07:01,565 Epoch[17] Batch [500]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.119095,	
2017-06-26 15:07:06,903 Epoch[17] Batch [510]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118752,	
2017-06-26 15:07:12,227 Epoch[17] Batch [520]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.118796,	
2017-06-26 15:07:16,931 Epoch[17] Batch [530]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.118733,	
2017-06-26 15:07:21,756 Epoch[17] Batch [540]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.118563,	
2017-06-26 15:07:26,862 Epoch[17] Batch [550]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.118595,	
2017-06-26 15:07:32,094 Epoch[17] Batch [560]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.118663,	
2017-06-26 15:07:37,172 Epoch[17] Batch [570]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.118727,	
2017-06-26 15:07:42,486 Epoch[17] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118598,	
2017-06-26 15:07:47,541 Epoch[17] Batch [590]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.118607,	
2017-06-26 15:07:52,459 Epoch[17] Batch [600]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.118644,	
2017-06-26 15:07:57,763 Epoch[17] Batch [610]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.118304,	
2017-06-26 15:08:03,106 Epoch[17] Batch [620]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118658,	
2017-06-26 15:08:08,304 Epoch[17] Batch [630]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.118518,	
2017-06-26 15:08:13,665 Epoch[17] Batch [640]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118606,	
2017-06-26 15:08:18,957 Epoch[17] Batch [650]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118503,	
2017-06-26 15:08:24,269 Epoch[17] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118414,	
2017-06-26 15:08:29,182 Epoch[17] Batch [670]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.118411,	
2017-06-26 15:08:34,262 Epoch[17] Batch [680]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.118302,	
2017-06-26 15:08:39,090 Epoch[17] Batch [690]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.118019,	
2017-06-26 15:08:44,078 Epoch[17] Batch [700]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.117977,	
2017-06-26 15:08:49,029 Epoch[17] Batch [710]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.118238,	
2017-06-26 15:08:54,396 Epoch[17] Batch [720]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118257,	
2017-06-26 15:08:59,690 Epoch[17] Batch [730]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118024,	
2017-06-26 15:09:04,800 Epoch[17] Batch [740]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.118006,	
2017-06-26 15:09:10,042 Epoch[17] Batch [750]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.117906,	
2017-06-26 15:09:15,388 Epoch[17] Batch [760]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118045,	
2017-06-26 15:09:20,700 Epoch[17] Batch [770]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117935,	
2017-06-26 15:09:26,107 Epoch[17] Batch [780]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.117878,	
2017-06-26 15:09:31,237 Epoch[17] Batch [790]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.117842,	
2017-06-26 15:09:36,309 Epoch[17] Batch [800]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.117792,	
2017-06-26 15:09:41,435 Epoch[17] Batch [810]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.117744,	
2017-06-26 15:09:46,770 Epoch[17] Batch [820]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117611,	
2017-06-26 15:09:52,061 Epoch[17] Batch [830]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.117545,	
2017-06-26 15:09:57,397 Epoch[17] Batch [840]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117535,	
2017-06-26 15:10:02,733 Epoch[17] Batch [850]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117530,	
2017-06-26 15:10:08,119 Epoch[17] Batch [860]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.117536,	
2017-06-26 15:10:13,454 Epoch[17] Batch [870]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117511,	
2017-06-26 15:10:18,804 Epoch[17] Batch [880]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117505,	
2017-06-26 15:10:24,161 Epoch[17] Batch [890]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117406,	
2017-06-26 15:10:29,452 Epoch[17] Batch [900]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.117452,	
2017-06-26 15:10:34,788 Epoch[17] Batch [910]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117339,	
2017-06-26 15:10:40,146 Epoch[17] Batch [920]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117312,	
2017-06-26 15:10:45,479 Epoch[17] Batch [930]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117226,	
2017-06-26 15:10:50,779 Epoch[17] Batch [940]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.117243,	
2017-06-26 15:10:56,102 Epoch[17] Batch [950]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117235,	
2017-06-26 15:11:01,437 Epoch[17] Batch [960]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117119,	
2017-06-26 15:11:06,791 Epoch[17] Batch [970]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116990,	
2017-06-26 15:11:11,971 Epoch[17] Batch [980]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.117050,	
2017-06-26 15:11:17,031 Epoch[17] Batch [990]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.116924,	
2017-06-26 15:11:22,030 Epoch[17] Batch [1000]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.116928,	
2017-06-26 15:11:27,198 Epoch[17] Batch [1010]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.116836,	
2017-06-26 15:11:32,529 Epoch[17] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116804,	
2017-06-26 15:11:37,852 Epoch[17] Batch [1030]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116706,	
2017-06-26 15:11:43,219 Epoch[17] Batch [1040]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116731,	
2017-06-26 15:11:48,552 Epoch[17] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116755,	
2017-06-26 15:11:53,874 Epoch[17] Batch [1060]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.116819,	
2017-06-26 15:11:59,242 Epoch[17] Batch [1070]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116688,	
2017-06-26 15:12:04,589 Epoch[17] Batch [1080]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.116722,	
2017-06-26 15:12:09,949 Epoch[17] Batch [1090]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.116766,	
2017-06-26 15:12:15,304 Epoch[17] Batch [1100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116915,	
2017-06-26 15:12:20,633 Epoch[17] Batch [1110]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116837,	
2017-06-26 15:12:25,915 Epoch[17] Batch [1120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.116816,	
2017-06-26 15:12:31,253 Epoch[17] Batch [1130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.116765,	
2017-06-26 15:12:36,642 Epoch[17] Batch [1140]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.116760,	
2017-06-26 15:12:41,944 Epoch[17] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116706,	
2017-06-26 15:12:47,275 Epoch[17] Batch [1160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116592,	
2017-06-26 15:12:52,507 Epoch[17] Batch [1170]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.116723,	
2017-06-26 15:12:57,834 Epoch[17] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116760,	
2017-06-26 15:13:03,163 Epoch[17] Batch [1190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116914,	
2017-06-26 15:13:08,470 Epoch[17] Batch [1200]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116915,	
2017-06-26 15:13:13,804 Epoch[17] Batch [1210]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116963,	
2017-06-26 15:13:19,109 Epoch[17] Batch [1220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116907,	
2017-06-26 15:13:24,459 Epoch[17] Batch [1230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.116942,	
2017-06-26 15:13:29,775 Epoch[17] Batch [1240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.116975,	
2017-06-26 15:13:35,173 Epoch[17] Batch [1250]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.116895,	
2017-06-26 15:13:40,525 Epoch[17] Batch [1260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116940,	
2017-06-26 15:13:45,847 Epoch[17] Batch [1270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.116896,	
2017-06-26 15:13:51,183 Epoch[17] Batch [1280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116909,	
2017-06-26 15:13:56,561 Epoch[17] Batch [1290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.116901,	
2017-06-26 15:14:01,833 Epoch[17] Batch [1300]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.116954,	
2017-06-26 15:14:07,204 Epoch[17] Batch [1310]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116986,	
2017-06-26 15:14:12,590 Epoch[17] Batch [1320]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.117026,	
2017-06-26 15:14:17,900 Epoch[17] Batch [1330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117172,	
2017-06-26 15:14:23,229 Epoch[17] Batch [1340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117242,	
2017-06-26 15:14:28,558 Epoch[17] Batch [1350]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117282,	
2017-06-26 15:14:33,984 Epoch[17] Batch [1360]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.117198,	
2017-06-26 15:14:39,310 Epoch[17] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117170,	
2017-06-26 15:14:44,631 Epoch[17] Batch [1380]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.117131,	
2017-06-26 15:14:49,972 Epoch[17] Batch [1390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117165,	
2017-06-26 15:14:55,302 Epoch[17] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117174,	
2017-06-26 15:15:00,625 Epoch[17] Batch [1410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117185,	
2017-06-26 15:15:05,951 Epoch[17] Batch [1420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117197,	
2017-06-26 15:15:10,875 Epoch[17] Batch [1430]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.117146,	
2017-06-26 15:15:15,833 Epoch[17] Batch [1440]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.117199,	
2017-06-26 15:15:20,918 Epoch[17] Batch [1450]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.117283,	
2017-06-26 15:15:26,057 Epoch[17] Batch [1460]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.117382,	
2017-06-26 15:15:31,085 Epoch[17] Batch [1470]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.117569,	
2017-06-26 15:15:36,195 Epoch[17] Batch [1480]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.117686,	
2017-06-26 15:15:39,390 Epoch[17] Train-FCNLogLoss=0.117645
2017-06-26 15:15:39,390 Epoch[17] Time cost=784.585
2017-06-26 15:15:40,240 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0018.params"
2017-06-26 15:15:41,918 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0018.states"
2017-06-26 15:15:47,656 Epoch[18] Batch [10]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.145272,	
2017-06-26 15:15:52,704 Epoch[18] Batch [20]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.137887,	
2017-06-26 15:15:57,537 Epoch[18] Batch [30]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.131432,	
2017-06-26 15:16:02,674 Epoch[18] Batch [40]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.127955,	
2017-06-26 15:16:07,818 Epoch[18] Batch [50]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.126175,	
2017-06-26 15:16:13,061 Epoch[18] Batch [60]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.124068,	
2017-06-26 15:16:18,417 Epoch[18] Batch [70]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.124095,	
2017-06-26 15:16:23,738 Epoch[18] Batch [80]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.123160,	
2017-06-26 15:16:29,115 Epoch[18] Batch [90]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.122998,	
2017-06-26 15:16:34,375 Epoch[18] Batch [100]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.121612,	
2017-06-26 15:16:39,703 Epoch[18] Batch [110]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.121324,	
2017-06-26 15:16:45,060 Epoch[18] Batch [120]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121000,	
2017-06-26 15:16:50,415 Epoch[18] Batch [130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121556,	
2017-06-26 15:16:55,788 Epoch[18] Batch [140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.121633,	
2017-06-26 15:17:01,046 Epoch[18] Batch [150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.122128,	
2017-06-26 15:17:06,200 Epoch[18] Batch [160]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.121384,	
2017-06-26 15:17:11,491 Epoch[18] Batch [170]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.120338,	
2017-06-26 15:17:16,594 Epoch[18] Batch [180]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.119885,	
2017-06-26 15:17:21,869 Epoch[18] Batch [190]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.119452,	
2017-06-26 15:17:27,049 Epoch[18] Batch [200]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.118844,	
2017-06-26 15:17:32,343 Epoch[18] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118747,	
2017-06-26 15:17:37,668 Epoch[18] Batch [220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.118300,	
2017-06-26 15:17:43,020 Epoch[18] Batch [230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118434,	
2017-06-26 15:17:48,349 Epoch[18] Batch [240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.118917,	
2017-06-26 15:17:53,640 Epoch[18] Batch [250]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.119009,	
2017-06-26 15:17:58,437 Epoch[18] Batch [260]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.119389,	
2017-06-26 15:18:03,647 Epoch[18] Batch [270]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.120504,	
2017-06-26 15:18:08,930 Epoch[18] Batch [280]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.120744,	
2017-06-26 15:18:14,194 Epoch[18] Batch [290]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.120397,	
2017-06-26 15:18:19,326 Epoch[18] Batch [300]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.120204,	
2017-06-26 15:18:24,668 Epoch[18] Batch [310]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.120152,	
2017-06-26 15:18:30,011 Epoch[18] Batch [320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119966,	
2017-06-26 15:18:35,353 Epoch[18] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119801,	
2017-06-26 15:18:40,688 Epoch[18] Batch [340]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119428,	
2017-06-26 15:18:46,022 Epoch[18] Batch [350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.119276,	
2017-06-26 15:18:51,382 Epoch[18] Batch [360]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.119647,	
2017-06-26 15:18:56,757 Epoch[18] Batch [370]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119442,	
2017-06-26 15:19:02,130 Epoch[18] Batch [380]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119295,	
2017-06-26 15:19:07,455 Epoch[18] Batch [390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119567,	
2017-06-26 15:19:12,711 Epoch[18] Batch [400]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.119277,	
2017-06-26 15:19:18,063 Epoch[18] Batch [410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118902,	
2017-06-26 15:19:23,371 Epoch[18] Batch [420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.119147,	
2017-06-26 15:19:28,743 Epoch[18] Batch [430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119123,	
2017-06-26 15:19:34,084 Epoch[18] Batch [440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118708,	
2017-06-26 15:19:39,454 Epoch[18] Batch [450]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118571,	
2017-06-26 15:19:44,756 Epoch[18] Batch [460]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.118320,	
2017-06-26 15:19:50,106 Epoch[18] Batch [470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118409,	
2017-06-26 15:19:55,187 Epoch[18] Batch [480]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.118393,	
2017-06-26 15:20:00,483 Epoch[18] Batch [490]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.118219,	
2017-06-26 15:20:05,824 Epoch[18] Batch [500]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118437,	
2017-06-26 15:20:11,180 Epoch[18] Batch [510]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118235,	
2017-06-26 15:20:16,490 Epoch[18] Batch [520]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.118168,	
2017-06-26 15:20:21,806 Epoch[18] Batch [530]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118118,	
2017-06-26 15:20:27,201 Epoch[18] Batch [540]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.118065,	
2017-06-26 15:20:32,537 Epoch[18] Batch [550]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118037,	
2017-06-26 15:20:37,873 Epoch[18] Batch [560]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117908,	
2017-06-26 15:20:43,186 Epoch[18] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117901,	
2017-06-26 15:20:47,877 Epoch[18] Batch [580]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.117828,	
2017-06-26 15:20:52,750 Epoch[18] Batch [590]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.117853,	
2017-06-26 15:20:58,069 Epoch[18] Batch [600]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.117518,	
2017-06-26 15:21:03,120 Epoch[18] Batch [610]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.117636,	
2017-06-26 15:21:08,164 Epoch[18] Batch [620]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.117458,	
2017-06-26 15:21:13,039 Epoch[18] Batch [630]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.117416,	
2017-06-26 15:21:17,908 Epoch[18] Batch [640]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.117347,	
2017-06-26 15:21:23,059 Epoch[18] Batch [650]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.117445,	
2017-06-26 15:21:28,373 Epoch[18] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117300,	
2017-06-26 15:21:33,716 Epoch[18] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117415,	
2017-06-26 15:21:39,087 Epoch[18] Batch [680]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117453,	
2017-06-26 15:21:44,457 Epoch[18] Batch [690]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117400,	
2017-06-26 15:21:49,814 Epoch[18] Batch [700]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117446,	
2017-06-26 15:21:55,171 Epoch[18] Batch [710]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117573,	
2017-06-26 15:22:00,482 Epoch[18] Batch [720]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117481,	
2017-06-26 15:22:05,851 Epoch[18] Batch [730]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117551,	
2017-06-26 15:22:11,150 Epoch[18] Batch [740]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.117421,	
2017-06-26 15:22:16,526 Epoch[18] Batch [750]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117284,	
2017-06-26 15:22:21,895 Epoch[18] Batch [760]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117241,	
2017-06-26 15:22:27,187 Epoch[18] Batch [770]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.117319,	
2017-06-26 15:22:32,501 Epoch[18] Batch [780]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117700,	
2017-06-26 15:22:37,842 Epoch[18] Batch [790]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117548,	
2017-06-26 15:22:43,181 Epoch[18] Batch [800]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117542,	
2017-06-26 15:22:48,510 Epoch[18] Batch [810]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117269,	
2017-06-26 15:22:53,847 Epoch[18] Batch [820]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117270,	
2017-06-26 15:22:59,204 Epoch[18] Batch [830]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.117586,	
2017-06-26 15:23:04,514 Epoch[18] Batch [840]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.117986,	
2017-06-26 15:23:09,822 Epoch[18] Batch [850]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.118193,	
2017-06-26 15:23:15,180 Epoch[18] Batch [860]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118217,	
2017-06-26 15:23:20,524 Epoch[18] Batch [870]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118290,	
2017-06-26 15:23:25,860 Epoch[18] Batch [880]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118423,	
2017-06-26 15:23:31,257 Epoch[18] Batch [890]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.118620,	
2017-06-26 15:23:36,523 Epoch[18] Batch [900]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.118503,	
2017-06-26 15:23:41,885 Epoch[18] Batch [910]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118529,	
2017-06-26 15:23:47,220 Epoch[18] Batch [920]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118618,	
2017-06-26 15:23:52,572 Epoch[18] Batch [930]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118490,	
2017-06-26 15:23:57,911 Epoch[18] Batch [940]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118271,	
2017-06-26 15:24:03,292 Epoch[18] Batch [950]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.118192,	
2017-06-26 15:24:08,631 Epoch[18] Batch [960]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118526,	
2017-06-26 15:24:13,920 Epoch[18] Batch [970]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118490,	
2017-06-26 15:24:19,306 Epoch[18] Batch [980]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.118505,	
2017-06-26 15:24:24,617 Epoch[18] Batch [990]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119000,	
2017-06-26 15:24:30,010 Epoch[18] Batch [1000]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.119099,	
2017-06-26 15:24:35,281 Epoch[18] Batch [1010]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.119295,	
2017-06-26 15:24:40,641 Epoch[18] Batch [1020]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.119483,	
2017-06-26 15:24:46,017 Epoch[18] Batch [1030]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.119555,	
2017-06-26 15:24:51,333 Epoch[18] Batch [1040]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119685,	
2017-06-26 15:24:56,661 Epoch[18] Batch [1050]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119777,	
2017-06-26 15:25:01,970 Epoch[18] Batch [1060]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119629,	
2017-06-26 15:25:07,320 Epoch[18] Batch [1070]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119590,	
2017-06-26 15:25:12,687 Epoch[18] Batch [1080]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119644,	
2017-06-26 15:25:17,999 Epoch[18] Batch [1090]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.119571,	
2017-06-26 15:25:23,372 Epoch[18] Batch [1100]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.119512,	
2017-06-26 15:25:28,713 Epoch[18] Batch [1110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119497,	
2017-06-26 15:25:34,042 Epoch[18] Batch [1120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.119399,	
2017-06-26 15:25:39,382 Epoch[18] Batch [1130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.119439,	
2017-06-26 15:25:44,728 Epoch[18] Batch [1140]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.119417,	
2017-06-26 15:25:50,010 Epoch[18] Batch [1150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.119390,	
2017-06-26 15:25:55,451 Epoch[18] Batch [1160]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.119365,	
2017-06-26 15:26:00,677 Epoch[18] Batch [1170]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.119491,	
2017-06-26 15:26:06,031 Epoch[18] Batch [1180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.119721,	
2017-06-26 15:26:11,358 Epoch[18] Batch [1190]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.120155,	
2017-06-26 15:26:16,728 Epoch[18] Batch [1200]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.120578,	
2017-06-26 15:26:22,049 Epoch[18] Batch [1210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.120914,	
2017-06-26 15:26:27,402 Epoch[18] Batch [1220]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121146,	
2017-06-26 15:26:32,788 Epoch[18] Batch [1230]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.121167,	
2017-06-26 15:26:38,084 Epoch[18] Batch [1240]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121227,	
2017-06-26 15:26:43,426 Epoch[18] Batch [1250]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121148,	
2017-06-26 15:26:48,768 Epoch[18] Batch [1260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121177,	
2017-06-26 15:26:54,124 Epoch[18] Batch [1270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121255,	
2017-06-26 15:26:59,437 Epoch[18] Batch [1280]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121153,	
2017-06-26 15:27:04,787 Epoch[18] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121236,	
2017-06-26 15:27:10,088 Epoch[18] Batch [1300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.121236,	
2017-06-26 15:27:15,434 Epoch[18] Batch [1310]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.121197,	
2017-06-26 15:27:20,786 Epoch[18] Batch [1320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121077,	
2017-06-26 15:27:26,106 Epoch[18] Batch [1330]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.120991,	
2017-06-26 15:27:31,471 Epoch[18] Batch [1340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.121041,	
2017-06-26 15:27:36,830 Epoch[18] Batch [1350]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.120921,	
2017-06-26 15:27:42,156 Epoch[18] Batch [1360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.120958,	
2017-06-26 15:27:47,512 Epoch[18] Batch [1370]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121120,	
2017-06-26 15:27:52,788 Epoch[18] Batch [1380]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.121276,	
2017-06-26 15:27:58,146 Epoch[18] Batch [1390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121230,	
2017-06-26 15:28:03,488 Epoch[18] Batch [1400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121306,	
2017-06-26 15:28:08,849 Epoch[18] Batch [1410]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.121260,	
2017-06-26 15:28:14,158 Epoch[18] Batch [1420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.121295,	
2017-06-26 15:28:19,515 Epoch[18] Batch [1430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.121204,	
2017-06-26 15:28:24,838 Epoch[18] Batch [1440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.121265,	
2017-06-26 15:28:30,145 Epoch[18] Batch [1450]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.121282,	
2017-06-26 15:28:35,488 Epoch[18] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.121277,	
2017-06-26 15:28:40,571 Epoch[18] Batch [1470]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.121261,	
2017-06-26 15:28:45,886 Epoch[18] Batch [1480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.121275,	
2017-06-26 15:28:49,091 Epoch[18] Train-FCNLogLoss=0.121331
2017-06-26 15:28:49,092 Epoch[18] Time cost=787.173
2017-06-26 15:28:49,909 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0019.params"
2017-06-26 15:28:51,613 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0019.states"
2017-06-26 15:28:57,666 Epoch[19] Batch [10]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.125958,	
2017-06-26 15:29:02,933 Epoch[19] Batch [20]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.117982,	
2017-06-26 15:29:08,276 Epoch[19] Batch [30]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118375,	
2017-06-26 15:29:13,464 Epoch[19] Batch [40]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.119308,	
2017-06-26 15:29:18,760 Epoch[19] Batch [50]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.117162,	
2017-06-26 15:29:24,119 Epoch[19] Batch [60]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.116888,	
2017-06-26 15:29:29,164 Epoch[19] Batch [70]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.116915,	
2017-06-26 15:29:34,471 Epoch[19] Batch [80]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.117674,	
2017-06-26 15:29:39,812 Epoch[19] Batch [90]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117217,	
2017-06-26 15:29:44,900 Epoch[19] Batch [100]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.119522,	
2017-06-26 15:29:50,263 Epoch[19] Batch [110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.119149,	
2017-06-26 15:29:55,526 Epoch[19] Batch [120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.118285,	
2017-06-26 15:30:00,914 Epoch[19] Batch [130]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.117543,	
2017-06-26 15:30:06,241 Epoch[19] Batch [140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117391,	
2017-06-26 15:30:11,171 Epoch[19] Batch [150]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.116729,	
2017-06-26 15:30:16,164 Epoch[19] Batch [160]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.117481,	
2017-06-26 15:30:21,215 Epoch[19] Batch [170]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.117608,	
2017-06-26 15:30:26,553 Epoch[19] Batch [180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.116987,	
2017-06-26 15:30:31,780 Epoch[19] Batch [190]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.116938,	
2017-06-26 15:30:36,772 Epoch[19] Batch [200]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.117239,	
2017-06-26 15:30:41,621 Epoch[19] Batch [210]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.116875,	
2017-06-26 15:30:46,889 Epoch[19] Batch [220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.116769,	
2017-06-26 15:30:52,024 Epoch[19] Batch [230]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.116929,	
2017-06-26 15:30:57,085 Epoch[19] Batch [240]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.116577,	
2017-06-26 15:31:02,351 Epoch[19] Batch [250]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.116214,	
2017-06-26 15:31:07,647 Epoch[19] Batch [260]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116719,	
2017-06-26 15:31:12,970 Epoch[19] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.116560,	
2017-06-26 15:31:18,288 Epoch[19] Batch [280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.116083,	
2017-06-26 15:31:23,630 Epoch[19] Batch [290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.115640,	
2017-06-26 15:31:28,974 Epoch[19] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.115635,	
2017-06-26 15:31:34,284 Epoch[19] Batch [310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.116272,	
2017-06-26 15:31:39,639 Epoch[19] Batch [320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116785,	
2017-06-26 15:31:44,965 Epoch[19] Batch [330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116674,	
2017-06-26 15:31:50,366 Epoch[19] Batch [340]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.117407,	
2017-06-26 15:31:55,629 Epoch[19] Batch [350]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.117230,	
2017-06-26 15:32:00,961 Epoch[19] Batch [360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.117332,	
2017-06-26 15:32:06,289 Epoch[19] Batch [370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.117496,	
2017-06-26 15:32:11,654 Epoch[19] Batch [380]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117652,	
2017-06-26 15:32:17,024 Epoch[19] Batch [390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118087,	
2017-06-26 15:32:22,373 Epoch[19] Batch [400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118437,	
2017-06-26 15:32:27,723 Epoch[19] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.118131,	
2017-06-26 15:32:33,119 Epoch[19] Batch [420]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.118351,	
2017-06-26 15:32:38,437 Epoch[19] Batch [430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118368,	
2017-06-26 15:32:43,811 Epoch[19] Batch [440]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.118256,	
2017-06-26 15:32:49,101 Epoch[19] Batch [450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118459,	
2017-06-26 15:32:54,472 Epoch[19] Batch [460]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118444,	
2017-06-26 15:32:59,825 Epoch[19] Batch [470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118390,	
2017-06-26 15:33:05,116 Epoch[19] Batch [480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.118117,	
2017-06-26 15:33:10,470 Epoch[19] Batch [490]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118260,	
2017-06-26 15:33:15,837 Epoch[19] Batch [500]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118158,	
2017-06-26 15:33:21,246 Epoch[19] Batch [510]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.117912,	
2017-06-26 15:33:26,554 Epoch[19] Batch [520]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.117882,	
2017-06-26 15:33:31,876 Epoch[19] Batch [530]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118140,	
2017-06-26 15:33:37,253 Epoch[19] Batch [540]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.118116,	
2017-06-26 15:33:42,549 Epoch[19] Batch [550]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.118237,	
2017-06-26 15:33:47,902 Epoch[19] Batch [560]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.118439,	
2017-06-26 15:33:53,279 Epoch[19] Batch [570]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.118529,	
2017-06-26 15:33:58,716 Epoch[19] Batch [580]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.118541,	
2017-06-26 15:34:03,813 Epoch[19] Batch [590]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.118970,	
2017-06-26 15:34:09,099 Epoch[19] Batch [600]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.119130,	
2017-06-26 15:34:13,647 Epoch[19] Batch [610]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.118948,	
2017-06-26 15:34:18,423 Epoch[19] Batch [620]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.118844,	
2017-06-26 15:34:23,723 Epoch[19] Batch [630]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.118848,	
2017-06-26 15:34:29,054 Epoch[19] Batch [640]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.118955,	
2017-06-26 15:34:34,417 Epoch[19] Batch [650]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118733,	
2017-06-26 15:34:39,740 Epoch[19] Batch [660]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.118594,	
2017-06-26 15:34:45,080 Epoch[19] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118460,	
2017-06-26 15:34:50,403 Epoch[19] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.118609,	
2017-06-26 15:34:55,773 Epoch[19] Batch [690]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.118586,	
2017-06-26 15:35:01,157 Epoch[19] Batch [700]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.118549,	
2017-06-26 15:35:06,460 Epoch[19] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.118461,	
2017-06-26 15:35:11,848 Epoch[19] Batch [720]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.118398,	
2017-06-26 15:35:17,242 Epoch[19] Batch [730]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.118427,	
2017-06-26 15:35:22,581 Epoch[19] Batch [740]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.118325,	
2017-06-26 15:35:27,942 Epoch[19] Batch [750]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118093,	
2017-06-26 15:35:33,306 Epoch[19] Batch [760]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.118040,	
2017-06-26 15:35:38,684 Epoch[19] Batch [770]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.118095,	
2017-06-26 15:35:43,793 Epoch[19] Batch [780]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.118019,	
2017-06-26 15:35:49,711 Epoch[19] Batch [790]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.117865,	
2017-06-26 15:35:55,285 Epoch[19] Batch [800]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.117870,	
2017-06-26 15:36:00,278 Epoch[19] Batch [810]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.117724,	
2017-06-26 15:36:05,330 Epoch[19] Batch [820]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.117713,	
2017-06-26 15:36:10,364 Epoch[19] Batch [830]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.117719,	
2017-06-26 15:36:15,269 Epoch[19] Batch [840]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.117755,	
2017-06-26 15:36:20,080 Epoch[19] Batch [850]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.117643,	
2017-06-26 15:36:25,157 Epoch[19] Batch [860]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.117634,	
2017-06-26 15:36:29,957 Epoch[19] Batch [870]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.117695,	
2017-06-26 15:36:34,983 Epoch[19] Batch [880]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.117600,	
2017-06-26 15:36:40,170 Epoch[19] Batch [890]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.117738,	
2017-06-26 15:36:45,375 Epoch[19] Batch [900]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.117655,	
2017-06-26 15:36:50,559 Epoch[19] Batch [910]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.117768,	
2017-06-26 15:36:55,682 Epoch[19] Batch [920]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.117558,	
2017-06-26 15:37:00,939 Epoch[19] Batch [930]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.117412,	
2017-06-26 15:37:06,315 Epoch[19] Batch [940]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.117224,	
2017-06-26 15:37:11,681 Epoch[19] Batch [950]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117073,	
2017-06-26 15:37:16,981 Epoch[19] Batch [960]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116955,	
2017-06-26 15:37:23,298 Epoch[19] Batch [970]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.117023,	
2017-06-26 15:37:29,425 Epoch[19] Batch [980]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.116981,	
2017-06-26 15:37:34,257 Epoch[19] Batch [990]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.117090,	
2017-06-26 15:37:39,332 Epoch[19] Batch [1000]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.117003,	
2017-06-26 15:37:44,616 Epoch[19] Batch [1010]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.116971,	
2017-06-26 15:37:49,967 Epoch[19] Batch [1020]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.116995,	
2017-06-26 15:37:55,307 Epoch[19] Batch [1030]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.117120,	
2017-06-26 15:38:00,653 Epoch[19] Batch [1040]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.117041,	
2017-06-26 15:38:05,959 Epoch[19] Batch [1050]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116969,	
2017-06-26 15:38:11,330 Epoch[19] Batch [1060]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116905,	
2017-06-26 15:38:16,678 Epoch[19] Batch [1070]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.116830,	
2017-06-26 15:38:22,010 Epoch[19] Batch [1080]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116853,	
2017-06-26 15:38:27,411 Epoch[19] Batch [1090]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.116813,	
2017-06-26 15:38:32,778 Epoch[19] Batch [1100]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116623,	
2017-06-26 15:38:38,149 Epoch[19] Batch [1110]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116587,	
2017-06-26 15:38:43,436 Epoch[19] Batch [1120]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.116679,	
2017-06-26 15:38:48,744 Epoch[19] Batch [1130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.116769,	
2017-06-26 15:38:53,641 Epoch[19] Batch [1140]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.116731,	
2017-06-26 15:38:58,649 Epoch[19] Batch [1150]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.116684,	
2017-06-26 15:39:03,774 Epoch[19] Batch [1160]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.116623,	
2017-06-26 15:39:09,142 Epoch[19] Batch [1170]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116593,	
2017-06-26 15:39:14,468 Epoch[19] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116504,	
2017-06-26 15:39:19,783 Epoch[19] Batch [1190]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.116363,	
2017-06-26 15:39:25,117 Epoch[19] Batch [1200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116306,	
2017-06-26 15:39:30,532 Epoch[19] Batch [1210]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.116354,	
2017-06-26 15:39:35,832 Epoch[19] Batch [1220]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116311,	
2017-06-26 15:39:41,144 Epoch[19] Batch [1230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.116262,	
2017-06-26 15:39:46,495 Epoch[19] Batch [1240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.116104,	
2017-06-26 15:39:51,807 Epoch[19] Batch [1250]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.116174,	
2017-06-26 15:39:57,100 Epoch[19] Batch [1260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.116129,	
2017-06-26 15:40:02,444 Epoch[19] Batch [1270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.116076,	
2017-06-26 15:40:07,529 Epoch[19] Batch [1280]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.116078,	
2017-06-26 15:40:12,320 Epoch[19] Batch [1290]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.116080,	
2017-06-26 15:40:17,085 Epoch[19] Batch [1300]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.116056,	
2017-06-26 15:40:21,460 Epoch[19] Batch [1310]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.116057,	
2017-06-26 15:40:26,019 Epoch[19] Batch [1320]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.115976,	
2017-06-26 15:40:31,184 Epoch[19] Batch [1330]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.115995,	
2017-06-26 15:40:36,469 Epoch[19] Batch [1340]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.115962,	
2017-06-26 15:40:41,740 Epoch[19] Batch [1350]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.115998,	
2017-06-26 15:40:47,078 Epoch[19] Batch [1360]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.116061,	
2017-06-26 15:40:52,438 Epoch[19] Batch [1370]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.116145,	
2017-06-26 15:40:57,775 Epoch[19] Batch [1380]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116174,	
2017-06-26 15:41:03,100 Epoch[19] Batch [1390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116205,	
2017-06-26 15:41:08,430 Epoch[19] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116182,	
2017-06-26 15:41:13,845 Epoch[19] Batch [1410]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.116133,	
2017-06-26 15:41:19,183 Epoch[19] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.116174,	
2017-06-26 15:41:24,512 Epoch[19] Batch [1430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.116145,	
2017-06-26 15:41:29,848 Epoch[19] Batch [1440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116148,	
2017-06-26 15:41:35,187 Epoch[19] Batch [1450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.116209,	
2017-06-26 15:41:40,557 Epoch[19] Batch [1460]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116277,	
2017-06-26 15:41:45,909 Epoch[19] Batch [1470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.116294,	
2017-06-26 15:41:51,206 Epoch[19] Batch [1480]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.116317,	
2017-06-26 15:41:54,371 Epoch[19] Train-FCNLogLoss=0.116337
2017-06-26 15:41:54,371 Epoch[19] Time cost=782.757
2017-06-26 15:41:55,200 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0020.params"
2017-06-26 15:41:56,802 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0020.states"
2017-06-26 15:42:02,708 Epoch[20] Batch [10]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.122267,	
2017-06-26 15:42:08,104 Epoch[20] Batch [20]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.115547,	
2017-06-26 15:42:13,456 Epoch[20] Batch [30]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.115627,	
2017-06-26 15:42:18,736 Epoch[20] Batch [40]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.114848,	
2017-06-26 15:42:24,135 Epoch[20] Batch [50]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.113636,	
2017-06-26 15:42:29,418 Epoch[20] Batch [60]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.111846,	
2017-06-26 15:42:34,738 Epoch[20] Batch [70]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.112761,	
2017-06-26 15:42:40,093 Epoch[20] Batch [80]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.114299,	
2017-06-26 15:42:45,408 Epoch[20] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.114667,	
2017-06-26 15:42:50,767 Epoch[20] Batch [100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.115623,	
2017-06-26 15:42:56,101 Epoch[20] Batch [110]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.115227,	
2017-06-26 15:43:01,498 Epoch[20] Batch [120]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.114853,	
2017-06-26 15:43:06,515 Epoch[20] Batch [130]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.113068,	
2017-06-26 15:43:11,797 Epoch[20] Batch [140]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.112514,	
2017-06-26 15:43:16,709 Epoch[20] Batch [150]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.112353,	
2017-06-26 15:43:20,947 Epoch[20] Batch [160]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.112858,	
2017-06-26 15:43:26,106 Epoch[20] Batch [170]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.112996,	
2017-06-26 15:43:31,213 Epoch[20] Batch [180]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.112604,	
2017-06-26 15:43:36,186 Epoch[20] Batch [190]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.111930,	
2017-06-26 15:43:41,488 Epoch[20] Batch [200]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.113005,	
2017-06-26 15:43:46,790 Epoch[20] Batch [210]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113587,	
2017-06-26 15:43:52,073 Epoch[20] Batch [220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.113200,	
2017-06-26 15:43:57,416 Epoch[20] Batch [230]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.112526,	
2017-06-26 15:44:02,756 Epoch[20] Batch [240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.112566,	
2017-06-26 15:44:08,096 Epoch[20] Batch [250]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113211,	
2017-06-26 15:44:13,442 Epoch[20] Batch [260]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.113679,	
2017-06-26 15:44:18,781 Epoch[20] Batch [270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.114050,	
2017-06-26 15:44:23,686 Epoch[20] Batch [280]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.114426,	
2017-06-26 15:44:28,981 Epoch[20] Batch [290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.114581,	
2017-06-26 15:44:34,326 Epoch[20] Batch [300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.114513,	
2017-06-26 15:44:39,613 Epoch[20] Batch [310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.114295,	
2017-06-26 15:44:44,930 Epoch[20] Batch [320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114276,	
2017-06-26 15:44:50,288 Epoch[20] Batch [330]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113985,	
2017-06-26 15:44:55,730 Epoch[20] Batch [340]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.114466,	
2017-06-26 15:45:00,953 Epoch[20] Batch [350]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.114543,	
2017-06-26 15:45:06,291 Epoch[20] Batch [360]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.114275,	
2017-06-26 15:45:11,639 Epoch[20] Batch [370]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.114113,	
2017-06-26 15:45:16,981 Epoch[20] Batch [380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113811,	
2017-06-26 15:45:22,345 Epoch[20] Batch [390]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113929,	
2017-06-26 15:45:27,666 Epoch[20] Batch [400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.113840,	
2017-06-26 15:45:33,017 Epoch[20] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.113879,	
2017-06-26 15:45:38,371 Epoch[20] Batch [420]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.114066,	
2017-06-26 15:45:43,739 Epoch[20] Batch [430]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114065,	
2017-06-26 15:45:49,057 Epoch[20] Batch [440]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.113909,	
2017-06-26 15:45:54,350 Epoch[20] Batch [450]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.113921,	
2017-06-26 15:45:59,733 Epoch[20] Batch [460]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.114068,	
2017-06-26 15:46:05,162 Epoch[20] Batch [470]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.114086,	
2017-06-26 15:46:10,372 Epoch[20] Batch [480]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.114120,	
2017-06-26 15:46:15,691 Epoch[20] Batch [490]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114123,	
2017-06-26 15:46:21,008 Epoch[20] Batch [500]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114071,	
2017-06-26 15:46:26,381 Epoch[20] Batch [510]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.113848,	
2017-06-26 15:46:31,649 Epoch[20] Batch [520]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113872,	
2017-06-26 15:46:36,979 Epoch[20] Batch [530]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113599,	
2017-06-26 15:46:42,421 Epoch[20] Batch [540]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.113702,	
2017-06-26 15:46:47,669 Epoch[20] Batch [550]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.113967,	
2017-06-26 15:46:53,018 Epoch[20] Batch [560]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.113959,	
2017-06-26 15:46:58,376 Epoch[20] Batch [570]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113966,	
2017-06-26 15:47:03,712 Epoch[20] Batch [580]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.114002,	
2017-06-26 15:47:09,056 Epoch[20] Batch [590]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.113855,	
2017-06-26 15:47:14,405 Epoch[20] Batch [600]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.114022,	
2017-06-26 15:47:19,489 Epoch[20] Batch [610]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.114084,	
2017-06-26 15:47:24,803 Epoch[20] Batch [620]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113909,	
2017-06-26 15:47:30,235 Epoch[20] Batch [630]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.113865,	
2017-06-26 15:47:35,543 Epoch[20] Batch [640]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113725,	
2017-06-26 15:47:40,905 Epoch[20] Batch [650]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113801,	
2017-06-26 15:47:46,198 Epoch[20] Batch [660]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.113655,	
2017-06-26 15:47:50,704 Epoch[20] Batch [670]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.113516,	
2017-06-26 15:47:55,129 Epoch[20] Batch [680]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.113482,	
2017-06-26 15:48:00,338 Epoch[20] Batch [690]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.113605,	
2017-06-26 15:48:05,747 Epoch[20] Batch [700]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.113377,	
2017-06-26 15:48:10,582 Epoch[20] Batch [710]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.113385,	
2017-06-26 15:48:15,909 Epoch[20] Batch [720]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113296,	
2017-06-26 15:48:21,250 Epoch[20] Batch [730]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113483,	
2017-06-26 15:48:26,579 Epoch[20] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113615,	
2017-06-26 15:48:31,953 Epoch[20] Batch [750]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.113620,	
2017-06-26 15:48:37,270 Epoch[20] Batch [760]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.113725,	
2017-06-26 15:48:42,612 Epoch[20] Batch [770]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113670,	
2017-06-26 15:48:47,983 Epoch[20] Batch [780]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.114005,	
2017-06-26 15:48:53,305 Epoch[20] Batch [790]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.114126,	
2017-06-26 15:48:58,614 Epoch[20] Batch [800]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.114179,	
2017-06-26 15:49:03,923 Epoch[20] Batch [810]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113983,	
2017-06-26 15:49:08,977 Epoch[20] Batch [820]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.114083,	
2017-06-26 15:49:14,059 Epoch[20] Batch [830]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.113960,	
2017-06-26 15:49:19,002 Epoch[20] Batch [840]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.113837,	
2017-06-26 15:49:23,794 Epoch[20] Batch [850]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.113612,	
2017-06-26 15:49:28,611 Epoch[20] Batch [860]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.113635,	
2017-06-26 15:49:33,378 Epoch[20] Batch [870]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.113816,	
2017-06-26 15:49:38,202 Epoch[20] Batch [880]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.113779,	
2017-06-26 15:49:42,868 Epoch[20] Batch [890]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.113851,	
2017-06-26 15:49:47,888 Epoch[20] Batch [900]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.113780,	
2017-06-26 15:49:53,289 Epoch[20] Batch [910]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.113711,	
2017-06-26 15:49:58,616 Epoch[20] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113597,	
2017-06-26 15:50:03,941 Epoch[20] Batch [930]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113454,	
2017-06-26 15:50:09,275 Epoch[20] Batch [940]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113321,	
2017-06-26 15:50:14,664 Epoch[20] Batch [950]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.113208,	
2017-06-26 15:50:20,015 Epoch[20] Batch [960]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.113198,	
2017-06-26 15:50:25,346 Epoch[20] Batch [970]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113108,	
2017-06-26 15:50:30,704 Epoch[20] Batch [980]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113146,	
2017-06-26 15:50:36,036 Epoch[20] Batch [990]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113171,	
2017-06-26 15:50:41,339 Epoch[20] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113312,	
2017-06-26 15:50:46,693 Epoch[20] Batch [1010]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113319,	
2017-06-26 15:50:52,032 Epoch[20] Batch [1020]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113399,	
2017-06-26 15:50:57,416 Epoch[20] Batch [1030]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.113537,	
2017-06-26 15:51:02,705 Epoch[20] Batch [1040]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.113624,	
2017-06-26 15:51:08,085 Epoch[20] Batch [1050]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.113463,	
2017-06-26 15:51:13,382 Epoch[20] Batch [1060]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.113467,	
2017-06-26 15:51:18,734 Epoch[20] Batch [1070]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113460,	
2017-06-26 15:51:24,019 Epoch[20] Batch [1080]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.113275,	
2017-06-26 15:51:29,351 Epoch[20] Batch [1090]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113320,	
2017-06-26 15:51:34,664 Epoch[20] Batch [1100]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113301,	
2017-06-26 15:51:40,020 Epoch[20] Batch [1110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113295,	
2017-06-26 15:51:45,332 Epoch[20] Batch [1120]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113318,	
2017-06-26 15:51:50,678 Epoch[20] Batch [1130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.113175,	
2017-06-26 15:51:56,036 Epoch[20] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113143,	
2017-06-26 15:52:01,364 Epoch[20] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113198,	
2017-06-26 15:52:06,401 Epoch[20] Batch [1160]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.113283,	
2017-06-26 15:52:11,285 Epoch[20] Batch [1170]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.113285,	
2017-06-26 15:52:16,089 Epoch[20] Batch [1180]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.113379,	
2017-06-26 15:52:21,347 Epoch[20] Batch [1190]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.113395,	
2017-06-26 15:52:26,635 Epoch[20] Batch [1200]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.113476,	
2017-06-26 15:52:32,143 Epoch[20] Batch [1210]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.113460,	
2017-06-26 15:52:37,415 Epoch[20] Batch [1220]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113469,	
2017-06-26 15:52:42,729 Epoch[20] Batch [1230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113528,	
2017-06-26 15:52:48,106 Epoch[20] Batch [1240]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.113451,	
2017-06-26 15:52:53,378 Epoch[20] Batch [1250]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.113375,	
2017-06-26 15:52:58,788 Epoch[20] Batch [1260]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.113353,	
2017-06-26 15:53:04,088 Epoch[20] Batch [1270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.113541,	
2017-06-26 15:53:09,448 Epoch[20] Batch [1280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113525,	
2017-06-26 15:53:14,764 Epoch[20] Batch [1290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.113545,	
2017-06-26 15:53:20,116 Epoch[20] Batch [1300]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113541,	
2017-06-26 15:53:25,394 Epoch[20] Batch [1310]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.113469,	
2017-06-26 15:53:30,788 Epoch[20] Batch [1320]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.113418,	
2017-06-26 15:53:36,112 Epoch[20] Batch [1330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113435,	
2017-06-26 15:53:41,433 Epoch[20] Batch [1340]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.113523,	
2017-06-26 15:53:46,745 Epoch[20] Batch [1350]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.113573,	
2017-06-26 15:53:52,071 Epoch[20] Batch [1360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113489,	
2017-06-26 15:53:57,400 Epoch[20] Batch [1370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113520,	
2017-06-26 15:54:02,765 Epoch[20] Batch [1380]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113500,	
2017-06-26 15:54:08,090 Epoch[20] Batch [1390]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113499,	
2017-06-26 15:54:13,467 Epoch[20] Batch [1400]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.113473,	
2017-06-26 15:54:18,774 Epoch[20] Batch [1410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.113374,	
2017-06-26 15:54:24,109 Epoch[20] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113270,	
2017-06-26 15:54:29,464 Epoch[20] Batch [1430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.113314,	
2017-06-26 15:54:34,795 Epoch[20] Batch [1440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113236,	
2017-06-26 15:54:40,158 Epoch[20] Batch [1450]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.113350,	
2017-06-26 15:54:45,509 Epoch[20] Batch [1460]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.113354,	
2017-06-26 15:54:50,847 Epoch[20] Batch [1470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113444,	
2017-06-26 15:54:56,185 Epoch[20] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113367,	
2017-06-26 15:54:59,372 Epoch[20] Train-FCNLogLoss=0.113362
2017-06-26 15:54:59,372 Epoch[20] Time cost=782.570
2017-06-26 15:55:00,178 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0021.params"
2017-06-26 15:55:01,941 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0021.states"
2017-06-26 15:55:08,098 Epoch[21] Batch [10]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.103505,	
2017-06-26 15:55:13,418 Epoch[21] Batch [20]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.109648,	
2017-06-26 15:55:18,797 Epoch[21] Batch [30]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.113384,	
2017-06-26 15:55:24,148 Epoch[21] Batch [40]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.112631,	
2017-06-26 15:55:29,461 Epoch[21] Batch [50]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.114558,	
2017-06-26 15:55:34,798 Epoch[21] Batch [60]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113453,	
2017-06-26 15:55:40,125 Epoch[21] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.114798,	
2017-06-26 15:55:45,484 Epoch[21] Batch [80]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.117177,	
2017-06-26 15:55:50,843 Epoch[21] Batch [90]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.115676,	
2017-06-26 15:55:56,296 Epoch[21] Batch [100]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.116487,	
2017-06-26 15:56:01,608 Epoch[21] Batch [110]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.115660,	
2017-06-26 15:56:06,944 Epoch[21] Batch [120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.116848,	
2017-06-26 15:56:12,317 Epoch[21] Batch [130]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.116485,	
2017-06-26 15:56:18,028 Epoch[21] Batch [140]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.118080,	
2017-06-26 15:56:24,069 Epoch[21] Batch [150]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.118866,	
2017-06-26 15:56:30,083 Epoch[21] Batch [160]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.118088,	
2017-06-26 15:56:36,082 Epoch[21] Batch [170]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.117647,	
2017-06-26 15:56:42,004 Epoch[21] Batch [180]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.117096,	
2017-06-26 15:56:48,035 Epoch[21] Batch [190]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.117261,	
2017-06-26 15:56:54,029 Epoch[21] Batch [200]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.117361,	
2017-06-26 15:56:59,972 Epoch[21] Batch [210]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.117647,	
2017-06-26 15:57:05,995 Epoch[21] Batch [220]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.117371,	
2017-06-26 15:57:11,953 Epoch[21] Batch [230]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.117611,	
2017-06-26 15:57:17,987 Epoch[21] Batch [240]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.117676,	
2017-06-26 15:57:23,944 Epoch[21] Batch [250]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.117788,	
2017-06-26 15:57:29,918 Epoch[21] Batch [260]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.117844,	
2017-06-26 15:57:35,910 Epoch[21] Batch [270]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.117961,	
2017-06-26 15:57:41,873 Epoch[21] Batch [280]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.117810,	
2017-06-26 15:57:47,821 Epoch[21] Batch [290]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.117724,	
2017-06-26 15:57:53,798 Epoch[21] Batch [300]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.117523,	
2017-06-26 15:57:59,815 Epoch[21] Batch [310]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.117059,	
2017-06-26 15:58:05,734 Epoch[21] Batch [320]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.116682,	
2017-06-26 15:58:11,720 Epoch[21] Batch [330]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.116346,	
2017-06-26 15:58:17,702 Epoch[21] Batch [340]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.116293,	
2017-06-26 15:58:23,730 Epoch[21] Batch [350]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.115776,	
2017-06-26 15:58:29,739 Epoch[21] Batch [360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.115567,	
2017-06-26 15:58:35,838 Epoch[21] Batch [370]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.114940,	
2017-06-26 15:58:41,853 Epoch[21] Batch [380]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.114876,	
2017-06-26 15:58:47,868 Epoch[21] Batch [390]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.114903,	
2017-06-26 15:58:53,808 Epoch[21] Batch [400]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.114950,	
2017-06-26 15:58:59,794 Epoch[21] Batch [410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.114654,	
2017-06-26 15:59:05,740 Epoch[21] Batch [420]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.114605,	
2017-06-26 15:59:11,693 Epoch[21] Batch [430]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.114302,	
2017-06-26 15:59:17,681 Epoch[21] Batch [440]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.114154,	
2017-06-26 15:59:23,648 Epoch[21] Batch [450]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.114286,	
2017-06-26 15:59:29,580 Epoch[21] Batch [460]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.114095,	
2017-06-26 15:59:35,582 Epoch[21] Batch [470]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.114182,	
2017-06-26 15:59:41,549 Epoch[21] Batch [480]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.114133,	
2017-06-26 15:59:47,519 Epoch[21] Batch [490]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.114061,	
2017-06-26 15:59:53,455 Epoch[21] Batch [500]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.113891,	
2017-06-26 15:59:58,714 Epoch[21] Batch [510]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.113686,	
2017-06-26 16:00:04,432 Epoch[21] Batch [520]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.113778,	
2017-06-26 16:00:09,946 Epoch[21] Batch [530]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.113624,	
2017-06-26 16:00:15,506 Epoch[21] Batch [540]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.113609,	
2017-06-26 16:00:21,552 Epoch[21] Batch [550]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.113339,	
2017-06-26 16:00:27,422 Epoch[21] Batch [560]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.113085,	
2017-06-26 16:00:33,411 Epoch[21] Batch [570]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.112991,	
2017-06-26 16:00:39,368 Epoch[21] Batch [580]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.112721,	
2017-06-26 16:00:45,315 Epoch[21] Batch [590]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.112929,	
2017-06-26 16:00:51,294 Epoch[21] Batch [600]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.112908,	
2017-06-26 16:00:57,270 Epoch[21] Batch [610]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.112739,	
2017-06-26 16:01:03,180 Epoch[21] Batch [620]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.112899,	
2017-06-26 16:01:09,160 Epoch[21] Batch [630]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.113038,	
2017-06-26 16:01:15,118 Epoch[21] Batch [640]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.113167,	
2017-06-26 16:01:21,085 Epoch[21] Batch [650]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.113486,	
2017-06-26 16:01:27,062 Epoch[21] Batch [660]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.113663,	
2017-06-26 16:01:32,983 Epoch[21] Batch [670]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.113722,	
2017-06-26 16:01:38,963 Epoch[21] Batch [680]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.113752,	
2017-06-26 16:01:44,903 Epoch[21] Batch [690]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.113533,	
2017-06-26 16:01:49,461 Epoch[21] Batch [700]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.113662,	
2017-06-26 16:01:54,270 Epoch[21] Batch [710]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.113714,	
2017-06-26 16:02:00,253 Epoch[21] Batch [720]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.113862,	
2017-06-26 16:02:06,189 Epoch[21] Batch [730]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.113875,	
2017-06-26 16:02:12,175 Epoch[21] Batch [740]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.114065,	
2017-06-26 16:02:18,198 Epoch[21] Batch [750]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.114133,	
2017-06-26 16:02:24,139 Epoch[21] Batch [760]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.114165,	
2017-06-26 16:02:30,138 Epoch[21] Batch [770]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.113891,	
2017-06-26 16:02:36,077 Epoch[21] Batch [780]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.113910,	
2017-06-26 16:02:42,051 Epoch[21] Batch [790]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.113725,	
2017-06-26 16:02:48,045 Epoch[21] Batch [800]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.113582,	
2017-06-26 16:02:54,033 Epoch[21] Batch [810]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113688,	
2017-06-26 16:02:59,940 Epoch[21] Batch [820]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.113645,	
2017-06-26 16:03:05,916 Epoch[21] Batch [830]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.113676,	
2017-06-26 16:03:11,865 Epoch[21] Batch [840]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.113628,	
2017-06-26 16:03:17,857 Epoch[21] Batch [850]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113733,	
2017-06-26 16:03:23,827 Epoch[21] Batch [860]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.113668,	
2017-06-26 16:03:29,823 Epoch[21] Batch [870]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.113499,	
2017-06-26 16:03:35,794 Epoch[21] Batch [880]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.113508,	
2017-06-26 16:03:41,744 Epoch[21] Batch [890]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.113425,	
2017-06-26 16:03:47,731 Epoch[21] Batch [900]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113325,	
2017-06-26 16:03:53,692 Epoch[21] Batch [910]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.113222,	
2017-06-26 16:03:59,642 Epoch[21] Batch [920]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.113374,	
2017-06-26 16:04:05,386 Epoch[21] Batch [930]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.113448,	
2017-06-26 16:04:10,873 Epoch[21] Batch [940]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.113352,	
2017-06-26 16:04:16,339 Epoch[21] Batch [950]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.113320,	
2017-06-26 16:04:21,876 Epoch[21] Batch [960]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.113284,	
2017-06-26 16:04:27,331 Epoch[21] Batch [970]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.113273,	
2017-06-26 16:04:32,671 Epoch[21] Batch [980]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113358,	
2017-06-26 16:04:38,125 Epoch[21] Batch [990]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.113391,	
2017-06-26 16:04:43,629 Epoch[21] Batch [1000]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.113331,	
2017-06-26 16:04:49,149 Epoch[21] Batch [1010]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.113525,	
2017-06-26 16:04:54,599 Epoch[21] Batch [1020]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.113584,	
2017-06-26 16:05:00,572 Epoch[21] Batch [1030]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.113556,	
2017-06-26 16:05:06,522 Epoch[21] Batch [1040]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.113441,	
2017-06-26 16:05:12,453 Epoch[21] Batch [1050]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.113347,	
2017-06-26 16:05:18,450 Epoch[21] Batch [1060]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.113177,	
2017-06-26 16:05:24,411 Epoch[21] Batch [1070]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.113251,	
2017-06-26 16:05:30,382 Epoch[21] Batch [1080]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.113209,	
2017-06-26 16:05:36,387 Epoch[21] Batch [1090]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.113119,	
2017-06-26 16:05:42,314 Epoch[21] Batch [1100]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.113099,	
2017-06-26 16:05:48,303 Epoch[21] Batch [1110]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113074,	
2017-06-26 16:05:54,236 Epoch[21] Batch [1120]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.113064,	
2017-06-26 16:06:00,195 Epoch[21] Batch [1130]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.113007,	
2017-06-26 16:06:06,145 Epoch[21] Batch [1140]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.112960,	
2017-06-26 16:06:12,146 Epoch[21] Batch [1150]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.112986,	
2017-06-26 16:06:18,112 Epoch[21] Batch [1160]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.112885,	
2017-06-26 16:06:24,049 Epoch[21] Batch [1170]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.112848,	
2017-06-26 16:06:30,054 Epoch[21] Batch [1180]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.112728,	
2017-06-26 16:06:35,997 Epoch[21] Batch [1190]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.112631,	
2017-06-26 16:06:41,974 Epoch[21] Batch [1200]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.112617,	
2017-06-26 16:06:48,042 Epoch[21] Batch [1210]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.112558,	
2017-06-26 16:06:53,986 Epoch[21] Batch [1220]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.112468,	
2017-06-26 16:06:59,942 Epoch[21] Batch [1230]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.112585,	
2017-06-26 16:07:05,916 Epoch[21] Batch [1240]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.112465,	
2017-06-26 16:07:11,879 Epoch[21] Batch [1250]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.112397,	
2017-06-26 16:07:17,872 Epoch[21] Batch [1260]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.112324,	
2017-06-26 16:07:23,859 Epoch[21] Batch [1270]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.112302,	
2017-06-26 16:07:29,822 Epoch[21] Batch [1280]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.112314,	
2017-06-26 16:07:35,857 Epoch[21] Batch [1290]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.112254,	
2017-06-26 16:07:41,840 Epoch[21] Batch [1300]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.112266,	
2017-06-26 16:07:47,801 Epoch[21] Batch [1310]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.112329,	
2017-06-26 16:07:53,767 Epoch[21] Batch [1320]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.112478,	
2017-06-26 16:07:59,736 Epoch[21] Batch [1330]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.112494,	
2017-06-26 16:08:05,719 Epoch[21] Batch [1340]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.112528,	
2017-06-26 16:08:11,716 Epoch[21] Batch [1350]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.112632,	
2017-06-26 16:08:17,655 Epoch[21] Batch [1360]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.112624,	
2017-06-26 16:08:23,622 Epoch[21] Batch [1370]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.112606,	
2017-06-26 16:08:29,622 Epoch[21] Batch [1380]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.112557,	
2017-06-26 16:08:35,618 Epoch[21] Batch [1390]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.112520,	
2017-06-26 16:08:41,049 Epoch[21] Batch [1400]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.112566,	
2017-06-26 16:08:46,311 Epoch[21] Batch [1410]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112579,	
2017-06-26 16:08:51,755 Epoch[21] Batch [1420]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.112619,	
2017-06-26 16:08:57,096 Epoch[21] Batch [1430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.112613,	
2017-06-26 16:09:02,127 Epoch[21] Batch [1440]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.112535,	
2017-06-26 16:09:07,595 Epoch[21] Batch [1450]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.112550,	
2017-06-26 16:09:13,057 Epoch[21] Batch [1460]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.112469,	
2017-06-26 16:09:18,249 Epoch[21] Batch [1470]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.112528,	
2017-06-26 16:09:22,967 Epoch[21] Batch [1480]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.112625,	
2017-06-26 16:09:26,133 Epoch[21] Train-FCNLogLoss=0.112618
2017-06-26 16:09:26,133 Epoch[21] Time cost=864.192
2017-06-26 16:09:26,832 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0022.params"
2017-06-26 16:09:28,417 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0022.states"
2017-06-26 16:09:35,162 Epoch[22] Batch [10]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.101912,	
2017-06-26 16:09:41,165 Epoch[22] Batch [20]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.108284,	
2017-06-26 16:09:47,112 Epoch[22] Batch [30]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.109667,	
2017-06-26 16:09:52,770 Epoch[22] Batch [40]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.110798,	
2017-06-26 16:09:58,250 Epoch[22] Batch [50]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.107698,	
2017-06-26 16:10:03,713 Epoch[22] Batch [60]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.107784,	
2017-06-26 16:10:09,047 Epoch[22] Batch [70]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.107548,	
2017-06-26 16:10:14,348 Epoch[22] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.109945,	
2017-06-26 16:10:19,663 Epoch[22] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.112678,	
2017-06-26 16:10:24,995 Epoch[22] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.113900,	
2017-06-26 16:10:30,333 Epoch[22] Batch [110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.113960,	
2017-06-26 16:10:35,660 Epoch[22] Batch [120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.113681,	
2017-06-26 16:10:40,989 Epoch[22] Batch [130]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.112722,	
2017-06-26 16:10:46,380 Epoch[22] Batch [140]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.112531,	
2017-06-26 16:10:51,967 Epoch[22] Batch [150]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.111968,	
2017-06-26 16:10:57,509 Epoch[22] Batch [160]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.111904,	
2017-06-26 16:11:03,078 Epoch[22] Batch [170]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.111873,	
2017-06-26 16:11:08,356 Epoch[22] Batch [180]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.111112,	
2017-06-26 16:11:13,725 Epoch[22] Batch [190]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.110887,	
2017-06-26 16:11:19,121 Epoch[22] Batch [200]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.111548,	
2017-06-26 16:11:24,523 Epoch[22] Batch [210]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.112028,	
2017-06-26 16:11:29,976 Epoch[22] Batch [220]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.111937,	
2017-06-26 16:11:35,291 Epoch[22] Batch [230]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.112238,	
2017-06-26 16:11:40,658 Epoch[22] Batch [240]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.112547,	
2017-06-26 16:11:46,037 Epoch[22] Batch [250]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.112945,	
2017-06-26 16:11:52,093 Epoch[22] Batch [260]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.113096,	
2017-06-26 16:11:58,102 Epoch[22] Batch [270]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.113159,	
2017-06-26 16:12:04,187 Epoch[22] Batch [280]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.112672,	
2017-06-26 16:12:10,259 Epoch[22] Batch [290]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.112645,	
2017-06-26 16:12:16,357 Epoch[22] Batch [300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.112418,	
2017-06-26 16:12:22,412 Epoch[22] Batch [310]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.112498,	
2017-06-26 16:12:28,438 Epoch[22] Batch [320]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.112720,	
2017-06-26 16:12:34,496 Epoch[22] Batch [330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.112723,	
2017-06-26 16:12:40,562 Epoch[22] Batch [340]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.112505,	
2017-06-26 16:12:46,613 Epoch[22] Batch [350]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.112228,	
2017-06-26 16:12:52,623 Epoch[22] Batch [360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.111821,	
2017-06-26 16:12:58,654 Epoch[22] Batch [370]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.111930,	
2017-06-26 16:13:04,734 Epoch[22] Batch [380]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.111891,	
2017-06-26 16:13:10,785 Epoch[22] Batch [390]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.111718,	
2017-06-26 16:13:16,910 Epoch[22] Batch [400]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.111437,	
2017-06-26 16:13:22,987 Epoch[22] Batch [410]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.111794,	
2017-06-26 16:13:29,118 Epoch[22] Batch [420]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.111654,	
2017-06-26 16:13:35,193 Epoch[22] Batch [430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.111559,	
2017-06-26 16:13:41,356 Epoch[22] Batch [440]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.111171,	
2017-06-26 16:13:47,460 Epoch[22] Batch [450]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.111471,	
2017-06-26 16:13:53,726 Epoch[22] Batch [460]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.111547,	
2017-06-26 16:13:59,801 Epoch[22] Batch [470]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.111738,	
2017-06-26 16:14:05,869 Epoch[22] Batch [480]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.111999,	
2017-06-26 16:14:11,979 Epoch[22] Batch [490]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.112019,	
2017-06-26 16:14:18,046 Epoch[22] Batch [500]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.112117,	
2017-06-26 16:14:24,150 Epoch[22] Batch [510]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.112234,	
2017-06-26 16:14:30,269 Epoch[22] Batch [520]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.112083,	
2017-06-26 16:14:36,467 Epoch[22] Batch [530]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.111954,	
2017-06-26 16:14:42,605 Epoch[22] Batch [540]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.111765,	
2017-06-26 16:14:48,718 Epoch[22] Batch [550]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.111654,	
2017-06-26 16:14:54,869 Epoch[22] Batch [560]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.111747,	
2017-06-26 16:15:00,865 Epoch[22] Batch [570]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.111805,	
2017-06-26 16:15:06,959 Epoch[22] Batch [580]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.112014,	
2017-06-26 16:15:12,992 Epoch[22] Batch [590]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.111893,	
2017-06-26 16:15:18,868 Epoch[22] Batch [600]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.112089,	
2017-06-26 16:15:24,809 Epoch[22] Batch [610]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.112125,	
2017-06-26 16:15:30,606 Epoch[22] Batch [620]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.112177,	
2017-06-26 16:15:35,823 Epoch[22] Batch [630]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.112198,	
2017-06-26 16:15:41,221 Epoch[22] Batch [640]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.112113,	
2017-06-26 16:15:45,758 Epoch[22] Batch [650]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.111941,	
2017-06-26 16:15:51,202 Epoch[22] Batch [660]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.111774,	
2017-06-26 16:15:56,464 Epoch[22] Batch [670]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.112289,	
2017-06-26 16:16:01,979 Epoch[22] Batch [680]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.112445,	
2017-06-26 16:16:07,258 Epoch[22] Batch [690]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.112507,	
2017-06-26 16:16:12,674 Epoch[22] Batch [700]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.112444,	
2017-06-26 16:16:18,015 Epoch[22] Batch [710]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.112644,	
2017-06-26 16:16:23,422 Epoch[22] Batch [720]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.112580,	
2017-06-26 16:16:28,582 Epoch[22] Batch [730]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.112427,	
2017-06-26 16:16:33,594 Epoch[22] Batch [740]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.112491,	
2017-06-26 16:16:39,096 Epoch[22] Batch [750]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.112409,	
2017-06-26 16:16:45,240 Epoch[22] Batch [760]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.112458,	
2017-06-26 16:16:51,345 Epoch[22] Batch [770]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.112418,	
2017-06-26 16:16:57,529 Epoch[22] Batch [780]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.112544,	
2017-06-26 16:17:03,705 Epoch[22] Batch [790]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.112569,	
2017-06-26 16:17:09,864 Epoch[22] Batch [800]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.112728,	
2017-06-26 16:17:16,011 Epoch[22] Batch [810]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.112704,	
2017-06-26 16:17:22,176 Epoch[22] Batch [820]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.112786,	
2017-06-26 16:17:28,232 Epoch[22] Batch [830]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.112769,	
2017-06-26 16:17:34,316 Epoch[22] Batch [840]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.112680,	
2017-06-26 16:17:40,486 Epoch[22] Batch [850]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.112793,	
2017-06-26 16:17:46,682 Epoch[22] Batch [860]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.112669,	
2017-06-26 16:17:52,870 Epoch[22] Batch [870]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.112668,	
2017-06-26 16:17:59,033 Epoch[22] Batch [880]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.112618,	
2017-06-26 16:18:05,189 Epoch[22] Batch [890]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.112706,	
2017-06-26 16:18:11,147 Epoch[22] Batch [900]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.112681,	
2017-06-26 16:18:17,187 Epoch[22] Batch [910]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.112621,	
2017-06-26 16:18:23,264 Epoch[22] Batch [920]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.112535,	
2017-06-26 16:18:29,256 Epoch[22] Batch [930]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.112550,	
2017-06-26 16:18:35,160 Epoch[22] Batch [940]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.112529,	
2017-06-26 16:18:40,986 Epoch[22] Batch [950]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.112521,	
2017-06-26 16:18:47,005 Epoch[22] Batch [960]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.113050,	
2017-06-26 16:18:53,019 Epoch[22] Batch [970]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.113690,	
2017-06-26 16:18:59,172 Epoch[22] Batch [980]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.114913,	
2017-06-26 16:19:05,326 Epoch[22] Batch [990]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.115605,	
2017-06-26 16:19:11,234 Epoch[22] Batch [1000]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.116549,	
2017-06-26 16:19:17,173 Epoch[22] Batch [1010]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.117016,	
2017-06-26 16:19:23,196 Epoch[22] Batch [1020]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.117204,	
2017-06-26 16:19:29,127 Epoch[22] Batch [1030]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.117282,	
2017-06-26 16:19:35,222 Epoch[22] Batch [1040]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.117327,	
2017-06-26 16:19:41,034 Epoch[22] Batch [1050]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.117245,	
2017-06-26 16:19:47,196 Epoch[22] Batch [1060]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.117509,	
2017-06-26 16:19:53,288 Epoch[22] Batch [1070]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.117593,	
2017-06-26 16:19:59,224 Epoch[22] Batch [1080]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.117547,	
2017-06-26 16:20:05,076 Epoch[22] Batch [1090]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.117674,	
2017-06-26 16:20:11,126 Epoch[22] Batch [1100]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.117874,	
2017-06-26 16:20:17,163 Epoch[22] Batch [1110]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.118044,	
2017-06-26 16:20:23,247 Epoch[22] Batch [1120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.118061,	
2017-06-26 16:20:29,293 Epoch[22] Batch [1130]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.118121,	
2017-06-26 16:20:35,088 Epoch[22] Batch [1140]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.118062,	
2017-06-26 16:20:40,911 Epoch[22] Batch [1150]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.118042,	
2017-06-26 16:20:46,679 Epoch[22] Batch [1160]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.118179,	
2017-06-26 16:20:52,513 Epoch[22] Batch [1170]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.118529,	
2017-06-26 16:20:58,033 Epoch[22] Batch [1180]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.118870,	
2017-06-26 16:21:03,767 Epoch[22] Batch [1190]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.119074,	
2017-06-26 16:21:09,667 Epoch[22] Batch [1200]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.119184,	
2017-06-26 16:21:15,801 Epoch[22] Batch [1210]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.119367,	
2017-06-26 16:21:21,842 Epoch[22] Batch [1220]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.119973,	
2017-06-26 16:21:27,976 Epoch[22] Batch [1230]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.120650,	
2017-06-26 16:21:34,034 Epoch[22] Batch [1240]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.120770,	
2017-06-26 16:21:40,180 Epoch[22] Batch [1250]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.121124,	
2017-06-26 16:21:46,373 Epoch[22] Batch [1260]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.121200,	
2017-06-26 16:21:52,450 Epoch[22] Batch [1270]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.121286,	
2017-06-26 16:21:58,590 Epoch[22] Batch [1280]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.121209,	
2017-06-26 16:22:04,805 Epoch[22] Batch [1290]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.121359,	
2017-06-26 16:22:10,955 Epoch[22] Batch [1300]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.121390,	
2017-06-26 16:22:17,094 Epoch[22] Batch [1310]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.121359,	
2017-06-26 16:22:23,286 Epoch[22] Batch [1320]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.121343,	
2017-06-26 16:22:29,449 Epoch[22] Batch [1330]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.121293,	
2017-06-26 16:22:35,451 Epoch[22] Batch [1340]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.121361,	
2017-06-26 16:22:41,529 Epoch[22] Batch [1350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.121317,	
2017-06-26 16:22:47,540 Epoch[22] Batch [1360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.121254,	
2017-06-26 16:22:53,593 Epoch[22] Batch [1370]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.121189,	
2017-06-26 16:22:59,673 Epoch[22] Batch [1380]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.121106,	
2017-06-26 16:23:05,742 Epoch[22] Batch [1390]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.121029,	
2017-06-26 16:23:12,012 Epoch[22] Batch [1400]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.121089,	
2017-06-26 16:23:17,900 Epoch[22] Batch [1410]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.121005,	
2017-06-26 16:23:23,966 Epoch[22] Batch [1420]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.120934,	
2017-06-26 16:23:29,859 Epoch[22] Batch [1430]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.120932,	
2017-06-26 16:23:35,695 Epoch[22] Batch [1440]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.120928,	
2017-06-26 16:23:41,476 Epoch[22] Batch [1450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.120861,	
2017-06-26 16:23:47,203 Epoch[22] Batch [1460]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.120802,	
2017-06-26 16:23:52,627 Epoch[22] Batch [1470]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.120900,	
2017-06-26 16:23:58,401 Epoch[22] Batch [1480]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.120869,	
2017-06-26 16:24:01,670 Epoch[22] Train-FCNLogLoss=0.120763
2017-06-26 16:24:01,670 Epoch[22] Time cost=873.250
2017-06-26 16:24:02,445 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0023.params"
2017-06-26 16:24:05,811 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0023.states"
2017-06-26 16:24:12,549 Epoch[23] Batch [10]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.125237,	
2017-06-26 16:24:18,397 Epoch[23] Batch [20]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.119198,	
2017-06-26 16:24:24,050 Epoch[23] Batch [30]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.126630,	
2017-06-26 16:24:29,793 Epoch[23] Batch [40]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.120967,	
2017-06-26 16:24:35,513 Epoch[23] Batch [50]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.119238,	
2017-06-26 16:24:41,740 Epoch[23] Batch [60]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.116518,	
2017-06-26 16:24:47,414 Epoch[23] Batch [70]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.117068,	
2017-06-26 16:24:53,265 Epoch[23] Batch [80]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.116565,	
2017-06-26 16:24:58,582 Epoch[23] Batch [90]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.117247,	
2017-06-26 16:25:04,397 Epoch[23] Batch [100]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.115735,	
2017-06-26 16:25:10,567 Epoch[23] Batch [110]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.117179,	
2017-06-26 16:25:16,931 Epoch[23] Batch [120]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.116367,	
2017-06-26 16:25:23,138 Epoch[23] Batch [130]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.117058,	
2017-06-26 16:25:28,887 Epoch[23] Batch [140]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.116911,	
2017-06-26 16:25:35,084 Epoch[23] Batch [150]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.117154,	
2017-06-26 16:25:41,165 Epoch[23] Batch [160]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.116916,	
2017-06-26 16:25:47,262 Epoch[23] Batch [170]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.115889,	
2017-06-26 16:25:53,277 Epoch[23] Batch [180]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.115506,	
2017-06-26 16:25:59,738 Epoch[23] Batch [190]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.116040,	
2017-06-26 16:26:05,825 Epoch[23] Batch [200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.116153,	
2017-06-26 16:26:12,221 Epoch[23] Batch [210]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.116475,	
2017-06-26 16:26:18,436 Epoch[23] Batch [220]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.116462,	
2017-06-26 16:26:25,005 Epoch[23] Batch [230]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.116252,	
2017-06-26 16:26:31,203 Epoch[23] Batch [240]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.116200,	
2017-06-26 16:26:37,664 Epoch[23] Batch [250]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.115945,	
2017-06-26 16:26:44,221 Epoch[23] Batch [260]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.115832,	
2017-06-26 16:26:50,699 Epoch[23] Batch [270]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.115680,	
2017-06-26 16:26:57,089 Epoch[23] Batch [280]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.115569,	
2017-06-26 16:27:03,646 Epoch[23] Batch [290]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.115666,	
2017-06-26 16:27:10,348 Epoch[23] Batch [300]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.115354,	
2017-06-26 16:27:16,622 Epoch[23] Batch [310]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.115560,	
2017-06-26 16:27:23,150 Epoch[23] Batch [320]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.115434,	
2017-06-26 16:27:29,511 Epoch[23] Batch [330]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.115449,	
2017-06-26 16:27:36,027 Epoch[23] Batch [340]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.115480,	
2017-06-26 16:27:42,664 Epoch[23] Batch [350]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.115164,	
2017-06-26 16:27:49,000 Epoch[23] Batch [360]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.114941,	
2017-06-26 16:27:55,321 Epoch[23] Batch [370]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.115091,	
2017-06-26 16:28:01,875 Epoch[23] Batch [380]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.114887,	
2017-06-26 16:28:08,436 Epoch[23] Batch [390]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.115055,	
2017-06-26 16:28:14,898 Epoch[23] Batch [400]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.115328,	
2017-06-26 16:28:21,174 Epoch[23] Batch [410]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.115463,	
2017-06-26 16:28:27,853 Epoch[23] Batch [420]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.114974,	
2017-06-26 16:28:34,612 Epoch[23] Batch [430]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.115074,	
2017-06-26 16:28:41,325 Epoch[23] Batch [440]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.114993,	
2017-06-26 16:28:47,727 Epoch[23] Batch [450]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.114700,	
2017-06-26 16:28:54,811 Epoch[23] Batch [460]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.114410,	
2017-06-26 16:29:02,080 Epoch[23] Batch [470]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.114568,	
2017-06-26 16:29:08,864 Epoch[23] Batch [480]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.114249,	
2017-06-26 16:29:15,510 Epoch[23] Batch [490]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.114026,	
2017-06-26 16:29:22,128 Epoch[23] Batch [500]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.113845,	
2017-06-26 16:29:28,698 Epoch[23] Batch [510]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.113944,	
2017-06-26 16:29:35,583 Epoch[23] Batch [520]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.113745,	
2017-06-26 16:29:42,192 Epoch[23] Batch [530]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.113676,	
2017-06-26 16:29:48,323 Epoch[23] Batch [540]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.113640,	
2017-06-26 16:29:54,217 Epoch[23] Batch [550]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.113782,	
2017-06-26 16:30:00,039 Epoch[23] Batch [560]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.113547,	
2017-06-26 16:30:05,886 Epoch[23] Batch [570]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.113961,	
2017-06-26 16:30:11,874 Epoch[23] Batch [580]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.114475,	
2017-06-26 16:30:17,763 Epoch[23] Batch [590]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.114602,	
2017-06-26 16:30:23,653 Epoch[23] Batch [600]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.114665,	
2017-06-26 16:30:29,142 Epoch[23] Batch [610]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.114557,	
2017-06-26 16:30:34,984 Epoch[23] Batch [620]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.115242,	
2017-06-26 16:30:40,928 Epoch[23] Batch [630]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.115428,	
2017-06-26 16:30:46,616 Epoch[23] Batch [640]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.115569,	
2017-06-26 16:30:52,279 Epoch[23] Batch [650]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.115692,	
2017-06-26 16:30:57,869 Epoch[23] Batch [660]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.115858,	
2017-06-26 16:31:03,841 Epoch[23] Batch [670]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.115591,	
2017-06-26 16:31:09,734 Epoch[23] Batch [680]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.115548,	
2017-06-26 16:31:15,958 Epoch[23] Batch [690]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.115641,	
2017-06-26 16:31:22,212 Epoch[23] Batch [700]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.115376,	
2017-06-26 16:31:28,109 Epoch[23] Batch [710]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.115339,	
2017-06-26 16:31:34,239 Epoch[23] Batch [720]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.115278,	
2017-06-26 16:31:39,976 Epoch[23] Batch [730]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.115187,	
2017-06-26 16:31:46,089 Epoch[23] Batch [740]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.115068,	
2017-06-26 16:31:52,156 Epoch[23] Batch [750]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.115094,	
2017-06-26 16:31:57,946 Epoch[23] Batch [760]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.115009,	
2017-06-26 16:32:03,833 Epoch[23] Batch [770]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.114980,	
2017-06-26 16:32:09,522 Epoch[23] Batch [780]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.114906,	
2017-06-26 16:32:15,239 Epoch[23] Batch [790]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.114724,	
2017-06-26 16:32:20,710 Epoch[23] Batch [800]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.114571,	
2017-06-26 16:32:26,844 Epoch[23] Batch [810]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.114709,	
2017-06-26 16:32:33,113 Epoch[23] Batch [820]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.114590,	
2017-06-26 16:32:39,446 Epoch[23] Batch [830]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.114678,	
2017-06-26 16:32:45,792 Epoch[23] Batch [840]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.114519,	
2017-06-26 16:32:52,505 Epoch[23] Batch [850]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.114638,	
2017-06-26 16:32:58,833 Epoch[23] Batch [860]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.114482,	
2017-06-26 16:33:04,332 Epoch[23] Batch [870]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.114572,	
2017-06-26 16:33:09,582 Epoch[23] Batch [880]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.114471,	
2017-06-26 16:33:15,649 Epoch[23] Batch [890]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.114443,	
2017-06-26 16:33:21,696 Epoch[23] Batch [900]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.114318,	
2017-06-26 16:33:27,826 Epoch[23] Batch [910]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.114261,	
2017-06-26 16:33:33,972 Epoch[23] Batch [920]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.114220,	
2017-06-26 16:33:40,201 Epoch[23] Batch [930]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.114170,	
2017-06-26 16:33:46,409 Epoch[23] Batch [940]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.114078,	
2017-06-26 16:33:52,579 Epoch[23] Batch [950]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.114021,	
2017-06-26 16:33:58,829 Epoch[23] Batch [960]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.113951,	
2017-06-26 16:34:04,909 Epoch[23] Batch [970]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.113971,	
2017-06-26 16:34:11,144 Epoch[23] Batch [980]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.113967,	
2017-06-26 16:34:17,317 Epoch[23] Batch [990]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.113889,	
2017-06-26 16:34:23,252 Epoch[23] Batch [1000]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.113948,	
2017-06-26 16:34:29,205 Epoch[23] Batch [1010]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.113946,	
2017-06-26 16:34:35,462 Epoch[23] Batch [1020]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.113866,	
2017-06-26 16:34:41,515 Epoch[23] Batch [1030]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.113757,	
2017-06-26 16:34:47,385 Epoch[23] Batch [1040]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.113822,	
2017-06-26 16:34:53,942 Epoch[23] Batch [1050]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.113893,	
2017-06-26 16:34:59,863 Epoch[23] Batch [1060]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.113848,	
2017-06-26 16:35:05,971 Epoch[23] Batch [1070]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.113751,	
2017-06-26 16:35:12,390 Epoch[23] Batch [1080]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.113689,	
2017-06-26 16:35:18,772 Epoch[23] Batch [1090]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.113598,	
2017-06-26 16:35:24,401 Epoch[23] Batch [1100]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.113586,	
2017-06-26 16:35:30,494 Epoch[23] Batch [1110]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.113620,	
2017-06-26 16:35:36,258 Epoch[23] Batch [1120]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.113540,	
2017-06-26 16:35:42,389 Epoch[23] Batch [1130]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.113459,	
2017-06-26 16:35:48,008 Epoch[23] Batch [1140]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.113354,	
2017-06-26 16:35:53,931 Epoch[23] Batch [1150]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.113327,	
2017-06-26 16:35:59,859 Epoch[23] Batch [1160]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.113379,	
2017-06-26 16:36:05,743 Epoch[23] Batch [1170]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.113376,	
2017-06-26 16:36:12,095 Epoch[23] Batch [1180]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.113327,	
2017-06-26 16:36:18,316 Epoch[23] Batch [1190]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.113251,	
2017-06-26 16:36:24,192 Epoch[23] Batch [1200]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.113230,	
2017-06-26 16:36:30,437 Epoch[23] Batch [1210]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.113149,	
2017-06-26 16:36:36,580 Epoch[23] Batch [1220]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.113132,	
2017-06-26 16:36:42,459 Epoch[23] Batch [1230]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.113063,	
2017-06-26 16:36:48,452 Epoch[23] Batch [1240]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.113055,	
2017-06-26 16:36:54,739 Epoch[23] Batch [1250]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.113075,	
2017-06-26 16:37:01,326 Epoch[23] Batch [1260]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.113059,	
2017-06-26 16:37:07,503 Epoch[23] Batch [1270]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.113068,	
2017-06-26 16:37:13,789 Epoch[23] Batch [1280]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.112993,	
2017-06-26 16:37:19,997 Epoch[23] Batch [1290]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.112963,	
2017-06-26 16:37:26,076 Epoch[23] Batch [1300]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.112922,	
2017-06-26 16:37:32,217 Epoch[23] Batch [1310]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.112977,	
2017-06-26 16:37:38,433 Epoch[23] Batch [1320]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.113028,	
2017-06-26 16:37:44,532 Epoch[23] Batch [1330]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.112983,	
2017-06-26 16:37:50,686 Epoch[23] Batch [1340]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.113074,	
2017-06-26 16:37:56,878 Epoch[23] Batch [1350]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.113104,	
2017-06-26 16:38:02,994 Epoch[23] Batch [1360]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.113080,	
2017-06-26 16:38:09,130 Epoch[23] Batch [1370]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.113035,	
2017-06-26 16:38:15,269 Epoch[23] Batch [1380]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.112963,	
2017-06-26 16:38:21,434 Epoch[23] Batch [1390]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.112946,	
2017-06-26 16:38:27,607 Epoch[23] Batch [1400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.113114,	
2017-06-26 16:38:33,547 Epoch[23] Batch [1410]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.113118,	
2017-06-26 16:38:39,504 Epoch[23] Batch [1420]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.113101,	
2017-06-26 16:38:45,538 Epoch[23] Batch [1430]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.113189,	
2017-06-26 16:38:51,855 Epoch[23] Batch [1440]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.113182,	
2017-06-26 16:38:58,746 Epoch[23] Batch [1450]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.113187,	
2017-06-26 16:39:06,079 Epoch[23] Batch [1460]	Speed: 5.45 samples/sec	Train-FCNLogLoss=0.113234,	
2017-06-26 16:39:12,841 Epoch[23] Batch [1470]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.113547,	
2017-06-26 16:39:19,590 Epoch[23] Batch [1480]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.113923,	
2017-06-26 16:39:23,394 Epoch[23] Train-FCNLogLoss=0.114126
2017-06-26 16:39:23,394 Epoch[23] Time cost=917.583
2017-06-26 16:39:24,229 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0024.params"
2017-06-26 16:39:27,765 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0024.states"
2017-06-26 16:39:35,279 Epoch[24] Batch [10]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.143260,	
2017-06-26 16:39:41,635 Epoch[24] Batch [20]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.136092,	
2017-06-26 16:39:48,057 Epoch[24] Batch [30]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.124812,	
2017-06-26 16:39:54,528 Epoch[24] Batch [40]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.123586,	
2017-06-26 16:40:01,127 Epoch[24] Batch [50]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.120419,	
2017-06-26 16:40:07,476 Epoch[24] Batch [60]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.119429,	
2017-06-26 16:40:13,930 Epoch[24] Batch [70]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.118784,	
2017-06-26 16:40:20,397 Epoch[24] Batch [80]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.118209,	
2017-06-26 16:40:27,265 Epoch[24] Batch [90]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.117915,	
2017-06-26 16:40:33,767 Epoch[24] Batch [100]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.118387,	
2017-06-26 16:40:40,620 Epoch[24] Batch [110]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.116871,	
2017-06-26 16:40:47,268 Epoch[24] Batch [120]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.116877,	
2017-06-26 16:40:54,372 Epoch[24] Batch [130]	Speed: 5.63 samples/sec	Train-FCNLogLoss=0.115309,	
2017-06-26 16:41:01,036 Epoch[24] Batch [140]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.116452,	
2017-06-26 16:41:07,770 Epoch[24] Batch [150]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.115992,	
2017-06-26 16:41:14,324 Epoch[24] Batch [160]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.116185,	
2017-06-26 16:41:21,198 Epoch[24] Batch [170]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.116560,	
2017-06-26 16:41:27,949 Epoch[24] Batch [180]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.116553,	
2017-06-26 16:41:34,738 Epoch[24] Batch [190]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.116020,	
2017-06-26 16:41:41,098 Epoch[24] Batch [200]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.115181,	
2017-06-26 16:41:47,797 Epoch[24] Batch [210]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.115151,	
2017-06-26 16:41:54,601 Epoch[24] Batch [220]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.115010,	
2017-06-26 16:42:01,427 Epoch[24] Batch [230]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.114592,	
2017-06-26 16:42:07,741 Epoch[24] Batch [240]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.114674,	
2017-06-26 16:42:14,493 Epoch[24] Batch [250]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.114598,	
2017-06-26 16:42:21,235 Epoch[24] Batch [260]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.114379,	
2017-06-26 16:42:28,150 Epoch[24] Batch [270]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.114174,	
2017-06-26 16:42:35,586 Epoch[24] Batch [280]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.114038,	
2017-06-26 16:42:42,530 Epoch[24] Batch [290]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.113907,	
2017-06-26 16:42:49,093 Epoch[24] Batch [300]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.114344,	
2017-06-26 16:42:55,475 Epoch[24] Batch [310]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.114341,	
2017-06-26 16:43:02,222 Epoch[24] Batch [320]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.114145,	
2017-06-26 16:43:08,556 Epoch[24] Batch [330]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.114109,	
2017-06-26 16:43:15,220 Epoch[24] Batch [340]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.113966,	
2017-06-26 16:43:21,842 Epoch[24] Batch [350]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.114319,	
2017-06-26 16:43:28,179 Epoch[24] Batch [360]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.113942,	
2017-06-26 16:43:35,170 Epoch[24] Batch [370]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.113755,	
2017-06-26 16:43:41,637 Epoch[24] Batch [380]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.113518,	
2017-06-26 16:43:48,322 Epoch[24] Batch [390]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.113636,	
2017-06-26 16:43:55,127 Epoch[24] Batch [400]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.113575,	
2017-06-26 16:44:01,578 Epoch[24] Batch [410]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.113231,	
2017-06-26 16:44:08,004 Epoch[24] Batch [420]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.113108,	
2017-06-26 16:44:13,379 Epoch[24] Batch [430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.112900,	
2017-06-26 16:44:18,886 Epoch[24] Batch [440]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.112871,	
2017-06-26 16:44:24,430 Epoch[24] Batch [450]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.112967,	
2017-06-26 16:44:30,214 Epoch[24] Batch [460]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.112808,	
2017-06-26 16:44:35,620 Epoch[24] Batch [470]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.112603,	
2017-06-26 16:44:40,930 Epoch[24] Batch [480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.112473,	
2017-06-26 16:44:46,704 Epoch[24] Batch [490]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.112213,	
2017-06-26 16:44:53,188 Epoch[24] Batch [500]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.112238,	
2017-06-26 16:44:59,580 Epoch[24] Batch [510]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.112241,	
2017-06-26 16:45:05,785 Epoch[24] Batch [520]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.112315,	
2017-06-26 16:45:12,300 Epoch[24] Batch [530]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.112044,	
2017-06-26 16:45:18,626 Epoch[24] Batch [540]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.112004,	
2017-06-26 16:45:24,742 Epoch[24] Batch [550]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.111999,	
2017-06-26 16:45:31,043 Epoch[24] Batch [560]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.111835,	
2017-06-26 16:45:37,605 Epoch[24] Batch [570]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.111806,	
2017-06-26 16:45:44,307 Epoch[24] Batch [580]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.111795,	
2017-06-26 16:45:50,890 Epoch[24] Batch [590]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.111780,	
2017-06-26 16:45:57,639 Epoch[24] Batch [600]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.111608,	
2017-06-26 16:46:04,452 Epoch[24] Batch [610]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.111770,	
2017-06-26 16:46:11,261 Epoch[24] Batch [620]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.111526,	
2017-06-26 16:46:17,618 Epoch[24] Batch [630]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.111414,	
2017-06-26 16:46:23,783 Epoch[24] Batch [640]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.111198,	
2017-06-26 16:46:30,064 Epoch[24] Batch [650]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.111048,	
2017-06-26 16:46:35,986 Epoch[24] Batch [660]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.110974,	
2017-06-26 16:46:42,082 Epoch[24] Batch [670]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.110912,	
2017-06-26 16:46:48,196 Epoch[24] Batch [680]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.110745,	
2017-06-26 16:46:53,992 Epoch[24] Batch [690]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110772,	
2017-06-26 16:46:59,778 Epoch[24] Batch [700]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110853,	
2017-06-26 16:47:05,527 Epoch[24] Batch [710]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.110739,	
2017-06-26 16:47:11,557 Epoch[24] Batch [720]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.110656,	
2017-06-26 16:47:17,498 Epoch[24] Batch [730]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.110566,	
2017-06-26 16:47:23,321 Epoch[24] Batch [740]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.110563,	
2017-06-26 16:47:29,151 Epoch[24] Batch [750]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110427,	
2017-06-26 16:47:34,938 Epoch[24] Batch [760]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110549,	
2017-06-26 16:47:40,686 Epoch[24] Batch [770]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.110548,	
2017-06-26 16:47:46,482 Epoch[24] Batch [780]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110456,	
2017-06-26 16:47:52,321 Epoch[24] Batch [790]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.110561,	
2017-06-26 16:47:58,121 Epoch[24] Batch [800]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110424,	
2017-06-26 16:48:03,917 Epoch[24] Batch [810]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.110362,	
2017-06-26 16:48:09,753 Epoch[24] Batch [820]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.110278,	
2017-06-26 16:48:15,600 Epoch[24] Batch [830]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.110157,	
2017-06-26 16:48:21,431 Epoch[24] Batch [840]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.110202,	
2017-06-26 16:48:27,300 Epoch[24] Batch [850]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.110401,	
2017-06-26 16:48:33,520 Epoch[24] Batch [860]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.110290,	
2017-06-26 16:48:39,066 Epoch[24] Batch [870]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.110273,	
2017-06-26 16:48:44,851 Epoch[24] Batch [880]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.110095,	
2017-06-26 16:48:50,814 Epoch[24] Batch [890]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.109984,	
2017-06-26 16:48:56,581 Epoch[24] Batch [900]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.109827,	
2017-06-26 16:49:02,380 Epoch[24] Batch [910]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.109689,	
2017-06-26 16:49:08,550 Epoch[24] Batch [920]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.109587,	
2017-06-26 16:49:14,596 Epoch[24] Batch [930]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.109690,	
2017-06-26 16:49:20,673 Epoch[24] Batch [940]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109693,	
2017-06-26 16:49:26,808 Epoch[24] Batch [950]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.109769,	
2017-06-26 16:49:32,955 Epoch[24] Batch [960]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.109759,	
2017-06-26 16:49:39,023 Epoch[24] Batch [970]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109844,	
2017-06-26 16:49:45,276 Epoch[24] Batch [980]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.109828,	
2017-06-26 16:49:51,373 Epoch[24] Batch [990]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.109999,	
2017-06-26 16:49:57,757 Epoch[24] Batch [1000]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.109969,	
2017-06-26 16:50:04,112 Epoch[24] Batch [1010]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.109937,	
2017-06-26 16:50:10,440 Epoch[24] Batch [1020]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.110051,	
2017-06-26 16:50:16,780 Epoch[24] Batch [1030]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.109918,	
2017-06-26 16:50:23,082 Epoch[24] Batch [1040]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.109900,	
2017-06-26 16:50:29,556 Epoch[24] Batch [1050]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.109909,	
2017-06-26 16:50:35,867 Epoch[24] Batch [1060]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.109875,	
2017-06-26 16:50:41,729 Epoch[24] Batch [1070]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.109750,	
2017-06-26 16:50:48,286 Epoch[24] Batch [1080]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.109715,	
2017-06-26 16:50:54,167 Epoch[24] Batch [1090]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.109666,	
2017-06-26 16:51:00,250 Epoch[24] Batch [1100]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109663,	
2017-06-26 16:51:06,527 Epoch[24] Batch [1110]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.109587,	
2017-06-26 16:51:12,554 Epoch[24] Batch [1120]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.109573,	
2017-06-26 16:51:18,554 Epoch[24] Batch [1130]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.109529,	
2017-06-26 16:51:24,416 Epoch[24] Batch [1140]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.109488,	
2017-06-26 16:51:30,573 Epoch[24] Batch [1150]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.109503,	
2017-06-26 16:51:36,644 Epoch[24] Batch [1160]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109614,	
2017-06-26 16:51:42,431 Epoch[24] Batch [1170]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.109562,	
2017-06-26 16:51:48,510 Epoch[24] Batch [1180]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109544,	
2017-06-26 16:51:54,826 Epoch[24] Batch [1190]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.109514,	
2017-06-26 16:52:00,929 Epoch[24] Batch [1200]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.109560,	
2017-06-26 16:52:06,981 Epoch[24] Batch [1210]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109508,	
2017-06-26 16:52:13,397 Epoch[24] Batch [1220]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.109523,	
2017-06-26 16:52:20,056 Epoch[24] Batch [1230]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.109649,	
2017-06-26 16:52:26,725 Epoch[24] Batch [1240]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109574,	
2017-06-26 16:52:31,998 Epoch[24] Batch [1250]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.109556,	
2017-06-26 16:52:37,330 Epoch[24] Batch [1260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.109564,	
2017-06-26 16:52:42,489 Epoch[24] Batch [1270]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.109523,	
2017-06-26 16:52:47,769 Epoch[24] Batch [1280]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.109554,	
2017-06-26 16:52:53,185 Epoch[24] Batch [1290]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.109605,	
2017-06-26 16:52:58,704 Epoch[24] Batch [1300]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.109611,	
2017-06-26 16:53:04,869 Epoch[24] Batch [1310]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.109725,	
2017-06-26 16:53:11,543 Epoch[24] Batch [1320]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.109810,	
2017-06-26 16:53:17,821 Epoch[24] Batch [1330]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.109668,	
2017-06-26 16:53:23,854 Epoch[24] Batch [1340]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.109710,	
2017-06-26 16:53:30,617 Epoch[24] Batch [1350]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.109655,	
2017-06-26 16:53:37,254 Epoch[24] Batch [1360]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.109676,	
2017-06-26 16:53:43,327 Epoch[24] Batch [1370]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109771,	
2017-06-26 16:53:49,674 Epoch[24] Batch [1380]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.109807,	
2017-06-26 16:53:56,280 Epoch[24] Batch [1390]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.109873,	
2017-06-26 16:54:02,528 Epoch[24] Batch [1400]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.109885,	
2017-06-26 16:54:09,122 Epoch[24] Batch [1410]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.109839,	
2017-06-26 16:54:15,816 Epoch[24] Batch [1420]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.109804,	
2017-06-26 16:54:22,575 Epoch[24] Batch [1430]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.109820,	
2017-06-26 16:54:29,413 Epoch[24] Batch [1440]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.109779,	
2017-06-26 16:54:35,466 Epoch[24] Batch [1450]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.109757,	
2017-06-26 16:54:41,415 Epoch[24] Batch [1460]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.109775,	
2017-06-26 16:54:47,633 Epoch[24] Batch [1470]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.109801,	
2017-06-26 16:54:53,566 Epoch[24] Batch [1480]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.109931,	
2017-06-26 16:54:57,038 Epoch[24] Train-FCNLogLoss=0.109915
2017-06-26 16:54:57,038 Epoch[24] Time cost=929.273
2017-06-26 16:54:57,866 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0025.params"
2017-06-26 16:55:01,266 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0025.states"
2017-06-26 16:55:07,656 Epoch[25] Batch [10]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.100211,	
2017-06-26 16:55:13,638 Epoch[25] Batch [20]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.100932,	
2017-06-26 16:55:19,876 Epoch[25] Batch [30]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.106280,	
2017-06-26 16:55:26,370 Epoch[25] Batch [40]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.106001,	
2017-06-26 16:55:32,771 Epoch[25] Batch [50]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.106559,	
2017-06-26 16:55:39,408 Epoch[25] Batch [60]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.106753,	
2017-06-26 16:55:45,886 Epoch[25] Batch [70]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.106817,	
2017-06-26 16:55:52,584 Epoch[25] Batch [80]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.106111,	
2017-06-26 16:55:59,602 Epoch[25] Batch [90]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.105794,	
2017-06-26 16:56:06,458 Epoch[25] Batch [100]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.106127,	
2017-06-26 16:56:13,287 Epoch[25] Batch [110]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.106898,	
2017-06-26 16:56:20,076 Epoch[25] Batch [120]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.106407,	
2017-06-26 16:56:27,097 Epoch[25] Batch [130]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.107105,	
2017-06-26 16:56:34,185 Epoch[25] Batch [140]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.107320,	
2017-06-26 16:56:41,351 Epoch[25] Batch [150]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.108686,	
2017-06-26 16:56:48,162 Epoch[25] Batch [160]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.109023,	
2017-06-26 16:56:55,025 Epoch[25] Batch [170]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.109521,	
2017-06-26 16:57:01,277 Epoch[25] Batch [180]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.109085,	
2017-06-26 16:57:07,150 Epoch[25] Batch [190]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.109682,	
2017-06-26 16:57:12,860 Epoch[25] Batch [200]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.109610,	
2017-06-26 16:57:18,708 Epoch[25] Batch [210]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.109197,	
2017-06-26 16:57:24,577 Epoch[25] Batch [220]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.109473,	
2017-06-26 16:57:30,540 Epoch[25] Batch [230]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.109690,	
2017-06-26 16:57:36,047 Epoch[25] Batch [240]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.109900,	
2017-06-26 16:57:42,886 Epoch[25] Batch [250]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.109438,	
2017-06-26 16:57:49,550 Epoch[25] Batch [260]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.109463,	
2017-06-26 16:57:56,430 Epoch[25] Batch [270]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.109248,	
2017-06-26 16:58:02,960 Epoch[25] Batch [280]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.109167,	
2017-06-26 16:58:09,152 Epoch[25] Batch [290]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.108931,	
2017-06-26 16:58:15,827 Epoch[25] Batch [300]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.108734,	
2017-06-26 16:58:22,319 Epoch[25] Batch [310]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.108854,	
2017-06-26 16:58:28,633 Epoch[25] Batch [320]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.108743,	
2017-06-26 16:58:35,167 Epoch[25] Batch [330]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.108539,	
2017-06-26 16:58:41,829 Epoch[25] Batch [340]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.108713,	
2017-06-26 16:58:48,527 Epoch[25] Batch [350]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.108361,	
2017-06-26 16:58:54,967 Epoch[25] Batch [360]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.108472,	
2017-06-26 16:59:01,716 Epoch[25] Batch [370]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.108563,	
2017-06-26 16:59:08,157 Epoch[25] Batch [380]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.108579,	
2017-06-26 16:59:13,683 Epoch[25] Batch [390]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.108410,	
2017-06-26 16:59:19,473 Epoch[25] Batch [400]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.108289,	
2017-06-26 16:59:25,305 Epoch[25] Batch [410]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.108012,	
2017-06-26 16:59:31,198 Epoch[25] Batch [420]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.107983,	
2017-06-26 16:59:36,762 Epoch[25] Batch [430]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.107863,	
2017-06-26 16:59:42,528 Epoch[25] Batch [440]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.108063,	
2017-06-26 16:59:49,138 Epoch[25] Batch [450]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.108028,	
2017-06-26 16:59:55,650 Epoch[25] Batch [460]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.108294,	
2017-06-26 17:00:02,902 Epoch[25] Batch [470]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.108479,	
2017-06-26 17:00:09,748 Epoch[25] Batch [480]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.108477,	
2017-06-26 17:00:16,060 Epoch[25] Batch [490]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.108412,	
2017-06-26 17:00:22,921 Epoch[25] Batch [500]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.108571,	
2017-06-26 17:00:29,595 Epoch[25] Batch [510]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.108636,	
2017-06-26 17:00:36,480 Epoch[25] Batch [520]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.108396,	
2017-06-26 17:00:43,471 Epoch[25] Batch [530]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.108588,	
2017-06-26 17:00:49,714 Epoch[25] Batch [540]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.108389,	
2017-06-26 17:00:55,727 Epoch[25] Batch [550]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.108372,	
2017-06-26 17:01:01,716 Epoch[25] Batch [560]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.108242,	
2017-06-26 17:01:07,774 Epoch[25] Batch [570]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108031,	
2017-06-26 17:01:13,934 Epoch[25] Batch [580]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.107895,	
2017-06-26 17:01:20,098 Epoch[25] Batch [590]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.107701,	
2017-06-26 17:01:26,280 Epoch[25] Batch [600]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.107711,	
2017-06-26 17:01:32,409 Epoch[25] Batch [610]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.107819,	
2017-06-26 17:01:38,482 Epoch[25] Batch [620]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107885,	
2017-06-26 17:01:44,643 Epoch[25] Batch [630]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.107809,	
2017-06-26 17:01:50,723 Epoch[25] Batch [640]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107774,	
2017-06-26 17:01:56,736 Epoch[25] Batch [650]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107783,	
2017-06-26 17:02:02,586 Epoch[25] Batch [660]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.107727,	
2017-06-26 17:02:08,552 Epoch[25] Batch [670]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.107666,	
2017-06-26 17:02:14,444 Epoch[25] Batch [680]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.107500,	
2017-06-26 17:02:20,665 Epoch[25] Batch [690]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.107402,	
2017-06-26 17:02:26,767 Epoch[25] Batch [700]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107517,	
2017-06-26 17:02:32,940 Epoch[25] Batch [710]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.107393,	
2017-06-26 17:02:39,268 Epoch[25] Batch [720]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.107338,	
2017-06-26 17:02:45,996 Epoch[25] Batch [730]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.107391,	
2017-06-26 17:02:52,154 Epoch[25] Batch [740]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.107339,	
2017-06-26 17:02:58,495 Epoch[25] Batch [750]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.107311,	
2017-06-26 17:03:05,137 Epoch[25] Batch [760]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.107209,	
2017-06-26 17:03:11,652 Epoch[25] Batch [770]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.107133,	
2017-06-26 17:03:17,951 Epoch[25] Batch [780]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.107075,	
2017-06-26 17:03:24,200 Epoch[25] Batch [790]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.106947,	
2017-06-26 17:03:30,657 Epoch[25] Batch [800]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.107043,	
2017-06-26 17:03:36,524 Epoch[25] Batch [810]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.107149,	
2017-06-26 17:03:42,592 Epoch[25] Batch [820]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.107013,	
2017-06-26 17:03:48,820 Epoch[25] Batch [830]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.106939,	
2017-06-26 17:03:54,906 Epoch[25] Batch [840]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.106917,	
2017-06-26 17:04:01,161 Epoch[25] Batch [850]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.106909,	
2017-06-26 17:04:07,555 Epoch[25] Batch [860]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.106977,	
2017-06-26 17:04:13,847 Epoch[25] Batch [870]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.106952,	
2017-06-26 17:04:19,804 Epoch[25] Batch [880]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.106997,	
2017-06-26 17:04:26,492 Epoch[25] Batch [890]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.106996,	
2017-06-26 17:04:33,475 Epoch[25] Batch [900]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.107172,	
2017-06-26 17:04:39,390 Epoch[25] Batch [910]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107306,	
2017-06-26 17:04:46,003 Epoch[25] Batch [920]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.107491,	
2017-06-26 17:04:52,376 Epoch[25] Batch [930]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.107690,	
2017-06-26 17:04:58,892 Epoch[25] Batch [940]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.107550,	
2017-06-26 17:05:05,323 Epoch[25] Batch [950]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.107558,	
2017-06-26 17:05:11,810 Epoch[25] Batch [960]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.107603,	
2017-06-26 17:05:18,130 Epoch[25] Batch [970]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.107540,	
2017-06-26 17:05:24,791 Epoch[25] Batch [980]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.107591,	
2017-06-26 17:05:30,672 Epoch[25] Batch [990]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.107843,	
2017-06-26 17:05:36,456 Epoch[25] Batch [1000]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.107757,	
2017-06-26 17:05:42,315 Epoch[25] Batch [1010]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.107916,	
2017-06-26 17:05:48,311 Epoch[25] Batch [1020]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.107866,	
2017-06-26 17:05:53,974 Epoch[25] Batch [1030]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.107980,	
2017-06-26 17:06:00,215 Epoch[25] Batch [1040]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.107986,	
2017-06-26 17:06:06,177 Epoch[25] Batch [1050]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.107927,	
2017-06-26 17:06:11,886 Epoch[25] Batch [1060]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.107841,	
2017-06-26 17:06:18,173 Epoch[25] Batch [1070]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.107787,	
2017-06-26 17:06:24,598 Epoch[25] Batch [1080]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.107821,	
2017-06-26 17:06:31,205 Epoch[25] Batch [1090]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.107781,	
2017-06-26 17:06:37,251 Epoch[25] Batch [1100]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.107719,	
2017-06-26 17:06:43,211 Epoch[25] Batch [1110]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.107674,	
2017-06-26 17:06:49,470 Epoch[25] Batch [1120]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.107631,	
2017-06-26 17:06:55,656 Epoch[25] Batch [1130]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.107686,	
2017-06-26 17:07:01,598 Epoch[25] Batch [1140]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.107601,	
2017-06-26 17:07:08,156 Epoch[25] Batch [1150]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.107606,	
2017-06-26 17:07:14,640 Epoch[25] Batch [1160]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.107686,	
2017-06-26 17:07:20,956 Epoch[25] Batch [1170]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.107794,	
2017-06-26 17:07:27,137 Epoch[25] Batch [1180]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.107712,	
2017-06-26 17:07:33,229 Epoch[25] Batch [1190]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107572,	
2017-06-26 17:07:39,740 Epoch[25] Batch [1200]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.107684,	
2017-06-26 17:07:45,423 Epoch[25] Batch [1210]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.107707,	
2017-06-26 17:07:50,874 Epoch[25] Batch [1220]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.107735,	
2017-06-26 17:07:56,119 Epoch[25] Batch [1230]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.107721,	
2017-06-26 17:08:01,504 Epoch[25] Batch [1240]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.107716,	
2017-06-26 17:08:06,896 Epoch[25] Batch [1250]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.107711,	
2017-06-26 17:08:12,339 Epoch[25] Batch [1260]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.107640,	
2017-06-26 17:08:17,513 Epoch[25] Batch [1270]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.107631,	
2017-06-26 17:08:23,399 Epoch[25] Batch [1280]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.107622,	
2017-06-26 17:08:29,318 Epoch[25] Batch [1290]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.107662,	
2017-06-26 17:08:34,893 Epoch[25] Batch [1300]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.107533,	
2017-06-26 17:08:41,038 Epoch[25] Batch [1310]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.107475,	
2017-06-26 17:08:46,863 Epoch[25] Batch [1320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.107495,	
2017-06-26 17:08:53,076 Epoch[25] Batch [1330]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.107472,	
2017-06-26 17:08:59,328 Epoch[25] Batch [1340]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.107546,	
2017-06-26 17:09:05,957 Epoch[25] Batch [1350]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.107582,	
2017-06-26 17:09:12,141 Epoch[25] Batch [1360]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.107564,	
2017-06-26 17:09:18,534 Epoch[25] Batch [1370]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.107536,	
2017-06-26 17:09:24,749 Epoch[25] Batch [1380]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.107476,	
2017-06-26 17:09:31,238 Epoch[25] Batch [1390]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.107503,	
2017-06-26 17:09:37,441 Epoch[25] Batch [1400]	Speed: 6.45 samples/sec	Train-FCNLogLoss=0.107437,	
2017-06-26 17:09:43,930 Epoch[25] Batch [1410]	Speed: 6.16 samples/sec	Train-FCNLogLoss=0.107372,	
2017-06-26 17:09:49,955 Epoch[25] Batch [1420]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.107414,	
2017-06-26 17:09:56,260 Epoch[25] Batch [1430]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.107375,	
2017-06-26 17:10:02,865 Epoch[25] Batch [1440]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.107354,	
2017-06-26 17:10:08,814 Epoch[25] Batch [1450]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.107311,	
2017-06-26 17:10:14,985 Epoch[25] Batch [1460]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.107251,	
2017-06-26 17:10:21,613 Epoch[25] Batch [1470]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.107242,	
2017-06-26 17:10:28,115 Epoch[25] Batch [1480]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.107197,	
2017-06-26 17:10:31,871 Epoch[25] Train-FCNLogLoss=0.107234
2017-06-26 17:10:31,871 Epoch[25] Time cost=930.604
2017-06-26 17:10:32,858 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0026.params"
2017-06-26 17:10:36,412 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0026.states"
2017-06-26 17:10:43,620 Epoch[26] Batch [10]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.106503,	
2017-06-26 17:10:50,088 Epoch[26] Batch [20]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.102552,	
2017-06-26 17:10:56,278 Epoch[26] Batch [30]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.103314,	
2017-06-26 17:11:02,208 Epoch[26] Batch [40]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.101532,	
2017-06-26 17:11:08,339 Epoch[26] Batch [50]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.099389,	
2017-06-26 17:11:15,158 Epoch[26] Batch [60]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.101109,	
2017-06-26 17:11:21,304 Epoch[26] Batch [70]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.102494,	
2017-06-26 17:11:27,675 Epoch[26] Batch [80]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.103042,	
2017-06-26 17:11:33,469 Epoch[26] Batch [90]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103035,	
2017-06-26 17:11:39,916 Epoch[26] Batch [100]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.102415,	
2017-06-26 17:11:46,059 Epoch[26] Batch [110]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.102199,	
2017-06-26 17:11:52,634 Epoch[26] Batch [120]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.101649,	
2017-06-26 17:11:59,141 Epoch[26] Batch [130]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.102153,	
2017-06-26 17:12:05,660 Epoch[26] Batch [140]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.101202,	
2017-06-26 17:12:11,826 Epoch[26] Batch [150]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.101330,	
2017-06-26 17:12:18,498 Epoch[26] Batch [160]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.101360,	
2017-06-26 17:12:24,716 Epoch[26] Batch [170]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.101178,	
2017-06-26 17:12:30,831 Epoch[26] Batch [180]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100905,	
2017-06-26 17:12:36,943 Epoch[26] Batch [190]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101679,	
2017-06-26 17:12:43,180 Epoch[26] Batch [200]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.102092,	
2017-06-26 17:12:49,268 Epoch[26] Batch [210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102382,	
2017-06-26 17:12:55,377 Epoch[26] Batch [220]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102410,	
2017-06-26 17:13:01,467 Epoch[26] Batch [230]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102391,	
2017-06-26 17:13:07,647 Epoch[26] Batch [240]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.102605,	
2017-06-26 17:13:13,760 Epoch[26] Batch [250]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102607,	
2017-06-26 17:13:19,895 Epoch[26] Batch [260]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102501,	
2017-06-26 17:13:25,855 Epoch[26] Batch [270]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.102646,	
2017-06-26 17:13:31,926 Epoch[26] Batch [280]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102449,	
2017-06-26 17:13:38,056 Epoch[26] Batch [290]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102415,	
2017-06-26 17:13:44,538 Epoch[26] Batch [300]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.102549,	
2017-06-26 17:13:51,243 Epoch[26] Batch [310]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.103069,	
2017-06-26 17:13:58,195 Epoch[26] Batch [320]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.102930,	
2017-06-26 17:14:05,364 Epoch[26] Batch [330]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.102932,	
2017-06-26 17:14:12,362 Epoch[26] Batch [340]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.102702,	
2017-06-26 17:14:19,588 Epoch[26] Batch [350]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.102803,	
2017-06-26 17:14:26,423 Epoch[26] Batch [360]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.102798,	
2017-06-26 17:14:32,545 Epoch[26] Batch [370]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103025,	
2017-06-26 17:14:38,367 Epoch[26] Batch [380]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.103243,	
2017-06-26 17:14:44,148 Epoch[26] Batch [390]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.103373,	
2017-06-26 17:14:50,188 Epoch[26] Batch [400]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103702,	
2017-06-26 17:14:56,247 Epoch[26] Batch [410]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103692,	
2017-06-26 17:15:02,303 Epoch[26] Batch [420]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103723,	
2017-06-26 17:15:08,873 Epoch[26] Batch [430]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.104479,	
2017-06-26 17:15:15,449 Epoch[26] Batch [440]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.104499,	
2017-06-26 17:15:22,249 Epoch[26] Batch [450]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.104532,	
2017-06-26 17:15:28,937 Epoch[26] Batch [460]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.104878,	
2017-06-26 17:15:35,756 Epoch[26] Batch [470]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.104917,	
2017-06-26 17:15:42,266 Epoch[26] Batch [480]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.104977,	
2017-06-26 17:15:49,320 Epoch[26] Batch [490]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.104849,	
2017-06-26 17:15:56,241 Epoch[26] Batch [500]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.104758,	
2017-06-26 17:16:03,175 Epoch[26] Batch [510]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.104498,	
2017-06-26 17:16:10,009 Epoch[26] Batch [520]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.104624,	
2017-06-26 17:16:16,402 Epoch[26] Batch [530]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.104450,	
2017-06-26 17:16:22,421 Epoch[26] Batch [540]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.104364,	
2017-06-26 17:16:28,474 Epoch[26] Batch [550]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.104300,	
2017-06-26 17:16:34,714 Epoch[26] Batch [560]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.104291,	
2017-06-26 17:16:40,848 Epoch[26] Batch [570]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.104199,	
2017-06-26 17:16:47,148 Epoch[26] Batch [580]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.104151,	
2017-06-26 17:16:53,244 Epoch[26] Batch [590]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.104361,	
2017-06-26 17:16:59,378 Epoch[26] Batch [600]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.104287,	
2017-06-26 17:17:05,334 Epoch[26] Batch [610]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104305,	
2017-06-26 17:17:11,413 Epoch[26] Batch [620]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.104163,	
2017-06-26 17:17:17,442 Epoch[26] Batch [630]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.104082,	
2017-06-26 17:17:23,635 Epoch[26] Batch [640]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.103960,	
2017-06-26 17:17:30,937 Epoch[26] Batch [650]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.103838,	
2017-06-26 17:17:37,625 Epoch[26] Batch [660]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.103881,	
2017-06-26 17:17:44,527 Epoch[26] Batch [670]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.103985,	
2017-06-26 17:17:51,507 Epoch[26] Batch [680]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.103958,	
2017-06-26 17:17:58,668 Epoch[26] Batch [690]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.104102,	
2017-06-26 17:18:05,572 Epoch[26] Batch [700]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.104168,	
2017-06-26 17:18:12,309 Epoch[26] Batch [710]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.104166,	
2017-06-26 17:18:19,694 Epoch[26] Batch [720]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.104226,	
2017-06-26 17:18:26,667 Epoch[26] Batch [730]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.104208,	
2017-06-26 17:18:33,876 Epoch[26] Batch [740]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.104091,	
2017-06-26 17:18:40,969 Epoch[26] Batch [750]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.104405,	
2017-06-26 17:18:48,528 Epoch[26] Batch [760]	Speed: 5.29 samples/sec	Train-FCNLogLoss=0.104476,	
2017-06-26 17:18:55,732 Epoch[26] Batch [770]	Speed: 5.55 samples/sec	Train-FCNLogLoss=0.104477,	
2017-06-26 17:19:02,655 Epoch[26] Batch [780]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.104545,	
2017-06-26 17:19:09,398 Epoch[26] Batch [790]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.104626,	
2017-06-26 17:19:15,899 Epoch[26] Batch [800]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.104764,	
2017-06-26 17:19:22,479 Epoch[26] Batch [810]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.104771,	
2017-06-26 17:19:29,370 Epoch[26] Batch [820]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.104710,	
2017-06-26 17:19:36,047 Epoch[26] Batch [830]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.104872,	
2017-06-26 17:19:43,182 Epoch[26] Batch [840]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.104913,	
2017-06-26 17:19:49,524 Epoch[26] Batch [850]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.105030,	
2017-06-26 17:19:55,559 Epoch[26] Batch [860]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.105011,	
2017-06-26 17:20:02,215 Epoch[26] Batch [870]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.104974,	
2017-06-26 17:20:08,962 Epoch[26] Batch [880]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.104919,	
2017-06-26 17:20:15,747 Epoch[26] Batch [890]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.104938,	
2017-06-26 17:20:22,638 Epoch[26] Batch [900]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.104994,	
2017-06-26 17:20:29,341 Epoch[26] Batch [910]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.105056,	
2017-06-26 17:20:36,219 Epoch[26] Batch [920]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.105055,	
2017-06-26 17:20:43,394 Epoch[26] Batch [930]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.105112,	
2017-06-26 17:20:50,346 Epoch[26] Batch [940]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.105180,	
2017-06-26 17:20:56,954 Epoch[26] Batch [950]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.105217,	
2017-06-26 17:21:03,738 Epoch[26] Batch [960]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.105263,	
2017-06-26 17:21:10,902 Epoch[26] Batch [970]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.105433,	
2017-06-26 17:21:17,946 Epoch[26] Batch [980]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.105433,	
2017-06-26 17:21:25,262 Epoch[26] Batch [990]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.105388,	
2017-06-26 17:21:32,444 Epoch[26] Batch [1000]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.105437,	
2017-06-26 17:21:39,421 Epoch[26] Batch [1010]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.105493,	
2017-06-26 17:21:46,415 Epoch[26] Batch [1020]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.105532,	
2017-06-26 17:21:53,386 Epoch[26] Batch [1030]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.105594,	
2017-06-26 17:22:00,364 Epoch[26] Batch [1040]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.105601,	
2017-06-26 17:22:07,349 Epoch[26] Batch [1050]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.105519,	
2017-06-26 17:22:14,537 Epoch[26] Batch [1060]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.105453,	
2017-06-26 17:22:21,499 Epoch[26] Batch [1070]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.105467,	
2017-06-26 17:22:28,215 Epoch[26] Batch [1080]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.105419,	
2017-06-26 17:22:34,897 Epoch[26] Batch [1090]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.105397,	
2017-06-26 17:22:41,911 Epoch[26] Batch [1100]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.105443,	
2017-06-26 17:22:48,598 Epoch[26] Batch [1110]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.105397,	
2017-06-26 17:22:55,373 Epoch[26] Batch [1120]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.105420,	
2017-06-26 17:23:02,176 Epoch[26] Batch [1130]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.105401,	
2017-06-26 17:23:08,692 Epoch[26] Batch [1140]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.105386,	
2017-06-26 17:23:15,533 Epoch[26] Batch [1150]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.105364,	
2017-06-26 17:23:22,004 Epoch[26] Batch [1160]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.105409,	
2017-06-26 17:23:28,813 Epoch[26] Batch [1170]	Speed: 5.88 samples/sec	Train-FCNLogLoss=0.105507,	
2017-06-26 17:23:35,573 Epoch[26] Batch [1180]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.105486,	
2017-06-26 17:23:42,704 Epoch[26] Batch [1190]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.105522,	
2017-06-26 17:23:49,923 Epoch[26] Batch [1200]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.105486,	
2017-06-26 17:23:56,714 Epoch[26] Batch [1210]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.105508,	
2017-06-26 17:24:03,721 Epoch[26] Batch [1220]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.105456,	
2017-06-26 17:24:10,516 Epoch[26] Batch [1230]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.105576,	
2017-06-26 17:24:17,509 Epoch[26] Batch [1240]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.105584,	
2017-06-26 17:24:24,485 Epoch[26] Batch [1250]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.105597,	
2017-06-26 17:24:30,482 Epoch[26] Batch [1260]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.105525,	
2017-06-26 17:24:36,114 Epoch[26] Batch [1270]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.105474,	
2017-06-26 17:24:41,795 Epoch[26] Batch [1280]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.105391,	
2017-06-26 17:24:47,434 Epoch[26] Batch [1290]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.105371,	
2017-06-26 17:24:53,302 Epoch[26] Batch [1300]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.105326,	
2017-06-26 17:24:59,263 Epoch[26] Batch [1310]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.105400,	
2017-06-26 17:25:05,053 Epoch[26] Batch [1320]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.105350,	
2017-06-26 17:25:11,114 Epoch[26] Batch [1330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.105372,	
2017-06-26 17:25:16,994 Epoch[26] Batch [1340]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.105338,	
2017-06-26 17:25:23,590 Epoch[26] Batch [1350]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.105334,	
2017-06-26 17:25:29,849 Epoch[26] Batch [1360]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.105329,	
2017-06-26 17:25:36,124 Epoch[26] Batch [1370]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.105373,	
2017-06-26 17:25:42,278 Epoch[26] Batch [1380]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.105399,	
2017-06-26 17:25:48,013 Epoch[26] Batch [1390]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.105510,	
2017-06-26 17:25:54,455 Epoch[26] Batch [1400]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.105491,	
2017-06-26 17:26:00,793 Epoch[26] Batch [1410]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.105493,	
2017-06-26 17:26:07,187 Epoch[26] Batch [1420]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.105529,	
2017-06-26 17:26:13,744 Epoch[26] Batch [1430]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.105433,	
2017-06-26 17:26:20,474 Epoch[26] Batch [1440]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.105417,	
2017-06-26 17:26:27,007 Epoch[26] Batch [1450]	Speed: 6.12 samples/sec	Train-FCNLogLoss=0.105519,	
2017-06-26 17:26:33,784 Epoch[26] Batch [1460]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.105604,	
2017-06-26 17:26:40,223 Epoch[26] Batch [1470]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.105612,	
2017-06-26 17:26:45,902 Epoch[26] Batch [1480]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.105601,	
2017-06-26 17:26:49,096 Epoch[26] Train-FCNLogLoss=0.105576
2017-06-26 17:26:49,096 Epoch[26] Time cost=972.684
2017-06-26 17:26:49,847 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0027.params"
2017-06-26 17:26:51,890 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0027.states"
2017-06-26 17:26:57,771 Epoch[27] Batch [10]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.095837,	
2017-06-26 17:27:03,219 Epoch[27] Batch [20]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.098437,	
2017-06-26 17:27:08,441 Epoch[27] Batch [30]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.100162,	
2017-06-26 17:27:14,137 Epoch[27] Batch [40]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.100162,	
2017-06-26 17:27:19,934 Epoch[27] Batch [50]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.098916,	
2017-06-26 17:27:26,038 Epoch[27] Batch [60]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101125,	
2017-06-26 17:27:32,265 Epoch[27] Batch [70]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.100487,	
2017-06-26 17:27:38,693 Epoch[27] Batch [80]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.101364,	
2017-06-26 17:27:44,924 Epoch[27] Batch [90]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.101464,	
2017-06-26 17:27:51,438 Epoch[27] Batch [100]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.101160,	
2017-06-26 17:27:57,342 Epoch[27] Batch [110]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.101114,	
2017-06-26 17:28:03,857 Epoch[27] Batch [120]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.101617,	
2017-06-26 17:28:10,124 Epoch[27] Batch [130]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.101106,	
2017-06-26 17:28:16,630 Epoch[27] Batch [140]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.101401,	
2017-06-26 17:28:23,172 Epoch[27] Batch [150]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.102434,	
2017-06-26 17:28:29,795 Epoch[27] Batch [160]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.102390,	
2017-06-26 17:28:36,372 Epoch[27] Batch [170]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.103388,	
2017-06-26 17:28:43,063 Epoch[27] Batch [180]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.103573,	
2017-06-26 17:28:49,639 Epoch[27] Batch [190]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.103576,	
2017-06-26 17:28:55,698 Epoch[27] Batch [200]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103616,	
2017-06-26 17:29:01,910 Epoch[27] Batch [210]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.103491,	
2017-06-26 17:29:07,872 Epoch[27] Batch [220]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.103677,	
2017-06-26 17:29:13,889 Epoch[27] Batch [230]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.104094,	
2017-06-26 17:29:19,840 Epoch[27] Batch [240]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.104312,	
2017-06-26 17:29:25,616 Epoch[27] Batch [250]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.104288,	
2017-06-26 17:29:32,634 Epoch[27] Batch [260]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.104485,	
2017-06-26 17:29:39,995 Epoch[27] Batch [270]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.104772,	
2017-06-26 17:29:47,388 Epoch[27] Batch [280]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.104625,	
2017-06-26 17:29:54,830 Epoch[27] Batch [290]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.104945,	
2017-06-26 17:30:02,139 Epoch[27] Batch [300]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.104714,	
2017-06-26 17:30:09,582 Epoch[27] Batch [310]	Speed: 5.37 samples/sec	Train-FCNLogLoss=0.105028,	
2017-06-26 17:30:16,910 Epoch[27] Batch [320]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.104912,	
2017-06-26 17:30:24,179 Epoch[27] Batch [330]	Speed: 5.50 samples/sec	Train-FCNLogLoss=0.104919,	
2017-06-26 17:30:31,355 Epoch[27] Batch [340]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.104850,	
2017-06-26 17:30:38,480 Epoch[27] Batch [350]	Speed: 5.61 samples/sec	Train-FCNLogLoss=0.104655,	
2017-06-26 17:30:45,669 Epoch[27] Batch [360]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.104618,	
2017-06-26 17:30:53,100 Epoch[27] Batch [370]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.104168,	
2017-06-26 17:31:00,406 Epoch[27] Batch [380]	Speed: 5.48 samples/sec	Train-FCNLogLoss=0.104415,	
2017-06-26 17:31:06,999 Epoch[27] Batch [390]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.104253,	
2017-06-26 17:31:13,075 Epoch[27] Batch [400]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.104367,	
2017-06-26 17:31:19,194 Epoch[27] Batch [410]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.104205,	
2017-06-26 17:31:25,308 Epoch[27] Batch [420]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103900,	
2017-06-26 17:31:31,377 Epoch[27] Batch [430]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103942,	
2017-06-26 17:31:37,544 Epoch[27] Batch [440]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.103832,	
2017-06-26 17:31:43,665 Epoch[27] Batch [450]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.104077,	
2017-06-26 17:31:49,853 Epoch[27] Batch [460]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.104046,	
2017-06-26 17:31:56,030 Epoch[27] Batch [470]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.104149,	
2017-06-26 17:32:02,350 Epoch[27] Batch [480]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.104214,	
2017-06-26 17:32:08,695 Epoch[27] Batch [490]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.104026,	
2017-06-26 17:32:15,388 Epoch[27] Batch [500]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.104136,	
2017-06-26 17:32:22,803 Epoch[27] Batch [510]	Speed: 5.39 samples/sec	Train-FCNLogLoss=0.103906,	
2017-06-26 17:32:30,195 Epoch[27] Batch [520]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.103679,	
2017-06-26 17:32:37,588 Epoch[27] Batch [530]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.103651,	
2017-06-26 17:32:45,137 Epoch[27] Batch [540]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.103621,	
2017-06-26 17:32:52,193 Epoch[27] Batch [550]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.103843,	
2017-06-26 17:32:59,182 Epoch[27] Batch [560]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.103918,	
2017-06-26 17:33:06,612 Epoch[27] Batch [570]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.103930,	
2017-06-26 17:33:14,124 Epoch[27] Batch [580]	Speed: 5.32 samples/sec	Train-FCNLogLoss=0.104176,	
2017-06-26 17:33:21,669 Epoch[27] Batch [590]	Speed: 5.30 samples/sec	Train-FCNLogLoss=0.104204,	
2017-06-26 17:33:29,109 Epoch[27] Batch [600]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.104051,	
2017-06-26 17:33:36,284 Epoch[27] Batch [610]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.103959,	
2017-06-26 17:33:41,995 Epoch[27] Batch [620]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.103938,	
2017-06-26 17:33:47,809 Epoch[27] Batch [630]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.103867,	
2017-06-26 17:33:53,606 Epoch[27] Batch [640]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.103980,	
2017-06-26 17:33:59,361 Epoch[27] Batch [650]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.103858,	
2017-06-26 17:34:05,116 Epoch[27] Batch [660]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.103842,	
2017-06-26 17:34:10,844 Epoch[27] Batch [670]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.103747,	
2017-06-26 17:34:16,415 Epoch[27] Batch [680]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.103826,	
2017-06-26 17:34:22,510 Epoch[27] Batch [690]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103860,	
2017-06-26 17:34:28,104 Epoch[27] Batch [700]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.103780,	
2017-06-26 17:34:33,598 Epoch[27] Batch [710]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.103928,	
2017-06-26 17:34:39,652 Epoch[27] Batch [720]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.104010,	
2017-06-26 17:34:45,739 Epoch[27] Batch [730]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.104181,	
2017-06-26 17:34:51,815 Epoch[27] Batch [740]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.104193,	
2017-06-26 17:34:57,926 Epoch[27] Batch [750]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104142,	
2017-06-26 17:35:03,959 Epoch[27] Batch [760]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.104204,	
2017-06-26 17:35:10,115 Epoch[27] Batch [770]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.104260,	
2017-06-26 17:35:16,148 Epoch[27] Batch [780]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.104260,	
2017-06-26 17:35:22,254 Epoch[27] Batch [790]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.104499,	
2017-06-26 17:35:28,158 Epoch[27] Batch [800]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.104403,	
2017-06-26 17:35:34,259 Epoch[27] Batch [810]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.104366,	
2017-06-26 17:35:40,609 Epoch[27] Batch [820]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.104382,	
2017-06-26 17:35:47,130 Epoch[27] Batch [830]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.104350,	
2017-06-26 17:35:53,693 Epoch[27] Batch [840]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.104333,	
2017-06-26 17:36:00,735 Epoch[27] Batch [850]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.104313,	
2017-06-26 17:36:07,751 Epoch[27] Batch [860]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.104221,	
2017-06-26 17:36:14,904 Epoch[27] Batch [870]	Speed: 5.59 samples/sec	Train-FCNLogLoss=0.104159,	
2017-06-26 17:36:22,259 Epoch[27] Batch [880]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.104202,	
2017-06-26 17:36:29,716 Epoch[27] Batch [890]	Speed: 5.36 samples/sec	Train-FCNLogLoss=0.104379,	
2017-06-26 17:36:36,719 Epoch[27] Batch [900]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.104411,	
2017-06-26 17:36:43,711 Epoch[27] Batch [910]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.104493,	
2017-06-26 17:36:50,763 Epoch[27] Batch [920]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.104478,	
2017-06-26 17:36:57,743 Epoch[27] Batch [930]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.104455,	
2017-06-26 17:37:04,979 Epoch[27] Batch [940]	Speed: 5.53 samples/sec	Train-FCNLogLoss=0.104367,	
2017-06-26 17:37:11,932 Epoch[27] Batch [950]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.104384,	
2017-06-26 17:37:18,961 Epoch[27] Batch [960]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.104462,	
2017-06-26 17:37:26,178 Epoch[27] Batch [970]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.104464,	
2017-06-26 17:37:32,878 Epoch[27] Batch [980]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.104455,	
2017-06-26 17:37:39,948 Epoch[27] Batch [990]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.104444,	
2017-06-26 17:37:46,970 Epoch[27] Batch [1000]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.104612,	
2017-06-26 17:37:53,715 Epoch[27] Batch [1010]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.104720,	
2017-06-26 17:38:00,907 Epoch[27] Batch [1020]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.104752,	
2017-06-26 17:38:07,783 Epoch[27] Batch [1030]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.104637,	
2017-06-26 17:38:14,758 Epoch[27] Batch [1040]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.104596,	
2017-06-26 17:38:21,593 Epoch[27] Batch [1050]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.104614,	
2017-06-26 17:38:28,858 Epoch[27] Batch [1060]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.104622,	
2017-06-26 17:38:35,804 Epoch[27] Batch [1070]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.104678,	
2017-06-26 17:38:43,116 Epoch[27] Batch [1080]	Speed: 5.47 samples/sec	Train-FCNLogLoss=0.104667,	
2017-06-26 17:38:50,613 Epoch[27] Batch [1090]	Speed: 5.34 samples/sec	Train-FCNLogLoss=0.104753,	
2017-06-26 17:38:58,217 Epoch[27] Batch [1100]	Speed: 5.26 samples/sec	Train-FCNLogLoss=0.104764,	
2017-06-26 17:39:05,202 Epoch[27] Batch [1110]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.104707,	
2017-06-26 17:39:12,384 Epoch[27] Batch [1120]	Speed: 5.57 samples/sec	Train-FCNLogLoss=0.104694,	
2017-06-26 17:39:19,239 Epoch[27] Batch [1130]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.104604,	
2017-06-26 17:39:26,227 Epoch[27] Batch [1140]	Speed: 5.72 samples/sec	Train-FCNLogLoss=0.104637,	
2017-06-26 17:39:33,422 Epoch[27] Batch [1150]	Speed: 5.56 samples/sec	Train-FCNLogLoss=0.104591,	
2017-06-26 17:39:40,339 Epoch[27] Batch [1160]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.104621,	
2017-06-26 17:39:47,413 Epoch[27] Batch [1170]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.104659,	
2017-06-26 17:39:54,198 Epoch[27] Batch [1180]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.104562,	
2017-06-26 17:40:01,064 Epoch[27] Batch [1190]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.104400,	
2017-06-26 17:40:08,116 Epoch[27] Batch [1200]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.104544,	
2017-06-26 17:40:14,843 Epoch[27] Batch [1210]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.104588,	
2017-06-26 17:40:22,007 Epoch[27] Batch [1220]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.104603,	
2017-06-26 17:40:29,481 Epoch[27] Batch [1230]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.104523,	
2017-06-26 17:40:36,431 Epoch[27] Batch [1240]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.104529,	
2017-06-26 17:40:43,497 Epoch[27] Batch [1250]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.104509,	
2017-06-26 17:40:50,533 Epoch[27] Batch [1260]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.104510,	
2017-06-26 17:40:56,923 Epoch[27] Batch [1270]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.104467,	
2017-06-26 17:41:03,854 Epoch[27] Batch [1280]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.104466,	
2017-06-26 17:41:10,784 Epoch[27] Batch [1290]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.104454,	
2017-06-26 17:41:17,643 Epoch[27] Batch [1300]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.104454,	
2017-06-26 17:41:24,568 Epoch[27] Batch [1310]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.104486,	
2017-06-26 17:41:31,461 Epoch[27] Batch [1320]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.104451,	
2017-06-26 17:41:38,477 Epoch[27] Batch [1330]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.104450,	
2017-06-26 17:41:45,448 Epoch[27] Batch [1340]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.104497,	
2017-06-26 17:41:52,316 Epoch[27] Batch [1350]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.104466,	
2017-06-26 17:41:59,406 Epoch[27] Batch [1360]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.104538,	
2017-06-26 17:42:06,082 Epoch[27] Batch [1370]	Speed: 5.99 samples/sec	Train-FCNLogLoss=0.104543,	
2017-06-26 17:42:13,011 Epoch[27] Batch [1380]	Speed: 5.77 samples/sec	Train-FCNLogLoss=0.104597,	
2017-06-26 17:42:19,637 Epoch[27] Batch [1390]	Speed: 6.04 samples/sec	Train-FCNLogLoss=0.104728,	
2017-06-26 17:42:26,692 Epoch[27] Batch [1400]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.104777,	
2017-06-26 17:42:33,387 Epoch[27] Batch [1410]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.104883,	
2017-06-26 17:42:40,221 Epoch[27] Batch [1420]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.104948,	
2017-06-26 17:42:46,962 Epoch[27] Batch [1430]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.105163,	
2017-06-26 17:42:53,989 Epoch[27] Batch [1440]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.105237,	
2017-06-26 17:43:01,079 Epoch[27] Batch [1450]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.105216,	
2017-06-26 17:43:08,245 Epoch[27] Batch [1460]	Speed: 5.58 samples/sec	Train-FCNLogLoss=0.105204,	
2017-06-26 17:43:15,487 Epoch[27] Batch [1470]	Speed: 5.52 samples/sec	Train-FCNLogLoss=0.105123,	
2017-06-26 17:43:22,183 Epoch[27] Batch [1480]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.105068,	
2017-06-26 17:43:26,387 Epoch[27] Train-FCNLogLoss=0.105005
2017-06-26 17:43:26,387 Epoch[27] Time cost=994.497
2017-06-26 17:43:27,404 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0028.params"
2017-06-26 17:43:30,961 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0028.states"
2017-06-26 17:43:39,058 Epoch[28] Batch [10]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.089431,	
2017-06-26 17:43:44,992 Epoch[28] Batch [20]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.091788,	
2017-06-26 17:43:51,073 Epoch[28] Batch [30]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.091890,	
2017-06-26 17:43:57,169 Epoch[28] Batch [40]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.093395,	
2017-06-26 17:44:03,301 Epoch[28] Batch [50]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.094475,	
2017-06-26 17:44:09,464 Epoch[28] Batch [60]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.094852,	
2017-06-26 17:44:15,307 Epoch[28] Batch [70]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.096243,	
2017-06-26 17:44:21,323 Epoch[28] Batch [80]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.097200,	
2017-06-26 17:44:28,042 Epoch[28] Batch [90]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.098284,	
2017-06-26 17:44:34,990 Epoch[28] Batch [100]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.098548,	
2017-06-26 17:44:41,867 Epoch[28] Batch [110]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.100236,	
2017-06-26 17:44:48,391 Epoch[28] Batch [120]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.101126,	
2017-06-26 17:44:55,041 Epoch[28] Batch [130]	Speed: 6.02 samples/sec	Train-FCNLogLoss=0.100468,	
2017-06-26 17:45:01,794 Epoch[28] Batch [140]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.099942,	
2017-06-26 17:45:08,274 Epoch[28] Batch [150]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.099202,	
2017-06-26 17:45:15,129 Epoch[28] Batch [160]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.098775,	
2017-06-26 17:45:22,053 Epoch[28] Batch [170]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.099163,	
2017-06-26 17:45:28,871 Epoch[28] Batch [180]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.099147,	
2017-06-26 17:45:35,587 Epoch[28] Batch [190]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.099022,	
2017-06-26 17:45:42,536 Epoch[28] Batch [200]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.098995,	
2017-06-26 17:45:49,397 Epoch[28] Batch [210]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.099413,	
2017-06-26 17:45:55,748 Epoch[28] Batch [220]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.098886,	
2017-06-26 17:46:01,862 Epoch[28] Batch [230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.099042,	
2017-06-26 17:46:07,880 Epoch[28] Batch [240]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.098988,	
2017-06-26 17:46:13,962 Epoch[28] Batch [250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099047,	
2017-06-26 17:46:19,893 Epoch[28] Batch [260]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.098706,	
2017-06-26 17:46:25,500 Epoch[28] Batch [270]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.098917,	
2017-06-26 17:46:31,139 Epoch[28] Batch [280]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.098660,	
2017-06-26 17:46:37,972 Epoch[28] Batch [290]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.098817,	
2017-06-26 17:46:44,453 Epoch[28] Batch [300]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.099159,	
2017-06-26 17:46:51,065 Epoch[28] Batch [310]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.099121,	
2017-06-26 17:46:57,451 Epoch[28] Batch [320]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.099272,	
2017-06-26 17:47:03,928 Epoch[28] Batch [330]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.099126,	
2017-06-26 17:47:10,683 Epoch[28] Batch [340]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.099291,	
2017-06-26 17:47:17,531 Epoch[28] Batch [350]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.099374,	
2017-06-26 17:47:24,350 Epoch[28] Batch [360]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.099682,	
2017-06-26 17:47:30,759 Epoch[28] Batch [370]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.099936,	
2017-06-26 17:47:37,503 Epoch[28] Batch [380]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.100020,	
2017-06-26 17:47:44,273 Epoch[28] Batch [390]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.099959,	
2017-06-26 17:47:51,173 Epoch[28] Batch [400]	Speed: 5.80 samples/sec	Train-FCNLogLoss=0.099614,	
2017-06-26 17:47:57,756 Epoch[28] Batch [410]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.099677,	
2017-06-26 17:48:04,824 Epoch[28] Batch [420]	Speed: 5.66 samples/sec	Train-FCNLogLoss=0.099780,	
2017-06-26 17:48:11,091 Epoch[28] Batch [430]	Speed: 6.38 samples/sec	Train-FCNLogLoss=0.100037,	
2017-06-26 17:48:17,931 Epoch[28] Batch [440]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.100200,	
2017-06-26 17:48:24,286 Epoch[28] Batch [450]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.100595,	
2017-06-26 17:48:30,269 Epoch[28] Batch [460]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.100606,	
2017-06-26 17:48:36,934 Epoch[28] Batch [470]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.100653,	
2017-06-26 17:48:43,240 Epoch[28] Batch [480]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.100723,	
2017-06-26 17:48:49,692 Epoch[28] Batch [490]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.100758,	
2017-06-26 17:48:56,027 Epoch[28] Batch [500]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.100828,	
2017-06-26 17:49:02,844 Epoch[28] Batch [510]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.100724,	
2017-06-26 17:49:08,978 Epoch[28] Batch [520]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.100722,	
2017-06-26 17:49:15,644 Epoch[28] Batch [530]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.100841,	
2017-06-26 17:49:22,314 Epoch[28] Batch [540]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.100719,	
2017-06-26 17:49:29,164 Epoch[28] Batch [550]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.100739,	
2017-06-26 17:49:36,036 Epoch[28] Batch [560]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.100559,	
2017-06-26 17:49:42,896 Epoch[28] Batch [570]	Speed: 5.85 samples/sec	Train-FCNLogLoss=0.100539,	
2017-06-26 17:49:49,375 Epoch[28] Batch [580]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.100509,	
2017-06-26 17:49:56,126 Epoch[28] Batch [590]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.100496,	
2017-06-26 17:50:02,982 Epoch[28] Batch [600]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.100631,	
2017-06-26 17:50:10,097 Epoch[28] Batch [610]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.100528,	
2017-06-26 17:50:16,972 Epoch[28] Batch [620]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.100767,	
2017-06-26 17:50:23,765 Epoch[28] Batch [630]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.100677,	
2017-06-26 17:50:30,640 Epoch[28] Batch [640]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.100821,	
2017-06-26 17:50:37,380 Epoch[28] Batch [650]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.100751,	
2017-06-26 17:50:43,905 Epoch[28] Batch [660]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.100830,	
2017-06-26 17:50:50,017 Epoch[28] Batch [670]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100719,	
2017-06-26 17:50:56,465 Epoch[28] Batch [680]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.100812,	
2017-06-26 17:51:02,934 Epoch[28] Batch [690]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.100767,	
2017-06-26 17:51:09,457 Epoch[28] Batch [700]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.100804,	
2017-06-26 17:51:15,715 Epoch[28] Batch [710]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.100815,	
2017-06-26 17:51:22,231 Epoch[28] Batch [720]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.100789,	
2017-06-26 17:51:28,620 Epoch[28] Batch [730]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.100918,	
2017-06-26 17:51:35,148 Epoch[28] Batch [740]	Speed: 6.13 samples/sec	Train-FCNLogLoss=0.101236,	
2017-06-26 17:51:41,859 Epoch[28] Batch [750]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.101263,	
2017-06-26 17:51:48,293 Epoch[28] Batch [760]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.101307,	
2017-06-26 17:51:54,880 Epoch[28] Batch [770]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.101278,	
2017-06-26 17:52:01,896 Epoch[28] Batch [780]	Speed: 5.70 samples/sec	Train-FCNLogLoss=0.101247,	
2017-06-26 17:52:08,681 Epoch[28] Batch [790]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.101329,	
2017-06-26 17:52:15,593 Epoch[28] Batch [800]	Speed: 5.79 samples/sec	Train-FCNLogLoss=0.101368,	
2017-06-26 17:52:22,066 Epoch[28] Batch [810]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.101401,	
2017-06-26 17:52:28,821 Epoch[28] Batch [820]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.101480,	
2017-06-26 17:52:35,789 Epoch[28] Batch [830]	Speed: 5.74 samples/sec	Train-FCNLogLoss=0.101457,	
2017-06-26 17:52:42,821 Epoch[28] Batch [840]	Speed: 5.69 samples/sec	Train-FCNLogLoss=0.101574,	
2017-06-26 17:52:49,542 Epoch[28] Batch [850]	Speed: 5.95 samples/sec	Train-FCNLogLoss=0.101725,	
2017-06-26 17:52:56,300 Epoch[28] Batch [860]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.101781,	
2017-06-26 17:53:03,159 Epoch[28] Batch [870]	Speed: 5.83 samples/sec	Train-FCNLogLoss=0.101981,	
2017-06-26 17:53:10,280 Epoch[28] Batch [880]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.102078,	
2017-06-26 17:53:16,240 Epoch[28] Batch [890]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.102166,	
2017-06-26 17:53:21,836 Epoch[28] Batch [900]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102134,	
2017-06-26 17:53:27,735 Epoch[28] Batch [910]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.102124,	
2017-06-26 17:53:33,874 Epoch[28] Batch [920]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102197,	
2017-06-26 17:53:39,580 Epoch[28] Batch [930]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.102178,	
2017-06-26 17:53:45,062 Epoch[28] Batch [940]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.102109,	
2017-06-26 17:53:50,891 Epoch[28] Batch [950]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.101954,	
2017-06-26 17:53:57,069 Epoch[28] Batch [960]	Speed: 6.47 samples/sec	Train-FCNLogLoss=0.102086,	
2017-06-26 17:54:04,153 Epoch[28] Batch [970]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.102046,	
2017-06-26 17:54:10,962 Epoch[28] Batch [980]	Speed: 5.87 samples/sec	Train-FCNLogLoss=0.102047,	
2017-06-26 17:54:18,077 Epoch[28] Batch [990]	Speed: 5.62 samples/sec	Train-FCNLogLoss=0.102064,	
2017-06-26 17:54:25,083 Epoch[28] Batch [1000]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.102142,	
2017-06-26 17:54:32,060 Epoch[28] Batch [1010]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.102218,	
2017-06-26 17:54:39,010 Epoch[28] Batch [1020]	Speed: 5.76 samples/sec	Train-FCNLogLoss=0.102320,	
2017-06-26 17:54:45,934 Epoch[28] Batch [1030]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.102416,	
2017-06-26 17:54:52,642 Epoch[28] Batch [1040]	Speed: 5.96 samples/sec	Train-FCNLogLoss=0.102463,	
2017-06-26 17:54:59,372 Epoch[28] Batch [1050]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.102487,	
2017-06-26 17:55:06,375 Epoch[28] Batch [1060]	Speed: 5.71 samples/sec	Train-FCNLogLoss=0.102566,	
2017-06-26 17:55:13,990 Epoch[28] Batch [1070]	Speed: 5.25 samples/sec	Train-FCNLogLoss=0.102530,	
2017-06-26 17:55:20,914 Epoch[28] Batch [1080]	Speed: 5.78 samples/sec	Train-FCNLogLoss=0.102539,	
2017-06-26 17:55:28,174 Epoch[28] Batch [1090]	Speed: 5.51 samples/sec	Train-FCNLogLoss=0.102569,	
2017-06-26 17:55:35,494 Epoch[28] Batch [1100]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.102553,	
2017-06-26 17:55:42,546 Epoch[28] Batch [1110]	Speed: 5.67 samples/sec	Train-FCNLogLoss=0.102530,	
2017-06-26 17:55:49,770 Epoch[28] Batch [1120]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.102601,	
2017-06-26 17:55:55,795 Epoch[28] Batch [1130]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102656,	
2017-06-26 17:56:01,898 Epoch[28] Batch [1140]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102606,	
2017-06-26 17:56:08,002 Epoch[28] Batch [1150]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102510,	
2017-06-26 17:56:14,179 Epoch[28] Batch [1160]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.102479,	
2017-06-26 17:56:20,025 Epoch[28] Batch [1170]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.102526,	
2017-06-26 17:56:26,279 Epoch[28] Batch [1180]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.102501,	
2017-06-26 17:56:32,134 Epoch[28] Batch [1190]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.102624,	
2017-06-26 17:56:38,472 Epoch[28] Batch [1200]	Speed: 6.31 samples/sec	Train-FCNLogLoss=0.102670,	
2017-06-26 17:56:44,265 Epoch[28] Batch [1210]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.102595,	
2017-06-26 17:56:50,132 Epoch[28] Batch [1220]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.102559,	
2017-06-26 17:56:56,101 Epoch[28] Batch [1230]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.102557,	
2017-06-26 17:57:02,270 Epoch[28] Batch [1240]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.102539,	
2017-06-26 17:57:08,436 Epoch[28] Batch [1250]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.102588,	
2017-06-26 17:57:14,660 Epoch[28] Batch [1260]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.102613,	
2017-06-26 17:57:21,323 Epoch[28] Batch [1270]	Speed: 6.00 samples/sec	Train-FCNLogLoss=0.102624,	
2017-06-26 17:57:28,470 Epoch[28] Batch [1280]	Speed: 5.60 samples/sec	Train-FCNLogLoss=0.102703,	
2017-06-26 17:57:35,568 Epoch[28] Batch [1290]	Speed: 5.64 samples/sec	Train-FCNLogLoss=0.102717,	
2017-06-26 17:57:43,000 Epoch[28] Batch [1300]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.102734,	
2017-06-26 17:57:50,379 Epoch[28] Batch [1310]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.102732,	
2017-06-26 17:57:57,606 Epoch[28] Batch [1320]	Speed: 5.54 samples/sec	Train-FCNLogLoss=0.102717,	
2017-06-26 17:58:05,041 Epoch[28] Batch [1330]	Speed: 5.38 samples/sec	Train-FCNLogLoss=0.102755,	
2017-06-26 17:58:10,747 Epoch[28] Batch [1340]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.102884,	
2017-06-26 17:58:16,451 Epoch[28] Batch [1350]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.102932,	
2017-06-26 17:58:22,089 Epoch[28] Batch [1360]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.103000,	
2017-06-26 17:58:27,953 Epoch[28] Batch [1370]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.103155,	
2017-06-26 17:58:33,817 Epoch[28] Batch [1380]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.103187,	
2017-06-26 17:58:39,301 Epoch[28] Batch [1390]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.103238,	
2017-06-26 17:58:45,476 Epoch[28] Batch [1400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.103259,	
2017-06-26 17:58:52,044 Epoch[28] Batch [1410]	Speed: 6.09 samples/sec	Train-FCNLogLoss=0.103256,	
2017-06-26 17:58:58,696 Epoch[28] Batch [1420]	Speed: 6.01 samples/sec	Train-FCNLogLoss=0.103295,	
2017-06-26 17:59:05,658 Epoch[28] Batch [1430]	Speed: 5.75 samples/sec	Train-FCNLogLoss=0.103260,	
2017-06-26 17:59:12,344 Epoch[28] Batch [1440]	Speed: 5.98 samples/sec	Train-FCNLogLoss=0.103272,	
2017-06-26 17:59:19,080 Epoch[28] Batch [1450]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.103276,	
2017-06-26 17:59:26,157 Epoch[28] Batch [1460]	Speed: 5.65 samples/sec	Train-FCNLogLoss=0.103235,	
2017-06-26 17:59:32,754 Epoch[28] Batch [1470]	Speed: 6.06 samples/sec	Train-FCNLogLoss=0.103204,	
2017-06-26 17:59:39,192 Epoch[28] Batch [1480]	Speed: 6.21 samples/sec	Train-FCNLogLoss=0.103267,	
2017-06-26 17:59:43,339 Epoch[28] Train-FCNLogLoss=0.103212
2017-06-26 17:59:43,339 Epoch[28] Time cost=972.378
2017-06-26 17:59:44,431 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0029.params"
2017-06-26 17:59:47,917 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0029.states"
2017-06-26 17:59:55,153 Epoch[29] Batch [10]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.114479,	
2017-06-26 18:00:01,608 Epoch[29] Batch [20]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.105200,	
2017-06-26 18:00:08,036 Epoch[29] Batch [30]	Speed: 6.22 samples/sec	Train-FCNLogLoss=0.106090,	
2017-06-26 18:00:14,666 Epoch[29] Batch [40]	Speed: 6.03 samples/sec	Train-FCNLogLoss=0.104110,	
2017-06-26 18:00:20,959 Epoch[29] Batch [50]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.104310,	
2017-06-26 18:00:27,545 Epoch[29] Batch [60]	Speed: 6.07 samples/sec	Train-FCNLogLoss=0.105039,	
2017-06-26 18:00:34,247 Epoch[29] Batch [70]	Speed: 5.97 samples/sec	Train-FCNLogLoss=0.103601,	
2017-06-26 18:00:40,255 Epoch[29] Batch [80]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.103048,	
2017-06-26 18:00:46,605 Epoch[29] Batch [90]	Speed: 6.30 samples/sec	Train-FCNLogLoss=0.102346,	
2017-06-26 18:00:53,106 Epoch[29] Batch [100]	Speed: 6.15 samples/sec	Train-FCNLogLoss=0.102043,	
2017-06-26 18:00:59,995 Epoch[29] Batch [110]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.101897,	
2017-06-26 18:01:06,550 Epoch[29] Batch [120]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.101901,	
2017-06-26 18:01:13,286 Epoch[29] Batch [130]	Speed: 5.94 samples/sec	Train-FCNLogLoss=0.100739,	
2017-06-26 18:01:19,647 Epoch[29] Batch [140]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.100136,	
2017-06-26 18:01:26,132 Epoch[29] Batch [150]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.100857,	
2017-06-26 18:01:32,709 Epoch[29] Batch [160]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.100669,	
2017-06-26 18:01:39,692 Epoch[29] Batch [170]	Speed: 5.73 samples/sec	Train-FCNLogLoss=0.100550,	
2017-06-26 18:01:45,904 Epoch[29] Batch [180]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.100613,	
2017-06-26 18:01:52,380 Epoch[29] Batch [190]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.101508,	
2017-06-26 18:01:58,900 Epoch[29] Batch [200]	Speed: 6.14 samples/sec	Train-FCNLogLoss=0.101476,	
2017-06-26 18:02:05,372 Epoch[29] Batch [210]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.101465,	
2017-06-26 18:02:12,160 Epoch[29] Batch [220]	Speed: 5.89 samples/sec	Train-FCNLogLoss=0.101429,	
2017-06-26 18:02:18,922 Epoch[29] Batch [230]	Speed: 5.92 samples/sec	Train-FCNLogLoss=0.101497,	
2017-06-26 18:02:25,159 Epoch[29] Batch [240]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.102009,	
2017-06-26 18:02:31,627 Epoch[29] Batch [250]	Speed: 6.18 samples/sec	Train-FCNLogLoss=0.102212,	
2017-06-26 18:02:38,185 Epoch[29] Batch [260]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.102374,	
2017-06-26 18:02:44,575 Epoch[29] Batch [270]	Speed: 6.26 samples/sec	Train-FCNLogLoss=0.102413,	
2017-06-26 18:02:50,170 Epoch[29] Batch [280]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102568,	
2017-06-26 18:02:55,862 Epoch[29] Batch [290]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.102655,	
2017-06-26 18:03:01,551 Epoch[29] Batch [300]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.102834,	
2017-06-26 18:03:07,369 Epoch[29] Batch [310]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.102149,	
2017-06-26 18:03:13,484 Epoch[29] Batch [320]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102231,	
2017-06-26 18:03:19,548 Epoch[29] Batch [330]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102303,	
2017-06-26 18:03:25,631 Epoch[29] Batch [340]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102213,	
2017-06-26 18:03:31,697 Epoch[29] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102052,	
2017-06-26 18:03:37,809 Epoch[29] Batch [360]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.102142,	
2017-06-26 18:03:43,844 Epoch[29] Batch [370]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102413,	
2017-06-26 18:03:49,913 Epoch[29] Batch [380]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102466,	
2017-06-26 18:03:55,948 Epoch[29] Batch [390]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102080,	
2017-06-26 18:04:02,019 Epoch[29] Batch [400]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101982,	
2017-06-26 18:04:08,122 Epoch[29] Batch [410]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101757,	
2017-06-26 18:04:14,160 Epoch[29] Batch [420]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101665,	
2017-06-26 18:04:20,218 Epoch[29] Batch [430]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101623,	
2017-06-26 18:04:26,285 Epoch[29] Batch [440]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101627,	
2017-06-26 18:04:32,323 Epoch[29] Batch [450]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101632,	
2017-06-26 18:04:38,400 Epoch[29] Batch [460]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101659,	
2017-06-26 18:04:44,450 Epoch[29] Batch [470]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101709,	
2017-06-26 18:04:50,501 Epoch[29] Batch [480]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101523,	
2017-06-26 18:04:56,536 Epoch[29] Batch [490]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101544,	
2017-06-26 18:05:02,604 Epoch[29] Batch [500]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101470,	
2017-06-26 18:05:08,696 Epoch[29] Batch [510]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101626,	
2017-06-26 18:05:14,749 Epoch[29] Batch [520]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101545,	
2017-06-26 18:05:20,770 Epoch[29] Batch [530]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.101710,	
2017-06-26 18:05:26,852 Epoch[29] Batch [540]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102028,	
2017-06-26 18:05:32,915 Epoch[29] Batch [550]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102266,	
2017-06-26 18:05:38,962 Epoch[29] Batch [560]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102388,	
2017-06-26 18:05:45,025 Epoch[29] Batch [570]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102547,	
2017-06-26 18:05:51,004 Epoch[29] Batch [580]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.102649,	
2017-06-26 18:05:57,058 Epoch[29] Batch [590]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102712,	
2017-06-26 18:06:03,157 Epoch[29] Batch [600]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102584,	
2017-06-26 18:06:09,251 Epoch[29] Batch [610]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102542,	
2017-06-26 18:06:15,300 Epoch[29] Batch [620]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102627,	
2017-06-26 18:06:21,401 Epoch[29] Batch [630]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102560,	
2017-06-26 18:06:27,542 Epoch[29] Batch [640]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.102639,	
2017-06-26 18:06:33,603 Epoch[29] Batch [650]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102740,	
2017-06-26 18:06:39,689 Epoch[29] Batch [660]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102677,	
2017-06-26 18:06:45,781 Epoch[29] Batch [670]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102677,	
2017-06-26 18:06:51,879 Epoch[29] Batch [680]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102725,	
2017-06-26 18:06:57,905 Epoch[29] Batch [690]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.102745,	
2017-06-26 18:07:03,443 Epoch[29] Batch [700]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.102756,	
2017-06-26 18:07:09,095 Epoch[29] Batch [710]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.102895,	
2017-06-26 18:07:14,701 Epoch[29] Batch [720]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.103039,	
2017-06-26 18:07:20,062 Epoch[29] Batch [730]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.102982,	
2017-06-26 18:07:25,680 Epoch[29] Batch [740]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.102923,	
2017-06-26 18:07:31,290 Epoch[29] Batch [750]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102861,	
2017-06-26 18:07:36,895 Epoch[29] Batch [760]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.102931,	
2017-06-26 18:07:42,486 Epoch[29] Batch [770]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.102840,	
2017-06-26 18:07:48,070 Epoch[29] Batch [780]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.102842,	
2017-06-26 18:07:54,158 Epoch[29] Batch [790]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102860,	
2017-06-26 18:08:00,224 Epoch[29] Batch [800]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102917,	
2017-06-26 18:08:06,283 Epoch[29] Batch [810]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102726,	
2017-06-26 18:08:12,347 Epoch[29] Batch [820]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102708,	
2017-06-26 18:08:18,355 Epoch[29] Batch [830]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102801,	
2017-06-26 18:08:24,414 Epoch[29] Batch [840]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102826,	
2017-06-26 18:08:30,459 Epoch[29] Batch [850]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102772,	
2017-06-26 18:08:36,558 Epoch[29] Batch [860]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102816,	
2017-06-26 18:08:42,703 Epoch[29] Batch [870]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.102807,	
2017-06-26 18:08:48,745 Epoch[29] Batch [880]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102884,	
2017-06-26 18:08:54,814 Epoch[29] Batch [890]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103023,	
2017-06-26 18:09:00,902 Epoch[29] Batch [900]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102948,	
2017-06-26 18:09:06,974 Epoch[29] Batch [910]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102805,	
2017-06-26 18:09:13,075 Epoch[29] Batch [920]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102730,	
2017-06-26 18:09:19,140 Epoch[29] Batch [930]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102664,	
2017-06-26 18:09:25,249 Epoch[29] Batch [940]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102695,	
2017-06-26 18:09:31,263 Epoch[29] Batch [950]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102759,	
2017-06-26 18:09:37,335 Epoch[29] Batch [960]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102789,	
2017-06-26 18:09:43,445 Epoch[29] Batch [970]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102726,	
2017-06-26 18:09:49,492 Epoch[29] Batch [980]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102798,	
2017-06-26 18:09:55,567 Epoch[29] Batch [990]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102778,	
2017-06-26 18:10:01,671 Epoch[29] Batch [1000]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102723,	
2017-06-26 18:10:07,726 Epoch[29] Batch [1010]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102825,	
2017-06-26 18:10:13,799 Epoch[29] Batch [1020]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102778,	
2017-06-26 18:10:19,890 Epoch[29] Batch [1030]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102827,	
2017-06-26 18:10:25,999 Epoch[29] Batch [1040]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.103144,	
2017-06-26 18:10:32,066 Epoch[29] Batch [1050]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103381,	
2017-06-26 18:10:38,161 Epoch[29] Batch [1060]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103442,	
2017-06-26 18:10:44,194 Epoch[29] Batch [1070]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103379,	
2017-06-26 18:10:50,290 Epoch[29] Batch [1080]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103487,	
2017-06-26 18:10:56,361 Epoch[29] Batch [1090]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103517,	
2017-06-26 18:11:02,388 Epoch[29] Batch [1100]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103523,	
2017-06-26 18:11:08,487 Epoch[29] Batch [1110]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103352,	
2017-06-26 18:11:14,579 Epoch[29] Batch [1120]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103396,	
2017-06-26 18:11:20,631 Epoch[29] Batch [1130]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.103297,	
2017-06-26 18:11:26,726 Epoch[29] Batch [1140]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103234,	
2017-06-26 18:11:32,756 Epoch[29] Batch [1150]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103212,	
2017-06-26 18:11:38,883 Epoch[29] Batch [1160]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103203,	
2017-06-26 18:11:44,785 Epoch[29] Batch [1170]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.103136,	
2017-06-26 18:11:50,783 Epoch[29] Batch [1180]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.103216,	
2017-06-26 18:11:56,588 Epoch[29] Batch [1190]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.103161,	
2017-06-26 18:12:02,330 Epoch[29] Batch [1200]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.103150,	
2017-06-26 18:12:08,252 Epoch[29] Batch [1210]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.103146,	
2017-06-26 18:12:14,134 Epoch[29] Batch [1220]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.103077,	
2017-06-26 18:12:20,220 Epoch[29] Batch [1230]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103138,	
2017-06-26 18:12:26,252 Epoch[29] Batch [1240]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103045,	
2017-06-26 18:12:32,385 Epoch[29] Batch [1250]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.103118,	
2017-06-26 18:12:38,485 Epoch[29] Batch [1260]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103192,	
2017-06-26 18:12:44,549 Epoch[29] Batch [1270]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103116,	
2017-06-26 18:12:50,645 Epoch[29] Batch [1280]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103158,	
2017-06-26 18:12:56,728 Epoch[29] Batch [1290]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103163,	
2017-06-26 18:13:02,830 Epoch[29] Batch [1300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103145,	
2017-06-26 18:13:08,863 Epoch[29] Batch [1310]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.103210,	
2017-06-26 18:13:14,938 Epoch[29] Batch [1320]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103161,	
2017-06-26 18:13:21,027 Epoch[29] Batch [1330]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103098,	
2017-06-26 18:13:27,119 Epoch[29] Batch [1340]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103064,	
2017-06-26 18:13:33,199 Epoch[29] Batch [1350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103025,	
2017-06-26 18:13:39,265 Epoch[29] Batch [1360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102996,	
2017-06-26 18:13:45,307 Epoch[29] Batch [1370]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103070,	
2017-06-26 18:13:51,423 Epoch[29] Batch [1380]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.103080,	
2017-06-26 18:13:57,490 Epoch[29] Batch [1390]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103054,	
2017-06-26 18:14:03,586 Epoch[29] Batch [1400]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103012,	
2017-06-26 18:14:09,682 Epoch[29] Batch [1410]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102961,	
2017-06-26 18:14:15,759 Epoch[29] Batch [1420]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102880,	
2017-06-26 18:14:21,850 Epoch[29] Batch [1430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102950,	
2017-06-26 18:14:27,885 Epoch[29] Batch [1440]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102985,	
2017-06-26 18:14:33,991 Epoch[29] Batch [1450]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102915,	
2017-06-26 18:14:40,115 Epoch[29] Batch [1460]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102941,	
2017-06-26 18:14:46,171 Epoch[29] Batch [1470]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102848,	
2017-06-26 18:14:52,270 Epoch[29] Batch [1480]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102783,	
2017-06-26 18:14:55,926 Epoch[29] Train-FCNLogLoss=0.102835
2017-06-26 18:14:55,927 Epoch[29] Time cost=908.009
2017-06-26 18:14:56,609 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0030.params"
2017-06-26 18:14:58,276 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0030.states"
2017-06-26 18:15:05,116 Epoch[30] Batch [10]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.104146,	
2017-06-26 18:15:11,192 Epoch[30] Batch [20]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100683,	
2017-06-26 18:15:15,423 Epoch[30] Batch [30]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.102216,	
2017-06-26 18:15:20,217 Epoch[30] Batch [40]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.101118,	
2017-06-26 18:15:26,271 Epoch[30] Batch [50]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102237,	
2017-06-26 18:15:32,364 Epoch[30] Batch [60]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103069,	
2017-06-26 18:15:38,424 Epoch[30] Batch [70]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104099,	
2017-06-26 18:15:44,479 Epoch[30] Batch [80]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102710,	
2017-06-26 18:15:50,564 Epoch[30] Batch [90]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102778,	
2017-06-26 18:15:56,638 Epoch[30] Batch [100]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102752,	
2017-06-26 18:16:02,471 Epoch[30] Batch [110]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.103165,	
2017-06-26 18:16:08,281 Epoch[30] Batch [120]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.102268,	
2017-06-26 18:16:14,052 Epoch[30] Batch [130]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.102281,	
2017-06-26 18:16:19,751 Epoch[30] Batch [140]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.105399,	
2017-06-26 18:16:25,369 Epoch[30] Batch [150]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.109234,	
2017-06-26 18:16:31,024 Epoch[30] Batch [160]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.115319,	
2017-06-26 18:16:36,748 Epoch[30] Batch [170]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.119025,	
2017-06-26 18:16:42,877 Epoch[30] Batch [180]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.119861,	
2017-06-26 18:16:48,971 Epoch[30] Batch [190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.120692,	
2017-06-26 18:16:55,031 Epoch[30] Batch [200]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.121302,	
2017-06-26 18:17:01,123 Epoch[30] Batch [210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.121499,	
2017-06-26 18:17:07,161 Epoch[30] Batch [220]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.122179,	
2017-06-26 18:17:13,256 Epoch[30] Batch [230]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.122416,	
2017-06-26 18:17:19,347 Epoch[30] Batch [240]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.122061,	
2017-06-26 18:17:25,436 Epoch[30] Batch [250]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.122235,	
2017-06-26 18:17:31,312 Epoch[30] Batch [260]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.121250,	
2017-06-26 18:17:37,354 Epoch[30] Batch [270]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.120863,	
2017-06-26 18:17:43,325 Epoch[30] Batch [280]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.120539,	
2017-06-26 18:17:49,376 Epoch[30] Batch [290]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.119897,	
2017-06-26 18:17:55,455 Epoch[30] Batch [300]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.119436,	
2017-06-26 18:18:01,483 Epoch[30] Batch [310]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.119429,	
2017-06-26 18:18:07,617 Epoch[30] Batch [320]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.119299,	
2017-06-26 18:18:13,665 Epoch[30] Batch [330]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.118656,	
2017-06-26 18:18:19,752 Epoch[30] Batch [340]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.118564,	
2017-06-26 18:18:25,796 Epoch[30] Batch [350]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.118553,	
2017-06-26 18:18:31,912 Epoch[30] Batch [360]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.117903,	
2017-06-26 18:18:37,954 Epoch[30] Batch [370]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.117837,	
2017-06-26 18:18:44,036 Epoch[30] Batch [380]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.117911,	
2017-06-26 18:18:50,105 Epoch[30] Batch [390]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.117773,	
2017-06-26 18:18:56,259 Epoch[30] Batch [400]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.117558,	
2017-06-26 18:19:02,280 Epoch[30] Batch [410]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.117277,	
2017-06-26 18:19:08,369 Epoch[30] Batch [420]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.117079,	
2017-06-26 18:19:14,444 Epoch[30] Batch [430]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.116903,	
2017-06-26 18:19:20,557 Epoch[30] Batch [440]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.116715,	
2017-06-26 18:19:26,584 Epoch[30] Batch [450]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.116591,	
2017-06-26 18:19:32,723 Epoch[30] Batch [460]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.116472,	
2017-06-26 18:19:38,819 Epoch[30] Batch [470]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.116338,	
2017-06-26 18:19:44,905 Epoch[30] Batch [480]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.116216,	
2017-06-26 18:19:50,882 Epoch[30] Batch [490]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.115787,	
2017-06-26 18:19:56,891 Epoch[30] Batch [500]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.115568,	
2017-06-26 18:20:02,946 Epoch[30] Batch [510]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.115391,	
2017-06-26 18:20:08,930 Epoch[30] Batch [520]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.115214,	
2017-06-26 18:20:15,016 Epoch[30] Batch [530]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.115242,	
2017-06-26 18:20:21,084 Epoch[30] Batch [540]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.114822,	
2017-06-26 18:20:27,189 Epoch[30] Batch [550]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.114558,	
2017-06-26 18:20:33,046 Epoch[30] Batch [560]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.114511,	
2017-06-26 18:20:38,638 Epoch[30] Batch [570]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.114273,	
2017-06-26 18:20:44,239 Epoch[30] Batch [580]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.113999,	
2017-06-26 18:20:49,844 Epoch[30] Batch [590]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.113752,	
2017-06-26 18:20:55,402 Epoch[30] Batch [600]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.113744,	
2017-06-26 18:21:00,979 Epoch[30] Batch [610]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.113562,	
2017-06-26 18:21:06,570 Epoch[30] Batch [620]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.113278,	
2017-06-26 18:21:12,133 Epoch[30] Batch [630]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.112852,	
2017-06-26 18:21:17,729 Epoch[30] Batch [640]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.112568,	
2017-06-26 18:21:23,405 Epoch[30] Batch [650]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.112350,	
2017-06-26 18:21:29,478 Epoch[30] Batch [660]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.112306,	
2017-06-26 18:21:35,569 Epoch[30] Batch [670]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.112079,	
2017-06-26 18:21:41,615 Epoch[30] Batch [680]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.112065,	
2017-06-26 18:21:47,670 Epoch[30] Batch [690]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.111953,	
2017-06-26 18:21:53,784 Epoch[30] Batch [700]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.111918,	
2017-06-26 18:21:59,652 Epoch[30] Batch [710]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.111868,	
2017-06-26 18:22:05,696 Epoch[30] Batch [720]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.111611,	
2017-06-26 18:22:11,700 Epoch[30] Batch [730]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.111424,	
2017-06-26 18:22:17,741 Epoch[30] Batch [740]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.111288,	
2017-06-26 18:22:23,826 Epoch[30] Batch [750]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.111309,	
2017-06-26 18:22:29,927 Epoch[30] Batch [760]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.111122,	
2017-06-26 18:22:36,050 Epoch[30] Batch [770]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.111706,	
2017-06-26 18:22:42,031 Epoch[30] Batch [780]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.111698,	
2017-06-26 18:22:48,155 Epoch[30] Batch [790]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.111575,	
2017-06-26 18:22:54,233 Epoch[30] Batch [800]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.111347,	
2017-06-26 18:23:00,358 Epoch[30] Batch [810]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.111290,	
2017-06-26 18:23:06,417 Epoch[30] Batch [820]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.111196,	
2017-06-26 18:23:12,331 Epoch[30] Batch [830]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.111058,	
2017-06-26 18:23:18,336 Epoch[30] Batch [840]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.110932,	
2017-06-26 18:23:24,314 Epoch[30] Batch [850]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.110803,	
2017-06-26 18:23:30,427 Epoch[30] Batch [860]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.110708,	
2017-06-26 18:23:36,524 Epoch[30] Batch [870]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.110573,	
2017-06-26 18:23:42,627 Epoch[30] Batch [880]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.110306,	
2017-06-26 18:23:48,703 Epoch[30] Batch [890]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.110134,	
2017-06-26 18:23:54,816 Epoch[30] Batch [900]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.110046,	
2017-06-26 18:24:00,883 Epoch[30] Batch [910]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109931,	
2017-06-26 18:24:06,920 Epoch[30] Batch [920]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.109777,	
2017-06-26 18:24:13,024 Epoch[30] Batch [930]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.109657,	
2017-06-26 18:24:19,113 Epoch[30] Batch [940]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.109573,	
2017-06-26 18:24:25,238 Epoch[30] Batch [950]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.109426,	
2017-06-26 18:24:31,308 Epoch[30] Batch [960]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109369,	
2017-06-26 18:24:37,395 Epoch[30] Batch [970]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.109297,	
2017-06-26 18:24:43,522 Epoch[30] Batch [980]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.109277,	
2017-06-26 18:24:49,600 Epoch[30] Batch [990]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109199,	
2017-06-26 18:24:55,674 Epoch[30] Batch [1000]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.109129,	
2017-06-26 18:25:01,748 Epoch[30] Batch [1010]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.109037,	
2017-06-26 18:25:07,778 Epoch[30] Batch [1020]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.109044,	
2017-06-26 18:25:13,884 Epoch[30] Batch [1030]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.108920,	
2017-06-26 18:25:19,856 Epoch[30] Batch [1040]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.108764,	
2017-06-26 18:25:25,407 Epoch[30] Batch [1050]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.108707,	
2017-06-26 18:25:30,757 Epoch[30] Batch [1060]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108606,	
2017-06-26 18:25:35,842 Epoch[30] Batch [1070]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.108505,	
2017-06-26 18:25:41,340 Epoch[30] Batch [1080]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.108566,	
2017-06-26 18:25:46,441 Epoch[30] Batch [1090]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.108535,	
2017-06-26 18:25:51,981 Epoch[30] Batch [1100]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.108405,	
2017-06-26 18:25:57,519 Epoch[30] Batch [1110]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.108395,	
2017-06-26 18:26:03,122 Epoch[30] Batch [1120]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.108337,	
2017-06-26 18:26:08,651 Epoch[30] Batch [1130]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.108256,	
2017-06-26 18:26:14,525 Epoch[30] Batch [1140]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.108218,	
2017-06-26 18:26:20,690 Epoch[30] Batch [1150]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.108186,	
2017-06-26 18:26:26,808 Epoch[30] Batch [1160]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.108071,	
2017-06-26 18:26:32,872 Epoch[30] Batch [1170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107974,	
2017-06-26 18:26:38,902 Epoch[30] Batch [1180]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.107911,	
2017-06-26 18:26:45,004 Epoch[30] Batch [1190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107926,	
2017-06-26 18:26:51,125 Epoch[30] Batch [1200]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.107800,	
2017-06-26 18:26:57,167 Epoch[30] Batch [1210]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.107763,	
2017-06-26 18:27:03,284 Epoch[30] Batch [1220]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.107787,	
2017-06-26 18:27:09,399 Epoch[30] Batch [1230]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.107837,	
2017-06-26 18:27:15,422 Epoch[30] Batch [1240]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.107818,	
2017-06-26 18:27:21,522 Epoch[30] Batch [1250]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.107881,	
2017-06-26 18:27:27,587 Epoch[30] Batch [1260]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.107853,	
2017-06-26 18:27:33,669 Epoch[30] Batch [1270]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.107818,	
2017-06-26 18:27:39,761 Epoch[30] Batch [1280]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107911,	
2017-06-26 18:27:45,822 Epoch[30] Batch [1290]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.108072,	
2017-06-26 18:27:51,888 Epoch[30] Batch [1300]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108424,	
2017-06-26 18:27:58,003 Epoch[30] Batch [1310]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.108534,	
2017-06-26 18:28:04,045 Epoch[30] Batch [1320]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108613,	
2017-06-26 18:28:09,978 Epoch[30] Batch [1330]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.108663,	
2017-06-26 18:28:16,032 Epoch[30] Batch [1340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.108626,	
2017-06-26 18:28:22,111 Epoch[30] Batch [1350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108564,	
2017-06-26 18:28:28,143 Epoch[30] Batch [1360]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.108569,	
2017-06-26 18:28:34,212 Epoch[30] Batch [1370]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108569,	
2017-06-26 18:28:40,193 Epoch[30] Batch [1380]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.108525,	
2017-06-26 18:28:46,216 Epoch[30] Batch [1390]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.108488,	
2017-06-26 18:28:52,300 Epoch[30] Batch [1400]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108476,	
2017-06-26 18:28:58,377 Epoch[30] Batch [1410]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.108463,	
2017-06-26 18:29:04,450 Epoch[30] Batch [1420]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108423,	
2017-06-26 18:29:10,571 Epoch[30] Batch [1430]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.108352,	
2017-06-26 18:29:16,660 Epoch[30] Batch [1440]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.108421,	
2017-06-26 18:29:22,545 Epoch[30] Batch [1450]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.108317,	
2017-06-26 18:29:28,616 Epoch[30] Batch [1460]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.108247,	
2017-06-26 18:29:34,639 Epoch[30] Batch [1470]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.108231,	
2017-06-26 18:29:40,686 Epoch[30] Batch [1480]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.108154,	
2017-06-26 18:29:44,271 Epoch[30] Train-FCNLogLoss=0.108066
2017-06-26 18:29:44,272 Epoch[30] Time cost=885.996
2017-06-26 18:29:44,952 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0031.params"
2017-06-26 18:29:46,671 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0031.states"
2017-06-26 18:29:53,313 Epoch[31] Batch [10]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.109367,	
2017-06-26 18:29:59,387 Epoch[31] Batch [20]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106313,	
2017-06-26 18:30:05,258 Epoch[31] Batch [30]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.103608,	
2017-06-26 18:30:10,891 Epoch[31] Batch [40]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.100453,	
2017-06-26 18:30:15,170 Epoch[31] Batch [50]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.099668,	
2017-06-26 18:30:19,588 Epoch[31] Batch [60]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.098406,	
2017-06-26 18:30:24,953 Epoch[31] Batch [70]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099374,	
2017-06-26 18:30:30,594 Epoch[31] Batch [80]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.099363,	
2017-06-26 18:30:36,150 Epoch[31] Batch [90]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.100254,	
2017-06-26 18:30:41,275 Epoch[31] Batch [100]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.100765,	
2017-06-26 18:30:46,704 Epoch[31] Batch [110]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.100481,	
2017-06-26 18:30:52,203 Epoch[31] Batch [120]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.099942,	
2017-06-26 18:30:57,336 Epoch[31] Batch [130]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.099900,	
2017-06-26 18:31:03,243 Epoch[31] Batch [140]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.104282,	
2017-06-26 18:31:09,333 Epoch[31] Batch [150]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103836,	
2017-06-26 18:31:15,455 Epoch[31] Batch [160]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.103630,	
2017-06-26 18:31:21,477 Epoch[31] Batch [170]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.103817,	
2017-06-26 18:31:27,562 Epoch[31] Batch [180]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103769,	
2017-06-26 18:31:33,638 Epoch[31] Batch [190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103693,	
2017-06-26 18:31:39,606 Epoch[31] Batch [200]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.104027,	
2017-06-26 18:31:45,672 Epoch[31] Batch [210]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103513,	
2017-06-26 18:31:51,710 Epoch[31] Batch [220]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103630,	
2017-06-26 18:31:57,691 Epoch[31] Batch [230]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.104000,	
2017-06-26 18:32:03,763 Epoch[31] Batch [240]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103754,	
2017-06-26 18:32:09,852 Epoch[31] Batch [250]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.104010,	
2017-06-26 18:32:15,909 Epoch[31] Batch [260]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104019,	
2017-06-26 18:32:21,971 Epoch[31] Batch [270]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103642,	
2017-06-26 18:32:28,059 Epoch[31] Batch [280]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103570,	
2017-06-26 18:32:34,115 Epoch[31] Batch [290]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.103621,	
2017-06-26 18:32:40,114 Epoch[31] Batch [300]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.103433,	
2017-06-26 18:32:46,075 Epoch[31] Batch [310]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.103239,	
2017-06-26 18:32:52,122 Epoch[31] Batch [320]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103348,	
2017-06-26 18:32:58,195 Epoch[31] Batch [330]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.103055,	
2017-06-26 18:33:04,245 Epoch[31] Batch [340]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.103107,	
2017-06-26 18:33:10,344 Epoch[31] Batch [350]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103046,	
2017-06-26 18:33:16,353 Epoch[31] Batch [360]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102788,	
2017-06-26 18:33:22,408 Epoch[31] Batch [370]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102688,	
2017-06-26 18:33:28,474 Epoch[31] Batch [380]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102535,	
2017-06-26 18:33:34,534 Epoch[31] Batch [390]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102613,	
2017-06-26 18:33:40,572 Epoch[31] Batch [400]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102477,	
2017-06-26 18:33:46,560 Epoch[31] Batch [410]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.102478,	
2017-06-26 18:33:52,659 Epoch[31] Batch [420]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102636,	
2017-06-26 18:33:58,748 Epoch[31] Batch [430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102407,	
2017-06-26 18:34:04,765 Epoch[31] Batch [440]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102661,	
2017-06-26 18:34:10,903 Epoch[31] Batch [450]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.102622,	
2017-06-26 18:34:16,905 Epoch[31] Batch [460]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102806,	
2017-06-26 18:34:23,015 Epoch[31] Batch [470]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102850,	
2017-06-26 18:34:29,108 Epoch[31] Batch [480]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102814,	
2017-06-26 18:34:35,157 Epoch[31] Batch [490]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102886,	
2017-06-26 18:34:41,236 Epoch[31] Batch [500]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.103073,	
2017-06-26 18:34:47,333 Epoch[31] Batch [510]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103134,	
2017-06-26 18:34:53,380 Epoch[31] Batch [520]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103277,	
2017-06-26 18:34:59,237 Epoch[31] Batch [530]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.103251,	
2017-06-26 18:35:05,087 Epoch[31] Batch [540]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.103371,	
2017-06-26 18:35:10,858 Epoch[31] Batch [550]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.103266,	
2017-06-26 18:35:16,610 Epoch[31] Batch [560]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.103315,	
2017-06-26 18:35:22,309 Epoch[31] Batch [570]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.103285,	
2017-06-26 18:35:28,157 Epoch[31] Batch [580]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.103127,	
2017-06-26 18:35:34,255 Epoch[31] Batch [590]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102821,	
2017-06-26 18:35:40,341 Epoch[31] Batch [600]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102644,	
2017-06-26 18:35:46,442 Epoch[31] Batch [610]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102483,	
2017-06-26 18:35:52,523 Epoch[31] Batch [620]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102309,	
2017-06-26 18:35:58,597 Epoch[31] Batch [630]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102157,	
2017-06-26 18:36:04,679 Epoch[31] Batch [640]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102042,	
2017-06-26 18:36:10,740 Epoch[31] Batch [650]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102108,	
2017-06-26 18:36:16,835 Epoch[31] Batch [660]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102320,	
2017-06-26 18:36:22,909 Epoch[31] Batch [670]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102208,	
2017-06-26 18:36:28,947 Epoch[31] Batch [680]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102098,	
2017-06-26 18:36:35,040 Epoch[31] Batch [690]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102075,	
2017-06-26 18:36:41,135 Epoch[31] Batch [700]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102087,	
2017-06-26 18:36:47,236 Epoch[31] Batch [710]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102102,	
2017-06-26 18:36:53,316 Epoch[31] Batch [720]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102071,	
2017-06-26 18:36:59,394 Epoch[31] Batch [730]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102085,	
2017-06-26 18:37:05,457 Epoch[31] Batch [740]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102249,	
2017-06-26 18:37:11,507 Epoch[31] Batch [750]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102173,	
2017-06-26 18:37:17,588 Epoch[31] Batch [760]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102225,	
2017-06-26 18:37:23,682 Epoch[31] Batch [770]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102180,	
2017-06-26 18:37:29,770 Epoch[31] Batch [780]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102088,	
2017-06-26 18:37:35,846 Epoch[31] Batch [790]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102025,	
2017-06-26 18:37:41,950 Epoch[31] Batch [800]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.102041,	
2017-06-26 18:37:48,063 Epoch[31] Batch [810]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101978,	
2017-06-26 18:37:54,203 Epoch[31] Batch [820]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101934,	
2017-06-26 18:38:00,048 Epoch[31] Batch [830]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.102045,	
2017-06-26 18:38:06,091 Epoch[31] Batch [840]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.101934,	
2017-06-26 18:38:12,138 Epoch[31] Batch [850]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101923,	
2017-06-26 18:38:18,211 Epoch[31] Batch [860]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101948,	
2017-06-26 18:38:24,260 Epoch[31] Batch [870]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102063,	
2017-06-26 18:38:30,332 Epoch[31] Batch [880]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102063,	
2017-06-26 18:38:36,344 Epoch[31] Batch [890]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.102062,	
2017-06-26 18:38:42,411 Epoch[31] Batch [900]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102187,	
2017-06-26 18:38:48,492 Epoch[31] Batch [910]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102274,	
2017-06-26 18:38:54,548 Epoch[31] Batch [920]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102314,	
2017-06-26 18:39:00,633 Epoch[31] Batch [930]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102337,	
2017-06-26 18:39:06,689 Epoch[31] Batch [940]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102355,	
2017-06-26 18:39:12,746 Epoch[31] Batch [950]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102330,	
2017-06-26 18:39:18,824 Epoch[31] Batch [960]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102288,	
2017-06-26 18:39:24,461 Epoch[31] Batch [970]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.102418,	
2017-06-26 18:39:30,036 Epoch[31] Batch [980]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.102405,	
2017-06-26 18:39:35,618 Epoch[31] Batch [990]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.102468,	
2017-06-26 18:39:41,226 Epoch[31] Batch [1000]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102377,	
2017-06-26 18:39:46,810 Epoch[31] Batch [1010]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.102306,	
2017-06-26 18:39:52,396 Epoch[31] Batch [1020]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.102392,	
2017-06-26 18:39:58,010 Epoch[31] Batch [1030]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102357,	
2017-06-26 18:40:03,574 Epoch[31] Batch [1040]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.102194,	
2017-06-26 18:40:09,159 Epoch[31] Batch [1050]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.102105,	
2017-06-26 18:40:14,896 Epoch[31] Batch [1060]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.102037,	
2017-06-26 18:40:20,896 Epoch[31] Batch [1070]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.101963,	
2017-06-26 18:40:26,901 Epoch[31] Batch [1080]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101971,	
2017-06-26 18:40:32,984 Epoch[31] Batch [1090]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.102026,	
2017-06-26 18:40:39,085 Epoch[31] Batch [1100]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.102006,	
2017-06-26 18:40:45,147 Epoch[31] Batch [1110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102013,	
2017-06-26 18:40:51,195 Epoch[31] Batch [1120]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102019,	
2017-06-26 18:40:57,289 Epoch[31] Batch [1130]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101962,	
2017-06-26 18:41:03,394 Epoch[31] Batch [1140]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101872,	
2017-06-26 18:41:09,452 Epoch[31] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101879,	
2017-06-26 18:41:15,567 Epoch[31] Batch [1160]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101908,	
2017-06-26 18:41:21,612 Epoch[31] Batch [1170]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102000,	
2017-06-26 18:41:27,715 Epoch[31] Batch [1180]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101972,	
2017-06-26 18:41:33,785 Epoch[31] Batch [1190]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101923,	
2017-06-26 18:41:39,877 Epoch[31] Batch [1200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101887,	
2017-06-26 18:41:45,954 Epoch[31] Batch [1210]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101881,	
2017-06-26 18:41:52,014 Epoch[31] Batch [1220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101926,	
2017-06-26 18:41:58,065 Epoch[31] Batch [1230]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101861,	
2017-06-26 18:42:04,172 Epoch[31] Batch [1240]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101845,	
2017-06-26 18:42:10,238 Epoch[31] Batch [1250]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101765,	
2017-06-26 18:42:16,332 Epoch[31] Batch [1260]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101725,	
2017-06-26 18:42:22,402 Epoch[31] Batch [1270]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101659,	
2017-06-26 18:42:28,481 Epoch[31] Batch [1280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101660,	
2017-06-26 18:42:34,606 Epoch[31] Batch [1290]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.101651,	
2017-06-26 18:42:40,659 Epoch[31] Batch [1300]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101675,	
2017-06-26 18:42:46,720 Epoch[31] Batch [1310]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101633,	
2017-06-26 18:42:52,797 Epoch[31] Batch [1320]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101579,	
2017-06-26 18:42:58,849 Epoch[31] Batch [1330]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101551,	
2017-06-26 18:43:04,938 Epoch[31] Batch [1340]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101573,	
2017-06-26 18:43:11,019 Epoch[31] Batch [1350]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101532,	
2017-06-26 18:43:17,162 Epoch[31] Batch [1360]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.101511,	
2017-06-26 18:43:23,224 Epoch[31] Batch [1370]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101556,	
2017-06-26 18:43:29,304 Epoch[31] Batch [1380]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101537,	
2017-06-26 18:43:35,384 Epoch[31] Batch [1390]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101514,	
2017-06-26 18:43:41,490 Epoch[31] Batch [1400]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101419,	
2017-06-26 18:43:47,542 Epoch[31] Batch [1410]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101371,	
2017-06-26 18:43:53,626 Epoch[31] Batch [1420]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101289,	
2017-06-26 18:43:59,724 Epoch[31] Batch [1430]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101275,	
2017-06-26 18:44:05,800 Epoch[31] Batch [1440]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101316,	
2017-06-26 18:44:11,577 Epoch[31] Batch [1450]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.101286,	
2017-06-26 18:44:17,159 Epoch[31] Batch [1460]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.101299,	
2017-06-26 18:44:22,743 Epoch[31] Batch [1470]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.101281,	
2017-06-26 18:44:28,383 Epoch[31] Batch [1480]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.101294,	
2017-06-26 18:44:31,731 Epoch[31] Train-FCNLogLoss=0.101303
2017-06-26 18:44:31,731 Epoch[31] Time cost=885.059
2017-06-26 18:44:32,425 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0032.params"
2017-06-26 18:44:33,979 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0032.states"
2017-06-26 18:44:40,007 Epoch[32] Batch [10]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.124829,	
2017-06-26 18:44:45,610 Epoch[32] Batch [20]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.118198,	
2017-06-26 18:44:51,227 Epoch[32] Batch [30]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.115276,	
2017-06-26 18:44:56,778 Epoch[32] Batch [40]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.115832,	
2017-06-26 18:45:02,576 Epoch[32] Batch [50]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.113003,	
2017-06-26 18:45:08,525 Epoch[32] Batch [60]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.110227,	
2017-06-26 18:45:12,648 Epoch[32] Batch [70]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.110319,	
2017-06-26 18:45:17,827 Epoch[32] Batch [80]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.108616,	
2017-06-26 18:45:23,790 Epoch[32] Batch [90]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.107343,	
2017-06-26 18:45:29,876 Epoch[32] Batch [100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.107232,	
2017-06-26 18:45:35,935 Epoch[32] Batch [110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.105817,	
2017-06-26 18:45:42,009 Epoch[32] Batch [120]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.106457,	
2017-06-26 18:45:48,054 Epoch[32] Batch [130]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.105162,	
2017-06-26 18:45:54,116 Epoch[32] Batch [140]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.104643,	
2017-06-26 18:46:00,191 Epoch[32] Batch [150]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.105063,	
2017-06-26 18:46:06,240 Epoch[32] Batch [160]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.103879,	
2017-06-26 18:46:12,342 Epoch[32] Batch [170]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.103566,	
2017-06-26 18:46:18,433 Epoch[32] Batch [180]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.103778,	
2017-06-26 18:46:24,475 Epoch[32] Batch [190]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.103625,	
2017-06-26 18:46:30,542 Epoch[32] Batch [200]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102820,	
2017-06-26 18:46:36,537 Epoch[32] Batch [210]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102926,	
2017-06-26 18:46:42,607 Epoch[32] Batch [220]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102726,	
2017-06-26 18:46:48,691 Epoch[32] Batch [230]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102567,	
2017-06-26 18:46:54,700 Epoch[32] Batch [240]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.102225,	
2017-06-26 18:47:00,784 Epoch[32] Batch [250]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101791,	
2017-06-26 18:47:06,883 Epoch[32] Batch [260]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101659,	
2017-06-26 18:47:12,960 Epoch[32] Batch [270]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101435,	
2017-06-26 18:47:18,989 Epoch[32] Batch [280]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.101518,	
2017-06-26 18:47:25,095 Epoch[32] Batch [290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101767,	
2017-06-26 18:47:31,196 Epoch[32] Batch [300]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101929,	
2017-06-26 18:47:37,288 Epoch[32] Batch [310]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101990,	
2017-06-26 18:47:43,339 Epoch[32] Batch [320]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102165,	
2017-06-26 18:47:49,488 Epoch[32] Batch [330]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.102107,	
2017-06-26 18:47:55,532 Epoch[32] Batch [340]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102036,	
2017-06-26 18:48:01,598 Epoch[32] Batch [350]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101977,	
2017-06-26 18:48:07,669 Epoch[32] Batch [360]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101904,	
2017-06-26 18:48:13,749 Epoch[32] Batch [370]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101623,	
2017-06-26 18:48:19,876 Epoch[32] Batch [380]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.101574,	
2017-06-26 18:48:25,990 Epoch[32] Batch [390]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101548,	
2017-06-26 18:48:32,204 Epoch[32] Batch [400]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.101606,	
2017-06-26 18:48:38,245 Epoch[32] Batch [410]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.102077,	
2017-06-26 18:48:44,367 Epoch[32] Batch [420]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.102215,	
2017-06-26 18:48:50,452 Epoch[32] Batch [430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.102463,	
2017-06-26 18:48:56,060 Epoch[32] Batch [440]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102260,	
2017-06-26 18:49:01,723 Epoch[32] Batch [450]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.102139,	
2017-06-26 18:49:07,293 Epoch[32] Batch [460]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.102113,	
2017-06-26 18:49:12,852 Epoch[32] Batch [470]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.102080,	
2017-06-26 18:49:18,254 Epoch[32] Batch [480]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.102100,	
2017-06-26 18:49:23,819 Epoch[32] Batch [490]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.102093,	
2017-06-26 18:49:29,439 Epoch[32] Batch [500]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.101922,	
2017-06-26 18:49:34,942 Epoch[32] Batch [510]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.101887,	
2017-06-26 18:49:40,262 Epoch[32] Batch [520]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.101868,	
2017-06-26 18:49:46,017 Epoch[32] Batch [530]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.101824,	
2017-06-26 18:49:52,048 Epoch[32] Batch [540]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101820,	
2017-06-26 18:49:58,053 Epoch[32] Batch [550]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101663,	
2017-06-26 18:50:04,064 Epoch[32] Batch [560]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.101786,	
2017-06-26 18:50:10,187 Epoch[32] Batch [570]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.101890,	
2017-06-26 18:50:16,296 Epoch[32] Batch [580]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101810,	
2017-06-26 18:50:22,399 Epoch[32] Batch [590]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101741,	
2017-06-26 18:50:28,283 Epoch[32] Batch [600]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.101567,	
2017-06-26 18:50:34,343 Epoch[32] Batch [610]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101642,	
2017-06-26 18:50:40,378 Epoch[32] Batch [620]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101453,	
2017-06-26 18:50:46,381 Epoch[32] Batch [630]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.101566,	
2017-06-26 18:50:52,480 Epoch[32] Batch [640]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101694,	
2017-06-26 18:50:58,550 Epoch[32] Batch [650]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101640,	
2017-06-26 18:51:04,675 Epoch[32] Batch [660]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.101504,	
2017-06-26 18:51:10,752 Epoch[32] Batch [670]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101372,	
2017-06-26 18:51:16,786 Epoch[32] Batch [680]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101150,	
2017-06-26 18:51:22,871 Epoch[32] Batch [690]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100967,	
2017-06-26 18:51:28,905 Epoch[32] Batch [700]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100907,	
2017-06-26 18:51:34,986 Epoch[32] Batch [710]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101005,	
2017-06-26 18:51:41,067 Epoch[32] Batch [720]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100813,	
2017-06-26 18:51:47,157 Epoch[32] Batch [730]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100775,	
2017-06-26 18:51:53,259 Epoch[32] Batch [740]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100696,	
2017-06-26 18:51:59,364 Epoch[32] Batch [750]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100552,	
2017-06-26 18:52:05,430 Epoch[32] Batch [760]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100593,	
2017-06-26 18:52:11,454 Epoch[32] Batch [770]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.100906,	
2017-06-26 18:52:17,553 Epoch[32] Batch [780]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100916,	
2017-06-26 18:52:23,689 Epoch[32] Batch [790]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.100820,	
2017-06-26 18:52:29,738 Epoch[32] Batch [800]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100752,	
2017-06-26 18:52:35,820 Epoch[32] Batch [810]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100830,	
2017-06-26 18:52:41,887 Epoch[32] Batch [820]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100884,	
2017-06-26 18:52:47,976 Epoch[32] Batch [830]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100809,	
2017-06-26 18:52:54,072 Epoch[32] Batch [840]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100854,	
2017-06-26 18:53:00,115 Epoch[32] Batch [850]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100840,	
2017-06-26 18:53:06,181 Epoch[32] Batch [860]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101099,	
2017-06-26 18:53:12,278 Epoch[32] Batch [870]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101150,	
2017-06-26 18:53:18,341 Epoch[32] Batch [880]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101222,	
2017-06-26 18:53:24,422 Epoch[32] Batch [890]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101237,	
2017-06-26 18:53:30,524 Epoch[32] Batch [900]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101242,	
2017-06-26 18:53:36,658 Epoch[32] Batch [910]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.101219,	
2017-06-26 18:53:42,469 Epoch[32] Batch [920]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.101361,	
2017-06-26 18:53:48,175 Epoch[32] Batch [930]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.101321,	
2017-06-26 18:53:53,943 Epoch[32] Batch [940]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.101272,	
2017-06-26 18:53:59,734 Epoch[32] Batch [950]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.101254,	
2017-06-26 18:54:05,627 Epoch[32] Batch [960]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.101301,	
2017-06-26 18:54:11,215 Epoch[32] Batch [970]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.101334,	
2017-06-26 18:54:17,335 Epoch[32] Batch [980]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101390,	
2017-06-26 18:54:23,415 Epoch[32] Batch [990]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101412,	
2017-06-26 18:54:29,486 Epoch[32] Batch [1000]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101369,	
2017-06-26 18:54:35,540 Epoch[32] Batch [1010]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101232,	
2017-06-26 18:54:41,609 Epoch[32] Batch [1020]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101320,	
2017-06-26 18:54:47,723 Epoch[32] Batch [1030]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101366,	
2017-06-26 18:54:53,839 Epoch[32] Batch [1040]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.101308,	
2017-06-26 18:54:59,877 Epoch[32] Batch [1050]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101293,	
2017-06-26 18:55:06,001 Epoch[32] Batch [1060]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.101321,	
2017-06-26 18:55:12,059 Epoch[32] Batch [1070]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101340,	
2017-06-26 18:55:18,137 Epoch[32] Batch [1080]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101335,	
2017-06-26 18:55:24,241 Epoch[32] Batch [1090]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.101261,	
2017-06-26 18:55:30,291 Epoch[32] Batch [1100]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101227,	
2017-06-26 18:55:36,341 Epoch[32] Batch [1110]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.101242,	
2017-06-26 18:55:42,440 Epoch[32] Batch [1120]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.101243,	
2017-06-26 18:55:48,350 Epoch[32] Batch [1130]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.101267,	
2017-06-26 18:55:54,351 Epoch[32] Batch [1140]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.101291,	
2017-06-26 18:56:00,381 Epoch[32] Batch [1150]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.101270,	
2017-06-26 18:56:06,404 Epoch[32] Batch [1160]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.101333,	
2017-06-26 18:56:12,466 Epoch[32] Batch [1170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101394,	
2017-06-26 18:56:18,508 Epoch[32] Batch [1180]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.101420,	
2017-06-26 18:56:24,587 Epoch[32] Batch [1190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101396,	
2017-06-26 18:56:30,673 Epoch[32] Batch [1200]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.101293,	
2017-06-26 18:56:36,749 Epoch[32] Batch [1210]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101424,	
2017-06-26 18:56:42,816 Epoch[32] Batch [1220]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101399,	
2017-06-26 18:56:48,873 Epoch[32] Batch [1230]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101384,	
2017-06-26 18:56:54,954 Epoch[32] Batch [1240]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101387,	
2017-06-26 18:57:01,019 Epoch[32] Batch [1250]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101493,	
2017-06-26 18:57:07,103 Epoch[32] Batch [1260]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101511,	
2017-06-26 18:57:13,171 Epoch[32] Batch [1270]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.101532,	
2017-06-26 18:57:19,255 Epoch[32] Batch [1280]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101531,	
2017-06-26 18:57:25,332 Epoch[32] Batch [1290]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101552,	
2017-06-26 18:57:31,394 Epoch[32] Batch [1300]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101611,	
2017-06-26 18:57:37,474 Epoch[32] Batch [1310]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101703,	
2017-06-26 18:57:43,495 Epoch[32] Batch [1320]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.101648,	
2017-06-26 18:57:49,576 Epoch[32] Batch [1330]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.101828,	
2017-06-26 18:57:55,642 Epoch[32] Batch [1340]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.102125,	
2017-06-26 18:58:01,676 Epoch[32] Batch [1350]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.102236,	
2017-06-26 18:58:07,582 Epoch[32] Batch [1360]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.102276,	
2017-06-26 18:58:13,092 Epoch[32] Batch [1370]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.102338,	
2017-06-26 18:58:18,697 Epoch[32] Batch [1380]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.102536,	
2017-06-26 18:58:24,309 Epoch[32] Batch [1390]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.102648,	
2017-06-26 18:58:29,733 Epoch[32] Batch [1400]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.102632,	
2017-06-26 18:58:35,246 Epoch[32] Batch [1410]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.102657,	
2017-06-26 18:58:40,846 Epoch[32] Batch [1420]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.102685,	
2017-06-26 18:58:46,099 Epoch[32] Batch [1430]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.102667,	
2017-06-26 18:58:51,481 Epoch[32] Batch [1440]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.102648,	
2017-06-26 18:58:57,058 Epoch[32] Batch [1450]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.102757,	
2017-06-26 18:59:03,014 Epoch[32] Batch [1460]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.102767,	
2017-06-26 18:59:09,013 Epoch[32] Batch [1470]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.102754,	
2017-06-26 18:59:15,086 Epoch[32] Batch [1480]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.102734,	
2017-06-26 18:59:18,791 Epoch[32] Train-FCNLogLoss=0.102803
2017-06-26 18:59:18,791 Epoch[32] Time cost=884.811
2017-06-26 18:59:19,465 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0033.params"
2017-06-26 18:59:21,087 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0033.states"
2017-06-26 18:59:27,814 Epoch[33] Batch [10]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.107137,	
2017-06-26 18:59:33,876 Epoch[33] Batch [20]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.103423,	
2017-06-26 18:59:39,925 Epoch[33] Batch [30]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.102537,	
2017-06-26 18:59:45,918 Epoch[33] Batch [40]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.101364,	
2017-06-26 18:59:51,954 Epoch[33] Batch [50]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099678,	
2017-06-26 18:59:58,054 Epoch[33] Batch [60]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099147,	
2017-06-26 19:00:04,108 Epoch[33] Batch [70]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100189,	
2017-06-26 19:00:09,114 Epoch[33] Batch [80]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.100326,	
2017-06-26 19:00:13,345 Epoch[33] Batch [90]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.099182,	
2017-06-26 19:00:19,414 Epoch[33] Batch [100]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099307,	
2017-06-26 19:00:25,477 Epoch[33] Batch [110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101189,	
2017-06-26 19:00:31,534 Epoch[33] Batch [120]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.101475,	
2017-06-26 19:00:37,606 Epoch[33] Batch [130]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.100917,	
2017-06-26 19:00:43,710 Epoch[33] Batch [140]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100821,	
2017-06-26 19:00:49,850 Epoch[33] Batch [150]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.100127,	
2017-06-26 19:00:55,925 Epoch[33] Batch [160]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099749,	
2017-06-26 19:01:02,002 Epoch[33] Batch [170]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099684,	
2017-06-26 19:01:08,112 Epoch[33] Batch [180]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100413,	
2017-06-26 19:01:14,187 Epoch[33] Batch [190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100413,	
2017-06-26 19:01:20,198 Epoch[33] Batch [200]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.100127,	
2017-06-26 19:01:26,114 Epoch[33] Batch [210]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.100587,	
2017-06-26 19:01:32,176 Epoch[33] Batch [220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.100163,	
2017-06-26 19:01:38,211 Epoch[33] Batch [230]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100420,	
2017-06-26 19:01:44,287 Epoch[33] Batch [240]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100321,	
2017-06-26 19:01:50,296 Epoch[33] Batch [250]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.100389,	
2017-06-26 19:01:56,332 Epoch[33] Batch [260]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.100088,	
2017-06-26 19:02:02,410 Epoch[33] Batch [270]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100182,	
2017-06-26 19:02:08,508 Epoch[33] Batch [280]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.100250,	
2017-06-26 19:02:14,616 Epoch[33] Batch [290]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.100139,	
2017-06-26 19:02:20,615 Epoch[33] Batch [300]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.099539,	
2017-06-26 19:02:26,728 Epoch[33] Batch [310]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.099330,	
2017-06-26 19:02:32,796 Epoch[33] Batch [320]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099323,	
2017-06-26 19:02:38,905 Epoch[33] Batch [330]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099412,	
2017-06-26 19:02:44,940 Epoch[33] Batch [340]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099519,	
2017-06-26 19:02:50,680 Epoch[33] Batch [350]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.099672,	
2017-06-26 19:02:56,227 Epoch[33] Batch [360]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.099286,	
2017-06-26 19:03:01,791 Epoch[33] Batch [370]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.099244,	
2017-06-26 19:03:07,390 Epoch[33] Batch [380]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.099324,	
2017-06-26 19:03:12,794 Epoch[33] Batch [390]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.099410,	
2017-06-26 19:03:18,245 Epoch[33] Batch [400]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.099354,	
2017-06-26 19:03:23,829 Epoch[33] Batch [410]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.099147,	
2017-06-26 19:03:29,326 Epoch[33] Batch [420]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.099399,	
2017-06-26 19:03:34,760 Epoch[33] Batch [430]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.099635,	
2017-06-26 19:03:39,995 Epoch[33] Batch [440]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.099618,	
2017-06-26 19:03:46,020 Epoch[33] Batch [450]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099517,	
2017-06-26 19:03:52,071 Epoch[33] Batch [460]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099706,	
2017-06-26 19:03:58,186 Epoch[33] Batch [470]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.099688,	
2017-06-26 19:04:04,223 Epoch[33] Batch [480]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099494,	
2017-06-26 19:04:10,143 Epoch[33] Batch [490]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.099443,	
2017-06-26 19:04:16,109 Epoch[33] Batch [500]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099812,	
2017-06-26 19:04:22,148 Epoch[33] Batch [510]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.100066,	
2017-06-26 19:04:28,205 Epoch[33] Batch [520]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100060,	
2017-06-26 19:04:34,292 Epoch[33] Batch [530]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.100070,	
2017-06-26 19:04:40,391 Epoch[33] Batch [540]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099925,	
2017-06-26 19:04:46,452 Epoch[33] Batch [550]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099846,	
2017-06-26 19:04:52,528 Epoch[33] Batch [560]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099946,	
2017-06-26 19:04:58,582 Epoch[33] Batch [570]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099966,	
2017-06-26 19:05:04,663 Epoch[33] Batch [580]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100073,	
2017-06-26 19:05:10,776 Epoch[33] Batch [590]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100045,	
2017-06-26 19:05:16,824 Epoch[33] Batch [600]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099958,	
2017-06-26 19:05:22,913 Epoch[33] Batch [610]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099859,	
2017-06-26 19:05:28,973 Epoch[33] Batch [620]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099732,	
2017-06-26 19:05:34,882 Epoch[33] Batch [630]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.100036,	
2017-06-26 19:05:40,930 Epoch[33] Batch [640]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.100177,	
2017-06-26 19:05:47,006 Epoch[33] Batch [650]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.100070,	
2017-06-26 19:05:53,069 Epoch[33] Batch [660]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099950,	
2017-06-26 19:05:59,141 Epoch[33] Batch [670]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099887,	
2017-06-26 19:06:05,204 Epoch[33] Batch [680]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099630,	
2017-06-26 19:06:11,261 Epoch[33] Batch [690]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099540,	
2017-06-26 19:06:17,320 Epoch[33] Batch [700]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099437,	
2017-06-26 19:06:23,390 Epoch[33] Batch [710]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099305,	
2017-06-26 19:06:29,436 Epoch[33] Batch [720]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.099195,	
2017-06-26 19:06:35,497 Epoch[33] Batch [730]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099209,	
2017-06-26 19:06:41,553 Epoch[33] Batch [740]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099253,	
2017-06-26 19:06:47,621 Epoch[33] Batch [750]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099173,	
2017-06-26 19:06:53,691 Epoch[33] Batch [760]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099289,	
2017-06-26 19:06:59,754 Epoch[33] Batch [770]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099332,	
2017-06-26 19:07:05,826 Epoch[33] Batch [780]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099338,	
2017-06-26 19:07:11,876 Epoch[33] Batch [790]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099383,	
2017-06-26 19:07:17,936 Epoch[33] Batch [800]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099313,	
2017-06-26 19:07:23,997 Epoch[33] Batch [810]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099387,	
2017-06-26 19:07:30,058 Epoch[33] Batch [820]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099211,	
2017-06-26 19:07:36,139 Epoch[33] Batch [830]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099157,	
2017-06-26 19:07:41,843 Epoch[33] Batch [840]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.098945,	
2017-06-26 19:07:47,580 Epoch[33] Batch [850]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.098910,	
2017-06-26 19:07:53,270 Epoch[33] Batch [860]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.098796,	
2017-06-26 19:07:59,004 Epoch[33] Batch [870]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.098752,	
2017-06-26 19:08:04,709 Epoch[33] Batch [880]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.098759,	
2017-06-26 19:08:10,431 Epoch[33] Batch [890]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.098700,	
2017-06-26 19:08:16,269 Epoch[33] Batch [900]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.098700,	
2017-06-26 19:08:22,320 Epoch[33] Batch [910]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098635,	
2017-06-26 19:08:28,382 Epoch[33] Batch [920]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098508,	
2017-06-26 19:08:34,471 Epoch[33] Batch [930]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098551,	
2017-06-26 19:08:40,496 Epoch[33] Batch [940]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.098541,	
2017-06-26 19:08:46,497 Epoch[33] Batch [950]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.098630,	
2017-06-26 19:08:52,578 Epoch[33] Batch [960]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098709,	
2017-06-26 19:08:58,626 Epoch[33] Batch [970]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098668,	
2017-06-26 19:09:04,724 Epoch[33] Batch [980]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098599,	
2017-06-26 19:09:10,819 Epoch[33] Batch [990]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098662,	
2017-06-26 19:09:16,897 Epoch[33] Batch [1000]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098717,	
2017-06-26 19:09:22,987 Epoch[33] Batch [1010]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098640,	
2017-06-26 19:09:29,058 Epoch[33] Batch [1020]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098656,	
2017-06-26 19:09:35,158 Epoch[33] Batch [1030]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098596,	
2017-06-26 19:09:41,231 Epoch[33] Batch [1040]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098618,	
2017-06-26 19:09:47,297 Epoch[33] Batch [1050]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098715,	
2017-06-26 19:09:53,373 Epoch[33] Batch [1060]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098703,	
2017-06-26 19:09:59,440 Epoch[33] Batch [1070]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098681,	
2017-06-26 19:10:05,558 Epoch[33] Batch [1080]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098594,	
2017-06-26 19:10:11,571 Epoch[33] Batch [1090]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.098711,	
2017-06-26 19:10:17,657 Epoch[33] Batch [1100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098754,	
2017-06-26 19:10:23,707 Epoch[33] Batch [1110]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098761,	
2017-06-26 19:10:29,832 Epoch[33] Batch [1120]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098797,	
2017-06-26 19:10:35,852 Epoch[33] Batch [1130]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.098802,	
2017-06-26 19:10:41,964 Epoch[33] Batch [1140]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098798,	
2017-06-26 19:10:48,028 Epoch[33] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098834,	
2017-06-26 19:10:54,114 Epoch[33] Batch [1160]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098780,	
2017-06-26 19:11:00,174 Epoch[33] Batch [1170]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098717,	
2017-06-26 19:11:06,263 Epoch[33] Batch [1180]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098697,	
2017-06-26 19:11:12,335 Epoch[33] Batch [1190]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098680,	
2017-06-26 19:11:18,407 Epoch[33] Batch [1200]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098699,	
2017-06-26 19:11:24,462 Epoch[33] Batch [1210]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098830,	
2017-06-26 19:11:30,523 Epoch[33] Batch [1220]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098865,	
2017-06-26 19:11:36,616 Epoch[33] Batch [1230]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098851,	
2017-06-26 19:11:42,747 Epoch[33] Batch [1240]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.098974,	
2017-06-26 19:11:48,839 Epoch[33] Batch [1250]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098912,	
2017-06-26 19:11:54,882 Epoch[33] Batch [1260]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098914,	
2017-06-26 19:12:00,914 Epoch[33] Batch [1270]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.098909,	
2017-06-26 19:12:07,053 Epoch[33] Batch [1280]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.098886,	
2017-06-26 19:12:12,657 Epoch[33] Batch [1290]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098995,	
2017-06-26 19:12:18,208 Epoch[33] Batch [1300]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.099049,	
2017-06-26 19:12:23,813 Epoch[33] Batch [1310]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.099066,	
2017-06-26 19:12:29,385 Epoch[33] Batch [1320]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.099086,	
2017-06-26 19:12:34,978 Epoch[33] Batch [1330]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099184,	
2017-06-26 19:12:40,528 Epoch[33] Batch [1340]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.099174,	
2017-06-26 19:12:46,150 Epoch[33] Batch [1350]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.099118,	
2017-06-26 19:12:51,681 Epoch[33] Batch [1360]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.099203,	
2017-06-26 19:12:56,969 Epoch[33] Batch [1370]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.099301,	
2017-06-26 19:13:01,924 Epoch[33] Batch [1380]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.099317,	
2017-06-26 19:13:07,890 Epoch[33] Batch [1390]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099247,	
2017-06-26 19:13:13,960 Epoch[33] Batch [1400]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099297,	
2017-06-26 19:13:20,064 Epoch[33] Batch [1410]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099287,	
2017-06-26 19:13:26,090 Epoch[33] Batch [1420]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.099123,	
2017-06-26 19:13:32,079 Epoch[33] Batch [1430]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.099078,	
2017-06-26 19:13:38,095 Epoch[33] Batch [1440]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.099067,	
2017-06-26 19:13:44,141 Epoch[33] Batch [1450]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.099012,	
2017-06-26 19:13:50,234 Epoch[33] Batch [1460]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098992,	
2017-06-26 19:13:56,325 Epoch[33] Batch [1470]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098962,	
2017-06-26 19:14:02,382 Epoch[33] Batch [1480]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098945,	
2017-06-26 19:14:06,029 Epoch[33] Train-FCNLogLoss=0.098913
2017-06-26 19:14:06,029 Epoch[33] Time cost=884.942
2017-06-26 19:14:06,727 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0034.params"
2017-06-26 19:14:08,358 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0034.states"
2017-06-26 19:14:14,966 Epoch[34] Batch [10]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.090499,	
2017-06-26 19:14:21,042 Epoch[34] Batch [20]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.094574,	
2017-06-26 19:14:27,136 Epoch[34] Batch [30]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.092961,	
2017-06-26 19:14:33,259 Epoch[34] Batch [40]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.093850,	
2017-06-26 19:14:39,069 Epoch[34] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.096073,	
2017-06-26 19:14:45,103 Epoch[34] Batch [60]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.095092,	
2017-06-26 19:14:51,078 Epoch[34] Batch [70]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.096332,	
2017-06-26 19:14:57,169 Epoch[34] Batch [80]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.096389,	
2017-06-26 19:15:03,235 Epoch[34] Batch [90]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097150,	
2017-06-26 19:15:07,935 Epoch[34] Batch [100]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.096569,	
2017-06-26 19:15:12,580 Epoch[34] Batch [110]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.096386,	
2017-06-26 19:15:18,610 Epoch[34] Batch [120]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.096251,	
2017-06-26 19:15:24,724 Epoch[34] Batch [130]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.095710,	
2017-06-26 19:15:30,799 Epoch[34] Batch [140]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.096502,	
2017-06-26 19:15:36,837 Epoch[34] Batch [150]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.096356,	
2017-06-26 19:15:42,958 Epoch[34] Batch [160]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.096575,	
2017-06-26 19:15:49,030 Epoch[34] Batch [170]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.096749,	
2017-06-26 19:15:55,125 Epoch[34] Batch [180]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097077,	
2017-06-26 19:16:01,219 Epoch[34] Batch [190]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097681,	
2017-06-26 19:16:07,302 Epoch[34] Batch [200]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097343,	
2017-06-26 19:16:13,339 Epoch[34] Batch [210]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.097085,	
2017-06-26 19:16:19,428 Epoch[34] Batch [220]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097387,	
2017-06-26 19:16:25,519 Epoch[34] Batch [230]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097606,	
2017-06-26 19:16:31,580 Epoch[34] Batch [240]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097625,	
2017-06-26 19:16:37,685 Epoch[34] Batch [250]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.097841,	
2017-06-26 19:16:43,795 Epoch[34] Batch [260]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.097748,	
2017-06-26 19:16:49,836 Epoch[34] Batch [270]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097741,	
2017-06-26 19:16:55,594 Epoch[34] Batch [280]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.097581,	
2017-06-26 19:17:01,149 Epoch[34] Batch [290]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.097382,	
2017-06-26 19:17:06,772 Epoch[34] Batch [300]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.097075,	
2017-06-26 19:17:12,302 Epoch[34] Batch [310]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.097053,	
2017-06-26 19:17:17,905 Epoch[34] Batch [320]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.096792,	
2017-06-26 19:17:23,449 Epoch[34] Batch [330]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.096597,	
2017-06-26 19:17:29,054 Epoch[34] Batch [340]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.096524,	
2017-06-26 19:17:34,619 Epoch[34] Batch [350]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.096792,	
2017-06-26 19:17:40,189 Epoch[34] Batch [360]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.096678,	
2017-06-26 19:17:45,582 Epoch[34] Batch [370]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.096522,	
2017-06-26 19:17:51,564 Epoch[34] Batch [380]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.096772,	
2017-06-26 19:17:57,596 Epoch[34] Batch [390]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.096788,	
2017-06-26 19:18:03,617 Epoch[34] Batch [400]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097173,	
2017-06-26 19:18:09,611 Epoch[34] Batch [410]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.097048,	
2017-06-26 19:18:15,699 Epoch[34] Batch [420]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097251,	
2017-06-26 19:18:21,762 Epoch[34] Batch [430]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097270,	
2017-06-26 19:18:27,820 Epoch[34] Batch [440]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097142,	
2017-06-26 19:18:33,935 Epoch[34] Batch [450]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.096967,	
2017-06-26 19:18:40,000 Epoch[34] Batch [460]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097082,	
2017-06-26 19:18:46,104 Epoch[34] Batch [470]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.097179,	
2017-06-26 19:18:52,181 Epoch[34] Batch [480]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097056,	
2017-06-26 19:18:58,286 Epoch[34] Batch [490]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.097257,	
2017-06-26 19:19:04,370 Epoch[34] Batch [500]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097288,	
2017-06-26 19:19:10,397 Epoch[34] Batch [510]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097240,	
2017-06-26 19:19:16,320 Epoch[34] Batch [520]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.097379,	
2017-06-26 19:19:22,319 Epoch[34] Batch [530]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.097448,	
2017-06-26 19:19:28,404 Epoch[34] Batch [540]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097475,	
2017-06-26 19:19:34,441 Epoch[34] Batch [550]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.097560,	
2017-06-26 19:19:40,429 Epoch[34] Batch [560]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.097804,	
2017-06-26 19:19:46,462 Epoch[34] Batch [570]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.097893,	
2017-06-26 19:19:52,523 Epoch[34] Batch [580]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098006,	
2017-06-26 19:19:58,597 Epoch[34] Batch [590]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097980,	
2017-06-26 19:20:04,690 Epoch[34] Batch [600]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098023,	
2017-06-26 19:20:10,778 Epoch[34] Batch [610]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098119,	
2017-06-26 19:20:16,821 Epoch[34] Batch [620]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098489,	
2017-06-26 19:20:22,925 Epoch[34] Batch [630]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098526,	
2017-06-26 19:20:28,959 Epoch[34] Batch [640]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.098479,	
2017-06-26 19:20:35,095 Epoch[34] Batch [650]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.098463,	
2017-06-26 19:20:41,209 Epoch[34] Batch [660]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098507,	
2017-06-26 19:20:47,247 Epoch[34] Batch [670]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.098508,	
2017-06-26 19:20:53,319 Epoch[34] Batch [680]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098433,	
2017-06-26 19:20:59,372 Epoch[34] Batch [690]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098481,	
2017-06-26 19:21:05,464 Epoch[34] Batch [700]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098501,	
2017-06-26 19:21:11,573 Epoch[34] Batch [710]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098541,	
2017-06-26 19:21:17,656 Epoch[34] Batch [720]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098428,	
2017-06-26 19:21:23,752 Epoch[34] Batch [730]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098549,	
2017-06-26 19:21:29,840 Epoch[34] Batch [740]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098629,	
2017-06-26 19:21:35,881 Epoch[34] Batch [750]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098603,	
2017-06-26 19:21:41,953 Epoch[34] Batch [760]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098706,	
2017-06-26 19:21:47,616 Epoch[34] Batch [770]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.098774,	
2017-06-26 19:21:53,198 Epoch[34] Batch [780]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.098798,	
2017-06-26 19:21:58,801 Epoch[34] Batch [790]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098707,	
2017-06-26 19:22:04,370 Epoch[34] Batch [800]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.098640,	
2017-06-26 19:22:09,888 Epoch[34] Batch [810]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.098544,	
2017-06-26 19:22:15,387 Epoch[34] Batch [820]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.098483,	
2017-06-26 19:22:20,937 Epoch[34] Batch [830]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.098459,	
2017-06-26 19:22:26,543 Epoch[34] Batch [840]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098257,	
2017-06-26 19:22:32,201 Epoch[34] Batch [850]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.098170,	
2017-06-26 19:22:38,237 Epoch[34] Batch [860]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.098132,	
2017-06-26 19:22:44,282 Epoch[34] Batch [870]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098072,	
2017-06-26 19:22:50,285 Epoch[34] Batch [880]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.098029,	
2017-06-26 19:22:56,328 Epoch[34] Batch [890]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098024,	
2017-06-26 19:23:02,432 Epoch[34] Batch [900]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.097952,	
2017-06-26 19:23:08,527 Epoch[34] Batch [910]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097960,	
2017-06-26 19:23:14,609 Epoch[34] Batch [920]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098078,	
2017-06-26 19:23:20,689 Epoch[34] Batch [930]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097991,	
2017-06-26 19:23:26,807 Epoch[34] Batch [940]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.097887,	
2017-06-26 19:23:32,863 Epoch[34] Batch [950]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097833,	
2017-06-26 19:23:38,949 Epoch[34] Batch [960]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097874,	
2017-06-26 19:23:45,018 Epoch[34] Batch [970]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097800,	
2017-06-26 19:23:50,917 Epoch[34] Batch [980]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.097793,	
2017-06-26 19:23:56,959 Epoch[34] Batch [990]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097836,	
2017-06-26 19:24:02,975 Epoch[34] Batch [1000]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.097844,	
2017-06-26 19:24:09,044 Epoch[34] Batch [1010]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097792,	
2017-06-26 19:24:15,036 Epoch[34] Batch [1020]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.097898,	
2017-06-26 19:24:21,057 Epoch[34] Batch [1030]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097846,	
2017-06-26 19:24:27,180 Epoch[34] Batch [1040]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.097877,	
2017-06-26 19:24:33,240 Epoch[34] Batch [1050]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097845,	
2017-06-26 19:24:39,338 Epoch[34] Batch [1060]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097826,	
2017-06-26 19:24:45,412 Epoch[34] Batch [1070]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097778,	
2017-06-26 19:24:51,458 Epoch[34] Batch [1080]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097860,	
2017-06-26 19:24:57,539 Epoch[34] Batch [1090]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097818,	
2017-06-26 19:25:03,575 Epoch[34] Batch [1100]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.097819,	
2017-06-26 19:25:09,630 Epoch[34] Batch [1110]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097969,	
2017-06-26 19:25:15,726 Epoch[34] Batch [1120]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098076,	
2017-06-26 19:25:21,861 Epoch[34] Batch [1130]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.098040,	
2017-06-26 19:25:27,953 Epoch[34] Batch [1140]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098112,	
2017-06-26 19:25:34,014 Epoch[34] Batch [1150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098173,	
2017-06-26 19:25:40,029 Epoch[34] Batch [1160]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.098238,	
2017-06-26 19:25:46,119 Epoch[34] Batch [1170]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098175,	
2017-06-26 19:25:52,200 Epoch[34] Batch [1180]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098066,	
2017-06-26 19:25:58,307 Epoch[34] Batch [1190]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.097938,	
2017-06-26 19:26:04,332 Epoch[34] Batch [1200]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097964,	
2017-06-26 19:26:10,389 Epoch[34] Batch [1210]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098035,	
2017-06-26 19:26:16,487 Epoch[34] Batch [1220]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098051,	
2017-06-26 19:26:22,589 Epoch[34] Batch [1230]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098066,	
2017-06-26 19:26:28,638 Epoch[34] Batch [1240]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098099,	
2017-06-26 19:26:34,205 Epoch[34] Batch [1250]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.098052,	
2017-06-26 19:26:39,939 Epoch[34] Batch [1260]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.098045,	
2017-06-26 19:26:45,697 Epoch[34] Batch [1270]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.098080,	
2017-06-26 19:26:51,397 Epoch[34] Batch [1280]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.098100,	
2017-06-26 19:26:57,072 Epoch[34] Batch [1290]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.098086,	
2017-06-26 19:27:02,747 Epoch[34] Batch [1300]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.098123,	
2017-06-26 19:27:08,602 Epoch[34] Batch [1310]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.098132,	
2017-06-26 19:27:14,708 Epoch[34] Batch [1320]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098117,	
2017-06-26 19:27:20,758 Epoch[34] Batch [1330]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098083,	
2017-06-26 19:27:26,848 Epoch[34] Batch [1340]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098096,	
2017-06-26 19:27:32,971 Epoch[34] Batch [1350]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098152,	
2017-06-26 19:27:39,055 Epoch[34] Batch [1360]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098220,	
2017-06-26 19:27:45,119 Epoch[34] Batch [1370]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098272,	
2017-06-26 19:27:51,201 Epoch[34] Batch [1380]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098325,	
2017-06-26 19:27:57,297 Epoch[34] Batch [1390]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098393,	
2017-06-26 19:28:03,323 Epoch[34] Batch [1400]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.098386,	
2017-06-26 19:28:09,410 Epoch[34] Batch [1410]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098416,	
2017-06-26 19:28:15,533 Epoch[34] Batch [1420]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098497,	
2017-06-26 19:28:21,619 Epoch[34] Batch [1430]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098544,	
2017-06-26 19:28:27,628 Epoch[34] Batch [1440]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.098611,	
2017-06-26 19:28:33,745 Epoch[34] Batch [1450]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.098689,	
2017-06-26 19:28:39,818 Epoch[34] Batch [1460]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098725,	
2017-06-26 19:28:45,897 Epoch[34] Batch [1470]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098762,	
2017-06-26 19:28:51,954 Epoch[34] Batch [1480]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098752,	
2017-06-26 19:28:55,648 Epoch[34] Train-FCNLogLoss=0.098745
2017-06-26 19:28:55,648 Epoch[34] Time cost=887.290
2017-06-26 19:28:56,313 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0035.params"
2017-06-26 19:28:58,921 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0035.states"
2017-06-26 19:29:05,748 Epoch[35] Batch [10]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-26 19:29:11,867 Epoch[35] Batch [20]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.100627,	
2017-06-26 19:29:17,961 Epoch[35] Batch [30]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099123,	
2017-06-26 19:29:24,012 Epoch[35] Batch [40]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097227,	
2017-06-26 19:29:30,080 Epoch[35] Batch [50]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.095887,	
2017-06-26 19:29:36,156 Epoch[35] Batch [60]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.095542,	
2017-06-26 19:29:42,190 Epoch[35] Batch [70]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.097097,	
2017-06-26 19:29:48,154 Epoch[35] Batch [80]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.098142,	
2017-06-26 19:29:54,171 Epoch[35] Batch [90]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.098115,	
2017-06-26 19:30:00,163 Epoch[35] Batch [100]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.096755,	
2017-06-26 19:30:05,120 Epoch[35] Batch [110]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.097292,	
2017-06-26 19:30:09,084 Epoch[35] Batch [120]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.097835,	
2017-06-26 19:30:14,990 Epoch[35] Batch [130]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.098589,	
2017-06-26 19:30:21,044 Epoch[35] Batch [140]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098906,	
2017-06-26 19:30:27,106 Epoch[35] Batch [150]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099723,	
2017-06-26 19:30:33,088 Epoch[35] Batch [160]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.099819,	
2017-06-26 19:30:39,174 Epoch[35] Batch [170]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099891,	
2017-06-26 19:30:45,230 Epoch[35] Batch [180]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099846,	
2017-06-26 19:30:51,313 Epoch[35] Batch [190]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099939,	
2017-06-26 19:30:57,076 Epoch[35] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.100236,	
2017-06-26 19:31:02,657 Epoch[35] Batch [210]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.099945,	
2017-06-26 19:31:08,252 Epoch[35] Batch [220]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099814,	
2017-06-26 19:31:13,848 Epoch[35] Batch [230]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.099339,	
2017-06-26 19:31:19,435 Epoch[35] Batch [240]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.099955,	
2017-06-26 19:31:25,019 Epoch[35] Batch [250]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.099754,	
2017-06-26 19:31:30,621 Epoch[35] Batch [260]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.099361,	
2017-06-26 19:31:36,193 Epoch[35] Batch [270]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.098985,	
2017-06-26 19:31:41,749 Epoch[35] Batch [280]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.098959,	
2017-06-26 19:31:47,816 Epoch[35] Batch [290]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098902,	
2017-06-26 19:31:53,887 Epoch[35] Batch [300]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099097,	
2017-06-26 19:31:59,944 Epoch[35] Batch [310]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099439,	
2017-06-26 19:32:05,974 Epoch[35] Batch [320]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.099630,	
2017-06-26 19:32:12,077 Epoch[35] Batch [330]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099719,	
2017-06-26 19:32:18,181 Epoch[35] Batch [340]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.099518,	
2017-06-26 19:32:24,245 Epoch[35] Batch [350]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099242,	
2017-06-26 19:32:30,329 Epoch[35] Batch [360]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099295,	
2017-06-26 19:32:36,424 Epoch[35] Batch [370]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099458,	
2017-06-26 19:32:42,525 Epoch[35] Batch [380]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.099604,	
2017-06-26 19:32:48,583 Epoch[35] Batch [390]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.099899,	
2017-06-26 19:32:54,636 Epoch[35] Batch [400]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.099807,	
2017-06-26 19:33:00,716 Epoch[35] Batch [410]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.099569,	
2017-06-26 19:33:06,804 Epoch[35] Batch [420]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099803,	
2017-06-26 19:33:12,941 Epoch[35] Batch [430]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.099935,	
2017-06-26 19:33:19,026 Epoch[35] Batch [440]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099520,	
2017-06-26 19:33:25,092 Epoch[35] Batch [450]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.099437,	
2017-06-26 19:33:31,180 Epoch[35] Batch [460]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.099348,	
2017-06-26 19:33:37,321 Epoch[35] Batch [470]	Speed: 6.51 samples/sec	Train-FCNLogLoss=0.099129,	
2017-06-26 19:33:43,361 Epoch[35] Batch [480]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098910,	
2017-06-26 19:33:49,423 Epoch[35] Batch [490]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098777,	
2017-06-26 19:33:55,480 Epoch[35] Batch [500]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098726,	
2017-06-26 19:34:01,575 Epoch[35] Batch [510]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098726,	
2017-06-26 19:34:07,681 Epoch[35] Batch [520]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098857,	
2017-06-26 19:34:13,727 Epoch[35] Batch [530]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098543,	
2017-06-26 19:34:19,837 Epoch[35] Batch [540]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.098544,	
2017-06-26 19:34:25,884 Epoch[35] Batch [550]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098340,	
2017-06-26 19:34:31,941 Epoch[35] Batch [560]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098304,	
2017-06-26 19:34:38,035 Epoch[35] Batch [570]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098316,	
2017-06-26 19:34:44,134 Epoch[35] Batch [580]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098303,	
2017-06-26 19:34:50,210 Epoch[35] Batch [590]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098119,	
2017-06-26 19:34:56,286 Epoch[35] Batch [600]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098182,	
2017-06-26 19:35:02,370 Epoch[35] Batch [610]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098331,	
2017-06-26 19:35:08,466 Epoch[35] Batch [620]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.098384,	
2017-06-26 19:35:14,531 Epoch[35] Batch [630]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098247,	
2017-06-26 19:35:20,617 Epoch[35] Batch [640]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098205,	
2017-06-26 19:35:26,672 Epoch[35] Batch [650]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098314,	
2017-06-26 19:35:32,763 Epoch[35] Batch [660]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098308,	
2017-06-26 19:35:38,818 Epoch[35] Batch [670]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098366,	
2017-06-26 19:35:44,339 Epoch[35] Batch [680]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.098321,	
2017-06-26 19:35:49,949 Epoch[35] Batch [690]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.098180,	
2017-06-26 19:35:55,543 Epoch[35] Batch [700]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098180,	
2017-06-26 19:36:01,136 Epoch[35] Batch [710]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.098207,	
2017-06-26 19:36:06,678 Epoch[35] Batch [720]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.098262,	
2017-06-26 19:36:12,304 Epoch[35] Batch [730]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.098295,	
2017-06-26 19:36:17,882 Epoch[35] Batch [740]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.098234,	
2017-06-26 19:36:23,488 Epoch[35] Batch [750]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.098024,	
2017-06-26 19:36:29,007 Epoch[35] Batch [760]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.098018,	
2017-06-26 19:36:34,900 Epoch[35] Batch [770]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.097929,	
2017-06-26 19:36:40,851 Epoch[35] Batch [780]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.097871,	
2017-06-26 19:36:46,911 Epoch[35] Batch [790]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097747,	
2017-06-26 19:36:53,044 Epoch[35] Batch [800]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.097788,	
2017-06-26 19:36:58,961 Epoch[35] Batch [810]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.097728,	
2017-06-26 19:37:05,018 Epoch[35] Batch [820]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097688,	
2017-06-26 19:37:11,068 Epoch[35] Batch [830]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097684,	
2017-06-26 19:37:17,150 Epoch[35] Batch [840]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097913,	
2017-06-26 19:37:23,190 Epoch[35] Batch [850]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097995,	
2017-06-26 19:37:29,269 Epoch[35] Batch [860]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.098086,	
2017-06-26 19:37:35,309 Epoch[35] Batch [870]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.098101,	
2017-06-26 19:37:41,381 Epoch[35] Batch [880]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098116,	
2017-06-26 19:37:47,431 Epoch[35] Batch [890]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.098025,	
2017-06-26 19:37:53,499 Epoch[35] Batch [900]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.098024,	
2017-06-26 19:37:59,527 Epoch[35] Batch [910]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097988,	
2017-06-26 19:38:05,514 Epoch[35] Batch [920]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.098007,	
2017-06-26 19:38:11,574 Epoch[35] Batch [930]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.098039,	
2017-06-26 19:38:17,697 Epoch[35] Batch [940]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.098045,	
2017-06-26 19:38:23,781 Epoch[35] Batch [950]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.098041,	
2017-06-26 19:38:29,832 Epoch[35] Batch [960]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097818,	
2017-06-26 19:38:35,922 Epoch[35] Batch [970]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097819,	
2017-06-26 19:38:42,016 Epoch[35] Batch [980]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097832,	
2017-06-26 19:38:48,054 Epoch[35] Batch [990]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097843,	
2017-06-26 19:38:54,181 Epoch[35] Batch [1000]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.097843,	
2017-06-26 19:39:00,088 Epoch[35] Batch [1010]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.097781,	
2017-06-26 19:39:06,135 Epoch[35] Batch [1020]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.097825,	
2017-06-26 19:39:12,168 Epoch[35] Batch [1030]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.097848,	
2017-06-26 19:39:18,147 Epoch[35] Batch [1040]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.097894,	
2017-06-26 19:39:24,251 Epoch[35] Batch [1050]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.097934,	
2017-06-26 19:39:30,312 Epoch[35] Batch [1060]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097884,	
2017-06-26 19:39:36,424 Epoch[35] Batch [1070]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.097885,	
2017-06-26 19:39:42,499 Epoch[35] Batch [1080]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.097930,	
2017-06-26 19:39:48,583 Epoch[35] Batch [1090]	Speed: 6.58 samples/sec	Train-FCNLogLoss=0.097998,	
2017-06-26 19:39:54,672 Epoch[35] Batch [1100]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.097937,	
2017-06-26 19:40:00,731 Epoch[35] Batch [1110]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.097812,	
2017-06-26 19:40:06,825 Epoch[35] Batch [1120]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.097856,	
2017-06-26 19:40:12,875 Epoch[35] Batch [1130]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097808,	
2017-06-26 19:40:18,928 Epoch[35] Batch [1140]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.097937,	
2017-06-26 19:40:24,954 Epoch[35] Batch [1150]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.097870,	
2017-06-26 19:40:30,512 Epoch[35] Batch [1160]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.097863,	
2017-06-26 19:40:35,924 Epoch[35] Batch [1170]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.097742,	
2017-06-26 19:40:41,409 Epoch[35] Batch [1180]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.097764,	
2017-06-26 19:40:47,005 Epoch[35] Batch [1190]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.097727,	
2017-06-26 19:40:52,633 Epoch[35] Batch [1200]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.097706,	
2017-06-26 19:40:58,011 Epoch[35] Batch [1210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097622,	
2017-06-26 19:41:03,648 Epoch[35] Batch [1220]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.097556,	
2017-06-26 19:41:09,156 Epoch[35] Batch [1230]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.097546,	
2017-06-26 19:41:14,702 Epoch[35] Batch [1240]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.097501,	
2017-06-26 19:41:20,154 Epoch[35] Batch [1250]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.097483,	
2017-06-26 19:41:25,509 Epoch[35] Batch [1260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097512,	
2017-06-26 19:41:30,782 Epoch[35] Batch [1270]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097472,	
2017-06-26 19:41:36,146 Epoch[35] Batch [1280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097493,	
2017-06-26 19:41:41,512 Epoch[35] Batch [1290]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097461,	
2017-06-26 19:41:46,824 Epoch[35] Batch [1300]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097558,	
2017-06-26 19:41:52,208 Epoch[35] Batch [1310]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.097566,	
2017-06-26 19:41:57,564 Epoch[35] Batch [1320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097621,	
2017-06-26 19:42:02,902 Epoch[35] Batch [1330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097592,	
2017-06-26 19:42:08,241 Epoch[35] Batch [1340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097557,	
2017-06-26 19:42:13,605 Epoch[35] Batch [1350]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097575,	
2017-06-26 19:42:18,893 Epoch[35] Batch [1360]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097526,	
2017-06-26 19:42:24,238 Epoch[35] Batch [1370]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097578,	
2017-06-26 19:42:29,624 Epoch[35] Batch [1380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.097518,	
2017-06-26 19:42:34,903 Epoch[35] Batch [1390]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.097538,	
2017-06-26 19:42:40,256 Epoch[35] Batch [1400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097560,	
2017-06-26 19:42:45,654 Epoch[35] Batch [1410]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097568,	
2017-06-26 19:42:50,960 Epoch[35] Batch [1420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097590,	
2017-06-26 19:42:56,307 Epoch[35] Batch [1430]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097563,	
2017-06-26 19:43:01,680 Epoch[35] Batch [1440]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097534,	
2017-06-26 19:43:07,003 Epoch[35] Batch [1450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097513,	
2017-06-26 19:43:12,336 Epoch[35] Batch [1460]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097497,	
2017-06-26 19:43:17,686 Epoch[35] Batch [1470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097517,	
2017-06-26 19:43:23,057 Epoch[35] Batch [1480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097516,	
2017-06-26 19:43:26,223 Epoch[35] Train-FCNLogLoss=0.097509
2017-06-26 19:43:26,223 Epoch[35] Time cost=867.302
2017-06-26 19:43:26,879 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0036.params"
2017-06-26 19:43:28,613 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0036.states"
2017-06-26 19:43:34,596 Epoch[36] Batch [10]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.097426,	
2017-06-26 19:43:39,957 Epoch[36] Batch [20]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093577,	
2017-06-26 19:43:45,323 Epoch[36] Batch [30]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093243,	
2017-06-26 19:43:50,601 Epoch[36] Batch [40]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096723,	
2017-06-26 19:43:55,941 Epoch[36] Batch [50]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097324,	
2017-06-26 19:44:01,290 Epoch[36] Batch [60]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095015,	
2017-06-26 19:44:06,620 Epoch[36] Batch [70]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094621,	
2017-06-26 19:44:11,950 Epoch[36] Batch [80]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095058,	
2017-06-26 19:44:17,300 Epoch[36] Batch [90]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095674,	
2017-06-26 19:44:22,642 Epoch[36] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097538,	
2017-06-26 19:44:27,961 Epoch[36] Batch [110]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097614,	
2017-06-26 19:44:33,126 Epoch[36] Batch [120]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.098279,	
2017-06-26 19:44:37,624 Epoch[36] Batch [130]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.098358,	
2017-06-26 19:44:42,906 Epoch[36] Batch [140]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098586,	
2017-06-26 19:44:48,251 Epoch[36] Batch [150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098757,	
2017-06-26 19:44:53,583 Epoch[36] Batch [160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098963,	
2017-06-26 19:44:58,910 Epoch[36] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.099196,	
2017-06-26 19:45:04,244 Epoch[36] Batch [180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098993,	
2017-06-26 19:45:09,645 Epoch[36] Batch [190]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.099225,	
2017-06-26 19:45:14,958 Epoch[36] Batch [200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098939,	
2017-06-26 19:45:20,280 Epoch[36] Batch [210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.099124,	
2017-06-26 19:45:25,564 Epoch[36] Batch [220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098815,	
2017-06-26 19:45:30,894 Epoch[36] Batch [230]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098333,	
2017-06-26 19:45:36,227 Epoch[36] Batch [240]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098240,	
2017-06-26 19:45:41,576 Epoch[36] Batch [250]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098515,	
2017-06-26 19:45:46,871 Epoch[36] Batch [260]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.098629,	
2017-06-26 19:45:52,209 Epoch[36] Batch [270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098441,	
2017-06-26 19:45:57,538 Epoch[36] Batch [280]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098598,	
2017-06-26 19:46:02,925 Epoch[36] Batch [290]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.098906,	
2017-06-26 19:46:08,254 Epoch[36] Batch [300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098799,	
2017-06-26 19:46:13,588 Epoch[36] Batch [310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098435,	
2017-06-26 19:46:18,939 Epoch[36] Batch [320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098609,	
2017-06-26 19:46:24,267 Epoch[36] Batch [330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098559,	
2017-06-26 19:46:29,560 Epoch[36] Batch [340]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098634,	
2017-06-26 19:46:34,911 Epoch[36] Batch [350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.098655,	
2017-06-26 19:46:40,223 Epoch[36] Batch [360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098602,	
2017-06-26 19:46:45,539 Epoch[36] Batch [370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.098517,	
2017-06-26 19:46:50,915 Epoch[36] Batch [380]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.098653,	
2017-06-26 19:46:56,248 Epoch[36] Batch [390]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.098591,	
2017-06-26 19:47:01,574 Epoch[36] Batch [400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098490,	
2017-06-26 19:47:06,886 Epoch[36] Batch [410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098437,	
2017-06-26 19:47:12,256 Epoch[36] Batch [420]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.098121,	
2017-06-26 19:47:17,577 Epoch[36] Batch [430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097928,	
2017-06-26 19:47:22,903 Epoch[36] Batch [440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.098012,	
2017-06-26 19:47:28,272 Epoch[36] Batch [450]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097760,	
2017-06-26 19:47:33,573 Epoch[36] Batch [460]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097649,	
2017-06-26 19:47:38,920 Epoch[36] Batch [470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097530,	
2017-06-26 19:47:44,249 Epoch[36] Batch [480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097543,	
2017-06-26 19:47:49,567 Epoch[36] Batch [490]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097603,	
2017-06-26 19:47:54,874 Epoch[36] Batch [500]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097532,	
2017-06-26 19:48:00,238 Epoch[36] Batch [510]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097446,	
2017-06-26 19:48:05,559 Epoch[36] Batch [520]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097472,	
2017-06-26 19:48:10,900 Epoch[36] Batch [530]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097441,	
2017-06-26 19:48:16,212 Epoch[36] Batch [540]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097329,	
2017-06-26 19:48:21,580 Epoch[36] Batch [550]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.097234,	
2017-06-26 19:48:26,911 Epoch[36] Batch [560]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097224,	
2017-06-26 19:48:32,266 Epoch[36] Batch [570]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.097188,	
2017-06-26 19:48:37,585 Epoch[36] Batch [580]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.097250,	
2017-06-26 19:48:42,931 Epoch[36] Batch [590]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097215,	
2017-06-26 19:48:48,223 Epoch[36] Batch [600]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097189,	
2017-06-26 19:48:53,560 Epoch[36] Batch [610]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097083,	
2017-06-26 19:48:58,896 Epoch[36] Batch [620]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097088,	
2017-06-26 19:49:04,219 Epoch[36] Batch [630]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096850,	
2017-06-26 19:49:09,564 Epoch[36] Batch [640]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096612,	
2017-06-26 19:49:14,907 Epoch[36] Batch [650]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096665,	
2017-06-26 19:49:20,263 Epoch[36] Batch [660]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096680,	
2017-06-26 19:49:25,601 Epoch[36] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096616,	
2017-06-26 19:49:30,967 Epoch[36] Batch [680]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096550,	
2017-06-26 19:49:36,289 Epoch[36] Batch [690]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096399,	
2017-06-26 19:49:41,629 Epoch[36] Batch [700]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096297,	
2017-06-26 19:49:46,962 Epoch[36] Batch [710]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096363,	
2017-06-26 19:49:52,294 Epoch[36] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096272,	
2017-06-26 19:49:57,673 Epoch[36] Batch [730]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096222,	
2017-06-26 19:50:02,972 Epoch[36] Batch [740]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096247,	
2017-06-26 19:50:08,305 Epoch[36] Batch [750]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096393,	
2017-06-26 19:50:13,693 Epoch[36] Batch [760]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.096261,	
2017-06-26 19:50:19,022 Epoch[36] Batch [770]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096163,	
2017-06-26 19:50:24,571 Epoch[36] Batch [780]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.096126,	
2017-06-26 19:50:29,922 Epoch[36] Batch [790]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096117,	
2017-06-26 19:50:35,443 Epoch[36] Batch [800]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.096045,	
2017-06-26 19:50:40,791 Epoch[36] Batch [810]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096079,	
2017-06-26 19:50:46,112 Epoch[36] Batch [820]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096019,	
2017-06-26 19:50:51,388 Epoch[36] Batch [830]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.096090,	
2017-06-26 19:50:56,798 Epoch[36] Batch [840]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.096036,	
2017-06-26 19:51:02,216 Epoch[36] Batch [850]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.096038,	
2017-06-26 19:51:07,523 Epoch[36] Batch [860]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096115,	
2017-06-26 19:51:12,871 Epoch[36] Batch [870]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096079,	
2017-06-26 19:51:18,354 Epoch[36] Batch [880]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.095989,	
2017-06-26 19:51:23,668 Epoch[36] Batch [890]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095988,	
2017-06-26 19:51:29,103 Epoch[36] Batch [900]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.095952,	
2017-06-26 19:51:34,458 Epoch[36] Batch [910]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096072,	
2017-06-26 19:51:39,738 Epoch[36] Batch [920]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095991,	
2017-06-26 19:51:45,111 Epoch[36] Batch [930]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095908,	
2017-06-26 19:51:50,523 Epoch[36] Batch [940]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.095862,	
2017-06-26 19:51:55,886 Epoch[36] Batch [950]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095851,	
2017-06-26 19:52:01,236 Epoch[36] Batch [960]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095914,	
2017-06-26 19:52:06,529 Epoch[36] Batch [970]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095817,	
2017-06-26 19:52:11,897 Epoch[36] Batch [980]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095883,	
2017-06-26 19:52:17,283 Epoch[36] Batch [990]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095940,	
2017-06-26 19:52:22,616 Epoch[36] Batch [1000]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096166,	
2017-06-26 19:52:27,924 Epoch[36] Batch [1010]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096195,	
2017-06-26 19:52:33,424 Epoch[36] Batch [1020]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.096240,	
2017-06-26 19:52:38,746 Epoch[36] Batch [1030]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096259,	
2017-06-26 19:52:44,102 Epoch[36] Batch [1040]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096212,	
2017-06-26 19:52:49,447 Epoch[36] Batch [1050]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096217,	
2017-06-26 19:52:54,781 Epoch[36] Batch [1060]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096279,	
2017-06-26 19:53:00,122 Epoch[36] Batch [1070]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096220,	
2017-06-26 19:53:05,428 Epoch[36] Batch [1080]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096203,	
2017-06-26 19:53:10,770 Epoch[36] Batch [1090]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096110,	
2017-06-26 19:53:16,279 Epoch[36] Batch [1100]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.096129,	
2017-06-26 19:53:21,623 Epoch[36] Batch [1110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096197,	
2017-06-26 19:53:26,940 Epoch[36] Batch [1120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096291,	
2017-06-26 19:53:32,290 Epoch[36] Batch [1130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096386,	
2017-06-26 19:53:37,623 Epoch[36] Batch [1140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096448,	
2017-06-26 19:53:42,907 Epoch[36] Batch [1150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096482,	
2017-06-26 19:53:48,303 Epoch[36] Batch [1160]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.096496,	
2017-06-26 19:53:53,625 Epoch[36] Batch [1170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096449,	
2017-06-26 19:53:58,954 Epoch[36] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096437,	
2017-06-26 19:54:04,293 Epoch[36] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096509,	
2017-06-26 19:54:09,614 Epoch[36] Batch [1200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096509,	
2017-06-26 19:54:14,974 Epoch[36] Batch [1210]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096496,	
2017-06-26 19:54:20,336 Epoch[36] Batch [1220]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096448,	
2017-06-26 19:54:25,644 Epoch[36] Batch [1230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096457,	
2017-06-26 19:54:30,976 Epoch[36] Batch [1240]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096443,	
2017-06-26 19:54:36,350 Epoch[36] Batch [1250]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096351,	
2017-06-26 19:54:41,702 Epoch[36] Batch [1260]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096330,	
2017-06-26 19:54:46,998 Epoch[36] Batch [1270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096286,	
2017-06-26 19:54:52,317 Epoch[36] Batch [1280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096264,	
2017-06-26 19:54:57,671 Epoch[36] Batch [1290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096173,	
2017-06-26 19:55:03,017 Epoch[36] Batch [1300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096210,	
2017-06-26 19:55:08,369 Epoch[36] Batch [1310]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096248,	
2017-06-26 19:55:13,688 Epoch[36] Batch [1320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096241,	
2017-06-26 19:55:19,026 Epoch[36] Batch [1330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096271,	
2017-06-26 19:55:24,365 Epoch[36] Batch [1340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096371,	
2017-06-26 19:55:29,715 Epoch[36] Batch [1350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096390,	
2017-06-26 19:55:35,013 Epoch[36] Batch [1360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.096364,	
2017-06-26 19:55:40,368 Epoch[36] Batch [1370]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096336,	
2017-06-26 19:55:45,670 Epoch[36] Batch [1380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.096338,	
2017-06-26 19:55:51,047 Epoch[36] Batch [1390]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096341,	
2017-06-26 19:55:56,401 Epoch[36] Batch [1400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096351,	
2017-06-26 19:56:01,724 Epoch[36] Batch [1410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096285,	
2017-06-26 19:56:07,035 Epoch[36] Batch [1420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096269,	
2017-06-26 19:56:12,376 Epoch[36] Batch [1430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096218,	
2017-06-26 19:56:17,710 Epoch[36] Batch [1440]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096254,	
2017-06-26 19:56:23,040 Epoch[36] Batch [1450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096241,	
2017-06-26 19:56:28,399 Epoch[36] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096230,	
2017-06-26 19:56:33,709 Epoch[36] Batch [1470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096308,	
2017-06-26 19:56:39,034 Epoch[36] Batch [1480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096319,	
2017-06-26 19:56:42,238 Epoch[36] Train-FCNLogLoss=0.096317
2017-06-26 19:56:42,238 Epoch[36] Time cost=793.625
2017-06-26 19:56:42,902 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0037.params"
2017-06-26 19:56:44,781 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0037.states"
2017-06-26 19:56:50,973 Epoch[37] Batch [10]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.093013,	
2017-06-26 19:56:56,320 Epoch[37] Batch [20]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092608,	
2017-06-26 19:57:01,648 Epoch[37] Batch [30]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093177,	
2017-06-26 19:57:06,971 Epoch[37] Batch [40]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094908,	
2017-06-26 19:57:12,307 Epoch[37] Batch [50]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095440,	
2017-06-26 19:57:17,639 Epoch[37] Batch [60]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095817,	
2017-06-26 19:57:22,987 Epoch[37] Batch [70]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095064,	
2017-06-26 19:57:28,348 Epoch[37] Batch [80]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094016,	
2017-06-26 19:57:33,710 Epoch[37] Batch [90]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093380,	
2017-06-26 19:57:39,047 Epoch[37] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092973,	
2017-06-26 19:57:44,347 Epoch[37] Batch [110]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093468,	
2017-06-26 19:57:49,504 Epoch[37] Batch [120]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.093609,	
2017-06-26 19:57:53,935 Epoch[37] Batch [130]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.093850,	
2017-06-26 19:57:59,261 Epoch[37] Batch [140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093478,	
2017-06-26 19:58:04,587 Epoch[37] Batch [150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.093521,	
2017-06-26 19:58:09,896 Epoch[37] Batch [160]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093075,	
2017-06-26 19:58:15,261 Epoch[37] Batch [170]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092803,	
2017-06-26 19:58:20,548 Epoch[37] Batch [180]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092770,	
2017-06-26 19:58:25,900 Epoch[37] Batch [190]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092982,	
2017-06-26 19:58:31,202 Epoch[37] Batch [200]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.092947,	
2017-06-26 19:58:36,573 Epoch[37] Batch [210]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092936,	
2017-06-26 19:58:41,895 Epoch[37] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092847,	
2017-06-26 19:58:47,246 Epoch[37] Batch [230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092646,	
2017-06-26 19:58:52,595 Epoch[37] Batch [240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092727,	
2017-06-26 19:58:57,998 Epoch[37] Batch [250]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.092889,	
2017-06-26 19:59:03,331 Epoch[37] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.092986,	
2017-06-26 19:59:08,677 Epoch[37] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092892,	
2017-06-26 19:59:13,982 Epoch[37] Batch [280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093099,	
2017-06-26 19:59:19,339 Epoch[37] Batch [290]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.093268,	
2017-06-26 19:59:24,677 Epoch[37] Batch [300]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093371,	
2017-06-26 19:59:30,112 Epoch[37] Batch [310]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.093184,	
2017-06-26 19:59:35,481 Epoch[37] Batch [320]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.093186,	
2017-06-26 19:59:40,875 Epoch[37] Batch [330]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.092974,	
2017-06-26 19:59:46,265 Epoch[37] Batch [340]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093104,	
2017-06-26 19:59:51,602 Epoch[37] Batch [350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093068,	
2017-06-26 19:59:57,126 Epoch[37] Batch [360]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.093310,	
2017-06-26 20:00:02,430 Epoch[37] Batch [370]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093231,	
2017-06-26 20:00:07,777 Epoch[37] Batch [380]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093302,	
2017-06-26 20:00:13,117 Epoch[37] Batch [390]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093172,	
2017-06-26 20:00:18,459 Epoch[37] Batch [400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093165,	
2017-06-26 20:00:23,956 Epoch[37] Batch [410]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093455,	
2017-06-26 20:00:29,294 Epoch[37] Batch [420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093474,	
2017-06-26 20:00:34,571 Epoch[37] Batch [430]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.093315,	
2017-06-26 20:00:40,069 Epoch[37] Batch [440]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.093330,	
2017-06-26 20:00:45,411 Epoch[37] Batch [450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093429,	
2017-06-26 20:00:50,727 Epoch[37] Batch [460]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093440,	
2017-06-26 20:00:56,119 Epoch[37] Batch [470]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.093429,	
2017-06-26 20:01:01,457 Epoch[37] Batch [480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093702,	
2017-06-26 20:01:06,836 Epoch[37] Batch [490]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.093784,	
2017-06-26 20:01:12,199 Epoch[37] Batch [500]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.093933,	
2017-06-26 20:01:17,586 Epoch[37] Batch [510]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.094023,	
2017-06-26 20:01:22,976 Epoch[37] Batch [520]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.094086,	
2017-06-26 20:01:28,258 Epoch[37] Batch [530]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094106,	
2017-06-26 20:01:33,622 Epoch[37] Batch [540]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094182,	
2017-06-26 20:01:38,989 Epoch[37] Batch [550]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094118,	
2017-06-26 20:01:44,311 Epoch[37] Batch [560]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094284,	
2017-06-26 20:01:49,653 Epoch[37] Batch [570]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094413,	
2017-06-26 20:01:55,167 Epoch[37] Batch [580]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.094307,	
2017-06-26 20:02:00,519 Epoch[37] Batch [590]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094130,	
2017-06-26 20:02:05,796 Epoch[37] Batch [600]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.094187,	
2017-06-26 20:02:11,168 Epoch[37] Batch [610]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094219,	
2017-06-26 20:02:16,500 Epoch[37] Batch [620]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094276,	
2017-06-26 20:02:21,851 Epoch[37] Batch [630]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094566,	
2017-06-26 20:02:27,188 Epoch[37] Batch [640]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094472,	
2017-06-26 20:02:32,546 Epoch[37] Batch [650]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094439,	
2017-06-26 20:02:37,858 Epoch[37] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094542,	
2017-06-26 20:02:43,229 Epoch[37] Batch [670]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094565,	
2017-06-26 20:02:48,729 Epoch[37] Batch [680]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.094578,	
2017-06-26 20:02:54,035 Epoch[37] Batch [690]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094414,	
2017-06-26 20:02:59,374 Epoch[37] Batch [700]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094383,	
2017-06-26 20:03:04,752 Epoch[37] Batch [710]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.094842,	
2017-06-26 20:03:10,080 Epoch[37] Batch [720]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095142,	
2017-06-26 20:03:15,429 Epoch[37] Batch [730]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095208,	
2017-06-26 20:03:20,741 Epoch[37] Batch [740]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095253,	
2017-06-26 20:03:26,101 Epoch[37] Batch [750]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095269,	
2017-06-26 20:03:31,444 Epoch[37] Batch [760]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095191,	
2017-06-26 20:03:36,747 Epoch[37] Batch [770]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095039,	
2017-06-26 20:03:42,069 Epoch[37] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094977,	
2017-06-26 20:03:47,447 Epoch[37] Batch [790]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095248,	
2017-06-26 20:03:52,744 Epoch[37] Batch [800]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095431,	
2017-06-26 20:03:58,067 Epoch[37] Batch [810]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095429,	
2017-06-26 20:04:03,430 Epoch[37] Batch [820]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095367,	
2017-06-26 20:04:08,761 Epoch[37] Batch [830]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095370,	
2017-06-26 20:04:14,066 Epoch[37] Batch [840]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095307,	
2017-06-26 20:04:19,423 Epoch[37] Batch [850]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095368,	
2017-06-26 20:04:24,729 Epoch[37] Batch [860]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095360,	
2017-06-26 20:04:30,093 Epoch[37] Batch [870]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095395,	
2017-06-26 20:04:35,436 Epoch[37] Batch [880]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095385,	
2017-06-26 20:04:40,753 Epoch[37] Batch [890]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095471,	
2017-06-26 20:04:46,106 Epoch[37] Batch [900]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095402,	
2017-06-26 20:04:51,390 Epoch[37] Batch [910]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095386,	
2017-06-26 20:04:56,750 Epoch[37] Batch [920]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095440,	
2017-06-26 20:05:02,120 Epoch[37] Batch [930]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095358,	
2017-06-26 20:05:07,420 Epoch[37] Batch [940]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095386,	
2017-06-26 20:05:12,780 Epoch[37] Batch [950]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095436,	
2017-06-26 20:05:18,082 Epoch[37] Batch [960]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095466,	
2017-06-26 20:05:23,431 Epoch[37] Batch [970]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095524,	
2017-06-26 20:05:28,751 Epoch[37] Batch [980]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095491,	
2017-06-26 20:05:34,104 Epoch[37] Batch [990]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095633,	
2017-06-26 20:05:39,393 Epoch[37] Batch [1000]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095670,	
2017-06-26 20:05:44,783 Epoch[37] Batch [1010]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095742,	
2017-06-26 20:05:50,051 Epoch[37] Batch [1020]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.095702,	
2017-06-26 20:05:55,425 Epoch[37] Batch [1030]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095737,	
2017-06-26 20:06:00,747 Epoch[37] Batch [1040]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095714,	
2017-06-26 20:06:06,068 Epoch[37] Batch [1050]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095726,	
2017-06-26 20:06:11,429 Epoch[37] Batch [1060]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095624,	
2017-06-26 20:06:16,782 Epoch[37] Batch [1070]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095509,	
2017-06-26 20:06:22,104 Epoch[37] Batch [1080]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095394,	
2017-06-26 20:06:27,472 Epoch[37] Batch [1090]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095387,	
2017-06-26 20:06:32,772 Epoch[37] Batch [1100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.095314,	
2017-06-26 20:06:38,153 Epoch[37] Batch [1110]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095303,	
2017-06-26 20:06:43,472 Epoch[37] Batch [1120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095358,	
2017-06-26 20:06:48,821 Epoch[37] Batch [1130]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095284,	
2017-06-26 20:06:54,175 Epoch[37] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095304,	
2017-06-26 20:06:59,503 Epoch[37] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095370,	
2017-06-26 20:07:04,836 Epoch[37] Batch [1160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095392,	
2017-06-26 20:07:10,150 Epoch[37] Batch [1170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095320,	
2017-06-26 20:07:15,458 Epoch[37] Batch [1180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095313,	
2017-06-26 20:07:20,819 Epoch[37] Batch [1190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095189,	
2017-06-26 20:07:26,151 Epoch[37] Batch [1200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095161,	
2017-06-26 20:07:31,466 Epoch[37] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095186,	
2017-06-26 20:07:36,855 Epoch[37] Batch [1220]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095192,	
2017-06-26 20:07:42,199 Epoch[37] Batch [1230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095284,	
2017-06-26 20:07:47,560 Epoch[37] Batch [1240]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095290,	
2017-06-26 20:07:52,920 Epoch[37] Batch [1250]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095343,	
2017-06-26 20:07:58,304 Epoch[37] Batch [1260]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095381,	
2017-06-26 20:08:03,622 Epoch[37] Batch [1270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095379,	
2017-06-26 20:08:08,936 Epoch[37] Batch [1280]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095433,	
2017-06-26 20:08:14,375 Epoch[37] Batch [1290]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.095543,	
2017-06-26 20:08:19,758 Epoch[37] Batch [1300]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095580,	
2017-06-26 20:08:25,147 Epoch[37] Batch [1310]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.095570,	
2017-06-26 20:08:30,465 Epoch[37] Batch [1320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095524,	
2017-06-26 20:08:35,992 Epoch[37] Batch [1330]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.095516,	
2017-06-26 20:08:41,408 Epoch[37] Batch [1340]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.095550,	
2017-06-26 20:08:46,703 Epoch[37] Batch [1350]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095552,	
2017-06-26 20:08:52,050 Epoch[37] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095539,	
2017-06-26 20:08:57,428 Epoch[37] Batch [1370]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.095579,	
2017-06-26 20:09:02,809 Epoch[37] Batch [1380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.095587,	
2017-06-26 20:09:08,169 Epoch[37] Batch [1390]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095616,	
2017-06-26 20:09:13,521 Epoch[37] Batch [1400]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.095602,	
2017-06-26 20:09:18,921 Epoch[37] Batch [1410]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.095645,	
2017-06-26 20:09:24,269 Epoch[37] Batch [1420]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095641,	
2017-06-26 20:09:29,589 Epoch[37] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095606,	
2017-06-26 20:09:34,935 Epoch[37] Batch [1440]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095622,	
2017-06-26 20:09:40,434 Epoch[37] Batch [1450]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.095593,	
2017-06-26 20:09:45,800 Epoch[37] Batch [1460]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095595,	
2017-06-26 20:09:51,169 Epoch[37] Batch [1470]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095506,	
2017-06-26 20:09:56,513 Epoch[37] Batch [1480]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095484,	
2017-06-26 20:09:59,722 Epoch[37] Train-FCNLogLoss=0.095497
2017-06-26 20:09:59,722 Epoch[37] Time cost=794.940
2017-06-26 20:10:00,372 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0038.params"
2017-06-26 20:10:02,413 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0038.states"
2017-06-26 20:10:08,524 Epoch[38] Batch [10]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.098416,	
2017-06-26 20:10:13,837 Epoch[38] Batch [20]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.100719,	
2017-06-26 20:10:19,183 Epoch[38] Batch [30]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097224,	
2017-06-26 20:10:24,528 Epoch[38] Batch [40]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094176,	
2017-06-26 20:10:29,989 Epoch[38] Batch [50]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094073,	
2017-06-26 20:10:35,308 Epoch[38] Batch [60]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092893,	
2017-06-26 20:10:40,630 Epoch[38] Batch [70]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.092094,	
2017-06-26 20:10:45,996 Epoch[38] Batch [80]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.092615,	
2017-06-26 20:10:51,472 Epoch[38] Batch [90]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.093321,	
2017-06-26 20:10:56,769 Epoch[38] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094917,	
2017-06-26 20:11:02,113 Epoch[38] Batch [110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094688,	
2017-06-26 20:11:07,276 Epoch[38] Batch [120]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.095069,	
2017-06-26 20:11:11,844 Epoch[38] Batch [130]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.094910,	
2017-06-26 20:11:17,165 Epoch[38] Batch [140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094789,	
2017-06-26 20:11:22,494 Epoch[38] Batch [150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094135,	
2017-06-26 20:11:27,836 Epoch[38] Batch [160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094065,	
2017-06-26 20:11:33,206 Epoch[38] Batch [170]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094288,	
2017-06-26 20:11:38,512 Epoch[38] Batch [180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094777,	
2017-06-26 20:11:43,844 Epoch[38] Batch [190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094371,	
2017-06-26 20:11:49,181 Epoch[38] Batch [200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094465,	
2017-06-26 20:11:54,498 Epoch[38] Batch [210]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094396,	
2017-06-26 20:11:59,855 Epoch[38] Batch [220]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094492,	
2017-06-26 20:12:05,216 Epoch[38] Batch [230]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094367,	
2017-06-26 20:12:10,563 Epoch[38] Batch [240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094711,	
2017-06-26 20:12:15,898 Epoch[38] Batch [250]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094357,	
2017-06-26 20:12:21,231 Epoch[38] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093928,	
2017-06-26 20:12:26,564 Epoch[38] Batch [270]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.093724,	
2017-06-26 20:12:31,868 Epoch[38] Batch [280]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093862,	
2017-06-26 20:12:37,228 Epoch[38] Batch [290]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.094172,	
2017-06-26 20:12:42,586 Epoch[38] Batch [300]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094285,	
2017-06-26 20:12:47,919 Epoch[38] Batch [310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094174,	
2017-06-26 20:12:53,292 Epoch[38] Batch [320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.094747,	
2017-06-26 20:12:58,624 Epoch[38] Batch [330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095865,	
2017-06-26 20:13:03,989 Epoch[38] Batch [340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.099453,	
2017-06-26 20:13:09,346 Epoch[38] Batch [350]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.100815,	
2017-06-26 20:13:14,622 Epoch[38] Batch [360]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.103219,	
2017-06-26 20:13:19,985 Epoch[38] Batch [370]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104210,	
2017-06-26 20:13:25,339 Epoch[38] Batch [380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.104847,	
2017-06-26 20:13:30,652 Epoch[38] Batch [390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.105355,	
2017-06-26 20:13:35,977 Epoch[38] Batch [400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107128,	
2017-06-26 20:13:41,323 Epoch[38] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.107669,	
2017-06-26 20:13:46,649 Epoch[38] Batch [420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107843,	
2017-06-26 20:13:51,986 Epoch[38] Batch [430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.107810,	
2017-06-26 20:13:57,326 Epoch[38] Batch [440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.107741,	
2017-06-26 20:14:02,660 Epoch[38] Batch [450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.107716,	
2017-06-26 20:14:07,986 Epoch[38] Batch [460]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107465,	
2017-06-26 20:14:13,329 Epoch[38] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.107273,	
2017-06-26 20:14:18,653 Epoch[38] Batch [480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107130,	
2017-06-26 20:14:23,979 Epoch[38] Batch [490]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107020,	
2017-06-26 20:14:29,307 Epoch[38] Batch [500]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.106646,	
2017-06-26 20:14:34,648 Epoch[38] Batch [510]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.106367,	
2017-06-26 20:14:39,983 Epoch[38] Batch [520]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105971,	
2017-06-26 20:14:45,310 Epoch[38] Batch [530]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.106038,	
2017-06-26 20:14:50,648 Epoch[38] Batch [540]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.106104,	
2017-06-26 20:14:55,955 Epoch[38] Batch [550]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.106060,	
2017-06-26 20:15:01,299 Epoch[38] Batch [560]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.105824,	
2017-06-26 20:15:06,623 Epoch[38] Batch [570]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.105817,	
2017-06-26 20:15:11,977 Epoch[38] Batch [580]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105579,	
2017-06-26 20:15:17,314 Epoch[38] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105357,	
2017-06-26 20:15:22,655 Epoch[38] Batch [600]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.105252,	
2017-06-26 20:15:27,985 Epoch[38] Batch [610]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.105187,	
2017-06-26 20:15:33,292 Epoch[38] Batch [620]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.105244,	
2017-06-26 20:15:38,668 Epoch[38] Batch [630]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.105300,	
2017-06-26 20:15:43,996 Epoch[38] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.105528,	
2017-06-26 20:15:49,311 Epoch[38] Batch [650]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.105579,	
2017-06-26 20:15:54,655 Epoch[38] Batch [660]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.105487,	
2017-06-26 20:15:59,971 Epoch[38] Batch [670]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105359,	
2017-06-26 20:16:05,306 Epoch[38] Batch [680]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105339,	
2017-06-26 20:16:10,664 Epoch[38] Batch [690]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105336,	
2017-06-26 20:16:15,976 Epoch[38] Batch [700]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.105160,	
2017-06-26 20:16:21,425 Epoch[38] Batch [710]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.105153,	
2017-06-26 20:16:26,780 Epoch[38] Batch [720]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.104883,	
2017-06-26 20:16:32,105 Epoch[38] Batch [730]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104886,	
2017-06-26 20:16:37,416 Epoch[38] Batch [740]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.104686,	
2017-06-26 20:16:42,731 Epoch[38] Batch [750]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.104723,	
2017-06-26 20:16:48,072 Epoch[38] Batch [760]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.104627,	
2017-06-26 20:16:53,505 Epoch[38] Batch [770]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.104601,	
2017-06-26 20:16:58,865 Epoch[38] Batch [780]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104516,	
2017-06-26 20:17:04,282 Epoch[38] Batch [790]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.104602,	
2017-06-26 20:17:09,640 Epoch[38] Batch [800]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.104608,	
2017-06-26 20:17:14,974 Epoch[38] Batch [810]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.104475,	
2017-06-26 20:17:20,326 Epoch[38] Batch [820]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.104699,	
2017-06-26 20:17:25,712 Epoch[38] Batch [830]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.104662,	
2017-06-26 20:17:31,129 Epoch[38] Batch [840]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.104562,	
2017-06-26 20:17:36,530 Epoch[38] Batch [850]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.104596,	
2017-06-26 20:17:41,895 Epoch[38] Batch [860]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.104535,	
2017-06-26 20:17:47,249 Epoch[38] Batch [870]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.104566,	
2017-06-26 20:17:52,684 Epoch[38] Batch [880]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.104534,	
2017-06-26 20:17:58,100 Epoch[38] Batch [890]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.104525,	
2017-06-26 20:18:03,440 Epoch[38] Batch [900]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.104561,	
2017-06-26 20:18:08,868 Epoch[38] Batch [910]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.104455,	
2017-06-26 20:18:14,196 Epoch[38] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104384,	
2017-06-26 20:18:19,651 Epoch[38] Batch [930]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.104385,	
2017-06-26 20:18:25,046 Epoch[38] Batch [940]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.104192,	
2017-06-26 20:18:30,374 Epoch[38] Batch [950]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104091,	
2017-06-26 20:18:35,766 Epoch[38] Batch [960]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.104100,	
2017-06-26 20:18:41,153 Epoch[38] Batch [970]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.104091,	
2017-06-26 20:18:46,556 Epoch[38] Batch [980]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.104011,	
2017-06-26 20:18:51,842 Epoch[38] Batch [990]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.104002,	
2017-06-26 20:18:57,177 Epoch[38] Batch [1000]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.104388,	
2017-06-26 20:19:02,554 Epoch[38] Batch [1010]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.104934,	
2017-06-26 20:19:07,917 Epoch[38] Batch [1020]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.105026,	
2017-06-26 20:19:13,317 Epoch[38] Batch [1030]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.105079,	
2017-06-26 20:19:18,671 Epoch[38] Batch [1040]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105347,	
2017-06-26 20:19:24,150 Epoch[38] Batch [1050]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.105394,	
2017-06-26 20:19:29,384 Epoch[38] Batch [1060]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.105300,	
2017-06-26 20:19:34,721 Epoch[38] Batch [1070]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105330,	
2017-06-26 20:19:40,111 Epoch[38] Batch [1080]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.105259,	
2017-06-26 20:19:45,525 Epoch[38] Batch [1090]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.105364,	
2017-06-26 20:19:50,848 Epoch[38] Batch [1100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.105301,	
2017-06-26 20:19:56,140 Epoch[38] Batch [1110]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.105338,	
2017-06-26 20:20:01,538 Epoch[38] Batch [1120]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.105535,	
2017-06-26 20:20:06,876 Epoch[38] Batch [1130]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.105747,	
2017-06-26 20:20:12,246 Epoch[38] Batch [1140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.105916,	
2017-06-26 20:20:17,507 Epoch[38] Batch [1150]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.106266,	
2017-06-26 20:20:22,854 Epoch[38] Batch [1160]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.106442,	
2017-06-26 20:20:28,339 Epoch[38] Batch [1170]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.106632,	
2017-06-26 20:20:33,646 Epoch[38] Batch [1180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.106687,	
2017-06-26 20:20:38,962 Epoch[38] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.106722,	
2017-06-26 20:20:44,311 Epoch[38] Batch [1200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.106734,	
2017-06-26 20:20:49,625 Epoch[38] Batch [1210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.106711,	
2017-06-26 20:20:55,131 Epoch[38] Batch [1220]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.106673,	
2017-06-26 20:21:00,494 Epoch[38] Batch [1230]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.106575,	
2017-06-26 20:21:05,819 Epoch[38] Batch [1240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.106597,	
2017-06-26 20:21:11,183 Epoch[38] Batch [1250]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.106532,	
2017-06-26 20:21:16,519 Epoch[38] Batch [1260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.106481,	
2017-06-26 20:21:21,824 Epoch[38] Batch [1270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.106525,	
2017-06-26 20:21:27,168 Epoch[38] Batch [1280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.106510,	
2017-06-26 20:21:32,514 Epoch[38] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.106385,	
2017-06-26 20:21:37,847 Epoch[38] Batch [1300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.106275,	
2017-06-26 20:21:43,222 Epoch[38] Batch [1310]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.106244,	
2017-06-26 20:21:48,548 Epoch[38] Batch [1320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.106275,	
2017-06-26 20:21:53,863 Epoch[38] Batch [1330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.106285,	
2017-06-26 20:21:59,260 Epoch[38] Batch [1340]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.106254,	
2017-06-26 20:22:04,558 Epoch[38] Batch [1350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.106173,	
2017-06-26 20:22:09,890 Epoch[38] Batch [1360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.106146,	
2017-06-26 20:22:15,232 Epoch[38] Batch [1370]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.106027,	
2017-06-26 20:22:20,557 Epoch[38] Batch [1380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.106040,	
2017-06-26 20:22:25,915 Epoch[38] Batch [1390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105979,	
2017-06-26 20:22:31,235 Epoch[38] Batch [1400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105920,	
2017-06-26 20:22:36,575 Epoch[38] Batch [1410]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.105900,	
2017-06-26 20:22:41,927 Epoch[38] Batch [1420]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.105844,	
2017-06-26 20:22:47,254 Epoch[38] Batch [1430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.105744,	
2017-06-26 20:22:52,617 Epoch[38] Batch [1440]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.105728,	
2017-06-26 20:22:57,934 Epoch[38] Batch [1450]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105687,	
2017-06-26 20:23:03,276 Epoch[38] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.105609,	
2017-06-26 20:23:08,589 Epoch[38] Batch [1470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.105555,	
2017-06-26 20:23:13,946 Epoch[38] Batch [1480]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105463,	
2017-06-26 20:23:17,144 Epoch[38] Train-FCNLogLoss=0.105418
2017-06-26 20:23:17,144 Epoch[38] Time cost=794.730
2017-06-26 20:23:17,807 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0039.params"
2017-06-26 20:23:20,060 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0039.states"
2017-06-26 20:23:26,053 Epoch[39] Batch [10]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089801,	
2017-06-26 20:23:31,359 Epoch[39] Batch [20]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.093691,	
2017-06-26 20:23:36,735 Epoch[39] Batch [30]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090732,	
2017-06-26 20:23:42,027 Epoch[39] Batch [40]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089982,	
2017-06-26 20:23:47,358 Epoch[39] Batch [50]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089480,	
2017-06-26 20:23:52,685 Epoch[39] Batch [60]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.092456,	
2017-06-26 20:23:58,050 Epoch[39] Batch [70]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092997,	
2017-06-26 20:24:03,400 Epoch[39] Batch [80]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093521,	
2017-06-26 20:24:08,721 Epoch[39] Batch [90]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094835,	
2017-06-26 20:24:14,054 Epoch[39] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094953,	
2017-06-26 20:24:19,393 Epoch[39] Batch [110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095393,	
2017-06-26 20:24:24,515 Epoch[39] Batch [120]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.096799,	
2017-06-26 20:24:29,199 Epoch[39] Batch [130]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.096964,	
2017-06-26 20:24:34,562 Epoch[39] Batch [140]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096904,	
2017-06-26 20:24:39,853 Epoch[39] Batch [150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097445,	
2017-06-26 20:24:45,200 Epoch[39] Batch [160]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097858,	
2017-06-26 20:24:50,599 Epoch[39] Batch [170]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.097915,	
2017-06-26 20:24:55,923 Epoch[39] Batch [180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.097027,	
2017-06-26 20:25:01,288 Epoch[39] Batch [190]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096351,	
2017-06-26 20:25:06,624 Epoch[39] Batch [200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096214,	
2017-06-26 20:25:11,936 Epoch[39] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095881,	
2017-06-26 20:25:17,305 Epoch[39] Batch [220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096041,	
2017-06-26 20:25:22,664 Epoch[39] Batch [230]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.096134,	
2017-06-26 20:25:27,986 Epoch[39] Batch [240]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096115,	
2017-06-26 20:25:33,302 Epoch[39] Batch [250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095728,	
2017-06-26 20:25:38,711 Epoch[39] Batch [260]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.095715,	
2017-06-26 20:25:44,020 Epoch[39] Batch [270]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095372,	
2017-06-26 20:25:49,358 Epoch[39] Batch [280]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095489,	
2017-06-26 20:25:54,737 Epoch[39] Batch [290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096038,	
2017-06-26 20:26:00,142 Epoch[39] Batch [300]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.095755,	
2017-06-26 20:26:05,452 Epoch[39] Batch [310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096069,	
2017-06-26 20:26:10,832 Epoch[39] Batch [320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.099583,	
2017-06-26 20:26:16,164 Epoch[39] Batch [330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.101343,	
2017-06-26 20:26:21,550 Epoch[39] Batch [340]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.102847,	
2017-06-26 20:26:26,989 Epoch[39] Batch [350]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.104093,	
2017-06-26 20:26:32,309 Epoch[39] Batch [360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104359,	
2017-06-26 20:26:37,611 Epoch[39] Batch [370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.105237,	
2017-06-26 20:26:43,020 Epoch[39] Batch [380]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.106860,	
2017-06-26 20:26:48,509 Epoch[39] Batch [390]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.107454,	
2017-06-26 20:26:53,857 Epoch[39] Batch [400]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108117,	
2017-06-26 20:26:59,202 Epoch[39] Batch [410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.108358,	
2017-06-26 20:27:04,640 Epoch[39] Batch [420]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.108192,	
2017-06-26 20:27:10,064 Epoch[39] Batch [430]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.108272,	
2017-06-26 20:27:15,370 Epoch[39] Batch [440]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.108168,	
2017-06-26 20:27:20,695 Epoch[39] Batch [450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.107975,	
2017-06-26 20:27:26,081 Epoch[39] Batch [460]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.107920,	
2017-06-26 20:27:31,453 Epoch[39] Batch [470]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.107852,	
2017-06-26 20:27:36,824 Epoch[39] Batch [480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.107717,	
2017-06-26 20:27:42,238 Epoch[39] Batch [490]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.107481,	
2017-06-26 20:27:47,634 Epoch[39] Batch [500]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.107475,	
2017-06-26 20:27:52,990 Epoch[39] Batch [510]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.107547,	
2017-06-26 20:27:58,404 Epoch[39] Batch [520]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.107543,	
2017-06-26 20:28:03,823 Epoch[39] Batch [530]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.107528,	
2017-06-26 20:28:09,204 Epoch[39] Batch [540]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.107384,	
2017-06-26 20:28:14,538 Epoch[39] Batch [550]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.107360,	
2017-06-26 20:28:19,849 Epoch[39] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.107415,	
2017-06-26 20:28:25,357 Epoch[39] Batch [570]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.107495,	
2017-06-26 20:28:30,754 Epoch[39] Batch [580]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.107466,	
2017-06-26 20:28:36,076 Epoch[39] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.107409,	
2017-06-26 20:28:41,413 Epoch[39] Batch [600]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.107252,	
2017-06-26 20:28:46,762 Epoch[39] Batch [610]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.107095,	
2017-06-26 20:28:52,099 Epoch[39] Batch [620]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.106995,	
2017-06-26 20:28:57,445 Epoch[39] Batch [630]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.106916,	
2017-06-26 20:29:02,881 Epoch[39] Batch [640]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.106729,	
2017-06-26 20:29:08,221 Epoch[39] Batch [650]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.106524,	
2017-06-26 20:29:13,611 Epoch[39] Batch [660]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.106389,	
2017-06-26 20:29:18,960 Epoch[39] Batch [670]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.106322,	
2017-06-26 20:29:24,279 Epoch[39] Batch [680]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.106078,	
2017-06-26 20:29:29,628 Epoch[39] Batch [690]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.106135,	
2017-06-26 20:29:34,980 Epoch[39] Batch [700]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.106046,	
2017-06-26 20:29:40,325 Epoch[39] Batch [710]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.106022,	
2017-06-26 20:29:45,661 Epoch[39] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105833,	
2017-06-26 20:29:51,097 Epoch[39] Batch [730]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.105816,	
2017-06-26 20:29:56,428 Epoch[39] Batch [740]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105793,	
2017-06-26 20:30:01,776 Epoch[39] Batch [750]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.105778,	
2017-06-26 20:30:07,136 Epoch[39] Batch [760]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.105600,	
2017-06-26 20:30:12,470 Epoch[39] Batch [770]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105461,	
2017-06-26 20:30:17,791 Epoch[39] Batch [780]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.105300,	
2017-06-26 20:30:23,122 Epoch[39] Batch [790]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.105272,	
2017-06-26 20:30:28,474 Epoch[39] Batch [800]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.105173,	
2017-06-26 20:30:33,841 Epoch[39] Batch [810]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.104995,	
2017-06-26 20:30:39,157 Epoch[39] Batch [820]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104843,	
2017-06-26 20:30:44,487 Epoch[39] Batch [830]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.104722,	
2017-06-26 20:30:49,805 Epoch[39] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.104620,	
2017-06-26 20:30:55,189 Epoch[39] Batch [850]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.104555,	
2017-06-26 20:31:00,494 Epoch[39] Batch [860]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.104458,	
2017-06-26 20:31:05,860 Epoch[39] Batch [870]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.104417,	
2017-06-26 20:31:11,172 Epoch[39] Batch [880]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.104348,	
2017-06-26 20:31:16,538 Epoch[39] Batch [890]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.104139,	
2017-06-26 20:31:21,825 Epoch[39] Batch [900]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.104148,	
2017-06-26 20:31:27,163 Epoch[39] Batch [910]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.103996,	
2017-06-26 20:31:32,546 Epoch[39] Batch [920]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.103888,	
2017-06-26 20:31:37,880 Epoch[39] Batch [930]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.103797,	
2017-06-26 20:31:43,188 Epoch[39] Batch [940]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.103762,	
2017-06-26 20:31:48,521 Epoch[39] Batch [950]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.103612,	
2017-06-26 20:31:53,874 Epoch[39] Batch [960]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.103490,	
2017-06-26 20:31:59,247 Epoch[39] Batch [970]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.103332,	
2017-06-26 20:32:04,592 Epoch[39] Batch [980]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103266,	
2017-06-26 20:32:09,944 Epoch[39] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103280,	
2017-06-26 20:32:15,252 Epoch[39] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.103235,	
2017-06-26 20:32:20,586 Epoch[39] Batch [1010]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.103303,	
2017-06-26 20:32:25,901 Epoch[39] Batch [1020]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.103139,	
2017-06-26 20:32:31,247 Epoch[39] Batch [1030]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103162,	
2017-06-26 20:32:36,592 Epoch[39] Batch [1040]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103136,	
2017-06-26 20:32:41,938 Epoch[39] Batch [1050]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.103098,	
2017-06-26 20:32:47,313 Epoch[39] Batch [1060]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.103047,	
2017-06-26 20:32:52,629 Epoch[39] Batch [1070]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.103014,	
2017-06-26 20:32:57,961 Epoch[39] Batch [1080]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.102867,	
2017-06-26 20:33:03,368 Epoch[39] Batch [1090]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.102773,	
2017-06-26 20:33:08,714 Epoch[39] Batch [1100]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.102736,	
2017-06-26 20:33:14,000 Epoch[39] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.102707,	
2017-06-26 20:33:19,368 Epoch[39] Batch [1120]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.102625,	
2017-06-26 20:33:24,678 Epoch[39] Batch [1130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.102567,	
2017-06-26 20:33:30,037 Epoch[39] Batch [1140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.102581,	
2017-06-26 20:33:35,388 Epoch[39] Batch [1150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.102546,	
2017-06-26 20:33:40,731 Epoch[39] Batch [1160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.102483,	
2017-06-26 20:33:46,046 Epoch[39] Batch [1170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.102416,	
2017-06-26 20:33:51,407 Epoch[39] Batch [1180]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.102341,	
2017-06-26 20:33:56,755 Epoch[39] Batch [1190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.102312,	
2017-06-26 20:34:02,109 Epoch[39] Batch [1200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.102238,	
2017-06-26 20:34:07,437 Epoch[39] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.102240,	
2017-06-26 20:34:12,739 Epoch[39] Batch [1220]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.102241,	
2017-06-26 20:34:18,114 Epoch[39] Batch [1230]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.102267,	
2017-06-26 20:34:23,441 Epoch[39] Batch [1240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.102245,	
2017-06-26 20:34:28,759 Epoch[39] Batch [1250]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.102232,	
2017-06-26 20:34:34,144 Epoch[39] Batch [1260]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.102301,	
2017-06-26 20:34:39,439 Epoch[39] Batch [1270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.102343,	
2017-06-26 20:34:44,804 Epoch[39] Batch [1280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.102298,	
2017-06-26 20:34:50,165 Epoch[39] Batch [1290]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.102331,	
2017-06-26 20:34:55,560 Epoch[39] Batch [1300]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.102279,	
2017-06-26 20:35:00,916 Epoch[39] Batch [1310]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.102270,	
2017-06-26 20:35:06,279 Epoch[39] Batch [1320]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.102305,	
2017-06-26 20:35:11,719 Epoch[39] Batch [1330]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.102280,	
2017-06-26 20:35:17,169 Epoch[39] Batch [1340]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.102148,	
2017-06-26 20:35:22,505 Epoch[39] Batch [1350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.102153,	
2017-06-26 20:35:27,840 Epoch[39] Batch [1360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.102072,	
2017-06-26 20:35:33,198 Epoch[39] Batch [1370]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.102006,	
2017-06-26 20:35:38,556 Epoch[39] Batch [1380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101929,	
2017-06-26 20:35:43,864 Epoch[39] Batch [1390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101932,	
2017-06-26 20:35:49,359 Epoch[39] Batch [1400]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.101921,	
2017-06-26 20:35:54,716 Epoch[39] Batch [1410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.101873,	
2017-06-26 20:36:00,089 Epoch[39] Batch [1420]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.101868,	
2017-06-26 20:36:05,387 Epoch[39] Batch [1430]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.101872,	
2017-06-26 20:36:10,933 Epoch[39] Batch [1440]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.101949,	
2017-06-26 20:36:16,272 Epoch[39] Batch [1450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.101861,	
2017-06-26 20:36:21,577 Epoch[39] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.101856,	
2017-06-26 20:36:27,003 Epoch[39] Batch [1470]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.101776,	
2017-06-26 20:36:32,328 Epoch[39] Batch [1480]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.101726,	
2017-06-26 20:36:35,549 Epoch[39] Train-FCNLogLoss=0.101709
2017-06-26 20:36:35,549 Epoch[39] Time cost=795.488
2017-06-26 20:36:36,182 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0040.params"
2017-06-26 20:36:38,364 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0040.states"
2017-06-26 20:36:44,455 Epoch[40] Batch [10]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.100480,	
2017-06-26 20:36:49,761 Epoch[40] Batch [20]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097836,	
2017-06-26 20:36:55,065 Epoch[40] Batch [30]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094035,	
2017-06-26 20:37:00,428 Epoch[40] Batch [40]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095198,	
2017-06-26 20:37:05,782 Epoch[40] Batch [50]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094045,	
2017-06-26 20:37:11,125 Epoch[40] Batch [60]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093914,	
2017-06-26 20:37:16,466 Epoch[40] Batch [70]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095333,	
2017-06-26 20:37:21,761 Epoch[40] Batch [80]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.098195,	
2017-06-26 20:37:27,148 Epoch[40] Batch [90]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.098840,	
2017-06-26 20:37:32,448 Epoch[40] Batch [100]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.100004,	
2017-06-26 20:37:37,790 Epoch[40] Batch [110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.100215,	
2017-06-26 20:37:43,219 Epoch[40] Batch [120]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.100065,	
2017-06-26 20:37:47,751 Epoch[40] Batch [130]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.099977,	
2017-06-26 20:37:53,054 Epoch[40] Batch [140]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.099458,	
2017-06-26 20:37:58,398 Epoch[40] Batch [150]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.098998,	
2017-06-26 20:38:03,713 Epoch[40] Batch [160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098519,	
2017-06-26 20:38:09,026 Epoch[40] Batch [170]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.098178,	
2017-06-26 20:38:14,400 Epoch[40] Batch [180]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.097757,	
2017-06-26 20:38:19,698 Epoch[40] Batch [190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.097545,	
2017-06-26 20:38:25,047 Epoch[40] Batch [200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.097031,	
2017-06-26 20:38:30,413 Epoch[40] Batch [210]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096407,	
2017-06-26 20:38:35,698 Epoch[40] Batch [220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096515,	
2017-06-26 20:38:41,073 Epoch[40] Batch [230]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096820,	
2017-06-26 20:38:46,384 Epoch[40] Batch [240]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097111,	
2017-06-26 20:38:51,747 Epoch[40] Batch [250]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097459,	
2017-06-26 20:38:57,041 Epoch[40] Batch [260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.097250,	
2017-06-26 20:39:02,452 Epoch[40] Batch [270]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.096986,	
2017-06-26 20:39:07,717 Epoch[40] Batch [280]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.096603,	
2017-06-26 20:39:13,028 Epoch[40] Batch [290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096899,	
2017-06-26 20:39:18,376 Epoch[40] Batch [300]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096635,	
2017-06-26 20:39:23,731 Epoch[40] Batch [310]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096739,	
2017-06-26 20:39:29,050 Epoch[40] Batch [320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096735,	
2017-06-26 20:39:34,374 Epoch[40] Batch [330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096694,	
2017-06-26 20:39:39,686 Epoch[40] Batch [340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096527,	
2017-06-26 20:39:45,033 Epoch[40] Batch [350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096546,	
2017-06-26 20:39:50,342 Epoch[40] Batch [360]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096404,	
2017-06-26 20:39:55,685 Epoch[40] Batch [370]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097086,	
2017-06-26 20:40:01,029 Epoch[40] Batch [380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.097180,	
2017-06-26 20:40:06,297 Epoch[40] Batch [390]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.097176,	
2017-06-26 20:40:11,660 Epoch[40] Batch [400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.097186,	
2017-06-26 20:40:16,993 Epoch[40] Batch [410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.097182,	
2017-06-26 20:40:22,302 Epoch[40] Batch [420]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.097029,	
2017-06-26 20:40:27,660 Epoch[40] Batch [430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096956,	
2017-06-26 20:40:32,986 Epoch[40] Batch [440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096712,	
2017-06-26 20:40:38,316 Epoch[40] Batch [450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.096516,	
2017-06-26 20:40:43,631 Epoch[40] Batch [460]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096500,	
2017-06-26 20:40:48,987 Epoch[40] Batch [470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096339,	
2017-06-26 20:40:54,278 Epoch[40] Batch [480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096287,	
2017-06-26 20:40:59,644 Epoch[40] Batch [490]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.096551,	
2017-06-26 20:41:04,931 Epoch[40] Batch [500]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.096547,	
2017-06-26 20:41:10,256 Epoch[40] Batch [510]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096547,	
2017-06-26 20:41:14,548 Update[60000]: Change learning rate to 5.00000e-05
2017-06-26 20:41:15,572 Epoch[40] Batch [520]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.096326,	
2017-06-26 20:41:20,898 Epoch[40] Batch [530]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.096167,	
2017-06-26 20:41:26,276 Epoch[40] Batch [540]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.096328,	
2017-06-26 20:41:31,566 Epoch[40] Batch [550]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.096311,	
2017-06-26 20:41:36,909 Epoch[40] Batch [560]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096197,	
2017-06-26 20:41:42,259 Epoch[40] Batch [570]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.096234,	
2017-06-26 20:41:47,575 Epoch[40] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.096032,	
2017-06-26 20:41:52,894 Epoch[40] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095975,	
2017-06-26 20:41:58,201 Epoch[40] Batch [600]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.095806,	
2017-06-26 20:42:03,521 Epoch[40] Batch [610]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095769,	
2017-06-26 20:42:08,842 Epoch[40] Batch [620]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095712,	
2017-06-26 20:42:14,202 Epoch[40] Batch [630]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095767,	
2017-06-26 20:42:19,495 Epoch[40] Batch [640]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095563,	
2017-06-26 20:42:24,828 Epoch[40] Batch [650]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.095433,	
2017-06-26 20:42:30,199 Epoch[40] Batch [660]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095705,	
2017-06-26 20:42:35,483 Epoch[40] Batch [670]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.095606,	
2017-06-26 20:42:40,824 Epoch[40] Batch [680]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095510,	
2017-06-26 20:42:46,143 Epoch[40] Batch [690]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095541,	
2017-06-26 20:42:51,466 Epoch[40] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095481,	
2017-06-26 20:42:56,795 Epoch[40] Batch [710]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.095513,	
2017-06-26 20:43:02,112 Epoch[40] Batch [720]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095469,	
2017-06-26 20:43:07,475 Epoch[40] Batch [730]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095400,	
2017-06-26 20:43:12,792 Epoch[40] Batch [740]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095311,	
2017-06-26 20:43:18,115 Epoch[40] Batch [750]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.095272,	
2017-06-26 20:43:23,458 Epoch[40] Batch [760]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.095264,	
2017-06-26 20:43:28,751 Epoch[40] Batch [770]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.095172,	
2017-06-26 20:43:34,123 Epoch[40] Batch [780]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095099,	
2017-06-26 20:43:39,432 Epoch[40] Batch [790]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.095062,	
2017-06-26 20:43:44,779 Epoch[40] Batch [800]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095058,	
2017-06-26 20:43:50,152 Epoch[40] Batch [810]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095005,	
2017-06-26 20:43:55,440 Epoch[40] Batch [820]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094998,	
2017-06-26 20:44:00,764 Epoch[40] Batch [830]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094979,	
2017-06-26 20:44:06,125 Epoch[40] Batch [840]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.095041,	
2017-06-26 20:44:11,476 Epoch[40] Batch [850]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094959,	
2017-06-26 20:44:16,834 Epoch[40] Batch [860]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094897,	
2017-06-26 20:44:22,102 Epoch[40] Batch [870]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094881,	
2017-06-26 20:44:27,470 Epoch[40] Batch [880]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094858,	
2017-06-26 20:44:32,804 Epoch[40] Batch [890]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094959,	
2017-06-26 20:44:38,174 Epoch[40] Batch [900]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094914,	
2017-06-26 20:44:43,449 Epoch[40] Batch [910]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.095091,	
2017-06-26 20:44:48,799 Epoch[40] Batch [920]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.095036,	
2017-06-26 20:44:54,217 Epoch[40] Batch [930]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.095057,	
2017-06-26 20:44:59,657 Epoch[40] Batch [940]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.094966,	
2017-06-26 20:45:05,086 Epoch[40] Batch [950]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.094904,	
2017-06-26 20:45:10,368 Epoch[40] Batch [960]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094881,	
2017-06-26 20:45:15,710 Epoch[40] Batch [970]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094858,	
2017-06-26 20:45:20,998 Epoch[40] Batch [980]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094890,	
2017-06-26 20:45:26,347 Epoch[40] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094891,	
2017-06-26 20:45:31,746 Epoch[40] Batch [1000]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.094877,	
2017-06-26 20:45:37,053 Epoch[40] Batch [1010]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094851,	
2017-06-26 20:45:42,388 Epoch[40] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094932,	
2017-06-26 20:45:47,849 Epoch[40] Batch [1030]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.094848,	
2017-06-26 20:45:53,206 Epoch[40] Batch [1040]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094787,	
2017-06-26 20:45:58,480 Epoch[40] Batch [1050]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094765,	
2017-06-26 20:46:03,928 Epoch[40] Batch [1060]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.094631,	
2017-06-26 20:46:09,140 Epoch[40] Batch [1070]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.094626,	
2017-06-26 20:46:14,260 Epoch[40] Batch [1080]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.094630,	
2017-06-26 20:46:19,611 Epoch[40] Batch [1090]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094565,	
2017-06-26 20:46:24,990 Epoch[40] Batch [1100]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.094577,	
2017-06-26 20:46:30,273 Epoch[40] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094617,	
2017-06-26 20:46:35,701 Epoch[40] Batch [1120]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.094645,	
2017-06-26 20:46:41,054 Epoch[40] Batch [1130]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094545,	
2017-06-26 20:46:46,372 Epoch[40] Batch [1140]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.094475,	
2017-06-26 20:46:51,672 Epoch[40] Batch [1150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094414,	
2017-06-26 20:46:57,022 Epoch[40] Batch [1160]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094383,	
2017-06-26 20:47:02,362 Epoch[40] Batch [1170]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094361,	
2017-06-26 20:47:07,710 Epoch[40] Batch [1180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094308,	
2017-06-26 20:47:13,110 Epoch[40] Batch [1190]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.094252,	
2017-06-26 20:47:17,984 Epoch[40] Batch [1200]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.094309,	
2017-06-26 20:47:23,189 Epoch[40] Batch [1210]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.094267,	
2017-06-26 20:47:28,472 Epoch[40] Batch [1220]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094333,	
2017-06-26 20:47:33,881 Epoch[40] Batch [1230]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.094316,	
2017-06-26 20:47:39,187 Epoch[40] Batch [1240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094337,	
2017-06-26 20:47:44,588 Epoch[40] Batch [1250]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.094347,	
2017-06-26 20:47:49,877 Epoch[40] Batch [1260]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.094395,	
2017-06-26 20:47:55,221 Epoch[40] Batch [1270]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094375,	
2017-06-26 20:48:00,578 Epoch[40] Batch [1280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094393,	
2017-06-26 20:48:05,927 Epoch[40] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094466,	
2017-06-26 20:48:11,256 Epoch[40] Batch [1300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094451,	
2017-06-26 20:48:16,605 Epoch[40] Batch [1310]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.094349,	
2017-06-26 20:48:21,945 Epoch[40] Batch [1320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094311,	
2017-06-26 20:48:27,276 Epoch[40] Batch [1330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094276,	
2017-06-26 20:48:32,614 Epoch[40] Batch [1340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094197,	
2017-06-26 20:48:37,986 Epoch[40] Batch [1350]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094192,	
2017-06-26 20:48:43,290 Epoch[40] Batch [1360]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.094223,	
2017-06-26 20:48:48,681 Epoch[40] Batch [1370]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.094190,	
2017-06-26 20:48:53,980 Epoch[40] Batch [1380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.094201,	
2017-06-26 20:48:59,334 Epoch[40] Batch [1390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094145,	
2017-06-26 20:49:04,678 Epoch[40] Batch [1400]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.094153,	
2017-06-26 20:49:10,056 Epoch[40] Batch [1410]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.094113,	
2017-06-26 20:49:15,306 Epoch[40] Batch [1420]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094131,	
2017-06-26 20:49:20,637 Epoch[40] Batch [1430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.094151,	
2017-06-26 20:49:26,035 Epoch[40] Batch [1440]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.094070,	
2017-06-26 20:49:31,389 Epoch[40] Batch [1450]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094081,	
2017-06-26 20:49:36,701 Epoch[40] Batch [1460]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.094027,	
2017-06-26 20:49:42,029 Epoch[40] Batch [1470]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.094061,	
2017-06-26 20:49:47,406 Epoch[40] Batch [1480]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.094065,	
2017-06-26 20:49:50,598 Epoch[40] Train-FCNLogLoss=0.094004
2017-06-26 20:49:50,598 Epoch[40] Time cost=792.234
2017-06-26 20:49:51,234 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0041.params"
2017-06-26 20:49:53,746 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0041.states"
2017-06-26 20:49:59,742 Epoch[41] Batch [10]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.084910,	
2017-06-26 20:50:05,271 Epoch[41] Batch [20]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088470,	
2017-06-26 20:50:10,555 Epoch[41] Batch [30]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088765,	
2017-06-26 20:50:16,584 Epoch[41] Batch [40]	Speed: 6.64 samples/sec	Train-FCNLogLoss=0.088919,	
2017-06-26 20:50:23,953 Epoch[41] Batch [50]	Speed: 5.43 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-26 20:50:29,239 Epoch[41] Batch [60]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089127,	
2017-06-26 20:50:34,540 Epoch[41] Batch [70]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089785,	
2017-06-26 20:50:40,115 Epoch[41] Batch [80]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.089438,	
2017-06-26 20:50:45,289 Epoch[41] Batch [90]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089416,	
2017-06-26 20:50:50,647 Epoch[41] Batch [100]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090040,	
2017-06-26 20:50:55,629 Epoch[41] Batch [110]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.089467,	
2017-06-26 20:51:00,801 Epoch[41] Batch [120]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089485,	
2017-06-26 20:51:05,308 Epoch[41] Batch [130]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.089837,	
2017-06-26 20:51:11,078 Epoch[41] Batch [140]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.089969,	
2017-06-26 20:51:16,399 Epoch[41] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090105,	
2017-06-26 20:51:24,366 Epoch[41] Batch [160]	Speed: 5.02 samples/sec	Train-FCNLogLoss=0.089835,	
2017-06-26 20:51:29,797 Epoch[41] Batch [170]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089507,	
2017-06-26 20:51:35,092 Epoch[41] Batch [180]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089495,	
2017-06-26 20:51:40,244 Epoch[41] Batch [190]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.089534,	
2017-06-26 20:51:47,118 Epoch[41] Batch [200]	Speed: 5.82 samples/sec	Train-FCNLogLoss=0.089550,	
2017-06-26 20:51:53,520 Epoch[41] Batch [210]	Speed: 6.25 samples/sec	Train-FCNLogLoss=0.089421,	
2017-06-26 20:51:58,837 Epoch[41] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089167,	
2017-06-26 20:52:03,550 Epoch[41] Batch [230]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.089611,	
2017-06-26 20:52:08,389 Epoch[41] Batch [240]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.089461,	
2017-06-26 20:52:13,692 Epoch[41] Batch [250]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089730,	
2017-06-26 20:52:19,029 Epoch[41] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089904,	
2017-06-26 20:52:24,328 Epoch[41] Batch [270]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089778,	
2017-06-26 20:52:29,686 Epoch[41] Batch [280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090290,	
2017-06-26 20:52:34,985 Epoch[41] Batch [290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090234,	
2017-06-26 20:52:40,316 Epoch[41] Batch [300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090153,	
2017-06-26 20:52:45,668 Epoch[41] Batch [310]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089945,	
2017-06-26 20:52:51,009 Epoch[41] Batch [320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089710,	
2017-06-26 20:52:56,340 Epoch[41] Batch [330]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089578,	
2017-06-26 20:53:01,698 Epoch[41] Batch [340]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089631,	
2017-06-26 20:53:06,981 Epoch[41] Batch [350]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089761,	
2017-06-26 20:53:12,619 Epoch[41] Batch [360]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.089862,	
2017-06-26 20:53:17,962 Epoch[41] Batch [370]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089898,	
2017-06-26 20:53:23,248 Epoch[41] Batch [380]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089715,	
2017-06-26 20:53:28,686 Epoch[41] Batch [390]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.089902,	
2017-06-26 20:53:34,179 Epoch[41] Batch [400]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.090302,	
2017-06-26 20:53:39,464 Epoch[41] Batch [410]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090353,	
2017-06-26 20:53:44,848 Epoch[41] Batch [420]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090093,	
2017-06-26 20:53:50,213 Epoch[41] Batch [430]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090052,	
2017-06-26 20:53:55,691 Epoch[41] Batch [440]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089940,	
2017-06-26 20:54:00,971 Epoch[41] Batch [450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089837,	
2017-06-26 20:54:06,355 Epoch[41] Batch [460]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090067,	
2017-06-26 20:54:11,859 Epoch[41] Batch [470]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.090093,	
2017-06-26 20:54:17,214 Epoch[41] Batch [480]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090080,	
2017-06-26 20:54:22,541 Epoch[41] Batch [490]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090116,	
2017-06-26 20:54:27,831 Epoch[41] Batch [500]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090256,	
2017-06-26 20:54:33,232 Epoch[41] Batch [510]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-26 20:54:38,746 Epoch[41] Batch [520]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.090244,	
2017-06-26 20:54:44,096 Epoch[41] Batch [530]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090496,	
2017-06-26 20:54:49,373 Epoch[41] Batch [540]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090478,	
2017-06-26 20:54:54,738 Epoch[41] Batch [550]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090207,	
2017-06-26 20:55:00,209 Epoch[41] Batch [560]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.090199,	
2017-06-26 20:55:05,521 Epoch[41] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-26 20:55:10,920 Epoch[41] Batch [580]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090321,	
2017-06-26 20:55:16,320 Epoch[41] Batch [590]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090308,	
2017-06-26 20:55:21,655 Epoch[41] Batch [600]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090379,	
2017-06-26 20:55:27,043 Epoch[41] Batch [610]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090510,	
2017-06-26 20:55:32,359 Epoch[41] Batch [620]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090458,	
2017-06-26 20:55:37,745 Epoch[41] Batch [630]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090287,	
2017-06-26 20:55:43,038 Epoch[41] Batch [640]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-26 20:55:48,403 Epoch[41] Batch [650]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090348,	
2017-06-26 20:55:53,728 Epoch[41] Batch [660]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090223,	
2017-06-26 20:55:59,115 Epoch[41] Batch [670]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090246,	
2017-06-26 20:56:04,438 Epoch[41] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090438,	
2017-06-26 20:56:09,795 Epoch[41] Batch [690]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090451,	
2017-06-26 20:56:15,120 Epoch[41] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090500,	
2017-06-26 20:56:20,573 Epoch[41] Batch [710]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.090531,	
2017-06-26 20:56:25,914 Epoch[41] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090546,	
2017-06-26 20:56:31,258 Epoch[41] Batch [730]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090594,	
2017-06-26 20:56:36,530 Epoch[41] Batch [740]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090769,	
2017-06-26 20:56:41,868 Epoch[41] Batch [750]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090750,	
2017-06-26 20:56:47,179 Epoch[41] Batch [760]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090721,	
2017-06-26 20:56:52,537 Epoch[41] Batch [770]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090774,	
2017-06-26 20:56:57,889 Epoch[41] Batch [780]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090835,	
2017-06-26 20:57:03,223 Epoch[41] Batch [790]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090799,	
2017-06-26 20:57:08,596 Epoch[41] Batch [800]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090807,	
2017-06-26 20:57:13,902 Epoch[41] Batch [810]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090840,	
2017-06-26 20:57:19,220 Epoch[41] Batch [820]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090879,	
2017-06-26 20:57:24,579 Epoch[41] Batch [830]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090891,	
2017-06-26 20:57:29,864 Epoch[41] Batch [840]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090972,	
2017-06-26 20:57:35,279 Epoch[41] Batch [850]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090981,	
2017-06-26 20:57:40,597 Epoch[41] Batch [860]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090955,	
2017-06-26 20:57:45,957 Epoch[41] Batch [870]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090916,	
2017-06-26 20:57:51,325 Epoch[41] Batch [880]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090758,	
2017-06-26 20:57:56,624 Epoch[41] Batch [890]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090705,	
2017-06-26 20:58:01,931 Epoch[41] Batch [900]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090699,	
2017-06-26 20:58:07,250 Epoch[41] Batch [910]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090746,	
2017-06-26 20:58:12,655 Epoch[41] Batch [920]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090665,	
2017-06-26 20:58:17,946 Epoch[41] Batch [930]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090804,	
2017-06-26 20:58:23,274 Epoch[41] Batch [940]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090780,	
2017-06-26 20:58:28,617 Epoch[41] Batch [950]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090778,	
2017-06-26 20:58:33,956 Epoch[41] Batch [960]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090626,	
2017-06-26 20:58:39,257 Epoch[41] Batch [970]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090572,	
2017-06-26 20:58:44,616 Epoch[41] Batch [980]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090566,	
2017-06-26 20:58:49,920 Epoch[41] Batch [990]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090621,	
2017-06-26 20:58:55,238 Epoch[41] Batch [1000]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090622,	
2017-06-26 20:59:00,617 Epoch[41] Batch [1010]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090627,	
2017-06-26 20:59:05,912 Epoch[41] Batch [1020]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090549,	
2017-06-26 20:59:11,277 Epoch[41] Batch [1030]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090591,	
2017-06-26 20:59:16,622 Epoch[41] Batch [1040]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090593,	
2017-06-26 20:59:21,980 Epoch[41] Batch [1050]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090536,	
2017-06-26 20:59:27,246 Epoch[41] Batch [1060]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090515,	
2017-06-26 20:59:32,580 Epoch[41] Batch [1070]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090584,	
2017-06-26 20:59:37,920 Epoch[41] Batch [1080]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090746,	
2017-06-26 20:59:43,276 Epoch[41] Batch [1090]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090796,	
2017-06-26 20:59:48,612 Epoch[41] Batch [1100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090752,	
2017-06-26 20:59:53,899 Epoch[41] Batch [1110]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090708,	
2017-06-26 20:59:59,253 Epoch[41] Batch [1120]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090728,	
2017-06-26 21:00:04,635 Epoch[41] Batch [1130]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090758,	
2017-06-26 21:00:09,931 Epoch[41] Batch [1140]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090734,	
2017-06-26 21:00:15,273 Epoch[41] Batch [1150]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090692,	
2017-06-26 21:00:20,632 Epoch[41] Batch [1160]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090747,	
2017-06-26 21:00:25,948 Epoch[41] Batch [1170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090806,	
2017-06-26 21:00:31,297 Epoch[41] Batch [1180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090792,	
2017-06-26 21:00:36,593 Epoch[41] Batch [1190]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090709,	
2017-06-26 21:00:41,987 Epoch[41] Batch [1200]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090642,	
2017-06-26 21:00:47,271 Epoch[41] Batch [1210]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090663,	
2017-06-26 21:00:52,631 Epoch[41] Batch [1220]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090658,	
2017-06-26 21:00:57,960 Epoch[41] Batch [1230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090651,	
2017-06-26 21:01:03,315 Epoch[41] Batch [1240]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090623,	
2017-06-26 21:01:08,657 Epoch[41] Batch [1250]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090623,	
2017-06-26 21:01:14,044 Epoch[41] Batch [1260]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090574,	
2017-06-26 21:01:19,379 Epoch[41] Batch [1270]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090625,	
2017-06-26 21:01:24,673 Epoch[41] Batch [1280]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090583,	
2017-06-26 21:01:30,021 Epoch[41] Batch [1290]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090600,	
2017-06-26 21:01:35,343 Epoch[41] Batch [1300]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090624,	
2017-06-26 21:01:40,675 Epoch[41] Batch [1310]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090674,	
2017-06-26 21:01:46,003 Epoch[41] Batch [1320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090658,	
2017-06-26 21:01:51,349 Epoch[41] Batch [1330]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090636,	
2017-06-26 21:01:56,710 Epoch[41] Batch [1340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090653,	
2017-06-26 21:02:02,007 Epoch[41] Batch [1350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090605,	
2017-06-26 21:02:07,355 Epoch[41] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090658,	
2017-06-26 21:02:12,687 Epoch[41] Batch [1370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090647,	
2017-06-26 21:02:18,013 Epoch[41] Batch [1380]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090725,	
2017-06-26 21:02:23,382 Epoch[41] Batch [1390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090654,	
2017-06-26 21:02:28,746 Epoch[41] Batch [1400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090690,	
2017-06-26 21:02:34,063 Epoch[41] Batch [1410]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090766,	
2017-06-26 21:02:39,425 Epoch[41] Batch [1420]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090825,	
2017-06-26 21:02:44,785 Epoch[41] Batch [1430]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090807,	
2017-06-26 21:02:50,145 Epoch[41] Batch [1440]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090745,	
2017-06-26 21:02:55,621 Epoch[41] Batch [1450]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.090790,	
2017-06-26 21:03:00,887 Epoch[41] Batch [1460]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090722,	
2017-06-26 21:03:06,202 Epoch[41] Batch [1470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090725,	
2017-06-26 21:03:11,648 Epoch[41] Batch [1480]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.090726,	
2017-06-26 21:03:14,778 Epoch[41] Train-FCNLogLoss=0.090732
2017-06-26 21:03:14,779 Epoch[41] Time cost=801.032
2017-06-26 21:03:15,420 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0042.params"
2017-06-26 21:03:17,502 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0042.states"
2017-06-26 21:03:23,303 Epoch[42] Batch [10]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.098752,	
2017-06-26 21:03:28,325 Epoch[42] Batch [20]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.098051,	
2017-06-26 21:03:33,678 Epoch[42] Batch [30]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.096622,	
2017-06-26 21:03:38,964 Epoch[42] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.097047,	
2017-06-26 21:03:44,336 Epoch[42] Batch [50]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.095019,	
2017-06-26 21:03:49,713 Epoch[42] Batch [60]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.092869,	
2017-06-26 21:03:54,988 Epoch[42] Batch [70]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091442,	
2017-06-26 21:04:00,333 Epoch[42] Batch [80]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.091002,	
2017-06-26 21:04:05,697 Epoch[42] Batch [90]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091676,	
2017-06-26 21:04:11,068 Epoch[42] Batch [100]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090478,	
2017-06-26 21:04:16,442 Epoch[42] Batch [110]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090253,	
2017-06-26 21:04:21,777 Epoch[42] Batch [120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089229,	
2017-06-26 21:04:27,291 Epoch[42] Batch [130]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.089649,	
2017-06-26 21:04:32,167 Epoch[42] Batch [140]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.089871,	
2017-06-26 21:04:36,981 Epoch[42] Batch [150]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.090662,	
2017-06-26 21:04:42,230 Epoch[42] Batch [160]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090966,	
2017-06-26 21:04:47,625 Epoch[42] Batch [170]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090843,	
2017-06-26 21:04:52,933 Epoch[42] Batch [180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.091408,	
2017-06-26 21:04:58,250 Epoch[42] Batch [190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091197,	
2017-06-26 21:05:03,603 Epoch[42] Batch [200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090970,	
2017-06-26 21:05:08,936 Epoch[42] Batch [210]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091156,	
2017-06-26 21:05:14,271 Epoch[42] Batch [220]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090920,	
2017-06-26 21:05:19,626 Epoch[42] Batch [230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090796,	
2017-06-26 21:05:24,950 Epoch[42] Batch [240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090487,	
2017-06-26 21:05:30,249 Epoch[42] Batch [250]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090591,	
2017-06-26 21:05:35,646 Epoch[42] Batch [260]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090647,	
2017-06-26 21:05:40,963 Epoch[42] Batch [270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090549,	
2017-06-26 21:05:46,295 Epoch[42] Batch [280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090397,	
2017-06-26 21:05:51,720 Epoch[42] Batch [290]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090487,	
2017-06-26 21:05:56,992 Epoch[42] Batch [300]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090650,	
2017-06-26 21:06:02,292 Epoch[42] Batch [310]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090621,	
2017-06-26 21:06:07,622 Epoch[42] Batch [320]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090995,	
2017-06-26 21:06:12,975 Epoch[42] Batch [330]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090867,	
2017-06-26 21:06:18,325 Epoch[42] Batch [340]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090962,	
2017-06-26 21:06:23,631 Epoch[42] Batch [350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090864,	
2017-06-26 21:06:28,985 Epoch[42] Batch [360]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090628,	
2017-06-26 21:06:34,310 Epoch[42] Batch [370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090338,	
2017-06-26 21:06:39,612 Epoch[42] Batch [380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090484,	
2017-06-26 21:06:44,996 Epoch[42] Batch [390]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090620,	
2017-06-26 21:06:50,360 Epoch[42] Batch [400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090780,	
2017-06-26 21:06:55,666 Epoch[42] Batch [410]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090748,	
2017-06-26 21:07:01,015 Epoch[42] Batch [420]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090553,	
2017-06-26 21:07:06,358 Epoch[42] Batch [430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090515,	
2017-06-26 21:07:11,710 Epoch[42] Batch [440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090596,	
2017-06-26 21:07:17,060 Epoch[42] Batch [450]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090809,	
2017-06-26 21:07:22,351 Epoch[42] Batch [460]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090730,	
2017-06-26 21:07:27,681 Epoch[42] Batch [470]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090976,	
2017-06-26 21:07:33,067 Epoch[42] Batch [480]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090946,	
2017-06-26 21:07:38,351 Epoch[42] Batch [490]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090956,	
2017-06-26 21:07:43,723 Epoch[42] Batch [500]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090925,	
2017-06-26 21:07:49,094 Epoch[42] Batch [510]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090790,	
2017-06-26 21:07:54,377 Epoch[42] Batch [520]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090870,	
2017-06-26 21:07:59,735 Epoch[42] Batch [530]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090780,	
2017-06-26 21:08:05,040 Epoch[42] Batch [540]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090714,	
2017-06-26 21:08:10,391 Epoch[42] Batch [550]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090657,	
2017-06-26 21:08:15,704 Epoch[42] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090437,	
2017-06-26 21:08:21,064 Epoch[42] Batch [570]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090300,	
2017-06-26 21:08:26,352 Epoch[42] Batch [580]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090530,	
2017-06-26 21:08:31,683 Epoch[42] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090572,	
2017-06-26 21:08:37,065 Epoch[42] Batch [600]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090654,	
2017-06-26 21:08:42,334 Epoch[42] Batch [610]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090706,	
2017-06-26 21:08:47,650 Epoch[42] Batch [620]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090729,	
2017-06-26 21:08:52,966 Epoch[42] Batch [630]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090734,	
2017-06-26 21:08:58,336 Epoch[42] Batch [640]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090689,	
2017-06-26 21:09:03,685 Epoch[42] Batch [650]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090593,	
2017-06-26 21:09:09,081 Epoch[42] Batch [660]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090562,	
2017-06-26 21:09:14,341 Epoch[42] Batch [670]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090649,	
2017-06-26 21:09:19,669 Epoch[42] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090577,	
2017-06-26 21:09:25,028 Epoch[42] Batch [690]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090736,	
2017-06-26 21:09:30,425 Epoch[42] Batch [700]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090734,	
2017-06-26 21:09:35,723 Epoch[42] Batch [710]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090789,	
2017-06-26 21:09:41,068 Epoch[42] Batch [720]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090775,	
2017-06-26 21:09:46,458 Epoch[42] Batch [730]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090840,	
2017-06-26 21:09:51,727 Epoch[42] Batch [740]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090747,	
2017-06-26 21:09:57,111 Epoch[42] Batch [750]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090778,	
2017-06-26 21:10:02,402 Epoch[42] Batch [760]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090755,	
2017-06-26 21:10:07,810 Epoch[42] Batch [770]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090776,	
2017-06-26 21:10:13,151 Epoch[42] Batch [780]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090929,	
2017-06-26 21:10:18,480 Epoch[42] Batch [790]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090790,	
2017-06-26 21:10:23,851 Epoch[42] Batch [800]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090780,	
2017-06-26 21:10:29,194 Epoch[42] Batch [810]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090801,	
2017-06-26 21:10:34,515 Epoch[42] Batch [820]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090841,	
2017-06-26 21:10:39,832 Epoch[42] Batch [830]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090786,	
2017-06-26 21:10:45,199 Epoch[42] Batch [840]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090775,	
2017-06-26 21:10:50,502 Epoch[42] Batch [850]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090801,	
2017-06-26 21:10:55,863 Epoch[42] Batch [860]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090865,	
2017-06-26 21:11:01,172 Epoch[42] Batch [870]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090861,	
2017-06-26 21:11:06,504 Epoch[42] Batch [880]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090834,	
2017-06-26 21:11:11,858 Epoch[42] Batch [890]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090772,	
2017-06-26 21:11:17,212 Epoch[42] Batch [900]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090813,	
2017-06-26 21:11:22,531 Epoch[42] Batch [910]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090740,	
2017-06-26 21:11:27,870 Epoch[42] Batch [920]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090978,	
2017-06-26 21:11:33,245 Epoch[42] Batch [930]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090973,	
2017-06-26 21:11:38,560 Epoch[42] Batch [940]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091085,	
2017-06-26 21:11:44,043 Epoch[42] Batch [950]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.091149,	
2017-06-26 21:11:49,395 Epoch[42] Batch [960]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091156,	
2017-06-26 21:11:54,650 Epoch[42] Batch [970]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.091133,	
2017-06-26 21:12:00,107 Epoch[42] Batch [980]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.091026,	
2017-06-26 21:12:05,478 Epoch[42] Batch [990]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090932,	
2017-06-26 21:12:10,383 Epoch[42] Batch [1000]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.090971,	
2017-06-26 21:12:15,366 Epoch[42] Batch [1010]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.091019,	
2017-06-26 21:12:20,545 Epoch[42] Batch [1020]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.090922,	
2017-06-26 21:12:25,937 Epoch[42] Batch [1030]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.091048,	
2017-06-26 21:12:31,219 Epoch[42] Batch [1040]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090990,	
2017-06-26 21:12:36,555 Epoch[42] Batch [1050]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090954,	
2017-06-26 21:12:41,896 Epoch[42] Batch [1060]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090921,	
2017-06-26 21:12:47,296 Epoch[42] Batch [1070]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090999,	
2017-06-26 21:12:52,644 Epoch[42] Batch [1080]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090965,	
2017-06-26 21:12:57,717 Epoch[42] Batch [1090]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.091023,	
2017-06-26 21:13:03,225 Epoch[42] Batch [1100]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.091048,	
2017-06-26 21:13:08,319 Epoch[42] Batch [1110]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090935,	
2017-06-26 21:13:13,376 Epoch[42] Batch [1120]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.090867,	
2017-06-26 21:13:18,700 Epoch[42] Batch [1130]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090867,	
2017-06-26 21:13:24,032 Epoch[42] Batch [1140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090860,	
2017-06-26 21:13:29,324 Epoch[42] Batch [1150]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090814,	
2017-06-26 21:13:34,322 Epoch[42] Batch [1160]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.090811,	
2017-06-26 21:13:39,537 Epoch[42] Batch [1170]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.090776,	
2017-06-26 21:13:44,862 Epoch[42] Batch [1180]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090781,	
2017-06-26 21:13:49,982 Epoch[42] Batch [1190]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090853,	
2017-06-26 21:13:55,027 Epoch[42] Batch [1200]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.090956,	
2017-06-26 21:14:00,378 Epoch[42] Batch [1210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090912,	
2017-06-26 21:14:05,630 Epoch[42] Batch [1220]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090841,	
2017-06-26 21:14:10,932 Epoch[42] Batch [1230]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090848,	
2017-06-26 21:14:16,334 Epoch[42] Batch [1240]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090824,	
2017-06-26 21:14:21,777 Epoch[42] Batch [1250]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.090820,	
2017-06-26 21:14:27,022 Epoch[42] Batch [1260]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090836,	
2017-06-26 21:14:32,387 Epoch[42] Batch [1270]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090841,	
2017-06-26 21:14:37,709 Epoch[42] Batch [1280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090787,	
2017-06-26 21:14:42,833 Epoch[42] Batch [1290]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090826,	
2017-06-26 21:14:48,194 Epoch[42] Batch [1300]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090798,	
2017-06-26 21:14:53,580 Epoch[42] Batch [1310]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090804,	
2017-06-26 21:14:58,821 Epoch[42] Batch [1320]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090768,	
2017-06-26 21:15:04,189 Epoch[42] Batch [1330]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090729,	
2017-06-26 21:15:09,428 Epoch[42] Batch [1340]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.090613,	
2017-06-26 21:15:14,567 Epoch[42] Batch [1350]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.090661,	
2017-06-26 21:15:19,794 Epoch[42] Batch [1360]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090738,	
2017-06-26 21:15:25,084 Epoch[42] Batch [1370]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090783,	
2017-06-26 21:15:30,272 Epoch[42] Batch [1380]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.090811,	
2017-06-26 21:15:35,041 Epoch[42] Batch [1390]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.090843,	
2017-06-26 21:15:40,138 Epoch[42] Batch [1400]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090817,	
2017-06-26 21:15:45,411 Epoch[42] Batch [1410]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090779,	
2017-06-26 21:15:50,754 Epoch[42] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090773,	
2017-06-26 21:15:55,540 Epoch[42] Batch [1430]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.090718,	
2017-06-26 21:16:00,546 Epoch[42] Batch [1440]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.090750,	
2017-06-26 21:16:05,813 Epoch[42] Batch [1450]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090753,	
2017-06-26 21:16:11,114 Epoch[42] Batch [1460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090729,	
2017-06-26 21:16:16,452 Epoch[42] Batch [1470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090686,	
2017-06-26 21:16:21,827 Epoch[42] Batch [1480]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090670,	
2017-06-26 21:16:24,952 Epoch[42] Train-FCNLogLoss=0.090687
2017-06-26 21:16:24,952 Epoch[42] Time cost=787.450
2017-06-26 21:16:25,642 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0043.params"
2017-06-26 21:16:27,991 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0043.states"
2017-06-26 21:16:34,021 Epoch[43] Batch [10]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089870,	
2017-06-26 21:16:39,080 Epoch[43] Batch [20]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.097208,	
2017-06-26 21:16:44,408 Epoch[43] Batch [30]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091623,	
2017-06-26 21:16:49,528 Epoch[43] Batch [40]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.091175,	
2017-06-26 21:16:54,343 Epoch[43] Batch [50]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.091927,	
2017-06-26 21:16:59,197 Epoch[43] Batch [60]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090707,	
2017-06-26 21:17:04,237 Epoch[43] Batch [70]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090964,	
2017-06-26 21:17:09,553 Epoch[43] Batch [80]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.091241,	
2017-06-26 21:17:14,876 Epoch[43] Batch [90]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091413,	
2017-06-26 21:17:20,201 Epoch[43] Batch [100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091374,	
2017-06-26 21:17:25,557 Epoch[43] Batch [110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091535,	
2017-06-26 21:17:30,886 Epoch[43] Batch [120]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091944,	
2017-06-26 21:17:36,182 Epoch[43] Batch [130]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091428,	
2017-06-26 21:17:41,238 Epoch[43] Batch [140]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.091544,	
2017-06-26 21:17:46,089 Epoch[43] Batch [150]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.091573,	
2017-06-26 21:17:51,147 Epoch[43] Batch [160]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.091941,	
2017-06-26 21:17:56,421 Epoch[43] Batch [170]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.091944,	
2017-06-26 21:18:01,121 Epoch[43] Batch [180]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.091343,	
2017-06-26 21:18:05,703 Epoch[43] Batch [190]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091134,	
2017-06-26 21:18:10,979 Epoch[43] Batch [200]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090814,	
2017-06-26 21:18:16,118 Epoch[43] Batch [210]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.090501,	
2017-06-26 21:18:21,155 Epoch[43] Batch [220]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090232,	
2017-06-26 21:18:26,301 Epoch[43] Batch [230]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.090142,	
2017-06-26 21:18:31,346 Epoch[43] Batch [240]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089816,	
2017-06-26 21:18:36,150 Epoch[43] Batch [250]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.089895,	
2017-06-26 21:18:41,425 Epoch[43] Batch [260]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089760,	
2017-06-26 21:18:46,286 Epoch[43] Batch [270]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089866,	
2017-06-26 21:18:51,404 Epoch[43] Batch [280]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089739,	
2017-06-26 21:18:56,351 Epoch[43] Batch [290]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.090068,	
2017-06-26 21:19:01,535 Epoch[43] Batch [300]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.090203,	
2017-06-26 21:19:06,847 Epoch[43] Batch [310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090228,	
2017-06-26 21:19:12,150 Epoch[43] Batch [320]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090305,	
2017-06-26 21:19:17,277 Epoch[43] Batch [330]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.090501,	
2017-06-26 21:19:22,487 Epoch[43] Batch [340]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.090673,	
2017-06-26 21:19:27,680 Epoch[43] Batch [350]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.090737,	
2017-06-26 21:19:32,416 Epoch[43] Batch [360]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.090940,	
2017-06-26 21:19:37,518 Epoch[43] Batch [370]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.090934,	
2017-06-26 21:19:42,444 Epoch[43] Batch [380]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.091049,	
2017-06-26 21:19:47,319 Epoch[43] Batch [390]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.090900,	
2017-06-26 21:19:52,468 Epoch[43] Batch [400]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.091001,	
2017-06-26 21:19:57,551 Epoch[43] Batch [410]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.090764,	
2017-06-26 21:20:02,332 Epoch[43] Batch [420]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.090669,	
2017-06-26 21:20:07,188 Epoch[43] Batch [430]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.090666,	
2017-06-26 21:20:12,263 Epoch[43] Batch [440]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.090920,	
2017-06-26 21:20:17,460 Epoch[43] Batch [450]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.090886,	
2017-06-26 21:20:22,818 Epoch[43] Batch [460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090690,	
2017-06-26 21:20:28,186 Epoch[43] Batch [470]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090839,	
2017-06-26 21:20:33,547 Epoch[43] Batch [480]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090900,	
2017-06-26 21:20:38,615 Epoch[43] Batch [490]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.090933,	
2017-06-26 21:20:43,949 Epoch[43] Batch [500]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090801,	
2017-06-26 21:20:49,380 Epoch[43] Batch [510]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090744,	
2017-06-26 21:20:54,806 Epoch[43] Batch [520]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090562,	
2017-06-26 21:21:00,109 Epoch[43] Batch [530]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090536,	
2017-06-26 21:21:05,508 Epoch[43] Batch [540]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090485,	
2017-06-26 21:21:10,797 Epoch[43] Batch [550]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090408,	
2017-06-26 21:21:16,229 Epoch[43] Batch [560]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090506,	
2017-06-26 21:21:21,606 Epoch[43] Batch [570]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090736,	
2017-06-26 21:21:26,771 Epoch[43] Batch [580]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.090953,	
2017-06-26 21:21:32,060 Epoch[43] Batch [590]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090941,	
2017-06-26 21:21:37,414 Epoch[43] Batch [600]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090908,	
2017-06-26 21:21:42,823 Epoch[43] Batch [610]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.091070,	
2017-06-26 21:21:48,202 Epoch[43] Batch [620]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090942,	
2017-06-26 21:21:53,519 Epoch[43] Batch [630]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.091052,	
2017-06-26 21:21:58,849 Epoch[43] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.091004,	
2017-06-26 21:22:04,270 Epoch[43] Batch [650]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.091000,	
2017-06-26 21:22:09,579 Epoch[43] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090922,	
2017-06-26 21:22:14,920 Epoch[43] Batch [670]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090933,	
2017-06-26 21:22:20,323 Epoch[43] Batch [680]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.090909,	
2017-06-26 21:22:25,770 Epoch[43] Batch [690]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.090950,	
2017-06-26 21:22:31,114 Epoch[43] Batch [700]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090994,	
2017-06-26 21:22:36,244 Epoch[43] Batch [710]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.090886,	
2017-06-26 21:22:41,484 Epoch[43] Batch [720]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090830,	
2017-06-26 21:22:46,361 Epoch[43] Batch [730]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.090784,	
2017-06-26 21:22:51,193 Epoch[43] Batch [740]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.090620,	
2017-06-26 21:22:56,525 Epoch[43] Batch [750]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090456,	
2017-06-26 21:23:01,617 Epoch[43] Batch [760]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.090497,	
2017-06-26 21:23:06,694 Epoch[43] Batch [770]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.090346,	
2017-06-26 21:23:11,942 Epoch[43] Batch [780]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.090510,	
2017-06-26 21:23:17,209 Epoch[43] Batch [790]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090514,	
2017-06-26 21:23:22,578 Epoch[43] Batch [800]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090520,	
2017-06-26 21:23:27,928 Epoch[43] Batch [810]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090546,	
2017-06-26 21:23:33,240 Epoch[43] Batch [820]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090438,	
2017-06-26 21:23:38,578 Epoch[43] Batch [830]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090428,	
2017-06-26 21:23:43,732 Epoch[43] Batch [840]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.090411,	
2017-06-26 21:23:48,576 Epoch[43] Batch [850]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.090388,	
2017-06-26 21:23:53,890 Epoch[43] Batch [860]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090459,	
2017-06-26 21:23:59,222 Epoch[43] Batch [870]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090446,	
2017-06-26 21:24:04,485 Epoch[43] Batch [880]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090349,	
2017-06-26 21:24:09,875 Epoch[43] Batch [890]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.090334,	
2017-06-26 21:24:15,198 Epoch[43] Batch [900]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090373,	
2017-06-26 21:24:20,546 Epoch[43] Batch [910]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090300,	
2017-06-26 21:24:25,907 Epoch[43] Batch [920]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090299,	
2017-06-26 21:24:31,265 Epoch[43] Batch [930]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-26 21:24:36,626 Epoch[43] Batch [940]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090263,	
2017-06-26 21:24:42,008 Epoch[43] Batch [950]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090286,	
2017-06-26 21:24:47,148 Epoch[43] Batch [960]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.090322,	
2017-06-26 21:24:52,340 Epoch[43] Batch [970]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.090255,	
2017-06-26 21:24:57,783 Epoch[43] Batch [980]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.090161,	
2017-06-26 21:25:03,125 Epoch[43] Batch [990]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090155,	
2017-06-26 21:25:08,458 Epoch[43] Batch [1000]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090171,	
2017-06-26 21:25:13,800 Epoch[43] Batch [1010]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090225,	
2017-06-26 21:25:19,175 Epoch[43] Batch [1020]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090249,	
2017-06-26 21:25:24,525 Epoch[43] Batch [1030]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090281,	
2017-06-26 21:25:29,863 Epoch[43] Batch [1040]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090353,	
2017-06-26 21:25:35,142 Epoch[43] Batch [1050]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090267,	
2017-06-26 21:25:40,236 Epoch[43] Batch [1060]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090182,	
2017-06-26 21:25:45,580 Epoch[43] Batch [1070]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090184,	
2017-06-26 21:25:50,912 Epoch[43] Batch [1080]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090147,	
2017-06-26 21:25:56,324 Epoch[43] Batch [1090]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090168,	
2017-06-26 21:26:01,589 Epoch[43] Batch [1100]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090102,	
2017-06-26 21:26:06,943 Epoch[43] Batch [1110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090101,	
2017-06-26 21:26:12,312 Epoch[43] Batch [1120]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090137,	
2017-06-26 21:26:17,618 Epoch[43] Batch [1130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090192,	
2017-06-26 21:26:23,030 Epoch[43] Batch [1140]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090213,	
2017-06-26 21:26:28,287 Epoch[43] Batch [1150]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.090164,	
2017-06-26 21:26:33,596 Epoch[43] Batch [1160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090197,	
2017-06-26 21:26:38,639 Epoch[43] Batch [1170]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.090242,	
2017-06-26 21:26:43,823 Epoch[43] Batch [1180]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.090251,	
2017-06-26 21:26:49,157 Epoch[43] Batch [1190]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090322,	
2017-06-26 21:26:54,420 Epoch[43] Batch [1200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-26 21:26:59,747 Epoch[43] Batch [1210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090398,	
2017-06-26 21:27:05,065 Epoch[43] Batch [1220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090387,	
2017-06-26 21:27:10,283 Epoch[43] Batch [1230]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.090479,	
2017-06-26 21:27:15,558 Epoch[43] Batch [1240]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090533,	
2017-06-26 21:27:20,931 Epoch[43] Batch [1250]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.090463,	
2017-06-26 21:27:26,213 Epoch[43] Batch [1260]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090507,	
2017-06-26 21:27:31,530 Epoch[43] Batch [1270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090504,	
2017-06-26 21:27:36,882 Epoch[43] Batch [1280]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090541,	
2017-06-26 21:27:42,206 Epoch[43] Batch [1290]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090505,	
2017-06-26 21:27:47,583 Epoch[43] Batch [1300]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090470,	
2017-06-26 21:27:52,859 Epoch[43] Batch [1310]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090456,	
2017-06-26 21:27:58,211 Epoch[43] Batch [1320]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090418,	
2017-06-26 21:28:03,524 Epoch[43] Batch [1330]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090376,	
2017-06-26 21:28:08,864 Epoch[43] Batch [1340]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090239,	
2017-06-26 21:28:14,197 Epoch[43] Batch [1350]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090131,	
2017-06-26 21:28:19,516 Epoch[43] Batch [1360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090106,	
2017-06-26 21:28:24,781 Epoch[43] Batch [1370]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090141,	
2017-06-26 21:28:29,913 Epoch[43] Batch [1380]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.090153,	
2017-06-26 21:28:35,034 Epoch[43] Batch [1390]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090146,	
2017-06-26 21:28:39,834 Epoch[43] Batch [1400]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.090123,	
2017-06-26 21:28:45,079 Epoch[43] Batch [1410]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090130,	
2017-06-26 21:28:50,489 Epoch[43] Batch [1420]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090102,	
2017-06-26 21:28:55,543 Epoch[43] Batch [1430]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.090075,	
2017-06-26 21:29:00,668 Epoch[43] Batch [1440]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090094,	
2017-06-26 21:29:05,765 Epoch[43] Batch [1450]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090138,	
2017-06-26 21:29:10,606 Epoch[43] Batch [1460]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.090137,	
2017-06-26 21:29:15,633 Epoch[43] Batch [1470]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.090102,	
2017-06-26 21:29:20,725 Epoch[43] Batch [1480]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.090169,	
2017-06-26 21:29:23,695 Epoch[43] Train-FCNLogLoss=0.090134
2017-06-26 21:29:23,695 Epoch[43] Time cost=775.703
2017-06-26 21:29:24,343 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0044.params"
2017-06-26 21:29:26,517 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0044.states"
2017-06-26 21:29:32,329 Epoch[44] Batch [10]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.091257,	
2017-06-26 21:29:37,599 Epoch[44] Batch [20]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.092125,	
2017-06-26 21:29:42,911 Epoch[44] Batch [30]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090436,	
2017-06-26 21:29:48,099 Epoch[44] Batch [40]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088423,	
2017-06-26 21:29:53,190 Epoch[44] Batch [50]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.086576,	
2017-06-26 21:29:58,172 Epoch[44] Batch [60]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.087009,	
2017-06-26 21:30:03,059 Epoch[44] Batch [70]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088127,	
2017-06-26 21:30:07,809 Epoch[44] Batch [80]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.088739,	
2017-06-26 21:30:12,932 Epoch[44] Batch [90]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.088344,	
2017-06-26 21:30:17,946 Epoch[44] Batch [100]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.088461,	
2017-06-26 21:30:23,054 Epoch[44] Batch [110]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088303,	
2017-06-26 21:30:28,429 Epoch[44] Batch [120]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088222,	
2017-06-26 21:30:33,741 Epoch[44] Batch [130]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088705,	
2017-06-26 21:30:39,211 Epoch[44] Batch [140]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088786,	
2017-06-26 21:30:44,611 Epoch[44] Batch [150]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088712,	
2017-06-26 21:30:49,740 Epoch[44] Batch [160]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088356,	
2017-06-26 21:30:54,895 Epoch[44] Batch [170]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.088243,	
2017-06-26 21:31:00,151 Epoch[44] Batch [180]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088657,	
2017-06-26 21:31:05,255 Epoch[44] Batch [190]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088840,	
2017-06-26 21:31:10,541 Epoch[44] Batch [200]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088997,	
2017-06-26 21:31:15,880 Epoch[44] Batch [210]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088979,	
2017-06-26 21:31:21,145 Epoch[44] Batch [220]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089030,	
2017-06-26 21:31:26,517 Epoch[44] Batch [230]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088788,	
2017-06-26 21:31:31,863 Epoch[44] Batch [240]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088668,	
2017-06-26 21:31:37,113 Epoch[44] Batch [250]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088903,	
2017-06-26 21:31:41,944 Epoch[44] Batch [260]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088741,	
2017-06-26 21:31:46,996 Epoch[44] Batch [270]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088455,	
2017-06-26 21:31:52,245 Epoch[44] Batch [280]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.088428,	
2017-06-26 21:31:57,215 Epoch[44] Batch [290]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089202,	
2017-06-26 21:32:01,974 Epoch[44] Batch [300]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.089286,	
2017-06-26 21:32:07,000 Epoch[44] Batch [310]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089231,	
2017-06-26 21:32:12,021 Epoch[44] Batch [320]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089377,	
2017-06-26 21:32:16,993 Epoch[44] Batch [330]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089288,	
2017-06-26 21:32:22,039 Epoch[44] Batch [340]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089468,	
2017-06-26 21:32:27,274 Epoch[44] Batch [350]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089673,	
2017-06-26 21:32:32,608 Epoch[44] Batch [360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089645,	
2017-06-26 21:32:37,938 Epoch[44] Batch [370]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089697,	
2017-06-26 21:32:43,083 Epoch[44] Batch [380]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.089793,	
2017-06-26 21:32:48,273 Epoch[44] Batch [390]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089652,	
2017-06-26 21:32:53,240 Epoch[44] Batch [400]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.089640,	
2017-06-26 21:32:58,401 Epoch[44] Batch [410]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.089541,	
2017-06-26 21:33:03,068 Epoch[44] Batch [420]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.089368,	
2017-06-26 21:33:07,896 Epoch[44] Batch [430]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.089499,	
2017-06-26 21:33:12,922 Epoch[44] Batch [440]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089667,	
2017-06-26 21:33:17,805 Epoch[44] Batch [450]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.089478,	
2017-06-26 21:33:22,660 Epoch[44] Batch [460]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.089288,	
2017-06-26 21:33:27,483 Epoch[44] Batch [470]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089273,	
2017-06-26 21:33:32,525 Epoch[44] Batch [480]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.089268,	
2017-06-26 21:33:37,309 Epoch[44] Batch [490]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.089292,	
2017-06-26 21:33:42,643 Epoch[44] Batch [500]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089336,	
2017-06-26 21:33:47,976 Epoch[44] Batch [510]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089338,	
2017-06-26 21:33:53,317 Epoch[44] Batch [520]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089389,	
2017-06-26 21:33:58,621 Epoch[44] Batch [530]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089749,	
2017-06-26 21:34:03,976 Epoch[44] Batch [540]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089664,	
2017-06-26 21:34:09,330 Epoch[44] Batch [550]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089744,	
2017-06-26 21:34:14,628 Epoch[44] Batch [560]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089780,	
2017-06-26 21:34:19,942 Epoch[44] Batch [570]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089763,	
2017-06-26 21:34:25,182 Epoch[44] Batch [580]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089739,	
2017-06-26 21:34:30,529 Epoch[44] Batch [590]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089714,	
2017-06-26 21:34:35,905 Epoch[44] Batch [600]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090024,	
2017-06-26 21:34:41,179 Epoch[44] Batch [610]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090043,	
2017-06-26 21:34:46,364 Epoch[44] Batch [620]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.090034,	
2017-06-26 21:34:51,422 Epoch[44] Batch [630]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089945,	
2017-06-26 21:34:56,047 Epoch[44] Batch [640]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.089836,	
2017-06-26 21:35:01,156 Epoch[44] Batch [650]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089906,	
2017-06-26 21:35:06,484 Epoch[44] Batch [660]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089969,	
2017-06-26 21:35:11,585 Epoch[44] Batch [670]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.089923,	
2017-06-26 21:35:16,365 Epoch[44] Batch [680]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.090049,	
2017-06-26 21:35:21,418 Epoch[44] Batch [690]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089973,	
2017-06-26 21:35:26,788 Epoch[44] Batch [700]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089945,	
2017-06-26 21:35:32,207 Epoch[44] Batch [710]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.090050,	
2017-06-26 21:35:37,542 Epoch[44] Batch [720]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089964,	
2017-06-26 21:35:42,864 Epoch[44] Batch [730]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090061,	
2017-06-26 21:35:48,186 Epoch[44] Batch [740]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.090146,	
2017-06-26 21:35:53,632 Epoch[44] Batch [750]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.090207,	
2017-06-26 21:35:58,897 Epoch[44] Batch [760]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090265,	
2017-06-26 21:36:04,170 Epoch[44] Batch [770]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090188,	
2017-06-26 21:36:09,502 Epoch[44] Batch [780]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090118,	
2017-06-26 21:36:14,700 Epoch[44] Batch [790]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089995,	
2017-06-26 21:36:19,753 Epoch[44] Batch [800]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089927,	
2017-06-26 21:36:24,800 Epoch[44] Batch [810]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089784,	
2017-06-26 21:36:29,884 Epoch[44] Batch [820]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089681,	
2017-06-26 21:36:35,132 Epoch[44] Batch [830]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089643,	
2017-06-26 21:36:40,433 Epoch[44] Batch [840]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089699,	
2017-06-26 21:36:45,507 Epoch[44] Batch [850]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089705,	
2017-06-26 21:36:50,301 Epoch[44] Batch [860]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.089809,	
2017-06-26 21:36:55,350 Epoch[44] Batch [870]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089813,	
2017-06-26 21:37:00,467 Epoch[44] Batch [880]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089816,	
2017-06-26 21:37:05,740 Epoch[44] Batch [890]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089912,	
2017-06-26 21:37:10,796 Epoch[44] Batch [900]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089838,	
2017-06-26 21:37:16,120 Epoch[44] Batch [910]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089856,	
2017-06-26 21:37:21,489 Epoch[44] Batch [920]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089823,	
2017-06-26 21:37:26,802 Epoch[44] Batch [930]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089819,	
2017-06-26 21:37:32,223 Epoch[44] Batch [940]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.089860,	
2017-06-26 21:37:37,504 Epoch[44] Batch [950]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089809,	
2017-06-26 21:37:42,898 Epoch[44] Batch [960]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089721,	
2017-06-26 21:37:47,760 Epoch[44] Batch [970]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089715,	
2017-06-26 21:37:52,906 Epoch[44] Batch [980]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089785,	
2017-06-26 21:37:58,178 Epoch[44] Batch [990]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089867,	
2017-06-26 21:38:03,468 Epoch[44] Batch [1000]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089852,	
2017-06-26 21:38:08,825 Epoch[44] Batch [1010]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089904,	
2017-06-26 21:38:14,180 Epoch[44] Batch [1020]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089935,	
2017-06-26 21:38:19,497 Epoch[44] Batch [1030]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089896,	
2017-06-26 21:38:24,797 Epoch[44] Batch [1040]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089872,	
2017-06-26 21:38:30,121 Epoch[44] Batch [1050]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089798,	
2017-06-26 21:38:35,458 Epoch[44] Batch [1060]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089793,	
2017-06-26 21:38:40,760 Epoch[44] Batch [1070]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089695,	
2017-06-26 21:38:46,086 Epoch[44] Batch [1080]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089713,	
2017-06-26 21:38:51,481 Epoch[44] Batch [1090]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089575,	
2017-06-26 21:38:56,631 Epoch[44] Batch [1100]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089571,	
2017-06-26 21:39:01,955 Epoch[44] Batch [1110]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089655,	
2017-06-26 21:39:07,278 Epoch[44] Batch [1120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089644,	
2017-06-26 21:39:12,681 Epoch[44] Batch [1130]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089634,	
2017-06-26 21:39:17,926 Epoch[44] Batch [1140]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089614,	
2017-06-26 21:39:23,292 Epoch[44] Batch [1150]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089569,	
2017-06-26 21:39:28,502 Epoch[44] Batch [1160]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.089518,	
2017-06-26 21:39:33,615 Epoch[44] Batch [1170]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089565,	
2017-06-26 21:39:38,964 Epoch[44] Batch [1180]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089613,	
2017-06-26 21:39:44,229 Epoch[44] Batch [1190]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089571,	
2017-06-26 21:39:49,577 Epoch[44] Batch [1200]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089543,	
2017-06-26 21:39:54,968 Epoch[44] Batch [1210]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089574,	
2017-06-26 21:40:00,330 Epoch[44] Batch [1220]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089478,	
2017-06-26 21:40:05,736 Epoch[44] Batch [1230]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089519,	
2017-06-26 21:40:11,114 Epoch[44] Batch [1240]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089612,	
2017-06-26 21:40:16,244 Epoch[44] Batch [1250]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.089643,	
2017-06-26 21:40:21,265 Epoch[44] Batch [1260]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089640,	
2017-06-26 21:40:26,161 Epoch[44] Batch [1270]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.089628,	
2017-06-26 21:40:31,403 Epoch[44] Batch [1280]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089650,	
2017-06-26 21:40:36,271 Epoch[44] Batch [1290]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.089585,	
2017-06-26 21:40:41,541 Epoch[44] Batch [1300]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089650,	
2017-06-26 21:40:46,686 Epoch[44] Batch [1310]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089672,	
2017-06-26 21:40:51,841 Epoch[44] Batch [1320]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.089674,	
2017-06-26 21:40:56,933 Epoch[44] Batch [1330]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089684,	
2017-06-26 21:41:01,778 Epoch[44] Batch [1340]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.089663,	
2017-06-26 21:41:07,020 Epoch[44] Batch [1350]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089666,	
2017-06-26 21:41:12,202 Epoch[44] Batch [1360]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089629,	
2017-06-26 21:41:17,406 Epoch[44] Batch [1370]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089666,	
2017-06-26 21:41:22,543 Epoch[44] Batch [1380]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089645,	
2017-06-26 21:41:27,597 Epoch[44] Batch [1390]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089673,	
2017-06-26 21:41:32,913 Epoch[44] Batch [1400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089681,	
2017-06-26 21:41:38,264 Epoch[44] Batch [1410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089700,	
2017-06-26 21:41:43,604 Epoch[44] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089717,	
2017-06-26 21:41:48,953 Epoch[44] Batch [1430]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089733,	
2017-06-26 21:41:54,232 Epoch[44] Batch [1440]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089712,	
2017-06-26 21:41:59,514 Epoch[44] Batch [1450]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089855,	
2017-06-26 21:42:04,871 Epoch[44] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089909,	
2017-06-26 21:42:10,192 Epoch[44] Batch [1470]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089810,	
2017-06-26 21:42:15,388 Epoch[44] Batch [1480]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089788,	
2017-06-26 21:42:18,587 Epoch[44] Train-FCNLogLoss=0.089756
2017-06-26 21:42:18,587 Epoch[44] Time cost=772.069
2017-06-26 21:42:19,318 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0045.params"
2017-06-26 21:42:21,802 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0045.states"
2017-06-26 21:42:27,583 Epoch[45] Batch [10]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.090701,	
2017-06-26 21:42:32,878 Epoch[45] Batch [20]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090667,	
2017-06-26 21:42:38,232 Epoch[45] Batch [30]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091276,	
2017-06-26 21:42:43,339 Epoch[45] Batch [40]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.095089,	
2017-06-26 21:42:48,611 Epoch[45] Batch [50]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.094726,	
2017-06-26 21:42:53,954 Epoch[45] Batch [60]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092989,	
2017-06-26 21:42:59,026 Epoch[45] Batch [70]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.092467,	
2017-06-26 21:43:04,102 Epoch[45] Batch [80]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.092681,	
2017-06-26 21:43:09,158 Epoch[45] Batch [90]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092570,	
2017-06-26 21:43:14,214 Epoch[45] Batch [100]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.091748,	
2017-06-26 21:43:19,337 Epoch[45] Batch [110]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.091938,	
2017-06-26 21:43:24,604 Epoch[45] Batch [120]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.092094,	
2017-06-26 21:43:29,905 Epoch[45] Batch [130]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.091178,	
2017-06-26 21:43:35,218 Epoch[45] Batch [140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090601,	
2017-06-26 21:43:40,504 Epoch[45] Batch [150]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090593,	
2017-06-26 21:43:45,846 Epoch[45] Batch [160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090559,	
2017-06-26 21:43:50,934 Epoch[45] Batch [170]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.090628,	
2017-06-26 21:43:56,044 Epoch[45] Batch [180]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.090295,	
2017-06-26 21:44:01,354 Epoch[45] Batch [190]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090000,	
2017-06-26 21:44:06,670 Epoch[45] Batch [200]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089823,	
2017-06-26 21:44:11,824 Epoch[45] Batch [210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.089890,	
2017-06-26 21:44:17,198 Epoch[45] Batch [220]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089437,	
2017-06-26 21:44:22,452 Epoch[45] Batch [230]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089100,	
2017-06-26 21:44:27,777 Epoch[45] Batch [240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088936,	
2017-06-26 21:44:33,083 Epoch[45] Batch [250]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089078,	
2017-06-26 21:44:38,391 Epoch[45] Batch [260]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089032,	
2017-06-26 21:44:43,685 Epoch[45] Batch [270]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089212,	
2017-06-26 21:44:49,087 Epoch[45] Batch [280]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089249,	
2017-06-26 21:44:54,365 Epoch[45] Batch [290]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089457,	
2017-06-26 21:44:59,518 Epoch[45] Batch [300]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.089313,	
2017-06-26 21:45:04,771 Epoch[45] Batch [310]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089716,	
2017-06-26 21:45:10,128 Epoch[45] Batch [320]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089675,	
2017-06-26 21:45:15,413 Epoch[45] Batch [330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089639,	
2017-06-26 21:45:20,426 Epoch[45] Batch [340]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.089393,	
2017-06-26 21:45:25,481 Epoch[45] Batch [350]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089348,	
2017-06-26 21:45:30,871 Epoch[45] Batch [360]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089381,	
2017-06-26 21:45:36,170 Epoch[45] Batch [370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089307,	
2017-06-26 21:45:41,334 Epoch[45] Batch [380]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.089421,	
2017-06-26 21:45:46,598 Epoch[45] Batch [390]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089366,	
2017-06-26 21:45:51,860 Epoch[45] Batch [400]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089313,	
2017-06-26 21:45:57,027 Epoch[45] Batch [410]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.089309,	
2017-06-26 21:46:02,367 Epoch[45] Batch [420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089347,	
2017-06-26 21:46:07,671 Epoch[45] Batch [430]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089180,	
2017-06-26 21:46:12,703 Epoch[45] Batch [440]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088984,	
2017-06-26 21:46:17,974 Epoch[45] Batch [450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088771,	
2017-06-26 21:46:23,377 Epoch[45] Batch [460]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088962,	
2017-06-26 21:46:28,492 Epoch[45] Batch [470]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088954,	
2017-06-26 21:46:33,744 Epoch[45] Batch [480]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089105,	
2017-06-26 21:46:39,090 Epoch[45] Batch [490]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089207,	
2017-06-26 21:46:44,303 Epoch[45] Batch [500]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.089224,	
2017-06-26 21:46:49,572 Epoch[45] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089150,	
2017-06-26 21:46:54,650 Epoch[45] Batch [520]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089028,	
2017-06-26 21:46:59,987 Epoch[45] Batch [530]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088948,	
2017-06-26 21:47:05,246 Epoch[45] Batch [540]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088998,	
2017-06-26 21:47:10,571 Epoch[45] Batch [550]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088957,	
2017-06-26 21:47:15,956 Epoch[45] Batch [560]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089003,	
2017-06-26 21:47:21,207 Epoch[45] Batch [570]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089109,	
2017-06-26 21:47:26,539 Epoch[45] Batch [580]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089312,	
2017-06-26 21:47:31,688 Epoch[45] Batch [590]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089393,	
2017-06-26 21:47:37,095 Epoch[45] Batch [600]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089586,	
2017-06-26 21:47:42,330 Epoch[45] Batch [610]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089742,	
2017-06-26 21:47:47,527 Epoch[45] Batch [620]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089880,	
2017-06-26 21:47:52,851 Epoch[45] Batch [630]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089913,	
2017-06-26 21:47:58,019 Epoch[45] Batch [640]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.089766,	
2017-06-26 21:48:03,221 Epoch[45] Batch [650]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089900,	
2017-06-26 21:48:08,666 Epoch[45] Batch [660]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.089928,	
2017-06-26 21:48:13,800 Epoch[45] Batch [670]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089994,	
2017-06-26 21:48:19,148 Epoch[45] Batch [680]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090039,	
2017-06-26 21:48:24,312 Epoch[45] Batch [690]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090074,	
2017-06-26 21:48:29,348 Epoch[45] Batch [700]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.090051,	
2017-06-26 21:48:34,351 Epoch[45] Batch [710]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.089977,	
2017-06-26 21:48:39,691 Epoch[45] Batch [720]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090010,	
2017-06-26 21:48:44,561 Epoch[45] Batch [730]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.089862,	
2017-06-26 21:48:49,913 Epoch[45] Batch [740]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089805,	
2017-06-26 21:48:55,386 Epoch[45] Batch [750]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.089679,	
2017-06-26 21:49:00,764 Epoch[45] Batch [760]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089652,	
2017-06-26 21:49:06,053 Epoch[45] Batch [770]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089625,	
2017-06-26 21:49:11,434 Epoch[45] Batch [780]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089493,	
2017-06-26 21:49:16,510 Epoch[45] Batch [790]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089599,	
2017-06-26 21:49:21,607 Epoch[45] Batch [800]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.089520,	
2017-06-26 21:49:26,912 Epoch[45] Batch [810]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089490,	
2017-06-26 21:49:32,242 Epoch[45] Batch [820]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089487,	
2017-06-26 21:49:37,389 Epoch[45] Batch [830]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.089512,	
2017-06-26 21:49:42,716 Epoch[45] Batch [840]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089662,	
2017-06-26 21:49:48,017 Epoch[45] Batch [850]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089620,	
2017-06-26 21:49:52,956 Epoch[45] Batch [860]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.089605,	
2017-06-26 21:49:58,159 Epoch[45] Batch [870]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.089492,	
2017-06-26 21:50:03,615 Epoch[45] Batch [880]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089493,	
2017-06-26 21:50:08,872 Epoch[45] Batch [890]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089501,	
2017-06-26 21:50:14,228 Epoch[45] Batch [900]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089536,	
2017-06-26 21:50:19,655 Epoch[45] Batch [910]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089547,	
2017-06-26 21:50:24,991 Epoch[45] Batch [920]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089536,	
2017-06-26 21:50:30,163 Epoch[45] Batch [930]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089448,	
2017-06-26 21:50:35,562 Epoch[45] Batch [940]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089419,	
2017-06-26 21:50:40,820 Epoch[45] Batch [950]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089434,	
2017-06-26 21:50:46,175 Epoch[45] Batch [960]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089425,	
2017-06-26 21:50:51,440 Epoch[45] Batch [970]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089391,	
2017-06-26 21:50:56,791 Epoch[45] Batch [980]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089326,	
2017-06-26 21:51:02,099 Epoch[45] Batch [990]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089299,	
2017-06-26 21:51:07,403 Epoch[45] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089354,	
2017-06-26 21:51:12,408 Epoch[45] Batch [1010]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.089290,	
2017-06-26 21:51:17,737 Epoch[45] Batch [1020]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089383,	
2017-06-26 21:51:22,925 Epoch[45] Batch [1030]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089413,	
2017-06-26 21:51:28,271 Epoch[45] Batch [1040]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089474,	
2017-06-26 21:51:33,554 Epoch[45] Batch [1050]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089466,	
2017-06-26 21:51:38,903 Epoch[45] Batch [1060]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089422,	
2017-06-26 21:51:44,202 Epoch[45] Batch [1070]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089494,	
2017-06-26 21:51:49,575 Epoch[45] Batch [1080]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089445,	
2017-06-26 21:51:54,622 Epoch[45] Batch [1090]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089519,	
2017-06-26 21:51:59,904 Epoch[45] Batch [1100]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089549,	
2017-06-26 21:52:05,260 Epoch[45] Batch [1110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089503,	
2017-06-26 21:52:10,643 Epoch[45] Batch [1120]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089502,	
2017-06-26 21:52:15,834 Epoch[45] Batch [1130]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089551,	
2017-06-26 21:52:20,554 Epoch[45] Batch [1140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.089519,	
2017-06-26 21:52:25,555 Epoch[45] Batch [1150]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.089440,	
2017-06-26 21:52:30,889 Epoch[45] Batch [1160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089430,	
2017-06-26 21:52:36,208 Epoch[45] Batch [1170]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089367,	
2017-06-26 21:52:41,519 Epoch[45] Batch [1180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089282,	
2017-06-26 21:52:46,839 Epoch[45] Batch [1190]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089303,	
2017-06-26 21:52:52,245 Epoch[45] Batch [1200]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089310,	
2017-06-26 21:52:57,490 Epoch[45] Batch [1210]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089260,	
2017-06-26 21:53:02,797 Epoch[45] Batch [1220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089325,	
2017-06-26 21:53:08,063 Epoch[45] Batch [1230]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089291,	
2017-06-26 21:53:13,394 Epoch[45] Batch [1240]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089343,	
2017-06-26 21:53:18,747 Epoch[45] Batch [1250]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089324,	
2017-06-26 21:53:24,088 Epoch[45] Batch [1260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089353,	
2017-06-26 21:53:29,408 Epoch[45] Batch [1270]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089281,	
2017-06-26 21:53:34,811 Epoch[45] Batch [1280]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089228,	
2017-06-26 21:53:40,148 Epoch[45] Batch [1290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089323,	
2017-06-26 21:53:45,439 Epoch[45] Batch [1300]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089297,	
2017-06-26 21:53:50,712 Epoch[45] Batch [1310]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089248,	
2017-06-26 21:53:56,089 Epoch[45] Batch [1320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089447,	
2017-06-26 21:54:01,320 Epoch[45] Batch [1330]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.089433,	
2017-06-26 21:54:06,558 Epoch[45] Batch [1340]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089428,	
2017-06-26 21:54:11,764 Epoch[45] Batch [1350]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.089406,	
2017-06-26 21:54:17,162 Epoch[45] Batch [1360]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089384,	
2017-06-26 21:54:22,502 Epoch[45] Batch [1370]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089426,	
2017-06-26 21:54:27,794 Epoch[45] Batch [1380]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089453,	
2017-06-26 21:54:32,960 Epoch[45] Batch [1390]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.089419,	
2017-06-26 21:54:38,275 Epoch[45] Batch [1400]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089414,	
2017-06-26 21:54:43,513 Epoch[45] Batch [1410]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.089414,	
2017-06-26 21:54:48,847 Epoch[45] Batch [1420]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089444,	
2017-06-26 21:54:54,180 Epoch[45] Batch [1430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089499,	
2017-06-26 21:54:59,095 Epoch[45] Batch [1440]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.089443,	
2017-06-26 21:55:04,372 Epoch[45] Batch [1450]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-26 21:55:09,721 Epoch[45] Batch [1460]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089456,	
2017-06-26 21:55:14,859 Epoch[45] Batch [1470]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089424,	
2017-06-26 21:55:20,080 Epoch[45] Batch [1480]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.089463,	
2017-06-26 21:55:23,250 Epoch[45] Train-FCNLogLoss=0.089466
2017-06-26 21:55:23,250 Epoch[45] Time cost=781.448
2017-06-26 21:55:23,871 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0046.params"
2017-06-26 21:55:26,294 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0046.states"
2017-06-26 21:55:32,321 Epoch[46] Batch [10]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088363,	
2017-06-26 21:55:37,653 Epoch[46] Batch [20]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088621,	
2017-06-26 21:55:42,829 Epoch[46] Batch [30]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.090571,	
2017-06-26 21:55:48,199 Epoch[46] Batch [40]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089997,	
2017-06-26 21:55:53,413 Epoch[46] Batch [50]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.091611,	
2017-06-26 21:55:58,623 Epoch[46] Batch [60]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.091182,	
2017-06-26 21:56:03,960 Epoch[46] Batch [70]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089905,	
2017-06-26 21:56:09,233 Epoch[46] Batch [80]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090014,	
2017-06-26 21:56:14,555 Epoch[46] Batch [90]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089679,	
2017-06-26 21:56:19,886 Epoch[46] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088999,	
2017-06-26 21:56:25,259 Epoch[46] Batch [110]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088068,	
2017-06-26 21:56:30,393 Epoch[46] Batch [120]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088908,	
2017-06-26 21:56:35,698 Epoch[46] Batch [130]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089394,	
2017-06-26 21:56:41,008 Epoch[46] Batch [140]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089402,	
2017-06-26 21:56:46,326 Epoch[46] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089392,	
2017-06-26 21:56:51,673 Epoch[46] Batch [160]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089053,	
2017-06-26 21:56:56,998 Epoch[46] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089243,	
2017-06-26 21:57:02,331 Epoch[46] Batch [180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089249,	
2017-06-26 21:57:07,747 Epoch[46] Batch [190]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090294,	
2017-06-26 21:57:13,205 Epoch[46] Batch [200]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.090147,	
2017-06-26 21:57:18,497 Epoch[46] Batch [210]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089778,	
2017-06-26 21:57:23,827 Epoch[46] Batch [220]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090179,	
2017-06-26 21:57:29,173 Epoch[46] Batch [230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090025,	
2017-06-26 21:57:34,509 Epoch[46] Batch [240]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089924,	
2017-06-26 21:57:39,794 Epoch[46] Batch [250]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089617,	
2017-06-26 21:57:45,128 Epoch[46] Batch [260]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089099,	
2017-06-26 21:57:50,498 Epoch[46] Batch [270]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089049,	
2017-06-26 21:57:55,922 Epoch[46] Batch [280]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.089195,	
2017-06-26 21:58:01,261 Epoch[46] Batch [290]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089381,	
2017-06-26 21:58:06,593 Epoch[46] Batch [300]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089084,	
2017-06-26 21:58:11,953 Epoch[46] Batch [310]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089153,	
2017-06-26 21:58:17,234 Epoch[46] Batch [320]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089258,	
2017-06-26 21:58:22,574 Epoch[46] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089184,	
2017-06-26 21:58:28,052 Epoch[46] Batch [340]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089170,	
2017-06-26 21:58:33,354 Epoch[46] Batch [350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089148,	
2017-06-26 21:58:38,730 Epoch[46] Batch [360]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089439,	
2017-06-26 21:58:44,031 Epoch[46] Batch [370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089189,	
2017-06-26 21:58:48,982 Epoch[46] Batch [380]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.089047,	
2017-06-26 21:58:53,715 Epoch[46] Batch [390]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.088946,	
2017-06-26 21:58:58,936 Epoch[46] Batch [400]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088895,	
2017-06-26 21:59:04,265 Epoch[46] Batch [410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088914,	
2017-06-26 21:59:09,440 Epoch[46] Batch [420]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089006,	
2017-06-26 21:59:14,696 Epoch[46] Batch [430]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089047,	
2017-06-26 21:59:19,982 Epoch[46] Batch [440]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089071,	
2017-06-26 21:59:24,886 Epoch[46] Batch [450]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.089223,	
2017-06-26 21:59:30,190 Epoch[46] Batch [460]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089031,	
2017-06-26 21:59:35,236 Epoch[46] Batch [470]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089181,	
2017-06-26 21:59:40,493 Epoch[46] Batch [480]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089229,	
2017-06-26 21:59:45,665 Epoch[46] Batch [490]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.089412,	
2017-06-26 21:59:50,768 Epoch[46] Batch [500]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.089434,	
2017-06-26 21:59:56,036 Epoch[46] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-26 22:00:01,355 Epoch[46] Batch [520]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089419,	
2017-06-26 22:00:06,628 Epoch[46] Batch [530]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089463,	
2017-06-26 22:00:11,762 Epoch[46] Batch [540]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089779,	
2017-06-26 22:00:16,789 Epoch[46] Batch [550]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089666,	
2017-06-26 22:00:21,672 Epoch[46] Batch [560]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.089664,	
2017-06-26 22:00:26,267 Epoch[46] Batch [570]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.089630,	
2017-06-26 22:00:31,523 Epoch[46] Batch [580]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089672,	
2017-06-26 22:00:36,705 Epoch[46] Batch [590]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089704,	
2017-06-26 22:00:41,551 Epoch[46] Batch [600]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089611,	
2017-06-26 22:00:46,831 Epoch[46] Batch [610]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089530,	
2017-06-26 22:00:51,894 Epoch[46] Batch [620]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089605,	
2017-06-26 22:00:57,109 Epoch[46] Batch [630]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.089632,	
2017-06-26 22:01:02,488 Epoch[46] Batch [640]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089794,	
2017-06-26 22:01:07,885 Epoch[46] Batch [650]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089944,	
2017-06-26 22:01:13,196 Epoch[46] Batch [660]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090009,	
2017-06-26 22:01:18,520 Epoch[46] Batch [670]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090117,	
2017-06-26 22:01:23,916 Epoch[46] Batch [680]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.090102,	
2017-06-26 22:01:29,203 Epoch[46] Batch [690]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.090018,	
2017-06-26 22:01:34,364 Epoch[46] Batch [700]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090027,	
2017-06-26 22:01:39,776 Epoch[46] Batch [710]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090078,	
2017-06-26 22:01:45,057 Epoch[46] Batch [720]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.090151,	
2017-06-26 22:01:50,351 Epoch[46] Batch [730]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090063,	
2017-06-26 22:01:55,704 Epoch[46] Batch [740]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090072,	
2017-06-26 22:02:00,598 Epoch[46] Batch [750]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.090033,	
2017-06-26 22:02:05,607 Epoch[46] Batch [760]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.090040,	
2017-06-26 22:02:10,938 Epoch[46] Batch [770]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089970,	
2017-06-26 22:02:16,233 Epoch[46] Batch [780]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089831,	
2017-06-26 22:02:21,314 Epoch[46] Batch [790]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089978,	
2017-06-26 22:02:26,401 Epoch[46] Batch [800]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.090020,	
2017-06-26 22:02:31,649 Epoch[46] Batch [810]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089974,	
2017-06-26 22:02:36,783 Epoch[46] Batch [820]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.090047,	
2017-06-26 22:02:42,078 Epoch[46] Batch [830]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090079,	
2017-06-26 22:02:47,372 Epoch[46] Batch [840]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090219,	
2017-06-26 22:02:52,724 Epoch[46] Batch [850]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090270,	
2017-06-26 22:02:58,040 Epoch[46] Batch [860]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090229,	
2017-06-26 22:03:03,378 Epoch[46] Batch [870]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090204,	
2017-06-26 22:03:08,682 Epoch[46] Batch [880]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090071,	
2017-06-26 22:03:14,056 Epoch[46] Batch [890]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.090051,	
2017-06-26 22:03:19,366 Epoch[46] Batch [900]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090021,	
2017-06-26 22:03:24,576 Epoch[46] Batch [910]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.090100,	
2017-06-26 22:03:29,808 Epoch[46] Batch [920]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090157,	
2017-06-26 22:03:35,158 Epoch[46] Batch [930]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090095,	
2017-06-26 22:03:40,317 Epoch[46] Batch [940]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.090058,	
2017-06-26 22:03:45,553 Epoch[46] Batch [950]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.090088,	
2017-06-26 22:03:50,885 Epoch[46] Batch [960]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090110,	
2017-06-26 22:03:55,998 Epoch[46] Batch [970]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.090196,	
2017-06-26 22:04:01,241 Epoch[46] Batch [980]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.090234,	
2017-06-26 22:04:06,552 Epoch[46] Batch [990]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090291,	
2017-06-26 22:04:11,517 Epoch[46] Batch [1000]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.090196,	
2017-06-26 22:04:16,671 Epoch[46] Batch [1010]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.090277,	
2017-06-26 22:04:21,771 Epoch[46] Batch [1020]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.090162,	
2017-06-26 22:04:27,084 Epoch[46] Batch [1030]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090150,	
2017-06-26 22:04:32,136 Epoch[46] Batch [1040]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.090144,	
2017-06-26 22:04:36,995 Epoch[46] Batch [1050]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.090150,	
2017-06-26 22:04:42,309 Epoch[46] Batch [1060]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.090136,	
2017-06-26 22:04:47,653 Epoch[46] Batch [1070]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090220,	
2017-06-26 22:04:52,750 Epoch[46] Batch [1080]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.090131,	
2017-06-26 22:04:57,976 Epoch[46] Batch [1090]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.090104,	
2017-06-26 22:05:03,317 Epoch[46] Batch [1100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090080,	
2017-06-26 22:05:08,681 Epoch[46] Batch [1110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090079,	
2017-06-26 22:05:13,971 Epoch[46] Batch [1120]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090143,	
2017-06-26 22:05:19,143 Epoch[46] Batch [1130]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.090162,	
2017-06-26 22:05:24,248 Epoch[46] Batch [1140]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.090128,	
2017-06-26 22:05:29,549 Epoch[46] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090104,	
2017-06-26 22:05:34,962 Epoch[46] Batch [1160]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090133,	
2017-06-26 22:05:39,912 Epoch[46] Batch [1170]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.090026,	
2017-06-26 22:05:45,181 Epoch[46] Batch [1180]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090015,	
2017-06-26 22:05:50,297 Epoch[46] Batch [1190]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.090091,	
2017-06-26 22:05:55,563 Epoch[46] Batch [1200]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.090014,	
2017-06-26 22:06:00,900 Epoch[46] Batch [1210]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090005,	
2017-06-26 22:06:06,253 Epoch[46] Batch [1220]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089995,	
2017-06-26 22:06:11,692 Epoch[46] Batch [1230]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.089940,	
2017-06-26 22:06:17,030 Epoch[46] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089884,	
2017-06-26 22:06:22,149 Epoch[46] Batch [1250]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.089779,	
2017-06-26 22:06:27,282 Epoch[46] Batch [1260]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089805,	
2017-06-26 22:06:32,561 Epoch[46] Batch [1270]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089771,	
2017-06-26 22:06:37,960 Epoch[46] Batch [1280]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089823,	
2017-06-26 22:06:43,295 Epoch[46] Batch [1290]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089915,	
2017-06-26 22:06:48,483 Epoch[46] Batch [1300]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.089914,	
2017-06-26 22:06:53,537 Epoch[46] Batch [1310]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089939,	
2017-06-26 22:06:58,638 Epoch[46] Batch [1320]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.089934,	
2017-06-26 22:07:03,978 Epoch[46] Batch [1330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090030,	
2017-06-26 22:07:09,101 Epoch[46] Batch [1340]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.090007,	
2017-06-26 22:07:14,448 Epoch[46] Batch [1350]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090018,	
2017-06-26 22:07:19,603 Epoch[46] Batch [1360]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.089883,	
2017-06-26 22:07:24,689 Epoch[46] Batch [1370]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089815,	
2017-06-26 22:07:29,872 Epoch[46] Batch [1380]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.089752,	
2017-06-26 22:07:34,862 Epoch[46] Batch [1390]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089724,	
2017-06-26 22:07:40,258 Epoch[46] Batch [1400]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089697,	
2017-06-26 22:07:45,600 Epoch[46] Batch [1410]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089657,	
2017-06-26 22:07:50,943 Epoch[46] Batch [1420]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089650,	
2017-06-26 22:07:56,258 Epoch[46] Batch [1430]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089641,	
2017-06-26 22:08:01,651 Epoch[46] Batch [1440]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089631,	
2017-06-26 22:08:07,036 Epoch[46] Batch [1450]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089671,	
2017-06-26 22:08:12,380 Epoch[46] Batch [1460]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089670,	
2017-06-26 22:08:17,728 Epoch[46] Batch [1470]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089691,	
2017-06-26 22:08:23,095 Epoch[46] Batch [1480]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089700,	
2017-06-26 22:08:26,231 Epoch[46] Train-FCNLogLoss=0.089693
2017-06-26 22:08:26,232 Epoch[46] Time cost=779.937
2017-06-26 22:08:26,854 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0047.params"
2017-06-26 22:08:29,266 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0047.states"
2017-06-26 22:08:35,332 Epoch[47] Batch [10]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.102192,	
2017-06-26 22:08:40,411 Epoch[47] Batch [20]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.094280,	
2017-06-26 22:08:45,708 Epoch[47] Batch [30]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.093639,	
2017-06-26 22:08:50,995 Epoch[47] Batch [40]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.092085,	
2017-06-26 22:08:56,375 Epoch[47] Batch [50]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.092418,	
2017-06-26 22:09:01,680 Epoch[47] Batch [60]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090532,	
2017-06-26 22:09:07,023 Epoch[47] Batch [70]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089282,	
2017-06-26 22:09:12,323 Epoch[47] Batch [80]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089308,	
2017-06-26 22:09:17,445 Epoch[47] Batch [90]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.089965,	
2017-06-26 22:09:22,627 Epoch[47] Batch [100]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088828,	
2017-06-26 22:09:27,671 Epoch[47] Batch [110]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-26 22:09:32,892 Epoch[47] Batch [120]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088426,	
2017-06-26 22:09:37,917 Epoch[47] Batch [130]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.087891,	
2017-06-26 22:09:43,033 Epoch[47] Batch [140]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.087653,	
2017-06-26 22:09:48,165 Epoch[47] Batch [150]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088045,	
2017-06-26 22:09:53,420 Epoch[47] Batch [160]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.087742,	
2017-06-26 22:09:58,529 Epoch[47] Batch [170]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.088238,	
2017-06-26 22:10:03,869 Epoch[47] Batch [180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087834,	
2017-06-26 22:10:09,299 Epoch[47] Batch [190]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088191,	
2017-06-26 22:10:14,556 Epoch[47] Batch [200]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088037,	
2017-06-26 22:10:19,930 Epoch[47] Batch [210]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-26 22:10:25,247 Epoch[47] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088230,	
2017-06-26 22:10:30,601 Epoch[47] Batch [230]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088513,	
2017-06-26 22:10:35,871 Epoch[47] Batch [240]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089243,	
2017-06-26 22:10:41,186 Epoch[47] Batch [250]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089099,	
2017-06-26 22:10:46,429 Epoch[47] Batch [260]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088848,	
2017-06-26 22:10:51,652 Epoch[47] Batch [270]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088509,	
2017-06-26 22:10:57,031 Epoch[47] Batch [280]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088574,	
2017-06-26 22:11:02,249 Epoch[47] Batch [290]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.088101,	
2017-06-26 22:11:07,397 Epoch[47] Batch [300]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088275,	
2017-06-26 22:11:12,678 Epoch[47] Batch [310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-26 22:11:17,967 Epoch[47] Batch [320]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088194,	
2017-06-26 22:11:23,287 Epoch[47] Batch [330]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088279,	
2017-06-26 22:11:28,622 Epoch[47] Batch [340]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088256,	
2017-06-26 22:11:33,929 Epoch[47] Batch [350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088057,	
2017-06-26 22:11:39,322 Epoch[47] Batch [360]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088230,	
2017-06-26 22:11:44,616 Epoch[47] Batch [370]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088221,	
2017-06-26 22:11:49,913 Epoch[47] Batch [380]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088437,	
2017-06-26 22:11:55,274 Epoch[47] Batch [390]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088143,	
2017-06-26 22:12:00,558 Epoch[47] Batch [400]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088194,	
2017-06-26 22:12:05,893 Epoch[47] Batch [410]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088171,	
2017-06-26 22:12:11,269 Epoch[47] Batch [420]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088197,	
2017-06-26 22:12:16,594 Epoch[47] Batch [430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-26 22:12:21,955 Epoch[47] Batch [440]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088568,	
2017-06-26 22:12:26,840 Epoch[47] Batch [450]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088417,	
2017-06-26 22:12:31,610 Epoch[47] Batch [460]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.088682,	
2017-06-26 22:12:36,439 Epoch[47] Batch [470]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-26 22:12:41,622 Epoch[47] Batch [480]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088687,	
2017-06-26 22:12:46,804 Epoch[47] Batch [490]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088803,	
2017-06-26 22:12:52,148 Epoch[47] Batch [500]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-26 22:12:57,251 Epoch[47] Batch [510]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088745,	
2017-06-26 22:13:02,224 Epoch[47] Batch [520]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088627,	
2017-06-26 22:13:07,101 Epoch[47] Batch [530]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.088504,	
2017-06-26 22:13:12,248 Epoch[47] Batch [540]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088332,	
2017-06-26 22:13:17,494 Epoch[47] Batch [550]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088188,	
2017-06-26 22:13:22,801 Epoch[47] Batch [560]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088514,	
2017-06-26 22:13:28,186 Epoch[47] Batch [570]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088554,	
2017-06-26 22:13:33,443 Epoch[47] Batch [580]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088658,	
2017-06-26 22:13:38,765 Epoch[47] Batch [590]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088749,	
2017-06-26 22:13:44,030 Epoch[47] Batch [600]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088720,	
2017-06-26 22:13:49,392 Epoch[47] Batch [610]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088831,	
2017-06-26 22:13:54,700 Epoch[47] Batch [620]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088764,	
2017-06-26 22:13:59,938 Epoch[47] Batch [630]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088726,	
2017-06-26 22:14:05,284 Epoch[47] Batch [640]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088785,	
2017-06-26 22:14:10,419 Epoch[47] Batch [650]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.088744,	
2017-06-26 22:14:15,661 Epoch[47] Batch [660]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088939,	
2017-06-26 22:14:20,849 Epoch[47] Batch [670]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088937,	
2017-06-26 22:14:26,127 Epoch[47] Batch [680]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088976,	
2017-06-26 22:14:31,191 Epoch[47] Batch [690]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.088875,	
2017-06-26 22:14:36,520 Epoch[47] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-26 22:14:41,637 Epoch[47] Batch [710]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088685,	
2017-06-26 22:14:46,742 Epoch[47] Batch [720]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088621,	
2017-06-26 22:14:51,856 Epoch[47] Batch [730]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-26 22:14:57,142 Epoch[47] Batch [740]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088653,	
2017-06-26 22:15:02,708 Epoch[47] Batch [750]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088666,	
2017-06-26 22:15:07,944 Epoch[47] Batch [760]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-26 22:15:12,841 Epoch[47] Batch [770]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088742,	
2017-06-26 22:15:17,818 Epoch[47] Batch [780]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088758,	
2017-06-26 22:15:23,183 Epoch[47] Batch [790]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088844,	
2017-06-26 22:15:27,887 Epoch[47] Batch [800]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.088911,	
2017-06-26 22:15:32,744 Epoch[47] Batch [810]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088868,	
2017-06-26 22:15:37,600 Epoch[47] Batch [820]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.088962,	
2017-06-26 22:15:42,684 Epoch[47] Batch [830]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.089130,	
2017-06-26 22:15:48,003 Epoch[47] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089101,	
2017-06-26 22:15:53,090 Epoch[47] Batch [850]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089120,	
2017-06-26 22:15:58,515 Epoch[47] Batch [860]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089257,	
2017-06-26 22:16:03,849 Epoch[47] Batch [870]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089247,	
2017-06-26 22:16:09,118 Epoch[47] Batch [880]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089152,	
2017-06-26 22:16:14,523 Epoch[47] Batch [890]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089186,	
2017-06-26 22:16:19,870 Epoch[47] Batch [900]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089225,	
2017-06-26 22:16:25,209 Epoch[47] Batch [910]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089271,	
2017-06-26 22:16:30,538 Epoch[47] Batch [920]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089336,	
2017-06-26 22:16:36,005 Epoch[47] Batch [930]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.089327,	
2017-06-26 22:16:40,842 Epoch[47] Batch [940]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.089247,	
2017-06-26 22:16:45,859 Epoch[47] Batch [950]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.089301,	
2017-06-26 22:16:51,155 Epoch[47] Batch [960]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089195,	
2017-06-26 22:16:56,573 Epoch[47] Batch [970]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.089272,	
2017-06-26 22:17:01,829 Epoch[47] Batch [980]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089188,	
2017-06-26 22:17:07,219 Epoch[47] Batch [990]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089210,	
2017-06-26 22:17:12,521 Epoch[47] Batch [1000]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089198,	
2017-06-26 22:17:17,857 Epoch[47] Batch [1010]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089251,	
2017-06-26 22:17:23,077 Epoch[47] Batch [1020]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.089384,	
2017-06-26 22:17:28,132 Epoch[47] Batch [1030]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089439,	
2017-06-26 22:17:33,186 Epoch[47] Batch [1040]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-26 22:17:38,403 Epoch[47] Batch [1050]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.089486,	
2017-06-26 22:17:43,756 Epoch[47] Batch [1060]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089436,	
2017-06-26 22:17:49,127 Epoch[47] Batch [1070]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089521,	
2017-06-26 22:17:54,425 Epoch[47] Batch [1080]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089521,	
2017-06-26 22:17:59,416 Epoch[47] Batch [1090]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.089557,	
2017-06-26 22:18:04,478 Epoch[47] Batch [1100]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089539,	
2017-06-26 22:18:09,741 Epoch[47] Batch [1110]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089608,	
2017-06-26 22:18:15,012 Epoch[47] Batch [1120]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089490,	
2017-06-26 22:18:20,409 Epoch[47] Batch [1130]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.089498,	
2017-06-26 22:18:25,656 Epoch[47] Batch [1140]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.089584,	
2017-06-26 22:18:30,866 Epoch[47] Batch [1150]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.089608,	
2017-06-26 22:18:35,933 Epoch[47] Batch [1160]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.089623,	
2017-06-26 22:18:40,804 Epoch[47] Batch [1170]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.089602,	
2017-06-26 22:18:45,939 Epoch[47] Batch [1180]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.089570,	
2017-06-26 22:18:50,866 Epoch[47] Batch [1190]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089544,	
2017-06-26 22:18:55,858 Epoch[47] Batch [1200]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089495,	
2017-06-26 22:19:00,976 Epoch[47] Batch [1210]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.089470,	
2017-06-26 22:19:06,094 Epoch[47] Batch [1220]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.089448,	
2017-06-26 22:19:11,139 Epoch[47] Batch [1230]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.089459,	
2017-06-26 22:19:15,870 Epoch[47] Batch [1240]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.089406,	
2017-06-26 22:19:20,558 Epoch[47] Batch [1250]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.089396,	
2017-06-26 22:19:25,632 Epoch[47] Batch [1260]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.089380,	
2017-06-26 22:19:30,558 Epoch[47] Batch [1270]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.089343,	
2017-06-26 22:19:35,616 Epoch[47] Batch [1280]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.089351,	
2017-06-26 22:19:40,873 Epoch[47] Batch [1290]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.089374,	
2017-06-26 22:19:46,068 Epoch[47] Batch [1300]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.089390,	
2017-06-26 22:19:51,291 Epoch[47] Batch [1310]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.089352,	
2017-06-26 22:19:56,554 Epoch[47] Batch [1320]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.089361,	
2017-06-26 22:20:01,382 Epoch[47] Batch [1330]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.089310,	
2017-06-26 22:20:06,547 Epoch[47] Batch [1340]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.089263,	
2017-06-26 22:20:11,540 Epoch[47] Batch [1350]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.089193,	
2017-06-26 22:20:16,553 Epoch[47] Batch [1360]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.089221,	
2017-06-26 22:20:21,648 Epoch[47] Batch [1370]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.089242,	
2017-06-26 22:20:26,758 Epoch[47] Batch [1380]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.089216,	
2017-06-26 22:20:32,111 Epoch[47] Batch [1390]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089221,	
2017-06-26 22:20:37,435 Epoch[47] Batch [1400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089277,	
2017-06-26 22:20:42,749 Epoch[47] Batch [1410]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089280,	
2017-06-26 22:20:47,994 Epoch[47] Batch [1420]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089247,	
2017-06-26 22:20:52,904 Epoch[47] Batch [1430]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.089237,	
2017-06-26 22:20:58,133 Epoch[47] Batch [1440]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.089245,	
2017-06-26 22:21:03,434 Epoch[47] Batch [1450]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089244,	
2017-06-26 22:21:08,565 Epoch[47] Batch [1460]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.089309,	
2017-06-26 22:21:13,428 Epoch[47] Batch [1470]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.089275,	
2017-06-26 22:21:18,517 Epoch[47] Batch [1480]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.089213,	
2017-06-26 22:21:21,717 Epoch[47] Train-FCNLogLoss=0.089216
2017-06-26 22:21:21,718 Epoch[47] Time cost=772.451
2017-06-26 22:21:22,395 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0048.params"
2017-06-26 22:21:25,168 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0048.states"
2017-06-26 22:21:30,692 Epoch[48] Batch [10]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.086159,	
2017-06-26 22:21:35,892 Epoch[48] Batch [20]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.085692,	
2017-06-26 22:21:41,032 Epoch[48] Batch [30]	Speed: 7.78 samples/sec	Train-FCNLogLoss=0.084861,	
2017-06-26 22:21:46,210 Epoch[48] Batch [40]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.084912,	
2017-06-26 22:21:51,492 Epoch[48] Batch [50]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.086814,	
2017-06-26 22:21:56,824 Epoch[48] Batch [60]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088196,	
2017-06-26 22:22:02,144 Epoch[48] Batch [70]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088996,	
2017-06-26 22:22:07,479 Epoch[48] Batch [80]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088566,	
2017-06-26 22:22:12,792 Epoch[48] Batch [90]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088270,	
2017-06-26 22:22:18,127 Epoch[48] Batch [100]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088811,	
2017-06-26 22:22:23,473 Epoch[48] Batch [110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089239,	
2017-06-26 22:22:28,791 Epoch[48] Batch [120]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088741,	
2017-06-26 22:22:34,107 Epoch[48] Batch [130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-26 22:22:39,471 Epoch[48] Batch [140]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088068,	
2017-06-26 22:22:44,807 Epoch[48] Batch [150]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088077,	
2017-06-26 22:22:50,147 Epoch[48] Batch [160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087680,	
2017-06-26 22:22:55,431 Epoch[48] Batch [170]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087739,	
2017-06-26 22:23:00,763 Epoch[48] Batch [180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087438,	
2017-06-26 22:23:06,110 Epoch[48] Batch [190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087208,	
2017-06-26 22:23:11,442 Epoch[48] Batch [200]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087563,	
2017-06-26 22:23:16,779 Epoch[48] Batch [210]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087377,	
2017-06-26 22:23:22,125 Epoch[48] Batch [220]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-26 22:23:27,449 Epoch[48] Batch [230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087329,	
2017-06-26 22:23:32,833 Epoch[48] Batch [240]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.087608,	
2017-06-26 22:23:38,177 Epoch[48] Batch [250]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087447,	
2017-06-26 22:23:43,551 Epoch[48] Batch [260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087416,	
2017-06-26 22:23:48,902 Epoch[48] Batch [270]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087558,	
2017-06-26 22:23:54,406 Epoch[48] Batch [280]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.087662,	
2017-06-26 22:23:59,723 Epoch[48] Batch [290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087812,	
2017-06-26 22:24:05,118 Epoch[48] Batch [300]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087526,	
2017-06-26 22:24:10,554 Epoch[48] Batch [310]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.087657,	
2017-06-26 22:24:15,880 Epoch[48] Batch [320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087800,	
2017-06-26 22:24:21,167 Epoch[48] Batch [330]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087805,	
2017-06-26 22:24:26,614 Epoch[48] Batch [340]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.087978,	
2017-06-26 22:24:32,073 Epoch[48] Batch [350]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.087880,	
2017-06-26 22:24:37,429 Epoch[48] Batch [360]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087919,	
2017-06-26 22:24:42,729 Epoch[48] Batch [370]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087883,	
2017-06-26 22:24:48,085 Epoch[48] Batch [380]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087870,	
2017-06-26 22:24:53,601 Epoch[48] Batch [390]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.088042,	
2017-06-26 22:24:58,924 Epoch[48] Batch [400]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088239,	
2017-06-26 22:25:04,280 Epoch[48] Batch [410]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088100,	
2017-06-26 22:25:09,723 Epoch[48] Batch [420]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.087891,	
2017-06-26 22:25:15,101 Epoch[48] Batch [430]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087819,	
2017-06-26 22:25:20,382 Epoch[48] Batch [440]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087788,	
2017-06-26 22:25:25,892 Epoch[48] Batch [450]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.087746,	
2017-06-26 22:25:31,241 Epoch[48] Batch [460]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-26 22:25:36,603 Epoch[48] Batch [470]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087827,	
2017-06-26 22:25:41,954 Epoch[48] Batch [480]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088093,	
2017-06-26 22:25:47,324 Epoch[48] Batch [490]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.087962,	
2017-06-26 22:25:52,706 Epoch[48] Batch [500]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.087974,	
2017-06-26 22:25:58,046 Epoch[48] Batch [510]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088091,	
2017-06-26 22:26:03,396 Epoch[48] Batch [520]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088063,	
2017-06-26 22:26:08,368 Epoch[48] Batch [530]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.088225,	
2017-06-26 22:26:13,344 Epoch[48] Batch [540]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.088017,	
2017-06-26 22:26:18,680 Epoch[48] Batch [550]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088243,	
2017-06-26 22:26:23,995 Epoch[48] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088280,	
2017-06-26 22:26:29,336 Epoch[48] Batch [570]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088314,	
2017-06-26 22:26:34,688 Epoch[48] Batch [580]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088168,	
2017-06-26 22:26:39,990 Epoch[48] Batch [590]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088137,	
2017-06-26 22:26:45,464 Epoch[48] Batch [600]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088011,	
2017-06-26 22:26:50,764 Epoch[48] Batch [610]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088133,	
2017-06-26 22:26:56,118 Epoch[48] Batch [620]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087975,	
2017-06-26 22:27:01,466 Epoch[48] Batch [630]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088075,	
2017-06-26 22:27:06,790 Epoch[48] Batch [640]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088071,	
2017-06-26 22:27:12,124 Epoch[48] Batch [650]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088163,	
2017-06-26 22:27:17,485 Epoch[48] Batch [660]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088135,	
2017-06-26 22:27:22,804 Epoch[48] Batch [670]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-26 22:27:28,147 Epoch[48] Batch [680]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088224,	
2017-06-26 22:27:33,485 Epoch[48] Batch [690]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088279,	
2017-06-26 22:27:38,961 Epoch[48] Batch [700]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088384,	
2017-06-26 22:27:44,311 Epoch[48] Batch [710]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-26 22:27:49,628 Epoch[48] Batch [720]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088478,	
2017-06-26 22:27:54,982 Epoch[48] Batch [730]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088522,	
2017-06-26 22:28:00,309 Epoch[48] Batch [740]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088515,	
2017-06-26 22:28:05,644 Epoch[48] Batch [750]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088420,	
2017-06-26 22:28:10,974 Epoch[48] Batch [760]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088430,	
2017-06-26 22:28:16,333 Epoch[48] Batch [770]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088559,	
2017-06-26 22:28:21,673 Epoch[48] Batch [780]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088569,	
2017-06-26 22:28:27,006 Epoch[48] Batch [790]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088720,	
2017-06-26 22:28:32,344 Epoch[48] Batch [800]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-26 22:28:37,693 Epoch[48] Batch [810]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088658,	
2017-06-26 22:28:43,021 Epoch[48] Batch [820]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088554,	
2017-06-26 22:28:48,351 Epoch[48] Batch [830]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088595,	
2017-06-26 22:28:53,670 Epoch[48] Batch [840]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088539,	
2017-06-26 22:28:59,008 Epoch[48] Batch [850]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088597,	
2017-06-26 22:29:04,351 Epoch[48] Batch [860]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088520,	
2017-06-26 22:29:09,660 Epoch[48] Batch [870]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088550,	
2017-06-26 22:29:14,989 Epoch[48] Batch [880]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088504,	
2017-06-26 22:29:20,340 Epoch[48] Batch [890]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088633,	
2017-06-26 22:29:25,646 Epoch[48] Batch [900]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088602,	
2017-06-26 22:29:31,009 Epoch[48] Batch [910]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088546,	
2017-06-26 22:29:36,342 Epoch[48] Batch [920]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088514,	
2017-06-26 22:29:41,659 Epoch[48] Batch [930]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088431,	
2017-06-26 22:29:46,985 Epoch[48] Batch [940]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-26 22:29:52,330 Epoch[48] Batch [950]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088481,	
2017-06-26 22:29:57,643 Epoch[48] Batch [960]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088466,	
2017-06-26 22:30:02,994 Epoch[48] Batch [970]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088436,	
2017-06-26 22:30:08,302 Epoch[48] Batch [980]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088490,	
2017-06-26 22:30:13,642 Epoch[48] Batch [990]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088535,	
2017-06-26 22:30:18,996 Epoch[48] Batch [1000]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088552,	
2017-06-26 22:30:24,337 Epoch[48] Batch [1010]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088539,	
2017-06-26 22:30:29,652 Epoch[48] Batch [1020]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-26 22:30:34,980 Epoch[48] Batch [1030]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088524,	
2017-06-26 22:30:40,320 Epoch[48] Batch [1040]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088590,	
2017-06-26 22:30:45,689 Epoch[48] Batch [1050]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088589,	
2017-06-26 22:30:50,978 Epoch[48] Batch [1060]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088552,	
2017-06-26 22:30:56,318 Epoch[48] Batch [1070]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088405,	
2017-06-26 22:31:01,647 Epoch[48] Batch [1080]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088400,	
2017-06-26 22:31:07,014 Epoch[48] Batch [1090]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088409,	
2017-06-26 22:31:12,335 Epoch[48] Batch [1100]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-26 22:31:17,719 Epoch[48] Batch [1110]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088476,	
2017-06-26 22:31:23,026 Epoch[48] Batch [1120]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088472,	
2017-06-26 22:31:28,349 Epoch[48] Batch [1130]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088485,	
2017-06-26 22:31:33,741 Epoch[48] Batch [1140]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088627,	
2017-06-26 22:31:39,042 Epoch[48] Batch [1150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088673,	
2017-06-26 22:31:44,372 Epoch[48] Batch [1160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088772,	
2017-06-26 22:31:49,714 Epoch[48] Batch [1170]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088773,	
2017-06-26 22:31:55,017 Epoch[48] Batch [1180]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088769,	
2017-06-26 22:32:00,360 Epoch[48] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088798,	
2017-06-26 22:32:05,701 Epoch[48] Batch [1200]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-26 22:32:11,157 Epoch[48] Batch [1210]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.088855,	
2017-06-26 22:32:16,522 Epoch[48] Batch [1220]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088870,	
2017-06-26 22:32:21,852 Epoch[48] Batch [1230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088933,	
2017-06-26 22:32:27,156 Epoch[48] Batch [1240]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088950,	
2017-06-26 22:32:32,597 Epoch[48] Batch [1250]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.088970,	
2017-06-26 22:32:37,874 Epoch[48] Batch [1260]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088951,	
2017-06-26 22:32:43,246 Epoch[48] Batch [1270]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088962,	
2017-06-26 22:32:48,695 Epoch[48] Batch [1280]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.089030,	
2017-06-26 22:32:54,079 Epoch[48] Batch [1290]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089004,	
2017-06-26 22:32:59,491 Epoch[48] Batch [1300]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088996,	
2017-06-26 22:33:04,800 Epoch[48] Batch [1310]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089046,	
2017-06-26 22:33:10,175 Epoch[48] Batch [1320]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089080,	
2017-06-26 22:33:15,534 Epoch[48] Batch [1330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089132,	
2017-06-26 22:33:20,988 Epoch[48] Batch [1340]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089076,	
2017-06-26 22:33:26,351 Epoch[48] Batch [1350]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089053,	
2017-06-26 22:33:31,681 Epoch[48] Batch [1360]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089024,	
2017-06-26 22:33:37,172 Epoch[48] Batch [1370]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.089121,	
2017-06-26 22:33:42,598 Epoch[48] Batch [1380]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089145,	
2017-06-26 22:33:47,910 Epoch[48] Batch [1390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089166,	
2017-06-26 22:33:53,281 Epoch[48] Batch [1400]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089169,	
2017-06-26 22:33:58,675 Epoch[48] Batch [1410]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089117,	
2017-06-26 22:34:04,147 Epoch[48] Batch [1420]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.089115,	
2017-06-26 22:34:09,469 Epoch[48] Batch [1430]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089081,	
2017-06-26 22:34:14,823 Epoch[48] Batch [1440]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089200,	
2017-06-26 22:34:20,159 Epoch[48] Batch [1450]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089223,	
2017-06-26 22:34:25,679 Epoch[48] Batch [1460]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.089195,	
2017-06-26 22:34:30,983 Epoch[48] Batch [1470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089219,	
2017-06-26 22:34:36,336 Epoch[48] Batch [1480]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089273,	
2017-06-26 22:34:39,663 Epoch[48] Train-FCNLogLoss=0.089278
2017-06-26 22:34:39,663 Epoch[48] Time cost=794.494
2017-06-26 22:34:40,319 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0049.params"
2017-06-26 22:34:42,816 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0049.states"
2017-06-26 22:34:48,822 Epoch[49] Batch [10]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.084678,	
2017-06-26 22:34:54,183 Epoch[49] Batch [20]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.086210,	
2017-06-26 22:34:59,500 Epoch[49] Batch [30]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088549,	
2017-06-26 22:35:04,839 Epoch[49] Batch [40]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090491,	
2017-06-26 22:35:10,186 Epoch[49] Batch [50]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.092659,	
2017-06-26 22:35:15,531 Epoch[49] Batch [60]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.093360,	
2017-06-26 22:35:20,900 Epoch[49] Batch [70]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.094128,	
2017-06-26 22:35:26,213 Epoch[49] Batch [80]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.093268,	
2017-06-26 22:35:31,585 Epoch[49] Batch [90]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091892,	
2017-06-26 22:35:36,928 Epoch[49] Batch [100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.092480,	
2017-06-26 22:35:42,283 Epoch[49] Batch [110]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.091403,	
2017-06-26 22:35:47,635 Epoch[49] Batch [120]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090829,	
2017-06-26 22:35:52,996 Epoch[49] Batch [130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.091021,	
2017-06-26 22:35:58,330 Epoch[49] Batch [140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.090411,	
2017-06-26 22:36:03,686 Epoch[49] Batch [150]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090045,	
2017-06-26 22:36:09,042 Epoch[49] Batch [160]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089582,	
2017-06-26 22:36:14,421 Epoch[49] Batch [170]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089499,	
2017-06-26 22:36:19,731 Epoch[49] Batch [180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089590,	
2017-06-26 22:36:25,112 Epoch[49] Batch [190]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089747,	
2017-06-26 22:36:30,499 Epoch[49] Batch [200]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089559,	
2017-06-26 22:36:35,849 Epoch[49] Batch [210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089705,	
2017-06-26 22:36:41,152 Epoch[49] Batch [220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089805,	
2017-06-26 22:36:46,554 Epoch[49] Batch [230]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089887,	
2017-06-26 22:36:51,848 Epoch[49] Batch [240]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089420,	
2017-06-26 22:36:57,221 Epoch[49] Batch [250]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089385,	
2017-06-26 22:37:02,564 Epoch[49] Batch [260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089371,	
2017-06-26 22:37:07,875 Epoch[49] Batch [270]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089286,	
2017-06-26 22:37:13,302 Epoch[49] Batch [280]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089099,	
2017-06-26 22:37:18,599 Epoch[49] Batch [290]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089137,	
2017-06-26 22:37:23,975 Epoch[49] Batch [300]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088956,	
2017-06-26 22:37:29,261 Epoch[49] Batch [310]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089054,	
2017-06-26 22:37:34,601 Epoch[49] Batch [320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088955,	
2017-06-26 22:37:39,941 Epoch[49] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088935,	
2017-06-26 22:37:45,247 Epoch[49] Batch [340]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088733,	
2017-06-26 22:37:50,628 Epoch[49] Batch [350]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088673,	
2017-06-26 22:37:55,961 Epoch[49] Batch [360]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088767,	
2017-06-26 22:38:01,327 Epoch[49] Batch [370]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088762,	
2017-06-26 22:38:06,588 Epoch[49] Batch [380]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088835,	
2017-06-26 22:38:11,934 Epoch[49] Batch [390]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088881,	
2017-06-26 22:38:17,267 Epoch[49] Batch [400]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088805,	
2017-06-26 22:38:22,596 Epoch[49] Batch [410]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088771,	
2017-06-26 22:38:28,010 Epoch[49] Batch [420]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088852,	
2017-06-26 22:38:33,292 Epoch[49] Batch [430]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088978,	
2017-06-26 22:38:38,589 Epoch[49] Batch [440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088873,	
2017-06-26 22:38:43,933 Epoch[49] Batch [450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088885,	
2017-06-26 22:38:49,295 Epoch[49] Batch [460]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088878,	
2017-06-26 22:38:54,603 Epoch[49] Batch [470]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088887,	
2017-06-26 22:38:59,991 Epoch[49] Batch [480]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088894,	
2017-06-26 22:39:05,333 Epoch[49] Batch [490]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088910,	
2017-06-26 22:39:10,646 Epoch[49] Batch [500]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088841,	
2017-06-26 22:39:15,999 Epoch[49] Batch [510]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088934,	
2017-06-26 22:39:21,285 Epoch[49] Batch [520]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088767,	
2017-06-26 22:39:26,001 Epoch[49] Batch [530]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088641,	
2017-06-26 22:39:30,898 Epoch[49] Batch [540]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.088910,	
2017-06-26 22:39:36,167 Epoch[49] Batch [550]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088825,	
2017-06-26 22:39:41,514 Epoch[49] Batch [560]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088951,	
2017-06-26 22:39:46,879 Epoch[49] Batch [570]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089066,	
2017-06-26 22:39:52,189 Epoch[49] Batch [580]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089210,	
2017-06-26 22:39:57,522 Epoch[49] Batch [590]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089121,	
2017-06-26 22:40:02,849 Epoch[49] Batch [600]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089115,	
2017-06-26 22:40:08,181 Epoch[49] Batch [610]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089098,	
2017-06-26 22:40:13,524 Epoch[49] Batch [620]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089034,	
2017-06-26 22:40:18,844 Epoch[49] Batch [630]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088974,	
2017-06-26 22:40:24,209 Epoch[49] Batch [640]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088968,	
2017-06-26 22:40:29,562 Epoch[49] Batch [650]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088957,	
2017-06-26 22:40:34,896 Epoch[49] Batch [660]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088863,	
2017-06-26 22:40:40,224 Epoch[49] Batch [670]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088865,	
2017-06-26 22:40:45,562 Epoch[49] Batch [680]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088859,	
2017-06-26 22:40:51,052 Epoch[49] Batch [690]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.088901,	
2017-06-26 22:40:56,366 Epoch[49] Batch [700]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088800,	
2017-06-26 22:41:01,686 Epoch[49] Batch [710]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088785,	
2017-06-26 22:41:07,004 Epoch[49] Batch [720]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088769,	
2017-06-26 22:41:12,463 Epoch[49] Batch [730]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.088848,	
2017-06-26 22:41:17,851 Epoch[49] Batch [740]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088936,	
2017-06-26 22:41:23,191 Epoch[49] Batch [750]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089076,	
2017-06-26 22:41:28,504 Epoch[49] Batch [760]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088920,	
2017-06-26 22:41:33,838 Epoch[49] Batch [770]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-26 22:41:39,256 Epoch[49] Batch [780]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.088660,	
2017-06-26 22:41:44,577 Epoch[49] Batch [790]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088689,	
2017-06-26 22:41:49,935 Epoch[49] Batch [800]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088598,	
2017-06-26 22:41:55,297 Epoch[49] Batch [810]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088691,	
2017-06-26 22:42:00,799 Epoch[49] Batch [820]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.088883,	
2017-06-26 22:42:06,144 Epoch[49] Batch [830]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088877,	
2017-06-26 22:42:11,558 Epoch[49] Batch [840]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088982,	
2017-06-26 22:42:16,911 Epoch[49] Batch [850]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088931,	
2017-06-26 22:42:22,281 Epoch[49] Batch [860]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088887,	
2017-06-26 22:42:27,694 Epoch[49] Batch [870]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088801,	
2017-06-26 22:42:33,195 Epoch[49] Batch [880]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.088859,	
2017-06-26 22:42:38,489 Epoch[49] Batch [890]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089000,	
2017-06-26 22:42:43,825 Epoch[49] Batch [900]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089095,	
2017-06-26 22:42:49,300 Epoch[49] Batch [910]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.089032,	
2017-06-26 22:42:54,617 Epoch[49] Batch [920]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088943,	
2017-06-26 22:42:59,963 Epoch[49] Batch [930]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088923,	
2017-06-26 22:43:05,383 Epoch[49] Batch [940]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.088944,	
2017-06-26 22:43:10,706 Epoch[49] Batch [950]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088871,	
2017-06-26 22:43:16,249 Epoch[49] Batch [960]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088993,	
2017-06-26 22:43:21,616 Epoch[49] Batch [970]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089019,	
2017-06-26 22:43:26,886 Epoch[49] Batch [980]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089060,	
2017-06-26 22:43:32,236 Epoch[49] Batch [990]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089166,	
2017-06-26 22:43:37,598 Epoch[49] Batch [1000]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089130,	
2017-06-26 22:43:43,078 Epoch[49] Batch [1010]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089188,	
2017-06-26 22:43:48,404 Epoch[49] Batch [1020]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089105,	
2017-06-26 22:43:53,726 Epoch[49] Batch [1030]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089144,	
2017-06-26 22:43:59,098 Epoch[49] Batch [1040]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089080,	
2017-06-26 22:44:04,375 Epoch[49] Batch [1050]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089141,	
2017-06-26 22:44:09,733 Epoch[49] Batch [1060]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089126,	
2017-06-26 22:44:15,095 Epoch[49] Batch [1070]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089187,	
2017-06-26 22:44:20,522 Epoch[49] Batch [1080]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.089187,	
2017-06-26 22:44:25,828 Epoch[49] Batch [1090]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089209,	
2017-06-26 22:44:31,158 Epoch[49] Batch [1100]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089258,	
2017-06-26 22:44:36,507 Epoch[49] Batch [1110]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089225,	
2017-06-26 22:44:41,839 Epoch[49] Batch [1120]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089266,	
2017-06-26 22:44:47,175 Epoch[49] Batch [1130]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089318,	
2017-06-26 22:44:52,543 Epoch[49] Batch [1140]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089337,	
2017-06-26 22:44:57,892 Epoch[49] Batch [1150]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089345,	
2017-06-26 22:45:03,232 Epoch[49] Batch [1160]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089338,	
2017-06-26 22:45:08,578 Epoch[49] Batch [1170]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089279,	
2017-06-26 22:45:13,869 Epoch[49] Batch [1180]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.089268,	
2017-06-26 22:45:19,217 Epoch[49] Batch [1190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089242,	
2017-06-26 22:45:24,601 Epoch[49] Batch [1200]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089215,	
2017-06-26 22:45:29,903 Epoch[49] Batch [1210]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089226,	
2017-06-26 22:45:35,210 Epoch[49] Batch [1220]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089222,	
2017-06-26 22:45:40,560 Epoch[49] Batch [1230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089201,	
2017-06-26 22:45:45,884 Epoch[49] Batch [1240]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089196,	
2017-06-26 22:45:51,226 Epoch[49] Batch [1250]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089234,	
2017-06-26 22:45:56,549 Epoch[49] Batch [1260]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089254,	
2017-06-26 22:46:01,904 Epoch[49] Batch [1270]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089248,	
2017-06-26 22:46:07,267 Epoch[49] Batch [1280]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089217,	
2017-06-26 22:46:12,585 Epoch[49] Batch [1290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089218,	
2017-06-26 22:46:17,940 Epoch[49] Batch [1300]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089203,	
2017-06-26 22:46:23,249 Epoch[49] Batch [1310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089277,	
2017-06-26 22:46:28,571 Epoch[49] Batch [1320]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089232,	
2017-06-26 22:46:33,920 Epoch[49] Batch [1330]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089292,	
2017-06-26 22:46:39,281 Epoch[49] Batch [1340]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089319,	
2017-06-26 22:46:44,585 Epoch[49] Batch [1350]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089398,	
2017-06-26 22:46:49,936 Epoch[49] Batch [1360]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089402,	
2017-06-26 22:46:55,258 Epoch[49] Batch [1370]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089393,	
2017-06-26 22:47:00,603 Epoch[49] Batch [1380]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089393,	
2017-06-26 22:47:05,913 Epoch[49] Batch [1390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089384,	
2017-06-26 22:47:11,274 Epoch[49] Batch [1400]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089418,	
2017-06-26 22:47:16,633 Epoch[49] Batch [1410]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089460,	
2017-06-26 22:47:21,930 Epoch[49] Batch [1420]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089501,	
2017-06-26 22:47:27,255 Epoch[49] Batch [1430]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089536,	
2017-06-26 22:47:32,585 Epoch[49] Batch [1440]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.089523,	
2017-06-26 22:47:37,931 Epoch[49] Batch [1450]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.089544,	
2017-06-26 22:47:43,285 Epoch[49] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089521,	
2017-06-26 22:47:48,601 Epoch[49] Batch [1470]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.089541,	
2017-06-26 22:47:53,932 Epoch[49] Batch [1480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.089487,	
2017-06-26 22:47:57,124 Epoch[49] Train-FCNLogLoss=0.089434
2017-06-26 22:47:57,124 Epoch[49] Time cost=794.308
2017-06-26 22:47:57,793 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0050.params"
2017-06-26 22:48:00,341 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0050.states"
2017-06-26 22:48:06,523 Epoch[50] Batch [10]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.094703,	
2017-06-26 22:48:11,885 Epoch[50] Batch [20]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090970,	
2017-06-26 22:48:17,170 Epoch[50] Batch [30]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.089778,	
2017-06-26 22:48:22,503 Epoch[50] Batch [40]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.091588,	
2017-06-26 22:48:27,875 Epoch[50] Batch [50]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.091112,	
2017-06-26 22:48:33,258 Epoch[50] Batch [60]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.089133,	
2017-06-26 22:48:38,547 Epoch[50] Batch [70]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088915,	
2017-06-26 22:48:43,920 Epoch[50] Batch [80]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088380,	
2017-06-26 22:48:49,224 Epoch[50] Batch [90]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087935,	
2017-06-26 22:48:54,602 Epoch[50] Batch [100]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087720,	
2017-06-26 22:48:59,873 Epoch[50] Batch [110]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088104,	
2017-06-26 22:49:05,246 Epoch[50] Batch [120]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087344,	
2017-06-26 22:49:10,615 Epoch[50] Batch [130]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.087398,	
2017-06-26 22:49:15,947 Epoch[50] Batch [140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087299,	
2017-06-26 22:49:21,270 Epoch[50] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087246,	
2017-06-26 22:49:26,594 Epoch[50] Batch [160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087579,	
2017-06-26 22:49:31,986 Epoch[50] Batch [170]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087527,	
2017-06-26 22:49:37,298 Epoch[50] Batch [180]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088119,	
2017-06-26 22:49:42,645 Epoch[50] Batch [190]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088728,	
2017-06-26 22:49:47,967 Epoch[50] Batch [200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088438,	
2017-06-26 22:49:53,292 Epoch[50] Batch [210]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088171,	
2017-06-26 22:49:58,708 Epoch[50] Batch [220]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088298,	
2017-06-26 22:50:04,084 Epoch[50] Batch [230]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088583,	
2017-06-26 22:50:09,491 Epoch[50] Batch [240]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088573,	
2017-06-26 22:50:14,892 Epoch[50] Batch [250]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088819,	
2017-06-26 22:50:20,172 Epoch[50] Batch [260]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088957,	
2017-06-26 22:50:25,563 Epoch[50] Batch [270]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.089109,	
2017-06-26 22:50:30,936 Epoch[50] Batch [280]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088965,	
2017-06-26 22:50:36,311 Epoch[50] Batch [290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089044,	
2017-06-26 22:50:41,639 Epoch[50] Batch [300]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088802,	
2017-06-26 22:50:47,077 Epoch[50] Batch [310]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088788,	
2017-06-26 22:50:52,520 Epoch[50] Batch [320]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.088819,	
2017-06-26 22:50:57,841 Epoch[50] Batch [330]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088734,	
2017-06-26 22:51:03,364 Epoch[50] Batch [340]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088891,	
2017-06-26 22:51:08,641 Epoch[50] Batch [350]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.089049,	
2017-06-26 22:51:14,032 Epoch[50] Batch [360]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088868,	
2017-06-26 22:51:19,546 Epoch[50] Batch [370]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.088737,	
2017-06-26 22:51:24,853 Epoch[50] Batch [380]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-26 22:51:30,169 Epoch[50] Batch [390]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088388,	
2017-06-26 22:51:35,740 Epoch[50] Batch [400]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088322,	
2017-06-26 22:51:41,134 Epoch[50] Batch [410]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088209,	
2017-06-26 22:51:46,577 Epoch[50] Batch [420]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.088164,	
2017-06-26 22:51:51,917 Epoch[50] Batch [430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088182,	
2017-06-26 22:51:57,415 Epoch[50] Batch [440]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.088366,	
2017-06-26 22:52:02,758 Epoch[50] Batch [450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088218,	
2017-06-26 22:52:08,099 Epoch[50] Batch [460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088325,	
2017-06-26 22:52:13,503 Epoch[50] Batch [470]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088338,	
2017-06-26 22:52:18,808 Epoch[50] Batch [480]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088311,	
2017-06-26 22:52:24,214 Epoch[50] Batch [490]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088185,	
2017-06-26 22:52:29,634 Epoch[50] Batch [500]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.088325,	
2017-06-26 22:52:35,071 Epoch[50] Batch [510]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088255,	
2017-06-26 22:52:40,374 Epoch[50] Batch [520]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088335,	
2017-06-26 22:52:45,066 Epoch[50] Batch [530]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-26 22:52:49,940 Epoch[50] Batch [540]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.088474,	
2017-06-26 22:52:55,262 Epoch[50] Batch [550]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088601,	
2017-06-26 22:53:00,615 Epoch[50] Batch [560]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088607,	
2017-06-26 22:53:05,985 Epoch[50] Batch [570]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088478,	
2017-06-26 22:53:11,315 Epoch[50] Batch [580]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088456,	
2017-06-26 22:53:16,714 Epoch[50] Batch [590]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088579,	
2017-06-26 22:53:22,026 Epoch[50] Batch [600]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088448,	
2017-06-26 22:53:27,507 Epoch[50] Batch [610]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088370,	
2017-06-26 22:53:32,913 Epoch[50] Batch [620]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088342,	
2017-06-26 22:53:38,224 Epoch[50] Batch [630]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088436,	
2017-06-26 22:53:43,560 Epoch[50] Batch [640]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088525,	
2017-06-26 22:53:48,982 Epoch[50] Batch [650]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.088512,	
2017-06-26 22:53:54,343 Epoch[50] Batch [660]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088606,	
2017-06-26 22:53:59,721 Epoch[50] Batch [670]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088590,	
2017-06-26 22:54:05,055 Epoch[50] Batch [680]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088433,	
2017-06-26 22:54:10,368 Epoch[50] Batch [690]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088285,	
2017-06-26 22:54:15,692 Epoch[50] Batch [700]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088260,	
2017-06-26 22:54:21,062 Epoch[50] Batch [710]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088230,	
2017-06-26 22:54:26,413 Epoch[50] Batch [720]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088177,	
2017-06-26 22:54:31,905 Epoch[50] Batch [730]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.088192,	
2017-06-26 22:54:37,226 Epoch[50] Batch [740]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088167,	
2017-06-26 22:54:42,585 Epoch[50] Batch [750]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088133,	
2017-06-26 22:54:47,869 Epoch[50] Batch [760]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088144,	
2017-06-26 22:54:53,232 Epoch[50] Batch [770]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087936,	
2017-06-26 22:54:58,615 Epoch[50] Batch [780]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.087965,	
2017-06-26 22:55:03,899 Epoch[50] Batch [790]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.087849,	
2017-06-26 22:55:09,261 Epoch[50] Batch [800]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087760,	
2017-06-26 22:55:14,697 Epoch[50] Batch [810]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.087847,	
2017-06-26 22:55:20,002 Epoch[50] Batch [820]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087832,	
2017-06-26 22:55:25,351 Epoch[50] Batch [830]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087855,	
2017-06-26 22:55:30,660 Epoch[50] Batch [840]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087781,	
2017-06-26 22:55:35,993 Epoch[50] Batch [850]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087821,	
2017-06-26 22:55:41,495 Epoch[50] Batch [860]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.087890,	
2017-06-26 22:55:46,823 Epoch[50] Batch [870]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087870,	
2017-06-26 22:55:52,130 Epoch[50] Batch [880]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.087858,	
2017-06-26 22:55:57,473 Epoch[50] Batch [890]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087927,	
2017-06-26 22:56:02,795 Epoch[50] Batch [900]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087923,	
2017-06-26 22:56:08,127 Epoch[50] Batch [910]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087905,	
2017-06-26 22:56:13,490 Epoch[50] Batch [920]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087951,	
2017-06-26 22:56:18,814 Epoch[50] Batch [930]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087937,	
2017-06-26 22:56:24,181 Epoch[50] Batch [940]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088100,	
2017-06-26 22:56:29,458 Epoch[50] Batch [950]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088235,	
2017-06-26 22:56:34,842 Epoch[50] Batch [960]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088174,	
2017-06-26 22:56:40,156 Epoch[50] Batch [970]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088265,	
2017-06-26 22:56:45,482 Epoch[50] Batch [980]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088275,	
2017-06-26 22:56:50,836 Epoch[50] Batch [990]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088230,	
2017-06-26 22:56:56,163 Epoch[50] Batch [1000]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088212,	
2017-06-26 22:57:01,510 Epoch[50] Batch [1010]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088387,	
2017-06-26 22:57:06,844 Epoch[50] Batch [1020]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088342,	
2017-06-26 22:57:12,205 Epoch[50] Batch [1030]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088371,	
2017-06-26 22:57:17,500 Epoch[50] Batch [1040]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088399,	
2017-06-26 22:57:22,853 Epoch[50] Batch [1050]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088353,	
2017-06-26 22:57:28,149 Epoch[50] Batch [1060]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-26 22:57:33,518 Epoch[50] Batch [1070]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088492,	
2017-06-26 22:57:38,836 Epoch[50] Batch [1080]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088462,	
2017-06-26 22:57:44,185 Epoch[50] Batch [1090]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088396,	
2017-06-26 22:57:49,528 Epoch[50] Batch [1100]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088435,	
2017-06-26 22:57:54,830 Epoch[50] Batch [1110]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088402,	
2017-06-26 22:58:00,211 Epoch[50] Batch [1120]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088467,	
2017-06-26 22:58:05,528 Epoch[50] Batch [1130]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088467,	
2017-06-26 22:58:10,890 Epoch[50] Batch [1140]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088454,	
2017-06-26 22:58:16,216 Epoch[50] Batch [1150]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088509,	
2017-06-26 22:58:21,529 Epoch[50] Batch [1160]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088523,	
2017-06-26 22:58:26,875 Epoch[50] Batch [1170]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088539,	
2017-06-26 22:58:32,209 Epoch[50] Batch [1180]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088632,	
2017-06-26 22:58:37,550 Epoch[50] Batch [1190]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088681,	
2017-06-26 22:58:42,904 Epoch[50] Batch [1200]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088745,	
2017-06-26 22:58:48,452 Epoch[50] Batch [1210]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.088790,	
2017-06-26 22:58:53,742 Epoch[50] Batch [1220]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088758,	
2017-06-26 22:58:59,093 Epoch[50] Batch [1230]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-26 22:59:04,437 Epoch[50] Batch [1240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088749,	
2017-06-26 22:59:09,751 Epoch[50] Batch [1250]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088750,	
2017-06-26 22:59:15,293 Epoch[50] Batch [1260]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088735,	
2017-06-26 22:59:20,677 Epoch[50] Batch [1270]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088756,	
2017-06-26 22:59:26,014 Epoch[50] Batch [1280]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088744,	
2017-06-26 22:59:31,303 Epoch[50] Batch [1290]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-26 22:59:36,737 Epoch[50] Batch [1300]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088673,	
2017-06-26 22:59:42,165 Epoch[50] Batch [1310]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-26 22:59:47,468 Epoch[50] Batch [1320]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088655,	
2017-06-26 22:59:52,839 Epoch[50] Batch [1330]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088626,	
2017-06-26 22:59:58,256 Epoch[50] Batch [1340]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088616,	
2017-06-26 23:00:03,716 Epoch[50] Batch [1350]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.088538,	
2017-06-26 23:00:09,120 Epoch[50] Batch [1360]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088541,	
2017-06-26 23:00:14,502 Epoch[50] Batch [1370]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088459,	
2017-06-26 23:00:19,938 Epoch[50] Batch [1380]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088493,	
2017-06-26 23:00:25,242 Epoch[50] Batch [1390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088476,	
2017-06-26 23:00:30,730 Epoch[50] Batch [1400]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.088424,	
2017-06-26 23:00:36,153 Epoch[50] Batch [1410]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.088455,	
2017-06-26 23:00:41,556 Epoch[50] Batch [1420]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088515,	
2017-06-26 23:00:46,892 Epoch[50] Batch [1430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088540,	
2017-06-26 23:00:52,234 Epoch[50] Batch [1440]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088512,	
2017-06-26 23:00:57,611 Epoch[50] Batch [1450]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088511,	
2017-06-26 23:01:03,151 Epoch[50] Batch [1460]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088513,	
2017-06-26 23:01:08,520 Epoch[50] Batch [1470]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088550,	
2017-06-26 23:01:13,851 Epoch[50] Batch [1480]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088543,	
2017-06-26 23:01:17,123 Epoch[50] Train-FCNLogLoss=0.088545
2017-06-26 23:01:17,123 Epoch[50] Time cost=796.781
2017-06-26 23:01:17,823 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0051.params"
2017-06-26 23:01:20,690 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0051.states"
2017-06-26 23:01:26,779 Epoch[51] Batch [10]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.104951,	
2017-06-26 23:01:32,117 Epoch[51] Batch [20]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.096696,	
2017-06-26 23:01:37,470 Epoch[51] Batch [30]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.092723,	
2017-06-26 23:01:42,783 Epoch[51] Batch [40]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.092445,	
2017-06-26 23:01:48,128 Epoch[51] Batch [50]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.093009,	
2017-06-26 23:01:53,455 Epoch[51] Batch [60]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.090975,	
2017-06-26 23:01:58,799 Epoch[51] Batch [70]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-26 23:02:04,279 Epoch[51] Batch [80]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089438,	
2017-06-26 23:02:09,651 Epoch[51] Batch [90]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089177,	
2017-06-26 23:02:15,028 Epoch[51] Batch [100]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089126,	
2017-06-26 23:02:20,508 Epoch[51] Batch [110]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089793,	
2017-06-26 23:02:25,868 Epoch[51] Batch [120]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.089487,	
2017-06-26 23:02:31,230 Epoch[51] Batch [130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088852,	
2017-06-26 23:02:36,557 Epoch[51] Batch [140]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088255,	
2017-06-26 23:02:41,878 Epoch[51] Batch [150]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087973,	
2017-06-26 23:02:47,247 Epoch[51] Batch [160]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088156,	
2017-06-26 23:02:52,613 Epoch[51] Batch [170]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088640,	
2017-06-26 23:02:57,957 Epoch[51] Batch [180]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-26 23:03:03,408 Epoch[51] Batch [190]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.088678,	
2017-06-26 23:03:08,726 Epoch[51] Batch [200]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088812,	
2017-06-26 23:03:14,074 Epoch[51] Batch [210]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088991,	
2017-06-26 23:03:19,426 Epoch[51] Batch [220]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089138,	
2017-06-26 23:03:24,800 Epoch[51] Batch [230]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.089464,	
2017-06-26 23:03:30,247 Epoch[51] Batch [240]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.089122,	
2017-06-26 23:03:35,555 Epoch[51] Batch [250]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.089474,	
2017-06-26 23:03:40,899 Epoch[51] Batch [260]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.089229,	
2017-06-26 23:03:46,266 Epoch[51] Batch [270]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.089103,	
2017-06-26 23:03:51,565 Epoch[51] Batch [280]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088897,	
2017-06-26 23:03:57,033 Epoch[51] Batch [290]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.088724,	
2017-06-26 23:04:02,430 Epoch[51] Batch [300]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088965,	
2017-06-26 23:04:07,734 Epoch[51] Batch [310]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088898,	
2017-06-26 23:04:13,061 Epoch[51] Batch [320]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088759,	
2017-06-26 23:04:18,403 Epoch[51] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088743,	
2017-06-26 23:04:23,789 Epoch[51] Batch [340]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088656,	
2017-06-26 23:04:29,086 Epoch[51] Batch [350]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088637,	
2017-06-26 23:04:34,462 Epoch[51] Batch [360]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088576,	
2017-06-26 23:04:39,768 Epoch[51] Batch [370]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088538,	
2017-06-26 23:04:45,149 Epoch[51] Batch [380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088619,	
2017-06-26 23:04:50,459 Epoch[51] Batch [390]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088571,	
2017-06-26 23:04:55,825 Epoch[51] Batch [400]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088584,	
2017-06-26 23:05:01,189 Epoch[51] Batch [410]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088856,	
2017-06-26 23:05:06,496 Epoch[51] Batch [420]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088834,	
2017-06-26 23:05:11,834 Epoch[51] Batch [430]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-26 23:05:17,196 Epoch[51] Batch [440]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088673,	
2017-06-26 23:05:22,520 Epoch[51] Batch [450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088458,	
2017-06-26 23:05:27,873 Epoch[51] Batch [460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088325,	
2017-06-26 23:05:33,234 Epoch[51] Batch [470]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088344,	
2017-06-26 23:05:38,546 Epoch[51] Batch [480]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088351,	
2017-06-26 23:05:43,916 Epoch[51] Batch [490]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088386,	
2017-06-26 23:05:49,248 Epoch[51] Batch [500]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088231,	
2017-06-26 23:05:54,601 Epoch[51] Batch [510]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088242,	
2017-06-26 23:05:59,944 Epoch[51] Batch [520]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088406,	
2017-06-26 23:06:04,660 Epoch[51] Batch [530]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088459,	
2017-06-26 23:06:10,012 Epoch[51] Batch [540]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088706,	
2017-06-26 23:06:15,334 Epoch[51] Batch [550]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088584,	
2017-06-26 23:06:20,667 Epoch[51] Batch [560]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088535,	
2017-06-26 23:06:26,013 Epoch[51] Batch [570]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088483,	
2017-06-26 23:06:31,346 Epoch[51] Batch [580]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088656,	
2017-06-26 23:06:36,694 Epoch[51] Batch [590]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088760,	
2017-06-26 23:06:42,033 Epoch[51] Batch [600]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088719,	
2017-06-26 23:06:47,431 Epoch[51] Batch [610]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088794,	
2017-06-26 23:06:52,786 Epoch[51] Batch [620]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088764,	
2017-06-26 23:06:59,250 Epoch[51] Batch [630]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088725,	
2017-06-26 23:07:05,446 Epoch[51] Batch [640]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088689,	
2017-06-26 23:07:11,662 Epoch[51] Batch [650]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.088763,	
2017-06-26 23:07:18,087 Epoch[51] Batch [660]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088654,	
2017-06-26 23:07:23,346 Epoch[51] Batch [670]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088694,	
2017-06-26 23:07:28,673 Epoch[51] Batch [680]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088501,	
2017-06-26 23:07:34,002 Epoch[51] Batch [690]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088395,	
2017-06-26 23:07:39,367 Epoch[51] Batch [700]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088403,	
2017-06-26 23:07:44,675 Epoch[51] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088432,	
2017-06-26 23:07:50,028 Epoch[51] Batch [720]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088390,	
2017-06-26 23:07:55,351 Epoch[51] Batch [730]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088409,	
2017-06-26 23:08:00,716 Epoch[51] Batch [740]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088464,	
2017-06-26 23:08:06,255 Epoch[51] Batch [750]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088525,	
2017-06-26 23:08:11,631 Epoch[51] Batch [760]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088510,	
2017-06-26 23:08:17,259 Epoch[51] Batch [770]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.088479,	
2017-06-26 23:08:22,815 Epoch[51] Batch [780]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088418,	
2017-06-26 23:08:28,395 Epoch[51] Batch [790]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088399,	
2017-06-26 23:08:34,342 Epoch[51] Batch [800]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.088380,	
2017-06-26 23:08:39,759 Epoch[51] Batch [810]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088526,	
2017-06-26 23:08:45,059 Epoch[51] Batch [820]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088564,	
2017-06-26 23:08:50,492 Epoch[51] Batch [830]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088561,	
2017-06-26 23:08:55,973 Epoch[51] Batch [840]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088629,	
2017-06-26 23:09:01,272 Epoch[51] Batch [850]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088539,	
2017-06-26 23:09:06,849 Epoch[51] Batch [860]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088535,	
2017-06-26 23:09:12,529 Epoch[51] Batch [870]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088484,	
2017-06-26 23:09:17,901 Epoch[51] Batch [880]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088522,	
2017-06-26 23:09:23,202 Epoch[51] Batch [890]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088519,	
2017-06-26 23:09:28,536 Epoch[51] Batch [900]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088616,	
2017-06-26 23:09:34,498 Epoch[51] Batch [910]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088428,	
2017-06-26 23:09:40,172 Epoch[51] Batch [920]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.088366,	
2017-06-26 23:09:45,523 Epoch[51] Batch [930]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088425,	
2017-06-26 23:09:50,830 Epoch[51] Batch [940]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-26 23:09:56,199 Epoch[51] Batch [950]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088501,	
2017-06-26 23:10:01,607 Epoch[51] Batch [960]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088402,	
2017-06-26 23:10:06,916 Epoch[51] Batch [970]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088366,	
2017-06-26 23:10:12,290 Epoch[51] Batch [980]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088444,	
2017-06-26 23:10:17,676 Epoch[51] Batch [990]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088398,	
2017-06-26 23:10:23,019 Epoch[51] Batch [1000]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088362,	
2017-06-26 23:10:28,333 Epoch[51] Batch [1010]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088392,	
2017-06-26 23:10:33,685 Epoch[51] Batch [1020]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088432,	
2017-06-26 23:10:39,028 Epoch[51] Batch [1030]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088488,	
2017-06-26 23:10:44,362 Epoch[51] Batch [1040]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088446,	
2017-06-26 23:10:49,709 Epoch[51] Batch [1050]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088425,	
2017-06-26 23:10:55,044 Epoch[51] Batch [1060]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088449,	
2017-06-26 23:11:00,531 Epoch[51] Batch [1070]	Speed: 7.29 samples/sec	Train-FCNLogLoss=0.088470,	
2017-06-26 23:11:05,922 Epoch[51] Batch [1080]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088410,	
2017-06-26 23:11:11,153 Epoch[51] Batch [1090]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088417,	
2017-06-26 23:11:16,513 Epoch[51] Batch [1100]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088445,	
2017-06-26 23:11:21,854 Epoch[51] Batch [1110]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088339,	
2017-06-26 23:11:27,233 Epoch[51] Batch [1120]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088414,	
2017-06-26 23:11:32,504 Epoch[51] Batch [1130]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088407,	
2017-06-26 23:11:37,837 Epoch[51] Batch [1140]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088414,	
2017-06-26 23:11:43,141 Epoch[51] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-26 23:11:48,477 Epoch[51] Batch [1160]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-26 23:11:53,814 Epoch[51] Batch [1170]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088460,	
2017-06-26 23:11:59,208 Epoch[51] Batch [1180]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.088412,	
2017-06-26 23:12:04,494 Epoch[51] Batch [1190]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088486,	
2017-06-26 23:12:09,862 Epoch[51] Batch [1200]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088527,	
2017-06-26 23:12:15,815 Epoch[51] Batch [1210]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.088557,	
2017-06-26 23:12:21,329 Epoch[51] Batch [1220]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-26 23:12:26,656 Epoch[51] Batch [1230]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088611,	
2017-06-26 23:12:31,989 Epoch[51] Batch [1240]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088610,	
2017-06-26 23:12:37,280 Epoch[51] Batch [1250]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088617,	
2017-06-26 23:12:42,655 Epoch[51] Batch [1260]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088621,	
2017-06-26 23:12:48,016 Epoch[51] Batch [1270]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088604,	
2017-06-26 23:12:53,364 Epoch[51] Batch [1280]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088612,	
2017-06-26 23:12:58,674 Epoch[51] Batch [1290]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088618,	
2017-06-26 23:13:03,973 Epoch[51] Batch [1300]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088624,	
2017-06-26 23:13:09,296 Epoch[51] Batch [1310]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088574,	
2017-06-26 23:13:14,683 Epoch[51] Batch [1320]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088577,	
2017-06-26 23:13:20,009 Epoch[51] Batch [1330]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088582,	
2017-06-26 23:13:25,310 Epoch[51] Batch [1340]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088619,	
2017-06-26 23:13:30,631 Epoch[51] Batch [1350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088636,	
2017-06-26 23:13:35,975 Epoch[51] Batch [1360]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088641,	
2017-06-26 23:13:41,288 Epoch[51] Batch [1370]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088651,	
2017-06-26 23:13:46,659 Epoch[51] Batch [1380]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088694,	
2017-06-26 23:13:51,950 Epoch[51] Batch [1390]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088668,	
2017-06-26 23:13:57,273 Epoch[51] Batch [1400]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088665,	
2017-06-26 23:14:02,623 Epoch[51] Batch [1410]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088608,	
2017-06-26 23:14:07,942 Epoch[51] Batch [1420]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088696,	
2017-06-26 23:14:13,299 Epoch[51] Batch [1430]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088646,	
2017-06-26 23:14:18,596 Epoch[51] Batch [1440]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088706,	
2017-06-26 23:14:23,937 Epoch[51] Batch [1450]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088687,	
2017-06-26 23:14:29,278 Epoch[51] Batch [1460]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088701,	
2017-06-26 23:14:34,649 Epoch[51] Batch [1470]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088727,	
2017-06-26 23:14:40,031 Epoch[51] Batch [1480]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088785,	
2017-06-26 23:14:43,156 Epoch[51] Train-FCNLogLoss=0.088819
2017-06-26 23:14:43,157 Epoch[51] Time cost=802.467
2017-06-26 23:14:43,806 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0052.params"
2017-06-26 23:14:47,133 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0052.states"
2017-06-26 23:14:53,506 Epoch[52] Batch [10]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.086075,	
2017-06-26 23:14:58,804 Epoch[52] Batch [20]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.085833,	
2017-06-26 23:15:04,169 Epoch[52] Batch [30]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.084307,	
2017-06-26 23:15:09,493 Epoch[52] Batch [40]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.085367,	
2017-06-26 23:15:14,805 Epoch[52] Batch [50]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.085298,	
2017-06-26 23:15:20,190 Epoch[52] Batch [60]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.085479,	
2017-06-26 23:15:25,990 Epoch[52] Batch [70]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.088423,	
2017-06-26 23:15:31,914 Epoch[52] Batch [80]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.089064,	
2017-06-26 23:15:38,277 Epoch[52] Batch [90]	Speed: 6.29 samples/sec	Train-FCNLogLoss=0.090092,	
2017-06-26 23:15:43,585 Epoch[52] Batch [100]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.090171,	
2017-06-26 23:15:48,949 Epoch[52] Batch [110]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.090036,	
2017-06-26 23:15:54,364 Epoch[52] Batch [120]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.090362,	
2017-06-26 23:15:59,605 Epoch[52] Batch [130]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.089953,	
2017-06-26 23:16:04,964 Epoch[52] Batch [140]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089672,	
2017-06-26 23:16:10,262 Epoch[52] Batch [150]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.089597,	
2017-06-26 23:16:15,619 Epoch[52] Batch [160]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.089101,	
2017-06-26 23:16:20,946 Epoch[52] Batch [170]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088704,	
2017-06-26 23:16:26,307 Epoch[52] Batch [180]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088598,	
2017-06-26 23:16:31,621 Epoch[52] Batch [190]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088289,	
2017-06-26 23:16:36,985 Epoch[52] Batch [200]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088634,	
2017-06-26 23:16:42,297 Epoch[52] Batch [210]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-26 23:16:47,638 Epoch[52] Batch [220]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088316,	
2017-06-26 23:16:52,941 Epoch[52] Batch [230]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.088393,	
2017-06-26 23:16:58,195 Epoch[52] Batch [240]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088022,	
2017-06-26 23:17:03,628 Epoch[52] Batch [250]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.087971,	
2017-06-26 23:17:08,838 Epoch[52] Batch [260]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.087655,	
2017-06-26 23:17:14,230 Epoch[52] Batch [270]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.087406,	
2017-06-26 23:17:19,551 Epoch[52] Batch [280]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087235,	
2017-06-26 23:17:24,871 Epoch[52] Batch [290]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087174,	
2017-06-26 23:17:30,193 Epoch[52] Batch [300]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087026,	
2017-06-26 23:17:35,556 Epoch[52] Batch [310]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.086906,	
2017-06-26 23:17:40,894 Epoch[52] Batch [320]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.087078,	
2017-06-26 23:17:46,258 Epoch[52] Batch [330]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.086855,	
2017-06-26 23:17:51,570 Epoch[52] Batch [340]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.086865,	
2017-06-26 23:17:56,972 Epoch[52] Batch [350]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.086805,	
2017-06-26 23:18:02,245 Epoch[52] Batch [360]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.087005,	
2017-06-26 23:18:07,576 Epoch[52] Batch [370]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087163,	
2017-06-26 23:18:12,985 Epoch[52] Batch [380]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.087208,	
2017-06-26 23:18:18,550 Epoch[52] Batch [390]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.087209,	
2017-06-26 23:18:23,921 Epoch[52] Batch [400]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.087236,	
2017-06-26 23:18:29,579 Epoch[52] Batch [410]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.087367,	
2017-06-26 23:18:35,156 Epoch[52] Batch [420]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.087134,	
2017-06-26 23:18:41,384 Epoch[52] Batch [430]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087306,	
2017-06-26 23:18:47,382 Epoch[52] Batch [440]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.087298,	
2017-06-26 23:18:53,077 Epoch[52] Batch [450]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.087348,	
2017-06-26 23:18:58,787 Epoch[52] Batch [460]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.087337,	
2017-06-26 23:19:04,732 Epoch[52] Batch [470]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087562,	
2017-06-26 23:19:10,793 Epoch[52] Batch [480]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.087321,	
2017-06-26 23:19:16,342 Epoch[52] Batch [490]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.087521,	
2017-06-26 23:19:22,571 Epoch[52] Batch [500]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087568,	
2017-06-26 23:19:28,303 Epoch[52] Batch [510]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087381,	
2017-06-26 23:19:34,395 Epoch[52] Batch [520]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.087357,	
2017-06-26 23:19:39,671 Epoch[52] Batch [530]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087419,	
2017-06-26 23:19:45,049 Epoch[52] Batch [540]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087381,	
2017-06-26 23:19:50,382 Epoch[52] Batch [550]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087471,	
2017-06-26 23:19:55,693 Epoch[52] Batch [560]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087402,	
2017-06-26 23:20:01,131 Epoch[52] Batch [570]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.087315,	
2017-06-26 23:20:06,394 Epoch[52] Batch [580]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.087412,	
2017-06-26 23:20:11,708 Epoch[52] Batch [590]	Speed: 7.53 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-26 23:20:17,066 Epoch[52] Batch [600]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087643,	
2017-06-26 23:20:22,411 Epoch[52] Batch [610]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087559,	
2017-06-26 23:20:27,942 Epoch[52] Batch [620]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.087621,	
2017-06-26 23:20:33,382 Epoch[52] Batch [630]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.087715,	
2017-06-26 23:20:39,264 Epoch[52] Batch [640]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087804,	
2017-06-26 23:20:45,112 Epoch[52] Batch [650]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.087877,	
2017-06-26 23:20:51,695 Epoch[52] Batch [660]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.087988,	
2017-06-26 23:20:57,667 Epoch[52] Batch [670]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.087961,	
2017-06-26 23:21:03,888 Epoch[52] Batch [680]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.087941,	
2017-06-26 23:21:09,870 Epoch[52] Batch [690]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087945,	
2017-06-26 23:21:16,104 Epoch[52] Batch [700]	Speed: 6.42 samples/sec	Train-FCNLogLoss=0.087991,	
2017-06-26 23:21:22,086 Epoch[52] Batch [710]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.087877,	
2017-06-26 23:21:28,243 Epoch[52] Batch [720]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.087942,	
2017-06-26 23:21:34,352 Epoch[52] Batch [730]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.087957,	
2017-06-26 23:21:40,315 Epoch[52] Batch [740]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087985,	
2017-06-26 23:21:45,807 Epoch[52] Batch [750]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.087996,	
2017-06-26 23:21:51,139 Epoch[52] Batch [760]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088130,	
2017-06-26 23:21:56,479 Epoch[52] Batch [770]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088277,	
2017-06-26 23:22:02,017 Epoch[52] Batch [780]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088298,	
2017-06-26 23:22:08,319 Epoch[52] Batch [790]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088316,	
2017-06-26 23:22:14,616 Epoch[52] Batch [800]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088359,	
2017-06-26 23:22:20,482 Epoch[52] Batch [810]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.088435,	
2017-06-26 23:22:26,545 Epoch[52] Batch [820]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.088396,	
2017-06-26 23:22:32,636 Epoch[52] Batch [830]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.088278,	
2017-06-26 23:22:38,772 Epoch[52] Batch [840]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088272,	
2017-06-26 23:22:45,143 Epoch[52] Batch [850]	Speed: 6.28 samples/sec	Train-FCNLogLoss=0.088205,	
2017-06-26 23:22:50,801 Epoch[52] Batch [860]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088118,	
2017-06-26 23:22:56,517 Epoch[52] Batch [870]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.088139,	
2017-06-26 23:23:02,523 Epoch[52] Batch [880]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.088097,	
2017-06-26 23:23:08,534 Epoch[52] Batch [890]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.088133,	
2017-06-26 23:23:14,118 Epoch[52] Batch [900]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.088005,	
2017-06-26 23:23:19,908 Epoch[52] Batch [910]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087952,	
2017-06-26 23:23:25,491 Epoch[52] Batch [920]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.087884,	
2017-06-26 23:23:30,787 Epoch[52] Batch [930]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.087923,	
2017-06-26 23:23:36,150 Epoch[52] Batch [940]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087912,	
2017-06-26 23:23:41,466 Epoch[52] Batch [950]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087926,	
2017-06-26 23:23:46,796 Epoch[52] Batch [960]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.087962,	
2017-06-26 23:23:52,129 Epoch[52] Batch [970]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.087907,	
2017-06-26 23:23:57,804 Epoch[52] Batch [980]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.087982,	
2017-06-26 23:24:03,399 Epoch[52] Batch [990]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.088083,	
2017-06-26 23:24:09,817 Epoch[52] Batch [1000]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088088,	
2017-06-26 23:24:15,871 Epoch[52] Batch [1010]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.088078,	
2017-06-26 23:24:21,737 Epoch[52] Batch [1020]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.088151,	
2017-06-26 23:24:28,187 Epoch[52] Batch [1030]	Speed: 6.20 samples/sec	Train-FCNLogLoss=0.088102,	
2017-06-26 23:24:33,985 Epoch[52] Batch [1040]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.088136,	
2017-06-26 23:24:39,688 Epoch[52] Batch [1050]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088168,	
2017-06-26 23:24:45,508 Epoch[52] Batch [1060]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088166,	
2017-06-26 23:24:51,231 Epoch[52] Batch [1070]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.088184,	
2017-06-26 23:24:57,075 Epoch[52] Batch [1080]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.088123,	
2017-06-26 23:25:03,340 Epoch[52] Batch [1090]	Speed: 6.39 samples/sec	Train-FCNLogLoss=0.088198,	
2017-06-26 23:25:10,110 Epoch[52] Batch [1100]	Speed: 5.91 samples/sec	Train-FCNLogLoss=0.088110,	
2017-06-26 23:25:16,001 Epoch[52] Batch [1110]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088097,	
2017-06-26 23:25:22,106 Epoch[52] Batch [1120]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.088131,	
2017-06-26 23:25:28,484 Epoch[52] Batch [1130]	Speed: 6.27 samples/sec	Train-FCNLogLoss=0.088141,	
2017-06-26 23:25:34,207 Epoch[52] Batch [1140]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.088143,	
2017-06-26 23:25:39,514 Epoch[52] Batch [1150]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088216,	
2017-06-26 23:25:44,839 Epoch[52] Batch [1160]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-26 23:25:50,217 Epoch[52] Batch [1170]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088225,	
2017-06-26 23:25:55,575 Epoch[52] Batch [1180]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088294,	
2017-06-26 23:26:00,839 Epoch[52] Batch [1190]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088375,	
2017-06-26 23:26:06,208 Epoch[52] Batch [1200]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088401,	
2017-06-26 23:26:12,310 Epoch[52] Batch [1210]	Speed: 6.56 samples/sec	Train-FCNLogLoss=0.088337,	
2017-06-26 23:26:18,099 Epoch[52] Batch [1220]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.088415,	
2017-06-26 23:26:24,712 Epoch[52] Batch [1230]	Speed: 6.05 samples/sec	Train-FCNLogLoss=0.088456,	
2017-06-26 23:26:31,039 Epoch[52] Batch [1240]	Speed: 6.32 samples/sec	Train-FCNLogLoss=0.088458,	
2017-06-26 23:26:37,078 Epoch[52] Batch [1250]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.088420,	
2017-06-26 23:26:43,659 Epoch[52] Batch [1260]	Speed: 6.08 samples/sec	Train-FCNLogLoss=0.088424,	
2017-06-26 23:26:50,120 Epoch[52] Batch [1270]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088365,	
2017-06-26 23:26:56,580 Epoch[52] Batch [1280]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088359,	
2017-06-26 23:27:03,129 Epoch[52] Batch [1290]	Speed: 6.11 samples/sec	Train-FCNLogLoss=0.088365,	
2017-06-26 23:27:09,590 Epoch[52] Batch [1300]	Speed: 6.19 samples/sec	Train-FCNLogLoss=0.088396,	
2017-06-26 23:27:15,784 Epoch[52] Batch [1310]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088345,	
2017-06-26 23:27:21,843 Epoch[52] Batch [1320]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.088367,	
2017-06-26 23:27:28,164 Epoch[52] Batch [1330]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.088394,	
2017-06-26 23:27:34,647 Epoch[52] Batch [1340]	Speed: 6.17 samples/sec	Train-FCNLogLoss=0.088494,	
2017-06-26 23:27:41,428 Epoch[52] Batch [1350]	Speed: 5.90 samples/sec	Train-FCNLogLoss=0.088471,	
2017-06-26 23:27:47,730 Epoch[52] Batch [1360]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088464,	
2017-06-26 23:27:54,005 Epoch[52] Batch [1370]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.088407,	
2017-06-26 23:28:00,230 Epoch[52] Batch [1380]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.088392,	
2017-06-26 23:28:06,006 Epoch[52] Batch [1390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088345,	
2017-06-26 23:28:12,219 Epoch[52] Batch [1400]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.088351,	
2017-06-26 23:28:17,878 Epoch[52] Batch [1410]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088360,	
2017-06-26 23:28:23,377 Epoch[52] Batch [1420]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.088365,	
2017-06-26 23:28:28,714 Epoch[52] Batch [1430]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088358,	
2017-06-26 23:28:34,242 Epoch[52] Batch [1440]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088329,	
2017-06-26 23:28:39,571 Epoch[52] Batch [1450]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088352,	
2017-06-26 23:28:44,928 Epoch[52] Batch [1460]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.088349,	
2017-06-26 23:28:50,338 Epoch[52] Batch [1470]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088343,	
2017-06-26 23:28:55,626 Epoch[52] Batch [1480]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088302,	
2017-06-26 23:28:58,831 Epoch[52] Train-FCNLogLoss=0.088288
2017-06-26 23:28:58,831 Epoch[52] Time cost=851.698
2017-06-26 23:28:59,611 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0053.params"
2017-06-26 23:29:02,912 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8-0053.states"
2017-06-26 23:29:02,925 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate8x8',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate8x8'}

2017-06-26 23:29:15,503 testing 4/500 data 0.7574s net 0.3211s post 0.0086s
2017-06-26 23:29:16,325 testing 8/500 data 0.6236s net 0.3214s post 0.0098s
2017-06-26 23:29:17,479 testing 12/500 data 0.7012s net 0.3105s post 0.0094s
2017-06-26 23:29:18,843 testing 16/500 data 0.7867s net 0.3114s post 0.0088s
2017-06-26 23:29:20,003 testing 20/500 data 0.7988s net 0.3104s post 0.0084s
2017-06-26 23:29:21,316 testing 24/500 data 0.8366s net 0.3047s post 0.0088s
2017-06-26 23:29:22,584 testing 28/500 data 0.8559s net 0.3024s post 0.0085s
2017-06-26 23:29:24,009 testing 32/500 data 0.8786s net 0.3117s post 0.0089s
2017-06-26 23:29:25,142 testing 36/500 data 0.8785s net 0.3044s post 0.0089s
2017-06-26 23:29:26,469 testing 40/500 data 0.8940s net 0.3026s post 0.0087s
2017-06-26 23:29:27,638 testing 44/500 data 0.8916s net 0.3019s post 0.0085s
2017-06-26 23:29:29,012 testing 48/500 data 0.9011s net 0.3066s post 0.0086s
2017-06-26 23:29:30,000 testing 52/500 data 0.8829s net 0.3075s post 0.0085s
2017-06-26 23:29:31,274 testing 56/500 data 0.8911s net 0.3048s post 0.0083s
2017-06-26 23:29:32,551 testing 60/500 data 0.8974s net 0.3034s post 0.0082s
2017-06-26 23:29:33,971 testing 64/500 data 0.9078s net 0.3061s post 0.0083s
2017-06-26 23:29:35,213 testing 68/500 data 0.9067s net 0.3083s post 0.0084s
2017-06-26 23:29:36,513 testing 72/500 data 0.9143s net 0.3051s post 0.0083s
2017-06-26 23:29:37,703 testing 76/500 data 0.9111s net 0.3063s post 0.0083s
2017-06-26 23:29:39,036 testing 80/500 data 0.9188s net 0.3039s post 0.0082s
2017-06-26 23:29:40,477 testing 84/500 data 0.9247s net 0.3082s post 0.0081s
2017-06-26 23:29:41,698 testing 88/500 data 0.9242s net 0.3078s post 0.0082s
2017-06-26 23:29:43,001 testing 92/500 data 0.9292s net 0.3056s post 0.0081s
2017-06-26 23:29:44,404 testing 96/500 data 0.9363s net 0.3049s post 0.0083s
2017-06-26 23:29:45,712 testing 100/500 data 0.9377s net 0.3057s post 0.0084s
2017-06-26 23:29:47,101 testing 104/500 data 0.9415s net 0.3071s post 0.0085s
2017-06-26 23:29:48,332 testing 108/500 data 0.9419s net 0.3059s post 0.0084s
2017-06-26 23:29:49,578 testing 112/500 data 0.9421s net 0.3052s post 0.0085s
2017-06-26 23:29:50,873 testing 116/500 data 0.9426s net 0.3059s post 0.0086s
2017-06-26 23:29:52,200 testing 120/500 data 0.9464s net 0.3046s post 0.0085s
2017-06-26 23:29:53,511 testing 124/500 data 0.9485s net 0.3040s post 0.0087s
2017-06-26 23:29:54,850 testing 128/500 data 0.9495s net 0.3055s post 0.0086s
2017-06-26 23:29:56,081 testing 132/500 data 0.9459s net 0.3080s post 0.0087s
2017-06-26 23:29:57,221 testing 136/500 data 0.9440s net 0.3063s post 0.0087s
2017-06-26 23:29:58,484 testing 140/500 data 0.9456s net 0.3047s post 0.0087s
2017-06-26 23:29:59,835 testing 144/500 data 0.9490s net 0.3039s post 0.0087s
2017-06-26 23:30:01,137 testing 148/500 data 0.9505s net 0.3035s post 0.0087s
2017-06-26 23:30:02,492 testing 152/500 data 0.9545s net 0.3020s post 0.0086s
2017-06-26 23:30:03,936 testing 156/500 data 0.9599s net 0.3012s post 0.0087s
2017-06-26 23:30:04,921 testing 160/500 data 0.9541s net 0.2999s post 0.0087s
2017-06-26 23:30:06,012 testing 164/500 data 0.9494s net 0.3003s post 0.0087s
2017-06-26 23:30:06,865 testing 168/500 data 0.9402s net 0.2999s post 0.0088s
2017-06-26 23:30:08,355 testing 172/500 data 0.9438s net 0.3019s post 0.0088s
2017-06-26 23:30:09,566 testing 176/500 data 0.9412s net 0.3035s post 0.0087s
2017-06-26 23:30:10,596 testing 180/500 data 0.9359s net 0.3039s post 0.0087s
2017-06-26 23:30:11,252 testing 184/500 data 0.9239s net 0.3030s post 0.0087s
2017-06-26 23:30:12,707 testing 188/500 data 0.9280s net 0.3036s post 0.0086s
2017-06-26 23:30:13,952 testing 192/500 data 0.9271s net 0.3046s post 0.0087s
2017-06-26 23:30:15,122 testing 196/500 data 0.9265s net 0.3038s post 0.0086s
2017-06-26 23:30:16,391 testing 200/500 data 0.9274s net 0.3035s post 0.0087s
2017-06-26 23:30:17,648 testing 204/500 data 0.9262s net 0.3050s post 0.0086s
2017-06-26 23:30:18,819 testing 208/500 data 0.9257s net 0.3042s post 0.0086s
2017-06-26 23:30:20,291 testing 212/500 data 0.9287s net 0.3056s post 0.0086s
2017-06-26 23:30:21,505 testing 216/500 data 0.9279s net 0.3059s post 0.0086s
2017-06-26 23:30:22,803 testing 220/500 data 0.9285s net 0.3063s post 0.0085s
2017-06-26 23:30:23,930 testing 224/500 data 0.9270s net 0.3058s post 0.0085s
2017-06-26 23:30:25,166 testing 228/500 data 0.9276s net 0.3051s post 0.0085s
2017-06-26 23:30:26,535 testing 232/500 data 0.9301s net 0.3048s post 0.0086s
2017-06-26 23:30:27,795 testing 236/500 data 0.9301s net 0.3050s post 0.0086s
2017-06-26 23:30:29,050 testing 240/500 data 0.9312s net 0.3041s post 0.0086s
2017-06-26 23:30:30,331 testing 244/500 data 0.9325s net 0.3034s post 0.0086s
2017-06-26 23:30:31,266 testing 248/500 data 0.9273s net 0.3037s post 0.0085s
2017-06-26 23:30:32,580 testing 252/500 data 0.9284s net 0.3038s post 0.0085s
2017-06-26 23:30:33,866 testing 256/500 data 0.9296s net 0.3034s post 0.0085s
2017-06-26 23:30:35,218 testing 260/500 data 0.9307s net 0.3040s post 0.0085s
2017-06-26 23:30:36,452 testing 264/500 data 0.9312s net 0.3033s post 0.0085s
2017-06-26 23:30:37,707 testing 268/500 data 0.9316s net 0.3030s post 0.0085s
2017-06-26 23:30:39,001 testing 272/500 data 0.9321s net 0.3033s post 0.0085s
2017-06-26 23:30:40,267 testing 276/500 data 0.9332s net 0.3025s post 0.0086s
2017-06-26 23:30:41,504 testing 280/500 data 0.9337s net 0.3018s post 0.0086s
2017-06-26 23:30:42,762 testing 284/500 data 0.9341s net 0.3016s post 0.0086s
2017-06-26 23:30:44,045 testing 288/500 data 0.9341s net 0.3022s post 0.0086s
2017-06-26 23:30:45,248 testing 292/500 data 0.9339s net 0.3017s post 0.0086s
2017-06-26 23:30:46,689 testing 296/500 data 0.9356s net 0.3027s post 0.0086s
2017-06-26 23:30:47,874 testing 300/500 data 0.9345s net 0.3030s post 0.0086s
2017-06-26 23:30:49,086 testing 304/500 data 0.9338s net 0.3033s post 0.0086s
2017-06-26 23:30:50,365 testing 308/500 data 0.9350s net 0.3025s post 0.0085s
2017-06-26 23:30:51,627 testing 312/500 data 0.9357s net 0.3020s post 0.0086s
2017-06-26 23:30:53,024 testing 316/500 data 0.9372s net 0.3024s post 0.0086s
2017-06-26 23:30:54,226 testing 320/500 data 0.9365s net 0.3026s post 0.0085s
2017-06-26 23:30:55,378 testing 324/500 data 0.9356s net 0.3022s post 0.0086s
2017-06-26 23:30:56,785 testing 328/500 data 0.9365s net 0.3033s post 0.0085s
2017-06-26 23:30:57,983 testing 332/500 data 0.9358s net 0.3035s post 0.0085s
2017-06-26 23:30:59,219 testing 336/500 data 0.9362s net 0.3029s post 0.0085s
2017-06-26 23:31:00,562 testing 340/500 data 0.9376s net 0.3026s post 0.0086s
2017-06-26 23:31:01,967 testing 344/500 data 0.9396s net 0.3024s post 0.0086s
2017-06-26 23:31:03,296 testing 348/500 data 0.9403s net 0.3027s post 0.0086s
2017-06-26 23:31:04,526 testing 352/500 data 0.9403s net 0.3024s post 0.0086s
2017-06-26 23:31:05,938 testing 356/500 data 0.9413s net 0.3033s post 0.0085s
2017-06-26 23:31:07,146 testing 360/500 data 0.9414s net 0.3026s post 0.0085s
2017-06-26 23:31:08,438 testing 364/500 data 0.9425s net 0.3020s post 0.0085s
2017-06-26 23:31:09,701 testing 368/500 data 0.9428s net 0.3017s post 0.0085s
2017-06-26 23:31:11,096 testing 372/500 data 0.9434s net 0.3026s post 0.0085s
2017-06-26 23:31:12,211 testing 376/500 data 0.9423s net 0.3023s post 0.0086s
2017-06-26 23:31:13,483 testing 380/500 data 0.9427s net 0.3021s post 0.0085s
2017-06-26 23:31:14,869 testing 384/500 data 0.9442s net 0.3020s post 0.0085s
2017-06-26 23:31:16,342 testing 388/500 data 0.9455s net 0.3029s post 0.0085s
2017-06-26 23:31:17,446 testing 392/500 data 0.9432s net 0.3038s post 0.0085s
2017-06-26 23:31:18,591 testing 396/500 data 0.9422s net 0.3037s post 0.0084s
2017-06-26 23:31:19,891 testing 400/500 data 0.9429s net 0.3034s post 0.0084s
2017-06-26 23:31:21,349 testing 404/500 data 0.9442s net 0.3041s post 0.0085s
2017-06-26 23:31:22,433 testing 408/500 data 0.9423s net 0.3043s post 0.0084s
2017-06-26 23:31:23,632 testing 412/500 data 0.9423s net 0.3038s post 0.0084s
2017-06-26 23:31:24,896 testing 416/500 data 0.9423s net 0.3039s post 0.0084s
2017-06-26 23:31:26,106 testing 420/500 data 0.9422s net 0.3036s post 0.0084s
2017-06-26 23:31:27,202 testing 424/500 data 0.9410s net 0.3033s post 0.0084s
2017-06-26 23:31:28,479 testing 428/500 data 0.9415s net 0.3031s post 0.0084s
2017-06-26 23:31:29,885 testing 432/500 data 0.9428s net 0.3032s post 0.0084s
2017-06-26 23:31:31,315 testing 436/500 data 0.9446s net 0.3030s post 0.0083s
2017-06-26 23:31:32,620 testing 440/500 data 0.9451s net 0.3029s post 0.0084s
2017-06-26 23:31:33,958 testing 444/500 data 0.9460s net 0.3028s post 0.0083s
2017-06-26 23:31:35,137 testing 448/500 data 0.9455s net 0.3026s post 0.0083s
2017-06-26 23:31:36,467 testing 452/500 data 0.9467s net 0.3021s post 0.0083s
2017-06-26 23:31:37,805 testing 456/500 data 0.9477s net 0.3018s post 0.0083s
2017-06-26 23:31:39,215 testing 460/500 data 0.9484s net 0.3024s post 0.0083s
2017-06-26 23:31:40,508 testing 464/500 data 0.9492s net 0.3020s post 0.0083s
2017-06-26 23:31:41,847 testing 468/500 data 0.9500s net 0.3018s post 0.0083s
2017-06-26 23:31:43,185 testing 472/500 data 0.9505s net 0.3020s post 0.0083s
2017-06-26 23:31:44,420 testing 476/500 data 0.9506s net 0.3016s post 0.0083s
2017-06-26 23:31:45,727 testing 480/500 data 0.9513s net 0.3014s post 0.0083s
2017-06-26 23:31:47,217 testing 484/500 data 0.9525s net 0.3020s post 0.0083s
2017-06-26 23:31:48,392 testing 488/500 data 0.9520s net 0.3018s post 0.0083s
2017-06-26 23:31:49,719 testing 492/500 data 0.9527s net 0.3016s post 0.0083s
2017-06-26 23:31:51,064 testing 496/500 data 0.9537s net 0.3013s post 0.0083s
2017-06-26 23:31:52,452 testing 500/500 data 0.9541s net 0.3018s post 0.0084s
2017-06-26 23:33:50,468 evaluate segmentation: 

2017-06-26 23:33:50,468 IU_array:

2017-06-26 23:33:50,468 0.97910
2017-06-26 23:33:50,468 0.83134
2017-06-26 23:33:50,468 0.91299
2017-06-26 23:33:50,468 0.51012
2017-06-26 23:33:50,468 0.54048
2017-06-26 23:33:50,468 0.53797
2017-06-26 23:33:50,468 0.63340
2017-06-26 23:33:50,468 0.72700
2017-06-26 23:33:50,468 0.91253
2017-06-26 23:33:50,469 0.62017
2017-06-26 23:33:50,469 0.93557
2017-06-26 23:33:50,469 0.77572
2017-06-26 23:33:50,469 0.56942
2017-06-26 23:33:50,469 0.93763
2017-06-26 23:33:50,469 0.66750
2017-06-26 23:33:50,469 0.81605
2017-06-26 23:33:50,469 0.65031
2017-06-26 23:33:50,469 0.57724
2017-06-26 23:33:50,469 0.73890
2017-06-26 23:33:50,469 meanIU:0.73018

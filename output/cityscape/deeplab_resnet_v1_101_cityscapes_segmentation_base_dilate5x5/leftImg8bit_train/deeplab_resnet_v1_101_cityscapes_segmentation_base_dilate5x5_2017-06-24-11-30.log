2017-06-24 11:30:21,731 training config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3,4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate5x5'}

2017-06-24 11:32:16,283 Epoch[0] Batch [10]	Speed: 5.68 samples/sec	Train-FCNLogLoss=2.821229,	
2017-06-24 11:32:30,192 Epoch[0] Batch [20]	Speed: 5.75 samples/sec	Train-FCNLogLoss=2.500531,	
2017-06-24 11:32:45,786 Epoch[0] Batch [30]	Speed: 5.13 samples/sec	Train-FCNLogLoss=2.125458,	
2017-06-24 11:33:01,200 Epoch[0] Batch [40]	Speed: 5.19 samples/sec	Train-FCNLogLoss=1.889882,	
2017-06-24 11:33:17,920 Epoch[0] Batch [50]	Speed: 4.78 samples/sec	Train-FCNLogLoss=1.689868,	
2017-06-24 11:33:33,314 Epoch[0] Batch [60]	Speed: 5.20 samples/sec	Train-FCNLogLoss=1.536595,	
2017-06-24 11:33:48,932 Epoch[0] Batch [70]	Speed: 5.12 samples/sec	Train-FCNLogLoss=1.411024,	
2017-06-24 11:34:04,620 Epoch[0] Batch [80]	Speed: 5.10 samples/sec	Train-FCNLogLoss=1.314464,	
2017-06-24 11:34:20,715 Epoch[0] Batch [90]	Speed: 4.97 samples/sec	Train-FCNLogLoss=1.233861,	
2017-06-24 11:34:36,027 Epoch[0] Batch [100]	Speed: 5.22 samples/sec	Train-FCNLogLoss=1.169098,	
2017-06-24 11:34:51,553 Epoch[0] Batch [110]	Speed: 5.15 samples/sec	Train-FCNLogLoss=1.110232,	
2017-06-24 11:35:07,818 Epoch[0] Batch [120]	Speed: 4.92 samples/sec	Train-FCNLogLoss=1.061043,	
2017-06-24 11:35:24,766 Epoch[0] Batch [130]	Speed: 4.72 samples/sec	Train-FCNLogLoss=1.019393,	
2017-06-24 11:35:41,554 Epoch[0] Batch [140]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.977571,	
2017-06-24 11:35:58,367 Epoch[0] Batch [150]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.940278,	
2017-06-24 11:36:15,168 Epoch[0] Batch [160]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.905344,	
2017-06-24 11:36:31,805 Epoch[0] Batch [170]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.879204,	
2017-06-24 11:36:49,164 Epoch[0] Batch [180]	Speed: 4.61 samples/sec	Train-FCNLogLoss=0.854136,	
2017-06-24 11:37:05,270 Epoch[0] Batch [190]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.831685,	
2017-06-24 11:37:21,617 Epoch[0] Batch [200]	Speed: 4.89 samples/sec	Train-FCNLogLoss=0.813246,	
2017-06-24 11:37:38,038 Epoch[0] Batch [210]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.792647,	
2017-06-24 11:37:54,516 Epoch[0] Batch [220]	Speed: 4.86 samples/sec	Train-FCNLogLoss=0.773840,	
2017-06-24 11:38:11,458 Epoch[0] Batch [230]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.756667,	
2017-06-24 11:38:28,109 Epoch[0] Batch [240]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.741116,	
2017-06-24 11:38:43,713 Epoch[0] Batch [250]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.726042,	
2017-06-24 11:39:01,012 Epoch[0] Batch [260]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.712724,	
2017-06-24 11:39:17,647 Epoch[0] Batch [270]	Speed: 4.81 samples/sec	Train-FCNLogLoss=0.701542,	
2017-06-24 11:39:34,069 Epoch[0] Batch [280]	Speed: 4.87 samples/sec	Train-FCNLogLoss=0.689994,	
2017-06-24 11:39:50,786 Epoch[0] Batch [290]	Speed: 4.79 samples/sec	Train-FCNLogLoss=0.680084,	
2017-06-24 11:40:08,243 Epoch[0] Batch [300]	Speed: 4.58 samples/sec	Train-FCNLogLoss=0.669488,	
2017-06-24 11:40:24,338 Epoch[0] Batch [310]	Speed: 4.97 samples/sec	Train-FCNLogLoss=0.657880,	
2017-06-24 11:40:41,722 Epoch[0] Batch [320]	Speed: 4.60 samples/sec	Train-FCNLogLoss=0.647939,	
2017-06-24 11:40:58,395 Epoch[0] Batch [330]	Speed: 4.80 samples/sec	Train-FCNLogLoss=0.638398,	
2017-06-24 11:41:14,312 Epoch[0] Batch [340]	Speed: 5.03 samples/sec	Train-FCNLogLoss=0.629879,	
2017-06-24 11:41:30,296 Epoch[0] Batch [350]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.622168,	
2017-06-24 11:41:47,394 Epoch[0] Batch [360]	Speed: 4.68 samples/sec	Train-FCNLogLoss=0.614260,	
2017-06-24 11:42:03,682 Epoch[0] Batch [370]	Speed: 4.91 samples/sec	Train-FCNLogLoss=0.606655,	
2017-06-24 11:42:19,069 Epoch[0] Batch [380]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.599778,	
2017-06-24 11:42:34,759 Epoch[0] Batch [390]	Speed: 5.10 samples/sec	Train-FCNLogLoss=0.592715,	
2017-06-24 11:42:49,710 Epoch[0] Batch [400]	Speed: 5.35 samples/sec	Train-FCNLogLoss=0.586268,	
2017-06-24 11:43:06,022 Epoch[0] Batch [410]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.580153,	
2017-06-24 11:43:22,266 Epoch[0] Batch [420]	Speed: 4.92 samples/sec	Train-FCNLogLoss=0.573860,	
2017-06-24 11:43:38,306 Epoch[0] Batch [430]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.567841,	
2017-06-24 11:43:54,500 Epoch[0] Batch [440]	Speed: 4.94 samples/sec	Train-FCNLogLoss=0.562549,	
2017-06-24 11:44:11,450 Epoch[0] Batch [450]	Speed: 4.72 samples/sec	Train-FCNLogLoss=0.557608,	
2017-06-24 11:44:28,238 Epoch[0] Batch [460]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.553353,	
2017-06-24 11:44:44,220 Epoch[0] Batch [470]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.548204,	
2017-06-24 11:45:00,221 Epoch[0] Batch [480]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.543978,	
2017-06-24 11:45:15,597 Epoch[0] Batch [490]	Speed: 5.20 samples/sec	Train-FCNLogLoss=0.539272,	
2017-06-24 11:45:31,714 Epoch[0] Batch [500]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.534309,	
2017-06-24 11:45:46,519 Epoch[0] Batch [510]	Speed: 5.40 samples/sec	Train-FCNLogLoss=0.530041,	
2017-06-24 11:46:02,102 Epoch[0] Batch [520]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.525494,	
2017-06-24 11:46:18,255 Epoch[0] Batch [530]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.521311,	
2017-06-24 11:46:33,696 Epoch[0] Batch [540]	Speed: 5.18 samples/sec	Train-FCNLogLoss=0.516787,	
2017-06-24 11:46:50,495 Epoch[0] Batch [550]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.512676,	
2017-06-24 11:47:06,616 Epoch[0] Batch [560]	Speed: 4.96 samples/sec	Train-FCNLogLoss=0.509021,	
2017-06-24 11:47:22,569 Epoch[0] Batch [570]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.505984,	
2017-06-24 11:47:38,889 Epoch[0] Batch [580]	Speed: 4.90 samples/sec	Train-FCNLogLoss=0.502388,	
2017-06-24 11:47:54,374 Epoch[0] Batch [590]	Speed: 5.17 samples/sec	Train-FCNLogLoss=0.499239,	
2017-06-24 11:48:09,535 Epoch[0] Batch [600]	Speed: 5.28 samples/sec	Train-FCNLogLoss=0.496313,	
2017-06-24 11:48:23,241 Epoch[0] Batch [610]	Speed: 5.84 samples/sec	Train-FCNLogLoss=0.493123,	
2017-06-24 11:48:39,397 Epoch[0] Batch [620]	Speed: 4.95 samples/sec	Train-FCNLogLoss=0.490567,	
2017-06-24 11:48:57,058 Epoch[0] Batch [630]	Speed: 4.53 samples/sec	Train-FCNLogLoss=0.487608,	
2017-06-24 11:49:13,955 Epoch[0] Batch [640]	Speed: 4.73 samples/sec	Train-FCNLogLoss=0.484488,	
2017-06-24 11:49:30,827 Epoch[0] Batch [650]	Speed: 4.74 samples/sec	Train-FCNLogLoss=0.481589,	
2017-06-24 11:49:47,994 Epoch[0] Batch [660]	Speed: 4.66 samples/sec	Train-FCNLogLoss=0.478947,	
2017-06-24 11:50:05,310 Epoch[0] Batch [670]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.476060,	
2017-06-24 11:50:22,359 Epoch[0] Batch [680]	Speed: 4.69 samples/sec	Train-FCNLogLoss=0.473080,	
2017-06-24 11:50:38,317 Epoch[0] Batch [690]	Speed: 5.01 samples/sec	Train-FCNLogLoss=0.470618,	
2017-06-24 11:50:52,407 Epoch[0] Batch [700]	Speed: 5.68 samples/sec	Train-FCNLogLoss=0.468320,	
2017-06-24 11:51:07,111 Epoch[0] Batch [710]	Speed: 5.44 samples/sec	Train-FCNLogLoss=0.465389,	
2017-06-24 11:51:21,901 Epoch[0] Batch [720]	Speed: 5.41 samples/sec	Train-FCNLogLoss=0.463164,	
2017-06-24 11:51:38,680 Epoch[0] Batch [730]	Speed: 4.77 samples/sec	Train-FCNLogLoss=0.461245,	
2017-06-24 11:51:56,565 Epoch[0] Batch [740]	Speed: 4.47 samples/sec	Train-FCNLogLoss=0.459051,	
2017-06-24 11:52:00,048 Epoch[0] Train-FCNLogLoss=0.458513
2017-06-24 11:52:00,048 Epoch[0] Time cost=1218.932
2017-06-24 11:52:02,440 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0001.params"
2017-06-24 11:52:07,508 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0001.states"
2017-06-24 11:52:18,781 Epoch[1] Batch [10]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.278694,	
2017-06-24 11:52:28,405 Epoch[1] Batch [20]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.292827,	
2017-06-24 11:52:37,186 Epoch[1] Batch [30]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.287029,	
2017-06-24 11:52:46,452 Epoch[1] Batch [40]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.284517,	
2017-06-24 11:52:55,039 Epoch[1] Batch [50]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.285335,	
2017-06-24 11:53:03,807 Epoch[1] Batch [60]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.283575,	
2017-06-24 11:53:12,788 Epoch[1] Batch [70]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.281489,	
2017-06-24 11:53:20,827 Epoch[1] Batch [80]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.278902,	
2017-06-24 11:53:29,025 Epoch[1] Batch [90]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.279368,	
2017-06-24 11:53:37,231 Epoch[1] Batch [100]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.279689,	
2017-06-24 11:53:45,317 Epoch[1] Batch [110]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.279168,	
2017-06-24 11:53:53,443 Epoch[1] Batch [120]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.277454,	
2017-06-24 11:54:02,110 Epoch[1] Batch [130]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.277853,	
2017-06-24 11:54:11,063 Epoch[1] Batch [140]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.277286,	
2017-06-24 11:54:20,093 Epoch[1] Batch [150]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.276969,	
2017-06-24 11:54:28,815 Epoch[1] Batch [160]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.275947,	
2017-06-24 11:54:37,425 Epoch[1] Batch [170]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.275890,	
2017-06-24 11:54:46,124 Epoch[1] Batch [180]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.276886,	
2017-06-24 11:54:54,931 Epoch[1] Batch [190]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.278554,	
2017-06-24 11:55:03,617 Epoch[1] Batch [200]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.277804,	
2017-06-24 11:55:13,096 Epoch[1] Batch [210]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.279402,	
2017-06-24 11:55:22,239 Epoch[1] Batch [220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.277818,	
2017-06-24 11:55:31,086 Epoch[1] Batch [230]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.275619,	
2017-06-24 11:55:40,354 Epoch[1] Batch [240]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.277132,	
2017-06-24 11:55:49,338 Epoch[1] Batch [250]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.276984,	
2017-06-24 11:55:58,488 Epoch[1] Batch [260]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.278407,	
2017-06-24 11:56:07,908 Epoch[1] Batch [270]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.282798,	
2017-06-24 11:56:16,289 Epoch[1] Batch [280]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.296388,	
2017-06-24 11:56:25,520 Epoch[1] Batch [290]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.308620,	
2017-06-24 11:56:36,814 Epoch[1] Batch [300]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.313762,	
2017-06-24 11:56:45,485 Epoch[1] Batch [310]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.319375,	
2017-06-24 11:56:53,818 Epoch[1] Batch [320]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.320547,	
2017-06-24 11:57:02,712 Epoch[1] Batch [330]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.322970,	
2017-06-24 11:57:11,778 Epoch[1] Batch [340]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.324722,	
2017-06-24 11:57:19,794 Epoch[1] Batch [350]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.325788,	
2017-06-24 11:57:28,841 Epoch[1] Batch [360]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.325989,	
2017-06-24 11:57:37,745 Epoch[1] Batch [370]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.325811,	
2017-06-24 11:57:46,927 Epoch[1] Batch [380]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.326407,	
2017-06-24 11:57:56,310 Epoch[1] Batch [390]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.326104,	
2017-06-24 11:58:05,803 Epoch[1] Batch [400]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.324835,	
2017-06-24 11:58:14,972 Epoch[1] Batch [410]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.324582,	
2017-06-24 11:58:23,623 Epoch[1] Batch [420]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.324016,	
2017-06-24 11:58:33,318 Epoch[1] Batch [430]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.324082,	
2017-06-24 11:58:43,110 Epoch[1] Batch [440]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.322918,	
2017-06-24 11:58:52,376 Epoch[1] Batch [450]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.322722,	
2017-06-24 11:59:01,757 Epoch[1] Batch [460]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.322465,	
2017-06-24 11:59:11,711 Epoch[1] Batch [470]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.322004,	
2017-06-24 11:59:21,175 Epoch[1] Batch [480]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.320806,	
2017-06-24 11:59:30,448 Epoch[1] Batch [490]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.320869,	
2017-06-24 11:59:38,643 Epoch[1] Batch [500]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.320121,	
2017-06-24 11:59:47,230 Epoch[1] Batch [510]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.319489,	
2017-06-24 11:59:56,231 Epoch[1] Batch [520]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.318311,	
2017-06-24 12:00:05,080 Epoch[1] Batch [530]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.317583,	
2017-06-24 12:00:14,027 Epoch[1] Batch [540]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.317654,	
2017-06-24 12:00:23,108 Epoch[1] Batch [550]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.316741,	
2017-06-24 12:00:32,236 Epoch[1] Batch [560]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.320704,	
2017-06-24 12:00:42,074 Epoch[1] Batch [570]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.327352,	
2017-06-24 12:00:51,306 Epoch[1] Batch [580]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.330128,	
2017-06-24 12:01:00,701 Epoch[1] Batch [590]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.330607,	
2017-06-24 12:01:10,288 Epoch[1] Batch [600]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.331926,	
2017-06-24 12:01:19,641 Epoch[1] Batch [610]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.332477,	
2017-06-24 12:01:28,746 Epoch[1] Batch [620]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.333196,	
2017-06-24 12:01:38,104 Epoch[1] Batch [630]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.332929,	
2017-06-24 12:01:47,736 Epoch[1] Batch [640]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.332543,	
2017-06-24 12:01:57,231 Epoch[1] Batch [650]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.332098,	
2017-06-24 12:02:06,641 Epoch[1] Batch [660]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.331342,	
2017-06-24 12:02:16,350 Epoch[1] Batch [670]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.330841,	
2017-06-24 12:02:27,974 Epoch[1] Batch [680]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.330543,	
2017-06-24 12:02:37,023 Epoch[1] Batch [690]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.329539,	
2017-06-24 12:02:47,051 Epoch[1] Batch [700]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.328676,	
2017-06-24 12:02:56,842 Epoch[1] Batch [710]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.327943,	
2017-06-24 12:03:07,329 Epoch[1] Batch [720]	Speed: 7.63 samples/sec	Train-FCNLogLoss=0.327435,	
2017-06-24 12:03:17,059 Epoch[1] Batch [730]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.326718,	
2017-06-24 12:03:26,701 Epoch[1] Batch [740]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.326281,	
2017-06-24 12:03:28,417 Epoch[1] Train-FCNLogLoss=0.326499
2017-06-24 12:03:28,417 Epoch[1] Time cost=680.908
2017-06-24 12:03:30,012 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0002.params"
2017-06-24 12:03:33,874 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0002.states"
2017-06-24 12:03:44,826 Epoch[2] Batch [10]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.276384,	
2017-06-24 12:03:54,445 Epoch[2] Batch [20]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.273620,	
2017-06-24 12:04:04,074 Epoch[2] Batch [30]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.278893,	
2017-06-24 12:04:13,353 Epoch[2] Batch [40]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.268915,	
2017-06-24 12:04:22,630 Epoch[2] Batch [50]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.263646,	
2017-06-24 12:04:31,711 Epoch[2] Batch [60]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.260180,	
2017-06-24 12:04:40,614 Epoch[2] Batch [70]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.260917,	
2017-06-24 12:04:49,913 Epoch[2] Batch [80]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.255718,	
2017-06-24 12:04:59,089 Epoch[2] Batch [90]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.254319,	
2017-06-24 12:05:08,548 Epoch[2] Batch [100]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.254880,	
2017-06-24 12:05:17,613 Epoch[2] Batch [110]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.253681,	
2017-06-24 12:05:26,470 Epoch[2] Batch [120]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.251156,	
2017-06-24 12:05:36,096 Epoch[2] Batch [130]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.249867,	
2017-06-24 12:05:44,836 Epoch[2] Batch [140]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.251584,	
2017-06-24 12:05:53,380 Epoch[2] Batch [150]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.251659,	
2017-06-24 12:06:01,978 Epoch[2] Batch [160]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.250697,	
2017-06-24 12:06:11,036 Epoch[2] Batch [170]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.249204,	
2017-06-24 12:06:20,288 Epoch[2] Batch [180]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.249638,	
2017-06-24 12:06:28,556 Epoch[2] Batch [190]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.247621,	
2017-06-24 12:06:36,546 Epoch[2] Batch [200]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.248054,	
2017-06-24 12:06:44,485 Epoch[2] Batch [210]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.247975,	
2017-06-24 12:06:52,102 Epoch[2] Batch [220]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.246375,	
2017-06-24 12:07:00,029 Epoch[2] Batch [230]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.244797,	
2017-06-24 12:07:07,452 Epoch[2] Batch [240]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.243449,	
2017-06-24 12:07:14,947 Epoch[2] Batch [250]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.244052,	
2017-06-24 12:07:22,608 Epoch[2] Batch [260]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.245941,	
2017-06-24 12:07:30,225 Epoch[2] Batch [270]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.245849,	
2017-06-24 12:07:37,544 Epoch[2] Batch [280]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.245771,	
2017-06-24 12:07:45,317 Epoch[2] Batch [290]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.245218,	
2017-06-24 12:07:52,722 Epoch[2] Batch [300]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.244936,	
2017-06-24 12:07:59,952 Epoch[2] Batch [310]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.244781,	
2017-06-24 12:08:07,491 Epoch[2] Batch [320]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.244555,	
2017-06-24 12:08:15,301 Epoch[2] Batch [330]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.243736,	
2017-06-24 12:08:22,743 Epoch[2] Batch [340]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.242822,	
2017-06-24 12:08:30,218 Epoch[2] Batch [350]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.242812,	
2017-06-24 12:08:37,671 Epoch[2] Batch [360]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.242069,	
2017-06-24 12:08:48,232 Epoch[2] Batch [370]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.241364,	
2017-06-24 12:08:57,955 Epoch[2] Batch [380]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.241282,	
2017-06-24 12:09:05,715 Epoch[2] Batch [390]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.241225,	
2017-06-24 12:09:12,924 Epoch[2] Batch [400]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.241440,	
2017-06-24 12:09:20,839 Epoch[2] Batch [410]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.240814,	
2017-06-24 12:09:28,726 Epoch[2] Batch [420]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.240846,	
2017-06-24 12:09:36,221 Epoch[2] Batch [430]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.240526,	
2017-06-24 12:09:43,949 Epoch[2] Batch [440]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.239829,	
2017-06-24 12:09:51,700 Epoch[2] Batch [450]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.239365,	
2017-06-24 12:09:59,238 Epoch[2] Batch [460]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.239037,	
2017-06-24 12:10:06,825 Epoch[2] Batch [470]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.238632,	
2017-06-24 12:10:14,394 Epoch[2] Batch [480]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.237587,	
2017-06-24 12:10:22,291 Epoch[2] Batch [490]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.236849,	
2017-06-24 12:10:29,805 Epoch[2] Batch [500]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.236866,	
2017-06-24 12:10:37,393 Epoch[2] Batch [510]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.236945,	
2017-06-24 12:10:45,241 Epoch[2] Batch [520]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.236723,	
2017-06-24 12:10:52,804 Epoch[2] Batch [530]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.236884,	
2017-06-24 12:11:00,499 Epoch[2] Batch [540]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.238413,	
2017-06-24 12:11:08,232 Epoch[2] Batch [550]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.238246,	
2017-06-24 12:11:16,007 Epoch[2] Batch [560]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.238210,	
2017-06-24 12:11:23,446 Epoch[2] Batch [570]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.237727,	
2017-06-24 12:11:30,923 Epoch[2] Batch [580]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.237412,	
2017-06-24 12:11:38,565 Epoch[2] Batch [590]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.237313,	
2017-06-24 12:11:46,183 Epoch[2] Batch [600]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.236783,	
2017-06-24 12:11:53,892 Epoch[2] Batch [610]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.236616,	
2017-06-24 12:12:01,693 Epoch[2] Batch [620]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.236791,	
2017-06-24 12:12:09,486 Epoch[2] Batch [630]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.236426,	
2017-06-24 12:12:16,792 Epoch[2] Batch [640]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.236312,	
2017-06-24 12:12:24,388 Epoch[2] Batch [650]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.235692,	
2017-06-24 12:12:32,052 Epoch[2] Batch [660]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.235970,	
2017-06-24 12:12:39,593 Epoch[2] Batch [670]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.235532,	
2017-06-24 12:12:46,914 Epoch[2] Batch [680]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.234998,	
2017-06-24 12:12:54,679 Epoch[2] Batch [690]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.234675,	
2017-06-24 12:13:02,472 Epoch[2] Batch [700]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.234390,	
2017-06-24 12:13:10,143 Epoch[2] Batch [710]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.234495,	
2017-06-24 12:13:17,472 Epoch[2] Batch [720]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.233960,	
2017-06-24 12:13:25,283 Epoch[2] Batch [730]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.234057,	
2017-06-24 12:13:32,882 Epoch[2] Batch [740]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.233670,	
2017-06-24 12:13:34,258 Epoch[2] Train-FCNLogLoss=0.233576
2017-06-24 12:13:34,259 Epoch[2] Time cost=600.384
2017-06-24 12:13:35,674 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0003.params"
2017-06-24 12:13:37,488 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0003.states"
2017-06-24 12:13:47,530 Epoch[3] Batch [10]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.228472,	
2017-06-24 12:13:54,689 Epoch[3] Batch [20]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.215101,	
2017-06-24 12:14:02,596 Epoch[3] Batch [30]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.209263,	
2017-06-24 12:14:09,938 Epoch[3] Batch [40]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.215506,	
2017-06-24 12:14:17,548 Epoch[3] Batch [50]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.217987,	
2017-06-24 12:14:25,311 Epoch[3] Batch [60]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.217569,	
2017-06-24 12:14:32,700 Epoch[3] Batch [70]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.217163,	
2017-06-24 12:14:40,028 Epoch[3] Batch [80]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.219371,	
2017-06-24 12:14:47,740 Epoch[3] Batch [90]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.220627,	
2017-06-24 12:14:55,246 Epoch[3] Batch [100]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.218010,	
2017-06-24 12:15:02,511 Epoch[3] Batch [110]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.217472,	
2017-06-24 12:15:09,876 Epoch[3] Batch [120]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.215839,	
2017-06-24 12:15:17,638 Epoch[3] Batch [130]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.215461,	
2017-06-24 12:15:25,310 Epoch[3] Batch [140]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.214396,	
2017-06-24 12:15:32,635 Epoch[3] Batch [150]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.215582,	
2017-06-24 12:15:39,992 Epoch[3] Batch [160]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.213566,	
2017-06-24 12:15:47,629 Epoch[3] Batch [170]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.211834,	
2017-06-24 12:15:55,061 Epoch[3] Batch [180]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.209819,	
2017-06-24 12:16:02,381 Epoch[3] Batch [190]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.209928,	
2017-06-24 12:16:09,953 Epoch[3] Batch [200]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.209048,	
2017-06-24 12:16:17,725 Epoch[3] Batch [210]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.209191,	
2017-06-24 12:16:25,033 Epoch[3] Batch [220]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.209601,	
2017-06-24 12:16:32,593 Epoch[3] Batch [230]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.209622,	
2017-06-24 12:16:40,239 Epoch[3] Batch [240]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.209756,	
2017-06-24 12:16:47,512 Epoch[3] Batch [250]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.209887,	
2017-06-24 12:16:54,855 Epoch[3] Batch [260]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.210465,	
2017-06-24 12:17:02,344 Epoch[3] Batch [270]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.210901,	
2017-06-24 12:17:09,981 Epoch[3] Batch [280]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.210597,	
2017-06-24 12:17:17,583 Epoch[3] Batch [290]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.210911,	
2017-06-24 12:17:24,879 Epoch[3] Batch [300]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.210734,	
2017-06-24 12:17:32,087 Epoch[3] Batch [310]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.211054,	
2017-06-24 12:17:39,548 Epoch[3] Batch [320]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.209982,	
2017-06-24 12:17:48,869 Epoch[3] Batch [330]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.209138,	
2017-06-24 12:17:59,899 Epoch[3] Batch [340]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.208078,	
2017-06-24 12:18:08,562 Epoch[3] Batch [350]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.207297,	
2017-06-24 12:18:16,803 Epoch[3] Batch [360]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.206714,	
2017-06-24 12:18:24,123 Epoch[3] Batch [370]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.206830,	
2017-06-24 12:18:31,571 Epoch[3] Batch [380]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.206816,	
2017-06-24 12:18:38,743 Epoch[3] Batch [390]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.206270,	
2017-06-24 12:18:46,554 Epoch[3] Batch [400]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.206048,	
2017-06-24 12:18:53,918 Epoch[3] Batch [410]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.205941,	
2017-06-24 12:19:01,480 Epoch[3] Batch [420]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.205389,	
2017-06-24 12:19:09,342 Epoch[3] Batch [430]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.205290,	
2017-06-24 12:19:16,971 Epoch[3] Batch [440]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.204932,	
2017-06-24 12:19:24,518 Epoch[3] Batch [450]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.205550,	
2017-06-24 12:19:32,057 Epoch[3] Batch [460]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.205190,	
2017-06-24 12:19:39,576 Epoch[3] Batch [470]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.205222,	
2017-06-24 12:19:47,140 Epoch[3] Batch [480]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.205082,	
2017-06-24 12:19:54,367 Epoch[3] Batch [490]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.204900,	
2017-06-24 12:20:01,673 Epoch[3] Batch [500]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.204392,	
2017-06-24 12:20:09,436 Epoch[3] Batch [510]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.204193,	
2017-06-24 12:20:16,932 Epoch[3] Batch [520]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.203646,	
2017-06-24 12:20:24,185 Epoch[3] Batch [530]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.202959,	
2017-06-24 12:20:32,057 Epoch[3] Batch [540]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.202433,	
2017-06-24 12:20:39,444 Epoch[3] Batch [550]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.202175,	
2017-06-24 12:20:47,208 Epoch[3] Batch [560]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.202239,	
2017-06-24 12:20:54,609 Epoch[3] Batch [570]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.201824,	
2017-06-24 12:21:02,078 Epoch[3] Batch [580]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.201437,	
2017-06-24 12:21:09,646 Epoch[3] Batch [590]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.201231,	
2017-06-24 12:21:17,452 Epoch[3] Batch [600]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.201080,	
2017-06-24 12:21:24,898 Epoch[3] Batch [610]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.200632,	
2017-06-24 12:21:32,182 Epoch[3] Batch [620]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.200334,	
2017-06-24 12:21:39,632 Epoch[3] Batch [630]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.199946,	
2017-06-24 12:21:47,121 Epoch[3] Batch [640]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.199698,	
2017-06-24 12:21:54,793 Epoch[3] Batch [650]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.199651,	
2017-06-24 12:22:02,200 Epoch[3] Batch [660]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.199087,	
2017-06-24 12:22:09,648 Epoch[3] Batch [670]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.198597,	
2017-06-24 12:22:17,032 Epoch[3] Batch [680]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.198637,	
2017-06-24 12:22:24,797 Epoch[3] Batch [690]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.198314,	
2017-06-24 12:22:32,133 Epoch[3] Batch [700]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.197970,	
2017-06-24 12:22:39,425 Epoch[3] Batch [710]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.197557,	
2017-06-24 12:22:48,316 Epoch[3] Batch [720]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.197434,	
2017-06-24 12:22:56,106 Epoch[3] Batch [730]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.197514,	
2017-06-24 12:23:03,663 Epoch[3] Batch [740]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.197342,	
2017-06-24 12:23:05,142 Epoch[3] Train-FCNLogLoss=0.197327
2017-06-24 12:23:05,142 Epoch[3] Time cost=567.654
2017-06-24 12:23:06,474 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0004.params"
2017-06-24 12:23:08,150 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0004.states"
2017-06-24 12:23:16,956 Epoch[4] Batch [10]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.173376,	
2017-06-24 12:23:24,464 Epoch[4] Batch [20]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.172311,	
2017-06-24 12:23:32,419 Epoch[4] Batch [30]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.170993,	
2017-06-24 12:23:40,263 Epoch[4] Batch [40]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.175950,	
2017-06-24 12:23:47,682 Epoch[4] Batch [50]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.178280,	
2017-06-24 12:23:55,189 Epoch[4] Batch [60]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.176171,	
2017-06-24 12:24:03,025 Epoch[4] Batch [70]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.179337,	
2017-06-24 12:24:10,376 Epoch[4] Batch [80]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.179045,	
2017-06-24 12:24:17,531 Epoch[4] Batch [90]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.179960,	
2017-06-24 12:24:24,910 Epoch[4] Batch [100]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.179591,	
2017-06-24 12:24:32,544 Epoch[4] Batch [110]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.180948,	
2017-06-24 12:24:40,342 Epoch[4] Batch [120]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.181119,	
2017-06-24 12:24:47,947 Epoch[4] Batch [130]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.180598,	
2017-06-24 12:24:55,486 Epoch[4] Batch [140]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.180719,	
2017-06-24 12:25:02,860 Epoch[4] Batch [150]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.179752,	
2017-06-24 12:25:10,094 Epoch[4] Batch [160]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.179715,	
2017-06-24 12:25:17,701 Epoch[4] Batch [170]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.181055,	
2017-06-24 12:25:25,254 Epoch[4] Batch [180]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.180235,	
2017-06-24 12:25:32,850 Epoch[4] Batch [190]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.180891,	
2017-06-24 12:25:40,089 Epoch[4] Batch [200]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.180062,	
2017-06-24 12:25:47,893 Epoch[4] Batch [210]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.180259,	
2017-06-24 12:25:55,311 Epoch[4] Batch [220]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.179912,	
2017-06-24 12:26:02,563 Epoch[4] Batch [230]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.180232,	
2017-06-24 12:26:09,830 Epoch[4] Batch [240]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.179975,	
2017-06-24 12:26:17,174 Epoch[4] Batch [250]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.181413,	
2017-06-24 12:26:24,842 Epoch[4] Batch [260]	Speed: 10.43 samples/sec	Train-FCNLogLoss=0.182037,	
2017-06-24 12:26:32,354 Epoch[4] Batch [270]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.182149,	
2017-06-24 12:26:39,590 Epoch[4] Batch [280]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.181672,	
2017-06-24 12:26:47,292 Epoch[4] Batch [290]	Speed: 10.39 samples/sec	Train-FCNLogLoss=0.181494,	
2017-06-24 12:26:54,659 Epoch[4] Batch [300]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.180984,	
2017-06-24 12:27:01,792 Epoch[4] Batch [310]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.181533,	
2017-06-24 12:27:09,812 Epoch[4] Batch [320]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.180950,	
2017-06-24 12:27:21,057 Epoch[4] Batch [330]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.180908,	
2017-06-24 12:27:29,278 Epoch[4] Batch [340]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.181127,	
2017-06-24 12:27:36,644 Epoch[4] Batch [350]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.180698,	
2017-06-24 12:27:44,454 Epoch[4] Batch [360]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.181336,	
2017-06-24 12:27:51,678 Epoch[4] Batch [370]	Speed: 11.08 samples/sec	Train-FCNLogLoss=0.181679,	
2017-06-24 12:27:58,967 Epoch[4] Batch [380]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.182064,	
2017-06-24 12:28:06,674 Epoch[4] Batch [390]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.182048,	
2017-06-24 12:28:14,300 Epoch[4] Batch [400]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.182240,	
2017-06-24 12:28:21,992 Epoch[4] Batch [410]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.182154,	
2017-06-24 12:28:29,509 Epoch[4] Batch [420]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.181737,	
2017-06-24 12:28:37,004 Epoch[4] Batch [430]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.182067,	
2017-06-24 12:28:44,440 Epoch[4] Batch [440]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.182252,	
2017-06-24 12:28:51,794 Epoch[4] Batch [450]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.182392,	
2017-06-24 12:28:59,342 Epoch[4] Batch [460]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.182554,	
2017-06-24 12:29:06,663 Epoch[4] Batch [470]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.182974,	
2017-06-24 12:29:14,380 Epoch[4] Batch [480]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.182590,	
2017-06-24 12:29:21,891 Epoch[4] Batch [490]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.182491,	
2017-06-24 12:29:29,503 Epoch[4] Batch [500]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.182292,	
2017-06-24 12:29:37,131 Epoch[4] Batch [510]	Speed: 10.49 samples/sec	Train-FCNLogLoss=0.182334,	
2017-06-24 12:29:44,485 Epoch[4] Batch [520]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.182401,	
2017-06-24 12:29:52,066 Epoch[4] Batch [530]	Speed: 10.55 samples/sec	Train-FCNLogLoss=0.182403,	
2017-06-24 12:29:59,580 Epoch[4] Batch [540]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.182444,	
2017-06-24 12:30:07,060 Epoch[4] Batch [550]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.182642,	
2017-06-24 12:30:14,610 Epoch[4] Batch [560]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.182475,	
2017-06-24 12:30:22,135 Epoch[4] Batch [570]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.182415,	
2017-06-24 12:30:29,918 Epoch[4] Batch [580]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.182307,	
2017-06-24 12:30:37,462 Epoch[4] Batch [590]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.182478,	
2017-06-24 12:30:44,849 Epoch[4] Batch [600]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.182469,	
2017-06-24 12:30:52,577 Epoch[4] Batch [610]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.182161,	
2017-06-24 12:30:59,829 Epoch[4] Batch [620]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.181850,	
2017-06-24 12:31:07,682 Epoch[4] Batch [630]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.181693,	
2017-06-24 12:31:15,217 Epoch[4] Batch [640]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.181743,	
2017-06-24 12:31:22,632 Epoch[4] Batch [650]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.181802,	
2017-06-24 12:31:30,072 Epoch[4] Batch [660]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.181900,	
2017-06-24 12:31:37,676 Epoch[4] Batch [670]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.182041,	
2017-06-24 12:31:45,267 Epoch[4] Batch [680]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.181964,	
2017-06-24 12:31:53,509 Epoch[4] Batch [690]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.181874,	
2017-06-24 12:32:01,541 Epoch[4] Batch [700]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.182035,	
2017-06-24 12:32:08,884 Epoch[4] Batch [710]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.181977,	
2017-06-24 12:32:16,229 Epoch[4] Batch [720]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.181757,	
2017-06-24 12:32:23,176 Epoch[4] Batch [730]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.181623,	
2017-06-24 12:32:30,571 Epoch[4] Batch [740]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.181555,	
2017-06-24 12:32:31,848 Epoch[4] Train-FCNLogLoss=0.181548
2017-06-24 12:32:31,848 Epoch[4] Time cost=563.698
2017-06-24 12:32:33,365 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0005.params"
2017-06-24 12:32:35,072 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0005.states"
2017-06-24 12:32:43,490 Epoch[5] Batch [10]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.162359,	
2017-06-24 12:32:50,586 Epoch[5] Batch [20]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.167657,	
2017-06-24 12:32:58,005 Epoch[5] Batch [30]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.165175,	
2017-06-24 12:33:05,154 Epoch[5] Batch [40]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.164137,	
2017-06-24 12:33:12,439 Epoch[5] Batch [50]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.162489,	
2017-06-24 12:33:19,762 Epoch[5] Batch [60]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.166647,	
2017-06-24 12:33:26,906 Epoch[5] Batch [70]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.165378,	
2017-06-24 12:33:33,983 Epoch[5] Batch [80]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.164691,	
2017-06-24 12:33:41,422 Epoch[5] Batch [90]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.164322,	
2017-06-24 12:33:48,659 Epoch[5] Batch [100]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.162182,	
2017-06-24 12:33:56,021 Epoch[5] Batch [110]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.166350,	
2017-06-24 12:34:02,999 Epoch[5] Batch [120]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.165841,	
2017-06-24 12:34:10,314 Epoch[5] Batch [130]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.166653,	
2017-06-24 12:34:17,392 Epoch[5] Batch [140]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.166595,	
2017-06-24 12:34:24,726 Epoch[5] Batch [150]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.165316,	
2017-06-24 12:34:31,948 Epoch[5] Batch [160]	Speed: 11.08 samples/sec	Train-FCNLogLoss=0.165339,	
2017-06-24 12:34:38,944 Epoch[5] Batch [170]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.164937,	
2017-06-24 12:34:46,258 Epoch[5] Batch [180]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.165222,	
2017-06-24 12:34:53,648 Epoch[5] Batch [190]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.165228,	
2017-06-24 12:35:00,683 Epoch[5] Batch [200]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.166386,	
2017-06-24 12:35:07,556 Epoch[5] Batch [210]	Speed: 11.64 samples/sec	Train-FCNLogLoss=0.167483,	
2017-06-24 12:35:15,036 Epoch[5] Batch [220]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.167639,	
2017-06-24 12:35:22,122 Epoch[5] Batch [230]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.167559,	
2017-06-24 12:35:29,260 Epoch[5] Batch [240]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.167393,	
2017-06-24 12:35:36,377 Epoch[5] Batch [250]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.167394,	
2017-06-24 12:35:43,310 Epoch[5] Batch [260]	Speed: 11.54 samples/sec	Train-FCNLogLoss=0.166974,	
2017-06-24 12:35:50,382 Epoch[5] Batch [270]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.167474,	
2017-06-24 12:35:57,649 Epoch[5] Batch [280]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.167346,	
2017-06-24 12:36:04,669 Epoch[5] Batch [290]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.167827,	
2017-06-24 12:36:12,044 Epoch[5] Batch [300]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.167980,	
2017-06-24 12:36:19,186 Epoch[5] Batch [310]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.167635,	
2017-06-24 12:36:26,365 Epoch[5] Batch [320]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.168877,	
2017-06-24 12:36:33,769 Epoch[5] Batch [330]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.168790,	
2017-06-24 12:36:40,727 Epoch[5] Batch [340]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.169157,	
2017-06-24 12:36:47,738 Epoch[5] Batch [350]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.170025,	
2017-06-24 12:36:57,527 Epoch[5] Batch [360]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.170304,	
2017-06-24 12:37:07,517 Epoch[5] Batch [370]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.170336,	
2017-06-24 12:37:14,768 Epoch[5] Batch [380]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.171004,	
2017-06-24 12:37:21,916 Epoch[5] Batch [390]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.170697,	
2017-06-24 12:37:29,438 Epoch[5] Batch [400]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.171405,	
2017-06-24 12:37:36,342 Epoch[5] Batch [410]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.171208,	
2017-06-24 12:37:43,751 Epoch[5] Batch [420]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.170984,	
2017-06-24 12:37:50,796 Epoch[5] Batch [430]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.170755,	
2017-06-24 12:37:58,193 Epoch[5] Batch [440]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.170325,	
2017-06-24 12:38:05,305 Epoch[5] Batch [450]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.169897,	
2017-06-24 12:38:12,361 Epoch[5] Batch [460]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.169810,	
2017-06-24 12:38:19,301 Epoch[5] Batch [470]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.169298,	
2017-06-24 12:38:26,530 Epoch[5] Batch [480]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.169122,	
2017-06-24 12:38:34,000 Epoch[5] Batch [490]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.168819,	
2017-06-24 12:38:41,177 Epoch[5] Batch [500]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.168807,	
2017-06-24 12:38:48,532 Epoch[5] Batch [510]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.168535,	
2017-06-24 12:38:55,605 Epoch[5] Batch [520]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.168591,	
2017-06-24 12:39:03,134 Epoch[5] Batch [530]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.168865,	
2017-06-24 12:39:10,365 Epoch[5] Batch [540]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.168614,	
2017-06-24 12:39:17,592 Epoch[5] Batch [550]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.168760,	
2017-06-24 12:39:24,850 Epoch[5] Batch [560]	Speed: 11.02 samples/sec	Train-FCNLogLoss=0.168479,	
2017-06-24 12:39:32,251 Epoch[5] Batch [570]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.168362,	
2017-06-24 12:39:39,363 Epoch[5] Batch [580]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.168101,	
2017-06-24 12:39:46,828 Epoch[5] Batch [590]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.167996,	
2017-06-24 12:39:53,923 Epoch[5] Batch [600]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.167671,	
2017-06-24 12:40:00,964 Epoch[5] Batch [610]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.167645,	
2017-06-24 12:40:08,231 Epoch[5] Batch [620]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.167573,	
2017-06-24 12:40:15,716 Epoch[5] Batch [630]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.167555,	
2017-06-24 12:40:22,846 Epoch[5] Batch [640]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.167697,	
2017-06-24 12:40:29,917 Epoch[5] Batch [650]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.167676,	
2017-06-24 12:40:37,188 Epoch[5] Batch [660]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.167748,	
2017-06-24 12:40:44,382 Epoch[5] Batch [670]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.167706,	
2017-06-24 12:40:51,379 Epoch[5] Batch [680]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.167440,	
2017-06-24 12:40:58,630 Epoch[5] Batch [690]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.167699,	
2017-06-24 12:41:05,918 Epoch[5] Batch [700]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.167831,	
2017-06-24 12:41:12,878 Epoch[5] Batch [710]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.167544,	
2017-06-24 12:41:20,340 Epoch[5] Batch [720]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.167859,	
2017-06-24 12:41:27,413 Epoch[5] Batch [730]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.167543,	
2017-06-24 12:41:34,907 Epoch[5] Batch [740]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.167324,	
2017-06-24 12:41:36,198 Epoch[5] Train-FCNLogLoss=0.167271
2017-06-24 12:41:36,199 Epoch[5] Time cost=541.126
2017-06-24 12:41:37,524 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0006.params"
2017-06-24 12:41:39,197 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0006.states"
2017-06-24 12:41:47,941 Epoch[6] Batch [10]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.189146,	
2017-06-24 12:41:54,937 Epoch[6] Batch [20]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.174911,	
2017-06-24 12:42:02,208 Epoch[6] Batch [30]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.171222,	
2017-06-24 12:42:09,564 Epoch[6] Batch [40]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.167737,	
2017-06-24 12:42:16,721 Epoch[6] Batch [50]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.168196,	
2017-06-24 12:42:23,662 Epoch[6] Batch [60]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.166862,	
2017-06-24 12:42:30,618 Epoch[6] Batch [70]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.166024,	
2017-06-24 12:42:38,085 Epoch[6] Batch [80]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.166162,	
2017-06-24 12:42:45,126 Epoch[6] Batch [90]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.165283,	
2017-06-24 12:42:52,015 Epoch[6] Batch [100]	Speed: 11.61 samples/sec	Train-FCNLogLoss=0.163864,	
2017-06-24 12:42:59,469 Epoch[6] Batch [110]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.162331,	
2017-06-24 12:43:06,454 Epoch[6] Batch [120]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.162748,	
2017-06-24 12:43:13,785 Epoch[6] Batch [130]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.162859,	
2017-06-24 12:43:20,912 Epoch[6] Batch [140]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.161874,	
2017-06-24 12:43:28,366 Epoch[6] Batch [150]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.160969,	
2017-06-24 12:43:35,545 Epoch[6] Batch [160]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.160475,	
2017-06-24 12:43:42,896 Epoch[6] Batch [170]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.159756,	
2017-06-24 12:43:50,175 Epoch[6] Batch [180]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.158575,	
2017-06-24 12:43:57,538 Epoch[6] Batch [190]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.158515,	
2017-06-24 12:44:04,558 Epoch[6] Batch [200]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.158286,	
2017-06-24 12:44:11,495 Epoch[6] Batch [210]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.158335,	
2017-06-24 12:44:18,646 Epoch[6] Batch [220]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.157895,	
2017-06-24 12:44:25,879 Epoch[6] Batch [230]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.157541,	
2017-06-24 12:44:33,072 Epoch[6] Batch [240]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.157461,	
2017-06-24 12:44:40,309 Epoch[6] Batch [250]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.157853,	
2017-06-24 12:44:47,356 Epoch[6] Batch [260]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.156929,	
2017-06-24 12:44:54,830 Epoch[6] Batch [270]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.157462,	
2017-06-24 12:45:01,971 Epoch[6] Batch [280]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.157770,	
2017-06-24 12:45:09,026 Epoch[6] Batch [290]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.157880,	
2017-06-24 12:45:16,435 Epoch[6] Batch [300]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.158188,	
2017-06-24 12:45:23,533 Epoch[6] Batch [310]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.157543,	
2017-06-24 12:45:30,629 Epoch[6] Batch [320]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.157769,	
2017-06-24 12:45:37,623 Epoch[6] Batch [330]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.157579,	
2017-06-24 12:45:44,725 Epoch[6] Batch [340]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.158659,	
2017-06-24 12:45:51,776 Epoch[6] Batch [350]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.158380,	
2017-06-24 12:45:58,984 Epoch[6] Batch [360]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.158197,	
2017-06-24 12:46:06,370 Epoch[6] Batch [370]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.158748,	
2017-06-24 12:46:13,299 Epoch[6] Batch [380]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.158441,	
2017-06-24 12:46:20,451 Epoch[6] Batch [390]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.158273,	
2017-06-24 12:46:27,640 Epoch[6] Batch [400]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.158505,	
2017-06-24 12:46:35,090 Epoch[6] Batch [410]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.159071,	
2017-06-24 12:46:42,207 Epoch[6] Batch [420]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.159007,	
2017-06-24 12:46:49,639 Epoch[6] Batch [430]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.159295,	
2017-06-24 12:46:56,569 Epoch[6] Batch [440]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.159176,	
2017-06-24 12:47:04,447 Epoch[6] Batch [450]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.158958,	
2017-06-24 12:47:16,247 Epoch[6] Batch [460]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.158898,	
2017-06-24 12:47:24,118 Epoch[6] Batch [470]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.159067,	
2017-06-24 12:47:31,610 Epoch[6] Batch [480]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.159203,	
2017-06-24 12:47:38,655 Epoch[6] Batch [490]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.159019,	
2017-06-24 12:47:46,040 Epoch[6] Batch [500]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.158923,	
2017-06-24 12:47:53,506 Epoch[6] Batch [510]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.158874,	
2017-06-24 12:48:00,718 Epoch[6] Batch [520]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.158685,	
2017-06-24 12:48:07,930 Epoch[6] Batch [530]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.158612,	
2017-06-24 12:48:15,487 Epoch[6] Batch [540]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.159084,	
2017-06-24 12:48:22,484 Epoch[6] Batch [550]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.159233,	
2017-06-24 12:48:29,633 Epoch[6] Batch [560]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.160068,	
2017-06-24 12:48:37,105 Epoch[6] Batch [570]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.159791,	
2017-06-24 12:48:44,085 Epoch[6] Batch [580]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.160059,	
2017-06-24 12:48:51,249 Epoch[6] Batch [590]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.160045,	
2017-06-24 12:48:58,654 Epoch[6] Batch [600]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.159856,	
2017-06-24 12:49:05,886 Epoch[6] Batch [610]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.160120,	
2017-06-24 12:49:13,008 Epoch[6] Batch [620]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.160220,	
2017-06-24 12:49:20,510 Epoch[6] Batch [630]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.160200,	
2017-06-24 12:49:27,500 Epoch[6] Batch [640]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.160315,	
2017-06-24 12:49:34,948 Epoch[6] Batch [650]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.160397,	
2017-06-24 12:49:41,871 Epoch[6] Batch [660]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.160584,	
2017-06-24 12:49:49,032 Epoch[6] Batch [670]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.160542,	
2017-06-24 12:49:56,676 Epoch[6] Batch [680]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.160235,	
2017-06-24 12:50:03,557 Epoch[6] Batch [690]	Speed: 11.63 samples/sec	Train-FCNLogLoss=0.160325,	
2017-06-24 12:50:10,990 Epoch[6] Batch [700]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.160215,	
2017-06-24 12:50:18,053 Epoch[6] Batch [710]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.160324,	
2017-06-24 12:50:25,369 Epoch[6] Batch [720]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.160306,	
2017-06-24 12:50:32,522 Epoch[6] Batch [730]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.160569,	
2017-06-24 12:50:39,924 Epoch[6] Batch [740]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.160738,	
2017-06-24 12:50:41,236 Epoch[6] Train-FCNLogLoss=0.160828
2017-06-24 12:50:41,236 Epoch[6] Time cost=542.039
2017-06-24 12:50:42,729 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0007.params"
2017-06-24 12:50:44,356 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0007.states"
2017-06-24 12:50:52,606 Epoch[7] Batch [10]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.178016,	
2017-06-24 12:51:00,031 Epoch[7] Batch [20]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.166880,	
2017-06-24 12:51:07,165 Epoch[7] Batch [30]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.162522,	
2017-06-24 12:51:14,356 Epoch[7] Batch [40]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.163836,	
2017-06-24 12:51:21,691 Epoch[7] Batch [50]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.161047,	
2017-06-24 12:51:29,047 Epoch[7] Batch [60]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.161243,	
2017-06-24 12:51:36,206 Epoch[7] Batch [70]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.158867,	
2017-06-24 12:51:43,557 Epoch[7] Batch [80]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.156941,	
2017-06-24 12:51:50,988 Epoch[7] Batch [90]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.155502,	
2017-06-24 12:51:58,003 Epoch[7] Batch [100]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.155379,	
2017-06-24 12:52:04,984 Epoch[7] Batch [110]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.154126,	
2017-06-24 12:52:12,325 Epoch[7] Batch [120]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.153271,	
2017-06-24 12:52:19,462 Epoch[7] Batch [130]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.153504,	
2017-06-24 12:52:26,913 Epoch[7] Batch [140]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.153056,	
2017-06-24 12:52:33,922 Epoch[7] Batch [150]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.154144,	
2017-06-24 12:52:40,908 Epoch[7] Batch [160]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.154351,	
2017-06-24 12:52:48,006 Epoch[7] Batch [170]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.154221,	
2017-06-24 12:52:55,277 Epoch[7] Batch [180]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.153356,	
2017-06-24 12:53:02,174 Epoch[7] Batch [190]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.152917,	
2017-06-24 12:53:09,207 Epoch[7] Batch [200]	Speed: 11.38 samples/sec	Train-FCNLogLoss=0.152833,	
2017-06-24 12:53:16,132 Epoch[7] Batch [210]	Speed: 11.55 samples/sec	Train-FCNLogLoss=0.153085,	
2017-06-24 12:53:23,522 Epoch[7] Batch [220]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.152896,	
2017-06-24 12:53:30,582 Epoch[7] Batch [230]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.152929,	
2017-06-24 12:53:37,870 Epoch[7] Batch [240]	Speed: 10.98 samples/sec	Train-FCNLogLoss=0.152935,	
2017-06-24 12:53:45,120 Epoch[7] Batch [250]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.152561,	
2017-06-24 12:53:52,308 Epoch[7] Batch [260]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.152359,	
2017-06-24 12:53:59,846 Epoch[7] Batch [270]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.152958,	
2017-06-24 12:54:06,947 Epoch[7] Batch [280]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.153007,	
2017-06-24 12:54:14,193 Epoch[7] Batch [290]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.153011,	
2017-06-24 12:54:21,286 Epoch[7] Batch [300]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.153203,	
2017-06-24 12:54:28,386 Epoch[7] Batch [310]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.153295,	
2017-06-24 12:54:35,453 Epoch[7] Batch [320]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.153204,	
2017-06-24 12:54:42,568 Epoch[7] Batch [330]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.152537,	
2017-06-24 12:54:49,938 Epoch[7] Batch [340]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.152224,	
2017-06-24 12:54:56,918 Epoch[7] Batch [350]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.151808,	
2017-06-24 12:55:03,977 Epoch[7] Batch [360]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.151761,	
2017-06-24 12:55:10,994 Epoch[7] Batch [370]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.151686,	
2017-06-24 12:55:17,992 Epoch[7] Batch [380]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.151892,	
2017-06-24 12:55:25,294 Epoch[7] Batch [390]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.151658,	
2017-06-24 12:55:32,730 Epoch[7] Batch [400]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.151535,	
2017-06-24 12:55:39,882 Epoch[7] Batch [410]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.151457,	
2017-06-24 12:55:46,819 Epoch[7] Batch [420]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.151498,	
2017-06-24 12:55:53,909 Epoch[7] Batch [430]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.151202,	
2017-06-24 12:56:01,300 Epoch[7] Batch [440]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.151066,	
2017-06-24 12:56:08,266 Epoch[7] Batch [450]	Speed: 11.48 samples/sec	Train-FCNLogLoss=0.151097,	
2017-06-24 12:56:15,342 Epoch[7] Batch [460]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.150909,	
2017-06-24 12:56:22,318 Epoch[7] Batch [470]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.151285,	
2017-06-24 12:56:29,881 Epoch[7] Batch [480]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.151845,	
2017-06-24 12:56:36,878 Epoch[7] Batch [490]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.152393,	
2017-06-24 12:56:44,116 Epoch[7] Batch [500]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.152828,	
2017-06-24 12:56:51,378 Epoch[7] Batch [510]	Speed: 11.02 samples/sec	Train-FCNLogLoss=0.153166,	
2017-06-24 12:56:58,438 Epoch[7] Batch [520]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.153099,	
2017-06-24 12:57:05,873 Epoch[7] Batch [530]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.153462,	
2017-06-24 12:57:12,882 Epoch[7] Batch [540]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.153583,	
2017-06-24 12:57:19,918 Epoch[7] Batch [550]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.153702,	
2017-06-24 12:57:29,513 Epoch[7] Batch [560]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.154001,	
2017-06-24 12:57:40,333 Epoch[7] Batch [570]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.154001,	
2017-06-24 12:57:47,293 Epoch[7] Batch [580]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.154201,	
2017-06-24 12:57:54,623 Epoch[7] Batch [590]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.154421,	
2017-06-24 12:58:01,621 Epoch[7] Batch [600]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.154424,	
2017-06-24 12:58:08,533 Epoch[7] Batch [610]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.154286,	
2017-06-24 12:58:15,632 Epoch[7] Batch [620]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.154137,	
2017-06-24 12:58:22,810 Epoch[7] Batch [630]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.153765,	
2017-06-24 12:58:30,299 Epoch[7] Batch [640]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.153898,	
2017-06-24 12:58:37,651 Epoch[7] Batch [650]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.153788,	
2017-06-24 12:58:44,676 Epoch[7] Batch [660]	Speed: 11.39 samples/sec	Train-FCNLogLoss=0.153625,	
2017-06-24 12:58:51,848 Epoch[7] Batch [670]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.153717,	
2017-06-24 12:58:59,330 Epoch[7] Batch [680]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.153511,	
2017-06-24 12:59:06,365 Epoch[7] Batch [690]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.153812,	
2017-06-24 12:59:13,355 Epoch[7] Batch [700]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.154591,	
2017-06-24 12:59:20,895 Epoch[7] Batch [710]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.154670,	
2017-06-24 12:59:28,215 Epoch[7] Batch [720]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.154908,	
2017-06-24 12:59:35,249 Epoch[7] Batch [730]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.154969,	
2017-06-24 12:59:42,150 Epoch[7] Batch [740]	Speed: 11.59 samples/sec	Train-FCNLogLoss=0.154745,	
2017-06-24 12:59:43,438 Epoch[7] Train-FCNLogLoss=0.154693
2017-06-24 12:59:43,438 Epoch[7] Time cost=539.081
2017-06-24 12:59:45,010 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0008.params"
2017-06-24 12:59:46,720 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0008.states"
2017-06-24 12:59:55,157 Epoch[8] Batch [10]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.138539,	
2017-06-24 13:00:02,103 Epoch[8] Batch [20]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.143306,	
2017-06-24 13:00:09,648 Epoch[8] Batch [30]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.140784,	
2017-06-24 13:00:16,824 Epoch[8] Batch [40]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.141447,	
2017-06-24 13:00:23,935 Epoch[8] Batch [50]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.142496,	
2017-06-24 13:00:30,994 Epoch[8] Batch [60]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.144094,	
2017-06-24 13:00:38,387 Epoch[8] Batch [70]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.146929,	
2017-06-24 13:00:45,701 Epoch[8] Batch [80]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.147134,	
2017-06-24 13:00:52,806 Epoch[8] Batch [90]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.147029,	
2017-06-24 13:01:00,083 Epoch[8] Batch [100]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.146361,	
2017-06-24 13:01:07,484 Epoch[8] Batch [110]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.147035,	
2017-06-24 13:01:14,543 Epoch[8] Batch [120]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.147066,	
2017-06-24 13:01:21,513 Epoch[8] Batch [130]	Speed: 11.48 samples/sec	Train-FCNLogLoss=0.147780,	
2017-06-24 13:01:28,986 Epoch[8] Batch [140]	Speed: 10.71 samples/sec	Train-FCNLogLoss=0.147473,	
2017-06-24 13:01:36,061 Epoch[8] Batch [150]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.146956,	
2017-06-24 13:01:43,557 Epoch[8] Batch [160]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.146969,	
2017-06-24 13:01:50,577 Epoch[8] Batch [170]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.147130,	
2017-06-24 13:01:57,801 Epoch[8] Batch [180]	Speed: 11.08 samples/sec	Train-FCNLogLoss=0.147524,	
2017-06-24 13:02:05,024 Epoch[8] Batch [190]	Speed: 11.08 samples/sec	Train-FCNLogLoss=0.147236,	
2017-06-24 13:02:12,378 Epoch[8] Batch [200]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.147997,	
2017-06-24 13:02:19,545 Epoch[8] Batch [210]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.147468,	
2017-06-24 13:02:27,049 Epoch[8] Batch [220]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.148218,	
2017-06-24 13:02:34,243 Epoch[8] Batch [230]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.148728,	
2017-06-24 13:02:41,208 Epoch[8] Batch [240]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.149155,	
2017-06-24 13:02:48,590 Epoch[8] Batch [250]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.149120,	
2017-06-24 13:02:55,814 Epoch[8] Batch [260]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.149621,	
2017-06-24 13:03:03,260 Epoch[8] Batch [270]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.149479,	
2017-06-24 13:03:10,241 Epoch[8] Batch [280]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.149692,	
2017-06-24 13:03:17,031 Epoch[8] Batch [290]	Speed: 11.78 samples/sec	Train-FCNLogLoss=0.149100,	
2017-06-24 13:03:24,267 Epoch[8] Batch [300]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.148956,	
2017-06-24 13:03:31,560 Epoch[8] Batch [310]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.148636,	
2017-06-24 13:03:38,608 Epoch[8] Batch [320]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.148496,	
2017-06-24 13:03:45,650 Epoch[8] Batch [330]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.148577,	
2017-06-24 13:03:52,895 Epoch[8] Batch [340]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.148641,	
2017-06-24 13:04:00,401 Epoch[8] Batch [350]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.148825,	
2017-06-24 13:04:07,585 Epoch[8] Batch [360]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.148868,	
2017-06-24 13:04:14,646 Epoch[8] Batch [370]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.149203,	
2017-06-24 13:04:21,737 Epoch[8] Batch [380]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.149375,	
2017-06-24 13:04:29,146 Epoch[8] Batch [390]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.149197,	
2017-06-24 13:04:36,153 Epoch[8] Batch [400]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.149345,	
2017-06-24 13:04:43,263 Epoch[8] Batch [410]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.149334,	
2017-06-24 13:04:50,178 Epoch[8] Batch [420]	Speed: 11.57 samples/sec	Train-FCNLogLoss=0.149498,	
2017-06-24 13:04:57,514 Epoch[8] Batch [430]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.149310,	
2017-06-24 13:05:04,678 Epoch[8] Batch [440]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.149144,	
2017-06-24 13:05:11,785 Epoch[8] Batch [450]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.149352,	
2017-06-24 13:05:19,325 Epoch[8] Batch [460]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.149931,	
2017-06-24 13:05:26,194 Epoch[8] Batch [470]	Speed: 11.65 samples/sec	Train-FCNLogLoss=0.149895,	
2017-06-24 13:05:33,360 Epoch[8] Batch [480]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.150141,	
2017-06-24 13:05:40,728 Epoch[8] Batch [490]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.150082,	
2017-06-24 13:05:47,744 Epoch[8] Batch [500]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.150305,	
2017-06-24 13:05:55,297 Epoch[8] Batch [510]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.150203,	
2017-06-24 13:06:02,308 Epoch[8] Batch [520]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.150274,	
2017-06-24 13:06:09,533 Epoch[8] Batch [530]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.150279,	
2017-06-24 13:06:16,810 Epoch[8] Batch [540]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.150389,	
2017-06-24 13:06:23,901 Epoch[8] Batch [550]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.150283,	
2017-06-24 13:06:30,979 Epoch[8] Batch [560]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.150214,	
2017-06-24 13:06:38,284 Epoch[8] Batch [570]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.150380,	
2017-06-24 13:06:45,769 Epoch[8] Batch [580]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.150315,	
2017-06-24 13:06:53,100 Epoch[8] Batch [590]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.150160,	
2017-06-24 13:07:00,323 Epoch[8] Batch [600]	Speed: 11.08 samples/sec	Train-FCNLogLoss=0.149794,	
2017-06-24 13:07:07,389 Epoch[8] Batch [610]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.149676,	
2017-06-24 13:07:14,530 Epoch[8] Batch [620]	Speed: 11.20 samples/sec	Train-FCNLogLoss=0.149574,	
2017-06-24 13:07:21,512 Epoch[8] Batch [630]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.149394,	
2017-06-24 13:07:28,707 Epoch[8] Batch [640]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.149254,	
2017-06-24 13:07:38,951 Epoch[8] Batch [650]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.149328,	
2017-06-24 13:07:48,641 Epoch[8] Batch [660]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.149158,	
2017-06-24 13:07:55,961 Epoch[8] Batch [670]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.148962,	
2017-06-24 13:08:03,127 Epoch[8] Batch [680]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.149204,	
2017-06-24 13:08:10,193 Epoch[8] Batch [690]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.149160,	
2017-06-24 13:08:17,561 Epoch[8] Batch [700]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.149136,	
2017-06-24 13:08:24,831 Epoch[8] Batch [710]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.149080,	
2017-06-24 13:08:31,847 Epoch[8] Batch [720]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.149072,	
2017-06-24 13:08:39,236 Epoch[8] Batch [730]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.148907,	
2017-06-24 13:08:46,267 Epoch[8] Batch [740]	Speed: 11.38 samples/sec	Train-FCNLogLoss=0.148827,	
2017-06-24 13:08:47,617 Epoch[8] Train-FCNLogLoss=0.148793
2017-06-24 13:08:47,617 Epoch[8] Time cost=540.897
2017-06-24 13:08:49,087 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0009.params"
2017-06-24 13:08:51,017 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0009.states"
2017-06-24 13:08:59,651 Epoch[9] Batch [10]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.130286,	
2017-06-24 13:09:06,646 Epoch[9] Batch [20]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.136163,	
2017-06-24 13:09:13,687 Epoch[9] Batch [30]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.139419,	
2017-06-24 13:09:20,609 Epoch[9] Batch [40]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.140895,	
2017-06-24 13:09:27,851 Epoch[9] Batch [50]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.138841,	
2017-06-24 13:09:35,225 Epoch[9] Batch [60]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.141559,	
2017-06-24 13:09:42,340 Epoch[9] Batch [70]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.140730,	
2017-06-24 13:09:49,703 Epoch[9] Batch [80]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.141469,	
2017-06-24 13:09:56,805 Epoch[9] Batch [90]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.142576,	
2017-06-24 13:10:03,723 Epoch[9] Batch [100]	Speed: 11.56 samples/sec	Train-FCNLogLoss=0.143783,	
2017-06-24 13:10:11,043 Epoch[9] Batch [110]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.144772,	
2017-06-24 13:10:18,230 Epoch[9] Batch [120]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.144692,	
2017-06-24 13:10:25,220 Epoch[9] Batch [130]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.144387,	
2017-06-24 13:10:32,457 Epoch[9] Batch [140]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.144316,	
2017-06-24 13:10:39,712 Epoch[9] Batch [150]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.144077,	
2017-06-24 13:10:46,702 Epoch[9] Batch [160]	Speed: 11.45 samples/sec	Train-FCNLogLoss=0.143674,	
2017-06-24 13:10:53,753 Epoch[9] Batch [170]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.143549,	
2017-06-24 13:11:01,290 Epoch[9] Batch [180]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.143410,	
2017-06-24 13:11:08,352 Epoch[9] Batch [190]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.144170,	
2017-06-24 13:11:15,801 Epoch[9] Batch [200]	Speed: 10.74 samples/sec	Train-FCNLogLoss=0.143700,	
2017-06-24 13:11:22,878 Epoch[9] Batch [210]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.143927,	
2017-06-24 13:11:30,121 Epoch[9] Batch [220]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.143703,	
2017-06-24 13:11:37,257 Epoch[9] Batch [230]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.143553,	
2017-06-24 13:11:44,112 Epoch[9] Batch [240]	Speed: 11.67 samples/sec	Train-FCNLogLoss=0.142699,	
2017-06-24 13:11:51,201 Epoch[9] Batch [250]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.142314,	
2017-06-24 13:11:58,205 Epoch[9] Batch [260]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.142044,	
2017-06-24 13:12:05,388 Epoch[9] Batch [270]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.142125,	
2017-06-24 13:12:12,432 Epoch[9] Batch [280]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.141954,	
2017-06-24 13:12:19,566 Epoch[9] Batch [290]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.142276,	
2017-06-24 13:12:27,061 Epoch[9] Batch [300]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.142345,	
2017-06-24 13:12:34,471 Epoch[9] Batch [310]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.142144,	
2017-06-24 13:12:41,558 Epoch[9] Batch [320]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.142018,	
2017-06-24 13:12:48,555 Epoch[9] Batch [330]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.141928,	
2017-06-24 13:12:55,870 Epoch[9] Batch [340]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.142071,	
2017-06-24 13:13:03,304 Epoch[9] Batch [350]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.141951,	
2017-06-24 13:13:10,267 Epoch[9] Batch [360]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.142383,	
2017-06-24 13:13:17,374 Epoch[9] Batch [370]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.142461,	
2017-06-24 13:13:24,738 Epoch[9] Batch [380]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.142452,	
2017-06-24 13:13:31,849 Epoch[9] Batch [390]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.142373,	
2017-06-24 13:13:38,917 Epoch[9] Batch [400]	Speed: 11.32 samples/sec	Train-FCNLogLoss=0.142431,	
2017-06-24 13:13:46,282 Epoch[9] Batch [410]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.142207,	
2017-06-24 13:13:53,193 Epoch[9] Batch [420]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.142578,	
2017-06-24 13:14:00,147 Epoch[9] Batch [430]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.143240,	
2017-06-24 13:14:07,056 Epoch[9] Batch [440]	Speed: 11.58 samples/sec	Train-FCNLogLoss=0.144001,	
2017-06-24 13:14:14,169 Epoch[9] Batch [450]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.144603,	
2017-06-24 13:14:21,682 Epoch[9] Batch [460]	Speed: 10.65 samples/sec	Train-FCNLogLoss=0.144646,	
2017-06-24 13:14:28,775 Epoch[9] Batch [470]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.144740,	
2017-06-24 13:14:35,856 Epoch[9] Batch [480]	Speed: 11.30 samples/sec	Train-FCNLogLoss=0.144849,	
2017-06-24 13:14:42,926 Epoch[9] Batch [490]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.145167,	
2017-06-24 13:14:50,168 Epoch[9] Batch [500]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.144771,	
2017-06-24 13:14:57,361 Epoch[9] Batch [510]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.144660,	
2017-06-24 13:15:04,378 Epoch[9] Batch [520]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.144535,	
2017-06-24 13:15:11,314 Epoch[9] Batch [530]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.144547,	
2017-06-24 13:15:18,522 Epoch[9] Batch [540]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.144404,	
2017-06-24 13:15:25,721 Epoch[9] Batch [550]	Speed: 11.11 samples/sec	Train-FCNLogLoss=0.144314,	
2017-06-24 13:15:32,726 Epoch[9] Batch [560]	Speed: 11.42 samples/sec	Train-FCNLogLoss=0.144254,	
2017-06-24 13:15:40,157 Epoch[9] Batch [570]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.143902,	
2017-06-24 13:15:47,363 Epoch[9] Batch [580]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.143894,	
2017-06-24 13:15:54,491 Epoch[9] Batch [590]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.144076,	
2017-06-24 13:16:01,877 Epoch[9] Batch [600]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.143878,	
2017-06-24 13:16:09,143 Epoch[9] Batch [610]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.143893,	
2017-06-24 13:16:16,309 Epoch[9] Batch [620]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.143832,	
2017-06-24 13:16:23,411 Epoch[9] Batch [630]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.144238,	
2017-06-24 13:16:30,716 Epoch[9] Batch [640]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.144281,	
2017-06-24 13:16:37,891 Epoch[9] Batch [650]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.144352,	
2017-06-24 13:16:44,965 Epoch[9] Batch [660]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.144232,	
2017-06-24 13:16:52,498 Epoch[9] Batch [670]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.144318,	
2017-06-24 13:16:59,537 Epoch[9] Batch [680]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.144283,	
2017-06-24 13:17:06,435 Epoch[9] Batch [690]	Speed: 11.60 samples/sec	Train-FCNLogLoss=0.144236,	
2017-06-24 13:17:13,636 Epoch[9] Batch [700]	Speed: 11.11 samples/sec	Train-FCNLogLoss=0.144117,	
2017-06-24 13:17:20,972 Epoch[9] Batch [710]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.144024,	
2017-06-24 13:17:27,922 Epoch[9] Batch [720]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.143843,	
2017-06-24 13:17:35,405 Epoch[9] Batch [730]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.143737,	
2017-06-24 13:17:42,381 Epoch[9] Batch [740]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.143668,	
2017-06-24 13:17:43,727 Epoch[9] Train-FCNLogLoss=0.143704
2017-06-24 13:17:43,728 Epoch[9] Time cost=532.710
2017-06-24 13:17:45,200 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0010.params"
2017-06-24 13:17:47,101 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0010.states"
2017-06-24 13:17:59,432 Epoch[10] Batch [10]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.140596,	
2017-06-24 13:18:08,372 Epoch[10] Batch [20]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.144809,	
2017-06-24 13:18:15,534 Epoch[10] Batch [30]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.139182,	
2017-06-24 13:18:22,491 Epoch[10] Batch [40]	Speed: 11.50 samples/sec	Train-FCNLogLoss=0.138411,	
2017-06-24 13:18:29,660 Epoch[10] Batch [50]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.136789,	
2017-06-24 13:18:36,866 Epoch[10] Batch [60]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.137002,	
2017-06-24 13:18:44,233 Epoch[10] Batch [70]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.137684,	
2017-06-24 13:18:51,179 Epoch[10] Batch [80]	Speed: 11.52 samples/sec	Train-FCNLogLoss=0.138422,	
2017-06-24 13:18:58,117 Epoch[10] Batch [90]	Speed: 11.53 samples/sec	Train-FCNLogLoss=0.138955,	
2017-06-24 13:19:05,413 Epoch[10] Batch [100]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.139541,	
2017-06-24 13:19:12,898 Epoch[10] Batch [110]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.140375,	
2017-06-24 13:19:20,051 Epoch[10] Batch [120]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.140435,	
2017-06-24 13:19:27,100 Epoch[10] Batch [130]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.139938,	
2017-06-24 13:19:34,438 Epoch[10] Batch [140]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.140623,	
2017-06-24 13:19:41,676 Epoch[10] Batch [150]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.140161,	
2017-06-24 13:19:48,722 Epoch[10] Batch [160]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.139688,	
2017-06-24 13:19:55,733 Epoch[10] Batch [170]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.140324,	
2017-06-24 13:20:02,880 Epoch[10] Batch [180]	Speed: 11.19 samples/sec	Train-FCNLogLoss=0.139678,	
2017-06-24 13:20:10,249 Epoch[10] Batch [190]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.140093,	
2017-06-24 13:20:17,356 Epoch[10] Batch [200]	Speed: 11.26 samples/sec	Train-FCNLogLoss=0.140337,	
2017-06-24 13:20:24,836 Epoch[10] Batch [210]	Speed: 10.70 samples/sec	Train-FCNLogLoss=0.141476,	
2017-06-24 13:20:31,693 Epoch[10] Batch [220]	Speed: 11.67 samples/sec	Train-FCNLogLoss=0.140953,	
2017-06-24 13:20:39,229 Epoch[10] Batch [230]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.140981,	
2017-06-24 13:20:46,481 Epoch[10] Batch [240]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.141806,	
2017-06-24 13:20:53,494 Epoch[10] Batch [250]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.142050,	
2017-06-24 13:21:00,588 Epoch[10] Batch [260]	Speed: 11.28 samples/sec	Train-FCNLogLoss=0.142255,	
2017-06-24 13:21:07,721 Epoch[10] Batch [270]	Speed: 11.22 samples/sec	Train-FCNLogLoss=0.141981,	
2017-06-24 13:21:15,016 Epoch[10] Batch [280]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.141585,	
2017-06-24 13:21:22,009 Epoch[10] Batch [290]	Speed: 11.44 samples/sec	Train-FCNLogLoss=0.141595,	
2017-06-24 13:21:29,068 Epoch[10] Batch [300]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.141884,	
2017-06-24 13:21:36,116 Epoch[10] Batch [310]	Speed: 11.35 samples/sec	Train-FCNLogLoss=0.142291,	
2017-06-24 13:21:43,307 Epoch[10] Batch [320]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.142425,	
2017-06-24 13:21:50,727 Epoch[10] Batch [330]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.142221,	
2017-06-24 13:21:57,744 Epoch[10] Batch [340]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.141891,	
2017-06-24 13:22:05,080 Epoch[10] Batch [350]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.141549,	
2017-06-24 13:22:12,433 Epoch[10] Batch [360]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.141506,	
2017-06-24 13:22:19,434 Epoch[10] Batch [370]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.141202,	
2017-06-24 13:22:26,495 Epoch[10] Batch [380]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.140924,	
2017-06-24 13:22:33,672 Epoch[10] Batch [390]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.141563,	
2017-06-24 13:22:41,019 Epoch[10] Batch [400]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.141639,	
2017-06-24 13:22:48,562 Epoch[10] Batch [410]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.141466,	
2017-06-24 13:22:55,853 Epoch[10] Batch [420]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.141450,	
2017-06-24 13:23:02,866 Epoch[10] Batch [430]	Speed: 11.41 samples/sec	Train-FCNLogLoss=0.141454,	
2017-06-24 13:23:09,886 Epoch[10] Batch [440]	Speed: 11.40 samples/sec	Train-FCNLogLoss=0.141372,	
2017-06-24 13:23:17,507 Epoch[10] Batch [450]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.141465,	
2017-06-24 13:23:24,762 Epoch[10] Batch [460]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.141492,	
2017-06-24 13:23:32,052 Epoch[10] Batch [470]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.141688,	
2017-06-24 13:23:39,088 Epoch[10] Batch [480]	Speed: 11.37 samples/sec	Train-FCNLogLoss=0.141777,	
2017-06-24 13:23:46,451 Epoch[10] Batch [490]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.141937,	
2017-06-24 13:23:53,576 Epoch[10] Batch [500]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.141878,	
2017-06-24 13:24:00,993 Epoch[10] Batch [510]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.141995,	
2017-06-24 13:24:08,169 Epoch[10] Batch [520]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.141795,	
2017-06-24 13:24:15,166 Epoch[10] Batch [530]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.141688,	
2017-06-24 13:24:22,304 Epoch[10] Batch [540]	Speed: 11.21 samples/sec	Train-FCNLogLoss=0.141322,	
2017-06-24 13:24:29,881 Epoch[10] Batch [550]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.141267,	
2017-06-24 13:24:37,078 Epoch[10] Batch [560]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.141435,	
2017-06-24 13:24:44,259 Epoch[10] Batch [570]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.141511,	
2017-06-24 13:24:51,529 Epoch[10] Batch [580]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.141323,	
2017-06-24 13:24:58,583 Epoch[10] Batch [590]	Speed: 11.34 samples/sec	Train-FCNLogLoss=0.141316,	
2017-06-24 13:25:05,706 Epoch[10] Batch [600]	Speed: 11.23 samples/sec	Train-FCNLogLoss=0.141216,	
2017-06-24 13:25:13,025 Epoch[10] Batch [610]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.140972,	
2017-06-24 13:25:20,225 Epoch[10] Batch [620]	Speed: 11.11 samples/sec	Train-FCNLogLoss=0.141151,	
2017-06-24 13:25:27,451 Epoch[10] Batch [630]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.141187,	
2017-06-24 13:25:34,618 Epoch[10] Batch [640]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.141370,	
2017-06-24 13:25:41,679 Epoch[10] Batch [650]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.141318,	
2017-06-24 13:25:48,722 Epoch[10] Batch [660]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.141245,	
2017-06-24 13:25:55,952 Epoch[10] Batch [670]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.141214,	
2017-06-24 13:26:03,308 Epoch[10] Batch [680]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.141137,	
2017-06-24 13:26:10,901 Epoch[10] Batch [690]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.141101,	
2017-06-24 13:26:18,238 Epoch[10] Batch [700]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.141074,	
2017-06-24 13:26:25,963 Epoch[10] Batch [710]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.140874,	
2017-06-24 13:26:33,270 Epoch[10] Batch [720]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.140814,	
2017-06-24 13:26:40,267 Epoch[10] Batch [730]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.140683,	
2017-06-24 13:26:47,511 Epoch[10] Batch [740]	Speed: 11.05 samples/sec	Train-FCNLogLoss=0.140598,	
2017-06-24 13:26:48,816 Epoch[10] Train-FCNLogLoss=0.140591
2017-06-24 13:26:48,816 Epoch[10] Time cost=541.714
2017-06-24 13:26:50,835 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0011.params"
2017-06-24 13:26:53,959 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0011.states"
2017-06-24 13:27:02,604 Epoch[11] Batch [10]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.154147,	
2017-06-24 13:27:09,993 Epoch[11] Batch [20]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.142905,	
2017-06-24 13:27:16,994 Epoch[11] Batch [30]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.139470,	
2017-06-24 13:27:24,375 Epoch[11] Batch [40]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.137330,	
2017-06-24 13:27:31,804 Epoch[11] Batch [50]	Speed: 10.77 samples/sec	Train-FCNLogLoss=0.134637,	
2017-06-24 13:27:39,114 Epoch[11] Batch [60]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.135479,	
2017-06-24 13:27:47,313 Epoch[11] Batch [70]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.134298,	
2017-06-24 13:27:59,041 Epoch[11] Batch [80]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.134682,	
2017-06-24 13:28:06,730 Epoch[11] Batch [90]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.135304,	
2017-06-24 13:28:14,463 Epoch[11] Batch [100]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.138084,	
2017-06-24 13:28:21,927 Epoch[11] Batch [110]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.137847,	
2017-06-24 13:28:29,205 Epoch[11] Batch [120]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.137930,	
2017-06-24 13:28:36,384 Epoch[11] Batch [130]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.138774,	
2017-06-24 13:28:43,538 Epoch[11] Batch [140]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.139612,	
2017-06-24 13:28:50,956 Epoch[11] Batch [150]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.139467,	
2017-06-24 13:28:58,121 Epoch[11] Batch [160]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.139039,	
2017-06-24 13:29:05,319 Epoch[11] Batch [170]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.138201,	
2017-06-24 13:29:12,554 Epoch[11] Batch [180]	Speed: 11.06 samples/sec	Train-FCNLogLoss=0.137473,	
2017-06-24 13:29:19,665 Epoch[11] Batch [190]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.137479,	
2017-06-24 13:29:27,187 Epoch[11] Batch [200]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.138403,	
2017-06-24 13:29:34,459 Epoch[11] Batch [210]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.138233,	
2017-06-24 13:29:41,519 Epoch[11] Batch [220]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.138423,	
2017-06-24 13:29:48,731 Epoch[11] Batch [230]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.138291,	
2017-06-24 13:29:55,683 Epoch[11] Batch [240]	Speed: 11.51 samples/sec	Train-FCNLogLoss=0.138934,	
2017-06-24 13:30:03,038 Epoch[11] Batch [250]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.138743,	
2017-06-24 13:30:10,562 Epoch[11] Batch [260]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.138635,	
2017-06-24 13:30:18,113 Epoch[11] Batch [270]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.139081,	
2017-06-24 13:30:25,444 Epoch[11] Batch [280]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.139548,	
2017-06-24 13:30:33,003 Epoch[11] Batch [290]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.139705,	
2017-06-24 13:30:40,340 Epoch[11] Batch [300]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.139760,	
2017-06-24 13:30:47,315 Epoch[11] Batch [310]	Speed: 11.47 samples/sec	Train-FCNLogLoss=0.139866,	
2017-06-24 13:30:54,561 Epoch[11] Batch [320]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.139818,	
2017-06-24 13:31:01,893 Epoch[11] Batch [330]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.139585,	
2017-06-24 13:31:08,922 Epoch[11] Batch [340]	Speed: 11.38 samples/sec	Train-FCNLogLoss=0.139487,	
2017-06-24 13:31:16,255 Epoch[11] Batch [350]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.139398,	
2017-06-24 13:31:23,565 Epoch[11] Batch [360]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.139236,	
2017-06-24 13:31:30,663 Epoch[11] Batch [370]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.138941,	
2017-06-24 13:31:37,940 Epoch[11] Batch [380]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.138765,	
2017-06-24 13:31:45,193 Epoch[11] Batch [390]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.138528,	
2017-06-24 13:31:52,303 Epoch[11] Batch [400]	Speed: 11.25 samples/sec	Train-FCNLogLoss=0.138335,	
2017-06-24 13:31:59,847 Epoch[11] Batch [410]	Speed: 10.61 samples/sec	Train-FCNLogLoss=0.137988,	
2017-06-24 13:32:07,239 Epoch[11] Batch [420]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.137769,	
2017-06-24 13:32:14,547 Epoch[11] Batch [430]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.137521,	
2017-06-24 13:32:22,210 Epoch[11] Batch [440]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.137448,	
2017-06-24 13:32:29,253 Epoch[11] Batch [450]	Speed: 11.36 samples/sec	Train-FCNLogLoss=0.137517,	
2017-06-24 13:32:36,432 Epoch[11] Batch [460]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.137169,	
2017-06-24 13:32:43,840 Epoch[11] Batch [470]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.137046,	
2017-06-24 13:32:50,925 Epoch[11] Batch [480]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.137071,	
2017-06-24 13:32:58,286 Epoch[11] Batch [490]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.137041,	
2017-06-24 13:33:05,637 Epoch[11] Batch [500]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.136706,	
2017-06-24 13:33:12,794 Epoch[11] Batch [510]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.136505,	
2017-06-24 13:33:19,913 Epoch[11] Batch [520]	Speed: 11.24 samples/sec	Train-FCNLogLoss=0.136328,	
2017-06-24 13:33:27,140 Epoch[11] Batch [530]	Speed: 11.07 samples/sec	Train-FCNLogLoss=0.136142,	
2017-06-24 13:33:34,563 Epoch[11] Batch [540]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.136049,	
2017-06-24 13:33:41,737 Epoch[11] Batch [550]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.135972,	
2017-06-24 13:33:48,890 Epoch[11] Batch [560]	Speed: 11.18 samples/sec	Train-FCNLogLoss=0.135972,	
2017-06-24 13:33:55,856 Epoch[11] Batch [570]	Speed: 11.49 samples/sec	Train-FCNLogLoss=0.135893,	
2017-06-24 13:34:03,281 Epoch[11] Batch [580]	Speed: 10.78 samples/sec	Train-FCNLogLoss=0.135507,	
2017-06-24 13:34:10,827 Epoch[11] Batch [590]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.135776,	
2017-06-24 13:34:18,352 Epoch[11] Batch [600]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.135702,	
2017-06-24 13:34:25,526 Epoch[11] Batch [610]	Speed: 11.15 samples/sec	Train-FCNLogLoss=0.135557,	
2017-06-24 13:34:32,804 Epoch[11] Batch [620]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.135251,	
2017-06-24 13:34:39,975 Epoch[11] Batch [630]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.135201,	
2017-06-24 13:34:47,339 Epoch[11] Batch [640]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.135183,	
2017-06-24 13:34:54,680 Epoch[11] Batch [650]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.135237,	
2017-06-24 13:35:01,880 Epoch[11] Batch [660]	Speed: 11.11 samples/sec	Train-FCNLogLoss=0.135208,	
2017-06-24 13:35:08,881 Epoch[11] Batch [670]	Speed: 11.43 samples/sec	Train-FCNLogLoss=0.135144,	
2017-06-24 13:35:16,213 Epoch[11] Batch [680]	Speed: 10.91 samples/sec	Train-FCNLogLoss=0.135076,	
2017-06-24 13:35:23,302 Epoch[11] Batch [690]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.134796,	
2017-06-24 13:35:30,790 Epoch[11] Batch [700]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.134832,	
2017-06-24 13:35:38,193 Epoch[11] Batch [710]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.134815,	
2017-06-24 13:35:45,637 Epoch[11] Batch [720]	Speed: 10.75 samples/sec	Train-FCNLogLoss=0.134885,	
2017-06-24 13:35:53,051 Epoch[11] Batch [730]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.134906,	
2017-06-24 13:36:00,458 Epoch[11] Batch [740]	Speed: 10.80 samples/sec	Train-FCNLogLoss=0.134958,	
2017-06-24 13:36:01,782 Epoch[11] Train-FCNLogLoss=0.134974
2017-06-24 13:36:01,783 Epoch[11] Time cost=547.823
2017-06-24 13:36:04,090 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0012.params"
2017-06-24 13:36:07,015 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0012.states"
2017-06-24 13:36:15,620 Epoch[12] Batch [10]	Speed: 11.13 samples/sec	Train-FCNLogLoss=0.145048,	
2017-06-24 13:36:22,695 Epoch[12] Batch [20]	Speed: 11.31 samples/sec	Train-FCNLogLoss=0.135338,	
2017-06-24 13:36:30,154 Epoch[12] Batch [30]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.136478,	
2017-06-24 13:36:37,368 Epoch[12] Batch [40]	Speed: 11.09 samples/sec	Train-FCNLogLoss=0.130915,	
2017-06-24 13:36:45,083 Epoch[12] Batch [50]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.130619,	
2017-06-24 13:36:52,470 Epoch[12] Batch [60]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.130479,	
2017-06-24 13:37:00,101 Epoch[12] Batch [70]	Speed: 10.48 samples/sec	Train-FCNLogLoss=0.131272,	
2017-06-24 13:37:07,451 Epoch[12] Batch [80]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.129963,	
2017-06-24 13:37:14,503 Epoch[12] Batch [90]	Speed: 11.38 samples/sec	Train-FCNLogLoss=0.130611,	
2017-06-24 13:37:24,764 Epoch[12] Batch [100]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.131126,	
2017-06-24 13:37:34,521 Epoch[12] Batch [110]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.130562,	
2017-06-24 13:37:41,681 Epoch[12] Batch [120]	Speed: 11.17 samples/sec	Train-FCNLogLoss=0.130092,	
2017-06-24 13:37:49,053 Epoch[12] Batch [130]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.129320,	
2017-06-24 13:37:56,519 Epoch[12] Batch [140]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.129176,	
2017-06-24 13:38:03,958 Epoch[12] Batch [150]	Speed: 10.76 samples/sec	Train-FCNLogLoss=0.129896,	
2017-06-24 13:38:11,417 Epoch[12] Batch [160]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.129462,	
2017-06-24 13:38:18,899 Epoch[12] Batch [170]	Speed: 10.69 samples/sec	Train-FCNLogLoss=0.129425,	
2017-06-24 13:38:26,300 Epoch[12] Batch [180]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.129029,	
2017-06-24 13:38:33,718 Epoch[12] Batch [190]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.129301,	
2017-06-24 13:38:41,039 Epoch[12] Batch [200]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.129361,	
2017-06-24 13:38:48,882 Epoch[12] Batch [210]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.129320,	
2017-06-24 13:38:56,597 Epoch[12] Batch [220]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.129854,	
2017-06-24 13:39:03,917 Epoch[12] Batch [230]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.130489,	
2017-06-24 13:39:11,527 Epoch[12] Batch [240]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.130599,	
2017-06-24 13:39:19,083 Epoch[12] Batch [250]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.130468,	
2017-06-24 13:39:26,541 Epoch[12] Batch [260]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.130914,	
2017-06-24 13:39:34,206 Epoch[12] Batch [270]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.130587,	
2017-06-24 13:39:41,922 Epoch[12] Batch [280]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.130995,	
2017-06-24 13:39:49,470 Epoch[12] Batch [290]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.131036,	
2017-06-24 13:39:56,757 Epoch[12] Batch [300]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.131787,	
2017-06-24 13:40:04,463 Epoch[12] Batch [310]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.131709,	
2017-06-24 13:40:12,190 Epoch[12] Batch [320]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.131714,	
2017-06-24 13:40:19,786 Epoch[12] Batch [330]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.131787,	
2017-06-24 13:40:27,468 Epoch[12] Batch [340]	Speed: 10.41 samples/sec	Train-FCNLogLoss=0.131773,	
2017-06-24 13:40:35,066 Epoch[12] Batch [350]	Speed: 10.53 samples/sec	Train-FCNLogLoss=0.131571,	
2017-06-24 13:40:42,444 Epoch[12] Batch [360]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.131561,	
2017-06-24 13:40:49,717 Epoch[12] Batch [370]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.131425,	
2017-06-24 13:40:56,965 Epoch[12] Batch [380]	Speed: 11.04 samples/sec	Train-FCNLogLoss=0.131238,	
2017-06-24 13:41:04,720 Epoch[12] Batch [390]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.131445,	
2017-06-24 13:41:12,048 Epoch[12] Batch [400]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.131340,	
2017-06-24 13:41:19,649 Epoch[12] Batch [410]	Speed: 10.52 samples/sec	Train-FCNLogLoss=0.131222,	
2017-06-24 13:41:27,009 Epoch[12] Batch [420]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.131569,	
2017-06-24 13:41:34,497 Epoch[12] Batch [430]	Speed: 10.68 samples/sec	Train-FCNLogLoss=0.132164,	
2017-06-24 13:41:42,069 Epoch[12] Batch [440]	Speed: 10.57 samples/sec	Train-FCNLogLoss=0.131899,	
2017-06-24 13:41:49,392 Epoch[12] Batch [450]	Speed: 10.93 samples/sec	Train-FCNLogLoss=0.131749,	
2017-06-24 13:41:56,737 Epoch[12] Batch [460]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.131517,	
2017-06-24 13:42:04,141 Epoch[12] Batch [470]	Speed: 10.81 samples/sec	Train-FCNLogLoss=0.131566,	
2017-06-24 13:42:11,485 Epoch[12] Batch [480]	Speed: 10.89 samples/sec	Train-FCNLogLoss=0.131791,	
2017-06-24 13:42:18,694 Epoch[12] Batch [490]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.131545,	
2017-06-24 13:42:25,977 Epoch[12] Batch [500]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.131616,	
2017-06-24 13:42:33,540 Epoch[12] Batch [510]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.131571,	
2017-06-24 13:42:41,319 Epoch[12] Batch [520]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.131516,	
2017-06-24 13:42:49,048 Epoch[12] Batch [530]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.131620,	
2017-06-24 13:42:56,565 Epoch[12] Batch [540]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.131503,	
2017-06-24 13:43:04,352 Epoch[12] Batch [550]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.131508,	
2017-06-24 13:43:11,721 Epoch[12] Batch [560]	Speed: 10.86 samples/sec	Train-FCNLogLoss=0.131464,	
2017-06-24 13:43:21,021 Epoch[12] Batch [570]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.131437,	
2017-06-24 13:43:30,273 Epoch[12] Batch [580]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.131206,	
2017-06-24 13:43:37,553 Epoch[12] Batch [590]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.130990,	
2017-06-24 13:43:44,725 Epoch[12] Batch [600]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.131057,	
2017-06-24 13:43:52,081 Epoch[12] Batch [610]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.130821,	
2017-06-24 13:43:59,265 Epoch[12] Batch [620]	Speed: 11.14 samples/sec	Train-FCNLogLoss=0.130826,	
2017-06-24 13:44:07,005 Epoch[12] Batch [630]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.130964,	
2017-06-24 13:44:16,397 Epoch[12] Batch [640]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.131238,	
2017-06-24 13:44:27,012 Epoch[12] Batch [650]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.131572,	
2017-06-24 13:44:35,069 Epoch[12] Batch [660]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.131635,	
2017-06-24 13:44:43,710 Epoch[12] Batch [670]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.131657,	
2017-06-24 13:44:51,882 Epoch[12] Batch [680]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.131452,	
2017-06-24 13:45:00,590 Epoch[12] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.131638,	
2017-06-24 13:45:09,329 Epoch[12] Batch [700]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.131896,	
2017-06-24 13:45:18,666 Epoch[12] Batch [710]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.132088,	
2017-06-24 13:45:30,430 Epoch[12] Batch [720]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.132291,	
2017-06-24 13:45:39,710 Epoch[12] Batch [730]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.132268,	
2017-06-24 13:45:47,623 Epoch[12] Batch [740]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.132193,	
2017-06-24 13:45:49,300 Epoch[12] Train-FCNLogLoss=0.132225
2017-06-24 13:45:49,300 Epoch[12] Time cost=582.285
2017-06-24 13:45:52,460 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0013.params"
2017-06-24 13:45:56,245 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0013.states"
2017-06-24 13:46:07,886 Epoch[13] Batch [10]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.140485,	
2017-06-24 13:46:18,304 Epoch[13] Batch [20]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.136183,	
2017-06-24 13:46:27,043 Epoch[13] Batch [30]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.132188,	
2017-06-24 13:46:35,529 Epoch[13] Batch [40]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.134119,	
2017-06-24 13:46:44,793 Epoch[13] Batch [50]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.132113,	
2017-06-24 13:46:55,133 Epoch[13] Batch [60]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.130305,	
2017-06-24 13:47:05,376 Epoch[13] Batch [70]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.129184,	
2017-06-24 13:47:14,266 Epoch[13] Batch [80]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.128857,	
2017-06-24 13:47:23,101 Epoch[13] Batch [90]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.127660,	
2017-06-24 13:47:31,628 Epoch[13] Batch [100]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.127371,	
2017-06-24 13:47:40,247 Epoch[13] Batch [110]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.126992,	
2017-06-24 13:47:48,809 Epoch[13] Batch [120]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.127509,	
2017-06-24 13:47:57,375 Epoch[13] Batch [130]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.127178,	
2017-06-24 13:48:05,992 Epoch[13] Batch [140]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.127749,	
2017-06-24 13:48:13,493 Epoch[13] Batch [150]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.127566,	
2017-06-24 13:48:20,473 Epoch[13] Batch [160]	Speed: 11.46 samples/sec	Train-FCNLogLoss=0.128207,	
2017-06-24 13:48:27,825 Epoch[13] Batch [170]	Speed: 10.88 samples/sec	Train-FCNLogLoss=0.128499,	
2017-06-24 13:48:34,913 Epoch[13] Batch [180]	Speed: 11.29 samples/sec	Train-FCNLogLoss=0.129071,	
2017-06-24 13:48:42,571 Epoch[13] Batch [190]	Speed: 10.45 samples/sec	Train-FCNLogLoss=0.128870,	
2017-06-24 13:48:50,161 Epoch[13] Batch [200]	Speed: 10.54 samples/sec	Train-FCNLogLoss=0.129419,	
2017-06-24 13:48:58,575 Epoch[13] Batch [210]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.129650,	
2017-06-24 13:49:07,084 Epoch[13] Batch [220]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.129716,	
2017-06-24 13:49:15,470 Epoch[13] Batch [230]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.129889,	
2017-06-24 13:49:23,922 Epoch[13] Batch [240]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.129766,	
2017-06-24 13:49:32,319 Epoch[13] Batch [250]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.129856,	
2017-06-24 13:49:41,870 Epoch[13] Batch [260]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.129665,	
2017-06-24 13:49:51,669 Epoch[13] Batch [270]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.129611,	
2017-06-24 13:50:01,533 Epoch[13] Batch [280]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.128974,	
2017-06-24 13:50:11,674 Epoch[13] Batch [290]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.129012,	
2017-06-24 13:50:20,733 Epoch[13] Batch [300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.128633,	
2017-06-24 13:50:29,951 Epoch[13] Batch [310]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.128588,	
2017-06-24 13:50:39,176 Epoch[13] Batch [320]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.128748,	
2017-06-24 13:50:48,764 Epoch[13] Batch [330]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.128761,	
2017-06-24 13:51:00,301 Epoch[13] Batch [340]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.128793,	
2017-06-24 13:51:10,933 Epoch[13] Batch [350]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.128881,	
2017-06-24 13:51:21,531 Epoch[13] Batch [360]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.129210,	
2017-06-24 13:51:31,998 Epoch[13] Batch [370]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.129098,	
2017-06-24 13:51:42,103 Epoch[13] Batch [380]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.129084,	
2017-06-24 13:51:52,084 Epoch[13] Batch [390]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.128909,	
2017-06-24 13:52:01,727 Epoch[13] Batch [400]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.128765,	
2017-06-24 13:52:10,887 Epoch[13] Batch [410]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.129043,	
2017-06-24 13:52:19,427 Epoch[13] Batch [420]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.129351,	
2017-06-24 13:52:28,076 Epoch[13] Batch [430]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.129300,	
2017-06-24 13:52:36,906 Epoch[13] Batch [440]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.129368,	
2017-06-24 13:52:45,554 Epoch[13] Batch [450]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.129504,	
2017-06-24 13:52:53,847 Epoch[13] Batch [460]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.129503,	
2017-06-24 13:53:01,150 Epoch[13] Batch [470]	Speed: 10.96 samples/sec	Train-FCNLogLoss=0.129284,	
2017-06-24 13:53:08,211 Epoch[13] Batch [480]	Speed: 11.33 samples/sec	Train-FCNLogLoss=0.129362,	
2017-06-24 13:53:15,383 Epoch[13] Batch [490]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.129405,	
2017-06-24 13:53:22,485 Epoch[13] Batch [500]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.129447,	
2017-06-24 13:53:29,752 Epoch[13] Batch [510]	Speed: 11.01 samples/sec	Train-FCNLogLoss=0.129390,	
2017-06-24 13:53:36,958 Epoch[13] Batch [520]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.128991,	
2017-06-24 13:53:44,341 Epoch[13] Batch [530]	Speed: 10.84 samples/sec	Train-FCNLogLoss=0.128819,	
2017-06-24 13:53:51,560 Epoch[13] Batch [540]	Speed: 11.08 samples/sec	Train-FCNLogLoss=0.128799,	
2017-06-24 13:53:58,870 Epoch[13] Batch [550]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.128716,	
2017-06-24 13:54:06,125 Epoch[13] Batch [560]	Speed: 11.03 samples/sec	Train-FCNLogLoss=0.128832,	
2017-06-24 13:54:13,488 Epoch[13] Batch [570]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.128685,	
2017-06-24 13:54:21,007 Epoch[13] Batch [580]	Speed: 10.64 samples/sec	Train-FCNLogLoss=0.128748,	
2017-06-24 13:54:28,774 Epoch[13] Batch [590]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.128468,	
2017-06-24 13:54:36,079 Epoch[13] Batch [600]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.128500,	
2017-06-24 13:54:43,272 Epoch[13] Batch [610]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.128494,	
2017-06-24 13:54:50,917 Epoch[13] Batch [620]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.128512,	
2017-06-24 13:54:58,422 Epoch[13] Batch [630]	Speed: 10.66 samples/sec	Train-FCNLogLoss=0.129238,	
2017-06-24 13:55:05,524 Epoch[13] Batch [640]	Speed: 11.27 samples/sec	Train-FCNLogLoss=0.129903,	
2017-06-24 13:55:12,990 Epoch[13] Batch [650]	Speed: 10.72 samples/sec	Train-FCNLogLoss=0.130194,	
2017-06-24 13:55:20,347 Epoch[13] Batch [660]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.130688,	
2017-06-24 13:55:27,553 Epoch[13] Batch [670]	Speed: 11.10 samples/sec	Train-FCNLogLoss=0.130943,	
2017-06-24 13:55:34,928 Epoch[13] Batch [680]	Speed: 10.85 samples/sec	Train-FCNLogLoss=0.131229,	
2017-06-24 13:55:42,271 Epoch[13] Batch [690]	Speed: 10.90 samples/sec	Train-FCNLogLoss=0.131329,	
2017-06-24 13:55:49,548 Epoch[13] Batch [700]	Speed: 10.99 samples/sec	Train-FCNLogLoss=0.131508,	
2017-06-24 13:55:56,714 Epoch[13] Batch [710]	Speed: 11.16 samples/sec	Train-FCNLogLoss=0.131429,	
2017-06-24 13:56:04,075 Epoch[13] Batch [720]	Speed: 10.87 samples/sec	Train-FCNLogLoss=0.131613,	
2017-06-24 13:56:11,606 Epoch[13] Batch [730]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.131852,	
2017-06-24 13:56:19,003 Epoch[13] Batch [740]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.131853,	
2017-06-24 13:56:20,418 Epoch[13] Train-FCNLogLoss=0.131899
2017-06-24 13:56:20,418 Epoch[13] Time cost=624.173
2017-06-24 13:56:22,621 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0014.params"
2017-06-24 13:56:25,507 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0014.states"
2017-06-24 13:56:34,442 Epoch[14] Batch [10]	Speed: 10.73 samples/sec	Train-FCNLogLoss=0.138335,	
2017-06-24 13:56:42,016 Epoch[14] Batch [20]	Speed: 10.56 samples/sec	Train-FCNLogLoss=0.128847,	
2017-06-24 13:56:49,676 Epoch[14] Batch [30]	Speed: 10.44 samples/sec	Train-FCNLogLoss=0.128929,	
2017-06-24 13:56:57,468 Epoch[14] Batch [40]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.127745,	
2017-06-24 13:57:05,266 Epoch[14] Batch [50]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.123999,	
2017-06-24 13:57:13,256 Epoch[14] Batch [60]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.126688,	
2017-06-24 13:57:21,406 Epoch[14] Batch [70]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.128415,	
2017-06-24 13:57:29,658 Epoch[14] Batch [80]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.128453,	
2017-06-24 13:57:38,016 Epoch[14] Batch [90]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.127897,	
2017-06-24 13:57:46,074 Epoch[14] Batch [100]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.128033,	
2017-06-24 13:57:54,209 Epoch[14] Batch [110]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.127412,	
2017-06-24 13:58:02,154 Epoch[14] Batch [120]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.127608,	
2017-06-24 13:58:13,472 Epoch[14] Batch [130]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.128456,	
2017-06-24 13:58:23,079 Epoch[14] Batch [140]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.128395,	
2017-06-24 13:58:32,371 Epoch[14] Batch [150]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.128532,	
2017-06-24 13:58:42,397 Epoch[14] Batch [160]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.128494,	
2017-06-24 13:58:51,841 Epoch[14] Batch [170]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.127680,	
2017-06-24 13:59:01,146 Epoch[14] Batch [180]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.127239,	
2017-06-24 13:59:10,991 Epoch[14] Batch [190]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.127067,	
2017-06-24 13:59:20,579 Epoch[14] Batch [200]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.126920,	
2017-06-24 13:59:29,275 Epoch[14] Batch [210]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.127975,	
2017-06-24 13:59:37,825 Epoch[14] Batch [220]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.128407,	
2017-06-24 13:59:46,805 Epoch[14] Batch [230]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.128778,	
2017-06-24 13:59:55,596 Epoch[14] Batch [240]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.128591,	
2017-06-24 14:00:04,723 Epoch[14] Batch [250]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.128680,	
2017-06-24 14:00:13,516 Epoch[14] Batch [260]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.128895,	
2017-06-24 14:00:21,718 Epoch[14] Batch [270]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.128907,	
2017-06-24 14:00:29,906 Epoch[14] Batch [280]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.128930,	
2017-06-24 14:00:38,752 Epoch[14] Batch [290]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.128748,	
2017-06-24 14:00:48,120 Epoch[14] Batch [300]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.128318,	
2017-06-24 14:00:57,286 Epoch[14] Batch [310]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.128897,	
2017-06-24 14:01:06,522 Epoch[14] Batch [320]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.129083,	
2017-06-24 14:01:15,847 Epoch[14] Batch [330]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.128637,	
2017-06-24 14:01:25,666 Epoch[14] Batch [340]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.128603,	
2017-06-24 14:01:34,574 Epoch[14] Batch [350]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.128660,	
2017-06-24 14:01:43,322 Epoch[14] Batch [360]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.128590,	
2017-06-24 14:01:52,641 Epoch[14] Batch [370]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.128772,	
2017-06-24 14:02:01,410 Epoch[14] Batch [380]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.128648,	
2017-06-24 14:02:09,496 Epoch[14] Batch [390]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.128490,	
2017-06-24 14:02:17,777 Epoch[14] Batch [400]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.128659,	
2017-06-24 14:02:26,250 Epoch[14] Batch [410]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.128661,	
2017-06-24 14:02:35,400 Epoch[14] Batch [420]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.128367,	
2017-06-24 14:02:44,451 Epoch[14] Batch [430]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.128061,	
2017-06-24 14:02:54,391 Epoch[14] Batch [440]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.127879,	
2017-06-24 14:03:04,933 Epoch[14] Batch [450]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.128392,	
2017-06-24 14:03:15,129 Epoch[14] Batch [460]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.128600,	
2017-06-24 14:03:24,755 Epoch[14] Batch [470]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.128560,	
2017-06-24 14:03:34,055 Epoch[14] Batch [480]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.128548,	
2017-06-24 14:03:42,926 Epoch[14] Batch [490]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.128632,	
2017-06-24 14:03:51,223 Epoch[14] Batch [500]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.128660,	
2017-06-24 14:04:00,935 Epoch[14] Batch [510]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.128712,	
2017-06-24 14:04:12,355 Epoch[14] Batch [520]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.128567,	
2017-06-24 14:04:21,005 Epoch[14] Batch [530]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.128547,	
2017-06-24 14:04:29,886 Epoch[14] Batch [540]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.128571,	
2017-06-24 14:04:39,745 Epoch[14] Batch [550]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.128574,	
2017-06-24 14:04:50,201 Epoch[14] Batch [560]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.128406,	
2017-06-24 14:05:00,223 Epoch[14] Batch [570]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.128150,	
2017-06-24 14:05:10,286 Epoch[14] Batch [580]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.128026,	
2017-06-24 14:05:19,363 Epoch[14] Batch [590]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.128049,	
2017-06-24 14:05:28,810 Epoch[14] Batch [600]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.127977,	
2017-06-24 14:05:37,381 Epoch[14] Batch [610]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.128019,	
2017-06-24 14:05:46,114 Epoch[14] Batch [620]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.128256,	
2017-06-24 14:05:54,498 Epoch[14] Batch [630]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.128300,	
2017-06-24 14:06:02,703 Epoch[14] Batch [640]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.128194,	
2017-06-24 14:06:11,626 Epoch[14] Batch [650]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.128087,	
2017-06-24 14:06:20,500 Epoch[14] Batch [660]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.127801,	
2017-06-24 14:06:29,353 Epoch[14] Batch [670]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.127953,	
2017-06-24 14:06:38,142 Epoch[14] Batch [680]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.128145,	
2017-06-24 14:06:47,271 Epoch[14] Batch [690]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.128025,	
2017-06-24 14:06:56,770 Epoch[14] Batch [700]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.127980,	
2017-06-24 14:07:07,376 Epoch[14] Batch [710]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.127899,	
2017-06-24 14:07:16,383 Epoch[14] Batch [720]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.127881,	
2017-06-24 14:07:25,216 Epoch[14] Batch [730]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.127847,	
2017-06-24 14:07:33,934 Epoch[14] Batch [740]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.127963,	
2017-06-24 14:07:35,507 Epoch[14] Train-FCNLogLoss=0.127998
2017-06-24 14:07:35,507 Epoch[14] Time cost=669.999
2017-06-24 14:07:38,117 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0015.params"
2017-06-24 14:07:41,393 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0015.states"
2017-06-24 14:07:51,233 Epoch[15] Batch [10]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.148701,	
2017-06-24 14:07:59,573 Epoch[15] Batch [20]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.136685,	
2017-06-24 14:08:07,528 Epoch[15] Batch [30]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.133488,	
2017-06-24 14:08:15,552 Epoch[15] Batch [40]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.131063,	
2017-06-24 14:08:24,903 Epoch[15] Batch [50]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.128636,	
2017-06-24 14:08:33,270 Epoch[15] Batch [60]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.127660,	
2017-06-24 14:08:41,969 Epoch[15] Batch [70]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.127957,	
2017-06-24 14:08:50,806 Epoch[15] Batch [80]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.125536,	
2017-06-24 14:09:00,016 Epoch[15] Batch [90]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.126060,	
2017-06-24 14:09:09,182 Epoch[15] Batch [100]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.125579,	
2017-06-24 14:09:17,720 Epoch[15] Batch [110]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.126151,	
2017-06-24 14:09:26,171 Epoch[15] Batch [120]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.125279,	
2017-06-24 14:09:35,077 Epoch[15] Batch [130]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.124513,	
2017-06-24 14:09:43,595 Epoch[15] Batch [140]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.124649,	
2017-06-24 14:09:52,347 Epoch[15] Batch [150]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.124024,	
2017-06-24 14:10:01,216 Epoch[15] Batch [160]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.124502,	
2017-06-24 14:10:12,166 Epoch[15] Batch [170]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.124047,	
2017-06-24 14:10:22,147 Epoch[15] Batch [180]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.123455,	
2017-06-24 14:10:30,801 Epoch[15] Batch [190]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.123439,	
2017-06-24 14:10:40,008 Epoch[15] Batch [200]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.123180,	
2017-06-24 14:10:48,978 Epoch[15] Batch [210]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.122983,	
2017-06-24 14:10:58,874 Epoch[15] Batch [220]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.122772,	
2017-06-24 14:11:07,868 Epoch[15] Batch [230]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.122871,	
2017-06-24 14:11:16,808 Epoch[15] Batch [240]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.123052,	
2017-06-24 14:11:26,691 Epoch[15] Batch [250]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.122429,	
2017-06-24 14:11:36,075 Epoch[15] Batch [260]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.122255,	
2017-06-24 14:11:45,319 Epoch[15] Batch [270]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.122281,	
2017-06-24 14:11:54,609 Epoch[15] Batch [280]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.122459,	
2017-06-24 14:12:02,969 Epoch[15] Batch [290]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.122495,	
2017-06-24 14:12:11,739 Epoch[15] Batch [300]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.122175,	
2017-06-24 14:12:20,682 Epoch[15] Batch [310]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.121944,	
2017-06-24 14:12:30,169 Epoch[15] Batch [320]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.121961,	
2017-06-24 14:12:40,087 Epoch[15] Batch [330]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.122265,	
2017-06-24 14:12:49,787 Epoch[15] Batch [340]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.122373,	
2017-06-24 14:12:58,949 Epoch[15] Batch [350]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.122318,	
2017-06-24 14:13:08,708 Epoch[15] Batch [360]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.122336,	
2017-06-24 14:13:17,601 Epoch[15] Batch [370]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.122325,	
2017-06-24 14:13:26,420 Epoch[15] Batch [380]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.122463,	
2017-06-24 14:13:35,780 Epoch[15] Batch [390]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.122715,	
2017-06-24 14:13:45,138 Epoch[15] Batch [400]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.122777,	
2017-06-24 14:13:53,849 Epoch[15] Batch [410]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.122769,	
2017-06-24 14:14:02,439 Epoch[15] Batch [420]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.122850,	
2017-06-24 14:14:11,406 Epoch[15] Batch [430]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.123000,	
2017-06-24 14:14:20,334 Epoch[15] Batch [440]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.123038,	
2017-06-24 14:14:29,319 Epoch[15] Batch [450]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.123155,	
2017-06-24 14:14:38,051 Epoch[15] Batch [460]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.122886,	
2017-06-24 14:14:47,470 Epoch[15] Batch [470]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.122895,	
2017-06-24 14:14:56,683 Epoch[15] Batch [480]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.122863,	
2017-06-24 14:15:05,882 Epoch[15] Batch [490]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.122842,	
2017-06-24 14:15:15,180 Epoch[15] Batch [500]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.122967,	
2017-06-24 14:15:24,656 Epoch[15] Batch [510]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.123188,	
2017-06-24 14:15:33,457 Epoch[15] Batch [520]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.123120,	
2017-06-24 14:15:42,044 Epoch[15] Batch [530]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.122958,	
2017-06-24 14:15:50,295 Epoch[15] Batch [540]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.122812,	
2017-06-24 14:16:00,256 Epoch[15] Batch [550]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.122680,	
2017-06-24 14:16:11,456 Epoch[15] Batch [560]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.122660,	
2017-06-24 14:16:20,516 Epoch[15] Batch [570]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.122445,	
2017-06-24 14:16:30,035 Epoch[15] Batch [580]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.122348,	
2017-06-24 14:16:39,134 Epoch[15] Batch [590]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.122272,	
2017-06-24 14:16:47,820 Epoch[15] Batch [600]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.122274,	
2017-06-24 14:16:57,371 Epoch[15] Batch [610]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.122116,	
2017-06-24 14:17:07,581 Epoch[15] Batch [620]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.122123,	
2017-06-24 14:17:17,002 Epoch[15] Batch [630]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.122208,	
2017-06-24 14:17:26,288 Epoch[15] Batch [640]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.122295,	
2017-06-24 14:17:35,546 Epoch[15] Batch [650]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.122246,	
2017-06-24 14:17:44,274 Epoch[15] Batch [660]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.122413,	
2017-06-24 14:17:52,534 Epoch[15] Batch [670]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.122400,	
2017-06-24 14:18:00,600 Epoch[15] Batch [680]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.122334,	
2017-06-24 14:18:09,422 Epoch[15] Batch [690]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.122254,	
2017-06-24 14:18:18,005 Epoch[15] Batch [700]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.122268,	
2017-06-24 14:18:26,613 Epoch[15] Batch [710]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.122216,	
2017-06-24 14:18:35,098 Epoch[15] Batch [720]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.122362,	
2017-06-24 14:18:43,810 Epoch[15] Batch [730]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.122373,	
2017-06-24 14:18:52,830 Epoch[15] Batch [740]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.122494,	
2017-06-24 14:18:54,358 Epoch[15] Train-FCNLogLoss=0.122501
2017-06-24 14:18:54,358 Epoch[15] Time cost=672.964
2017-06-24 14:18:57,502 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0016.params"
2017-06-24 14:19:01,228 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0016.states"
2017-06-24 14:19:11,051 Epoch[16] Batch [10]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.129714,	
2017-06-24 14:19:19,700 Epoch[16] Batch [20]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.121386,	
2017-06-24 14:19:28,290 Epoch[16] Batch [30]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.123467,	
2017-06-24 14:19:36,608 Epoch[16] Batch [40]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.121767,	
2017-06-24 14:19:45,028 Epoch[16] Batch [50]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.119759,	
2017-06-24 14:19:53,094 Epoch[16] Batch [60]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.119653,	
2017-06-24 14:20:02,024 Epoch[16] Batch [70]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.118832,	
2017-06-24 14:20:10,857 Epoch[16] Batch [80]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.119387,	
2017-06-24 14:20:19,654 Epoch[16] Batch [90]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.120162,	
2017-06-24 14:20:27,882 Epoch[16] Batch [100]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.119358,	
2017-06-24 14:20:37,166 Epoch[16] Batch [110]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.119762,	
2017-06-24 14:20:46,057 Epoch[16] Batch [120]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.119283,	
2017-06-24 14:20:56,013 Epoch[16] Batch [130]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.119217,	
2017-06-24 14:21:05,395 Epoch[16] Batch [140]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.118890,	
2017-06-24 14:21:14,522 Epoch[16] Batch [150]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.118097,	
2017-06-24 14:21:23,479 Epoch[16] Batch [160]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.118323,	
2017-06-24 14:21:31,953 Epoch[16] Batch [170]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.118571,	
2017-06-24 14:21:40,733 Epoch[16] Batch [180]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.118449,	
2017-06-24 14:21:49,473 Epoch[16] Batch [190]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.117640,	
2017-06-24 14:21:57,685 Epoch[16] Batch [200]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117416,	
2017-06-24 14:22:06,898 Epoch[16] Batch [210]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.117269,	
2017-06-24 14:22:16,928 Epoch[16] Batch [220]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.117238,	
2017-06-24 14:22:26,918 Epoch[16] Batch [230]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.117224,	
2017-06-24 14:22:35,273 Epoch[16] Batch [240]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.117087,	
2017-06-24 14:22:45,011 Epoch[16] Batch [250]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.117246,	
2017-06-24 14:22:54,476 Epoch[16] Batch [260]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.117467,	
2017-06-24 14:23:04,071 Epoch[16] Batch [270]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.117628,	
2017-06-24 14:23:13,361 Epoch[16] Batch [280]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.117514,	
2017-06-24 14:23:22,430 Epoch[16] Batch [290]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.117213,	
2017-06-24 14:23:31,104 Epoch[16] Batch [300]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.117308,	
2017-06-24 14:23:39,673 Epoch[16] Batch [310]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.117237,	
2017-06-24 14:23:47,740 Epoch[16] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.117259,	
2017-06-24 14:23:55,381 Epoch[16] Batch [330]	Speed: 10.47 samples/sec	Train-FCNLogLoss=0.117410,	
2017-06-24 14:24:04,286 Epoch[16] Batch [340]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.117306,	
2017-06-24 14:24:13,023 Epoch[16] Batch [350]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.117404,	
2017-06-24 14:24:21,504 Epoch[16] Batch [360]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.117252,	
2017-06-24 14:24:30,575 Epoch[16] Batch [370]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.117145,	
2017-06-24 14:24:40,234 Epoch[16] Batch [380]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.117154,	
2017-06-24 14:24:50,976 Epoch[16] Batch [390]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.117234,	
2017-06-24 14:25:01,029 Epoch[16] Batch [400]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.117507,	
2017-06-24 14:25:10,374 Epoch[16] Batch [410]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.117443,	
2017-06-24 14:25:19,861 Epoch[16] Batch [420]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.117388,	
2017-06-24 14:25:28,694 Epoch[16] Batch [430]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.117181,	
2017-06-24 14:25:37,700 Epoch[16] Batch [440]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.117231,	
2017-06-24 14:25:46,072 Epoch[16] Batch [450]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.117240,	
2017-06-24 14:25:54,841 Epoch[16] Batch [460]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.117311,	
2017-06-24 14:26:03,788 Epoch[16] Batch [470]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.117175,	
2017-06-24 14:26:12,636 Epoch[16] Batch [480]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.117223,	
2017-06-24 14:26:21,191 Epoch[16] Batch [490]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.117115,	
2017-06-24 14:26:30,084 Epoch[16] Batch [500]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.117191,	
2017-06-24 14:26:39,763 Epoch[16] Batch [510]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.117268,	
2017-06-24 14:26:48,842 Epoch[16] Batch [520]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.117348,	
2017-06-24 14:26:57,924 Epoch[16] Batch [530]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.117373,	
2017-06-24 14:27:06,507 Epoch[16] Batch [540]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.117252,	
2017-06-24 14:27:15,009 Epoch[16] Batch [550]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.117131,	
2017-06-24 14:27:23,463 Epoch[16] Batch [560]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.117050,	
2017-06-24 14:27:32,008 Epoch[16] Batch [570]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.116946,	
2017-06-24 14:27:40,226 Epoch[16] Batch [580]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.116995,	
2017-06-24 14:27:48,541 Epoch[16] Batch [590]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.117157,	
2017-06-24 14:27:56,770 Epoch[16] Batch [600]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.117247,	
2017-06-24 14:28:05,486 Epoch[16] Batch [610]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.117335,	
2017-06-24 14:28:14,355 Epoch[16] Batch [620]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.117209,	
2017-06-24 14:28:25,678 Epoch[16] Batch [630]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.117171,	
2017-06-24 14:28:35,977 Epoch[16] Batch [640]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.117096,	
2017-06-24 14:28:46,056 Epoch[16] Batch [650]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.117177,	
2017-06-24 14:28:55,218 Epoch[16] Batch [660]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.117294,	
2017-06-24 14:29:04,567 Epoch[16] Batch [670]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.117341,	
2017-06-24 14:29:13,196 Epoch[16] Batch [680]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.117347,	
2017-06-24 14:29:22,010 Epoch[16] Batch [690]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.117391,	
2017-06-24 14:29:30,603 Epoch[16] Batch [700]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.117548,	
2017-06-24 14:29:38,882 Epoch[16] Batch [710]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.117491,	
2017-06-24 14:29:47,190 Epoch[16] Batch [720]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.117531,	
2017-06-24 14:29:55,134 Epoch[16] Batch [730]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.117591,	
2017-06-24 14:30:03,666 Epoch[16] Batch [740]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.117663,	
2017-06-24 14:30:05,281 Epoch[16] Train-FCNLogLoss=0.117695
2017-06-24 14:30:05,281 Epoch[16] Time cost=664.053
2017-06-24 14:30:06,908 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0017.params"
2017-06-24 14:30:10,505 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0017.states"
2017-06-24 14:30:20,648 Epoch[17] Batch [10]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.120121,	
2017-06-24 14:30:29,706 Epoch[17] Batch [20]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.117486,	
2017-06-24 14:30:39,664 Epoch[17] Batch [30]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.118526,	
2017-06-24 14:30:49,066 Epoch[17] Batch [40]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.118235,	
2017-06-24 14:30:58,253 Epoch[17] Batch [50]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.117743,	
2017-06-24 14:31:07,253 Epoch[17] Batch [60]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.117646,	
2017-06-24 14:31:16,656 Epoch[17] Batch [70]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.117207,	
2017-06-24 14:31:25,201 Epoch[17] Batch [80]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.116909,	
2017-06-24 14:31:33,806 Epoch[17] Batch [90]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.116592,	
2017-06-24 14:31:42,378 Epoch[17] Batch [100]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.116956,	
2017-06-24 14:31:50,696 Epoch[17] Batch [110]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.115657,	
2017-06-24 14:31:59,122 Epoch[17] Batch [120]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.115488,	
2017-06-24 14:32:07,480 Epoch[17] Batch [130]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.115355,	
2017-06-24 14:32:16,454 Epoch[17] Batch [140]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.114838,	
2017-06-24 14:32:25,884 Epoch[17] Batch [150]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.115026,	
2017-06-24 14:32:34,451 Epoch[17] Batch [160]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.114950,	
2017-06-24 14:32:43,879 Epoch[17] Batch [170]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.114713,	
2017-06-24 14:32:53,993 Epoch[17] Batch [180]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.115129,	
2017-06-24 14:33:03,677 Epoch[17] Batch [190]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.115462,	
2017-06-24 14:33:12,727 Epoch[17] Batch [200]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.115208,	
2017-06-24 14:33:21,995 Epoch[17] Batch [210]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.114851,	
2017-06-24 14:33:30,576 Epoch[17] Batch [220]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.114646,	
2017-06-24 14:33:39,134 Epoch[17] Batch [230]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.115705,	
2017-06-24 14:33:48,565 Epoch[17] Batch [240]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.116026,	
2017-06-24 14:33:57,060 Epoch[17] Batch [250]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.116283,	
2017-06-24 14:34:06,012 Epoch[17] Batch [260]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.116690,	
2017-06-24 14:34:15,464 Epoch[17] Batch [270]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.116597,	
2017-06-24 14:34:25,905 Epoch[17] Batch [280]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.116449,	
2017-06-24 14:34:36,770 Epoch[17] Batch [290]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.116401,	
2017-06-24 14:34:45,928 Epoch[17] Batch [300]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.116156,	
2017-06-24 14:34:55,040 Epoch[17] Batch [310]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.116090,	
2017-06-24 14:35:03,902 Epoch[17] Batch [320]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.116125,	
2017-06-24 14:35:13,151 Epoch[17] Batch [330]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.116376,	
2017-06-24 14:35:22,312 Epoch[17] Batch [340]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.116359,	
2017-06-24 14:35:31,132 Epoch[17] Batch [350]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.116303,	
2017-06-24 14:35:39,199 Epoch[17] Batch [360]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.116158,	
2017-06-24 14:35:47,095 Epoch[17] Batch [370]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.116665,	
2017-06-24 14:35:55,468 Epoch[17] Batch [380]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.116565,	
2017-06-24 14:36:04,644 Epoch[17] Batch [390]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.116682,	
2017-06-24 14:36:13,355 Epoch[17] Batch [400]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.116944,	
2017-06-24 14:36:21,601 Epoch[17] Batch [410]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.117058,	
2017-06-24 14:36:29,883 Epoch[17] Batch [420]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.116913,	
2017-06-24 14:36:38,288 Epoch[17] Batch [430]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.116781,	
2017-06-24 14:36:46,664 Epoch[17] Batch [440]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.116689,	
2017-06-24 14:36:55,512 Epoch[17] Batch [450]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.116774,	
2017-06-24 14:37:04,100 Epoch[17] Batch [460]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.116557,	
2017-06-24 14:37:13,150 Epoch[17] Batch [470]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.116490,	
2017-06-24 14:37:22,135 Epoch[17] Batch [480]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.116419,	
2017-06-24 14:37:30,962 Epoch[17] Batch [490]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.116413,	
2017-06-24 14:37:40,033 Epoch[17] Batch [500]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.116476,	
2017-06-24 14:37:49,099 Epoch[17] Batch [510]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.116669,	
2017-06-24 14:37:58,225 Epoch[17] Batch [520]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.116643,	
2017-06-24 14:38:07,238 Epoch[17] Batch [530]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.116712,	
2017-06-24 14:38:16,001 Epoch[17] Batch [540]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.116599,	
2017-06-24 14:38:24,977 Epoch[17] Batch [550]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.116725,	
2017-06-24 14:38:33,661 Epoch[17] Batch [560]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.117053,	
2017-06-24 14:38:42,678 Epoch[17] Batch [570]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.117202,	
2017-06-24 14:38:51,208 Epoch[17] Batch [580]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.117314,	
2017-06-24 14:39:00,273 Epoch[17] Batch [590]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.117308,	
2017-06-24 14:39:09,799 Epoch[17] Batch [600]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.117226,	
2017-06-24 14:39:19,215 Epoch[17] Batch [610]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.117351,	
2017-06-24 14:39:28,692 Epoch[17] Batch [620]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.117424,	
2017-06-24 14:39:38,529 Epoch[17] Batch [630]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.117366,	
2017-06-24 14:39:47,954 Epoch[17] Batch [640]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.117274,	
2017-06-24 14:39:56,993 Epoch[17] Batch [650]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.117253,	
2017-06-24 14:40:05,553 Epoch[17] Batch [660]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.117100,	
2017-06-24 14:40:14,026 Epoch[17] Batch [670]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.117045,	
2017-06-24 14:40:22,668 Epoch[17] Batch [680]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.117073,	
2017-06-24 14:40:32,561 Epoch[17] Batch [690]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.117144,	
2017-06-24 14:40:43,723 Epoch[17] Batch [700]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.117108,	
2017-06-24 14:40:52,409 Epoch[17] Batch [710]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.117177,	
2017-06-24 14:41:01,132 Epoch[17] Batch [720]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.117259,	
2017-06-24 14:41:09,457 Epoch[17] Batch [730]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.117049,	
2017-06-24 14:41:18,141 Epoch[17] Batch [740]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.116935,	
2017-06-24 14:41:19,460 Epoch[17] Train-FCNLogLoss=0.116898
2017-06-24 14:41:19,460 Epoch[17] Time cost=668.954
2017-06-24 14:41:21,676 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0018.params"
2017-06-24 14:41:24,960 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0018.states"
2017-06-24 14:41:34,946 Epoch[18] Batch [10]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.111848,	
2017-06-24 14:41:43,350 Epoch[18] Batch [20]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.115497,	
2017-06-24 14:41:51,686 Epoch[18] Batch [30]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.119569,	
2017-06-24 14:42:00,615 Epoch[18] Batch [40]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.116211,	
2017-06-24 14:42:09,983 Epoch[18] Batch [50]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.116465,	
2017-06-24 14:42:18,389 Epoch[18] Batch [60]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.116477,	
2017-06-24 14:42:27,640 Epoch[18] Batch [70]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.115324,	
2017-06-24 14:42:37,190 Epoch[18] Batch [80]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.115921,	
2017-06-24 14:42:46,038 Epoch[18] Batch [90]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.116773,	
2017-06-24 14:42:54,663 Epoch[18] Batch [100]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.116883,	
2017-06-24 14:43:04,312 Epoch[18] Batch [110]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.116612,	
2017-06-24 14:43:13,491 Epoch[18] Batch [120]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.116390,	
2017-06-24 14:43:22,590 Epoch[18] Batch [130]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.116688,	
2017-06-24 14:43:31,895 Epoch[18] Batch [140]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.116351,	
2017-06-24 14:43:40,804 Epoch[18] Batch [150]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.116165,	
2017-06-24 14:43:49,866 Epoch[18] Batch [160]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.116378,	
2017-06-24 14:43:58,809 Epoch[18] Batch [170]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.116503,	
2017-06-24 14:44:08,229 Epoch[18] Batch [180]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.116397,	
2017-06-24 14:44:16,800 Epoch[18] Batch [190]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.116206,	
2017-06-24 14:44:26,068 Epoch[18] Batch [200]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.116073,	
2017-06-24 14:44:35,665 Epoch[18] Batch [210]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.115995,	
2017-06-24 14:44:44,288 Epoch[18] Batch [220]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.116168,	
2017-06-24 14:44:54,009 Epoch[18] Batch [230]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.116044,	
2017-06-24 14:45:02,662 Epoch[18] Batch [240]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.116839,	
2017-06-24 14:45:11,428 Epoch[18] Batch [250]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.117113,	
2017-06-24 14:45:20,444 Epoch[18] Batch [260]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.118370,	
2017-06-24 14:45:29,134 Epoch[18] Batch [270]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.118882,	
2017-06-24 14:45:37,750 Epoch[18] Batch [280]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.119582,	
2017-06-24 14:45:46,397 Epoch[18] Batch [290]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.119786,	
2017-06-24 14:45:54,975 Epoch[18] Batch [300]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.119564,	
2017-06-24 14:46:03,724 Epoch[18] Batch [310]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.119599,	
2017-06-24 14:46:12,245 Epoch[18] Batch [320]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.119431,	
2017-06-24 14:46:20,826 Epoch[18] Batch [330]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.119712,	
2017-06-24 14:46:30,430 Epoch[18] Batch [340]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.119478,	
2017-06-24 14:46:39,139 Epoch[18] Batch [350]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.119583,	
2017-06-24 14:46:50,601 Epoch[18] Batch [360]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.119486,	
2017-06-24 14:46:58,894 Epoch[18] Batch [370]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.119733,	
2017-06-24 14:47:06,505 Epoch[18] Batch [380]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.119762,	
2017-06-24 14:47:14,315 Epoch[18] Batch [390]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.119635,	
2017-06-24 14:47:22,512 Epoch[18] Batch [400]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.119392,	
2017-06-24 14:47:30,725 Epoch[18] Batch [410]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.119053,	
2017-06-24 14:47:38,113 Epoch[18] Batch [420]	Speed: 10.83 samples/sec	Train-FCNLogLoss=0.118777,	
2017-06-24 14:47:45,509 Epoch[18] Batch [430]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.118591,	
2017-06-24 14:47:52,712 Epoch[18] Batch [440]	Speed: 11.11 samples/sec	Train-FCNLogLoss=0.118515,	
2017-06-24 14:48:00,985 Epoch[18] Batch [450]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.118523,	
2017-06-24 14:48:09,210 Epoch[18] Batch [460]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.118492,	
2017-06-24 14:48:17,610 Epoch[18] Batch [470]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.118512,	
2017-06-24 14:48:25,817 Epoch[18] Batch [480]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.118444,	
2017-06-24 14:48:34,217 Epoch[18] Batch [490]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.118269,	
2017-06-24 14:48:42,431 Epoch[18] Batch [500]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.118277,	
2017-06-24 14:48:50,844 Epoch[18] Batch [510]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.118193,	
2017-06-24 14:48:59,427 Epoch[18] Batch [520]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.118119,	
2017-06-24 14:49:07,875 Epoch[18] Batch [530]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.118015,	
2017-06-24 14:49:16,363 Epoch[18] Batch [540]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.118113,	
2017-06-24 14:49:25,151 Epoch[18] Batch [550]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.118081,	
2017-06-24 14:49:33,562 Epoch[18] Batch [560]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.118128,	
2017-06-24 14:49:41,540 Epoch[18] Batch [570]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.118145,	
2017-06-24 14:49:49,771 Epoch[18] Batch [580]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.118106,	
2017-06-24 14:49:57,677 Epoch[18] Batch [590]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.117953,	
2017-06-24 14:50:05,617 Epoch[18] Batch [600]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.118021,	
2017-06-24 14:50:13,722 Epoch[18] Batch [610]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.118007,	
2017-06-24 14:50:22,100 Epoch[18] Batch [620]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.118141,	
2017-06-24 14:50:30,398 Epoch[18] Batch [630]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.118148,	
2017-06-24 14:50:38,615 Epoch[18] Batch [640]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.118139,	
2017-06-24 14:50:46,933 Epoch[18] Batch [650]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.118056,	
2017-06-24 14:50:55,488 Epoch[18] Batch [660]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.117986,	
2017-06-24 14:51:03,917 Epoch[18] Batch [670]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.117891,	
2017-06-24 14:51:12,387 Epoch[18] Batch [680]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.117774,	
2017-06-24 14:51:20,602 Epoch[18] Batch [690]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.117926,	
2017-06-24 14:51:28,526 Epoch[18] Batch [700]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.118076,	
2017-06-24 14:51:36,500 Epoch[18] Batch [710]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.117999,	
2017-06-24 14:51:44,496 Epoch[18] Batch [720]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.118015,	
2017-06-24 14:51:52,696 Epoch[18] Batch [730]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.118069,	
2017-06-24 14:52:00,758 Epoch[18] Batch [740]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.118150,	
2017-06-24 14:52:02,156 Epoch[18] Train-FCNLogLoss=0.118221
2017-06-24 14:52:02,156 Epoch[18] Time cost=637.195
2017-06-24 14:52:04,324 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0019.params"
2017-06-24 14:52:07,459 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0019.states"
2017-06-24 14:52:16,898 Epoch[19] Batch [10]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.123729,	
2017-06-24 14:52:24,657 Epoch[19] Batch [20]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.123462,	
2017-06-24 14:52:32,750 Epoch[19] Batch [30]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.121641,	
2017-06-24 14:52:41,117 Epoch[19] Batch [40]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.121167,	
2017-06-24 14:52:49,364 Epoch[19] Batch [50]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.118007,	
2017-06-24 14:52:57,409 Epoch[19] Batch [60]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.118985,	
2017-06-24 14:53:05,586 Epoch[19] Batch [70]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.117117,	
2017-06-24 14:53:14,265 Epoch[19] Batch [80]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.115735,	
2017-06-24 14:53:23,027 Epoch[19] Batch [90]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.115599,	
2017-06-24 14:53:31,638 Epoch[19] Batch [100]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.113932,	
2017-06-24 14:53:40,232 Epoch[19] Batch [110]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.112730,	
2017-06-24 14:53:49,169 Epoch[19] Batch [120]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.112143,	
2017-06-24 14:53:57,406 Epoch[19] Batch [130]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.112948,	
2017-06-24 14:54:05,538 Epoch[19] Batch [140]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.113116,	
2017-06-24 14:54:13,368 Epoch[19] Batch [150]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.113621,	
2017-06-24 14:54:21,014 Epoch[19] Batch [160]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.113830,	
2017-06-24 14:54:28,810 Epoch[19] Batch [170]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.113223,	
2017-06-24 14:54:37,113 Epoch[19] Batch [180]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.113471,	
2017-06-24 14:54:45,430 Epoch[19] Batch [190]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.113549,	
2017-06-24 14:54:53,890 Epoch[19] Batch [200]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.113358,	
2017-06-24 14:55:02,015 Epoch[19] Batch [210]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.113703,	
2017-06-24 14:55:10,333 Epoch[19] Batch [220]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.114568,	
2017-06-24 14:55:19,040 Epoch[19] Batch [230]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.115173,	
2017-06-24 14:55:27,803 Epoch[19] Batch [240]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.115598,	
2017-06-24 14:55:36,558 Epoch[19] Batch [250]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.115654,	
2017-06-24 14:55:44,743 Epoch[19] Batch [260]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.115665,	
2017-06-24 14:55:52,901 Epoch[19] Batch [270]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.115711,	
2017-06-24 14:56:00,888 Epoch[19] Batch [280]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.116121,	
2017-06-24 14:56:08,779 Epoch[19] Batch [290]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.116242,	
2017-06-24 14:56:17,027 Epoch[19] Batch [300]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.115829,	
2017-06-24 14:56:25,351 Epoch[19] Batch [310]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.115837,	
2017-06-24 14:56:32,973 Epoch[19] Batch [320]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.116007,	
2017-06-24 14:56:40,889 Epoch[19] Batch [330]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.116119,	
2017-06-24 14:56:49,382 Epoch[19] Batch [340]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.116298,	
2017-06-24 14:56:57,163 Epoch[19] Batch [350]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.116661,	
2017-06-24 14:57:05,776 Epoch[19] Batch [360]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.116411,	
2017-06-24 14:57:14,748 Epoch[19] Batch [370]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.116181,	
2017-06-24 14:57:24,203 Epoch[19] Batch [380]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.116104,	
2017-06-24 14:57:33,350 Epoch[19] Batch [390]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.115990,	
2017-06-24 14:57:42,071 Epoch[19] Batch [400]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.116117,	
2017-06-24 14:57:50,852 Epoch[19] Batch [410]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.116018,	
2017-06-24 14:57:59,820 Epoch[19] Batch [420]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.115877,	
2017-06-24 14:58:09,005 Epoch[19] Batch [430]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.115863,	
2017-06-24 14:58:18,474 Epoch[19] Batch [440]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.115671,	
2017-06-24 14:58:26,927 Epoch[19] Batch [450]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.115513,	
2017-06-24 14:58:36,134 Epoch[19] Batch [460]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.115384,	
2017-06-24 14:58:46,151 Epoch[19] Batch [470]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.115246,	
2017-06-24 14:58:56,562 Epoch[19] Batch [480]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.115288,	
2017-06-24 14:59:06,901 Epoch[19] Batch [490]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.115424,	
2017-06-24 14:59:16,880 Epoch[19] Batch [500]	Speed: 8.02 samples/sec	Train-FCNLogLoss=0.115271,	
2017-06-24 14:59:26,705 Epoch[19] Batch [510]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.115076,	
2017-06-24 14:59:36,048 Epoch[19] Batch [520]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.115141,	
2017-06-24 14:59:44,993 Epoch[19] Batch [530]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.115285,	
2017-06-24 14:59:54,074 Epoch[19] Batch [540]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.115277,	
2017-06-24 15:00:03,433 Epoch[19] Batch [550]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.115257,	
2017-06-24 15:00:12,412 Epoch[19] Batch [560]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.115401,	
2017-06-24 15:00:20,934 Epoch[19] Batch [570]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.115476,	
2017-06-24 15:00:30,303 Epoch[19] Batch [580]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.115470,	
2017-06-24 15:00:41,292 Epoch[19] Batch [590]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.115407,	
2017-06-24 15:00:52,494 Epoch[19] Batch [600]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.115195,	
2017-06-24 15:01:03,547 Epoch[19] Batch [610]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.115040,	
2017-06-24 15:01:13,740 Epoch[19] Batch [620]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.115229,	
2017-06-24 15:01:23,315 Epoch[19] Batch [630]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.115331,	
2017-06-24 15:01:33,345 Epoch[19] Batch [640]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.115319,	
2017-06-24 15:01:44,093 Epoch[19] Batch [650]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.115254,	
2017-06-24 15:01:55,044 Epoch[19] Batch [660]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.115380,	
2017-06-24 15:02:05,346 Epoch[19] Batch [670]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.115744,	
2017-06-24 15:02:15,226 Epoch[19] Batch [680]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.115727,	
2017-06-24 15:02:25,103 Epoch[19] Batch [690]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.115848,	
2017-06-24 15:02:35,062 Epoch[19] Batch [700]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.115845,	
2017-06-24 15:02:44,669 Epoch[19] Batch [710]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.115737,	
2017-06-24 15:02:52,947 Epoch[19] Batch [720]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.115588,	
2017-06-24 15:03:01,791 Epoch[19] Batch [730]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.115562,	
2017-06-24 15:03:10,747 Epoch[19] Batch [740]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.115473,	
2017-06-24 15:03:12,437 Epoch[19] Train-FCNLogLoss=0.115527
2017-06-24 15:03:12,437 Epoch[19] Time cost=664.977
2017-06-24 15:03:15,270 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0020.params"
2017-06-24 15:03:18,805 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0020.states"
2017-06-24 15:03:28,365 Epoch[20] Batch [10]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.118962,	
2017-06-24 15:03:36,429 Epoch[20] Batch [20]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.114604,	
2017-06-24 15:03:44,958 Epoch[20] Batch [30]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.114516,	
2017-06-24 15:03:53,535 Epoch[20] Batch [40]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.116049,	
2017-06-24 15:04:01,433 Epoch[20] Batch [50]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.115863,	
2017-06-24 15:04:09,527 Epoch[20] Batch [60]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.115342,	
2017-06-24 15:04:18,076 Epoch[20] Batch [70]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.116409,	
2017-06-24 15:04:26,054 Epoch[20] Batch [80]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.114742,	
2017-06-24 15:04:35,284 Epoch[20] Batch [90]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.113964,	
2017-06-24 15:04:43,493 Epoch[20] Batch [100]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.114191,	
2017-06-24 15:04:52,510 Epoch[20] Batch [110]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.113978,	
2017-06-24 15:05:01,144 Epoch[20] Batch [120]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.114169,	
2017-06-24 15:05:09,462 Epoch[20] Batch [130]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.113409,	
2017-06-24 15:05:18,307 Epoch[20] Batch [140]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.113322,	
2017-06-24 15:05:26,602 Epoch[20] Batch [150]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.113720,	
2017-06-24 15:05:34,853 Epoch[20] Batch [160]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113905,	
2017-06-24 15:05:43,060 Epoch[20] Batch [170]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.113756,	
2017-06-24 15:05:51,304 Epoch[20] Batch [180]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.113862,	
2017-06-24 15:05:59,515 Epoch[20] Batch [190]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.113910,	
2017-06-24 15:06:07,260 Epoch[20] Batch [200]	Speed: 10.33 samples/sec	Train-FCNLogLoss=0.114182,	
2017-06-24 15:06:14,952 Epoch[20] Batch [210]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.114322,	
2017-06-24 15:06:23,252 Epoch[20] Batch [220]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.113979,	
2017-06-24 15:06:32,212 Epoch[20] Batch [230]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.113831,	
2017-06-24 15:06:40,369 Epoch[20] Batch [240]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.113542,	
2017-06-24 15:06:48,647 Epoch[20] Batch [250]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113457,	
2017-06-24 15:06:57,082 Epoch[20] Batch [260]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.113552,	
2017-06-24 15:07:06,100 Epoch[20] Batch [270]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.113653,	
2017-06-24 15:07:15,041 Epoch[20] Batch [280]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.113487,	
2017-06-24 15:07:23,759 Epoch[20] Batch [290]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.113545,	
2017-06-24 15:07:32,063 Epoch[20] Batch [300]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.113547,	
2017-06-24 15:07:40,337 Epoch[20] Batch [310]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.113778,	
2017-06-24 15:07:48,771 Epoch[20] Batch [320]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.113639,	
2017-06-24 15:07:57,314 Epoch[20] Batch [330]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.113665,	
2017-06-24 15:08:05,038 Epoch[20] Batch [340]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.113455,	
2017-06-24 15:08:12,849 Epoch[20] Batch [350]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.113152,	
2017-06-24 15:08:20,580 Epoch[20] Batch [360]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.113364,	
2017-06-24 15:08:28,202 Epoch[20] Batch [370]	Speed: 10.50 samples/sec	Train-FCNLogLoss=0.113267,	
2017-06-24 15:08:35,973 Epoch[20] Batch [380]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.113293,	
2017-06-24 15:08:43,469 Epoch[20] Batch [390]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.113064,	
2017-06-24 15:08:51,620 Epoch[20] Batch [400]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.113095,	
2017-06-24 15:09:00,008 Epoch[20] Batch [410]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.113102,	
2017-06-24 15:09:08,455 Epoch[20] Batch [420]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113094,	
2017-06-24 15:09:17,369 Epoch[20] Batch [430]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.113447,	
2017-06-24 15:09:26,569 Epoch[20] Batch [440]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.113807,	
2017-06-24 15:09:34,994 Epoch[20] Batch [450]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.114095,	
2017-06-24 15:09:43,393 Epoch[20] Batch [460]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.114132,	
2017-06-24 15:09:51,404 Epoch[20] Batch [470]	Speed: 9.99 samples/sec	Train-FCNLogLoss=0.114158,	
2017-06-24 15:09:59,313 Epoch[20] Batch [480]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.114455,	
2017-06-24 15:10:07,096 Epoch[20] Batch [490]	Speed: 10.28 samples/sec	Train-FCNLogLoss=0.114506,	
2017-06-24 15:10:14,931 Epoch[20] Batch [500]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.114697,	
2017-06-24 15:10:22,736 Epoch[20] Batch [510]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.114789,	
2017-06-24 15:10:30,667 Epoch[20] Batch [520]	Speed: 10.09 samples/sec	Train-FCNLogLoss=0.114937,	
2017-06-24 15:10:38,686 Epoch[20] Batch [530]	Speed: 9.98 samples/sec	Train-FCNLogLoss=0.114678,	
2017-06-24 15:10:46,940 Epoch[20] Batch [540]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.114706,	
2017-06-24 15:10:54,989 Epoch[20] Batch [550]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.114835,	
2017-06-24 15:11:03,707 Epoch[20] Batch [560]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.114790,	
2017-06-24 15:11:13,007 Epoch[20] Batch [570]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.115244,	
2017-06-24 15:11:22,515 Epoch[20] Batch [580]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.115523,	
2017-06-24 15:11:30,819 Epoch[20] Batch [590]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.115715,	
2017-06-24 15:11:39,045 Epoch[20] Batch [600]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.115652,	
2017-06-24 15:11:47,632 Epoch[20] Batch [610]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.115599,	
2017-06-24 15:11:56,124 Epoch[20] Batch [620]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.115581,	
2017-06-24 15:12:05,132 Epoch[20] Batch [630]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.115717,	
2017-06-24 15:12:13,112 Epoch[20] Batch [640]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.115709,	
2017-06-24 15:12:21,232 Epoch[20] Batch [650]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.115689,	
2017-06-24 15:12:29,126 Epoch[20] Batch [660]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.115593,	
2017-06-24 15:12:36,736 Epoch[20] Batch [670]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.115516,	
2017-06-24 15:12:44,880 Epoch[20] Batch [680]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.115439,	
2017-06-24 15:12:53,091 Epoch[20] Batch [690]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.115339,	
2017-06-24 15:13:01,545 Epoch[20] Batch [700]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.115351,	
2017-06-24 15:13:09,802 Epoch[20] Batch [710]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.115405,	
2017-06-24 15:13:18,400 Epoch[20] Batch [720]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.115376,	
2017-06-24 15:13:27,406 Epoch[20] Batch [730]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.115389,	
2017-06-24 15:13:36,598 Epoch[20] Batch [740]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.115317,	
2017-06-24 15:13:38,396 Epoch[20] Train-FCNLogLoss=0.115253
2017-06-24 15:13:38,397 Epoch[20] Time cost=619.591
2017-06-24 15:13:40,378 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0021.params"
2017-06-24 15:13:43,876 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0021.states"
2017-06-24 15:13:53,781 Epoch[21] Batch [10]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.112678,	
2017-06-24 15:14:02,271 Epoch[21] Batch [20]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.111878,	
2017-06-24 15:14:10,961 Epoch[21] Batch [30]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.108752,	
2017-06-24 15:14:19,015 Epoch[21] Batch [40]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107430,	
2017-06-24 15:14:27,151 Epoch[21] Batch [50]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.107255,	
2017-06-24 15:14:35,029 Epoch[21] Batch [60]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.108625,	
2017-06-24 15:14:43,256 Epoch[21] Batch [70]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.109332,	
2017-06-24 15:14:51,489 Epoch[21] Batch [80]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110116,	
2017-06-24 15:15:00,399 Epoch[21] Batch [90]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.109984,	
2017-06-24 15:15:09,238 Epoch[21] Batch [100]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.109991,	
2017-06-24 15:15:19,389 Epoch[21] Batch [110]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.109997,	
2017-06-24 15:15:28,875 Epoch[21] Batch [120]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.110114,	
2017-06-24 15:15:38,866 Epoch[21] Batch [130]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.110412,	
2017-06-24 15:15:48,380 Epoch[21] Batch [140]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.110636,	
2017-06-24 15:15:56,414 Epoch[21] Batch [150]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.110572,	
2017-06-24 15:16:04,760 Epoch[21] Batch [160]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.110531,	
2017-06-24 15:16:13,440 Epoch[21] Batch [170]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.109935,	
2017-06-24 15:16:21,671 Epoch[21] Batch [180]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110673,	
2017-06-24 15:16:30,057 Epoch[21] Batch [190]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.110809,	
2017-06-24 15:16:38,018 Epoch[21] Batch [200]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.111109,	
2017-06-24 15:16:46,786 Epoch[21] Batch [210]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.110744,	
2017-06-24 15:16:56,040 Epoch[21] Batch [220]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.110485,	
2017-06-24 15:17:04,909 Epoch[21] Batch [230]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.110060,	
2017-06-24 15:17:14,323 Epoch[21] Batch [240]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.109759,	
2017-06-24 15:17:24,338 Epoch[21] Batch [250]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.110075,	
2017-06-24 15:17:34,038 Epoch[21] Batch [260]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.110020,	
2017-06-24 15:17:43,866 Epoch[21] Batch [270]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.109974,	
2017-06-24 15:17:53,177 Epoch[21] Batch [280]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.110436,	
2017-06-24 15:18:02,242 Epoch[21] Batch [290]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.110453,	
2017-06-24 15:18:11,235 Epoch[21] Batch [300]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.110209,	
2017-06-24 15:18:19,592 Epoch[21] Batch [310]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.110004,	
2017-06-24 15:18:27,656 Epoch[21] Batch [320]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.110165,	
2017-06-24 15:18:36,054 Epoch[21] Batch [330]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.110336,	
2017-06-24 15:18:45,462 Epoch[21] Batch [340]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.110569,	
2017-06-24 15:18:54,450 Epoch[21] Batch [350]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.110893,	
2017-06-24 15:19:03,927 Epoch[21] Batch [360]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.111242,	
2017-06-24 15:19:13,202 Epoch[21] Batch [370]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.111160,	
2017-06-24 15:19:22,385 Epoch[21] Batch [380]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.111032,	
2017-06-24 15:19:31,294 Epoch[21] Batch [390]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.111060,	
2017-06-24 15:19:40,277 Epoch[21] Batch [400]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.111002,	
2017-06-24 15:19:49,144 Epoch[21] Batch [410]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.111202,	
2017-06-24 15:19:57,124 Epoch[21] Batch [420]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.111229,	
2017-06-24 15:20:04,881 Epoch[21] Batch [430]	Speed: 10.31 samples/sec	Train-FCNLogLoss=0.111343,	
2017-06-24 15:20:12,937 Epoch[21] Batch [440]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.111389,	
2017-06-24 15:20:21,024 Epoch[21] Batch [450]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.111214,	
2017-06-24 15:20:29,429 Epoch[21] Batch [460]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.111292,	
2017-06-24 15:20:38,112 Epoch[21] Batch [470]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.111444,	
2017-06-24 15:20:47,020 Epoch[21] Batch [480]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.111387,	
2017-06-24 15:20:55,775 Epoch[21] Batch [490]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.111130,	
2017-06-24 15:21:05,536 Epoch[21] Batch [500]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.111100,	
2017-06-24 15:21:14,835 Epoch[21] Batch [510]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.111084,	
2017-06-24 15:21:23,800 Epoch[21] Batch [520]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.111330,	
2017-06-24 15:21:33,312 Epoch[21] Batch [530]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.111173,	
2017-06-24 15:21:42,226 Epoch[21] Batch [540]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.111197,	
2017-06-24 15:21:50,923 Epoch[21] Batch [550]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.111325,	
2017-06-24 15:21:59,468 Epoch[21] Batch [560]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.111247,	
2017-06-24 15:22:08,137 Epoch[21] Batch [570]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.111262,	
2017-06-24 15:22:16,918 Epoch[21] Batch [580]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.111299,	
2017-06-24 15:22:25,506 Epoch[21] Batch [590]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.111304,	
2017-06-24 15:22:34,152 Epoch[21] Batch [600]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.111258,	
2017-06-24 15:22:43,306 Epoch[21] Batch [610]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.111124,	
2017-06-24 15:22:52,270 Epoch[21] Batch [620]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.111142,	
2017-06-24 15:23:01,431 Epoch[21] Batch [630]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.111123,	
2017-06-24 15:23:09,857 Epoch[21] Batch [640]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.110989,	
2017-06-24 15:23:18,361 Epoch[21] Batch [650]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.111277,	
2017-06-24 15:23:26,925 Epoch[21] Batch [660]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.111419,	
2017-06-24 15:23:35,181 Epoch[21] Batch [670]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.112133,	
2017-06-24 15:23:43,813 Epoch[21] Batch [680]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.112432,	
2017-06-24 15:23:52,205 Epoch[21] Batch [690]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.112541,	
2017-06-24 15:24:00,695 Epoch[21] Batch [700]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.112760,	
2017-06-24 15:24:09,285 Epoch[21] Batch [710]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.112907,	
2017-06-24 15:24:17,709 Epoch[21] Batch [720]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.112983,	
2017-06-24 15:24:26,082 Epoch[21] Batch [730]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.113058,	
2017-06-24 15:24:34,510 Epoch[21] Batch [740]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.113131,	
2017-06-24 15:24:36,130 Epoch[21] Train-FCNLogLoss=0.113102
2017-06-24 15:24:36,130 Epoch[21] Time cost=652.254
2017-06-24 15:24:39,086 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0022.params"
2017-06-24 15:24:42,695 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0022.states"
2017-06-24 15:24:53,068 Epoch[22] Batch [10]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.127391,	
2017-06-24 15:25:01,683 Epoch[22] Batch [20]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.122747,	
2017-06-24 15:25:10,213 Epoch[22] Batch [30]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.119921,	
2017-06-24 15:25:18,967 Epoch[22] Batch [40]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.119009,	
2017-06-24 15:25:27,062 Epoch[22] Batch [50]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.121078,	
2017-06-24 15:25:35,837 Epoch[22] Batch [60]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.118614,	
2017-06-24 15:25:44,016 Epoch[22] Batch [70]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.119188,	
2017-06-24 15:25:52,065 Epoch[22] Batch [80]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.118787,	
2017-06-24 15:26:00,865 Epoch[22] Batch [90]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.118731,	
2017-06-24 15:26:09,627 Epoch[22] Batch [100]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.119156,	
2017-06-24 15:26:17,486 Epoch[22] Batch [110]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.118936,	
2017-06-24 15:26:25,588 Epoch[22] Batch [120]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.118479,	
2017-06-24 15:26:33,727 Epoch[22] Batch [130]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.118121,	
2017-06-24 15:26:42,257 Epoch[22] Batch [140]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.117730,	
2017-06-24 15:26:50,551 Epoch[22] Batch [150]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.117209,	
2017-06-24 15:26:59,118 Epoch[22] Batch [160]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.117149,	
2017-06-24 15:27:08,162 Epoch[22] Batch [170]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.116942,	
2017-06-24 15:27:18,034 Epoch[22] Batch [180]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.116573,	
2017-06-24 15:27:27,936 Epoch[22] Batch [190]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.116164,	
2017-06-24 15:27:38,261 Epoch[22] Batch [200]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.115815,	
2017-06-24 15:27:47,753 Epoch[22] Batch [210]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.115775,	
2017-06-24 15:27:56,568 Epoch[22] Batch [220]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.115884,	
2017-06-24 15:28:05,783 Epoch[22] Batch [230]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.115907,	
2017-06-24 15:28:14,265 Epoch[22] Batch [240]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.115887,	
2017-06-24 15:28:22,380 Epoch[22] Batch [250]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.115680,	
2017-06-24 15:28:30,962 Epoch[22] Batch [260]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.115302,	
2017-06-24 15:28:39,997 Epoch[22] Batch [270]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.115068,	
2017-06-24 15:28:48,536 Epoch[22] Batch [280]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.114968,	
2017-06-24 15:28:57,342 Epoch[22] Batch [290]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.114533,	
2017-06-24 15:29:05,747 Epoch[22] Batch [300]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.114273,	
2017-06-24 15:29:14,372 Epoch[22] Batch [310]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.114187,	
2017-06-24 15:29:22,464 Epoch[22] Batch [320]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.114021,	
2017-06-24 15:29:31,437 Epoch[22] Batch [330]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.114024,	
2017-06-24 15:29:39,988 Epoch[22] Batch [340]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.114076,	
2017-06-24 15:29:47,929 Epoch[22] Batch [350]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.114168,	
2017-06-24 15:29:56,842 Epoch[22] Batch [360]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.114111,	
2017-06-24 15:30:05,446 Epoch[22] Batch [370]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.113902,	
2017-06-24 15:30:14,281 Epoch[22] Batch [380]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.113719,	
2017-06-24 15:30:22,863 Epoch[22] Batch [390]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.113464,	
2017-06-24 15:30:31,495 Epoch[22] Batch [400]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.113204,	
2017-06-24 15:30:40,208 Epoch[22] Batch [410]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.113205,	
2017-06-24 15:30:48,818 Epoch[22] Batch [420]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.113258,	
2017-06-24 15:30:58,180 Epoch[22] Batch [430]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.113374,	
2017-06-24 15:31:06,655 Epoch[22] Batch [440]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.113722,	
2017-06-24 15:31:15,870 Epoch[22] Batch [450]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.113729,	
2017-06-24 15:31:24,979 Epoch[22] Batch [460]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.113888,	
2017-06-24 15:31:34,226 Epoch[22] Batch [470]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.113902,	
2017-06-24 15:31:42,563 Epoch[22] Batch [480]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.113942,	
2017-06-24 15:31:51,182 Epoch[22] Batch [490]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.113795,	
2017-06-24 15:31:59,677 Epoch[22] Batch [500]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.113759,	
2017-06-24 15:32:08,314 Epoch[22] Batch [510]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.113569,	
2017-06-24 15:32:17,223 Epoch[22] Batch [520]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.113520,	
2017-06-24 15:32:25,672 Epoch[22] Batch [530]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.113368,	
2017-06-24 15:32:34,453 Epoch[22] Batch [540]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.113315,	
2017-06-24 15:32:43,426 Epoch[22] Batch [550]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.113271,	
2017-06-24 15:32:52,201 Epoch[22] Batch [560]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.113236,	
2017-06-24 15:33:01,111 Epoch[22] Batch [570]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.113227,	
2017-06-24 15:33:09,896 Epoch[22] Batch [580]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.113332,	
2017-06-24 15:33:18,932 Epoch[22] Batch [590]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.113279,	
2017-06-24 15:33:27,754 Epoch[22] Batch [600]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.113191,	
2017-06-24 15:33:36,423 Epoch[22] Batch [610]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.113023,	
2017-06-24 15:33:45,405 Epoch[22] Batch [620]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.112886,	
2017-06-24 15:33:54,379 Epoch[22] Batch [630]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.112920,	
2017-06-24 15:34:03,528 Epoch[22] Batch [640]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.112925,	
2017-06-24 15:34:12,269 Epoch[22] Batch [650]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.112866,	
2017-06-24 15:34:20,599 Epoch[22] Batch [660]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.112669,	
2017-06-24 15:34:29,297 Epoch[22] Batch [670]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.112492,	
2017-06-24 15:34:37,955 Epoch[22] Batch [680]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.112321,	
2017-06-24 15:34:46,707 Epoch[22] Batch [690]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.112263,	
2017-06-24 15:34:55,599 Epoch[22] Batch [700]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.112185,	
2017-06-24 15:35:04,596 Epoch[22] Batch [710]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.112265,	
2017-06-24 15:35:13,807 Epoch[22] Batch [720]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.112235,	
2017-06-24 15:35:23,515 Epoch[22] Batch [730]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.112310,	
2017-06-24 15:35:33,455 Epoch[22] Batch [740]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.112068,	
2017-06-24 15:35:35,169 Epoch[22] Train-FCNLogLoss=0.112081
2017-06-24 15:35:35,169 Epoch[22] Time cost=652.474
2017-06-24 15:35:37,921 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0023.params"
2017-06-24 15:35:41,488 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0023.states"
2017-06-24 15:35:52,506 Epoch[23] Batch [10]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.114773,	
2017-06-24 15:36:00,952 Epoch[23] Batch [20]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.109175,	
2017-06-24 15:36:09,435 Epoch[23] Batch [30]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.107409,	
2017-06-24 15:36:18,156 Epoch[23] Batch [40]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.107557,	
2017-06-24 15:36:27,478 Epoch[23] Batch [50]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.107511,	
2017-06-24 15:36:38,000 Epoch[23] Batch [60]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.107073,	
2017-06-24 15:36:48,178 Epoch[23] Batch [70]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.107256,	
2017-06-24 15:36:58,883 Epoch[23] Batch [80]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.107646,	
2017-06-24 15:37:09,038 Epoch[23] Batch [90]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.108825,	
2017-06-24 15:37:19,101 Epoch[23] Batch [100]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.108311,	
2017-06-24 15:37:28,792 Epoch[23] Batch [110]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.110648,	
2017-06-24 15:37:38,332 Epoch[23] Batch [120]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.110644,	
2017-06-24 15:37:47,595 Epoch[23] Batch [130]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.110519,	
2017-06-24 15:37:56,149 Epoch[23] Batch [140]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.110445,	
2017-06-24 15:38:04,732 Epoch[23] Batch [150]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.110843,	
2017-06-24 15:38:13,057 Epoch[23] Batch [160]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.110475,	
2017-06-24 15:38:21,043 Epoch[23] Batch [170]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.110542,	
2017-06-24 15:38:28,883 Epoch[23] Batch [180]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.110183,	
2017-06-24 15:38:36,533 Epoch[23] Batch [190]	Speed: 10.46 samples/sec	Train-FCNLogLoss=0.110029,	
2017-06-24 15:38:43,844 Epoch[23] Batch [200]	Speed: 10.94 samples/sec	Train-FCNLogLoss=0.109893,	
2017-06-24 15:38:51,657 Epoch[23] Batch [210]	Speed: 10.24 samples/sec	Train-FCNLogLoss=0.109623,	
2017-06-24 15:38:59,657 Epoch[23] Batch [220]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.109499,	
2017-06-24 15:39:07,745 Epoch[23] Batch [230]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.109395,	
2017-06-24 15:39:15,898 Epoch[23] Batch [240]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.109603,	
2017-06-24 15:39:23,447 Epoch[23] Batch [250]	Speed: 10.60 samples/sec	Train-FCNLogLoss=0.109641,	
2017-06-24 15:39:30,858 Epoch[23] Batch [260]	Speed: 10.79 samples/sec	Train-FCNLogLoss=0.109683,	
2017-06-24 15:39:38,555 Epoch[23] Batch [270]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.109818,	
2017-06-24 15:39:45,829 Epoch[23] Batch [280]	Speed: 11.00 samples/sec	Train-FCNLogLoss=0.110015,	
2017-06-24 15:39:53,535 Epoch[23] Batch [290]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.109562,	
2017-06-24 15:40:00,730 Epoch[23] Batch [300]	Speed: 11.12 samples/sec	Train-FCNLogLoss=0.109659,	
2017-06-24 15:40:08,225 Epoch[23] Batch [310]	Speed: 10.67 samples/sec	Train-FCNLogLoss=0.109862,	
2017-06-24 15:40:15,517 Epoch[23] Batch [320]	Speed: 10.97 samples/sec	Train-FCNLogLoss=0.110111,	
2017-06-24 15:40:23,243 Epoch[23] Batch [330]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.109789,	
2017-06-24 15:40:31,167 Epoch[23] Batch [340]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.109688,	
2017-06-24 15:40:39,028 Epoch[23] Batch [350]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.109700,	
2017-06-24 15:40:46,718 Epoch[23] Batch [360]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.109533,	
2017-06-24 15:40:54,489 Epoch[23] Batch [370]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.109590,	
2017-06-24 15:41:02,286 Epoch[23] Batch [380]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.109686,	
2017-06-24 15:41:10,417 Epoch[23] Batch [390]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.109964,	
2017-06-24 15:41:18,396 Epoch[23] Batch [400]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.110093,	
2017-06-24 15:41:26,616 Epoch[23] Batch [410]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.110031,	
2017-06-24 15:41:34,497 Epoch[23] Batch [420]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.109917,	
2017-06-24 15:41:42,636 Epoch[23] Batch [430]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110219,	
2017-06-24 15:41:50,939 Epoch[23] Batch [440]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.110128,	
2017-06-24 15:41:58,863 Epoch[23] Batch [450]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.110526,	
2017-06-24 15:42:06,419 Epoch[23] Batch [460]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.110565,	
2017-06-24 15:42:14,191 Epoch[23] Batch [470]	Speed: 10.29 samples/sec	Train-FCNLogLoss=0.110624,	
2017-06-24 15:42:22,535 Epoch[23] Batch [480]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.110694,	
2017-06-24 15:42:30,514 Epoch[23] Batch [490]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.110612,	
2017-06-24 15:42:39,004 Epoch[23] Batch [500]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.110455,	
2017-06-24 15:42:46,849 Epoch[23] Batch [510]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.110367,	
2017-06-24 15:42:54,909 Epoch[23] Batch [520]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110406,	
2017-06-24 15:43:02,812 Epoch[23] Batch [530]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.110214,	
2017-06-24 15:43:10,781 Epoch[23] Batch [540]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110137,	
2017-06-24 15:43:19,299 Epoch[23] Batch [550]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.110012,	
2017-06-24 15:43:27,069 Epoch[23] Batch [560]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.110002,	
2017-06-24 15:43:34,968 Epoch[23] Batch [570]	Speed: 10.13 samples/sec	Train-FCNLogLoss=0.110445,	
2017-06-24 15:43:42,676 Epoch[23] Batch [580]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.110511,	
2017-06-24 15:43:50,501 Epoch[23] Batch [590]	Speed: 10.22 samples/sec	Train-FCNLogLoss=0.110651,	
2017-06-24 15:43:58,908 Epoch[23] Batch [600]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.110788,	
2017-06-24 15:44:07,307 Epoch[23] Batch [610]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.110766,	
2017-06-24 15:44:15,563 Epoch[23] Batch [620]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.110608,	
2017-06-24 15:44:23,121 Epoch[23] Batch [630]	Speed: 10.58 samples/sec	Train-FCNLogLoss=0.110648,	
2017-06-24 15:44:31,479 Epoch[23] Batch [640]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.110674,	
2017-06-24 15:44:39,445 Epoch[23] Batch [650]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.110565,	
2017-06-24 15:44:47,338 Epoch[23] Batch [660]	Speed: 10.14 samples/sec	Train-FCNLogLoss=0.110548,	
2017-06-24 15:44:55,392 Epoch[23] Batch [670]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.110346,	
2017-06-24 15:45:02,928 Epoch[23] Batch [680]	Speed: 10.62 samples/sec	Train-FCNLogLoss=0.110309,	
2017-06-24 15:45:10,787 Epoch[23] Batch [690]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110216,	
2017-06-24 15:45:18,709 Epoch[23] Batch [700]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.110114,	
2017-06-24 15:45:26,399 Epoch[23] Batch [710]	Speed: 10.40 samples/sec	Train-FCNLogLoss=0.110136,	
2017-06-24 15:45:34,339 Epoch[23] Batch [720]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.109949,	
2017-06-24 15:45:42,744 Epoch[23] Batch [730]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.109802,	
2017-06-24 15:45:51,099 Epoch[23] Batch [740]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.109688,	
2017-06-24 15:45:52,822 Epoch[23] Train-FCNLogLoss=0.109626
2017-06-24 15:45:52,822 Epoch[23] Time cost=611.334
2017-06-24 15:45:55,567 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0024.params"
2017-06-24 15:45:59,012 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0024.states"
2017-06-24 15:46:08,361 Epoch[24] Batch [10]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.112275,	
2017-06-24 15:46:16,602 Epoch[24] Batch [20]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.108067,	
2017-06-24 15:46:24,395 Epoch[24] Batch [30]	Speed: 10.27 samples/sec	Train-FCNLogLoss=0.103970,	
2017-06-24 15:46:32,358 Epoch[24] Batch [40]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.105190,	
2017-06-24 15:46:40,085 Epoch[24] Batch [50]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.104864,	
2017-06-24 15:46:47,694 Epoch[24] Batch [60]	Speed: 10.51 samples/sec	Train-FCNLogLoss=0.104268,	
2017-06-24 15:46:56,001 Epoch[24] Batch [70]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.104747,	
2017-06-24 15:47:04,696 Epoch[24] Batch [80]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.104126,	
2017-06-24 15:47:13,458 Epoch[24] Batch [90]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.103629,	
2017-06-24 15:47:21,433 Epoch[24] Batch [100]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.105267,	
2017-06-24 15:47:29,463 Epoch[24] Batch [110]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.105236,	
2017-06-24 15:47:37,908 Epoch[24] Batch [120]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.105305,	
2017-06-24 15:47:45,438 Epoch[24] Batch [130]	Speed: 10.63 samples/sec	Train-FCNLogLoss=0.106188,	
2017-06-24 15:47:53,351 Epoch[24] Batch [140]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.106626,	
2017-06-24 15:48:01,427 Epoch[24] Batch [150]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.107415,	
2017-06-24 15:48:09,401 Epoch[24] Batch [160]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.107014,	
2017-06-24 15:48:17,482 Epoch[24] Batch [170]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.107065,	
2017-06-24 15:48:25,436 Epoch[24] Batch [180]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.107059,	
2017-06-24 15:48:33,674 Epoch[24] Batch [190]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.106674,	
2017-06-24 15:48:41,875 Epoch[24] Batch [200]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.106177,	
2017-06-24 15:48:49,783 Epoch[24] Batch [210]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.106189,	
2017-06-24 15:48:57,647 Epoch[24] Batch [220]	Speed: 10.17 samples/sec	Train-FCNLogLoss=0.105921,	
2017-06-24 15:49:05,415 Epoch[24] Batch [230]	Speed: 10.30 samples/sec	Train-FCNLogLoss=0.106057,	
2017-06-24 15:49:13,382 Epoch[24] Batch [240]	Speed: 10.04 samples/sec	Train-FCNLogLoss=0.106015,	
2017-06-24 15:49:21,214 Epoch[24] Batch [250]	Speed: 10.21 samples/sec	Train-FCNLogLoss=0.105773,	
2017-06-24 15:49:28,930 Epoch[24] Batch [260]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.105640,	
2017-06-24 15:49:36,257 Epoch[24] Batch [270]	Speed: 10.92 samples/sec	Train-FCNLogLoss=0.105420,	
2017-06-24 15:49:44,190 Epoch[24] Batch [280]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.105506,	
2017-06-24 15:49:52,063 Epoch[24] Batch [290]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.106047,	
2017-06-24 15:49:59,882 Epoch[24] Batch [300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.105662,	
2017-06-24 15:50:07,945 Epoch[24] Batch [310]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.105331,	
2017-06-24 15:50:15,821 Epoch[24] Batch [320]	Speed: 10.16 samples/sec	Train-FCNLogLoss=0.105395,	
2017-06-24 15:50:24,165 Epoch[24] Batch [330]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.105395,	
2017-06-24 15:50:32,321 Epoch[24] Batch [340]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.105365,	
2017-06-24 15:50:40,799 Epoch[24] Batch [350]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.105400,	
2017-06-24 15:50:49,783 Epoch[24] Batch [360]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.105509,	
2017-06-24 15:50:58,690 Epoch[24] Batch [370]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.105278,	
2017-06-24 15:51:07,293 Epoch[24] Batch [380]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.105512,	
2017-06-24 15:51:15,376 Epoch[24] Batch [390]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.105841,	
2017-06-24 15:51:23,454 Epoch[24] Batch [400]	Speed: 9.90 samples/sec	Train-FCNLogLoss=0.106330,	
2017-06-24 15:51:31,337 Epoch[24] Batch [410]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.106818,	
2017-06-24 15:51:39,249 Epoch[24] Batch [420]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107036,	
2017-06-24 15:51:47,529 Epoch[24] Batch [430]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.107270,	
2017-06-24 15:51:55,512 Epoch[24] Batch [440]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.107444,	
2017-06-24 15:52:03,465 Epoch[24] Batch [450]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.107434,	
2017-06-24 15:52:11,350 Epoch[24] Batch [460]	Speed: 10.15 samples/sec	Train-FCNLogLoss=0.107355,	
2017-06-24 15:52:19,080 Epoch[24] Batch [470]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.107345,	
2017-06-24 15:52:27,024 Epoch[24] Batch [480]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.107260,	
2017-06-24 15:52:34,778 Epoch[24] Batch [490]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.107378,	
2017-06-24 15:52:42,910 Epoch[24] Batch [500]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.107398,	
2017-06-24 15:52:51,244 Epoch[24] Batch [510]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.107597,	
2017-06-24 15:52:59,300 Epoch[24] Batch [520]	Speed: 9.93 samples/sec	Train-FCNLogLoss=0.107717,	
2017-06-24 15:53:07,208 Epoch[24] Batch [530]	Speed: 10.12 samples/sec	Train-FCNLogLoss=0.107800,	
2017-06-24 15:53:15,486 Epoch[24] Batch [540]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.107795,	
2017-06-24 15:53:23,932 Epoch[24] Batch [550]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.107776,	
2017-06-24 15:53:32,347 Epoch[24] Batch [560]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.107699,	
2017-06-24 15:53:41,589 Epoch[24] Batch [570]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.108066,	
2017-06-24 15:53:48,893 Epoch[24] Batch [580]	Speed: 10.95 samples/sec	Train-FCNLogLoss=0.108067,	
2017-06-24 15:53:57,238 Epoch[24] Batch [590]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.108037,	
2017-06-24 15:54:05,611 Epoch[24] Batch [600]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.108008,	
2017-06-24 15:54:13,948 Epoch[24] Batch [610]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.107924,	
2017-06-24 15:54:22,702 Epoch[24] Batch [620]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.107901,	
2017-06-24 15:54:30,614 Epoch[24] Batch [630]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.107905,	
2017-06-24 15:54:38,592 Epoch[24] Batch [640]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.107795,	
2017-06-24 15:54:46,688 Epoch[24] Batch [650]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.107836,	
2017-06-24 15:54:55,293 Epoch[24] Batch [660]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.107916,	
2017-06-24 15:55:03,727 Epoch[24] Batch [670]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.107976,	
2017-06-24 15:55:12,489 Epoch[24] Batch [680]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.108020,	
2017-06-24 15:55:20,750 Epoch[24] Batch [690]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.108190,	
2017-06-24 15:55:29,006 Epoch[24] Batch [700]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.108155,	
2017-06-24 15:55:37,101 Epoch[24] Batch [710]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.108893,	
2017-06-24 15:55:45,782 Epoch[24] Batch [720]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.110330,	
2017-06-24 15:55:54,247 Epoch[24] Batch [730]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.111459,	
2017-06-24 15:56:02,615 Epoch[24] Batch [740]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.112060,	
2017-06-24 15:56:04,230 Epoch[24] Train-FCNLogLoss=0.112125
2017-06-24 15:56:04,230 Epoch[24] Time cost=605.218
2017-06-24 15:56:07,073 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0025.params"
2017-06-24 15:56:10,633 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0025.states"
2017-06-24 15:56:20,871 Epoch[25] Batch [10]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.118422,	
2017-06-24 15:56:29,602 Epoch[25] Batch [20]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.119059,	
2017-06-24 15:56:38,255 Epoch[25] Batch [30]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.119597,	
2017-06-24 15:56:46,521 Epoch[25] Batch [40]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.119309,	
2017-06-24 15:56:54,484 Epoch[25] Batch [50]	Speed: 10.05 samples/sec	Train-FCNLogLoss=0.118405,	
2017-06-24 15:57:02,531 Epoch[25] Batch [60]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.118544,	
2017-06-24 15:57:10,922 Epoch[25] Batch [70]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.118139,	
2017-06-24 15:57:19,892 Epoch[25] Batch [80]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.116885,	
2017-06-24 15:57:28,223 Epoch[25] Batch [90]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.116027,	
2017-06-24 15:57:36,083 Epoch[25] Batch [100]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.115870,	
2017-06-24 15:57:44,529 Epoch[25] Batch [110]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.115649,	
2017-06-24 15:57:52,630 Epoch[25] Batch [120]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.115096,	
2017-06-24 15:58:00,973 Epoch[25] Batch [130]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.115015,	
2017-06-24 15:58:08,740 Epoch[25] Batch [140]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.114224,	
2017-06-24 15:58:16,878 Epoch[25] Batch [150]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.113754,	
2017-06-24 15:58:24,822 Epoch[25] Batch [160]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.113111,	
2017-06-24 15:58:33,087 Epoch[25] Batch [170]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113508,	
2017-06-24 15:58:41,276 Epoch[25] Batch [180]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.113574,	
2017-06-24 15:58:49,543 Epoch[25] Batch [190]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.113373,	
2017-06-24 15:58:58,278 Epoch[25] Batch [200]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.113007,	
2017-06-24 15:59:06,970 Epoch[25] Batch [210]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.112628,	
2017-06-24 15:59:15,906 Epoch[25] Batch [220]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.112153,	
2017-06-24 15:59:24,941 Epoch[25] Batch [230]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.111845,	
2017-06-24 15:59:33,613 Epoch[25] Batch [240]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.111852,	
2017-06-24 15:59:42,551 Epoch[25] Batch [250]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.111438,	
2017-06-24 15:59:50,874 Epoch[25] Batch [260]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.110978,	
2017-06-24 15:59:58,869 Epoch[25] Batch [270]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.110710,	
2017-06-24 16:00:06,731 Epoch[25] Batch [280]	Speed: 10.18 samples/sec	Train-FCNLogLoss=0.110932,	
2017-06-24 16:00:14,670 Epoch[25] Batch [290]	Speed: 10.08 samples/sec	Train-FCNLogLoss=0.110952,	
2017-06-24 16:00:22,812 Epoch[25] Batch [300]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.110704,	
2017-06-24 16:00:31,083 Epoch[25] Batch [310]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.110563,	
2017-06-24 16:00:39,557 Epoch[25] Batch [320]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.110508,	
2017-06-24 16:00:48,227 Epoch[25] Batch [330]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.110501,	
2017-06-24 16:00:56,692 Epoch[25] Batch [340]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.110411,	
2017-06-24 16:01:05,000 Epoch[25] Batch [350]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.110728,	
2017-06-24 16:01:13,722 Epoch[25] Batch [360]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.110666,	
2017-06-24 16:01:21,951 Epoch[25] Batch [370]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.110720,	
2017-06-24 16:01:30,641 Epoch[25] Batch [380]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.110593,	
2017-06-24 16:01:39,076 Epoch[25] Batch [390]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.110575,	
2017-06-24 16:01:47,431 Epoch[25] Batch [400]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110550,	
2017-06-24 16:01:55,779 Epoch[25] Batch [410]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.110400,	
2017-06-24 16:02:04,205 Epoch[25] Batch [420]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.110288,	
2017-06-24 16:02:12,682 Epoch[25] Batch [430]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.110261,	
2017-06-24 16:02:21,127 Epoch[25] Batch [440]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.110558,	
2017-06-24 16:02:29,877 Epoch[25] Batch [450]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.110516,	
2017-06-24 16:02:38,024 Epoch[25] Batch [460]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.110453,	
2017-06-24 16:02:46,500 Epoch[25] Batch [470]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.110327,	
2017-06-24 16:02:55,645 Epoch[25] Batch [480]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.110438,	
2017-06-24 16:03:04,385 Epoch[25] Batch [490]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.110462,	
2017-06-24 16:03:13,060 Epoch[25] Batch [500]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.110552,	
2017-06-24 16:03:21,921 Epoch[25] Batch [510]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.110582,	
2017-06-24 16:03:30,948 Epoch[25] Batch [520]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.110590,	
2017-06-24 16:03:40,031 Epoch[25] Batch [530]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.110544,	
2017-06-24 16:03:48,413 Epoch[25] Batch [540]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.110466,	
2017-06-24 16:03:57,454 Epoch[25] Batch [550]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.110255,	
2017-06-24 16:04:06,468 Epoch[25] Batch [560]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.110267,	
2017-06-24 16:04:15,435 Epoch[25] Batch [570]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.110198,	
2017-06-24 16:04:25,398 Epoch[25] Batch [580]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.110110,	
2017-06-24 16:04:34,811 Epoch[25] Batch [590]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.110021,	
2017-06-24 16:04:44,080 Epoch[25] Batch [600]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.109980,	
2017-06-24 16:04:53,074 Epoch[25] Batch [610]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.109966,	
2017-06-24 16:05:02,167 Epoch[25] Batch [620]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.109999,	
2017-06-24 16:05:11,401 Epoch[25] Batch [630]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.109814,	
2017-06-24 16:05:20,517 Epoch[25] Batch [640]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109720,	
2017-06-24 16:05:29,340 Epoch[25] Batch [650]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.109741,	
2017-06-24 16:05:38,553 Epoch[25] Batch [660]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109822,	
2017-06-24 16:05:47,806 Epoch[25] Batch [670]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.109664,	
2017-06-24 16:05:56,633 Epoch[25] Batch [680]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.109619,	
2017-06-24 16:06:05,342 Epoch[25] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.109639,	
2017-06-24 16:06:14,182 Epoch[25] Batch [700]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.109565,	
2017-06-24 16:06:23,844 Epoch[25] Batch [710]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.109662,	
2017-06-24 16:06:32,754 Epoch[25] Batch [720]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.109758,	
2017-06-24 16:06:41,967 Epoch[25] Batch [730]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.109751,	
2017-06-24 16:06:50,753 Epoch[25] Batch [740]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.109799,	
2017-06-24 16:06:52,319 Epoch[25] Train-FCNLogLoss=0.109760
2017-06-24 16:06:52,320 Epoch[25] Time cost=641.686
2017-06-24 16:06:55,900 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0026.params"
2017-06-24 16:06:59,736 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0026.states"
2017-06-24 16:07:09,593 Epoch[26] Batch [10]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.102973,	
2017-06-24 16:07:18,084 Epoch[26] Batch [20]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.104225,	
2017-06-24 16:07:26,323 Epoch[26] Batch [30]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.106841,	
2017-06-24 16:07:35,083 Epoch[26] Batch [40]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.107939,	
2017-06-24 16:07:43,305 Epoch[26] Batch [50]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.108132,	
2017-06-24 16:07:52,190 Epoch[26] Batch [60]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.108913,	
2017-06-24 16:08:01,494 Epoch[26] Batch [70]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.109198,	
2017-06-24 16:08:10,601 Epoch[26] Batch [80]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.109139,	
2017-06-24 16:08:19,743 Epoch[26] Batch [90]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.108424,	
2017-06-24 16:08:28,497 Epoch[26] Batch [100]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.107565,	
2017-06-24 16:08:37,181 Epoch[26] Batch [110]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.106886,	
2017-06-24 16:08:45,344 Epoch[26] Batch [120]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.107170,	
2017-06-24 16:08:54,160 Epoch[26] Batch [130]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.106437,	
2017-06-24 16:09:03,296 Epoch[26] Batch [140]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.106477,	
2017-06-24 16:09:12,682 Epoch[26] Batch [150]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.106400,	
2017-06-24 16:09:21,263 Epoch[26] Batch [160]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.106242,	
2017-06-24 16:09:30,333 Epoch[26] Batch [170]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.106171,	
2017-06-24 16:09:39,247 Epoch[26] Batch [180]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.105953,	
2017-06-24 16:09:47,702 Epoch[26] Batch [190]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.105717,	
2017-06-24 16:09:56,053 Epoch[26] Batch [200]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.106005,	
2017-06-24 16:10:04,683 Epoch[26] Batch [210]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.106190,	
2017-06-24 16:10:13,524 Epoch[26] Batch [220]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.106613,	
2017-06-24 16:10:22,294 Epoch[26] Batch [230]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.106958,	
2017-06-24 16:10:30,877 Epoch[26] Batch [240]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.106920,	
2017-06-24 16:10:39,552 Epoch[26] Batch [250]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.107218,	
2017-06-24 16:10:48,415 Epoch[26] Batch [260]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.107206,	
2017-06-24 16:10:57,469 Epoch[26] Batch [270]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.107285,	
2017-06-24 16:11:06,672 Epoch[26] Batch [280]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.107509,	
2017-06-24 16:11:15,370 Epoch[26] Batch [290]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.107385,	
2017-06-24 16:11:24,428 Epoch[26] Batch [300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.107269,	
2017-06-24 16:11:33,324 Epoch[26] Batch [310]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.107100,	
2017-06-24 16:11:41,671 Epoch[26] Batch [320]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.106960,	
2017-06-24 16:11:49,993 Epoch[26] Batch [330]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.106920,	
2017-06-24 16:11:58,472 Epoch[26] Batch [340]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.107481,	
2017-06-24 16:12:07,070 Epoch[26] Batch [350]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.107690,	
2017-06-24 16:12:15,366 Epoch[26] Batch [360]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.107818,	
2017-06-24 16:12:23,867 Epoch[26] Batch [370]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.107584,	
2017-06-24 16:12:32,319 Epoch[26] Batch [380]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.107521,	
2017-06-24 16:12:40,605 Epoch[26] Batch [390]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.107681,	
2017-06-24 16:12:48,929 Epoch[26] Batch [400]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.107505,	
2017-06-24 16:12:57,067 Epoch[26] Batch [410]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.107308,	
2017-06-24 16:13:05,108 Epoch[26] Batch [420]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.107460,	
2017-06-24 16:13:13,455 Epoch[26] Batch [430]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.107444,	
2017-06-24 16:13:21,529 Epoch[26] Batch [440]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.107586,	
2017-06-24 16:13:29,754 Epoch[26] Batch [450]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.107378,	
2017-06-24 16:13:37,695 Epoch[26] Batch [460]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.107333,	
2017-06-24 16:13:46,381 Epoch[26] Batch [470]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.107183,	
2017-06-24 16:13:55,279 Epoch[26] Batch [480]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.107070,	
2017-06-24 16:14:03,966 Epoch[26] Batch [490]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.106864,	
2017-06-24 16:14:12,421 Epoch[26] Batch [500]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.106869,	
2017-06-24 16:14:20,693 Epoch[26] Batch [510]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.106795,	
2017-06-24 16:14:29,004 Epoch[26] Batch [520]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.106817,	
2017-06-24 16:14:37,294 Epoch[26] Batch [530]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.106769,	
2017-06-24 16:14:45,848 Epoch[26] Batch [540]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.106592,	
2017-06-24 16:14:54,718 Epoch[26] Batch [550]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.106589,	
2017-06-24 16:15:03,270 Epoch[26] Batch [560]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.106511,	
2017-06-24 16:15:11,719 Epoch[26] Batch [570]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.106457,	
2017-06-24 16:15:20,195 Epoch[26] Batch [580]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.106384,	
2017-06-24 16:15:28,181 Epoch[26] Batch [590]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.106398,	
2017-06-24 16:15:36,284 Epoch[26] Batch [600]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.106285,	
2017-06-24 16:15:44,531 Epoch[26] Batch [610]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.106397,	
2017-06-24 16:15:52,933 Epoch[26] Batch [620]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.106315,	
2017-06-24 16:16:01,044 Epoch[26] Batch [630]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.106304,	
2017-06-24 16:16:09,341 Epoch[26] Batch [640]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.106307,	
2017-06-24 16:16:17,880 Epoch[26] Batch [650]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.106311,	
2017-06-24 16:16:26,478 Epoch[26] Batch [660]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.106373,	
2017-06-24 16:16:34,803 Epoch[26] Batch [670]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.106452,	
2017-06-24 16:16:43,451 Epoch[26] Batch [680]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.106416,	
2017-06-24 16:16:52,039 Epoch[26] Batch [690]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.106425,	
2017-06-24 16:17:00,512 Epoch[26] Batch [700]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.106349,	
2017-06-24 16:17:08,725 Epoch[26] Batch [710]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.106269,	
2017-06-24 16:17:16,999 Epoch[26] Batch [720]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.106238,	
2017-06-24 16:17:25,228 Epoch[26] Batch [730]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.106074,	
2017-06-24 16:17:33,849 Epoch[26] Batch [740]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.106017,	
2017-06-24 16:17:35,701 Epoch[26] Train-FCNLogLoss=0.106018
2017-06-24 16:17:35,701 Epoch[26] Time cost=635.965
2017-06-24 16:17:38,977 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0027.params"
2017-06-24 16:17:42,740 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0027.states"
2017-06-24 16:17:52,749 Epoch[27] Batch [10]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.106339,	
2017-06-24 16:18:00,985 Epoch[27] Batch [20]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.105799,	
2017-06-24 16:18:09,659 Epoch[27] Batch [30]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.103601,	
2017-06-24 16:18:18,455 Epoch[27] Batch [40]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.103434,	
2017-06-24 16:18:26,773 Epoch[27] Batch [50]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.104345,	
2017-06-24 16:18:35,760 Epoch[27] Batch [60]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.103562,	
2017-06-24 16:18:45,273 Epoch[27] Batch [70]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.103684,	
2017-06-24 16:18:54,374 Epoch[27] Batch [80]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.103990,	
2017-06-24 16:19:03,667 Epoch[27] Batch [90]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.104236,	
2017-06-24 16:19:12,644 Epoch[27] Batch [100]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.103669,	
2017-06-24 16:19:21,726 Epoch[27] Batch [110]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.103910,	
2017-06-24 16:19:30,745 Epoch[27] Batch [120]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.104097,	
2017-06-24 16:19:39,506 Epoch[27] Batch [130]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.104126,	
2017-06-24 16:19:49,237 Epoch[27] Batch [140]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.104125,	
2017-06-24 16:19:58,606 Epoch[27] Batch [150]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.103699,	
2017-06-24 16:20:07,579 Epoch[27] Batch [160]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.103971,	
2017-06-24 16:20:16,035 Epoch[27] Batch [170]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.103989,	
2017-06-24 16:20:24,560 Epoch[27] Batch [180]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.103210,	
2017-06-24 16:20:33,352 Epoch[27] Batch [190]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.102678,	
2017-06-24 16:20:41,798 Epoch[27] Batch [200]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.102272,	
2017-06-24 16:20:50,545 Epoch[27] Batch [210]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.102103,	
2017-06-24 16:21:00,150 Epoch[27] Batch [220]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.101950,	
2017-06-24 16:21:09,861 Epoch[27] Batch [230]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.101911,	
2017-06-24 16:21:19,526 Epoch[27] Batch [240]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.101882,	
2017-06-24 16:21:29,739 Epoch[27] Batch [250]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.102179,	
2017-06-24 16:21:40,234 Epoch[27] Batch [260]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.102048,	
2017-06-24 16:21:50,480 Epoch[27] Batch [270]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.102060,	
2017-06-24 16:22:00,308 Epoch[27] Batch [280]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.102075,	
2017-06-24 16:22:09,850 Epoch[27] Batch [290]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.102016,	
2017-06-24 16:22:19,421 Epoch[27] Batch [300]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.102142,	
2017-06-24 16:22:28,602 Epoch[27] Batch [310]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.102290,	
2017-06-24 16:22:37,929 Epoch[27] Batch [320]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.102553,	
2017-06-24 16:22:47,090 Epoch[27] Batch [330]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.102756,	
2017-06-24 16:22:55,890 Epoch[27] Batch [340]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.103039,	
2017-06-24 16:23:04,274 Epoch[27] Batch [350]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.103265,	
2017-06-24 16:23:13,739 Epoch[27] Batch [360]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.103074,	
2017-06-24 16:23:24,174 Epoch[27] Batch [370]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.103093,	
2017-06-24 16:23:33,925 Epoch[27] Batch [380]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.103220,	
2017-06-24 16:23:44,121 Epoch[27] Batch [390]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.103207,	
2017-06-24 16:23:53,961 Epoch[27] Batch [400]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.103071,	
2017-06-24 16:24:03,085 Epoch[27] Batch [410]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.103078,	
2017-06-24 16:24:12,350 Epoch[27] Batch [420]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.103023,	
2017-06-24 16:24:21,913 Epoch[27] Batch [430]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.102858,	
2017-06-24 16:24:31,372 Epoch[27] Batch [440]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.102653,	
2017-06-24 16:24:40,683 Epoch[27] Batch [450]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.102684,	
2017-06-24 16:24:50,157 Epoch[27] Batch [460]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.102828,	
2017-06-24 16:24:59,472 Epoch[27] Batch [470]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.102855,	
2017-06-24 16:25:08,546 Epoch[27] Batch [480]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.103065,	
2017-06-24 16:25:17,771 Epoch[27] Batch [490]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.103285,	
2017-06-24 16:25:27,406 Epoch[27] Batch [500]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.103609,	
2017-06-24 16:25:35,910 Epoch[27] Batch [510]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.103780,	
2017-06-24 16:25:44,501 Epoch[27] Batch [520]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.103934,	
2017-06-24 16:25:53,611 Epoch[27] Batch [530]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.104018,	
2017-06-24 16:26:02,227 Epoch[27] Batch [540]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.104028,	
2017-06-24 16:26:11,018 Epoch[27] Batch [550]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.104042,	
2017-06-24 16:26:19,646 Epoch[27] Batch [560]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.104130,	
2017-06-24 16:26:28,570 Epoch[27] Batch [570]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.104209,	
2017-06-24 16:26:37,043 Epoch[27] Batch [580]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.104063,	
2017-06-24 16:26:45,567 Epoch[27] Batch [590]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.104000,	
2017-06-24 16:26:53,987 Epoch[27] Batch [600]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.103943,	
2017-06-24 16:27:03,192 Epoch[27] Batch [610]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.103925,	
2017-06-24 16:27:12,067 Epoch[27] Batch [620]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.103949,	
2017-06-24 16:27:20,565 Epoch[27] Batch [630]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.103833,	
2017-06-24 16:27:30,038 Epoch[27] Batch [640]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.103678,	
2017-06-24 16:27:39,025 Epoch[27] Batch [650]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.103524,	
2017-06-24 16:27:47,363 Epoch[27] Batch [660]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.103542,	
2017-06-24 16:27:55,760 Epoch[27] Batch [670]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.103560,	
2017-06-24 16:28:04,022 Epoch[27] Batch [680]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.103481,	
2017-06-24 16:28:12,852 Epoch[27] Batch [690]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103540,	
2017-06-24 16:28:21,207 Epoch[27] Batch [700]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.103440,	
2017-06-24 16:28:30,003 Epoch[27] Batch [710]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.103420,	
2017-06-24 16:28:38,832 Epoch[27] Batch [720]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.103405,	
2017-06-24 16:28:47,504 Epoch[27] Batch [730]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.103457,	
2017-06-24 16:28:56,524 Epoch[27] Batch [740]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.103604,	
2017-06-24 16:28:58,178 Epoch[27] Train-FCNLogLoss=0.103570
2017-06-24 16:28:58,178 Epoch[27] Time cost=675.438
2017-06-24 16:29:01,394 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0028.params"
2017-06-24 16:29:05,176 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0028.states"
2017-06-24 16:29:15,605 Epoch[28] Batch [10]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.108005,	
2017-06-24 16:29:25,230 Epoch[28] Batch [20]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.103383,	
2017-06-24 16:29:34,561 Epoch[28] Batch [30]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.101809,	
2017-06-24 16:29:43,777 Epoch[28] Batch [40]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.101995,	
2017-06-24 16:29:53,445 Epoch[28] Batch [50]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.102817,	
2017-06-24 16:30:02,630 Epoch[28] Batch [60]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.101349,	
2017-06-24 16:30:12,511 Epoch[28] Batch [70]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.101428,	
2017-06-24 16:30:21,536 Epoch[28] Batch [80]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.102105,	
2017-06-24 16:30:30,460 Epoch[28] Batch [90]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.101678,	
2017-06-24 16:30:39,015 Epoch[28] Batch [100]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.101677,	
2017-06-24 16:30:47,710 Epoch[28] Batch [110]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.101967,	
2017-06-24 16:30:57,025 Epoch[28] Batch [120]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.102589,	
2017-06-24 16:31:07,049 Epoch[28] Batch [130]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.102521,	
2017-06-24 16:31:16,562 Epoch[28] Batch [140]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.102427,	
2017-06-24 16:31:26,485 Epoch[28] Batch [150]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.102382,	
2017-06-24 16:31:36,284 Epoch[28] Batch [160]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.102608,	
2017-06-24 16:31:46,207 Epoch[28] Batch [170]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.103268,	
2017-06-24 16:31:55,377 Epoch[28] Batch [180]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.103868,	
2017-06-24 16:32:04,227 Epoch[28] Batch [190]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.103904,	
2017-06-24 16:32:13,254 Epoch[28] Batch [200]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.103850,	
2017-06-24 16:32:22,247 Epoch[28] Batch [210]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.103786,	
2017-06-24 16:32:31,898 Epoch[28] Batch [220]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.103569,	
2017-06-24 16:32:42,000 Epoch[28] Batch [230]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.103285,	
2017-06-24 16:32:51,559 Epoch[28] Batch [240]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.103252,	
2017-06-24 16:33:01,443 Epoch[28] Batch [250]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.103350,	
2017-06-24 16:33:11,203 Epoch[28] Batch [260]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.103391,	
2017-06-24 16:33:21,095 Epoch[28] Batch [270]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.103363,	
2017-06-24 16:33:31,047 Epoch[28] Batch [280]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.103553,	
2017-06-24 16:33:40,757 Epoch[28] Batch [290]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.103584,	
2017-06-24 16:33:50,298 Epoch[28] Batch [300]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.103245,	
2017-06-24 16:33:59,804 Epoch[28] Batch [310]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.103245,	
2017-06-24 16:34:09,166 Epoch[28] Batch [320]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.103029,	
2017-06-24 16:34:18,544 Epoch[28] Batch [330]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.103061,	
2017-06-24 16:34:28,002 Epoch[28] Batch [340]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.103184,	
2017-06-24 16:34:37,788 Epoch[28] Batch [350]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.103222,	
2017-06-24 16:34:46,991 Epoch[28] Batch [360]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.103107,	
2017-06-24 16:34:56,627 Epoch[28] Batch [370]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.103096,	
2017-06-24 16:35:05,866 Epoch[28] Batch [380]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.103074,	
2017-06-24 16:35:15,286 Epoch[28] Batch [390]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.103082,	
2017-06-24 16:35:24,935 Epoch[28] Batch [400]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.102965,	
2017-06-24 16:35:34,101 Epoch[28] Batch [410]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.102851,	
2017-06-24 16:35:43,152 Epoch[28] Batch [420]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.102632,	
2017-06-24 16:35:52,913 Epoch[28] Batch [430]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.102636,	
2017-06-24 16:36:03,013 Epoch[28] Batch [440]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.102593,	
2017-06-24 16:36:12,980 Epoch[28] Batch [450]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.102509,	
2017-06-24 16:36:22,379 Epoch[28] Batch [460]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.102583,	
2017-06-24 16:36:31,862 Epoch[28] Batch [470]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.102607,	
2017-06-24 16:36:41,643 Epoch[28] Batch [480]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.102603,	
2017-06-24 16:36:50,799 Epoch[28] Batch [490]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.102465,	
2017-06-24 16:36:59,867 Epoch[28] Batch [500]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.102459,	
2017-06-24 16:37:09,122 Epoch[28] Batch [510]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.102468,	
2017-06-24 16:37:18,012 Epoch[28] Batch [520]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.102429,	
2017-06-24 16:37:27,974 Epoch[28] Batch [530]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.102430,	
2017-06-24 16:37:38,030 Epoch[28] Batch [540]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.102495,	
2017-06-24 16:37:47,647 Epoch[28] Batch [550]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.102384,	
2017-06-24 16:37:57,358 Epoch[28] Batch [560]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.102430,	
2017-06-24 16:38:06,948 Epoch[28] Batch [570]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.102512,	
2017-06-24 16:38:15,974 Epoch[28] Batch [580]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.102430,	
2017-06-24 16:38:26,174 Epoch[28] Batch [590]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.102405,	
2017-06-24 16:38:36,511 Epoch[28] Batch [600]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.102331,	
2017-06-24 16:38:45,457 Epoch[28] Batch [610]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.102264,	
2017-06-24 16:38:54,724 Epoch[28] Batch [620]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.102330,	
2017-06-24 16:39:04,922 Epoch[28] Batch [630]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.102243,	
2017-06-24 16:39:14,773 Epoch[28] Batch [640]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.102217,	
2017-06-24 16:39:24,514 Epoch[28] Batch [650]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.102194,	
2017-06-24 16:39:34,752 Epoch[28] Batch [660]	Speed: 7.81 samples/sec	Train-FCNLogLoss=0.102233,	
2017-06-24 16:39:44,165 Epoch[28] Batch [670]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.102211,	
2017-06-24 16:39:54,166 Epoch[28] Batch [680]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.102185,	
2017-06-24 16:40:03,723 Epoch[28] Batch [690]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.102278,	
2017-06-24 16:40:12,969 Epoch[28] Batch [700]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.102194,	
2017-06-24 16:40:22,271 Epoch[28] Batch [710]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.102220,	
2017-06-24 16:40:31,240 Epoch[28] Batch [720]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.102207,	
2017-06-24 16:40:41,051 Epoch[28] Batch [730]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.102299,	
2017-06-24 16:40:51,411 Epoch[28] Batch [740]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.102283,	
2017-06-24 16:40:53,432 Epoch[28] Train-FCNLogLoss=0.102252
2017-06-24 16:40:53,433 Epoch[28] Time cost=708.256
2017-06-24 16:40:56,928 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0029.params"
2017-06-24 16:41:00,770 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0029.states"
2017-06-24 16:41:12,870 Epoch[29] Batch [10]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.105493,	
2017-06-24 16:41:22,976 Epoch[29] Batch [20]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.099807,	
2017-06-24 16:41:32,918 Epoch[29] Batch [30]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.099450,	
2017-06-24 16:41:42,882 Epoch[29] Batch [40]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.099262,	
2017-06-24 16:41:51,968 Epoch[29] Batch [50]	Speed: 8.81 samples/sec	Train-FCNLogLoss=0.099323,	
2017-06-24 16:42:00,965 Epoch[29] Batch [60]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.099538,	
2017-06-24 16:42:10,035 Epoch[29] Batch [70]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.099129,	
2017-06-24 16:42:19,228 Epoch[29] Batch [80]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.099041,	
2017-06-24 16:42:28,466 Epoch[29] Batch [90]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.100799,	
2017-06-24 16:42:37,802 Epoch[29] Batch [100]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.100136,	
2017-06-24 16:42:48,137 Epoch[29] Batch [110]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.100251,	
2017-06-24 16:42:57,750 Epoch[29] Batch [120]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.100520,	
2017-06-24 16:43:07,557 Epoch[29] Batch [130]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.100135,	
2017-06-24 16:43:16,986 Epoch[29] Batch [140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.099906,	
2017-06-24 16:43:26,203 Epoch[29] Batch [150]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.099809,	
2017-06-24 16:43:34,977 Epoch[29] Batch [160]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.099725,	
2017-06-24 16:43:44,733 Epoch[29] Batch [170]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.099687,	
2017-06-24 16:43:54,232 Epoch[29] Batch [180]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.099992,	
2017-06-24 16:44:03,755 Epoch[29] Batch [190]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.100453,	
2017-06-24 16:44:13,577 Epoch[29] Batch [200]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.100023,	
2017-06-24 16:44:23,309 Epoch[29] Batch [210]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.100483,	
2017-06-24 16:44:32,709 Epoch[29] Batch [220]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.100230,	
2017-06-24 16:44:42,274 Epoch[29] Batch [230]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.100236,	
2017-06-24 16:44:52,314 Epoch[29] Batch [240]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.100256,	
2017-06-24 16:45:01,330 Epoch[29] Batch [250]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.100277,	
2017-06-24 16:45:10,256 Epoch[29] Batch [260]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.100430,	
2017-06-24 16:45:20,704 Epoch[29] Batch [270]	Speed: 7.66 samples/sec	Train-FCNLogLoss=0.100612,	
2017-06-24 16:45:30,762 Epoch[29] Batch [280]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.100401,	
2017-06-24 16:45:40,999 Epoch[29] Batch [290]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.100332,	
2017-06-24 16:45:50,811 Epoch[29] Batch [300]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.100145,	
2017-06-24 16:46:01,011 Epoch[29] Batch [310]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.099933,	
2017-06-24 16:46:10,531 Epoch[29] Batch [320]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.100125,	
2017-06-24 16:46:19,665 Epoch[29] Batch [330]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.100112,	
2017-06-24 16:46:28,686 Epoch[29] Batch [340]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.100026,	
2017-06-24 16:46:38,103 Epoch[29] Batch [350]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.099862,	
2017-06-24 16:46:47,304 Epoch[29] Batch [360]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.099905,	
2017-06-24 16:46:57,014 Epoch[29] Batch [370]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.100025,	
2017-06-24 16:47:06,816 Epoch[29] Batch [380]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.099999,	
2017-06-24 16:47:16,617 Epoch[29] Batch [390]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.099964,	
2017-06-24 16:47:26,726 Epoch[29] Batch [400]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.100138,	
2017-06-24 16:47:35,983 Epoch[29] Batch [410]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.100377,	
2017-06-24 16:47:46,152 Epoch[29] Batch [420]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.100396,	
2017-06-24 16:47:56,610 Epoch[29] Batch [430]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.100528,	
2017-06-24 16:48:06,198 Epoch[29] Batch [440]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.100374,	
2017-06-24 16:48:14,973 Epoch[29] Batch [450]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.100546,	
2017-06-24 16:48:24,159 Epoch[29] Batch [460]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.100609,	
2017-06-24 16:48:33,930 Epoch[29] Batch [470]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.100628,	
2017-06-24 16:48:43,885 Epoch[29] Batch [480]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.100498,	
2017-06-24 16:48:53,241 Epoch[29] Batch [490]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.100547,	
2017-06-24 16:49:02,430 Epoch[29] Batch [500]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.100626,	
2017-06-24 16:49:12,150 Epoch[29] Batch [510]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.100597,	
2017-06-24 16:49:21,286 Epoch[29] Batch [520]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.100521,	
2017-06-24 16:49:30,450 Epoch[29] Batch [530]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.100572,	
2017-06-24 16:49:39,757 Epoch[29] Batch [540]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.100597,	
2017-06-24 16:49:49,412 Epoch[29] Batch [550]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.100974,	
2017-06-24 16:49:58,343 Epoch[29] Batch [560]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.101022,	
2017-06-24 16:50:07,831 Epoch[29] Batch [570]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.100967,	
2017-06-24 16:50:17,348 Epoch[29] Batch [580]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.100996,	
2017-06-24 16:50:27,261 Epoch[29] Batch [590]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.101010,	
2017-06-24 16:50:37,035 Epoch[29] Batch [600]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.100975,	
2017-06-24 16:50:46,477 Epoch[29] Batch [610]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.101045,	
2017-06-24 16:50:56,334 Epoch[29] Batch [620]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.101118,	
2017-06-24 16:51:06,469 Epoch[29] Batch [630]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.101118,	
2017-06-24 16:51:16,254 Epoch[29] Batch [640]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.101187,	
2017-06-24 16:51:25,757 Epoch[29] Batch [650]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.101198,	
2017-06-24 16:51:35,271 Epoch[29] Batch [660]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.101168,	
2017-06-24 16:51:44,975 Epoch[29] Batch [670]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.101100,	
2017-06-24 16:51:54,394 Epoch[29] Batch [680]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.100969,	
2017-06-24 16:52:04,522 Epoch[29] Batch [690]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.100826,	
2017-06-24 16:52:14,512 Epoch[29] Batch [700]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.100735,	
2017-06-24 16:52:24,509 Epoch[29] Batch [710]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.100708,	
2017-06-24 16:52:34,225 Epoch[29] Batch [720]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.100674,	
2017-06-24 16:52:44,240 Epoch[29] Batch [730]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.100768,	
2017-06-24 16:52:53,427 Epoch[29] Batch [740]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.100779,	
2017-06-24 16:52:55,155 Epoch[29] Train-FCNLogLoss=0.100797
2017-06-24 16:52:55,155 Epoch[29] Time cost=714.385
2017-06-24 16:52:58,365 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0030.params"
2017-06-24 16:53:02,156 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0030.states"
2017-06-24 16:53:13,464 Epoch[30] Batch [10]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.093689,	
2017-06-24 16:53:23,194 Epoch[30] Batch [20]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.094634,	
2017-06-24 16:53:32,974 Epoch[30] Batch [30]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.095944,	
2017-06-24 16:53:42,572 Epoch[30] Batch [40]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.096705,	
2017-06-24 16:53:52,407 Epoch[30] Batch [50]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.096927,	
2017-06-24 16:54:01,151 Epoch[30] Batch [60]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.098318,	
2017-06-24 16:54:10,714 Epoch[30] Batch [70]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.098185,	
2017-06-24 16:54:20,655 Epoch[30] Batch [80]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.099247,	
2017-06-24 16:54:29,655 Epoch[30] Batch [90]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.099874,	
2017-06-24 16:54:38,988 Epoch[30] Batch [100]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.099923,	
2017-06-24 16:54:48,580 Epoch[30] Batch [110]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.098976,	
2017-06-24 16:54:58,626 Epoch[30] Batch [120]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.099366,	
2017-06-24 16:55:07,755 Epoch[30] Batch [130]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.099206,	
2017-06-24 16:55:18,254 Epoch[30] Batch [140]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.098762,	
2017-06-24 16:55:28,650 Epoch[30] Batch [150]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.098581,	
2017-06-24 16:55:37,707 Epoch[30] Batch [160]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.098605,	
2017-06-24 16:55:47,342 Epoch[30] Batch [170]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.098141,	
2017-06-24 16:55:57,293 Epoch[30] Batch [180]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.098354,	
2017-06-24 16:56:06,276 Epoch[30] Batch [190]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.098603,	
2017-06-24 16:56:15,667 Epoch[30] Batch [200]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.098961,	
2017-06-24 16:56:24,891 Epoch[30] Batch [210]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.098907,	
2017-06-24 16:56:35,290 Epoch[30] Batch [220]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.098906,	
2017-06-24 16:56:45,371 Epoch[30] Batch [230]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.099050,	
2017-06-24 16:56:55,159 Epoch[30] Batch [240]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.098667,	
2017-06-24 16:57:04,570 Epoch[30] Batch [250]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.098607,	
2017-06-24 16:57:14,487 Epoch[30] Batch [260]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.098668,	
2017-06-24 16:57:24,061 Epoch[30] Batch [270]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.098679,	
2017-06-24 16:57:33,837 Epoch[30] Batch [280]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.098536,	
2017-06-24 16:57:43,523 Epoch[30] Batch [290]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.098499,	
2017-06-24 16:57:52,579 Epoch[30] Batch [300]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.098553,	
2017-06-24 16:58:02,298 Epoch[30] Batch [310]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.098804,	
2017-06-24 16:58:11,711 Epoch[30] Batch [320]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.098822,	
2017-06-24 16:58:21,761 Epoch[30] Batch [330]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.099139,	
2017-06-24 16:58:31,306 Epoch[30] Batch [340]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.098977,	
2017-06-24 16:58:41,169 Epoch[30] Batch [350]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.099039,	
2017-06-24 16:58:51,115 Epoch[30] Batch [360]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.099344,	
2017-06-24 16:59:00,589 Epoch[30] Batch [370]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.099541,	
2017-06-24 16:59:09,699 Epoch[30] Batch [380]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.099794,	
2017-06-24 16:59:19,039 Epoch[30] Batch [390]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.099837,	
2017-06-24 16:59:28,357 Epoch[30] Batch [400]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.099763,	
2017-06-24 16:59:37,687 Epoch[30] Batch [410]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.099646,	
2017-06-24 16:59:48,468 Epoch[30] Batch [420]	Speed: 7.42 samples/sec	Train-FCNLogLoss=0.099814,	
2017-06-24 16:59:58,412 Epoch[30] Batch [430]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.099832,	
2017-06-24 17:00:07,956 Epoch[30] Batch [440]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.099644,	
2017-06-24 17:00:17,429 Epoch[30] Batch [450]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.099557,	
2017-06-24 17:00:27,055 Epoch[30] Batch [460]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.099453,	
2017-06-24 17:00:36,359 Epoch[30] Batch [470]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.099411,	
2017-06-24 17:00:45,678 Epoch[30] Batch [480]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.099379,	
2017-06-24 17:00:55,439 Epoch[30] Batch [490]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.099380,	
2017-06-24 17:01:04,629 Epoch[30] Batch [500]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.099612,	
2017-06-24 17:01:14,843 Epoch[30] Batch [510]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.099592,	
2017-06-24 17:01:24,201 Epoch[30] Batch [520]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.099640,	
2017-06-24 17:01:34,225 Epoch[30] Batch [530]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.099641,	
2017-06-24 17:01:43,729 Epoch[30] Batch [540]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099736,	
2017-06-24 17:01:53,485 Epoch[30] Batch [550]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.099731,	
2017-06-24 17:02:02,803 Epoch[30] Batch [560]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.099830,	
2017-06-24 17:02:12,187 Epoch[30] Batch [570]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.099747,	
2017-06-24 17:02:22,008 Epoch[30] Batch [580]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.099646,	
2017-06-24 17:02:31,296 Epoch[30] Batch [590]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.099559,	
2017-06-24 17:02:40,740 Epoch[30] Batch [600]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.099501,	
2017-06-24 17:02:50,037 Epoch[30] Batch [610]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.099459,	
2017-06-24 17:02:59,884 Epoch[30] Batch [620]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.099439,	
2017-06-24 17:03:09,928 Epoch[30] Batch [630]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.099443,	
2017-06-24 17:03:19,920 Epoch[30] Batch [640]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.099508,	
2017-06-24 17:03:29,517 Epoch[30] Batch [650]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.099581,	
2017-06-24 17:03:39,728 Epoch[30] Batch [660]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.099517,	
2017-06-24 17:03:49,567 Epoch[30] Batch [670]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.099545,	
2017-06-24 17:03:59,217 Epoch[30] Batch [680]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.099599,	
2017-06-24 17:04:09,439 Epoch[30] Batch [690]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.099490,	
2017-06-24 17:04:18,926 Epoch[30] Batch [700]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099446,	
2017-06-24 17:04:28,515 Epoch[30] Batch [710]	Speed: 8.34 samples/sec	Train-FCNLogLoss=0.099313,	
2017-06-24 17:04:38,655 Epoch[30] Batch [720]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.099326,	
2017-06-24 17:04:49,200 Epoch[30] Batch [730]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.099363,	
2017-06-24 17:04:58,962 Epoch[30] Batch [740]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.099337,	
2017-06-24 17:05:00,913 Epoch[30] Train-FCNLogLoss=0.099361
2017-06-24 17:05:00,914 Epoch[30] Time cost=718.758
2017-06-24 17:05:04,338 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0031.params"
2017-06-24 17:05:08,078 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0031.states"
2017-06-24 17:05:19,306 Epoch[31] Batch [10]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.113187,	
2017-06-24 17:05:28,511 Epoch[31] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.117345,	
2017-06-24 17:05:37,862 Epoch[31] Batch [30]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.120050,	
2017-06-24 17:05:46,669 Epoch[31] Batch [40]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.124007,	
2017-06-24 17:05:56,081 Epoch[31] Batch [50]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.122558,	
2017-06-24 17:06:05,708 Epoch[31] Batch [60]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.120927,	
2017-06-24 17:06:15,256 Epoch[31] Batch [70]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.119802,	
2017-06-24 17:06:25,110 Epoch[31] Batch [80]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.117269,	
2017-06-24 17:06:34,549 Epoch[31] Batch [90]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.114702,	
2017-06-24 17:06:44,319 Epoch[31] Batch [100]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.113445,	
2017-06-24 17:06:53,871 Epoch[31] Batch [110]	Speed: 8.38 samples/sec	Train-FCNLogLoss=0.113632,	
2017-06-24 17:07:03,147 Epoch[31] Batch [120]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.114751,	
2017-06-24 17:07:12,961 Epoch[31] Batch [130]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.115533,	
2017-06-24 17:07:21,987 Epoch[31] Batch [140]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.115149,	
2017-06-24 17:07:31,504 Epoch[31] Batch [150]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.114528,	
2017-06-24 17:07:40,966 Epoch[31] Batch [160]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.114407,	
2017-06-24 17:07:51,035 Epoch[31] Batch [170]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.113856,	
2017-06-24 17:08:00,510 Epoch[31] Batch [180]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.113643,	
2017-06-24 17:08:10,064 Epoch[31] Batch [190]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.113510,	
2017-06-24 17:08:19,177 Epoch[31] Batch [200]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.113921,	
2017-06-24 17:08:28,434 Epoch[31] Batch [210]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.113436,	
2017-06-24 17:08:37,695 Epoch[31] Batch [220]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.112630,	
2017-06-24 17:08:47,024 Epoch[31] Batch [230]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.112455,	
2017-06-24 17:08:56,788 Epoch[31] Batch [240]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.112079,	
2017-06-24 17:09:06,240 Epoch[31] Batch [250]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.111720,	
2017-06-24 17:09:16,144 Epoch[31] Batch [260]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.111427,	
2017-06-24 17:09:25,991 Epoch[31] Batch [270]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.111196,	
2017-06-24 17:09:35,758 Epoch[31] Batch [280]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.110779,	
2017-06-24 17:09:45,692 Epoch[31] Batch [290]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.110918,	
2017-06-24 17:09:54,607 Epoch[31] Batch [300]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.110643,	
2017-06-24 17:10:03,620 Epoch[31] Batch [310]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.110506,	
2017-06-24 17:10:12,734 Epoch[31] Batch [320]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.110255,	
2017-06-24 17:10:22,779 Epoch[31] Batch [330]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.110078,	
2017-06-24 17:10:31,935 Epoch[31] Batch [340]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.109795,	
2017-06-24 17:10:41,729 Epoch[31] Batch [350]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.109593,	
2017-06-24 17:10:51,438 Epoch[31] Batch [360]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.109587,	
2017-06-24 17:11:01,298 Epoch[31] Batch [370]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.109152,	
2017-06-24 17:11:11,373 Epoch[31] Batch [380]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.108940,	
2017-06-24 17:11:20,431 Epoch[31] Batch [390]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.108964,	
2017-06-24 17:11:29,078 Epoch[31] Batch [400]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.108708,	
2017-06-24 17:11:37,726 Epoch[31] Batch [410]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.108405,	
2017-06-24 17:11:46,378 Epoch[31] Batch [420]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.108364,	
2017-06-24 17:11:55,965 Epoch[31] Batch [430]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.108215,	
2017-06-24 17:12:04,560 Epoch[31] Batch [440]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.108054,	
2017-06-24 17:12:14,036 Epoch[31] Batch [450]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.108074,	
2017-06-24 17:12:23,374 Epoch[31] Batch [460]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.108055,	
2017-06-24 17:12:32,954 Epoch[31] Batch [470]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.107780,	
2017-06-24 17:12:42,453 Epoch[31] Batch [480]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.107688,	
2017-06-24 17:12:52,547 Epoch[31] Batch [490]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.107470,	
2017-06-24 17:13:02,865 Epoch[31] Batch [500]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.107263,	
2017-06-24 17:13:12,433 Epoch[31] Batch [510]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.107179,	
2017-06-24 17:13:21,703 Epoch[31] Batch [520]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.106970,	
2017-06-24 17:13:30,920 Epoch[31] Batch [530]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.106884,	
2017-06-24 17:13:40,283 Epoch[31] Batch [540]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.106784,	
2017-06-24 17:13:49,371 Epoch[31] Batch [550]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.106643,	
2017-06-24 17:13:58,758 Epoch[31] Batch [560]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.106502,	
2017-06-24 17:14:08,673 Epoch[31] Batch [570]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.106723,	
2017-06-24 17:14:18,088 Epoch[31] Batch [580]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.106552,	
2017-06-24 17:14:27,622 Epoch[31] Batch [590]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.106438,	
2017-06-24 17:14:37,427 Epoch[31] Batch [600]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.106475,	
2017-06-24 17:14:46,654 Epoch[31] Batch [610]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.106353,	
2017-06-24 17:14:55,994 Epoch[31] Batch [620]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.106136,	
2017-06-24 17:15:05,189 Epoch[31] Batch [630]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.106160,	
2017-06-24 17:15:15,078 Epoch[31] Batch [640]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.106049,	
2017-06-24 17:15:24,724 Epoch[31] Batch [650]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.105932,	
2017-06-24 17:15:34,193 Epoch[31] Batch [660]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.105758,	
2017-06-24 17:15:44,229 Epoch[31] Batch [670]	Speed: 7.97 samples/sec	Train-FCNLogLoss=0.105724,	
2017-06-24 17:15:54,038 Epoch[31] Batch [680]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.105697,	
2017-06-24 17:16:03,826 Epoch[31] Batch [690]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.105599,	
2017-06-24 17:16:13,566 Epoch[31] Batch [700]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.105586,	
2017-06-24 17:16:22,772 Epoch[31] Batch [710]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.105575,	
2017-06-24 17:16:31,959 Epoch[31] Batch [720]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.105512,	
2017-06-24 17:16:41,615 Epoch[31] Batch [730]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.105489,	
2017-06-24 17:16:51,348 Epoch[31] Batch [740]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.105367,	
2017-06-24 17:16:52,982 Epoch[31] Train-FCNLogLoss=0.105371
2017-06-24 17:16:52,983 Epoch[31] Time cost=704.904
2017-06-24 17:16:56,262 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0032.params"
2017-06-24 17:17:00,026 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0032.states"
2017-06-24 17:17:11,419 Epoch[32] Batch [10]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.099325,	
2017-06-24 17:17:21,617 Epoch[32] Batch [20]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.106595,	
2017-06-24 17:17:30,788 Epoch[32] Batch [30]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.105821,	
2017-06-24 17:17:40,094 Epoch[32] Batch [40]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.104991,	
2017-06-24 17:17:49,767 Epoch[32] Batch [50]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.103492,	
2017-06-24 17:17:59,493 Epoch[32] Batch [60]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.102505,	
2017-06-24 17:18:08,898 Epoch[32] Batch [70]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.101374,	
2017-06-24 17:18:18,177 Epoch[32] Batch [80]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.101392,	
2017-06-24 17:18:27,561 Epoch[32] Batch [90]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.101786,	
2017-06-24 17:18:36,868 Epoch[32] Batch [100]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.102452,	
2017-06-24 17:18:45,378 Epoch[32] Batch [110]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.102465,	
2017-06-24 17:18:54,208 Epoch[32] Batch [120]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.102037,	
2017-06-24 17:19:03,994 Epoch[32] Batch [130]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.101793,	
2017-06-24 17:19:14,197 Epoch[32] Batch [140]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.101630,	
2017-06-24 17:19:24,132 Epoch[32] Batch [150]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.102032,	
2017-06-24 17:19:33,579 Epoch[32] Batch [160]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.101438,	
2017-06-24 17:19:43,142 Epoch[32] Batch [170]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.101266,	
2017-06-24 17:19:52,946 Epoch[32] Batch [180]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.101189,	
2017-06-24 17:20:02,429 Epoch[32] Batch [190]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.102550,	
2017-06-24 17:20:12,639 Epoch[32] Batch [200]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.102729,	
2017-06-24 17:20:21,543 Epoch[32] Batch [210]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.102710,	
2017-06-24 17:20:31,651 Epoch[32] Batch [220]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.102405,	
2017-06-24 17:20:41,265 Epoch[32] Batch [230]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.102669,	
2017-06-24 17:20:51,019 Epoch[32] Batch [240]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.102941,	
2017-06-24 17:21:00,001 Epoch[32] Batch [250]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.102789,	
2017-06-24 17:21:08,738 Epoch[32] Batch [260]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.102622,	
2017-06-24 17:21:18,113 Epoch[32] Batch [270]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.102236,	
2017-06-24 17:21:27,405 Epoch[32] Batch [280]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.101951,	
2017-06-24 17:21:36,625 Epoch[32] Batch [290]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.101622,	
2017-06-24 17:21:45,978 Epoch[32] Batch [300]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.101550,	
2017-06-24 17:21:54,715 Epoch[32] Batch [310]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.101268,	
2017-06-24 17:22:03,973 Epoch[32] Batch [320]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.101331,	
2017-06-24 17:22:13,313 Epoch[32] Batch [330]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.101273,	
2017-06-24 17:22:22,599 Epoch[32] Batch [340]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.100978,	
2017-06-24 17:22:32,467 Epoch[32] Batch [350]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.100865,	
2017-06-24 17:22:41,986 Epoch[32] Batch [360]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.100649,	
2017-06-24 17:22:51,014 Epoch[32] Batch [370]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.100443,	
2017-06-24 17:23:00,234 Epoch[32] Batch [380]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.100528,	
2017-06-24 17:23:10,018 Epoch[32] Batch [390]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.100419,	
2017-06-24 17:23:19,719 Epoch[32] Batch [400]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.100369,	
2017-06-24 17:23:28,840 Epoch[32] Batch [410]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.100577,	
2017-06-24 17:23:38,089 Epoch[32] Batch [420]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.100582,	
2017-06-24 17:23:48,215 Epoch[32] Batch [430]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.100671,	
2017-06-24 17:23:58,541 Epoch[32] Batch [440]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.100624,	
2017-06-24 17:24:07,999 Epoch[32] Batch [450]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.100553,	
2017-06-24 17:24:17,779 Epoch[32] Batch [460]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.100411,	
2017-06-24 17:24:27,121 Epoch[32] Batch [470]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.100486,	
2017-06-24 17:24:35,531 Epoch[32] Batch [480]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.100624,	
2017-06-24 17:24:45,259 Epoch[32] Batch [490]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.100673,	
2017-06-24 17:24:54,510 Epoch[32] Batch [500]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.100495,	
2017-06-24 17:25:03,758 Epoch[32] Batch [510]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.100407,	
2017-06-24 17:25:13,891 Epoch[32] Batch [520]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.100301,	
2017-06-24 17:25:24,018 Epoch[32] Batch [530]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.100144,	
2017-06-24 17:25:33,773 Epoch[32] Batch [540]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.100086,	
2017-06-24 17:25:43,538 Epoch[32] Batch [550]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.099978,	
2017-06-24 17:25:52,892 Epoch[32] Batch [560]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.100030,	
2017-06-24 17:26:02,424 Epoch[32] Batch [570]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.100018,	
2017-06-24 17:26:11,574 Epoch[32] Batch [580]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.100129,	
2017-06-24 17:26:21,330 Epoch[32] Batch [590]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.100081,	
2017-06-24 17:26:31,138 Epoch[32] Batch [600]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.100000,	
2017-06-24 17:26:40,408 Epoch[32] Batch [610]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.099972,	
2017-06-24 17:26:49,934 Epoch[32] Batch [620]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.099817,	
2017-06-24 17:26:59,215 Epoch[32] Batch [630]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.099765,	
2017-06-24 17:27:08,285 Epoch[32] Batch [640]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.099669,	
2017-06-24 17:27:18,152 Epoch[32] Batch [650]	Speed: 8.11 samples/sec	Train-FCNLogLoss=0.099641,	
2017-06-24 17:27:27,687 Epoch[32] Batch [660]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.099611,	
2017-06-24 17:27:37,493 Epoch[32] Batch [670]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.099628,	
2017-06-24 17:27:46,980 Epoch[32] Batch [680]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.099633,	
2017-06-24 17:27:56,536 Epoch[32] Batch [690]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.099686,	
2017-06-24 17:28:05,650 Epoch[32] Batch [700]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.099627,	
2017-06-24 17:28:14,971 Epoch[32] Batch [710]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.099706,	
2017-06-24 17:28:24,483 Epoch[32] Batch [720]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.099551,	
2017-06-24 17:28:34,386 Epoch[32] Batch [730]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.099596,	
2017-06-24 17:28:43,820 Epoch[32] Batch [740]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.099620,	
2017-06-24 17:28:45,756 Epoch[32] Train-FCNLogLoss=0.099618
2017-06-24 17:28:45,756 Epoch[32] Time cost=705.729
2017-06-24 17:28:49,155 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0033.params"
2017-06-24 17:28:52,872 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0033.states"
2017-06-24 17:29:03,701 Epoch[33] Batch [10]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.090550,	
2017-06-24 17:29:12,912 Epoch[33] Batch [20]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.093833,	
2017-06-24 17:29:21,910 Epoch[33] Batch [30]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.095292,	
2017-06-24 17:29:31,053 Epoch[33] Batch [40]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.095166,	
2017-06-24 17:29:40,254 Epoch[33] Batch [50]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.096095,	
2017-06-24 17:29:49,169 Epoch[33] Batch [60]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.096223,	
2017-06-24 17:29:58,578 Epoch[33] Batch [70]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.096137,	
2017-06-24 17:30:08,417 Epoch[33] Batch [80]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.095140,	
2017-06-24 17:30:18,523 Epoch[33] Batch [90]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.096408,	
2017-06-24 17:30:28,664 Epoch[33] Batch [100]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.096793,	
2017-06-24 17:30:38,501 Epoch[33] Batch [110]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.096564,	
2017-06-24 17:30:47,624 Epoch[33] Batch [120]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.096836,	
2017-06-24 17:30:57,302 Epoch[33] Batch [130]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.097303,	
2017-06-24 17:31:06,583 Epoch[33] Batch [140]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.097879,	
2017-06-24 17:31:16,005 Epoch[33] Batch [150]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.098063,	
2017-06-24 17:31:25,109 Epoch[33] Batch [160]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.098139,	
2017-06-24 17:31:34,495 Epoch[33] Batch [170]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.098207,	
2017-06-24 17:31:43,862 Epoch[33] Batch [180]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.097545,	
2017-06-24 17:31:53,153 Epoch[33] Batch [190]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.097678,	
2017-06-24 17:32:02,790 Epoch[33] Batch [200]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.097541,	
2017-06-24 17:32:12,300 Epoch[33] Batch [210]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.097648,	
2017-06-24 17:32:21,652 Epoch[33] Batch [220]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.097706,	
2017-06-24 17:32:30,890 Epoch[33] Batch [230]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.097614,	
2017-06-24 17:32:40,567 Epoch[33] Batch [240]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.097419,	
2017-06-24 17:32:50,491 Epoch[33] Batch [250]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.097425,	
2017-06-24 17:32:59,489 Epoch[33] Batch [260]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.097526,	
2017-06-24 17:33:08,896 Epoch[33] Batch [270]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.097694,	
2017-06-24 17:33:18,861 Epoch[33] Batch [280]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.097775,	
2017-06-24 17:33:29,247 Epoch[33] Batch [290]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.097911,	
2017-06-24 17:33:38,966 Epoch[33] Batch [300]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.098208,	
2017-06-24 17:33:48,866 Epoch[33] Batch [310]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.098379,	
2017-06-24 17:33:57,759 Epoch[33] Batch [320]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.098239,	
2017-06-24 17:34:07,585 Epoch[33] Batch [330]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.098266,	
2017-06-24 17:34:16,987 Epoch[33] Batch [340]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.098192,	
2017-06-24 17:34:26,018 Epoch[33] Batch [350]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.098157,	
2017-06-24 17:34:35,123 Epoch[33] Batch [360]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.097898,	
2017-06-24 17:34:44,229 Epoch[33] Batch [370]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.097828,	
2017-06-24 17:34:54,050 Epoch[33] Batch [380]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.097856,	
2017-06-24 17:35:04,657 Epoch[33] Batch [390]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.097973,	
2017-06-24 17:35:14,381 Epoch[33] Batch [400]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.097760,	
2017-06-24 17:35:23,595 Epoch[33] Batch [410]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.097663,	
2017-06-24 17:35:31,850 Epoch[33] Batch [420]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.097752,	
2017-06-24 17:35:40,979 Epoch[33] Batch [430]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.097770,	
2017-06-24 17:35:50,772 Epoch[33] Batch [440]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.097677,	
2017-06-24 17:36:00,094 Epoch[33] Batch [450]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.097840,	
2017-06-24 17:36:09,666 Epoch[33] Batch [460]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.097925,	
2017-06-24 17:36:18,560 Epoch[33] Batch [470]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.098008,	
2017-06-24 17:36:28,980 Epoch[33] Batch [480]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.098025,	
2017-06-24 17:36:38,389 Epoch[33] Batch [490]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.097969,	
2017-06-24 17:36:48,191 Epoch[33] Batch [500]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.097923,	
2017-06-24 17:36:58,482 Epoch[33] Batch [510]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.097886,	
2017-06-24 17:37:08,177 Epoch[33] Batch [520]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.097865,	
2017-06-24 17:37:17,932 Epoch[33] Batch [530]	Speed: 8.20 samples/sec	Train-FCNLogLoss=0.097908,	
2017-06-24 17:37:27,284 Epoch[33] Batch [540]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.097879,	
2017-06-24 17:37:37,414 Epoch[33] Batch [550]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.097944,	
2017-06-24 17:37:46,876 Epoch[33] Batch [560]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.097958,	
2017-06-24 17:37:56,540 Epoch[33] Batch [570]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.098022,	
2017-06-24 17:38:06,270 Epoch[33] Batch [580]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.098156,	
2017-06-24 17:38:15,746 Epoch[33] Batch [590]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.098069,	
2017-06-24 17:38:25,255 Epoch[33] Batch [600]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098047,	
2017-06-24 17:38:34,876 Epoch[33] Batch [610]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.098102,	
2017-06-24 17:38:44,893 Epoch[33] Batch [620]	Speed: 7.99 samples/sec	Train-FCNLogLoss=0.097968,	
2017-06-24 17:38:53,787 Epoch[33] Batch [630]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.097894,	
2017-06-24 17:39:02,996 Epoch[33] Batch [640]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.097772,	
2017-06-24 17:39:12,369 Epoch[33] Batch [650]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.097693,	
2017-06-24 17:39:21,910 Epoch[33] Batch [660]	Speed: 8.39 samples/sec	Train-FCNLogLoss=0.097687,	
2017-06-24 17:39:31,337 Epoch[33] Batch [670]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.097648,	
2017-06-24 17:39:41,364 Epoch[33] Batch [680]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.097752,	
2017-06-24 17:39:51,199 Epoch[33] Batch [690]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.097691,	
2017-06-24 17:40:01,136 Epoch[33] Batch [700]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.097696,	
2017-06-24 17:40:10,785 Epoch[33] Batch [710]	Speed: 8.29 samples/sec	Train-FCNLogLoss=0.097623,	
2017-06-24 17:40:19,881 Epoch[33] Batch [720]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.097601,	
2017-06-24 17:40:29,582 Epoch[33] Batch [730]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.097569,	
2017-06-24 17:40:38,436 Epoch[33] Batch [740]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.097621,	
2017-06-24 17:40:40,175 Epoch[33] Train-FCNLogLoss=0.097647
2017-06-24 17:40:40,176 Epoch[33] Time cost=707.302
2017-06-24 17:40:42,458 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0034.params"
2017-06-24 17:40:46,205 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0034.states"
2017-06-24 17:40:56,722 Epoch[34] Batch [10]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.095552,	
2017-06-24 17:41:06,107 Epoch[34] Batch [20]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.098790,	
2017-06-24 17:41:15,464 Epoch[34] Batch [30]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.098975,	
2017-06-24 17:41:25,825 Epoch[34] Batch [40]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.098168,	
2017-06-24 17:41:35,490 Epoch[34] Batch [50]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.097017,	
2017-06-24 17:41:45,221 Epoch[34] Batch [60]	Speed: 8.22 samples/sec	Train-FCNLogLoss=0.097790,	
2017-06-24 17:41:54,126 Epoch[34] Batch [70]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.097783,	
2017-06-24 17:42:03,563 Epoch[34] Batch [80]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.098204,	
2017-06-24 17:42:13,313 Epoch[34] Batch [90]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.097822,	
2017-06-24 17:42:22,881 Epoch[34] Batch [100]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.097833,	
2017-06-24 17:42:32,192 Epoch[34] Batch [110]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.097898,	
2017-06-24 17:42:42,219 Epoch[34] Batch [120]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.097572,	
2017-06-24 17:42:52,565 Epoch[34] Batch [130]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.098050,	
2017-06-24 17:43:01,997 Epoch[34] Batch [140]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.097282,	
2017-06-24 17:43:11,765 Epoch[34] Batch [150]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.097636,	
2017-06-24 17:43:21,870 Epoch[34] Batch [160]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.097580,	
2017-06-24 17:43:31,921 Epoch[34] Batch [170]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.097355,	
2017-06-24 17:43:40,812 Epoch[34] Batch [180]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.097610,	
2017-06-24 17:43:50,255 Epoch[34] Batch [190]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.097554,	
2017-06-24 17:44:00,064 Epoch[34] Batch [200]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.097330,	
2017-06-24 17:44:09,339 Epoch[34] Batch [210]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.097077,	
2017-06-24 17:44:18,481 Epoch[34] Batch [220]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.097337,	
2017-06-24 17:44:28,293 Epoch[34] Batch [230]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.097319,	
2017-06-24 17:44:37,590 Epoch[34] Batch [240]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.097768,	
2017-06-24 17:44:47,164 Epoch[34] Batch [250]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.097490,	
2017-06-24 17:44:56,725 Epoch[34] Batch [260]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.097256,	
2017-06-24 17:45:06,655 Epoch[34] Batch [270]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.097037,	
2017-06-24 17:45:16,088 Epoch[34] Batch [280]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.096841,	
2017-06-24 17:45:25,226 Epoch[34] Batch [290]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.096642,	
2017-06-24 17:45:34,579 Epoch[34] Batch [300]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.096789,	
2017-06-24 17:45:44,181 Epoch[34] Batch [310]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.096652,	
2017-06-24 17:45:53,331 Epoch[34] Batch [320]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.096546,	
2017-06-24 17:46:03,132 Epoch[34] Batch [330]	Speed: 8.16 samples/sec	Train-FCNLogLoss=0.096520,	
2017-06-24 17:46:12,432 Epoch[34] Batch [340]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.096608,	
2017-06-24 17:46:21,991 Epoch[34] Batch [350]	Speed: 8.37 samples/sec	Train-FCNLogLoss=0.096422,	
2017-06-24 17:46:31,366 Epoch[34] Batch [360]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.096287,	
2017-06-24 17:46:40,696 Epoch[34] Batch [370]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.096412,	
2017-06-24 17:46:49,959 Epoch[34] Batch [380]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.096419,	
2017-06-24 17:46:58,731 Epoch[34] Batch [390]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.096213,	
2017-06-24 17:47:08,403 Epoch[34] Batch [400]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.096212,	
2017-06-24 17:47:18,070 Epoch[34] Batch [410]	Speed: 8.28 samples/sec	Train-FCNLogLoss=0.096252,	
2017-06-24 17:47:27,694 Epoch[34] Batch [420]	Speed: 8.31 samples/sec	Train-FCNLogLoss=0.096457,	
2017-06-24 17:47:37,382 Epoch[34] Batch [430]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.096429,	
2017-06-24 17:47:47,068 Epoch[34] Batch [440]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.096333,	
2017-06-24 17:47:56,854 Epoch[34] Batch [450]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.096361,	
2017-06-24 17:48:06,620 Epoch[34] Batch [460]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.096311,	
2017-06-24 17:48:16,505 Epoch[34] Batch [470]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.096244,	
2017-06-24 17:48:25,954 Epoch[34] Batch [480]	Speed: 8.47 samples/sec	Train-FCNLogLoss=0.096225,	
2017-06-24 17:48:36,078 Epoch[34] Batch [490]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.096154,	
2017-06-24 17:48:45,484 Epoch[34] Batch [500]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.096041,	
2017-06-24 17:48:55,450 Epoch[34] Batch [510]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.095929,	
2017-06-24 17:49:04,555 Epoch[34] Batch [520]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.095971,	
2017-06-24 17:49:13,481 Epoch[34] Batch [530]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.095881,	
2017-06-24 17:49:23,001 Epoch[34] Batch [540]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.095937,	
2017-06-24 17:49:31,675 Epoch[34] Batch [550]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.096065,	
2017-06-24 17:49:40,427 Epoch[34] Batch [560]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.096002,	
2017-06-24 17:49:49,322 Epoch[34] Batch [570]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.095956,	
2017-06-24 17:49:57,765 Epoch[34] Batch [580]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.096022,	
2017-06-24 17:50:06,756 Epoch[34] Batch [590]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.096036,	
2017-06-24 17:50:15,610 Epoch[34] Batch [600]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095991,	
2017-06-24 17:50:24,183 Epoch[34] Batch [610]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.096069,	
2017-06-24 17:50:32,904 Epoch[34] Batch [620]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.096049,	
2017-06-24 17:50:42,432 Epoch[34] Batch [630]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.096127,	
2017-06-24 17:50:51,636 Epoch[34] Batch [640]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.096127,	
2017-06-24 17:51:00,354 Epoch[34] Batch [650]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.096154,	
2017-06-24 17:51:08,954 Epoch[34] Batch [660]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.096149,	
2017-06-24 17:51:17,698 Epoch[34] Batch [670]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.096132,	
2017-06-24 17:51:26,300 Epoch[34] Batch [680]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.096071,	
2017-06-24 17:51:35,123 Epoch[34] Batch [690]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.096175,	
2017-06-24 17:51:44,380 Epoch[34] Batch [700]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.096127,	
2017-06-24 17:51:53,014 Epoch[34] Batch [710]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.096036,	
2017-06-24 17:52:01,758 Epoch[34] Batch [720]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095988,	
2017-06-24 17:52:10,316 Epoch[34] Batch [730]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.096011,	
2017-06-24 17:52:19,328 Epoch[34] Batch [740]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.096053,	
2017-06-24 17:52:21,073 Epoch[34] Train-FCNLogLoss=0.096072
2017-06-24 17:52:21,073 Epoch[34] Time cost=694.868
2017-06-24 17:52:24,196 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0035.params"
2017-06-24 17:52:27,884 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0035.states"
2017-06-24 17:52:38,672 Epoch[35] Batch [10]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.093049,	
2017-06-24 17:52:47,330 Epoch[35] Batch [20]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.092046,	
2017-06-24 17:52:56,258 Epoch[35] Batch [30]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.093093,	
2017-06-24 17:53:05,425 Epoch[35] Batch [40]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.091172,	
2017-06-24 17:53:13,580 Epoch[35] Batch [50]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.092702,	
2017-06-24 17:53:21,743 Epoch[35] Batch [60]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.092062,	
2017-06-24 17:53:29,961 Epoch[35] Batch [70]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.092333,	
2017-06-24 17:53:38,540 Epoch[35] Batch [80]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.092969,	
2017-06-24 17:53:47,425 Epoch[35] Batch [90]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.093683,	
2017-06-24 17:53:56,114 Epoch[35] Batch [100]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.094195,	
2017-06-24 17:54:04,507 Epoch[35] Batch [110]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.093857,	
2017-06-24 17:54:13,092 Epoch[35] Batch [120]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.093668,	
2017-06-24 17:54:21,576 Epoch[35] Batch [130]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.093162,	
2017-06-24 17:54:30,202 Epoch[35] Batch [140]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.093768,	
2017-06-24 17:54:38,727 Epoch[35] Batch [150]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.094037,	
2017-06-24 17:54:46,906 Epoch[35] Batch [160]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.094343,	
2017-06-24 17:54:55,576 Epoch[35] Batch [170]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.094724,	
2017-06-24 17:55:04,213 Epoch[35] Batch [180]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.094662,	
2017-06-24 17:55:12,857 Epoch[35] Batch [190]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.094464,	
2017-06-24 17:55:21,568 Epoch[35] Batch [200]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.094409,	
2017-06-24 17:55:30,221 Epoch[35] Batch [210]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.094930,	
2017-06-24 17:55:38,735 Epoch[35] Batch [220]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.095015,	
2017-06-24 17:55:47,497 Epoch[35] Batch [230]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095096,	
2017-06-24 17:55:55,923 Epoch[35] Batch [240]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.094597,	
2017-06-24 17:56:04,013 Epoch[35] Batch [250]	Speed: 9.89 samples/sec	Train-FCNLogLoss=0.094670,	
2017-06-24 17:56:12,599 Epoch[35] Batch [260]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094712,	
2017-06-24 17:56:21,198 Epoch[35] Batch [270]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094703,	
2017-06-24 17:56:29,580 Epoch[35] Batch [280]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.094581,	
2017-06-24 17:56:37,965 Epoch[35] Batch [290]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.095144,	
2017-06-24 17:56:46,838 Epoch[35] Batch [300]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.096600,	
2017-06-24 17:56:55,543 Epoch[35] Batch [310]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.097722,	
2017-06-24 17:57:04,259 Epoch[35] Batch [320]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.098383,	
2017-06-24 17:57:12,508 Epoch[35] Batch [330]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.099007,	
2017-06-24 17:57:20,885 Epoch[35] Batch [340]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.099569,	
2017-06-24 17:57:28,692 Epoch[35] Batch [350]	Speed: 10.25 samples/sec	Train-FCNLogLoss=0.099899,	
2017-06-24 17:57:37,148 Epoch[35] Batch [360]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.100188,	
2017-06-24 17:57:45,597 Epoch[35] Batch [370]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.100423,	
2017-06-24 17:57:54,551 Epoch[35] Batch [380]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.100393,	
2017-06-24 17:58:03,392 Epoch[35] Batch [390]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.100464,	
2017-06-24 17:58:11,873 Epoch[35] Batch [400]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100516,	
2017-06-24 17:58:20,528 Epoch[35] Batch [410]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.100471,	
2017-06-24 17:58:28,789 Epoch[35] Batch [420]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.100409,	
2017-06-24 17:58:37,404 Epoch[35] Batch [430]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.100218,	
2017-06-24 17:58:46,139 Epoch[35] Batch [440]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.100192,	
2017-06-24 17:58:54,620 Epoch[35] Batch [450]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.100236,	
2017-06-24 17:59:03,171 Epoch[35] Batch [460]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.100282,	
2017-06-24 17:59:11,764 Epoch[35] Batch [470]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.100217,	
2017-06-24 17:59:19,930 Epoch[35] Batch [480]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.100143,	
2017-06-24 17:59:28,937 Epoch[35] Batch [490]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.100023,	
2017-06-24 17:59:37,770 Epoch[35] Batch [500]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.099882,	
2017-06-24 17:59:46,363 Epoch[35] Batch [510]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.099763,	
2017-06-24 17:59:55,174 Epoch[35] Batch [520]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099649,	
2017-06-24 18:00:03,810 Epoch[35] Batch [530]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.099556,	
2017-06-24 18:00:12,260 Epoch[35] Batch [540]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.099502,	
2017-06-24 18:00:20,765 Epoch[35] Batch [550]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.099735,	
2017-06-24 18:00:29,099 Epoch[35] Batch [560]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.099845,	
2017-06-24 18:00:37,773 Epoch[35] Batch [570]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.099999,	
2017-06-24 18:00:46,795 Epoch[35] Batch [580]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.099979,	
2017-06-24 18:00:55,470 Epoch[35] Batch [590]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.099937,	
2017-06-24 18:01:04,181 Epoch[35] Batch [600]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.100261,	
2017-06-24 18:01:13,100 Epoch[35] Batch [610]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.101478,	
2017-06-24 18:01:22,283 Epoch[35] Batch [620]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.102267,	
2017-06-24 18:01:30,838 Epoch[35] Batch [630]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.102757,	
2017-06-24 18:01:39,217 Epoch[35] Batch [640]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.103029,	
2017-06-24 18:01:48,032 Epoch[35] Batch [650]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.103278,	
2017-06-24 18:01:56,661 Epoch[35] Batch [660]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.103319,	
2017-06-24 18:02:05,623 Epoch[35] Batch [670]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.103372,	
2017-06-24 18:02:14,046 Epoch[35] Batch [680]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.103543,	
2017-06-24 18:02:22,612 Epoch[35] Batch [690]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.103431,	
2017-06-24 18:02:30,745 Epoch[35] Batch [700]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.103398,	
2017-06-24 18:02:39,449 Epoch[35] Batch [710]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.103427,	
2017-06-24 18:02:48,127 Epoch[35] Batch [720]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.103452,	
2017-06-24 18:02:56,998 Epoch[35] Batch [730]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.103258,	
2017-06-24 18:03:05,214 Epoch[35] Batch [740]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.103284,	
2017-06-24 18:03:06,757 Epoch[35] Train-FCNLogLoss=0.103301
2017-06-24 18:03:06,757 Epoch[35] Time cost=638.873
2017-06-24 18:03:09,610 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0036.params"
2017-06-24 18:03:13,165 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0036.states"
2017-06-24 18:03:22,987 Epoch[36] Batch [10]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.100074,	
2017-06-24 18:03:31,724 Epoch[36] Batch [20]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.098154,	
2017-06-24 18:03:40,559 Epoch[36] Batch [30]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.097289,	
2017-06-24 18:03:49,411 Epoch[36] Batch [40]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.096531,	
2017-06-24 18:03:58,518 Epoch[36] Batch [50]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.096932,	
2017-06-24 18:04:07,423 Epoch[36] Batch [60]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.097913,	
2017-06-24 18:04:16,490 Epoch[36] Batch [70]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.098099,	
2017-06-24 18:04:25,133 Epoch[36] Batch [80]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097347,	
2017-06-24 18:04:34,122 Epoch[36] Batch [90]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.097897,	
2017-06-24 18:04:43,142 Epoch[36] Batch [100]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.098339,	
2017-06-24 18:04:52,129 Epoch[36] Batch [110]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.098743,	
2017-06-24 18:05:01,041 Epoch[36] Batch [120]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.098281,	
2017-06-24 18:05:09,901 Epoch[36] Batch [130]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.098501,	
2017-06-24 18:05:18,495 Epoch[36] Batch [140]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.098742,	
2017-06-24 18:05:27,395 Epoch[36] Batch [150]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.098400,	
2017-06-24 18:05:36,664 Epoch[36] Batch [160]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.097778,	
2017-06-24 18:05:45,725 Epoch[36] Batch [170]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.097781,	
2017-06-24 18:05:54,464 Epoch[36] Batch [180]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.097981,	
2017-06-24 18:06:03,401 Epoch[36] Batch [190]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.098036,	
2017-06-24 18:06:12,040 Epoch[36] Batch [200]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.097834,	
2017-06-24 18:06:21,547 Epoch[36] Batch [210]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.098386,	
2017-06-24 18:06:30,343 Epoch[36] Batch [220]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.099689,	
2017-06-24 18:06:39,355 Epoch[36] Batch [230]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.100551,	
2017-06-24 18:06:48,189 Epoch[36] Batch [240]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.100423,	
2017-06-24 18:06:56,914 Epoch[36] Batch [250]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.100370,	
2017-06-24 18:07:05,628 Epoch[36] Batch [260]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.100320,	
2017-06-24 18:07:14,410 Epoch[36] Batch [270]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.100299,	
2017-06-24 18:07:23,241 Epoch[36] Batch [280]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.100028,	
2017-06-24 18:07:32,114 Epoch[36] Batch [290]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.100003,	
2017-06-24 18:07:41,046 Epoch[36] Batch [300]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.100030,	
2017-06-24 18:07:49,886 Epoch[36] Batch [310]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.099892,	
2017-06-24 18:07:58,669 Epoch[36] Batch [320]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.099761,	
2017-06-24 18:08:08,139 Epoch[36] Batch [330]	Speed: 8.45 samples/sec	Train-FCNLogLoss=0.099466,	
2017-06-24 18:08:16,951 Epoch[36] Batch [340]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099342,	
2017-06-24 18:08:25,812 Epoch[36] Batch [350]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.099562,	
2017-06-24 18:08:34,599 Epoch[36] Batch [360]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.099661,	
2017-06-24 18:08:43,290 Epoch[36] Batch [370]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.099735,	
2017-06-24 18:08:51,580 Epoch[36] Batch [380]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.099694,	
2017-06-24 18:09:00,388 Epoch[36] Batch [390]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.099608,	
2017-06-24 18:09:09,061 Epoch[36] Batch [400]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.099430,	
2017-06-24 18:09:17,462 Epoch[36] Batch [410]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.099274,	
2017-06-24 18:09:26,376 Epoch[36] Batch [420]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.099114,	
2017-06-24 18:09:35,226 Epoch[36] Batch [430]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.099119,	
2017-06-24 18:09:43,976 Epoch[36] Batch [440]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.099266,	
2017-06-24 18:09:52,577 Epoch[36] Batch [450]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.099271,	
2017-06-24 18:10:01,334 Epoch[36] Batch [460]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.099287,	
2017-06-24 18:10:09,802 Epoch[36] Batch [470]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.099226,	
2017-06-24 18:10:18,578 Epoch[36] Batch [480]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.098962,	
2017-06-24 18:10:27,420 Epoch[36] Batch [490]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.098766,	
2017-06-24 18:10:36,061 Epoch[36] Batch [500]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.098842,	
2017-06-24 18:10:44,751 Epoch[36] Batch [510]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.099033,	
2017-06-24 18:10:53,900 Epoch[36] Batch [520]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.099072,	
2017-06-24 18:11:02,719 Epoch[36] Batch [530]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.098963,	
2017-06-24 18:11:11,557 Epoch[36] Batch [540]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.098798,	
2017-06-24 18:11:20,690 Epoch[36] Batch [550]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.098794,	
2017-06-24 18:11:29,695 Epoch[36] Batch [560]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.098849,	
2017-06-24 18:11:38,248 Epoch[36] Batch [570]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.098944,	
2017-06-24 18:11:46,901 Epoch[36] Batch [580]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.098857,	
2017-06-24 18:11:56,177 Epoch[36] Batch [590]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.098927,	
2017-06-24 18:12:04,879 Epoch[36] Batch [600]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.098976,	
2017-06-24 18:12:14,033 Epoch[36] Batch [610]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.098940,	
2017-06-24 18:12:22,454 Epoch[36] Batch [620]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.098825,	
2017-06-24 18:12:30,844 Epoch[36] Batch [630]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.098776,	
2017-06-24 18:12:39,989 Epoch[36] Batch [640]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.098707,	
2017-06-24 18:12:49,164 Epoch[36] Batch [650]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.098618,	
2017-06-24 18:12:58,408 Epoch[36] Batch [660]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.098500,	
2017-06-24 18:13:07,200 Epoch[36] Batch [670]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.098377,	
2017-06-24 18:13:16,108 Epoch[36] Batch [680]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.098380,	
2017-06-24 18:13:24,815 Epoch[36] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.098165,	
2017-06-24 18:13:33,392 Epoch[36] Batch [700]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.098059,	
2017-06-24 18:13:42,185 Epoch[36] Batch [710]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.097958,	
2017-06-24 18:13:50,734 Epoch[36] Batch [720]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.097888,	
2017-06-24 18:13:59,193 Epoch[36] Batch [730]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.097825,	
2017-06-24 18:14:07,876 Epoch[36] Batch [740]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.097770,	
2017-06-24 18:14:09,519 Epoch[36] Train-FCNLogLoss=0.097794
2017-06-24 18:14:09,519 Epoch[36] Time cost=656.354
2017-06-24 18:14:11,797 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0037.params"
2017-06-24 18:14:15,470 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0037.states"
2017-06-24 18:14:26,196 Epoch[37] Batch [10]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.096897,	
2017-06-24 18:14:35,092 Epoch[37] Batch [20]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.094304,	
2017-06-24 18:14:43,878 Epoch[37] Batch [30]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.094080,	
2017-06-24 18:14:52,555 Epoch[37] Batch [40]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.094999,	
2017-06-24 18:15:01,135 Epoch[37] Batch [50]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094985,	
2017-06-24 18:15:09,909 Epoch[37] Batch [60]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.094244,	
2017-06-24 18:15:19,280 Epoch[37] Batch [70]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.093236,	
2017-06-24 18:15:28,338 Epoch[37] Batch [80]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.093434,	
2017-06-24 18:15:37,226 Epoch[37] Batch [90]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.093684,	
2017-06-24 18:15:45,960 Epoch[37] Batch [100]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.094245,	
2017-06-24 18:15:54,823 Epoch[37] Batch [110]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.094315,	
2017-06-24 18:16:03,739 Epoch[37] Batch [120]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.095046,	
2017-06-24 18:16:12,293 Epoch[37] Batch [130]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.095090,	
2017-06-24 18:16:21,107 Epoch[37] Batch [140]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.094527,	
2017-06-24 18:16:30,106 Epoch[37] Batch [150]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.094844,	
2017-06-24 18:16:39,457 Epoch[37] Batch [160]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.095382,	
2017-06-24 18:16:48,212 Epoch[37] Batch [170]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.095430,	
2017-06-24 18:16:57,547 Epoch[37] Batch [180]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.095526,	
2017-06-24 18:17:06,758 Epoch[37] Batch [190]	Speed: 8.69 samples/sec	Train-FCNLogLoss=0.095605,	
2017-06-24 18:17:15,519 Epoch[37] Batch [200]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095073,	
2017-06-24 18:17:25,570 Epoch[37] Batch [210]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.095134,	
2017-06-24 18:17:34,863 Epoch[37] Batch [220]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.095344,	
2017-06-24 18:17:43,992 Epoch[37] Batch [230]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.095510,	
2017-06-24 18:17:53,056 Epoch[37] Batch [240]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.095322,	
2017-06-24 18:18:01,822 Epoch[37] Batch [250]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.095425,	
2017-06-24 18:18:10,707 Epoch[37] Batch [260]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.095525,	
2017-06-24 18:18:19,555 Epoch[37] Batch [270]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095313,	
2017-06-24 18:18:28,547 Epoch[37] Batch [280]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.095235,	
2017-06-24 18:18:37,964 Epoch[37] Batch [290]	Speed: 8.50 samples/sec	Train-FCNLogLoss=0.095336,	
2017-06-24 18:18:46,788 Epoch[37] Batch [300]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.095335,	
2017-06-24 18:18:55,318 Epoch[37] Batch [310]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095235,	
2017-06-24 18:19:04,416 Epoch[37] Batch [320]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.095420,	
2017-06-24 18:19:13,306 Epoch[37] Batch [330]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.095210,	
2017-06-24 18:19:21,953 Epoch[37] Batch [340]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.095107,	
2017-06-24 18:19:31,048 Epoch[37] Batch [350]	Speed: 8.80 samples/sec	Train-FCNLogLoss=0.094807,	
2017-06-24 18:19:39,728 Epoch[37] Batch [360]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.094767,	
2017-06-24 18:19:47,849 Epoch[37] Batch [370]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.094890,	
2017-06-24 18:19:56,604 Epoch[37] Batch [380]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.095072,	
2017-06-24 18:20:05,362 Epoch[37] Batch [390]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.095090,	
2017-06-24 18:20:13,740 Epoch[37] Batch [400]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.094996,	
2017-06-24 18:20:22,727 Epoch[37] Batch [410]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.094975,	
2017-06-24 18:20:31,177 Epoch[37] Batch [420]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.094957,	
2017-06-24 18:20:39,934 Epoch[37] Batch [430]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.094928,	
2017-06-24 18:20:48,811 Epoch[37] Batch [440]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.094714,	
2017-06-24 18:20:57,824 Epoch[37] Batch [450]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.094761,	
2017-06-24 18:21:06,788 Epoch[37] Batch [460]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.094884,	
2017-06-24 18:21:15,543 Epoch[37] Batch [470]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.094923,	
2017-06-24 18:21:23,960 Epoch[37] Batch [480]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.094947,	
2017-06-24 18:21:32,586 Epoch[37] Batch [490]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.094940,	
2017-06-24 18:21:40,793 Epoch[37] Batch [500]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.094850,	
2017-06-24 18:21:49,692 Epoch[37] Batch [510]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.094820,	
2017-06-24 18:21:57,963 Epoch[37] Batch [520]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.094700,	
2017-06-24 18:22:06,803 Epoch[37] Batch [530]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.094818,	
2017-06-24 18:22:15,632 Epoch[37] Batch [540]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.094924,	
2017-06-24 18:22:24,971 Epoch[37] Batch [550]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.095017,	
2017-06-24 18:22:34,073 Epoch[37] Batch [560]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.094965,	
2017-06-24 18:22:42,409 Epoch[37] Batch [570]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.095028,	
2017-06-24 18:22:51,306 Epoch[37] Batch [580]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.095103,	
2017-06-24 18:23:00,289 Epoch[37] Batch [590]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.095105,	
2017-06-24 18:23:09,032 Epoch[37] Batch [600]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.095018,	
2017-06-24 18:23:17,846 Epoch[37] Batch [610]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.094992,	
2017-06-24 18:23:26,639 Epoch[37] Batch [620]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.095038,	
2017-06-24 18:23:35,169 Epoch[37] Batch [630]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.095035,	
2017-06-24 18:23:44,311 Epoch[37] Batch [640]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.095221,	
2017-06-24 18:23:53,334 Epoch[37] Batch [650]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.095240,	
2017-06-24 18:24:02,199 Epoch[37] Batch [660]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.095281,	
2017-06-24 18:24:10,791 Epoch[37] Batch [670]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.095259,	
2017-06-24 18:24:19,542 Epoch[37] Batch [680]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.095112,	
2017-06-24 18:24:28,806 Epoch[37] Batch [690]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.095082,	
2017-06-24 18:24:37,736 Epoch[37] Batch [700]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.095081,	
2017-06-24 18:24:46,747 Epoch[37] Batch [710]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.095130,	
2017-06-24 18:24:55,362 Epoch[37] Batch [720]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.095188,	
2017-06-24 18:25:04,214 Epoch[37] Batch [730]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.095111,	
2017-06-24 18:25:13,039 Epoch[37] Batch [740]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.095074,	
2017-06-24 18:25:14,825 Epoch[37] Train-FCNLogLoss=0.095066
2017-06-24 18:25:14,826 Epoch[37] Time cost=659.356
2017-06-24 18:25:17,781 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0038.params"
2017-06-24 18:25:21,538 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0038.states"
2017-06-24 18:25:31,503 Epoch[38] Batch [10]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.096757,	
2017-06-24 18:25:40,769 Epoch[38] Batch [20]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.091458,	
2017-06-24 18:25:50,252 Epoch[38] Batch [30]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.090325,	
2017-06-24 18:25:59,169 Epoch[38] Batch [40]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.091330,	
2017-06-24 18:26:08,175 Epoch[38] Batch [50]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.091161,	
2017-06-24 18:26:17,293 Epoch[38] Batch [60]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.091613,	
2017-06-24 18:26:25,919 Epoch[38] Batch [70]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.092159,	
2017-06-24 18:26:34,676 Epoch[38] Batch [80]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.091997,	
2017-06-24 18:26:43,821 Epoch[38] Batch [90]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.093108,	
2017-06-24 18:26:52,184 Epoch[38] Batch [100]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.093272,	
2017-06-24 18:27:01,339 Epoch[38] Batch [110]	Speed: 8.74 samples/sec	Train-FCNLogLoss=0.093988,	
2017-06-24 18:27:10,147 Epoch[38] Batch [120]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.093565,	
2017-06-24 18:27:18,613 Epoch[38] Batch [130]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.093464,	
2017-06-24 18:27:27,178 Epoch[38] Batch [140]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.093989,	
2017-06-24 18:27:35,745 Epoch[38] Batch [150]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.094294,	
2017-06-24 18:27:44,295 Epoch[38] Batch [160]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.094571,	
2017-06-24 18:27:53,437 Epoch[38] Batch [170]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.094635,	
2017-06-24 18:28:02,086 Epoch[38] Batch [180]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.094332,	
2017-06-24 18:28:10,770 Epoch[38] Batch [190]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.094352,	
2017-06-24 18:28:19,133 Epoch[38] Batch [200]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.094474,	
2017-06-24 18:28:27,686 Epoch[38] Batch [210]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.094502,	
2017-06-24 18:28:36,266 Epoch[38] Batch [220]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.094674,	
2017-06-24 18:28:45,153 Epoch[38] Batch [230]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.094802,	
2017-06-24 18:28:53,954 Epoch[38] Batch [240]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.095247,	
2017-06-24 18:29:02,541 Epoch[38] Batch [250]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.096135,	
2017-06-24 18:29:11,190 Epoch[38] Batch [260]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.096729,	
2017-06-24 18:29:19,827 Epoch[38] Batch [270]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.096990,	
2017-06-24 18:29:28,324 Epoch[38] Batch [280]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.097026,	
2017-06-24 18:29:37,341 Epoch[38] Batch [290]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.096921,	
2017-06-24 18:29:46,489 Epoch[38] Batch [300]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.096728,	
2017-06-24 18:29:55,395 Epoch[38] Batch [310]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.096938,	
2017-06-24 18:30:03,948 Epoch[38] Batch [320]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.097006,	
2017-06-24 18:30:12,413 Epoch[38] Batch [330]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.096944,	
2017-06-24 18:30:21,066 Epoch[38] Batch [340]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.096911,	
2017-06-24 18:30:29,782 Epoch[38] Batch [350]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.096804,	
2017-06-24 18:30:38,851 Epoch[38] Batch [360]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.096686,	
2017-06-24 18:30:47,918 Epoch[38] Batch [370]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.096522,	
2017-06-24 18:30:56,411 Epoch[38] Batch [380]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.096330,	
2017-06-24 18:31:05,901 Epoch[38] Batch [390]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.096215,	
2017-06-24 18:31:15,646 Epoch[38] Batch [400]	Speed: 8.21 samples/sec	Train-FCNLogLoss=0.096245,	
2017-06-24 18:31:24,655 Epoch[38] Batch [410]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.096132,	
2017-06-24 18:31:35,024 Epoch[38] Batch [420]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.096030,	
2017-06-24 18:31:45,535 Epoch[38] Batch [430]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.096013,	
2017-06-24 18:31:55,360 Epoch[38] Batch [440]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.096119,	
2017-06-24 18:32:04,994 Epoch[38] Batch [450]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.096079,	
2017-06-24 18:32:14,154 Epoch[38] Batch [460]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.095945,	
2017-06-24 18:32:23,173 Epoch[38] Batch [470]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.096046,	
2017-06-24 18:32:32,405 Epoch[38] Batch [480]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.095985,	
2017-06-24 18:32:42,016 Epoch[38] Batch [490]	Speed: 8.32 samples/sec	Train-FCNLogLoss=0.096162,	
2017-06-24 18:32:51,263 Epoch[38] Batch [500]	Speed: 8.65 samples/sec	Train-FCNLogLoss=0.096299,	
2017-06-24 18:33:01,143 Epoch[38] Batch [510]	Speed: 8.10 samples/sec	Train-FCNLogLoss=0.096253,	
2017-06-24 18:33:10,518 Epoch[38] Batch [520]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.096217,	
2017-06-24 18:33:19,922 Epoch[38] Batch [530]	Speed: 8.51 samples/sec	Train-FCNLogLoss=0.096169,	
2017-06-24 18:33:30,827 Epoch[38] Batch [540]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.096186,	
2017-06-24 18:33:40,889 Epoch[38] Batch [550]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.096104,	
2017-06-24 18:33:50,473 Epoch[38] Batch [560]	Speed: 8.35 samples/sec	Train-FCNLogLoss=0.096064,	
2017-06-24 18:34:00,154 Epoch[38] Batch [570]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.096054,	
2017-06-24 18:34:09,796 Epoch[38] Batch [580]	Speed: 8.30 samples/sec	Train-FCNLogLoss=0.095955,	
2017-06-24 18:34:19,185 Epoch[38] Batch [590]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.096025,	
2017-06-24 18:34:28,399 Epoch[38] Batch [600]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.096023,	
2017-06-24 18:34:37,678 Epoch[38] Batch [610]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.096067,	
2017-06-24 18:34:47,368 Epoch[38] Batch [620]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.096060,	
2017-06-24 18:34:56,511 Epoch[38] Batch [630]	Speed: 8.75 samples/sec	Train-FCNLogLoss=0.096084,	
2017-06-24 18:35:05,221 Epoch[38] Batch [640]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.096142,	
2017-06-24 18:35:14,135 Epoch[38] Batch [650]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.096036,	
2017-06-24 18:35:22,901 Epoch[38] Batch [660]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.096073,	
2017-06-24 18:35:32,269 Epoch[38] Batch [670]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.096045,	
2017-06-24 18:35:41,384 Epoch[38] Batch [680]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.095857,	
2017-06-24 18:35:50,692 Epoch[38] Batch [690]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.095880,	
2017-06-24 18:35:59,973 Epoch[38] Batch [700]	Speed: 8.62 samples/sec	Train-FCNLogLoss=0.095924,	
2017-06-24 18:36:09,539 Epoch[38] Batch [710]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.095902,	
2017-06-24 18:36:18,571 Epoch[38] Batch [720]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.095792,	
2017-06-24 18:36:27,529 Epoch[38] Batch [730]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.095868,	
2017-06-24 18:36:36,712 Epoch[38] Batch [740]	Speed: 8.71 samples/sec	Train-FCNLogLoss=0.095765,	
2017-06-24 18:36:38,214 Epoch[38] Train-FCNLogLoss=0.095783
2017-06-24 18:36:38,214 Epoch[38] Time cost=676.675
2017-06-24 18:36:40,927 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0039.params"
2017-06-24 18:36:44,611 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0039.states"
2017-06-24 18:36:55,533 Epoch[39] Batch [10]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.098014,	
2017-06-24 18:37:04,693 Epoch[39] Batch [20]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.093618,	
2017-06-24 18:37:13,746 Epoch[39] Batch [30]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.094368,	
2017-06-24 18:37:22,689 Epoch[39] Batch [40]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.094692,	
2017-06-24 18:37:32,210 Epoch[39] Batch [50]	Speed: 8.40 samples/sec	Train-FCNLogLoss=0.095459,	
2017-06-24 18:37:41,431 Epoch[39] Batch [60]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.095571,	
2017-06-24 18:37:50,139 Epoch[39] Batch [70]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.096857,	
2017-06-24 18:38:00,030 Epoch[39] Batch [80]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.095299,	
2017-06-24 18:38:08,943 Epoch[39] Batch [90]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.094357,	
2017-06-24 18:38:17,917 Epoch[39] Batch [100]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.094890,	
2017-06-24 18:38:26,890 Epoch[39] Batch [110]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.094823,	
2017-06-24 18:38:35,391 Epoch[39] Batch [120]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.094977,	
2017-06-24 18:38:44,293 Epoch[39] Batch [130]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.094742,	
2017-06-24 18:38:53,076 Epoch[39] Batch [140]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.094148,	
2017-06-24 18:39:01,433 Epoch[39] Batch [150]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.093923,	
2017-06-24 18:39:10,418 Epoch[39] Batch [160]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.094036,	
2017-06-24 18:39:19,013 Epoch[39] Batch [170]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.093533,	
2017-06-24 18:39:28,009 Epoch[39] Batch [180]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.093168,	
2017-06-24 18:39:37,180 Epoch[39] Batch [190]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.093707,	
2017-06-24 18:39:46,613 Epoch[39] Batch [200]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.093264,	
2017-06-24 18:39:55,885 Epoch[39] Batch [210]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.093099,	
2017-06-24 18:40:05,051 Epoch[39] Batch [220]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.093029,	
2017-06-24 18:40:14,150 Epoch[39] Batch [230]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.092993,	
2017-06-24 18:40:23,091 Epoch[39] Batch [240]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.093223,	
2017-06-24 18:40:32,088 Epoch[39] Batch [250]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.093581,	
2017-06-24 18:40:40,735 Epoch[39] Batch [260]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.094086,	
2017-06-24 18:40:49,470 Epoch[39] Batch [270]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.094543,	
2017-06-24 18:40:58,069 Epoch[39] Batch [280]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.094846,	
2017-06-24 18:41:07,016 Epoch[39] Batch [290]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.094913,	
2017-06-24 18:41:15,978 Epoch[39] Batch [300]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.094948,	
2017-06-24 18:41:24,639 Epoch[39] Batch [310]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.094731,	
2017-06-24 18:41:33,166 Epoch[39] Batch [320]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.094659,	
2017-06-24 18:41:41,993 Epoch[39] Batch [330]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.094824,	
2017-06-24 18:41:50,733 Epoch[39] Batch [340]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.094901,	
2017-06-24 18:41:59,738 Epoch[39] Batch [350]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.094972,	
2017-06-24 18:42:09,058 Epoch[39] Batch [360]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.094853,	
2017-06-24 18:42:18,082 Epoch[39] Batch [370]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.094910,	
2017-06-24 18:42:27,094 Epoch[39] Batch [380]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.094747,	
2017-06-24 18:42:36,805 Epoch[39] Batch [390]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.094745,	
2017-06-24 18:42:45,721 Epoch[39] Batch [400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.094579,	
2017-06-24 18:42:55,637 Epoch[39] Batch [410]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.094668,	
2017-06-24 18:43:05,634 Epoch[39] Batch [420]	Speed: 8.00 samples/sec	Train-FCNLogLoss=0.094623,	
2017-06-24 18:43:15,412 Epoch[39] Batch [430]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.094503,	
2017-06-24 18:43:25,372 Epoch[39] Batch [440]	Speed: 8.03 samples/sec	Train-FCNLogLoss=0.094499,	
2017-06-24 18:43:35,402 Epoch[39] Batch [450]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.094630,	
2017-06-24 18:43:45,921 Epoch[39] Batch [460]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.094510,	
2017-06-24 18:43:55,850 Epoch[39] Batch [470]	Speed: 8.06 samples/sec	Train-FCNLogLoss=0.094452,	
2017-06-24 18:44:05,784 Epoch[39] Batch [480]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.094266,	
2017-06-24 18:44:16,084 Epoch[39] Batch [490]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.094431,	
2017-06-24 18:44:25,320 Epoch[39] Batch [500]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.094504,	
2017-06-24 18:44:34,893 Epoch[39] Batch [510]	Speed: 8.36 samples/sec	Train-FCNLogLoss=0.094529,	
2017-06-24 18:44:45,233 Epoch[39] Batch [520]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.094466,	
2017-06-24 18:44:55,054 Epoch[39] Batch [530]	Speed: 8.15 samples/sec	Train-FCNLogLoss=0.094417,	
2017-06-24 18:45:05,128 Epoch[39] Batch [540]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.094379,	
2017-06-24 18:45:15,630 Epoch[39] Batch [550]	Speed: 7.62 samples/sec	Train-FCNLogLoss=0.094391,	
2017-06-24 18:45:25,985 Epoch[39] Batch [560]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.094489,	
2017-06-24 18:45:35,918 Epoch[39] Batch [570]	Speed: 8.05 samples/sec	Train-FCNLogLoss=0.094365,	
2017-06-24 18:45:46,708 Epoch[39] Batch [580]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.094446,	
2017-06-24 18:45:56,939 Epoch[39] Batch [590]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.094387,	
2017-06-24 18:46:06,101 Epoch[39] Batch [600]	Speed: 8.73 samples/sec	Train-FCNLogLoss=0.094547,	
2017-06-24 18:46:16,811 Epoch[39] Batch [610]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.094656,	
2017-06-24 18:46:27,612 Epoch[39] Batch [620]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.094620,	
2017-06-24 18:46:39,575 Epoch[39] Batch [630]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.094612,	
2017-06-24 18:46:51,575 Epoch[39] Batch [640]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.094620,	
2017-06-24 18:47:02,594 Epoch[39] Batch [650]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.094712,	
2017-06-24 18:47:14,093 Epoch[39] Batch [660]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.094783,	
2017-06-24 18:47:25,006 Epoch[39] Batch [670]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.094800,	
2017-06-24 18:47:36,268 Epoch[39] Batch [680]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.094721,	
2017-06-24 18:47:47,091 Epoch[39] Batch [690]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.094570,	
2017-06-24 18:47:58,579 Epoch[39] Batch [700]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.094585,	
2017-06-24 18:48:08,835 Epoch[39] Batch [710]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.094591,	
2017-06-24 18:48:20,829 Epoch[39] Batch [720]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.094508,	
2017-06-24 18:48:32,223 Epoch[39] Batch [730]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.094377,	
2017-06-24 18:48:43,728 Epoch[39] Batch [740]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.094365,	
2017-06-24 18:48:45,727 Epoch[39] Train-FCNLogLoss=0.094403
2017-06-24 18:48:45,727 Epoch[39] Time cost=721.116
2017-06-24 18:48:48,511 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0040.params"
2017-06-24 18:48:52,653 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0040.states"
2017-06-24 18:49:03,934 Epoch[40] Batch [10]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.090024,	
2017-06-24 18:49:16,580 Epoch[40] Batch [20]	Speed: 6.33 samples/sec	Train-FCNLogLoss=0.092099,	
2017-06-24 18:49:28,122 Epoch[40] Batch [30]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.090788,	
2017-06-24 18:49:38,522 Epoch[40] Batch [40]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.092601,	
2017-06-24 18:49:49,657 Epoch[40] Batch [50]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.091988,	
2017-06-24 18:50:01,175 Epoch[40] Batch [60]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.092373,	
2017-06-24 18:50:12,794 Epoch[40] Batch [70]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.093243,	
2017-06-24 18:50:24,583 Epoch[40] Batch [80]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.092030,	
2017-06-24 18:50:35,842 Epoch[40] Batch [90]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.092525,	
2017-06-24 18:50:46,635 Epoch[40] Batch [100]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.092072,	
2017-06-24 18:50:58,067 Epoch[40] Batch [110]	Speed: 7.00 samples/sec	Train-FCNLogLoss=0.092864,	
2017-06-24 18:51:09,346 Epoch[40] Batch [120]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.092709,	
2017-06-24 18:51:20,064 Epoch[40] Batch [130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.092394,	
2017-06-24 18:51:31,741 Epoch[40] Batch [140]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.092093,	
2017-06-24 18:51:42,052 Epoch[40] Batch [150]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.091695,	
2017-06-24 18:51:52,803 Epoch[40] Batch [160]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.091413,	
2017-06-24 18:52:04,791 Epoch[40] Batch [170]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.091777,	
2017-06-24 18:52:16,381 Epoch[40] Batch [180]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.092149,	
2017-06-24 18:52:28,368 Epoch[40] Batch [190]	Speed: 6.67 samples/sec	Train-FCNLogLoss=0.092573,	
2017-06-24 18:52:41,496 Epoch[40] Batch [200]	Speed: 6.10 samples/sec	Train-FCNLogLoss=0.092556,	
2017-06-24 18:52:53,082 Epoch[40] Batch [210]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.092604,	
2017-06-24 18:53:05,387 Epoch[40] Batch [220]	Speed: 6.50 samples/sec	Train-FCNLogLoss=0.092467,	
2017-06-24 18:53:16,376 Epoch[40] Batch [230]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.092403,	
2017-06-24 18:53:26,490 Epoch[40] Batch [240]	Speed: 7.91 samples/sec	Train-FCNLogLoss=0.092439,	
2017-06-24 18:53:36,871 Epoch[40] Batch [250]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.092325,	
2017-06-24 18:53:48,690 Epoch[40] Batch [260]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.092249,	
2017-06-24 18:54:00,208 Epoch[40] Batch [270]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.092291,	
2017-06-24 18:54:09,824 Update[30000]: Change learning rate to 5.00000e-05
2017-06-24 18:54:11,521 Epoch[40] Batch [280]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.092134,	
2017-06-24 18:54:23,064 Epoch[40] Batch [290]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.092183,	
2017-06-24 18:54:34,988 Epoch[40] Batch [300]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.092226,	
2017-06-24 18:54:46,359 Epoch[40] Batch [310]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.092268,	
2017-06-24 18:54:58,235 Epoch[40] Batch [320]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.092373,	
2017-06-24 18:55:08,436 Epoch[40] Batch [330]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.092322,	
2017-06-24 18:55:19,238 Epoch[40] Batch [340]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.092372,	
2017-06-24 18:55:30,407 Epoch[40] Batch [350]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.092246,	
2017-06-24 18:55:41,867 Epoch[40] Batch [360]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.092167,	
2017-06-24 18:55:52,750 Epoch[40] Batch [370]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.091995,	
2017-06-24 18:56:03,833 Epoch[40] Batch [380]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.091974,	
2017-06-24 18:56:15,677 Epoch[40] Batch [390]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.091899,	
2017-06-24 18:56:27,345 Epoch[40] Batch [400]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.091779,	
2017-06-24 18:56:38,504 Epoch[40] Batch [410]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.091754,	
2017-06-24 18:56:49,752 Epoch[40] Batch [420]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.091711,	
2017-06-24 18:57:00,618 Epoch[40] Batch [430]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.091573,	
2017-06-24 18:57:10,960 Epoch[40] Batch [440]	Speed: 7.74 samples/sec	Train-FCNLogLoss=0.091610,	
2017-06-24 18:57:22,135 Epoch[40] Batch [450]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.091461,	
2017-06-24 18:57:34,261 Epoch[40] Batch [460]	Speed: 6.60 samples/sec	Train-FCNLogLoss=0.091303,	
2017-06-24 18:57:45,750 Epoch[40] Batch [470]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.091128,	
2017-06-24 18:57:57,722 Epoch[40] Batch [480]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.091069,	
2017-06-24 18:58:09,297 Epoch[40] Batch [490]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.091051,	
2017-06-24 18:58:20,068 Epoch[40] Batch [500]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.090994,	
2017-06-24 18:58:31,088 Epoch[40] Batch [510]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.090896,	
2017-06-24 18:58:41,685 Epoch[40] Batch [520]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.090855,	
2017-06-24 18:58:52,222 Epoch[40] Batch [530]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.090769,	
2017-06-24 18:59:03,088 Epoch[40] Batch [540]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.090645,	
2017-06-24 18:59:14,845 Epoch[40] Batch [550]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.090569,	
2017-06-24 18:59:26,410 Epoch[40] Batch [560]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.090437,	
2017-06-24 18:59:38,618 Epoch[40] Batch [570]	Speed: 6.55 samples/sec	Train-FCNLogLoss=0.090441,	
2017-06-24 18:59:50,274 Epoch[40] Batch [580]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.090424,	
2017-06-24 19:00:02,066 Epoch[40] Batch [590]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.090435,	
2017-06-24 19:00:13,638 Epoch[40] Batch [600]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.090453,	
2017-06-24 19:00:25,254 Epoch[40] Batch [610]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.090541,	
2017-06-24 19:00:36,420 Epoch[40] Batch [620]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.090406,	
2017-06-24 19:00:46,505 Epoch[40] Batch [630]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.090478,	
2017-06-24 19:00:59,070 Epoch[40] Batch [640]	Speed: 6.37 samples/sec	Train-FCNLogLoss=0.090499,	
2017-06-24 19:01:10,232 Epoch[40] Batch [650]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.090392,	
2017-06-24 19:01:21,283 Epoch[40] Batch [660]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.090343,	
2017-06-24 19:01:31,988 Epoch[40] Batch [670]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.090302,	
2017-06-24 19:01:42,918 Epoch[40] Batch [680]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.090306,	
2017-06-24 19:01:54,219 Epoch[40] Batch [690]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.090291,	
2017-06-24 19:02:05,879 Epoch[40] Batch [700]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.090372,	
2017-06-24 19:02:17,578 Epoch[40] Batch [710]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.090331,	
2017-06-24 19:02:27,789 Epoch[40] Batch [720]	Speed: 7.83 samples/sec	Train-FCNLogLoss=0.090386,	
2017-06-24 19:02:37,620 Epoch[40] Batch [730]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.090357,	
2017-06-24 19:02:48,472 Epoch[40] Batch [740]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.090351,	
2017-06-24 19:02:50,833 Epoch[40] Train-FCNLogLoss=0.090382
2017-06-24 19:02:50,833 Epoch[40] Time cost=838.179
2017-06-24 19:02:52,812 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0041.params"
2017-06-24 19:02:56,867 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0041.states"
2017-06-24 19:03:10,099 Epoch[41] Batch [10]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.093469,	
2017-06-24 19:03:22,032 Epoch[41] Batch [20]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.089611,	
2017-06-24 19:03:34,040 Epoch[41] Batch [30]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.089732,	
2017-06-24 19:03:45,713 Epoch[41] Batch [40]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.089505,	
2017-06-24 19:03:56,554 Epoch[41] Batch [50]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.090559,	
2017-06-24 19:04:08,025 Epoch[41] Batch [60]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.090596,	
2017-06-24 19:04:18,560 Epoch[41] Batch [70]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.089876,	
2017-06-24 19:04:28,718 Epoch[41] Batch [80]	Speed: 7.88 samples/sec	Train-FCNLogLoss=0.090098,	
2017-06-24 19:04:39,934 Epoch[41] Batch [90]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.090141,	
2017-06-24 19:04:52,280 Epoch[41] Batch [100]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.089295,	
2017-06-24 19:05:04,112 Epoch[41] Batch [110]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.089897,	
2017-06-24 19:05:14,688 Epoch[41] Batch [120]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.090055,	
2017-06-24 19:05:26,200 Epoch[41] Batch [130]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.089931,	
2017-06-24 19:05:37,572 Epoch[41] Batch [140]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.089966,	
2017-06-24 19:05:48,385 Epoch[41] Batch [150]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.089681,	
2017-06-24 19:05:59,779 Epoch[41] Batch [160]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.089233,	
2017-06-24 19:06:09,481 Epoch[41] Batch [170]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.089365,	
2017-06-24 19:06:19,529 Epoch[41] Batch [180]	Speed: 7.96 samples/sec	Train-FCNLogLoss=0.089465,	
2017-06-24 19:06:30,416 Epoch[41] Batch [190]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.089411,	
2017-06-24 19:06:41,936 Epoch[41] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.089233,	
2017-06-24 19:06:53,653 Epoch[41] Batch [210]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.089271,	
2017-06-24 19:07:04,291 Epoch[41] Batch [220]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.089218,	
2017-06-24 19:07:15,497 Epoch[41] Batch [230]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.089199,	
2017-06-24 19:07:26,307 Epoch[41] Batch [240]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088963,	
2017-06-24 19:07:37,935 Epoch[41] Batch [250]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088600,	
2017-06-24 19:07:49,255 Epoch[41] Batch [260]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088609,	
2017-06-24 19:08:00,887 Epoch[41] Batch [270]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088448,	
2017-06-24 19:08:11,684 Epoch[41] Batch [280]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088568,	
2017-06-24 19:08:23,083 Epoch[41] Batch [290]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.088671,	
2017-06-24 19:08:34,846 Epoch[41] Batch [300]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.088485,	
2017-06-24 19:08:46,766 Epoch[41] Batch [310]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088417,	
2017-06-24 19:08:58,630 Epoch[41] Batch [320]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.088734,	
2017-06-24 19:09:09,639 Epoch[41] Batch [330]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.088846,	
2017-06-24 19:09:20,027 Epoch[41] Batch [340]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088845,	
2017-06-24 19:09:30,457 Epoch[41] Batch [350]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.088928,	
2017-06-24 19:09:41,100 Epoch[41] Batch [360]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.088945,	
2017-06-24 19:09:51,819 Epoch[41] Batch [370]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088818,	
2017-06-24 19:10:02,586 Epoch[41] Batch [380]	Speed: 7.43 samples/sec	Train-FCNLogLoss=0.088803,	
2017-06-24 19:10:13,310 Epoch[41] Batch [390]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.088903,	
2017-06-24 19:10:25,068 Epoch[41] Batch [400]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.088936,	
2017-06-24 19:10:37,133 Epoch[41] Batch [410]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.088814,	
2017-06-24 19:10:48,595 Epoch[41] Batch [420]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.088929,	
2017-06-24 19:11:00,278 Epoch[41] Batch [430]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088857,	
2017-06-24 19:11:11,677 Epoch[41] Batch [440]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.088724,	
2017-06-24 19:11:22,422 Epoch[41] Batch [450]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-24 19:11:33,352 Epoch[41] Batch [460]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.088808,	
2017-06-24 19:11:43,923 Epoch[41] Batch [470]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088855,	
2017-06-24 19:11:54,983 Epoch[41] Batch [480]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088837,	
2017-06-24 19:12:05,537 Epoch[41] Batch [490]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088734,	
2017-06-24 19:12:16,414 Epoch[41] Batch [500]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088611,	
2017-06-24 19:12:28,177 Epoch[41] Batch [510]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.088752,	
2017-06-24 19:12:39,793 Epoch[41] Batch [520]	Speed: 6.89 samples/sec	Train-FCNLogLoss=0.088850,	
2017-06-24 19:12:50,365 Epoch[41] Batch [530]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088896,	
2017-06-24 19:13:01,388 Epoch[41] Batch [540]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088865,	
2017-06-24 19:13:11,990 Epoch[41] Batch [550]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088853,	
2017-06-24 19:13:22,421 Epoch[41] Batch [560]	Speed: 7.67 samples/sec	Train-FCNLogLoss=0.088762,	
2017-06-24 19:13:32,198 Epoch[41] Batch [570]	Speed: 8.18 samples/sec	Train-FCNLogLoss=0.088770,	
2017-06-24 19:13:42,499 Epoch[41] Batch [580]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088894,	
2017-06-24 19:13:53,012 Epoch[41] Batch [590]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088914,	
2017-06-24 19:14:03,605 Epoch[41] Batch [600]	Speed: 7.55 samples/sec	Train-FCNLogLoss=0.088878,	
2017-06-24 19:14:15,116 Epoch[41] Batch [610]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088816,	
2017-06-24 19:14:27,375 Epoch[41] Batch [620]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.088825,	
2017-06-24 19:14:38,829 Epoch[41] Batch [630]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.088787,	
2017-06-24 19:14:50,452 Epoch[41] Batch [640]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088710,	
2017-06-24 19:15:01,637 Epoch[41] Batch [650]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.088793,	
2017-06-24 19:15:12,865 Epoch[41] Batch [660]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.088780,	
2017-06-24 19:15:23,454 Epoch[41] Batch [670]	Speed: 7.56 samples/sec	Train-FCNLogLoss=0.088757,	
2017-06-24 19:15:33,832 Epoch[41] Batch [680]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088866,	
2017-06-24 19:15:43,939 Epoch[41] Batch [690]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088726,	
2017-06-24 19:15:55,066 Epoch[41] Batch [700]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088756,	
2017-06-24 19:16:06,243 Epoch[41] Batch [710]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.088783,	
2017-06-24 19:16:17,895 Epoch[41] Batch [720]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088784,	
2017-06-24 19:16:28,148 Epoch[41] Batch [730]	Speed: 7.80 samples/sec	Train-FCNLogLoss=0.088768,	
2017-06-24 19:16:38,276 Epoch[41] Batch [740]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.088725,	
2017-06-24 19:16:40,170 Epoch[41] Train-FCNLogLoss=0.088690
2017-06-24 19:16:40,170 Epoch[41] Time cost=823.303
2017-06-24 19:16:43,906 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0042.params"
2017-06-24 19:16:47,957 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0042.states"
2017-06-24 19:17:01,192 Epoch[42] Batch [10]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.091606,	
2017-06-24 19:17:13,005 Epoch[42] Batch [20]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.091036,	
2017-06-24 19:17:24,206 Epoch[42] Batch [30]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.090425,	
2017-06-24 19:17:34,889 Epoch[42] Batch [40]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.090830,	
2017-06-24 19:17:46,744 Epoch[42] Batch [50]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.089096,	
2017-06-24 19:17:57,809 Epoch[42] Batch [60]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088076,	
2017-06-24 19:18:10,144 Epoch[42] Batch [70]	Speed: 6.49 samples/sec	Train-FCNLogLoss=0.086933,	
2017-06-24 19:18:21,994 Epoch[42] Batch [80]	Speed: 6.75 samples/sec	Train-FCNLogLoss=0.087193,	
2017-06-24 19:18:34,027 Epoch[42] Batch [90]	Speed: 6.65 samples/sec	Train-FCNLogLoss=0.087189,	
2017-06-24 19:18:45,470 Epoch[42] Batch [100]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.087388,	
2017-06-24 19:18:56,313 Epoch[42] Batch [110]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.087526,	
2017-06-24 19:19:06,488 Epoch[42] Batch [120]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087492,	
2017-06-24 19:19:17,211 Epoch[42] Batch [130]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087611,	
2017-06-24 19:19:27,622 Epoch[42] Batch [140]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.088093,	
2017-06-24 19:19:38,669 Epoch[42] Batch [150]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088053,	
2017-06-24 19:19:50,139 Epoch[42] Batch [160]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087761,	
2017-06-24 19:20:02,312 Epoch[42] Batch [170]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.087931,	
2017-06-24 19:20:14,730 Epoch[42] Batch [180]	Speed: 6.44 samples/sec	Train-FCNLogLoss=0.087649,	
2017-06-24 19:20:26,470 Epoch[42] Batch [190]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087821,	
2017-06-24 19:20:38,308 Epoch[42] Batch [200]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.087861,	
2017-06-24 19:20:48,674 Epoch[42] Batch [210]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.087681,	
2017-06-24 19:20:58,815 Epoch[42] Batch [220]	Speed: 7.89 samples/sec	Train-FCNLogLoss=0.088046,	
2017-06-24 19:21:09,365 Epoch[42] Batch [230]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.088135,	
2017-06-24 19:21:20,963 Epoch[42] Batch [240]	Speed: 6.90 samples/sec	Train-FCNLogLoss=0.087821,	
2017-06-24 19:21:32,662 Epoch[42] Batch [250]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.087767,	
2017-06-24 19:21:44,327 Epoch[42] Batch [260]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.087830,	
2017-06-24 19:21:56,071 Epoch[42] Batch [270]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087875,	
2017-06-24 19:22:08,218 Epoch[42] Batch [280]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087847,	
2017-06-24 19:22:18,966 Epoch[42] Batch [290]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.087943,	
2017-06-24 19:22:28,802 Epoch[42] Batch [300]	Speed: 8.13 samples/sec	Train-FCNLogLoss=0.088051,	
2017-06-24 19:22:39,129 Epoch[42] Batch [310]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.088236,	
2017-06-24 19:22:48,852 Epoch[42] Batch [320]	Speed: 8.23 samples/sec	Train-FCNLogLoss=0.088420,	
2017-06-24 19:22:59,537 Epoch[42] Batch [330]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088356,	
2017-06-24 19:23:11,113 Epoch[42] Batch [340]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.088539,	
2017-06-24 19:23:22,500 Epoch[42] Batch [350]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088423,	
2017-06-24 19:23:34,458 Epoch[42] Batch [360]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.088431,	
2017-06-24 19:23:45,969 Epoch[42] Batch [370]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088487,	
2017-06-24 19:23:56,632 Epoch[42] Batch [380]	Speed: 7.50 samples/sec	Train-FCNLogLoss=0.088520,	
2017-06-24 19:24:07,846 Epoch[42] Batch [390]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.088520,	
2017-06-24 19:24:18,843 Epoch[42] Batch [400]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.088464,	
2017-06-24 19:24:30,052 Epoch[42] Batch [410]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.088614,	
2017-06-24 19:24:40,580 Epoch[42] Batch [420]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088643,	
2017-06-24 19:24:51,001 Epoch[42] Batch [430]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.088586,	
2017-06-24 19:25:02,308 Epoch[42] Batch [440]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.088513,	
2017-06-24 19:25:13,726 Epoch[42] Batch [450]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088489,	
2017-06-24 19:25:24,479 Epoch[42] Batch [460]	Speed: 7.44 samples/sec	Train-FCNLogLoss=0.088529,	
2017-06-24 19:25:35,158 Epoch[42] Batch [470]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088628,	
2017-06-24 19:25:45,984 Epoch[42] Batch [480]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088571,	
2017-06-24 19:25:56,969 Epoch[42] Batch [490]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.088422,	
2017-06-24 19:26:07,581 Epoch[42] Batch [500]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088379,	
2017-06-24 19:26:18,127 Epoch[42] Batch [510]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088442,	
2017-06-24 19:26:28,579 Epoch[42] Batch [520]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088436,	
2017-06-24 19:26:40,441 Epoch[42] Batch [530]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.088596,	
2017-06-24 19:26:51,375 Epoch[42] Batch [540]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.088514,	
2017-06-24 19:27:02,723 Epoch[42] Batch [550]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.088434,	
2017-06-24 19:27:14,468 Epoch[42] Batch [560]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.088379,	
2017-06-24 19:27:25,673 Epoch[42] Batch [570]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.088465,	
2017-06-24 19:27:37,090 Epoch[42] Batch [580]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088612,	
2017-06-24 19:27:48,994 Epoch[42] Batch [590]	Speed: 6.72 samples/sec	Train-FCNLogLoss=0.088533,	
2017-06-24 19:28:00,134 Epoch[42] Batch [600]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088639,	
2017-06-24 19:28:10,555 Epoch[42] Batch [610]	Speed: 7.68 samples/sec	Train-FCNLogLoss=0.088598,	
2017-06-24 19:28:21,159 Epoch[42] Batch [620]	Speed: 7.54 samples/sec	Train-FCNLogLoss=0.088497,	
2017-06-24 19:28:32,483 Epoch[42] Batch [630]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088510,	
2017-06-24 19:28:44,407 Epoch[42] Batch [640]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.088609,	
2017-06-24 19:28:55,434 Epoch[42] Batch [650]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.088578,	
2017-06-24 19:29:06,557 Epoch[42] Batch [660]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088575,	
2017-06-24 19:29:18,566 Epoch[42] Batch [670]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.088647,	
2017-06-24 19:29:29,751 Epoch[42] Batch [680]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.088676,	
2017-06-24 19:29:41,235 Epoch[42] Batch [690]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.088660,	
2017-06-24 19:29:52,597 Epoch[42] Batch [700]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088692,	
2017-06-24 19:30:03,530 Epoch[42] Batch [710]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.088756,	
2017-06-24 19:30:13,595 Epoch[42] Batch [720]	Speed: 7.95 samples/sec	Train-FCNLogLoss=0.088704,	
2017-06-24 19:30:23,423 Epoch[42] Batch [730]	Speed: 8.14 samples/sec	Train-FCNLogLoss=0.088609,	
2017-06-24 19:30:36,024 Epoch[42] Batch [740]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088667,	
2017-06-24 19:30:38,321 Epoch[42] Train-FCNLogLoss=0.088649
2017-06-24 19:30:38,322 Epoch[42] Time cost=830.364
2017-06-24 19:30:40,879 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0043.params"
2017-06-24 19:30:44,978 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0043.states"
2017-06-24 19:31:04,397 Epoch[43] Batch [10]	Speed: 4.57 samples/sec	Train-FCNLogLoss=0.083683,	
2017-06-24 19:31:21,700 Epoch[43] Batch [20]	Speed: 4.62 samples/sec	Train-FCNLogLoss=0.090532,	
2017-06-24 19:31:35,186 Epoch[43] Batch [30]	Speed: 5.93 samples/sec	Train-FCNLogLoss=0.089926,	
2017-06-24 19:31:48,841 Epoch[43] Batch [40]	Speed: 5.86 samples/sec	Train-FCNLogLoss=0.090154,	
2017-06-24 19:31:59,158 Epoch[43] Batch [50]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.089055,	
2017-06-24 19:32:09,067 Epoch[43] Batch [60]	Speed: 8.07 samples/sec	Train-FCNLogLoss=0.088915,	
2017-06-24 19:32:20,431 Epoch[43] Batch [70]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088471,	
2017-06-24 19:32:33,039 Epoch[43] Batch [80]	Speed: 6.35 samples/sec	Train-FCNLogLoss=0.088412,	
2017-06-24 19:32:44,770 Epoch[43] Batch [90]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.089195,	
2017-06-24 19:32:56,422 Epoch[43] Batch [100]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088952,	
2017-06-24 19:33:07,752 Epoch[43] Batch [110]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.089310,	
2017-06-24 19:33:18,711 Epoch[43] Batch [120]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.089333,	
2017-06-24 19:33:30,269 Epoch[43] Batch [130]	Speed: 6.92 samples/sec	Train-FCNLogLoss=0.089003,	
2017-06-24 19:33:41,110 Epoch[43] Batch [140]	Speed: 7.38 samples/sec	Train-FCNLogLoss=0.088903,	
2017-06-24 19:33:52,008 Epoch[43] Batch [150]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.088643,	
2017-06-24 19:34:02,579 Epoch[43] Batch [160]	Speed: 7.57 samples/sec	Train-FCNLogLoss=0.088614,	
2017-06-24 19:34:13,126 Epoch[43] Batch [170]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088818,	
2017-06-24 19:34:25,513 Epoch[43] Batch [180]	Speed: 6.46 samples/sec	Train-FCNLogLoss=0.088738,	
2017-06-24 19:34:37,053 Epoch[43] Batch [190]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088822,	
2017-06-24 19:34:49,883 Epoch[43] Batch [200]	Speed: 6.24 samples/sec	Train-FCNLogLoss=0.088567,	
2017-06-24 19:35:02,051 Epoch[43] Batch [210]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.088419,	
2017-06-24 19:35:13,727 Epoch[43] Batch [220]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088617,	
2017-06-24 19:35:25,803 Epoch[43] Batch [230]	Speed: 6.63 samples/sec	Train-FCNLogLoss=0.088750,	
2017-06-24 19:35:36,313 Epoch[43] Batch [240]	Speed: 7.61 samples/sec	Train-FCNLogLoss=0.088790,	
2017-06-24 19:35:47,454 Epoch[43] Batch [250]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088633,	
2017-06-24 19:35:56,894 Epoch[43] Batch [260]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.088417,	
2017-06-24 19:36:08,275 Epoch[43] Batch [270]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088417,	
2017-06-24 19:36:20,238 Epoch[43] Batch [280]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.088506,	
2017-06-24 19:36:31,370 Epoch[43] Batch [290]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088466,	
2017-06-24 19:36:42,694 Epoch[43] Batch [300]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088667,	
2017-06-24 19:36:53,868 Epoch[43] Batch [310]	Speed: 7.16 samples/sec	Train-FCNLogLoss=0.088795,	
2017-06-24 19:37:05,516 Epoch[43] Batch [320]	Speed: 6.87 samples/sec	Train-FCNLogLoss=0.088620,	
2017-06-24 19:37:17,004 Epoch[43] Batch [330]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.088571,	
2017-06-24 19:37:28,799 Epoch[43] Batch [340]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.088607,	
2017-06-24 19:37:38,657 Epoch[43] Batch [350]	Speed: 8.12 samples/sec	Train-FCNLogLoss=0.088415,	
2017-06-24 19:37:49,798 Epoch[43] Batch [360]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088532,	
2017-06-24 19:38:01,579 Epoch[43] Batch [370]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088824,	
2017-06-24 19:38:12,910 Epoch[43] Batch [380]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.088679,	
2017-06-24 19:38:24,457 Epoch[43] Batch [390]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088687,	
2017-06-24 19:38:36,808 Epoch[43] Batch [400]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.088746,	
2017-06-24 19:38:48,102 Epoch[43] Batch [410]	Speed: 7.08 samples/sec	Train-FCNLogLoss=0.088684,	
2017-06-24 19:38:58,758 Epoch[43] Batch [420]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088700,	
2017-06-24 19:39:10,037 Epoch[43] Batch [430]	Speed: 7.09 samples/sec	Train-FCNLogLoss=0.088769,	
2017-06-24 19:39:20,836 Epoch[43] Batch [440]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088675,	
2017-06-24 19:39:31,209 Epoch[43] Batch [450]	Speed: 7.71 samples/sec	Train-FCNLogLoss=0.088651,	
2017-06-24 19:39:42,412 Epoch[43] Batch [460]	Speed: 7.14 samples/sec	Train-FCNLogLoss=0.088729,	
2017-06-24 19:39:53,634 Epoch[43] Batch [470]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.088823,	
2017-06-24 19:40:05,510 Epoch[43] Batch [480]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.088751,	
2017-06-24 19:40:17,999 Epoch[43] Batch [490]	Speed: 6.41 samples/sec	Train-FCNLogLoss=0.088905,	
2017-06-24 19:40:29,733 Epoch[43] Batch [500]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.088850,	
2017-06-24 19:40:39,499 Epoch[43] Batch [510]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.088923,	
2017-06-24 19:40:49,904 Epoch[43] Batch [520]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088874,	
2017-06-24 19:41:02,008 Epoch[43] Batch [530]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.088758,	
2017-06-24 19:41:12,957 Epoch[43] Batch [540]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.088669,	
2017-06-24 19:41:23,823 Epoch[43] Batch [550]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088723,	
2017-06-24 19:41:34,974 Epoch[43] Batch [560]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088708,	
2017-06-24 19:41:47,055 Epoch[43] Batch [570]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.088630,	
2017-06-24 19:41:58,992 Epoch[43] Batch [580]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.088652,	
2017-06-24 19:42:10,435 Epoch[43] Batch [590]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.088562,	
2017-06-24 19:42:21,754 Epoch[43] Batch [600]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088591,	
2017-06-24 19:42:32,654 Epoch[43] Batch [610]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-24 19:42:44,478 Epoch[43] Batch [620]	Speed: 6.77 samples/sec	Train-FCNLogLoss=0.088650,	
2017-06-24 19:42:56,158 Epoch[43] Batch [630]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088695,	
2017-06-24 19:43:08,112 Epoch[43] Batch [640]	Speed: 6.69 samples/sec	Train-FCNLogLoss=0.088653,	
2017-06-24 19:43:19,179 Epoch[43] Batch [650]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088643,	
2017-06-24 19:43:29,368 Epoch[43] Batch [660]	Speed: 7.85 samples/sec	Train-FCNLogLoss=0.088637,	
2017-06-24 19:43:40,502 Epoch[43] Batch [670]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088495,	
2017-06-24 19:43:51,560 Epoch[43] Batch [680]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088558,	
2017-06-24 19:44:02,415 Epoch[43] Batch [690]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088535,	
2017-06-24 19:44:13,477 Epoch[43] Batch [700]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088477,	
2017-06-24 19:44:24,559 Epoch[43] Batch [710]	Speed: 7.22 samples/sec	Train-FCNLogLoss=0.088366,	
2017-06-24 19:44:36,180 Epoch[43] Batch [720]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.088356,	
2017-06-24 19:44:47,927 Epoch[43] Batch [730]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.088445,	
2017-06-24 19:44:59,115 Epoch[43] Batch [740]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.088326,	
2017-06-24 19:45:01,252 Epoch[43] Train-FCNLogLoss=0.088321
2017-06-24 19:45:01,253 Epoch[43] Time cost=856.274
2017-06-24 19:45:02,718 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0044.params"
2017-06-24 19:45:06,714 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0044.states"
2017-06-24 19:45:18,322 Epoch[44] Batch [10]	Speed: 7.98 samples/sec	Train-FCNLogLoss=0.082875,	
2017-06-24 19:45:29,772 Epoch[44] Batch [20]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.089263,	
2017-06-24 19:45:41,566 Epoch[44] Batch [30]	Speed: 6.78 samples/sec	Train-FCNLogLoss=0.089583,	
2017-06-24 19:45:52,797 Epoch[44] Batch [40]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.089140,	
2017-06-24 19:46:02,918 Epoch[44] Batch [50]	Speed: 7.90 samples/sec	Train-FCNLogLoss=0.088111,	
2017-06-24 19:46:14,427 Epoch[44] Batch [60]	Speed: 6.95 samples/sec	Train-FCNLogLoss=0.088136,	
2017-06-24 19:46:25,145 Epoch[44] Batch [70]	Speed: 7.46 samples/sec	Train-FCNLogLoss=0.087988,	
2017-06-24 19:46:36,532 Epoch[44] Batch [80]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088872,	
2017-06-24 19:46:47,595 Epoch[44] Batch [90]	Speed: 7.23 samples/sec	Train-FCNLogLoss=0.088412,	
2017-06-24 19:46:58,496 Epoch[44] Batch [100]	Speed: 7.34 samples/sec	Train-FCNLogLoss=0.088629,	
2017-06-24 19:47:09,300 Epoch[44] Batch [110]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.088520,	
2017-06-24 19:47:21,162 Epoch[44] Batch [120]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.088220,	
2017-06-24 19:47:32,842 Epoch[44] Batch [130]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088779,	
2017-06-24 19:47:43,661 Epoch[44] Batch [140]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088746,	
2017-06-24 19:47:54,054 Epoch[44] Batch [150]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088568,	
2017-06-24 19:48:05,599 Epoch[44] Batch [160]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088443,	
2017-06-24 19:48:16,856 Epoch[44] Batch [170]	Speed: 7.11 samples/sec	Train-FCNLogLoss=0.088314,	
2017-06-24 19:48:28,322 Epoch[44] Batch [180]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087980,	
2017-06-24 19:48:40,546 Epoch[44] Batch [190]	Speed: 6.54 samples/sec	Train-FCNLogLoss=0.088493,	
2017-06-24 19:48:51,348 Epoch[44] Batch [200]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088517,	
2017-06-24 19:49:01,433 Epoch[44] Batch [210]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088469,	
2017-06-24 19:49:12,176 Epoch[44] Batch [220]	Speed: 7.45 samples/sec	Train-FCNLogLoss=0.088090,	
2017-06-24 19:49:22,652 Epoch[44] Batch [230]	Speed: 7.64 samples/sec	Train-FCNLogLoss=0.088434,	
2017-06-24 19:49:33,332 Epoch[44] Batch [240]	Speed: 7.49 samples/sec	Train-FCNLogLoss=0.088611,	
2017-06-24 19:49:44,211 Epoch[44] Batch [250]	Speed: 7.35 samples/sec	Train-FCNLogLoss=0.088677,	
2017-06-24 19:49:55,748 Epoch[44] Batch [260]	Speed: 6.93 samples/sec	Train-FCNLogLoss=0.088996,	
2017-06-24 19:50:06,150 Epoch[44] Batch [270]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088878,	
2017-06-24 19:50:16,244 Epoch[44] Batch [280]	Speed: 7.93 samples/sec	Train-FCNLogLoss=0.088951,	
2017-06-24 19:50:27,341 Epoch[44] Batch [290]	Speed: 7.21 samples/sec	Train-FCNLogLoss=0.089007,	
2017-06-24 19:50:38,463 Epoch[44] Batch [300]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088876,	
2017-06-24 19:50:49,869 Epoch[44] Batch [310]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088929,	
2017-06-24 19:50:59,949 Epoch[44] Batch [320]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088888,	
2017-06-24 19:51:10,486 Epoch[44] Batch [330]	Speed: 7.59 samples/sec	Train-FCNLogLoss=0.088998,	
2017-06-24 19:51:21,140 Epoch[44] Batch [340]	Speed: 7.51 samples/sec	Train-FCNLogLoss=0.088961,	
2017-06-24 19:51:32,058 Epoch[44] Batch [350]	Speed: 7.33 samples/sec	Train-FCNLogLoss=0.089181,	
2017-06-24 19:51:43,416 Epoch[44] Batch [360]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.089325,	
2017-06-24 19:51:55,521 Epoch[44] Batch [370]	Speed: 6.61 samples/sec	Train-FCNLogLoss=0.089194,	
2017-06-24 19:52:06,991 Epoch[44] Batch [380]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.089168,	
2017-06-24 19:52:19,335 Epoch[44] Batch [390]	Speed: 6.48 samples/sec	Train-FCNLogLoss=0.088889,	
2017-06-24 19:52:30,442 Epoch[44] Batch [400]	Speed: 7.20 samples/sec	Train-FCNLogLoss=0.088972,	
2017-06-24 19:52:40,809 Epoch[44] Batch [410]	Speed: 7.72 samples/sec	Train-FCNLogLoss=0.088918,	
2017-06-24 19:52:51,036 Epoch[44] Batch [420]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088798,	
2017-06-24 19:53:02,088 Epoch[44] Batch [430]	Speed: 7.24 samples/sec	Train-FCNLogLoss=0.088682,	
2017-06-24 19:53:13,237 Epoch[44] Batch [440]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-24 19:53:24,730 Epoch[44] Batch [450]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.088589,	
2017-06-24 19:53:36,558 Epoch[44] Batch [460]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.088519,	
2017-06-24 19:53:48,270 Epoch[44] Batch [470]	Speed: 6.83 samples/sec	Train-FCNLogLoss=0.088473,	
2017-06-24 19:53:59,956 Epoch[44] Batch [480]	Speed: 6.85 samples/sec	Train-FCNLogLoss=0.088553,	
2017-06-24 19:54:11,318 Epoch[44] Batch [490]	Speed: 7.04 samples/sec	Train-FCNLogLoss=0.088563,	
2017-06-24 19:54:22,626 Epoch[44] Batch [500]	Speed: 7.07 samples/sec	Train-FCNLogLoss=0.088598,	
2017-06-24 19:54:33,157 Epoch[44] Batch [510]	Speed: 7.60 samples/sec	Train-FCNLogLoss=0.088468,	
2017-06-24 19:54:44,288 Epoch[44] Batch [520]	Speed: 7.19 samples/sec	Train-FCNLogLoss=0.088406,	
2017-06-24 19:54:55,514 Epoch[44] Batch [530]	Speed: 7.13 samples/sec	Train-FCNLogLoss=0.088293,	
2017-06-24 19:55:06,210 Epoch[44] Batch [540]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.088329,	
2017-06-24 19:55:17,471 Epoch[44] Batch [550]	Speed: 7.10 samples/sec	Train-FCNLogLoss=0.088190,	
2017-06-24 19:55:28,426 Epoch[44] Batch [560]	Speed: 7.30 samples/sec	Train-FCNLogLoss=0.088228,	
2017-06-24 19:55:40,207 Epoch[44] Batch [570]	Speed: 6.79 samples/sec	Train-FCNLogLoss=0.088300,	
2017-06-24 19:55:52,713 Epoch[44] Batch [580]	Speed: 6.40 samples/sec	Train-FCNLogLoss=0.088262,	
2017-06-24 19:56:04,895 Epoch[44] Batch [590]	Speed: 6.57 samples/sec	Train-FCNLogLoss=0.088281,	
2017-06-24 19:56:16,250 Epoch[44] Batch [600]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.088278,	
2017-06-24 19:56:27,114 Epoch[44] Batch [610]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.088291,	
2017-06-24 19:56:37,415 Epoch[44] Batch [620]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088252,	
2017-06-24 19:56:48,801 Epoch[44] Batch [630]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.088180,	
2017-06-24 19:56:59,102 Epoch[44] Batch [640]	Speed: 7.77 samples/sec	Train-FCNLogLoss=0.088182,	
2017-06-24 19:57:10,456 Epoch[44] Batch [650]	Speed: 7.05 samples/sec	Train-FCNLogLoss=0.088110,	
2017-06-24 19:57:21,914 Epoch[44] Batch [660]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.088080,	
2017-06-24 19:57:34,186 Epoch[44] Batch [670]	Speed: 6.52 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-24 19:57:45,599 Epoch[44] Batch [680]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.088195,	
2017-06-24 19:57:57,605 Epoch[44] Batch [690]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.088175,	
2017-06-24 19:58:08,769 Epoch[44] Batch [700]	Speed: 7.17 samples/sec	Train-FCNLogLoss=0.088277,	
2017-06-24 19:58:20,219 Epoch[44] Batch [710]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.088273,	
2017-06-24 19:58:30,621 Epoch[44] Batch [720]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.088233,	
2017-06-24 19:58:40,852 Epoch[44] Batch [730]	Speed: 7.82 samples/sec	Train-FCNLogLoss=0.088161,	
2017-06-24 19:58:51,644 Epoch[44] Batch [740]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.088048,	
2017-06-24 19:58:53,643 Epoch[44] Train-FCNLogLoss=0.088094
2017-06-24 19:58:53,643 Epoch[44] Time cost=826.928
2017-06-24 19:58:57,441 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0045.params"
2017-06-24 19:59:01,541 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0045.states"
2017-06-24 19:59:15,196 Epoch[45] Batch [10]	Speed: 6.62 samples/sec	Train-FCNLogLoss=0.087194,	
2017-06-24 19:59:27,773 Epoch[45] Batch [20]	Speed: 6.36 samples/sec	Train-FCNLogLoss=0.085562,	
2017-06-24 19:59:40,211 Epoch[45] Batch [30]	Speed: 6.43 samples/sec	Train-FCNLogLoss=0.087717,	
2017-06-24 19:59:51,212 Epoch[45] Batch [40]	Speed: 7.27 samples/sec	Train-FCNLogLoss=0.087652,	
2017-06-24 20:00:02,839 Epoch[45] Batch [50]	Speed: 6.88 samples/sec	Train-FCNLogLoss=0.087427,	
2017-06-24 20:00:13,832 Epoch[45] Batch [60]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.087827,	
2017-06-24 20:00:23,816 Epoch[45] Batch [70]	Speed: 8.01 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-24 20:00:35,307 Epoch[45] Batch [80]	Speed: 6.96 samples/sec	Train-FCNLogLoss=0.088044,	
2017-06-24 20:00:47,239 Epoch[45] Batch [90]	Speed: 6.70 samples/sec	Train-FCNLogLoss=0.088475,	
2017-06-24 20:00:58,427 Epoch[45] Batch [100]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087824,	
2017-06-24 20:01:10,355 Epoch[45] Batch [110]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087704,	
2017-06-24 20:01:22,023 Epoch[45] Batch [120]	Speed: 6.86 samples/sec	Train-FCNLogLoss=0.088391,	
2017-06-24 20:01:33,426 Epoch[45] Batch [130]	Speed: 7.02 samples/sec	Train-FCNLogLoss=0.088033,	
2017-06-24 20:01:44,900 Epoch[45] Batch [140]	Speed: 6.97 samples/sec	Train-FCNLogLoss=0.087868,	
2017-06-24 20:01:55,167 Epoch[45] Batch [150]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087410,	
2017-06-24 20:02:05,564 Epoch[45] Batch [160]	Speed: 7.69 samples/sec	Train-FCNLogLoss=0.087045,	
2017-06-24 20:02:15,463 Epoch[45] Batch [170]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087039,	
2017-06-24 20:02:25,736 Epoch[45] Batch [180]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087188,	
2017-06-24 20:02:37,204 Epoch[45] Batch [190]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087155,	
2017-06-24 20:02:48,735 Epoch[45] Batch [200]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087331,	
2017-06-24 20:02:59,537 Epoch[45] Batch [210]	Speed: 7.41 samples/sec	Train-FCNLogLoss=0.087155,	
2017-06-24 20:03:11,224 Epoch[45] Batch [220]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.087528,	
2017-06-24 20:03:22,158 Epoch[45] Batch [230]	Speed: 7.32 samples/sec	Train-FCNLogLoss=0.087307,	
2017-06-24 20:03:33,171 Epoch[45] Batch [240]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.087567,	
2017-06-24 20:03:44,503 Epoch[45] Batch [250]	Speed: 7.06 samples/sec	Train-FCNLogLoss=0.087591,	
2017-06-24 20:03:55,053 Epoch[45] Batch [260]	Speed: 7.58 samples/sec	Train-FCNLogLoss=0.087712,	
2017-06-24 20:04:05,406 Epoch[45] Batch [270]	Speed: 7.73 samples/sec	Train-FCNLogLoss=0.087920,	
2017-06-24 20:04:15,727 Epoch[45] Batch [280]	Speed: 7.75 samples/sec	Train-FCNLogLoss=0.087838,	
2017-06-24 20:04:27,176 Epoch[45] Batch [290]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.087882,	
2017-06-24 20:04:38,635 Epoch[45] Batch [300]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.087999,	
2017-06-24 20:04:49,624 Epoch[45] Batch [310]	Speed: 7.28 samples/sec	Train-FCNLogLoss=0.087852,	
2017-06-24 20:05:01,373 Epoch[45] Batch [320]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.087821,	
2017-06-24 20:05:12,389 Epoch[45] Batch [330]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.087886,	
2017-06-24 20:05:23,263 Epoch[45] Batch [340]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.087963,	
2017-06-24 20:05:34,276 Epoch[45] Batch [350]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.087978,	
2017-06-24 20:05:44,381 Epoch[45] Batch [360]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.088022,	
2017-06-24 20:05:55,257 Epoch[45] Batch [370]	Speed: 7.36 samples/sec	Train-FCNLogLoss=0.087867,	
2017-06-24 20:06:06,451 Epoch[45] Batch [380]	Speed: 7.15 samples/sec	Train-FCNLogLoss=0.087630,	
2017-06-24 20:06:17,682 Epoch[45] Batch [390]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.087688,	
2017-06-24 20:06:29,524 Epoch[45] Batch [400]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.087650,	
2017-06-24 20:06:41,402 Epoch[45] Batch [410]	Speed: 6.74 samples/sec	Train-FCNLogLoss=0.087784,	
2017-06-24 20:06:52,815 Epoch[45] Batch [420]	Speed: 7.01 samples/sec	Train-FCNLogLoss=0.087754,	
2017-06-24 20:07:04,514 Epoch[45] Batch [430]	Speed: 6.84 samples/sec	Train-FCNLogLoss=0.087893,	
2017-06-24 20:07:16,279 Epoch[45] Batch [440]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087854,	
2017-06-24 20:07:26,555 Epoch[45] Batch [450]	Speed: 7.79 samples/sec	Train-FCNLogLoss=0.087934,	
2017-06-24 20:07:37,197 Epoch[45] Batch [460]	Speed: 7.52 samples/sec	Train-FCNLogLoss=0.087994,	
2017-06-24 20:07:47,908 Epoch[45] Batch [470]	Speed: 7.47 samples/sec	Train-FCNLogLoss=0.087921,	
2017-06-24 20:07:59,057 Epoch[45] Batch [480]	Speed: 7.18 samples/sec	Train-FCNLogLoss=0.087972,	
2017-06-24 20:08:09,753 Epoch[45] Batch [490]	Speed: 7.48 samples/sec	Train-FCNLogLoss=0.087867,	
2017-06-24 20:08:21,649 Epoch[45] Batch [500]	Speed: 6.73 samples/sec	Train-FCNLogLoss=0.087895,	
2017-06-24 20:08:33,096 Epoch[45] Batch [510]	Speed: 6.99 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-24 20:08:45,023 Epoch[45] Batch [520]	Speed: 6.71 samples/sec	Train-FCNLogLoss=0.087909,	
2017-06-24 20:08:56,760 Epoch[45] Batch [530]	Speed: 6.82 samples/sec	Train-FCNLogLoss=0.087813,	
2017-06-24 20:09:07,700 Epoch[45] Batch [540]	Speed: 7.31 samples/sec	Train-FCNLogLoss=0.087897,	
2017-06-24 20:09:18,090 Epoch[45] Batch [550]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.087955,	
2017-06-24 20:09:29,112 Epoch[45] Batch [560]	Speed: 7.26 samples/sec	Train-FCNLogLoss=0.087888,	
2017-06-24 20:09:41,086 Epoch[45] Batch [570]	Speed: 6.68 samples/sec	Train-FCNLogLoss=0.087806,	
2017-06-24 20:09:52,656 Epoch[45] Batch [580]	Speed: 6.91 samples/sec	Train-FCNLogLoss=0.087897,	
2017-06-24 20:10:04,042 Epoch[45] Batch [590]	Speed: 7.03 samples/sec	Train-FCNLogLoss=0.087854,	
2017-06-24 20:10:16,048 Epoch[45] Batch [600]	Speed: 6.66 samples/sec	Train-FCNLogLoss=0.088020,	
2017-06-24 20:10:27,504 Epoch[45] Batch [610]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.088127,	
2017-06-24 20:10:39,759 Epoch[45] Batch [620]	Speed: 6.53 samples/sec	Train-FCNLogLoss=0.088096,	
2017-06-24 20:10:50,795 Epoch[45] Batch [630]	Speed: 7.25 samples/sec	Train-FCNLogLoss=0.088106,	
2017-06-24 20:11:01,250 Epoch[45] Batch [640]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088027,	
2017-06-24 20:11:12,078 Epoch[45] Batch [650]	Speed: 7.39 samples/sec	Train-FCNLogLoss=0.088051,	
2017-06-24 20:11:23,603 Epoch[45] Batch [660]	Speed: 6.94 samples/sec	Train-FCNLogLoss=0.087971,	
2017-06-24 20:11:35,355 Epoch[45] Batch [670]	Speed: 6.81 samples/sec	Train-FCNLogLoss=0.088017,	
2017-06-24 20:11:45,809 Epoch[45] Batch [680]	Speed: 7.65 samples/sec	Train-FCNLogLoss=0.088040,	
2017-06-24 20:11:57,956 Epoch[45] Batch [690]	Speed: 6.59 samples/sec	Train-FCNLogLoss=0.087981,	
2017-06-24 20:12:09,789 Epoch[45] Batch [700]	Speed: 6.76 samples/sec	Train-FCNLogLoss=0.087931,	
2017-06-24 20:12:21,259 Epoch[45] Batch [710]	Speed: 6.98 samples/sec	Train-FCNLogLoss=0.088037,	
2017-06-24 20:12:32,494 Epoch[45] Batch [720]	Speed: 7.12 samples/sec	Train-FCNLogLoss=0.088086,	
2017-06-24 20:12:43,353 Epoch[45] Batch [730]	Speed: 7.37 samples/sec	Train-FCNLogLoss=0.088053,	
2017-06-24 20:12:56,191 Epoch[45] Batch [740]	Speed: 6.23 samples/sec	Train-FCNLogLoss=0.088006,	
2017-06-24 20:12:57,687 Epoch[45] Train-FCNLogLoss=0.088083
2017-06-24 20:12:57,687 Epoch[45] Time cost=836.146
2017-06-24 20:13:00,487 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0046.params"
2017-06-24 20:13:04,353 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0046.states"
2017-06-24 20:13:14,297 Epoch[46] Batch [10]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.090254,	
2017-06-24 20:13:23,316 Epoch[46] Batch [20]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.088131,	
2017-06-24 20:13:32,365 Epoch[46] Batch [30]	Speed: 8.84 samples/sec	Train-FCNLogLoss=0.090021,	
2017-06-24 20:13:41,578 Epoch[46] Batch [40]	Speed: 8.68 samples/sec	Train-FCNLogLoss=0.088243,	
2017-06-24 20:13:51,748 Epoch[46] Batch [50]	Speed: 7.87 samples/sec	Train-FCNLogLoss=0.088621,	
2017-06-24 20:14:01,703 Epoch[46] Batch [60]	Speed: 8.04 samples/sec	Train-FCNLogLoss=0.089085,	
2017-06-24 20:14:11,017 Epoch[46] Batch [70]	Speed: 8.59 samples/sec	Train-FCNLogLoss=0.088661,	
2017-06-24 20:14:21,223 Epoch[46] Batch [80]	Speed: 7.84 samples/sec	Train-FCNLogLoss=0.088517,	
2017-06-24 20:14:31,612 Epoch[46] Batch [90]	Speed: 7.70 samples/sec	Train-FCNLogLoss=0.088605,	
2017-06-24 20:14:41,685 Epoch[46] Batch [100]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088510,	
2017-06-24 20:14:51,765 Epoch[46] Batch [110]	Speed: 7.94 samples/sec	Train-FCNLogLoss=0.088083,	
2017-06-24 20:15:01,120 Epoch[46] Batch [120]	Speed: 8.55 samples/sec	Train-FCNLogLoss=0.088222,	
2017-06-24 20:15:10,798 Epoch[46] Batch [130]	Speed: 8.27 samples/sec	Train-FCNLogLoss=0.088017,	
2017-06-24 20:15:20,504 Epoch[46] Batch [140]	Speed: 8.24 samples/sec	Train-FCNLogLoss=0.087521,	
2017-06-24 20:15:30,605 Epoch[46] Batch [150]	Speed: 7.92 samples/sec	Train-FCNLogLoss=0.087445,	
2017-06-24 20:15:40,787 Epoch[46] Batch [160]	Speed: 7.86 samples/sec	Train-FCNLogLoss=0.087747,	
2017-06-24 20:15:50,132 Epoch[46] Batch [170]	Speed: 8.56 samples/sec	Train-FCNLogLoss=0.087525,	
2017-06-24 20:15:59,637 Epoch[46] Batch [180]	Speed: 8.42 samples/sec	Train-FCNLogLoss=0.087582,	
2017-06-24 20:16:09,404 Epoch[46] Batch [190]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.087322,	
2017-06-24 20:16:18,923 Epoch[46] Batch [200]	Speed: 8.41 samples/sec	Train-FCNLogLoss=0.087228,	
2017-06-24 20:16:28,416 Epoch[46] Batch [210]	Speed: 8.43 samples/sec	Train-FCNLogLoss=0.087327,	
2017-06-24 20:16:37,715 Epoch[46] Batch [220]	Speed: 8.60 samples/sec	Train-FCNLogLoss=0.087240,	
2017-06-24 20:16:48,022 Epoch[46] Batch [230]	Speed: 7.76 samples/sec	Train-FCNLogLoss=0.087054,	
2017-06-24 20:16:57,626 Epoch[46] Batch [240]	Speed: 8.33 samples/sec	Train-FCNLogLoss=0.086834,	
2017-06-24 20:17:07,058 Epoch[46] Batch [250]	Speed: 8.48 samples/sec	Train-FCNLogLoss=0.086858,	
2017-06-24 20:17:16,252 Epoch[46] Batch [260]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.086828,	
2017-06-24 20:17:25,637 Epoch[46] Batch [270]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.086821,	
2017-06-24 20:17:35,410 Epoch[46] Batch [280]	Speed: 8.19 samples/sec	Train-FCNLogLoss=0.086750,	
2017-06-24 20:17:44,522 Epoch[46] Batch [290]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.086688,	
2017-06-24 20:17:53,533 Epoch[46] Batch [300]	Speed: 8.88 samples/sec	Train-FCNLogLoss=0.086858,	
2017-06-24 20:18:03,320 Epoch[46] Batch [310]	Speed: 8.17 samples/sec	Train-FCNLogLoss=0.086673,	
2017-06-24 20:18:13,019 Epoch[46] Batch [320]	Speed: 8.25 samples/sec	Train-FCNLogLoss=0.086852,	
2017-06-24 20:18:22,908 Epoch[46] Batch [330]	Speed: 8.09 samples/sec	Train-FCNLogLoss=0.086926,	
2017-06-24 20:18:32,805 Epoch[46] Batch [340]	Speed: 8.08 samples/sec	Train-FCNLogLoss=0.087007,	
2017-06-24 20:18:42,491 Epoch[46] Batch [350]	Speed: 8.26 samples/sec	Train-FCNLogLoss=0.087222,	
2017-06-24 20:18:51,484 Epoch[46] Batch [360]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087192,	
2017-06-24 20:19:00,848 Epoch[46] Batch [370]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087327,	
2017-06-24 20:19:09,666 Epoch[46] Batch [380]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087216,	
2017-06-24 20:19:18,779 Epoch[46] Batch [390]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087281,	
2017-06-24 20:19:27,693 Epoch[46] Batch [400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087221,	
2017-06-24 20:19:36,112 Epoch[46] Batch [410]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.087114,	
2017-06-24 20:19:44,404 Epoch[46] Batch [420]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.087128,	
2017-06-24 20:19:52,386 Epoch[46] Batch [430]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.087114,	
2017-06-24 20:20:00,807 Epoch[46] Batch [440]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.087166,	
2017-06-24 20:20:09,076 Epoch[46] Batch [450]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087213,	
2017-06-24 20:20:17,121 Epoch[46] Batch [460]	Speed: 9.94 samples/sec	Train-FCNLogLoss=0.087400,	
2017-06-24 20:20:25,662 Epoch[46] Batch [470]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.087444,	
2017-06-24 20:20:34,316 Epoch[46] Batch [480]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087510,	
2017-06-24 20:20:43,011 Epoch[46] Batch [490]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087364,	
2017-06-24 20:20:51,604 Epoch[46] Batch [500]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087237,	
2017-06-24 20:21:01,025 Epoch[46] Batch [510]	Speed: 8.49 samples/sec	Train-FCNLogLoss=0.087288,	
2017-06-24 20:21:10,507 Epoch[46] Batch [520]	Speed: 8.44 samples/sec	Train-FCNLogLoss=0.087295,	
2017-06-24 20:21:18,867 Epoch[46] Batch [530]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087233,	
2017-06-24 20:21:26,844 Epoch[46] Batch [540]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.087329,	
2017-06-24 20:21:35,974 Epoch[46] Batch [550]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087442,	
2017-06-24 20:21:44,326 Epoch[46] Batch [560]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.087376,	
2017-06-24 20:21:53,155 Epoch[46] Batch [570]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087302,	
2017-06-24 20:22:01,733 Epoch[46] Batch [580]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087385,	
2017-06-24 20:22:10,019 Epoch[46] Batch [590]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.087315,	
2017-06-24 20:22:18,231 Epoch[46] Batch [600]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.087256,	
2017-06-24 20:22:26,338 Epoch[46] Batch [610]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.087285,	
2017-06-24 20:22:34,806 Epoch[46] Batch [620]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.087266,	
2017-06-24 20:22:43,284 Epoch[46] Batch [630]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087402,	
2017-06-24 20:22:51,509 Epoch[46] Batch [640]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.087403,	
2017-06-24 20:23:00,315 Epoch[46] Batch [650]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087460,	
2017-06-24 20:23:08,913 Epoch[46] Batch [660]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.087572,	
2017-06-24 20:23:16,984 Epoch[46] Batch [670]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.087537,	
2017-06-24 20:23:25,346 Epoch[46] Batch [680]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087535,	
2017-06-24 20:23:33,838 Epoch[46] Batch [690]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087641,	
2017-06-24 20:23:42,643 Epoch[46] Batch [700]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087610,	
2017-06-24 20:23:50,771 Epoch[46] Batch [710]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.087560,	
2017-06-24 20:23:59,162 Epoch[46] Batch [720]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.087505,	
2017-06-24 20:24:07,615 Epoch[46] Batch [730]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087500,	
2017-06-24 20:24:15,006 Epoch[46] Batch [740]	Speed: 10.82 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-24 20:24:16,673 Epoch[46] Train-FCNLogLoss=0.087440
2017-06-24 20:24:16,673 Epoch[46] Time cost=672.319
2017-06-24 20:24:19,326 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0047.params"
2017-06-24 20:24:22,800 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0047.states"
2017-06-24 20:24:32,088 Epoch[47] Batch [10]	Speed: 10.03 samples/sec	Train-FCNLogLoss=0.089680,	
2017-06-24 20:24:40,044 Epoch[47] Batch [20]	Speed: 10.06 samples/sec	Train-FCNLogLoss=0.089667,	
2017-06-24 20:24:48,196 Epoch[47] Batch [30]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.088216,	
2017-06-24 20:24:55,923 Epoch[47] Batch [40]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.088646,	
2017-06-24 20:25:04,506 Epoch[47] Batch [50]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.088378,	
2017-06-24 20:25:12,694 Epoch[47] Batch [60]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.088525,	
2017-06-24 20:25:20,953 Epoch[47] Batch [70]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.089307,	
2017-06-24 20:25:29,112 Epoch[47] Batch [80]	Speed: 9.81 samples/sec	Train-FCNLogLoss=0.089633,	
2017-06-24 20:25:37,596 Epoch[47] Batch [90]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.090715,	
2017-06-24 20:25:45,994 Epoch[47] Batch [100]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.090659,	
2017-06-24 20:25:54,552 Epoch[47] Batch [110]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.089788,	
2017-06-24 20:26:03,341 Epoch[47] Batch [120]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.090004,	
2017-06-24 20:26:12,202 Epoch[47] Batch [130]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.089133,	
2017-06-24 20:26:20,480 Epoch[47] Batch [140]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.088794,	
2017-06-24 20:26:28,546 Epoch[47] Batch [150]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.088380,	
2017-06-24 20:26:37,318 Epoch[47] Batch [160]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088233,	
2017-06-24 20:26:46,233 Epoch[47] Batch [170]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.088121,	
2017-06-24 20:26:54,437 Epoch[47] Batch [180]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.088118,	
2017-06-24 20:27:02,946 Epoch[47] Batch [190]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.088287,	
2017-06-24 20:27:11,849 Epoch[47] Batch [200]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.088014,	
2017-06-24 20:27:20,690 Epoch[47] Batch [210]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.088064,	
2017-06-24 20:27:29,128 Epoch[47] Batch [220]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.087878,	
2017-06-24 20:27:37,251 Epoch[47] Batch [230]	Speed: 9.85 samples/sec	Train-FCNLogLoss=0.087538,	
2017-06-24 20:27:44,967 Epoch[47] Batch [240]	Speed: 10.37 samples/sec	Train-FCNLogLoss=0.087538,	
2017-06-24 20:27:53,000 Epoch[47] Batch [250]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.087596,	
2017-06-24 20:28:01,320 Epoch[47] Batch [260]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.087603,	
2017-06-24 20:28:09,672 Epoch[47] Batch [270]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.087714,	
2017-06-24 20:28:17,405 Epoch[47] Batch [280]	Speed: 10.35 samples/sec	Train-FCNLogLoss=0.087724,	
2017-06-24 20:28:25,576 Epoch[47] Batch [290]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087816,	
2017-06-24 20:28:33,740 Epoch[47] Batch [300]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.087719,	
2017-06-24 20:28:41,877 Epoch[47] Batch [310]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.087810,	
2017-06-24 20:28:50,324 Epoch[47] Batch [320]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.087906,	
2017-06-24 20:28:58,796 Epoch[47] Batch [330]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087731,	
2017-06-24 20:29:07,185 Epoch[47] Batch [340]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.087827,	
2017-06-24 20:29:15,394 Epoch[47] Batch [350]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.087948,	
2017-06-24 20:29:23,129 Epoch[47] Batch [360]	Speed: 10.34 samples/sec	Train-FCNLogLoss=0.088008,	
2017-06-24 20:29:31,204 Epoch[47] Batch [370]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.088013,	
2017-06-24 20:29:40,023 Epoch[47] Batch [380]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087987,	
2017-06-24 20:29:48,491 Epoch[47] Batch [390]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.088168,	
2017-06-24 20:29:56,753 Epoch[47] Batch [400]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087991,	
2017-06-24 20:30:04,865 Epoch[47] Batch [410]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.087865,	
2017-06-24 20:30:13,289 Epoch[47] Batch [420]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.087806,	
2017-06-24 20:30:20,845 Epoch[47] Batch [430]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.087779,	
2017-06-24 20:30:28,793 Epoch[47] Batch [440]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.087825,	
2017-06-24 20:30:36,786 Epoch[47] Batch [450]	Speed: 10.01 samples/sec	Train-FCNLogLoss=0.087929,	
2017-06-24 20:30:44,820 Epoch[47] Batch [460]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.087905,	
2017-06-24 20:30:53,612 Epoch[47] Batch [470]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087795,	
2017-06-24 20:31:01,466 Epoch[47] Batch [480]	Speed: 10.19 samples/sec	Train-FCNLogLoss=0.087858,	
2017-06-24 20:31:09,727 Epoch[47] Batch [490]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087770,	
2017-06-24 20:31:18,298 Epoch[47] Batch [500]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087741,	
2017-06-24 20:31:26,924 Epoch[47] Batch [510]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.087611,	
2017-06-24 20:31:35,777 Epoch[47] Batch [520]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087570,	
2017-06-24 20:31:44,546 Epoch[47] Batch [530]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087542,	
2017-06-24 20:31:53,246 Epoch[47] Batch [540]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087592,	
2017-06-24 20:32:01,886 Epoch[47] Batch [550]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087593,	
2017-06-24 20:32:10,004 Epoch[47] Batch [560]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.087618,	
2017-06-24 20:32:18,871 Epoch[47] Batch [570]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087556,	
2017-06-24 20:32:27,696 Epoch[47] Batch [580]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087669,	
2017-06-24 20:32:35,737 Epoch[47] Batch [590]	Speed: 9.95 samples/sec	Train-FCNLogLoss=0.087707,	
2017-06-24 20:32:43,442 Epoch[47] Batch [600]	Speed: 10.38 samples/sec	Train-FCNLogLoss=0.087628,	
2017-06-24 20:32:52,235 Epoch[47] Batch [610]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087524,	
2017-06-24 20:33:00,491 Epoch[47] Batch [620]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.087525,	
2017-06-24 20:33:09,195 Epoch[47] Batch [630]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087532,	
2017-06-24 20:33:17,584 Epoch[47] Batch [640]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-24 20:33:26,582 Epoch[47] Batch [650]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087591,	
2017-06-24 20:33:35,208 Epoch[47] Batch [660]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087597,	
2017-06-24 20:33:42,933 Epoch[47] Batch [670]	Speed: 10.36 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-24 20:33:51,819 Epoch[47] Batch [680]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087502,	
2017-06-24 20:34:00,307 Epoch[47] Batch [690]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087414,	
2017-06-24 20:34:08,668 Epoch[47] Batch [700]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087566,	
2017-06-24 20:34:17,073 Epoch[47] Batch [710]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087519,	
2017-06-24 20:34:25,803 Epoch[47] Batch [720]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087531,	
2017-06-24 20:34:34,766 Epoch[47] Batch [730]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087483,	
2017-06-24 20:34:42,954 Epoch[47] Batch [740]	Speed: 9.77 samples/sec	Train-FCNLogLoss=0.087468,	
2017-06-24 20:34:44,705 Epoch[47] Train-FCNLogLoss=0.087511
2017-06-24 20:34:44,705 Epoch[47] Time cost=621.905
2017-06-24 20:34:47,208 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0048.params"
2017-06-24 20:34:50,972 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0048.states"
2017-06-24 20:35:01,608 Epoch[48] Batch [10]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087130,	
2017-06-24 20:35:10,286 Epoch[48] Batch [20]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.088027,	
2017-06-24 20:35:18,970 Epoch[48] Batch [30]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.087134,	
2017-06-24 20:35:27,965 Epoch[48] Batch [40]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.088035,	
2017-06-24 20:35:36,616 Epoch[48] Batch [50]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087582,	
2017-06-24 20:35:45,015 Epoch[48] Batch [60]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.087019,	
2017-06-24 20:35:53,430 Epoch[48] Batch [70]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.086657,	
2017-06-24 20:36:02,365 Epoch[48] Batch [80]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.085751,	
2017-06-24 20:36:10,967 Epoch[48] Batch [90]	Speed: 9.30 samples/sec	Train-FCNLogLoss=0.085395,	
2017-06-24 20:36:19,506 Epoch[48] Batch [100]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.085473,	
2017-06-24 20:36:27,965 Epoch[48] Batch [110]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.085319,	
2017-06-24 20:36:36,105 Epoch[48] Batch [120]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.086629,	
2017-06-24 20:36:44,440 Epoch[48] Batch [130]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.086614,	
2017-06-24 20:36:52,984 Epoch[48] Batch [140]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087146,	
2017-06-24 20:37:02,122 Epoch[48] Batch [150]	Speed: 8.76 samples/sec	Train-FCNLogLoss=0.087307,	
2017-06-24 20:37:10,803 Epoch[48] Batch [160]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087764,	
2017-06-24 20:37:19,502 Epoch[48] Batch [170]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087290,	
2017-06-24 20:37:28,376 Epoch[48] Batch [180]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087371,	
2017-06-24 20:37:37,162 Epoch[48] Batch [190]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087449,	
2017-06-24 20:37:46,039 Epoch[48] Batch [200]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.087686,	
2017-06-24 20:37:55,417 Epoch[48] Batch [210]	Speed: 8.53 samples/sec	Train-FCNLogLoss=0.087856,	
2017-06-24 20:38:04,181 Epoch[48] Batch [220]	Speed: 9.13 samples/sec	Train-FCNLogLoss=0.087830,	
2017-06-24 20:38:13,063 Epoch[48] Batch [230]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.087818,	
2017-06-24 20:38:21,429 Epoch[48] Batch [240]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.087713,	
2017-06-24 20:38:29,455 Epoch[48] Batch [250]	Speed: 9.97 samples/sec	Train-FCNLogLoss=0.087598,	
2017-06-24 20:38:37,635 Epoch[48] Batch [260]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.087692,	
2017-06-24 20:38:45,545 Epoch[48] Batch [270]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.087784,	
2017-06-24 20:38:54,079 Epoch[48] Batch [280]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.087523,	
2017-06-24 20:39:02,486 Epoch[48] Batch [290]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087592,	
2017-06-24 20:39:10,305 Epoch[48] Batch [300]	Speed: 10.23 samples/sec	Train-FCNLogLoss=0.087589,	
2017-06-24 20:39:18,808 Epoch[48] Batch [310]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.087542,	
2017-06-24 20:39:27,653 Epoch[48] Batch [320]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.087656,	
2017-06-24 20:39:36,002 Epoch[48] Batch [330]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.087548,	
2017-06-24 20:39:44,266 Epoch[48] Batch [340]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087350,	
2017-06-24 20:39:52,364 Epoch[48] Batch [350]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.087359,	
2017-06-24 20:40:00,767 Epoch[48] Batch [360]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087032,	
2017-06-24 20:40:09,065 Epoch[48] Batch [370]	Speed: 9.64 samples/sec	Train-FCNLogLoss=0.087042,	
2017-06-24 20:40:17,583 Epoch[48] Batch [380]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087121,	
2017-06-24 20:40:25,809 Epoch[48] Batch [390]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.087073,	
2017-06-24 20:40:34,296 Epoch[48] Batch [400]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087046,	
2017-06-24 20:40:42,506 Epoch[48] Batch [410]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.086973,	
2017-06-24 20:40:51,165 Epoch[48] Batch [420]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087000,	
2017-06-24 20:40:59,485 Epoch[48] Batch [430]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.086903,	
2017-06-24 20:41:07,750 Epoch[48] Batch [440]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.086965,	
2017-06-24 20:41:16,106 Epoch[48] Batch [450]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.086861,	
2017-06-24 20:41:24,494 Epoch[48] Batch [460]	Speed: 9.54 samples/sec	Train-FCNLogLoss=0.086946,	
2017-06-24 20:41:33,129 Epoch[48] Batch [470]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087016,	
2017-06-24 20:41:41,724 Epoch[48] Batch [480]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.086989,	
2017-06-24 20:41:50,340 Epoch[48] Batch [490]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087048,	
2017-06-24 20:41:58,135 Epoch[48] Batch [500]	Speed: 10.26 samples/sec	Train-FCNLogLoss=0.087134,	
2017-06-24 20:42:06,419 Epoch[48] Batch [510]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.087117,	
2017-06-24 20:42:14,265 Epoch[48] Batch [520]	Speed: 10.20 samples/sec	Train-FCNLogLoss=0.087223,	
2017-06-24 20:42:22,926 Epoch[48] Batch [530]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087292,	
2017-06-24 20:42:30,836 Epoch[48] Batch [540]	Speed: 10.11 samples/sec	Train-FCNLogLoss=0.087295,	
2017-06-24 20:42:38,390 Epoch[48] Batch [550]	Speed: 10.59 samples/sec	Train-FCNLogLoss=0.087258,	
2017-06-24 20:42:46,631 Epoch[48] Batch [560]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.087432,	
2017-06-24 20:42:54,800 Epoch[48] Batch [570]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087375,	
2017-06-24 20:43:02,862 Epoch[48] Batch [580]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.087372,	
2017-06-24 20:43:11,402 Epoch[48] Batch [590]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.087444,	
2017-06-24 20:43:19,805 Epoch[48] Batch [600]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087312,	
2017-06-24 20:43:28,380 Epoch[48] Batch [610]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087400,	
2017-06-24 20:43:37,048 Epoch[48] Batch [620]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087360,	
2017-06-24 20:43:45,226 Epoch[48] Batch [630]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.087355,	
2017-06-24 20:43:53,588 Epoch[48] Batch [640]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087340,	
2017-06-24 20:44:02,661 Epoch[48] Batch [650]	Speed: 8.82 samples/sec	Train-FCNLogLoss=0.087422,	
2017-06-24 20:44:11,299 Epoch[48] Batch [660]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087443,	
2017-06-24 20:44:19,705 Epoch[48] Batch [670]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087451,	
2017-06-24 20:44:28,222 Epoch[48] Batch [680]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087495,	
2017-06-24 20:44:37,066 Epoch[48] Batch [690]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.087410,	
2017-06-24 20:44:45,531 Epoch[48] Batch [700]	Speed: 9.45 samples/sec	Train-FCNLogLoss=0.087363,	
2017-06-24 20:44:54,369 Epoch[48] Batch [710]	Speed: 9.05 samples/sec	Train-FCNLogLoss=0.087296,	
2017-06-24 20:45:03,167 Epoch[48] Batch [720]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087393,	
2017-06-24 20:45:11,526 Epoch[48] Batch [730]	Speed: 9.57 samples/sec	Train-FCNLogLoss=0.087439,	
2017-06-24 20:45:19,751 Epoch[48] Batch [740]	Speed: 9.73 samples/sec	Train-FCNLogLoss=0.087408,	
2017-06-24 20:45:21,387 Epoch[48] Train-FCNLogLoss=0.087421
2017-06-24 20:45:21,387 Epoch[48] Time cost=630.415
2017-06-24 20:45:24,145 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0049.params"
2017-06-24 20:45:27,981 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0049.states"
2017-06-24 20:45:37,689 Epoch[49] Batch [10]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.085139,	
2017-06-24 20:45:45,817 Epoch[49] Batch [20]	Speed: 9.84 samples/sec	Train-FCNLogLoss=0.086562,	
2017-06-24 20:45:54,409 Epoch[49] Batch [30]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087592,	
2017-06-24 20:46:02,513 Epoch[49] Batch [40]	Speed: 9.87 samples/sec	Train-FCNLogLoss=0.089165,	
2017-06-24 20:46:11,065 Epoch[49] Batch [50]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.088858,	
2017-06-24 20:46:19,951 Epoch[49] Batch [60]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.088647,	
2017-06-24 20:46:28,881 Epoch[49] Batch [70]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.088838,	
2017-06-24 20:46:37,342 Epoch[49] Batch [80]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.088222,	
2017-06-24 20:46:46,367 Epoch[49] Batch [90]	Speed: 8.86 samples/sec	Train-FCNLogLoss=0.088373,	
2017-06-24 20:46:55,122 Epoch[49] Batch [100]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.088584,	
2017-06-24 20:47:03,291 Epoch[49] Batch [110]	Speed: 9.79 samples/sec	Train-FCNLogLoss=0.087917,	
2017-06-24 20:47:11,531 Epoch[49] Batch [120]	Speed: 9.71 samples/sec	Train-FCNLogLoss=0.087573,	
2017-06-24 20:47:20,030 Epoch[49] Batch [130]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.087694,	
2017-06-24 20:47:28,425 Epoch[49] Batch [140]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.087508,	
2017-06-24 20:47:36,349 Epoch[49] Batch [150]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.087471,	
2017-06-24 20:47:44,911 Epoch[49] Batch [160]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087489,	
2017-06-24 20:47:53,367 Epoch[49] Batch [170]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087269,	
2017-06-24 20:48:02,001 Epoch[49] Batch [180]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087563,	
2017-06-24 20:48:10,727 Epoch[49] Batch [190]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087429,	
2017-06-24 20:48:18,924 Epoch[49] Batch [200]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.087199,	
2017-06-24 20:48:27,215 Epoch[49] Batch [210]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.087297,	
2017-06-24 20:48:36,070 Epoch[49] Batch [220]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.087239,	
2017-06-24 20:48:44,512 Epoch[49] Batch [230]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.087167,	
2017-06-24 20:48:52,858 Epoch[49] Batch [240]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.087061,	
2017-06-24 20:49:00,956 Epoch[49] Batch [250]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.086979,	
2017-06-24 20:49:09,363 Epoch[49] Batch [260]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087146,	
2017-06-24 20:49:18,087 Epoch[49] Batch [270]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087232,	
2017-06-24 20:49:26,973 Epoch[49] Batch [280]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087191,	
2017-06-24 20:49:35,008 Epoch[49] Batch [290]	Speed: 9.96 samples/sec	Train-FCNLogLoss=0.087311,	
2017-06-24 20:49:43,071 Epoch[49] Batch [300]	Speed: 9.92 samples/sec	Train-FCNLogLoss=0.087346,	
2017-06-24 20:49:51,967 Epoch[49] Batch [310]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087257,	
2017-06-24 20:50:00,250 Epoch[49] Batch [320]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.087251,	
2017-06-24 20:50:08,527 Epoch[49] Batch [330]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.087134,	
2017-06-24 20:50:17,121 Epoch[49] Batch [340]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087031,	
2017-06-24 20:50:25,838 Epoch[49] Batch [350]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.087114,	
2017-06-24 20:50:34,116 Epoch[49] Batch [360]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.087230,	
2017-06-24 20:50:42,516 Epoch[49] Batch [370]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.087351,	
2017-06-24 20:50:51,258 Epoch[49] Batch [380]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087360,	
2017-06-24 20:50:59,808 Epoch[49] Batch [390]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087425,	
2017-06-24 20:51:08,223 Epoch[49] Batch [400]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.087500,	
2017-06-24 20:51:16,787 Epoch[49] Batch [410]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087557,	
2017-06-24 20:51:25,787 Epoch[49] Batch [420]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087576,	
2017-06-24 20:51:34,276 Epoch[49] Batch [430]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087528,	
2017-06-24 20:51:42,958 Epoch[49] Batch [440]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087537,	
2017-06-24 20:51:51,288 Epoch[49] Batch [450]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.087716,	
2017-06-24 20:51:59,874 Epoch[49] Batch [460]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.087708,	
2017-06-24 20:52:08,453 Epoch[49] Batch [470]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087743,	
2017-06-24 20:52:17,004 Epoch[49] Batch [480]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087690,	
2017-06-24 20:52:25,265 Epoch[49] Batch [490]	Speed: 9.68 samples/sec	Train-FCNLogLoss=0.087763,	
2017-06-24 20:52:33,859 Epoch[49] Batch [500]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087785,	
2017-06-24 20:52:41,961 Epoch[49] Batch [510]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.087764,	
2017-06-24 20:52:50,216 Epoch[49] Batch [520]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.087667,	
2017-06-24 20:52:58,660 Epoch[49] Batch [530]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.087641,	
2017-06-24 20:53:07,059 Epoch[49] Batch [540]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.087647,	
2017-06-24 20:53:15,668 Epoch[49] Batch [550]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087683,	
2017-06-24 20:53:24,303 Epoch[49] Batch [560]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087665,	
2017-06-24 20:53:32,718 Epoch[49] Batch [570]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.087678,	
2017-06-24 20:53:41,055 Epoch[49] Batch [580]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.087593,	
2017-06-24 20:53:49,563 Epoch[49] Batch [590]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.087525,	
2017-06-24 20:53:57,988 Epoch[49] Batch [600]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.087552,	
2017-06-24 20:54:06,578 Epoch[49] Batch [610]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087527,	
2017-06-24 20:54:15,019 Epoch[49] Batch [620]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.087654,	
2017-06-24 20:54:22,769 Epoch[49] Batch [630]	Speed: 10.32 samples/sec	Train-FCNLogLoss=0.087682,	
2017-06-24 20:54:31,117 Epoch[49] Batch [640]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.087611,	
2017-06-24 20:54:39,450 Epoch[49] Batch [650]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.087652,	
2017-06-24 20:54:47,545 Epoch[49] Batch [660]	Speed: 9.88 samples/sec	Train-FCNLogLoss=0.087654,	
2017-06-24 20:54:55,877 Epoch[49] Batch [670]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.087667,	
2017-06-24 20:55:03,797 Epoch[49] Batch [680]	Speed: 10.10 samples/sec	Train-FCNLogLoss=0.087664,	
2017-06-24 20:55:12,052 Epoch[49] Batch [690]	Speed: 9.69 samples/sec	Train-FCNLogLoss=0.087672,	
2017-06-24 20:55:20,054 Epoch[49] Batch [700]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.087746,	
2017-06-24 20:55:28,556 Epoch[49] Batch [710]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.087700,	
2017-06-24 20:55:37,012 Epoch[49] Batch [720]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087618,	
2017-06-24 20:55:45,330 Epoch[49] Batch [730]	Speed: 9.62 samples/sec	Train-FCNLogLoss=0.087584,	
2017-06-24 20:55:54,158 Epoch[49] Batch [740]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087629,	
2017-06-24 20:55:55,662 Epoch[49] Train-FCNLogLoss=0.087618
2017-06-24 20:55:55,662 Epoch[49] Time cost=627.680
2017-06-24 20:55:58,363 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0050.params"
2017-06-24 20:56:01,897 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0050.states"
2017-06-24 20:56:11,878 Epoch[50] Batch [10]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.089179,	
2017-06-24 20:56:20,542 Epoch[50] Batch [20]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.093891,	
2017-06-24 20:56:29,113 Epoch[50] Batch [30]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.091211,	
2017-06-24 20:56:37,636 Epoch[50] Batch [40]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.089568,	
2017-06-24 20:56:46,258 Epoch[50] Batch [50]	Speed: 9.28 samples/sec	Train-FCNLogLoss=0.089448,	
2017-06-24 20:56:54,502 Epoch[50] Batch [60]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.087573,	
2017-06-24 20:57:03,311 Epoch[50] Batch [70]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087378,	
2017-06-24 20:57:11,516 Epoch[50] Batch [80]	Speed: 9.75 samples/sec	Train-FCNLogLoss=0.087269,	
2017-06-24 20:57:20,169 Epoch[50] Batch [90]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087693,	
2017-06-24 20:57:28,414 Epoch[50] Batch [100]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.087451,	
2017-06-24 20:57:37,148 Epoch[50] Batch [110]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087165,	
2017-06-24 20:57:45,603 Epoch[50] Batch [120]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087443,	
2017-06-24 20:57:54,384 Epoch[50] Batch [130]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087418,	
2017-06-24 20:58:02,757 Epoch[50] Batch [140]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-24 20:58:11,322 Epoch[50] Batch [150]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087340,	
2017-06-24 20:58:19,871 Epoch[50] Batch [160]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087028,	
2017-06-24 20:58:28,389 Epoch[50] Batch [170]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086884,	
2017-06-24 20:58:36,885 Epoch[50] Batch [180]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.086889,	
2017-06-24 20:58:45,311 Epoch[50] Batch [190]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.086983,	
2017-06-24 20:58:53,899 Epoch[50] Batch [200]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.086734,	
2017-06-24 20:59:02,176 Epoch[50] Batch [210]	Speed: 9.67 samples/sec	Train-FCNLogLoss=0.086784,	
2017-06-24 20:59:10,567 Epoch[50] Batch [220]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.086533,	
2017-06-24 20:59:19,140 Epoch[50] Batch [230]	Speed: 9.33 samples/sec	Train-FCNLogLoss=0.087112,	
2017-06-24 20:59:31,755 Epoch[50] Batch [240]	Speed: 6.34 samples/sec	Train-FCNLogLoss=0.087180,	
2017-06-24 20:59:48,577 Epoch[50] Batch [250]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.087106,	
2017-06-24 21:00:05,775 Epoch[50] Batch [260]	Speed: 4.65 samples/sec	Train-FCNLogLoss=0.087263,	
2017-06-24 21:00:21,422 Epoch[50] Batch [270]	Speed: 5.11 samples/sec	Train-FCNLogLoss=0.087417,	
2017-06-24 21:00:37,408 Epoch[50] Batch [280]	Speed: 5.00 samples/sec	Train-FCNLogLoss=0.087419,	
2017-06-24 21:00:53,012 Epoch[50] Batch [290]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087302,	
2017-06-24 21:01:08,602 Epoch[50] Batch [300]	Speed: 5.13 samples/sec	Train-FCNLogLoss=0.087525,	
2017-06-24 21:01:24,636 Epoch[50] Batch [310]	Speed: 4.99 samples/sec	Train-FCNLogLoss=0.087636,	
2017-06-24 21:01:41,438 Epoch[50] Batch [320]	Speed: 4.76 samples/sec	Train-FCNLogLoss=0.087666,	
2017-06-24 21:01:56,099 Epoch[50] Batch [330]	Speed: 5.46 samples/sec	Train-FCNLogLoss=0.087605,	
2017-06-24 21:02:10,860 Epoch[50] Batch [340]	Speed: 5.42 samples/sec	Train-FCNLogLoss=0.087625,	
2017-06-24 21:02:24,629 Epoch[50] Batch [350]	Speed: 5.81 samples/sec	Train-FCNLogLoss=0.087613,	
2017-06-24 21:02:36,396 Epoch[50] Batch [360]	Speed: 6.80 samples/sec	Train-FCNLogLoss=0.087442,	
2017-06-24 21:02:47,202 Epoch[50] Batch [370]	Speed: 7.40 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-24 21:02:56,491 Epoch[50] Batch [380]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.087394,	
2017-06-24 21:03:05,734 Epoch[50] Batch [390]	Speed: 8.66 samples/sec	Train-FCNLogLoss=0.087432,	
2017-06-24 21:03:14,649 Epoch[50] Batch [400]	Speed: 8.97 samples/sec	Train-FCNLogLoss=0.087382,	
2017-06-24 21:03:23,839 Epoch[50] Batch [410]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087479,	
2017-06-24 21:03:33,234 Epoch[50] Batch [420]	Speed: 8.52 samples/sec	Train-FCNLogLoss=0.087487,	
2017-06-24 21:03:42,218 Epoch[50] Batch [430]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087580,	
2017-06-24 21:03:51,546 Epoch[50] Batch [440]	Speed: 8.58 samples/sec	Train-FCNLogLoss=0.087636,	
2017-06-24 21:04:00,078 Epoch[50] Batch [450]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.087604,	
2017-06-24 21:04:08,793 Epoch[50] Batch [460]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.087546,	
2017-06-24 21:04:17,275 Epoch[50] Batch [470]	Speed: 9.43 samples/sec	Train-FCNLogLoss=0.087525,	
2017-06-24 21:04:25,613 Epoch[50] Batch [480]	Speed: 9.60 samples/sec	Train-FCNLogLoss=0.087385,	
2017-06-24 21:04:34,421 Epoch[50] Batch [490]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087393,	
2017-06-24 21:04:43,422 Epoch[50] Batch [500]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087530,	
2017-06-24 21:04:52,875 Epoch[50] Batch [510]	Speed: 8.46 samples/sec	Train-FCNLogLoss=0.087569,	
2017-06-24 21:05:01,729 Epoch[50] Batch [520]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087578,	
2017-06-24 21:05:10,358 Epoch[50] Batch [530]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.087525,	
2017-06-24 21:05:19,151 Epoch[50] Batch [540]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087506,	
2017-06-24 21:05:27,715 Epoch[50] Batch [550]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087520,	
2017-06-24 21:05:36,737 Epoch[50] Batch [560]	Speed: 8.87 samples/sec	Train-FCNLogLoss=0.087487,	
2017-06-24 21:05:45,392 Epoch[50] Batch [570]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087417,	
2017-06-24 21:05:54,066 Epoch[50] Batch [580]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.087378,	
2017-06-24 21:06:02,521 Epoch[50] Batch [590]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087436,	
2017-06-24 21:06:10,956 Epoch[50] Batch [600]	Speed: 9.48 samples/sec	Train-FCNLogLoss=0.087380,	
2017-06-24 21:06:19,430 Epoch[50] Batch [610]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087361,	
2017-06-24 21:06:27,807 Epoch[50] Batch [620]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.087351,	
2017-06-24 21:06:36,673 Epoch[50] Batch [630]	Speed: 9.02 samples/sec	Train-FCNLogLoss=0.087253,	
2017-06-24 21:06:45,873 Epoch[50] Batch [640]	Speed: 8.70 samples/sec	Train-FCNLogLoss=0.087321,	
2017-06-24 21:06:54,727 Epoch[50] Batch [650]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.087365,	
2017-06-24 21:07:03,515 Epoch[50] Batch [660]	Speed: 9.10 samples/sec	Train-FCNLogLoss=0.087280,	
2017-06-24 21:07:11,766 Epoch[50] Batch [670]	Speed: 9.70 samples/sec	Train-FCNLogLoss=0.087176,	
2017-06-24 21:07:20,545 Epoch[50] Batch [680]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087132,	
2017-06-24 21:07:29,471 Epoch[50] Batch [690]	Speed: 8.96 samples/sec	Train-FCNLogLoss=0.087124,	
2017-06-24 21:07:38,159 Epoch[50] Batch [700]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.087167,	
2017-06-24 21:07:46,729 Epoch[50] Batch [710]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087312,	
2017-06-24 21:07:55,507 Epoch[50] Batch [720]	Speed: 9.11 samples/sec	Train-FCNLogLoss=0.087322,	
2017-06-24 21:08:03,829 Epoch[50] Batch [730]	Speed: 9.61 samples/sec	Train-FCNLogLoss=0.087341,	
2017-06-24 21:08:13,051 Epoch[50] Batch [740]	Speed: 8.67 samples/sec	Train-FCNLogLoss=0.087407,	
2017-06-24 21:08:14,643 Epoch[50] Train-FCNLogLoss=0.087377
2017-06-24 21:08:14,643 Epoch[50] Time cost=732.745
2017-06-24 21:08:17,544 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0051.params"
2017-06-24 21:08:21,367 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0051.states"
2017-06-24 21:08:31,372 Epoch[51] Batch [10]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.088028,	
2017-06-24 21:08:40,052 Epoch[51] Batch [20]	Speed: 9.22 samples/sec	Train-FCNLogLoss=0.089443,	
2017-06-24 21:08:49,094 Epoch[51] Batch [30]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087907,	
2017-06-24 21:08:57,685 Epoch[51] Batch [40]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087168,	
2017-06-24 21:09:06,426 Epoch[51] Batch [50]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.086497,	
2017-06-24 21:09:15,362 Epoch[51] Batch [60]	Speed: 8.95 samples/sec	Train-FCNLogLoss=0.086205,	
2017-06-24 21:09:24,468 Epoch[51] Batch [70]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.086931,	
2017-06-24 21:09:33,274 Epoch[51] Batch [80]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.086892,	
2017-06-24 21:09:42,005 Epoch[51] Batch [90]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087453,	
2017-06-24 21:09:50,404 Epoch[51] Batch [100]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.088289,	
2017-06-24 21:09:58,831 Epoch[51] Batch [110]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.088716,	
2017-06-24 21:10:07,240 Epoch[51] Batch [120]	Speed: 9.51 samples/sec	Train-FCNLogLoss=0.088471,	
2017-06-24 21:10:15,606 Epoch[51] Batch [130]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.088142,	
2017-06-24 21:10:24,706 Epoch[51] Batch [140]	Speed: 8.79 samples/sec	Train-FCNLogLoss=0.088234,	
2017-06-24 21:10:33,140 Epoch[51] Batch [150]	Speed: 9.49 samples/sec	Train-FCNLogLoss=0.088141,	
2017-06-24 21:10:41,488 Epoch[51] Batch [160]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.088377,	
2017-06-24 21:10:49,627 Epoch[51] Batch [170]	Speed: 9.83 samples/sec	Train-FCNLogLoss=0.088142,	
2017-06-24 21:10:58,194 Epoch[51] Batch [180]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.088055,	
2017-06-24 21:11:07,046 Epoch[51] Batch [190]	Speed: 9.04 samples/sec	Train-FCNLogLoss=0.088092,	
2017-06-24 21:11:15,676 Epoch[51] Batch [200]	Speed: 9.27 samples/sec	Train-FCNLogLoss=0.088099,	
2017-06-24 21:11:23,660 Epoch[51] Batch [210]	Speed: 10.02 samples/sec	Train-FCNLogLoss=0.087892,	
2017-06-24 21:11:32,228 Epoch[51] Batch [220]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087891,	
2017-06-24 21:11:40,583 Epoch[51] Batch [230]	Speed: 9.58 samples/sec	Train-FCNLogLoss=0.087691,	
2017-06-24 21:11:48,818 Epoch[51] Batch [240]	Speed: 9.72 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-24 21:11:57,779 Epoch[51] Batch [250]	Speed: 8.93 samples/sec	Train-FCNLogLoss=0.087972,	
2017-06-24 21:12:06,823 Epoch[51] Batch [260]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.088115,	
2017-06-24 21:12:15,945 Epoch[51] Batch [270]	Speed: 8.77 samples/sec	Train-FCNLogLoss=0.088209,	
2017-06-24 21:12:24,896 Epoch[51] Batch [280]	Speed: 8.94 samples/sec	Train-FCNLogLoss=0.088373,	
2017-06-24 21:12:33,418 Epoch[51] Batch [290]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.088502,	
2017-06-24 21:12:42,076 Epoch[51] Batch [300]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.088157,	
2017-06-24 21:12:50,953 Epoch[51] Batch [310]	Speed: 9.01 samples/sec	Train-FCNLogLoss=0.087941,	
2017-06-24 21:12:59,940 Epoch[51] Batch [320]	Speed: 8.90 samples/sec	Train-FCNLogLoss=0.087899,	
2017-06-24 21:13:08,665 Epoch[51] Batch [330]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087788,	
2017-06-24 21:13:17,462 Epoch[51] Batch [340]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087720,	
2017-06-24 21:13:26,796 Epoch[51] Batch [350]	Speed: 8.57 samples/sec	Train-FCNLogLoss=0.087863,	
2017-06-24 21:13:35,327 Epoch[51] Batch [360]	Speed: 9.38 samples/sec	Train-FCNLogLoss=0.087845,	
2017-06-24 21:13:44,044 Epoch[51] Batch [370]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.087942,	
2017-06-24 21:13:52,871 Epoch[51] Batch [380]	Speed: 9.06 samples/sec	Train-FCNLogLoss=0.087871,	
2017-06-24 21:14:01,425 Epoch[51] Batch [390]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.087709,	
2017-06-24 21:14:09,947 Epoch[51] Batch [400]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087787,	
2017-06-24 21:14:19,319 Epoch[51] Batch [410]	Speed: 8.54 samples/sec	Train-FCNLogLoss=0.087832,	
2017-06-24 21:14:28,381 Epoch[51] Batch [420]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.087795,	
2017-06-24 21:14:37,640 Epoch[51] Batch [430]	Speed: 8.64 samples/sec	Train-FCNLogLoss=0.087654,	
2017-06-24 21:14:46,393 Epoch[51] Batch [440]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.087682,	
2017-06-24 21:14:55,565 Epoch[51] Batch [450]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.087572,	
2017-06-24 21:15:04,535 Epoch[51] Batch [460]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087467,	
2017-06-24 21:15:13,580 Epoch[51] Batch [470]	Speed: 8.85 samples/sec	Train-FCNLogLoss=0.087377,	
2017-06-24 21:15:22,242 Epoch[51] Batch [480]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087425,	
2017-06-24 21:15:30,809 Epoch[51] Batch [490]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087413,	
2017-06-24 21:15:38,753 Epoch[51] Batch [500]	Speed: 10.07 samples/sec	Train-FCNLogLoss=0.087334,	
2017-06-24 21:15:47,206 Epoch[51] Batch [510]	Speed: 9.46 samples/sec	Train-FCNLogLoss=0.087276,	
2017-06-24 21:15:55,943 Epoch[51] Batch [520]	Speed: 9.16 samples/sec	Train-FCNLogLoss=0.087209,	
2017-06-24 21:16:05,117 Epoch[51] Batch [530]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.087154,	
2017-06-24 21:16:13,979 Epoch[51] Batch [540]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.087169,	
2017-06-24 21:16:22,263 Epoch[51] Batch [550]	Speed: 9.66 samples/sec	Train-FCNLogLoss=0.087066,	
2017-06-24 21:16:30,443 Epoch[51] Batch [560]	Speed: 9.78 samples/sec	Train-FCNLogLoss=0.087008,	
2017-06-24 21:16:38,733 Epoch[51] Batch [570]	Speed: 9.65 samples/sec	Train-FCNLogLoss=0.087059,	
2017-06-24 21:16:48,026 Epoch[51] Batch [580]	Speed: 8.61 samples/sec	Train-FCNLogLoss=0.086916,	
2017-06-24 21:16:56,618 Epoch[51] Batch [590]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.086881,	
2017-06-24 21:17:05,214 Epoch[51] Batch [600]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.086785,	
2017-06-24 21:17:13,915 Epoch[51] Batch [610]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.086751,	
2017-06-24 21:17:22,601 Epoch[51] Batch [620]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.086736,	
2017-06-24 21:17:31,107 Epoch[51] Batch [630]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.086712,	
2017-06-24 21:17:39,415 Epoch[51] Batch [640]	Speed: 9.63 samples/sec	Train-FCNLogLoss=0.086717,	
2017-06-24 21:17:48,104 Epoch[51] Batch [650]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.086814,	
2017-06-24 21:17:57,077 Epoch[51] Batch [660]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.086842,	
2017-06-24 21:18:05,782 Epoch[51] Batch [670]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.086831,	
2017-06-24 21:18:14,327 Epoch[51] Batch [680]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.086746,	
2017-06-24 21:18:23,099 Epoch[51] Batch [690]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.086773,	
2017-06-24 21:18:31,769 Epoch[51] Batch [700]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.086888,	
2017-06-24 21:18:40,477 Epoch[51] Batch [710]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.086894,	
2017-06-24 21:18:48,995 Epoch[51] Batch [720]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.086957,	
2017-06-24 21:18:57,392 Epoch[51] Batch [730]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.086944,	
2017-06-24 21:19:06,277 Epoch[51] Batch [740]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.086909,	
2017-06-24 21:19:07,926 Epoch[51] Train-FCNLogLoss=0.086903
2017-06-24 21:19:07,926 Epoch[51] Time cost=646.559
2017-06-24 21:19:11,135 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0052.params"
2017-06-24 21:19:14,827 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0052.states"
2017-06-24 21:19:25,062 Epoch[52] Batch [10]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.088109,	
2017-06-24 21:19:33,210 Epoch[52] Batch [20]	Speed: 9.82 samples/sec	Train-FCNLogLoss=0.088205,	
2017-06-24 21:19:41,575 Epoch[52] Batch [30]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.087908,	
2017-06-24 21:19:50,048 Epoch[52] Batch [40]	Speed: 9.44 samples/sec	Train-FCNLogLoss=0.087359,	
2017-06-24 21:19:58,541 Epoch[52] Batch [50]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.088179,	
2017-06-24 21:20:06,741 Epoch[52] Batch [60]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.088459,	
2017-06-24 21:20:15,425 Epoch[52] Batch [70]	Speed: 9.21 samples/sec	Train-FCNLogLoss=0.088467,	
2017-06-24 21:20:24,165 Epoch[52] Batch [80]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.088819,	
2017-06-24 21:20:32,918 Epoch[52] Batch [90]	Speed: 9.14 samples/sec	Train-FCNLogLoss=0.088856,	
2017-06-24 21:20:41,559 Epoch[52] Batch [100]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.089213,	
2017-06-24 21:20:50,098 Epoch[52] Batch [110]	Speed: 9.37 samples/sec	Train-FCNLogLoss=0.088985,	
2017-06-24 21:20:58,615 Epoch[52] Batch [120]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.088854,	
2017-06-24 21:21:06,687 Epoch[52] Batch [130]	Speed: 9.91 samples/sec	Train-FCNLogLoss=0.088461,	
2017-06-24 21:21:15,093 Epoch[52] Batch [140]	Speed: 9.52 samples/sec	Train-FCNLogLoss=0.088175,	
2017-06-24 21:21:23,869 Epoch[52] Batch [150]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.088168,	
2017-06-24 21:21:32,315 Epoch[52] Batch [160]	Speed: 9.47 samples/sec	Train-FCNLogLoss=0.087836,	
2017-06-24 21:21:41,200 Epoch[52] Batch [170]	Speed: 9.00 samples/sec	Train-FCNLogLoss=0.087619,	
2017-06-24 21:21:49,410 Epoch[52] Batch [180]	Speed: 9.74 samples/sec	Train-FCNLogLoss=0.087539,	
2017-06-24 21:21:57,956 Epoch[52] Batch [190]	Speed: 9.36 samples/sec	Train-FCNLogLoss=0.087520,	
2017-06-24 21:22:06,729 Epoch[52] Batch [200]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087433,	
2017-06-24 21:22:15,340 Epoch[52] Batch [210]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087397,	
2017-06-24 21:22:23,892 Epoch[52] Batch [220]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.087642,	
2017-06-24 21:22:32,259 Epoch[52] Batch [230]	Speed: 9.56 samples/sec	Train-FCNLogLoss=0.087654,	
2017-06-24 21:22:40,420 Epoch[52] Batch [240]	Speed: 9.80 samples/sec	Train-FCNLogLoss=0.087802,	
2017-06-24 21:22:49,067 Epoch[52] Batch [250]	Speed: 9.25 samples/sec	Train-FCNLogLoss=0.087686,	
2017-06-24 21:22:57,653 Epoch[52] Batch [260]	Speed: 9.32 samples/sec	Train-FCNLogLoss=0.087516,	
2017-06-24 21:23:06,308 Epoch[52] Batch [270]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087317,	
2017-06-24 21:23:14,820 Epoch[52] Batch [280]	Speed: 9.40 samples/sec	Train-FCNLogLoss=0.087524,	
2017-06-24 21:23:23,718 Epoch[52] Batch [290]	Speed: 8.99 samples/sec	Train-FCNLogLoss=0.087451,	
2017-06-24 21:23:32,115 Epoch[52] Batch [300]	Speed: 9.53 samples/sec	Train-FCNLogLoss=0.087588,	
2017-06-24 21:23:40,812 Epoch[52] Batch [310]	Speed: 9.20 samples/sec	Train-FCNLogLoss=0.087577,	
2017-06-24 21:23:48,928 Epoch[52] Batch [320]	Speed: 9.86 samples/sec	Train-FCNLogLoss=0.087533,	
2017-06-24 21:23:57,121 Epoch[52] Batch [330]	Speed: 9.76 samples/sec	Train-FCNLogLoss=0.087625,	
2017-06-24 21:24:05,612 Epoch[52] Batch [340]	Speed: 9.42 samples/sec	Train-FCNLogLoss=0.087605,	
2017-06-24 21:24:13,990 Epoch[52] Batch [350]	Speed: 9.55 samples/sec	Train-FCNLogLoss=0.087559,	
2017-06-24 21:24:22,512 Epoch[52] Batch [360]	Speed: 9.39 samples/sec	Train-FCNLogLoss=0.087623,	
2017-06-24 21:24:31,241 Epoch[52] Batch [370]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087634,	
2017-06-24 21:24:39,243 Epoch[52] Batch [380]	Speed: 10.00 samples/sec	Train-FCNLogLoss=0.087510,	
2017-06-24 21:24:47,915 Epoch[52] Batch [390]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087421,	
2017-06-24 21:24:56,977 Epoch[52] Batch [400]	Speed: 8.83 samples/sec	Train-FCNLogLoss=0.087470,	
2017-06-24 21:25:05,978 Epoch[52] Batch [410]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087544,	
2017-06-24 21:25:14,778 Epoch[52] Batch [420]	Speed: 9.09 samples/sec	Train-FCNLogLoss=0.087555,	
2017-06-24 21:25:23,776 Epoch[52] Batch [430]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087641,	
2017-06-24 21:25:32,524 Epoch[52] Batch [440]	Speed: 9.15 samples/sec	Train-FCNLogLoss=0.087777,	
2017-06-24 21:25:41,292 Epoch[52] Batch [450]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087726,	
2017-06-24 21:25:50,002 Epoch[52] Batch [460]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087830,	
2017-06-24 21:25:58,343 Epoch[52] Batch [470]	Speed: 9.59 samples/sec	Train-FCNLogLoss=0.087748,	
2017-06-24 21:26:07,150 Epoch[52] Batch [480]	Speed: 9.08 samples/sec	Train-FCNLogLoss=0.087687,	
2017-06-24 21:26:16,119 Epoch[52] Batch [490]	Speed: 8.92 samples/sec	Train-FCNLogLoss=0.087788,	
2017-06-24 21:26:24,823 Epoch[52] Batch [500]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087846,	
2017-06-24 21:26:33,643 Epoch[52] Batch [510]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087839,	
2017-06-24 21:26:42,755 Epoch[52] Batch [520]	Speed: 8.78 samples/sec	Train-FCNLogLoss=0.087778,	
2017-06-24 21:26:51,252 Epoch[52] Batch [530]	Speed: 9.41 samples/sec	Train-FCNLogLoss=0.087806,	
2017-06-24 21:26:59,974 Epoch[52] Batch [540]	Speed: 9.17 samples/sec	Train-FCNLogLoss=0.087730,	
2017-06-24 21:27:08,639 Epoch[52] Batch [550]	Speed: 9.23 samples/sec	Train-FCNLogLoss=0.087662,	
2017-06-24 21:27:17,282 Epoch[52] Batch [560]	Speed: 9.26 samples/sec	Train-FCNLogLoss=0.087616,	
2017-06-24 21:27:25,943 Epoch[52] Batch [570]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087550,	
2017-06-24 21:27:34,848 Epoch[52] Batch [580]	Speed: 8.98 samples/sec	Train-FCNLogLoss=0.087512,	
2017-06-24 21:27:43,417 Epoch[52] Batch [590]	Speed: 9.34 samples/sec	Train-FCNLogLoss=0.087589,	
2017-06-24 21:27:52,027 Epoch[52] Batch [600]	Speed: 9.29 samples/sec	Train-FCNLogLoss=0.087536,	
2017-06-24 21:28:00,686 Epoch[52] Batch [610]	Speed: 9.24 samples/sec	Train-FCNLogLoss=0.087479,	
2017-06-24 21:28:09,541 Epoch[52] Batch [620]	Speed: 9.03 samples/sec	Train-FCNLogLoss=0.087405,	
2017-06-24 21:28:18,312 Epoch[52] Batch [630]	Speed: 9.12 samples/sec	Train-FCNLogLoss=0.087286,	
2017-06-24 21:28:27,287 Epoch[52] Batch [640]	Speed: 8.91 samples/sec	Train-FCNLogLoss=0.087266,	
2017-06-24 21:28:36,109 Epoch[52] Batch [650]	Speed: 9.07 samples/sec	Train-FCNLogLoss=0.087291,	
2017-06-24 21:28:44,670 Epoch[52] Batch [660]	Speed: 9.35 samples/sec	Train-FCNLogLoss=0.087322,	
2017-06-24 21:28:53,386 Epoch[52] Batch [670]	Speed: 9.18 samples/sec	Train-FCNLogLoss=0.087390,	
2017-06-24 21:29:01,981 Epoch[52] Batch [680]	Speed: 9.31 samples/sec	Train-FCNLogLoss=0.087326,	
2017-06-24 21:29:10,702 Epoch[52] Batch [690]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087249,	
2017-06-24 21:29:19,703 Epoch[52] Batch [700]	Speed: 8.89 samples/sec	Train-FCNLogLoss=0.087142,	
2017-06-24 21:29:28,406 Epoch[52] Batch [710]	Speed: 9.19 samples/sec	Train-FCNLogLoss=0.087197,	
2017-06-24 21:29:36,830 Epoch[52] Batch [720]	Speed: 9.50 samples/sec	Train-FCNLogLoss=0.087270,	
2017-06-24 21:29:46,105 Epoch[52] Batch [730]	Speed: 8.63 samples/sec	Train-FCNLogLoss=0.087302,	
2017-06-24 21:29:55,275 Epoch[52] Batch [740]	Speed: 8.72 samples/sec	Train-FCNLogLoss=0.087279,	
2017-06-24 21:29:56,867 Epoch[52] Train-FCNLogLoss=0.087299
2017-06-24 21:29:56,867 Epoch[52] Time cost=642.039
2017-06-24 21:30:00,227 Saved checkpoint to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0053.params"
2017-06-24 21:30:03,968 Saved optimizer state to "./output/cityscape/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5/leftImg8bit_train/deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5-0053.states"
2017-06-24 21:30:03,977 testing config:{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(1024, 2048)],
 'TEST': {'BATCH_IMAGES': 1, 'test_epoch': 53},
 'TRAIN': {'BATCH_IMAGES': 1,
           'CROP_HEIGHT': 768,
           'CROP_WIDTH': 1024,
           'ENABLE_CROP': True,
           'ENABLE_OHEM': False,
           'FLIP': True,
           'RESUME': False,
           'SHUFFLE': True,
           'begin_epoch': 0,
           'end_epoch': 53,
           'lr': 0.0005,
           'lr_step': '40.336',
           'model_prefix': 'deeplab_resnet_v1_101_cityscapes_segmentation_base_dilate5x5',
           'momentum': 0.9,
           'warmup': True,
           'warmup_lr': 5e-05,
           'warmup_step': 1000,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 19,
             'annotation_prefix': 'gtFine',
             'dataset': 'CityScape',
             'dataset_path': '/data/haowang/seg_dataset/',
             'image_set': 'leftImg8bit_train',
             'root_path': '/data/haowang/seg_dataset/',
             'test_image_set': 'leftImg8bit_val'},
 'default': {'frequent': 10, 'kvstore': 'device'},
 'gpus': '0,1,2,3,4,5,6,7',
 'network': {'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'FIXED_PARAMS_SHARED': ['conv1',
                                     'bn_conv1',
                                     'res2',
                                     'bn2',
                                     'res3',
                                     'bn3',
                                     'res4',
                                     'bn4',
                                     'gamma',
                                     'beta'],
             'IMAGE_STRIDE': 0,
             'PIXEL_MEANS': array([ 103.06,  115.9 ,  123.15]),
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0},
 'output_path': './output/cityscape',
 'symbol': 'resnet_v1_101_deeplab_dilate5x5'}

2017-06-24 21:30:22,736 testing 8/500 data 2.5102s net 0.3339s post 0.0229s
2017-06-24 21:30:24,220 testing 16/500 data 1.8595s net 0.2976s post 0.0181s
2017-06-24 21:30:26,705 testing 24/500 data 1.9501s net 0.3121s post 0.0164s
2017-06-24 21:30:28,938 testing 32/500 data 1.9534s net 0.2983s post 0.0155s
2017-06-24 21:30:31,244 testing 40/500 data 1.9705s net 0.2899s post 0.0146s
2017-06-24 21:30:33,591 testing 48/500 data 1.9826s net 0.2894s post 0.0150s
2017-06-24 21:30:35,974 testing 56/500 data 1.9952s net 0.2905s post 0.0149s
2017-06-24 21:30:38,457 testing 64/500 data 2.0104s net 0.2985s post 0.0147s
2017-06-24 21:30:40,829 testing 72/500 data 2.0184s net 0.2960s post 0.0144s
2017-06-24 21:30:43,108 testing 80/500 data 2.0179s net 0.2919s post 0.0141s
2017-06-24 21:30:45,316 testing 88/500 data 2.0090s net 0.2903s post 0.0140s
2017-06-24 21:30:47,653 testing 96/500 data 2.0109s net 0.2903s post 0.0141s
2017-06-24 21:30:49,914 testing 104/500 data 2.0095s net 0.2877s post 0.0139s
2017-06-24 21:30:52,245 testing 112/500 data 2.0128s net 0.2859s post 0.0139s
2017-06-24 21:30:54,630 testing 120/500 data 2.0164s net 0.2870s post 0.0140s
2017-06-24 21:30:57,036 testing 128/500 data 2.0230s net 0.2853s post 0.0146s
2017-06-24 21:30:59,402 testing 136/500 data 2.0269s net 0.2839s post 0.0146s
2017-06-24 21:31:01,723 testing 144/500 data 2.0218s net 0.2882s post 0.0152s
2017-06-24 21:31:04,040 testing 152/500 data 2.0234s net 0.2863s post 0.0151s
2017-06-24 21:31:06,637 testing 160/500 data 2.0321s net 0.2910s post 0.0152s
2017-06-24 21:31:09,013 testing 168/500 data 2.0358s net 0.2893s post 0.0151s
2017-06-24 21:31:11,399 testing 176/500 data 2.0390s net 0.2882s post 0.0150s
2017-06-24 21:31:13,939 testing 184/500 data 2.0438s net 0.2917s post 0.0154s
2017-06-24 21:31:16,374 testing 192/500 data 2.0484s net 0.2905s post 0.0154s
2017-06-24 21:31:18,894 testing 200/500 data 2.0564s net 0.2892s post 0.0154s
2017-06-24 21:31:21,542 testing 208/500 data 2.0629s net 0.2937s post 0.0155s
2017-06-24 21:31:23,964 testing 216/500 data 2.0632s net 0.2950s post 0.0157s
2017-06-24 21:31:26,368 testing 224/500 data 2.0658s net 0.2935s post 0.0156s
2017-06-24 21:31:28,722 testing 232/500 data 2.0654s net 0.2932s post 0.0156s
2017-06-24 21:31:31,207 testing 240/500 data 2.0703s net 0.2920s post 0.0156s
2017-06-24 21:31:33,692 testing 248/500 data 2.0749s net 0.2909s post 0.0156s
2017-06-24 21:31:35,785 testing 256/500 data 2.0671s net 0.2898s post 0.0155s
2017-06-24 21:31:38,558 testing 264/500 data 2.0765s net 0.2925s post 0.0155s
2017-06-24 21:31:40,955 testing 272/500 data 2.0779s net 0.2914s post 0.0155s
2017-06-24 21:31:43,333 testing 280/500 data 2.0776s net 0.2916s post 0.0155s
2017-06-24 21:31:45,643 testing 288/500 data 2.0766s net 0.2906s post 0.0154s
2017-06-24 21:31:48,186 testing 296/500 data 2.0813s net 0.2902s post 0.0155s
2017-06-24 21:31:50,585 testing 304/500 data 2.0818s net 0.2900s post 0.0154s
2017-06-24 21:31:53,067 testing 312/500 data 2.0812s net 0.2930s post 0.0155s
2017-06-24 21:31:55,473 testing 320/500 data 2.0823s net 0.2922s post 0.0156s
2017-06-24 21:31:58,156 testing 328/500 data 2.0870s net 0.2947s post 0.0156s
2017-06-24 21:32:00,491 testing 336/500 data 2.0835s net 0.2967s post 0.0155s
2017-06-24 21:32:03,115 testing 344/500 data 2.0897s net 0.2957s post 0.0156s
2017-06-24 21:32:05,326 testing 352/500 data 2.0864s net 0.2948s post 0.0155s
2017-06-24 21:32:08,168 testing 360/500 data 2.0945s net 0.2966s post 0.0156s
2017-06-24 21:32:10,563 testing 368/500 data 2.0951s net 0.2957s post 0.0156s
2017-06-24 21:32:12,948 testing 376/500 data 2.0956s net 0.2948s post 0.0155s
2017-06-24 21:32:15,476 testing 384/500 data 2.0982s net 0.2947s post 0.0155s
2017-06-24 21:32:17,902 testing 392/500 data 2.0994s net 0.2939s post 0.0155s
2017-06-24 21:32:19,877 testing 400/500 data 2.0916s net 0.2931s post 0.0154s
2017-06-24 21:32:22,356 testing 408/500 data 2.0931s net 0.2931s post 0.0155s
2017-06-24 21:32:24,978 testing 416/500 data 2.0980s net 0.2923s post 0.0156s
2017-06-24 21:32:26,890 testing 424/500 data 2.0894s net 0.2916s post 0.0156s
2017-06-24 21:32:28,676 testing 432/500 data 2.0788s net 0.2909s post 0.0156s
2017-06-24 21:32:31,223 testing 440/500 data 2.0799s net 0.2927s post 0.0156s
2017-06-24 21:32:33,655 testing 448/500 data 2.0812s net 0.2921s post 0.0157s
2017-06-24 21:32:35,764 testing 456/500 data 2.0755s net 0.2930s post 0.0156s
2017-06-24 21:32:38,138 testing 464/500 data 2.0760s net 0.2923s post 0.0156s
2017-06-24 21:32:40,572 testing 472/500 data 2.0775s net 0.2917s post 0.0156s
2017-06-24 21:32:42,245 testing 480/500 data 2.0657s net 0.2916s post 0.0156s
2017-06-24 21:32:44,844 testing 488/500 data 2.0695s net 0.2915s post 0.0157s
2017-06-24 21:32:47,232 testing 496/500 data 2.0704s net 0.2908s post 0.0156s
2017-06-24 21:32:48,217 testing 504/500 data 2.0447s net 0.2946s post 0.0155s
2017-06-24 21:34:44,411 evaluate segmentation: 

2017-06-24 21:34:44,411 IU_array:

2017-06-24 21:34:44,411 0.97862
2017-06-24 21:34:44,411 0.82949
2017-06-24 21:34:44,411 0.91254
2017-06-24 21:34:44,411 0.50657
2017-06-24 21:34:44,411 0.53230
2017-06-24 21:34:44,411 0.53286
2017-06-24 21:34:44,412 0.64063
2017-06-24 21:34:44,412 0.72317
2017-06-24 21:34:44,412 0.91318
2017-06-24 21:34:44,412 0.61573
2017-06-24 21:34:44,412 0.93599
2017-06-24 21:34:44,412 0.77568
2017-06-24 21:34:44,412 0.56484
2017-06-24 21:34:44,412 0.93527
2017-06-24 21:34:44,412 0.60646
2017-06-24 21:34:44,412 0.81519
2017-06-24 21:34:44,412 0.62819
2017-06-24 21:34:44,412 0.59221
2017-06-24 21:34:44,412 0.73968
2017-06-24 21:34:44,412 meanIU:0.72519
